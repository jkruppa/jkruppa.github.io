```{r echo = FALSE}
#| message: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, patchwork, ggimage,
               plotly, conflicted)
conflicts_prefer(plotly::layout)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
source("images/R/stat-modeling-R.R")
source("images/R/stat-modeling-basic.R")
set.seed(20250708)
theme_modeling <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(size = 12, face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

# Multiple lineare Regression {#sec-mult-reg-basic}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-basic.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"All models are approximations. Essentially, all models are wrong, but some are useful. However, the approximate nature of the model must always be borne in mind." --- George E. P. Box*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion (seit 07.2025)

Dieses Kapitel wird in den nächsten Wochen geschrieben und ist damit meine aktuelle Großbaustelle. Ich plane zum Beginn des WiSe 2025/26 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

In diesem Kapitel geht es um die multiple lineare Regression. Der große Unterschied zu der simplen linearen Regression ist, dass wir in der multiplen Regression mehr als eine Einflussvariable vorliegen haben. Damit wird unser Modell um einiges komplexer. Hier gibt es jetzt gewisse Überschneidungen mit den [Marginal effect models](#sec-marginal), die im Prinzip die Erweiterung der multiplen Regression sind. Wir können mit den *Marginal effect models* eben dann doch etwas anders lineare und nicht linare Regressionen interpretieren. Damit kannst du in dem Kapitel dann mehr über eine alternative Art der Interpretation von multiplen Modellen lernen. Ebenso gehe nicht hier so stark auf das [Modellieren in R](#sec-modeling-R) ein. Hier kannst du dann in dem entsprechenden Kapitel auch nochmal mehr lesen. Hier zeige ich dann die Basisanwendungen. Am Ende habe ich mich auch entschieden hier nur einen normalverteilten Messwert zu betrachten. Sonst wird es einfach viel zu komplex, wenn wir hier noch andere Verteilungen berücksichtigen. Dazu dann mehr in den entsprechenden [Kapiteln zur statistischen Modellierung](https://jkruppa.github.io/stat-modeling-preface.html).

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"In den folgenden Kapiteln gibt es immer mal wieder Redundanzen. Teilweise sind diese Redundanzen gewollt, denn eine gute Widerholung hilft ja immer. Meistens habe ich aber den Überblick verloren und fand, dass das Thema dann an der Stelle doch nochmal gut reinpasste. Ist so passiert." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

## Allgemeiner Hintergrund

> *"This idea of 'holding everything constant' though can be tricky to wrap your head around." --- [Andrew Heiss](https://www.andrewheiss.com/blog/2022/05/20/marginalia/#regression-sliders-switches-and-mixing-boards)*

Wenn wir über die multiple lineare Regression sprechen, dann sprechen wir immer über mehr als eine Einflussvariable. Dadurch können wir den Fall haben, dass wir nicht nur eine Kovariate sondern mehrere Kovariaten in einem Modell vorliegen haben. Zum Beispiel wollen wir wissen, ob die Sprungweite von dem Gewicht der Flöhe oder der Anzahl an Beinhaaren abhängt. Wir haben hier also mehrere kontinuierliche Einflussvariablen vorliegen. Ebenso können wir den Fall haben, dass uns nur kategoriale Einflussvariablen interessieren. Hat die Ernährungsform oder aber der Entwicklungsstand einen Einfluss auf die Sprungweite der Flöhe. Klassischerweise wären wir hier zwar auf dem ANOVA Pfad eines faktoriellen Experiments, aber wir können natürlich die Koeffzienten eines mehfaktoriellen Modells in der Form einer multiplen Regression interpretieren. Wenn wir dann keinen normalverteilten Messwert haben, dann bietet sich natürlich dennoch die multiple Regression als eine Analyseform an. Abschließend können wir natürlich auch kombinierte Modelle vorliegen haben. Wir haben also in unseren multiple Modell nicht nur Kovariaten oder Faktoren sondern eben eine Mischung aus beiden Formen. Das führt dann zu einer noch komplexeren Interpretation. Alle Fälle wollen wir uns hier in diesem Kapitel einmal an einem normalverteilten Messwert anschauen.

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use independent variable because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Jeder nennt in der Statistik sein Y und X wie er möchte. Da ich hier nicht nur von Y und X schreiben will, führe ich eben die Worte ein, die ich nutzen will. Damit sind die Worte dann auch richtig, da der Kontext definiert ist. Andere mögen es dann anders machen. Ich mache es eben dann so. Danke." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Testen. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren. Du kannst dann immer zu dem Kasten zurückgehen, wenn wir mal ein Wort nicht mehr ganz klar ist. Die fetten Begriffe sind die üblichen in den folgenden Kapiteln. Die anderen Worte werden immer mal wieder in der Literatur genutzt.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

#### Wie multiple Einflussvariablen interpretieren? {.unnumbered .unlisted}

Wie schon im Zitat am Anfang erwähnt, heißt die Regel, dass wir jeden Koeffizienten unseres Modell nur in soweit interpretieren können, wenn sich die anderen Einflussvariablen nicht ändern. Das klingt jetzt kryptisch und macht eigentlich nur Sinn, wenn man schon alles verstanden hat. Deshalb hier einmal die Analogie mit Schaltern und Schieberegelern. Wir können eine kategoriale Variable oder Faktor durch die Level durchschalten. Daher können wir uns den Effekt von weiblichen oder männlichen Flöhen anschauen. Es gibt aber nur diese beiden Möglichkeiten. Entweder steht der Schalter auf männlichen Floh oder aber auf weiblichen Floh. Etwas anderes ist es wenn wir uns eine Kovariate vorliegen haben. Eine kontinuierliche Einflussvariable können wir beliebig einstellen. Wir können das Gewicht eines Flohs eben hin und herschieben um einen Wert zu haben.

![Unterschied zwischen einer kategorialen Variable und einer kontinuierlichen Variable in einem statistischen Modell visualisiert als Schalter und Schieberegler. Übersetzt nach @heiss2022](images/marginal/slider-switch-annotated-trans.png){#fig-utest-intro-01 fig-align="center" width="100%"}

In einer multiplen Regression kombinieren wir nun alles miteinander. Wir haben eben eine Art Mischpult vorliegen. Auf unserem Mischpult finden wir eben Schalter und Schieberegler. Wir haben dann auch in unserem Modell Faktoren und Kovariaten vorliegen. Dann können wir auch Schalter auf verschiedene Positionen setzen und die Regler verschieden einstellen.

![Kombination verschiedener kategorialer Variablen und kontinuierlichen Variablen in einem statistischen Modell visualisiert als Mischpult. Übersetzt nach @heiss2022](images/marginal/mixer-board-annotated-trans.png){#fig-utest-intro-02 fig-align="center" width="100%"}

Worher kommt nun die Interpretation, dass wir eine Einflussvaribale nur interpretieren können, wenn wir den Rest der Einflussvariablen konstant halten? Wenn wir an dem Schieberegler des Gewichts der Flöhe drehen, dann müssen die anderen Schalter und Regler still stehen. Wir interpretieren dann eben das sich änderende Gewicht, *für weibliche Flöhe unter der Ernährung mit Ketchup*. Wir können nicht global das gesmate Modell interpretieren. Einen Ausweg bieten die [Marginal effect models](#sec-marginal), aber diese werden wir in diesem Kapitel nur am Rande behandeln. Dafür ist das Thema zu komplex. Daher behalte ich Kopf, wenn wir später einzelne Einflussvariablen betrachten, dann tuen wir das immer im Kontext fixierter anderer Einflussvariablen.

#### Eine Frage der Einheit! {.unnumbered .unlisted}

Die Einheit von den Messwerten oder auch Kovariaten hat einen nicht zu unterschätzenden Einfluss auf die Interpretation der Koeffizienten oder eben der Effekt einer multiplen linearen Modellierung. Da wir ja mehrere Einflussvariablen vorliegen haben bist du schnell dabei die Koeffizienten der Steigung untereinander zu vergleichen. Dann kommt man schnell zu einem Schluss der eventuell nicht wahr ist. Ich zeige dir hier einmal in der folgenden Abbildung den Fall, wo wir visuell die gleiche Steigung in den Daten vorliegen haben. Was sich aber in den beiden Abbildungen fundamental unterscheidet ist die Einheit der Kovariate.

![Der Zusammenhang von Hohlstrunk Boniturnote und Kopfgewicht sowie Strunkdurchmesser. In dem Beispiel ist gut der Zusammenhang zwischen der Steigung und der Einheit der Kovariate zu erkennen.](images/corr_example_einheit.jpeg){#fig-corr-01 fig-align="center"}

In der linken Abbildung ist der Koeffizient der Steigung des Kopfgewichts $0.021$ mehr mittlere Boniturnote pro Gramm Kopfgewicht. Das wirkt sehr klein. Im Gegensatz ist der Koeffizient der Steigung des Strunkdurchmessers $5.15$ mehr mittlere Boniturnoten pro Zentimeter Strunkdurchmesser. Es wirkt als hätte der Strunkdurchmesser einen viel größeren Effekt als das Gewicht auf die Boniturnoten. Das ist aber ein Trugschluss, wie wir dann gleich nochmal sehen werden. Ich zeige dir den Zusammenhang hier nochmal in der Tabelle.

|                  | Kopfgewicht \[g\]          | Strunkdurchmesser \[cm\]   |
|:-----------------|----------------------------|----------------------------|
| Gradengleichung  | $y = 0.021 \cdot x - 8.42$ | $y = 5.15 \cdot x - 16.65$ |
| Bestimmtheitsmaß | $R^2 = 0.74$               | $R^2 = 0.93$               |
| Faktor Steigung  | $\times1$                  | $\times 245.24$            |

: Vergleich vom Kopfgewicht und dem Strunkdurchmesser nach Gradengleichung, Bestimmtheitsmaß und dem Faktor der Steigung für Strunkdurchmesser. {#tbl-einheit}

Wir würden jetzt meinen, dass der Effekt des Strunkdurchmessers 245mal größer ist als der des Kopfgewichts. Das ist aber ein Trugschluss! Wir haben die Einheiten nicht beachtet. Die Spannweite bei dem Kopfgewicht geht von etwas über 450 Gramm bis fast 750 Gramm. Daher ist die Steigerung um eine Einheit nur eine kleine Menge mehr an Boniturnote. Bei dem Strunkdurchmesser haben wir als kleinsten Wert 3.5cm und als höchsten Wert 5cm für die Grade. Erhöhen wir den Strunkdurchmesser um 1 Zentimeter durchlaufen wir fast die gesamte Spannweite. Wenn du für den Vergleich eine einheitslose Steigung brauchst, dann schaue nochmal in dem [Kapitel zur Korrelation](#sec-lin-reg-corr) vorbei oder weiter unten in dem entsprechenden Abschnitt zur Einheit.

#### Wie verschiedene Modelle darstellen? {.unnumbered .unlisted}

Häufig stellt sich dann die Frage, wie so multiple Regressionsmodelle dargestellt werden können. Daher hier gleich einmal vorweg ein Beispiel für eine Darstellung einer multiplen linearen Regression in einer wissenschaftlichen Arbeit. In der Arbeit [Energy expenditure and obesity across the economic spectrum](https://www.pnas.org/doi/10.1073/pnas.2420902122) von @mcgrosky2025energy wird die multiple lineare Regression genutzt um den Zusammenhang von Energieaufnahme und dem Energieverbauch in veschiedenen Entwicklungsstufen von Ländern zu modellieren. Dabei kommt eigentlich ein recht spannendes Ergebnis heraus, wenn ich das einmal sehr kanpp zitieren darf. Es kommt eben mehr auf die Energieaufnahme als auf den Verbrauch an. Oder anders herum, wenn du abnehmen willst achte auf dein Essen und nicht so sehr auf deine Bewegung.

> *"Our analyses suggest that increased energy intake has been roughly 10 times more important than declining total energy expenditure (TEE) in driving the modern obesity crisis." --- @mcgrosky2025energy*

In der folgenden Tabelle siehst du dann eimal das multiple lineare Modell mit dem prozentualen Körperfettanteil als Messwert. Es wurden dann acht verschiedene multiple Modelle gerechnet und in jedem Modell wurden andere Einflussvariablen aufgenommen. In der vorletzten Zeile findest du dann noch das Bestimmtheitsmaß $R^2$, was dir angibt wie gut das Modell funktioniert hat. Hier wollen wir eigentlich einen Wert gegen Eins sehen, aber in Beobachtungsdaten wie hier, ist eine höhere Zahl erstmal eine bessere Zahl.

![Lineare Modelle für den Einfluss des Anteils ultraverarbeiteter Lebensmittel in der Ernährung (Anteil an der gesamten Kalorienaufnahme, %UPF) und des Fleischkonsums (kg pro Kopf) auf den Körperfettanteil. Signifikante Effekte (\*p\<0,05, \*\*p\<0,01, \*\*\*p\<0,001) in Fettdruck, negative Effekte in Blau. Quelle: @mcgrosky2025energy](images/mcgrosky2025energy.png){fig-align="center" width="100%"}

Was sagt uns jetzt die Tabelle aus? Zuerst einmal rechnen wir hier acht Modelle in den Spalten der Tabelle, die wir dann untereinander vergleichen. Wir nehmen verschiedene Einflussvariablen mit in das Modell, die alle in den Zeilen stehen. Teilweise ist das bei kategorialen Variablen wie dem Geschlecht die Gruppe angegeben. Wie interpretieren wir nun diese Tabelle? Hier einmal ein Auszug zu dem Einfluss des Fleischkonsum (eng. *per capita meat consumption*) in den letzten drei Spalten auf den Messwert Körperfetrprozent.

> *"\[...\], per capita meat consumption, another dietary change associated with development, was not significantly associated with fat percentage when added to models including percent ultraprocessed foods (UPF) \[i.e., industrial formulations of five or more ingredients (29)\]" --- @mcgrosky2025energy*

Was lesen wir hier? Wenn wir den Fleischkonsum zusammen mit den hochverarbeiteten Lebensmittel mit ins Modell nehmen, dann wird der Fleichkonsum nicht signifikant. Dies ist eine Art eine multiple lineare Regression zu rechnen und die Einflussvariablen untereinander zu vergleichen. Mehr dazu dann in den folgenden Abschnitten und den entsprechenden [Kapiteln zur statistischen Modellierung](https://jkruppa.github.io/stat-modeling-preface.html).

::: callout-note
## Defintion von hochverarbeiteten Lebensmittel (eng. *ultraprocessed foods*)

Wir können in der Abrbeit von @gibney2019ultra nocheinmal nachlesen, was die aktuelle Definition eines hochverarbeiteten Lebensmittel (eng. *ultraprocessed foods*) ist. Das ist ja immer wieder ein Streitpunkt, der aktuell ja auch noch offen ist. Wir halten uns einmal an die folgende Definition.

> *"Industrial formulations typically with 5 or more and usually many ingredients. Besides salt, sugar, oils, and fats, ingredients of ultra-processed foods include food substances not commonly used in culinary preparations, such as hydrolyzed protein, modified starches, and hydrogenated or interesterified oils, and additives whose purpose is to imitate sensorial qualities of unprocessed or minimally processed foods and their culinary preparations or to disguise undesirable qualities of the final product, such as colorants, flavorings, nonsugar sweeteners, emulsifiers, humectants, sequestrants, and firming, bulking, de-foaming, anticaking, and glazing agents." --- @gibney2019ultra*
:::

In diesem Kapitel findest du dann noch am Ende einige Abschnitte zu Dingen von Interesse. Wenn wir nämlich über den Effekt sprechen, dann müssen wir auch nochmal über die Einheiten von den Einflussvariablen sprechen. Wenn diese sehr unterschiedliche sind, dann kann das zu Problemen führen. Auch können Einflussvariablen mit sehr großen numerischen Werten ein Problem in der Interpretation sein. Dann schauen wir nochmal auf die Korrelation der Einflussvariablen. Eigentlich sollten ja alle Einflussvariablen untereinander unabhängig sein. Dann wollen wir nochmal schauen, wie wir den verschiedene multiple Modelle untereinander vergleichen können um das beste multiple Modell zu finden.

Jetzt kommen wir aber nochmal zu dem theoretischen Hintergrund. Wir wollen hier nochmal gleich verstehen, wie die multiplen Modelle aufgebaut sind und wie die Modelle in R dargestellt werden. Wenn du dich mit dem allgemeinen Hintergrund zufrieden gibst, dann kannst du auch gerne direkt in die Beispiele und deren Auswertung springen. Oder eben dann nochmal später zurückkommen, wenn der Bedarf besteht.

## Theoretischer Hintergrund

In dem theoretischen Hintergrund der multiplen Modelle bleibe ich etwas oberflächlich und gehe nicht auf die mathematischen Hintergründe tiefer ein. Das lohnt hier auch nicht weiter. In den Anwendungen habe ich dann immer noch die theoretische Berechnung in R ergänzt, die dir dann nochmal zeigt, wie in R intern die Modelle gerechnet werden. Ganz allgemein kann ich das Buch von @kery2010introduction wärmstens empfehlen. Dort habe ich viel über die Modelle und die Berechnungen gelernt. In dem Zusammenhang kann ich auch noch @dormann2013parametrische empfehlen, wenn es um die Maximum Likelihood Methode geht, die dort gut beschrieben ist. Ich gebe hier dann die Zusammenfassung wieder.

Beginnen wir nochmal mit dem klassischen statistischen Modell in der folgenden Abbildung. Wir haben Daten vorliegen, die wir in ein Modell und einen Fehler zerlegen wollen. Das liest sich sehr allgemein, in der Praxis haben wir auf der linken Seite den beobachteten Messwert Y stehen und auf der linken Seite das Modell aus dem der erklärte Anteil am Y rauskommt. Die Differenz zu den beobachteten Messwerten ist dann der Fehler. Somit ist unser Modell die Kombination aus dem Messwert und unseren Einflussvariablen. Was die Einflussvariablen an dem Messwert nicht erklären können wandert in den Fehler. Somit wollen wir einen geringen Fehler in unserer Modellierung.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 1.5
#| fig-width: 7
#| fig-cap: "Der Zusammenhang von Daten, dem statistischen Modell und dem Fehler. Das Modell versucht durch ein statistisches Modell $f(x)$ den Zusammenhang zwischen den Einflussvariablen dem Messwert zu erklären. Den Anteil des unerklärten Messwert geht in den Fehlerterm. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-model-abstract

p_model_abstract 
```

Erinnern wir uns nochmal an das simple und multiple lineares Modell. Die beiden Modelle entscheiden sich durch die Anzahl an Einflussvariablen. In der folgenden Abbildung siehst du nochmal das simple lineare Modell. Wir haben hier eine Einflussvariable X. Dann kommen noch die Koeffizienten $\beta_0$ für den Intercept und der Koeffizient $\beta_1$ für die Steigung der eine Einflussvariable hinzu. Alles was wir nicht durch die Grae erklären können, wandert dann in die Residuen oder Fehler $\epsilon$. Eine klassische Gradengleichung mit einer Einflussvariable.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der simplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ für die Steigung der Graden für eine Einflussvariable $x_1$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-07

p_simple_model
```

In diesem Kapitel erweitern wir das simple lineare Modell um mehr Einflussvariablen. Dann erhalten wir ein multiples lineares Modell wie in der folgenden Abbildung. Meistens haben wir dann mehr als zwei Einflussvariablen sondern eben $p$ Stück. Jede dieser Einflussvariablen hat dann eine eigene Stigung. Wir haben dann aber immer noch nur einen Intercept vorliegen. Auch haben wir dann am Ende nur einen Wert für die Residuen oder Fehler. Die Einflussvariablen können eine beliebige Kombination an Kovariten und Faktoren sein.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der multiplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ bis $\\beta_p$ für die partielle Steigung der Graden für jede Einflussvariable $x_1$ bis $x_p$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-04

p_mult_model 
```

Jetzt können wir uns nochmal die Formelschreibweise in R anschauen. Wir brauchen hier natürlich nicht die Koeffizienten zu benennen, denn wir wollen die Werte für die Steigung und den Intercept ja durch die multiple Regression bestimmen. Wir schreiben dann auf die linke Seite der Tilde `~` unseren Messwert und auf die rechte Seite dann die Einflussvariablen durch ein Plus `+` miteinander verbunden. Wir lernen dann im Kapitel zum [Modellieren in R](#sec-modeling-R) noch andere Möglichkeiten in der Formelschreibweise in R. Häufig reichen die Grundlagen aber aus.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Statistische Modellschreibweise in R mit dem Messwert auf der linken Seite und den Einflussvariablen auf der rechten Seite der Tilde. Die Platzhalter $Y$ und $X$ werden durch die Spaltennamen im Datensatz ersetzt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-22

p_lhs_rhs_mult_r 
```

Jetzt könnte man meinen, so kompliziert ist es ja dann doch nicht. Dafür musst du aber noch wissen, dass wir nicht nur eine Art von Messwert vorliegen haben. Jeder Messwert auf der linken Seite der Tilde folgt einer Verteilung. Zwar sind die Arten der Verteilungen in etwa begrenz, aber wir haben doch einige vorliegen. Daher müssen wir abhängig von der Verteilunsgfamilie noch die Regression ändern. In der folgenden Abbildung habe ich dir einmal den Zusammenhang der schrecklich netten Verteilunsgfamilie zusammengefasst. Wir müssen eben entscheiden, welcher Verteilungsfamilie unser Messwert angehört und dann eben schauen, wie unsere Einflussvariablen beschaffen sind. Daraus ergibt sich dann die Interpretation des statistischen Modells. Mehr dazu dann in den folgenden Abschnitten und den entsprechenden [Kapiteln zur statistischen Modellierung](https://jkruppa.github.io/stat-modeling-preface.html).

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.7
#| fig-width: 7
#| fig-cap: "Erweiterte Darstellung der statistischen Modellierung. Die Messwerte $Y$ folgen einer Verteilung. Die Einflussvariablen liegen kontinuierlich als Kovariaten oder aber kategorial als Faktoren vor. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-09

p_lhs_rhs_detail
```

Damit sind wir hier für das erste auch durch mit der theoretischen Betrachtung. Ich habe dann bei dem kausalen Modellen immer noch einen Tab ergänzt in dem ich mehr auf die Hinetrgründe eingehe. Wir wollen hier aber nichts händsich rechnen, so dass ich mich auf die praktsiche Umsetzung in R konzentriere. Teilweise gibt es dann wieder Überschneidungen mit der ANOVA oder anderen Kapiteln, aber das ist dann eben auch so gewollt.

::: {layout="[25,75]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> *Wenn du jetzt denkst 'Hä? Was soll denn mehrdimensional bedeuten?', dann besuche doch einmal die fantastische Seite [Explained Visually \| Ordinary Least Squares Regression](https://setosa.io/ev/ordinary-least-squares-regression/) um selber zu erfahren, was eine multiple lineare Regression macht. Auf der Seite findest du interaktive Abbildungen, die dir das Konzept der linearen Regression sehr anschaulich nachvollziehen lassen.*
:::

::: callout-tip
## Weitere Tutorien für die multiple lineare Regression

Wir immer geht natürlich mehr als ich hier Vorstellen kann. Du findest im Folgenden Tutorien, die mich hier in dem Kapitel inspiriert haben. Ich habe mich ja in diesem Kapitel auf die Durchführbarkeit in R und die allgemeine Verständlichkeit konzentriert.

-   Wir funktioniert nun so eine lineare Regression und was sind den jetzt eigentlich die Koeffizienten $\beta_0$ und $\beta_1$ eigentlich? Hier gibt es die fantastische Seite [Explained Visually \| Ordinary Least Squares Regression](https://setosa.io/ev/ordinary-least-squares-regression/), die dir nochmal erlaubt selbe mit Punkten in einem Scatterplot zu spielen und zu sehen wie sich dann die Regressionsgleichung ändert.
-   Das Buch [Tidy Modeling with R](https://www.tmwr.org/) gibt nochmal einen tieferen Einblick in das Modellieren in R. Wir immer, es ist ein Vorschlag aber kein Muss.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom,
               see, performance, car, parameters,
               conflicted)
conflicts_prefer(magrittr::set_names)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

In diesem Kapitel schauen wir uns zwei Datensätze an. Zum einen den Datensatz zu den Sprungweiten von Flöhen und anderen Messwerten. Eigentlich ein faktorielles Experiment mit zwei Faktoren und einiges an spannenden Kovariaten. An diesem Datensatz können wir dann die verschiedenen multiplen Regressionen einmal nachvollziehen. Als zweiten Datensatz habe ich Schlangen mitgebracht. Der Datensatz ist super klein und auch sehr künstlich, da wir uns hier nur die theoretischen Berechnungen in R anschauen wollen. Da brauche ich nicht viel und da habe ich diesen Datensatz dann genutzt.

#### Modellierung von Flöhen {.unnumbered .unlisted}

![In unseren Daten zu der Modellierung der Flöhe schauen wir auf verschiedene Ernährungsformen sowie Entwicklungsstadien und fragen uns, ob sich die Sprungweiten und andere Messwerte unterscheiden.](images/flea_feeding_stage.png){#fig-flea-yedi fig-align="center" width="60%"}

Der folgende Datensatz zu den Sprungweiten und anderen Messwerten von juvenilen und adulten Flöhen ist von mir so gebaut, dass wir hier usn einige Aspekte der multiplen Regression gut anschauen können. Als Hauptfaktor haben wir hier drei verschiedene Ernährungsformen vorliegen und betrachten als zweiten Faktor eben den Entwicklungsstand der Flöhe. Dazu kommen dann noch eine ganze Reihe von Einflussvariablen wie das Gewicht und Laborwerte. Insgesamt also ein sehr großer Datensatz. Wir schauen uns dann aber immer nur einzelene Kombinationen von Einflussvariablen an. Als meinen Messwert nehme ich dann immer die Sprungweite als einen normalverteilten Messwert.

```{r}
flea_model_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(feeding = as_factor(feeding),
         stage = as_factor(stage),
         bonitur = as.numeric(bonitur),
         infected = as.numeric(infected))
```

Da der Datensatz so groß ist, schaue ich mir hier nicht alle möglichen Abbildungen an sondern gebe dir hier einmal einen Auszug aus der Tabelle wieder. Wie du siehst haben wir einiges an Möglichkeiten mit den Daten. Wir haben hier verschiedene Einflussvariablen sowie verschiedene Messwerte vorliegen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table
#| tbl-cap: "Tabelle der Modelldaten zu den Sprungweiten und den Ernährungsformen von juvenilen und adulten Flöhen."

model_raw_tbl <- read_excel("data/fleas_model_data.xlsx")

rbind(head(model_raw_tbl, n = 3),
      rep("...", times = ncol(model_raw_tbl)),
      tail(model_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

In den folgenden Abschnitten nehem ich dann immer wieder einzelne Einflussvariablen und kombiniere diese miteinander in ein statistsiches Modell. Dabei nehme ich als Messwert immer die Sprungweite der Flöhe. Mehr Informationen findest du dann im [Kapitel zu von der Modellierung der Flöhe](#sec-example-flea-model). Dort sind dann auch die Einheiten und übersichtliche Abbildungen zu finden.

#### Theoretischer Datensatz {.unnumbered .unlisted}

![In unseren theoretischen Datensatz schauen wir uns die Körperlängen von verschiedenen Schlangen mit unterschiedlichen Einflussvariablen an. Wir schauen uns die Körperfarbe sowie die Regionen der Messung an.](images/snakes_region.png){fig-align="center" width="100%"}

Abschließend kommen wir noch zu einem theoretischen Datensatz dem ich @kery2010introduction entlehnt habe. Ich möchte nochmal zeigen, wie R intern mit der Modellmatrix die Berechnungen durchführt. Das hat mich interessiert und deshalb habe ich es einmal für mein Verständnis aufgeschrieben. Wenn es dich auch interessiert, dann kannst du in den entsprechenden Tabs weiter unten einmal nachschauen. Hier also erstmal ein sehr simpler theoretischer Datensatz zu Körperlängen von Schlangen. Wir müssen hier dann noch die Faktoren einmal umwandeln, damit wir auch später die Modellmatrix sauber vorliegen haben. Deshalb hier die explizite Benennung der Level der Faktoren in dem Datensatz.

```{r}
#| message: false
snake_tbl <- read_xlsx("data/regression_data.xlsx", sheet = "theory_mult") |> 
  mutate(region = factor(region, levels = c("west", "nord")),
         color = factor(color, levels = c("schwarz", "rot", "blau")))
```

In der folgenden Tabelle ist der Datensatz `snake_tbl` nochmal dargestellt. Wir haben die Schlangenlänge `svl` als Messwert sowie das Gewicht der Schlangen `mass` sowie den Durchmesser der Schlange $diameter$ als kontinuierliche Einflussvariable, die Sammelregion `region` und die Farbe der Schlangen `color` und als kategoriale Einflussvariablen mit unterschiedlichen Anzahlen an Gruppen. Die Region `region` ist also ein Faktor mit zwei Leveln und die Schlangenfarbe `color` ein Faktor mit drei Leveln. Ich nutze den Datensatz also einmal als einen Spieldatensatz um die Modellierung theoretisch besser nachvollziehen zu können.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz zu den Körperlängen als Messwert von acht Schlangen mit verschiedenen Einflussvariablen. Die Einflussvariablen haben verschiedene Eigenschaften und müssen daher unterschiedliche modelliert werden."
#| label: tbl-snakes

snake_tbl |> 
  kable(align = "c", "pipe")
```

Damit haben wir dann auch die beiden Datensätze zusammen. Im Folgenden gehe ich dann einmal auf das kausale Modell sowie das prädktive Modell ein. Hier nimmt das kausale Modell mehr Platz ein, da wir eigentlich in der multiplen Regression mehr an dem Zusammenhang interessiert sind. Die Prädiktion ist aber immer mehr im Vormarsch und es kommt hier wirklich auf deine Fragestellung an. Es kann sogar sein, dass du mit vorgesagten Werten mehr Informationen aus deinen Daten ziehen kannst, als mit einem kausalen Modell.

## Kausales Modell

Was ist das kausale Modell? Wir wollen wissen, welchen Einfluss die Einflussvariablen auf den Messwert haben. Das ist jetzt erstmal einleuchtend. Wir bauen uns ein Modell und wollen wissen, ob es einen kausalen Zusammenhang zwischen einzelnen Kovariaten oder Faktoren und einem Messwert gibt. Dabei müssen nicht alle Kovariaten und alle Faktoren einen signifikanten Einfluss haben. Es geht hier eher um eine Art vor und zurück. Wir probieren verschiedene Modell aus und wollen das beste Modell finden. Dafür müssen wir abr verstehen, was die Interpretation der einzelnen Modell ist. Daher schauen wir uns jetzt einmal rein kovariate Modelle, reine faktorielle Modelle und Kombinationen davon an.

### Mehrkovariates Modell

Beginnen wir mit einem mehrkovariaten Modell. Im Gegensatz zu einem einkovaraten Modell in der simplen linearen Regression haben wir jetzt nicht mehr nur eine Kovariate sondern mindestens zwei Kovariaten im Modell. Für die Interpretation nutzen wir hier nur ein zweikovariates Modell inhaltlich lässt sich das Modell aber auch auf mehr als zwei Kovariaten erweitern. In der folgenden Abbildung siehst du einmal das Modell dargestellt. Wir haben einen Messwert auf der linken Seite und zwei Kovariaten auf der rechten Seite. Wir wollen jetzt wissen, wie die beiden Kovariaten den Messwert erklären.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-12

p_2cov_model
```

Die Grundidee ist in der folgenen Abbildung einmal dargestellt. Du kennst dich ja schon mit der simplen linearen Regression aus. In dem mehrkovariaten Fall haben wir nun im zweikovariaten Fall einen Scatterplit in drei Dimensionen vorliegen. Je mehr Kovariaten desto hoöher wird die Dimension. Ich kann aber nicht einen vier dimensionalen Scatterplot darstellen, daher hier die Einschränkung auf zwei Kovariaten. Wie du siehst zeichnen wir jetzt nicht eine Grade im eigentlichen Sinne sondern eine Ebene durch die Punkte hindurch. Dennoch wird der quadratische Abstand zu den Punkten eben über diese Ebene minimiert. Wir erhalten somit auch nur für jede einzelne Beobachtung einen Wert für die Residuen wieder.

![Ein 3D Scatterplot von zwei Kovariaten und einem Messwert Y in drei Dimensionen. Statt eine Grade wird ein Ebene (eng. *regression plane*) durch die Punkte im dreidimensionalen Raum gelegt. Die Residuen sind die Abweichungen der Beobachtungen zu den Werten auf der Ebene. Modifiziert nach https://stackoverflow.com/users/8770170/frans-rodenburg](images/mult-reg-scatter3d-00.png){#fig-scatter3d-00 fig-align="center" width="100%"}

Die Darstellung einer multiplen linearen Regression ist vollkommen unüblich. Wir zeigen eigentlich nicht die Daten als Visualisierung sondern müssen uns dann mit statistischen Maßzahlen helfen, wenn wir wissen wollen, ob unsere Regression gelungen ist. Deshalb auch im Folgenden einmal die praktische Anwendung in R und wie wir die zweikovariate Regression interpretieren.

::: panel-tabset
## Praktisch in R

Dann rechnen wir einmal eine zweikovariate Analyse in R. Dafür brauchen wir einmal einen normalverteilten Messwert. Das ist nicht notwendig, aber für die Interpretation gleich viel einfacher. Dann nehmen wir noch die zwei Kovariten des Flohgewichts und der mitleren Anzahl an Beinhaaren mit ins Modell. Damit haben wir also ein klassisches kovariates Modell.

```{r}
cov2_fit <- lm(jump_length ~ weight + count_leg, data = flea_model_tbl) 
```

Dann können wir uns auch schon die drei Koeffizienten für den Intercept und die Steigungen für die beiden Kovariaten wiedergeben lassen. Da wir das Modell so rechnen, dass wir beide Kovariaten mit ins Modell nehmen, haben wir hier natürlich auch jeweils für die anderen Kovariate den Effekt adjustiert. Will heißen, wir schauen uns den Effekt des Gewichts bereinigt um den Effekt der Beinhaare auf die Sprungweiten an. Und eben umgekehrt dann auch.

```{r}
cov2_fit |> 
  coef() |> round(2)
```

Jetzt müssen wir bei den Koeffizienten aufpassen. Ohne die Einheit, würde man denken, dass der Effekt der mittleren Beinzahl auf die Sprungweite klein wäre. Aber wir haben hier die Steigung pro Änderung der Einheit um Eins in den Einflussvariablen. Die Beinhaare haben aber eine Spannweite von 9 bis 1351! Das ist eine ganz andere Änderung als beim Gewicht mit einer Spannweite von 2.71mg bis 25.73mg. Deshalb brauchen wir auch hier dann die zusammenfassende Ausgabe um einmal die Signifikanz bewerten zu können.

```{r}
#| eval: true
cov2_fit |> summary()
```

Die Zusammenfassugn ist manchmal etwas schwer zu lesen, deshalb habe ich dir einmal die Ausgabe im Folgenden annotiert. Hier siehst du dann auch sehr schön, dass die mittlere Anzahl an Haaren auf den Beinen auch signifikant ist. Ansonsten sieht unser Modell recht gut aus. die Resdiuen sind einigermaßen normalverteilt und auch das Bestimmtheitsmaß ist relativ hoch. Der Fehler der Residuen könnte mit 17.78 etwas kleiner sein. Am Ende passt das Modell.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "Annotierte Ausgabe der Funktion `summary()` aus einer linearen Modellanpassung mit der Funktion `lm()`. Die Ausgabe der Funktion teilt sich grob in drei informative Bereiche: Informationen zu den Residuen, Informationen zu den Koeffizienten und Informationen zu der Modelgüte. *[Zum Vergrößern anklicken]*"
#| label: fig-model-c2-summary

p_lm_summary_cov2_explained
```

Was sagt jetzt noch diese seltsame ANOVA aus? Wir scheinen hier ja noch eine ANOVA am Ende zu rechnen. Das ist hier jetzt nicht die einfaktorielle ANOVA, die wir aus den simplen linearen Regressionen kennen, sondern beinhaltet einen Modellvergleich. Welche Modelle vergleichen wir aber nun? In diesem Fall einmal das Nullmodell und das volle Modell, welches wir gerechnet haben. Was soll der Name Nullmodell bedeuten? Wir haben in diesem Modell nichts weiter außer dem Intercept. Hier einmal das Nullmodel gerechnet.

```{r}
lm(jump_length ~ 1, data = flea_model_tbl)
```

Wir erhalten also einmal den globalen Mittelwert über alle Sprungweiten wiedergeben. Jetzt können wir mit der ANOVA auch einen MOdellvergleich rechnen. Wir wollen wissen, ob sich unser volles zweifaktorielles Modell von dem Modell nur mit dem Intercept unterscheidet. Da sehen wir wieder den p-Wert wie wir ihn auch oben in der Ausgabe haben.

```{r}
anova(lm(jump_length ~ 1, data = flea_model_tbl),
      lm(jump_length ~ weight + count_leg, data = flea_model_tbl))
```

Brauchen wir den Vergleich? Meistens nicht. Denn wir können ja direkt schauen, ob sich die Koeffizienten sigifkant von Nhull unterscheiden. Dann brauchen wir auch nur sehr selten den Vergleich zu dem Nullmodell. Das Nullmodell beinhaltet eigentlich nie eine Information, die wir wirklich brauchen. Daher ist es eher ein Artefakt der Programmierung aus den Anfangstagen. Wir können es, also packen wir es mit in die Ausgabe rein.

Die folgende Abbildung dient hier nur der Anschauung. Wir publizieren eigentlich nicht eine Visualisierung in drei Dimensionen. Wie du hier schon siehst, ist die Darstellung durch die unterschiedlich Minima- und Maximawerte des Gewichts und der Anzahl an Beinhaaren sehr verdreht. Häufig sieht dann die Abbildung in drei Dimensionen nur gut aus, wenn alle drei Achsen die gleichen Spannweiten an Werten haben. Daher dient die Abbildung eher nochmal zum Verständnis der Berechnungen der Residuen aus der Ebene der Regression.

![Ein 3D Scatterplot von den zwei Kovariaten Gewicht der Flöhe in \[mg\] sowie der mittleren Anzahl an Beinhaaren und der Sprungweite in drei Dimensionen. Statt eine Grade wird ein Ebene (eng. *regression plane*) durch die Punkte im dreidimensionalen Raum gelegt. Die Residuen sind die Abweichungen der Beobachtungen zu den Werten auf der Ebene.](images/mult-reg-scatter3d-01.png){fig-align="center" width="100%"}

## Theoretisch in R

```{r}
model.matrix(svl ~ mass + diameter, data = snake_tbl) |> as_tibble() 
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 6 & 9 \\
  1 & 8 & 3 \\
  1 & 5 & 6 \\
  1 & 7 & 7 \\
  1 & 9 & 5 \\
  1 & 11& 4 \\
  1 & 12& 10 \\
  1 & 10& 11 \\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} \\
  \beta_{diameter} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
$$

```{r}
cov2_fit <- lm(svl ~ mass + diameter, data = snake_tbl)
```

```{r}
cov2_fit |> coef() |> round(2)
```

```{r}
cov2_fit |> residuals() |> round(2)
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  51 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  28.27 & 6 \cdot 2.67 & 9 \cdot -0.30 \\
  28.27 & 8 \cdot 2.67 & 3 \cdot -0.30 \\
  28.27 & 5 \cdot 2.67 & 6 \cdot -0.30 \\
  28.27 & 7 \cdot 2.67 & 7 \cdot -0.30 \\
  28.27 & 9 \cdot 2.67 & 5 \cdot -0.30 \\
  28.27 & 11 \cdot 2.67 & 4 \cdot -0.30 \\
  28.27 & 12 \cdot 2.67 & 10 \cdot -0.30 \\
  28.27 & 10 \cdot 2.67 & 11 \cdot -0.30 \\
 \end{pmatrix} +
  \begin{pmatrix}
  -1.56 \\
  -3.71 \\
  -0.80 \\
  +6.17 \\
  +1.22 \\
  +0.58 \\
  +0.73 \\
  -2.63 \\
 \end{pmatrix}
$$

```{r}
c(28.27 +  6*2.67 + 9*(-0.30) - 1.56,
  28.27 +  8*2.67 + 3*(-0.30) - 3.71,
  28.27 +  5*2.67 + 6*(-0.30) - 0.80,
  28.27 +  7*2.67 + 7*(-0.30) + 6.17,
  28.27 +  9*2.67 + 5*(-0.30) + 1.22,
  28.27 + 11*2.67 + 4*(-0.30) + 0.58,
  28.27 + 12*2.67 + 10*(-0.30) + 0.73,
  28.27 + 10*2.67 + 11*(-0.30) - 2.63) |> round()
```

```{r}
snake_tbl |> pull(svl)
```

## Simulation

```{r}
cov2_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   c_2 = rnorm(10, 0, 1),
                   y = 2 + 
                       1 * c_1 + 
                       2 * c_2 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2, cov2_tbl) |> 
  coef() |> round(2)
```
:::

### Mehrfaktorielles Modell

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln und deren Interaktion $f_A \\times f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-13

p_2fac_model  +
  labs(title = "") 
```

::: panel-tabset
## Praktisch in R

```{r}
fac2_fit <- lm(jump_length ~ feeding + stage + stage:feeding, data = flea_model_tbl) 
```

```{r}
fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
fac2_fit |> summary()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "Annotierte Ausgabe der Funktion `summary()` aus einer linearen Modellanpassung mit der Funktion `lm()`. Die Ausgabe der Funktion teilt sich grob in drei informative Bereiche: Informationen zu den Residuen, Informationen zu den Koeffizienten und Informationen zu der Modelgüte. Die Erklärung der Schätzer (eng. *estimate*) kann in der folgenden Tabelle nachvollzogen werden. *[Zum Vergrößern anklicken]*"
#| label: fig-model-f2-summary

p_lm_summary_fac2_explained
```

text

text

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac2
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = rep(c("sugar", "blood", "ketchup"), each = 2),
       "$f_{stage}$" = rep(c("adult", "juvenile"), 3),
       "$\\bar{Y}$" = c(78.9, 61.03, 99.71, 116.03, 92.15, 111.24), 
       "$\\boldsymbol{\\beta_{0}}$" = 78.98,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, NA, 20.73, 20.73, NA, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, NA, NA, 13.17, 13.17),
       "$\\boldsymbol{\\beta_{juvenile}}$" = c(NA, -17.94, NA, -17.94, NA, -17.94),
       "$\\boldsymbol{\\beta_{blood \\times juvenile}}$" = c(NA, NA, NA, 34.26, NA, NA),
       "$\\boldsymbol{\\beta_{ketchup \\times juvenile}}$" = c(NA, NA, NA, NA, NA, 37.03)) |> 
  kable(align = "c", "pipe")
```

text

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe.  *[Zum Vergrößern anklicken]*"
#| label: fig-model-basis-fac2

ggplot(flea_model_tbl, aes(feeding, jump_length, color = stage)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 78.98, linewidth = 0.5, color = "#CC79A7") +
  geom_point(position = position_dodge(0.2)) +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y.., 2)), 
               position = position_nudge(c(-0.3, 0.3, -0.3, 0.3, -0.3, 0.3)),
               show.legend = FALSE) +
  scale_x_discrete(labels = c("Zuckerwasser", "Blut", "Ketchup")) +
  labs(title = "Zweifaktorielles Modell mit Interaktion",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der\nBehandlung Zuckerwasser bei den adulten Flöhen",
       x = "Fütterungsart", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top")
```

## Theoretisch in R

Aus Gründen der Einfachheit lassen wir einmal die Interaktion weg.

```{r}
model.matrix(svl ~ color + region, data = snake_tbl) |> as_tibble() 
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 0 & 0 & 0 \\
  1 & 0 & 0 & 0 \\
  1 & 1 & 0 & 0 \\
  1 & 1 & 0 & 1 \\
  1 & 1 & 0 & 1 \\
  1 & 0 & 1 & 1 \\
  1 & 0 & 1 & 1 \\
  1 & 0 & 1 & 1 \\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta^{color}_{rot} \\
  \beta^{color}_{blau} \\
  \beta^{region}_{nord} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
$$

```{r}
fac2_fit <- lm(svl ~ color + region, data = snake_tbl)
```

```{r}
fac2_fit |> coef() |> round(2)
```

```{r}
fac2_fit |> residuals() |> round(2)
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  51 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  42.50 & 0 \cdot -3.50 & 0 \cdot -0.33 & 0 \cdot 12.50 \\
  42.50 & 0 \cdot -3.50 & 0 \cdot -0.33 & 0 \cdot 12.50 \\
  42.50 & 1 \cdot -3.50 & 0 \cdot -0.33 & 0 \cdot 12.50 \\
  42.50 & 1 \cdot -3.50 & 0 \cdot -0.33 & 1 \cdot 12.50 \\
  42.50 & 1 \cdot -3.50 & 0 \cdot -0.33 & 1 \cdot 12.50 \\
  42.50 & 0 \cdot -3.50 & 1 \cdot -0.33 & 1 \cdot 12.50 \\
  42.50 & 0 \cdot -3.50 & 1 \cdot -0.33 & 1 \cdot 12.50 \\
  42.50 & 0 \cdot -3.50 & 1 \cdot -0.33 & 1 \cdot 12.50 \\
 \end{pmatrix} +
  \begin{pmatrix}
  -2.50 \\
  +2.50 \\
  0.00 \\
  -0.50 \\
  +0.50 \\
  +2.33 \\
  +3.33 \\
  -5.67 \\
 \end{pmatrix}
$$

```{r}
c(42.50 +  0*(-3.50) + 0*(-0.33) + 0*12.50 - 2.50,
  42.50 +  0*(-3.50) + 0*(-0.33) + 0*12.50 + 2.50,
  42.50 +  1*(-3.50) + 0*(-0.33) + 0*12.50 + 0.00,
  42.50 +  1*(-3.50) + 0*(-0.33) + 1*12.50 - 0.50,
  42.50 +  1*(-3.50) + 0*(-0.33) + 1*12.50 + 0.50,
  42.50 +  0*(-3.50) + 1*(-0.33) + 1*12.50 + 2.33,
  42.50 +  0*(-3.50) + 1*(-0.33) + 1*12.50 + 3.33,
  42.50 +  0*(-3.50) + 1*(-0.33) + 1*12.50 - 5.67) |> round()
```

```{r}
snake_tbl |> pull(svl)
```

## Simulation

```{r}
fac2_tbl <- tibble(f_a = rep(gl(3, 5), 2),
                   f_b = gl(2, 15),
                   y = 2 + 
                       2 * as.numeric(f_a) + 
                       3 * as.numeric(f_b) + 
                       2 * as.numeric(f_a) * as.numeric(f_b) +
                           rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + f_b + f_a:f_b, fac2_tbl) |> 
  coef() |> round(2)
```
:::

### Kombinierte Modelle

Wenn wir eine Kovariate mit einem Faktor kombinieren, dann kippen wir den Intercept der Graden um die Steigung der Kovariate. Die Level der Faktoren liegen dann auf den Mittelwerten der Kovariaten für das entsprechende Level des Fakotrs. Wenn wir dann noch eine Interaktion hinzunehmen, dann erlauben wir jedem Level des Faktors eine eigene Steigung der Kovariaten.

#### $f_A + c_1$ {.unnumbered .unlisted}

Hier rechnen wir eigentlich eine klassische [einfaktorielle ANCOVA](#sec-ancova) (eng. *analysis of covariance*)

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-14

p_fa_c1_model
```

::: panel-tabset
## Praktisch in R

#### Ohne Interaktion {.unnumbered .unlisted}

```{r}
cov1_fac1_fit <- lm(jump_length ~ feeding + K, data = flea_model_tbl) 
```

```{r}
cov1_fac1_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov1_fac1_fit |> summary()
```

```{r}
flea_model_tbl |> 
  group_by(feeding) |> 
  summarise(mean(jump_length),
            mean(K))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac1-cov1
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = c("sugar", "blood", "ketchup"),
       "$\\bar{c}_{K}$" = c(33.69, 29.47, 25.06), 
       "$\\bar{Y}$" = c(70.01, 107.87, 101.69), 
       "$\\boldsymbol{\\beta_{0}}$" = 58.48,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, 39.31, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, 34.64),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{K}}$" = c("$11.45 = 33.69 \\cdot 0.34$",
                                             "$10.02 = 29.47 \\cdot 0.34$",
                                             "$8.52 = 25.06 \\cdot 0.34$")) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6.5
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe. *[Zum Vergrößern anklicken]*"
#| label: fig-model-basic-cov1-fac1-01

ggplot(flea_model_tbl, aes(K, jump_length, color = feeding)) +
  theme_modeling() +
  geom_vline(xintercept = 33.69, linewidth = 0.5, color = "#E69F00") +
  geom_vline(xintercept = 29.46, linewidth = 0.5, color = "#56B4E9") +
  geom_vline(xintercept = 25.05, linewidth = 0.5, color = "#009E73") +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 58.48, linewidth = 0.5, color = "#CC79A7", linetype = 11) +
  geom_point(position = position_dodge(0.2)) +
  geom_function(fun = \(x) 58.48 + 0.342 * x, color = "#CC79A7") +
  xlim(c(0, NA)) + ylim(c(40, 150)) +
  annotate("point", x = c(25.05, 29.46, 33.69), y = c(70.0, 107.8, 101.7), 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 1, size = 2, shape = 23) +
  annotate("label", x = c(25.05, 29.46, 33.69)+c(2,3,3), y = c(70.0, 107.8, 101.7)+5, 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 0.5, size = 3) +
  labs(title = "Modell mit Kovariate und Faktor",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der Behandlung Zuckerwasser.\nDer Intercept ist um die Steigung der Kovariate gekippt",
       x = "Gewicht in [mg]", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top") +
  geom_segment(aes(x = 40, xend = 40, y = 58.48, yend = 58.48 + 40 * 0.3420),
               color = "#CC79A7") +
  annotate("text", hjust = "left", x = 41, y = 58.48 + (40 * 0.3420)/2,
           label = expression(beta[K]*"="~40%.%0.34)) +
  scale_x_continuous(breaks = c(10, 20, 25.05, 29.46, 33.69, 40, 50),
                     guide = guide_axis(n.dodge = 2))
```

#### Mit Interaktion {.unnumbered .unlisted}

```{r}
cov1_fac1_fit <- lm(jump_length ~ feeding + K + feeding:K, data = flea_model_tbl) 
```

```{r}
#| eval: true
cov1_fac1_fit |> summary()
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac1-cov1-inter
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = c("sugar", "blood", "ketchup"),
       "$\\bar{c}_{K}$" = c(33.69, 29.47, 25.06), 
       "$\\bar{Y}$" = c(70.01, 107.87, 101.69), 
       "$\\boldsymbol{\\beta_{0}}$" = 44.13,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, 44.59, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, 81.63),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{K}}$" = c("$25.94 = 33.69 \\cdot 0.77$",
                                             "$22.69 = 29.47 \\cdot 0.77$",
                                             "$19.29 = 25.06 \\cdot 0.77$"),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{blood\\times K}}$" = c(NA,
                                                          "$-3.54 = 29.47 \\cdot -0.12$",
                                                          NA),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{ketchup\\times K}}$" = c(NA, NA,
                                                          "$-43.35 = 25.06 \\cdot -1.73$"),
       ) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6.5
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe. foo. *[Zum Vergrößern anklicken]*"
#| label: fig-model-basic-cov1-fac1-02

ggplot(flea_model_tbl, aes(K, jump_length, color = feeding)) +
  theme_modeling() +
  geom_vline(xintercept = 33.69, linewidth = 0.5, color = "#E69F00") +
  geom_vline(xintercept = 29.46, linewidth = 0.5, color = "#56B4E9") +
  geom_vline(xintercept = 25.05, linewidth = 0.5, color = "#009E73") +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 44.1255, linewidth = 0.5, color = "#CC79A7", linetype = 11) +
  geom_point(position = position_dodge(0.2)) +
  geom_function(fun = \(x) 44.1255 + 0.7681 * x, color = "#CC79A7") +
  xlim(c(0, NA)) + ylim(c(40, 150)) +
  annotate("point", x = c(25.05, 29.46, 33.69), y = c(70.0, 107.8, 101.7), 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 1, size = 2, shape = 23) +
  annotate("label", x = c(25.05, 29.46, 33.69)+c(2,3,3), y = c(70.0, 107.8, 101.7)+5, 
           label = c(70.01, 107.87, 101.69), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 0.5, size = 3) +
  labs(title = "Modell mit Kovariate und Faktor sowie Interaktion",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der Behandlung Zuckerwasser.\nDer Intercept ist um die Steigung der Kovariate gekippt",
       x = "Fütterungsart", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top") +
  geom_segment(aes(x = 40, xend = 40, y = 44.1255, yend = 44.1255 + 40 * 0.7681),
               color = "#CC79A7") +
  annotate("text", hjust = "left", x = 41, y = 44.1255 + (40 * 0.7681)/2,
           label = expression(beta[K]*"="~40%.%0.77)) +
  scale_x_continuous(breaks = c(10, 20, 25.05, 29.46, 33.69, 40, 50),
                     guide = guide_axis(n.dodge = 2))
```

## Theoretisch in R

## Simulation

```{r}
cov1_fac1_tbl <- tibble(c_1 = rnorm(15, 0, 1),
                        f_a = gl(3, 5),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + c_1, cov1_fac1_tbl) |> 
  coef() |> round(2)
```
:::

#### $c_1 + f_A + f_B$ {.unnumbered .unlisted}

Hier rechnen wir eigentlich eine klassische [zweifaktorielle ANCOVA](#sec-ancova) (eng. *analysis of covariance*)

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-16

p_c1_fa_2lvl_fb_3lvl_model
```

::: panel-tabset
## Praktisch in R

```{r}
cov1_fac2_fit <- lm(jump_length ~ weight + feeding + stage, data = flea_model_tbl) 
```

```{r}
cov1_fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov1_fac2_fit |> summary()
```

## Theoretisch in R

```{r}
model.matrix(svl ~ mass + region + color, data = snake_tbl) |> as_tibble() 
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  51 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 6 & 0 & 0 & 0 \\
  1 & 8 & 0 & 0 & 0\\
  1 & 5 & 0 & 1 & 0\\
  1 & 7 & 1 & 1 & 0\\
  1 & 9 & 1 & 1 & 0\\
  1 & 11& 1 & 0 & 1\\
  1 & 12& 1 & 0 & 1\\
  1 & 10& 1 & 0 & 1\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} \\
  \beta^{region}_{nord} \\
  \beta^{color}_{rot} \\
  \beta^{color}_{blau} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
$$

```{r}
fit_4 <- lm(svl ~ mass + region + color, data = snake_tbl) 
fit_4 |> coef() |> round(2)
```

```{r}
fit_4 |> residuals() |> round(2)
```

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  49 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  25 & \phantom{0}6 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83 \\
  25 & \phantom{0}8 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}5 \cdot 2.5 & 0 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}7 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}9 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & 11\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 12\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 10\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
 \end{pmatrix} +
  \begin{pmatrix}
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  +2.00 \\
  -2.00 \\
  +2.33 \\
  +0.83 \\
  -3.17 \\
 \end{pmatrix}
$$

```{r}
c(25 +  6*2.5 + 0*5 + 0*1.5 + 0*-2.83 + 0.00,
  25 +  8*2.5 + 0*5 + 0*1.5 + 0*-2.83 + 0.00,
  25 +  5*2.5 + 0*5 + 1*1.5 + 0*-2.83 + 0.00,
  25 +  7*2.5 + 1*5 + 1*1.5 + 0*-2.83 + 2.00,
  25 +  9*2.5 + 1*5 + 1*1.5 + 0*-2.83 - 2.00,
  25 + 11*2.5 + 1*5 + 0*1.5 + 1*-2.83 + 2.33,
  25 + 12*2.5 + 1*5 + 0*1.5 + 1*-2.83 + 0.83,
  25 + 10*2.5 + 1*5 + 0*1.5 + 1*-2.83 - 3.17) 
```

## Simulation

```{r}
cov1_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + f_a + f_b, cov1_fac2_tbl) |> 
  coef() |> round(2)
```
:::

#### $c_1 + c_2 + f_A + f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-21

p_c2_fa_2lvl_fb_3lvl_model 
```

::: panel-tabset
## Praktisch in R

```{r}
cov2_fac2_fit <- lm(jump_length ~ weight + count_leg + feeding + stage, data = flea_model_tbl) 
```

```{r}
cov2_fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov2_fac2_fit |> summary()
```

## Theoretisch in R

## Simulation

```{r}
cov2_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        c_2 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            -1 * c_2 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2 + f_a + f_b, cov2_fac2_tbl) |> 
  coef() |> round(2)
```
:::

## Prädiktives Modell

## Weiteres von Interesse

### Einheit der Kovariaten

![Ein seltener Jedifloh, der so machtsensitiv ist, dass seine Fähigkeiten in der Sprungweite extrem erhöht sind.](images/flea_yedi.png){fig-align="center" width="60%"}

Manche Flöhe haben hohe Werte der [Midi-Chlorianer](https://www.jedipedia.net/wiki/Midi-Chlorianer) oder einfach M-Werte. Damit sind diese Flöhe insbesondere sensitiv für die Macht und somit auch in etwa Jediflöhe.

```{r}
lm(jump_length ~ M, data = flea_model_tbl) |> 
  summary()
```

### Korrelation der Kovariaten

```{r}
cov2_fit <- lm(jump_length ~ count_leg + count_leg_left + count_leg_right, data = flea_model_tbl) 
```

```{r}
cov2_fit |> 
  coef() |> round(2)
```

```{r}
 1.37 -1.15 -0.12 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der Sprungweite in [cm] und dem Gewicht in [mg] von sieben Hundeflöhen. Die lineare Grade und die Gradengleichung wurden ergänzt. *[Zum Vergrößern anklicken]*"
#| label: fig-mult-count-leg

ggplot(flea_model_tbl, aes(x = count_leg, y = jump_length)) +
  geom_point() +
  geom_point(aes(x = count_leg_left), color = "red") +
  geom_point(aes(x = count_leg_right), color = "blue") 
  

```

```{r}
#| eval: true
cov2_fit |> summary()
```

```{r}
cov2_fit <- lm(jump_length ~ count_leg, data = flea_model_tbl) 
```

```{r}
cov2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov2_fit |> summary()
```

### Variance inflation factor (VIF) {#sec-vif}

Eigentlich nur für Kovariaten geht es auch mit Faktoren. **Hier nochmal nach GVIF schauen.**

$$
VIF = \cfrac{1}{1- R^2}
$$

Die Interpretation der VIF-Werte (Variance Inflation Factor) hilft dir, den Grad der Multikollinearität in deinem Modell zu bewerten:

-   VIF = 1: Es gibt keine Multikollinearität.
-   VIF zwischen 1 und 5: Es liegt moderate Multikollinearität vor, die in der Regel unproblematisch ist.
-   VIF \> 5: Es gibt eine hohe Multikollinearität, die die Koeffizienten unzuverlässig machen kann. Hier sollten Maßnahmen ergriffen werden.
-   VIF \> 10: Dies deutet auf eine sehr hohe Multikollinearität hin, die dringend korrigiert werden muss.

```{r}
juvenile_flea_tbl <- filter(flea_model_tbl, stage == "juvenile")
```

```{r}
juvenile_fit <- lm(jump_length ~ K + Mg + CRP + Hb + BSG + M, 
                   data = juvenile_flea_tbl)
```

::: panel-tabset
## `{car}`

```{r}
vif(juvenile_fit)
```

## `{performance}`

Wir können uns mit der Funcktion `check_model()` aus dem R Paket `{performance}` auch die Unsicherheit mit angeben lassen. In unserem Beispiel hieft dies gerade nicht sehr viel weiter. Wir bleiben bei den geschätzen Werten und ignorieren das Intervall.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: Graphische Darstellung des VIF mit der Funktion `check_model()`.
#| label: fig-stat-modeling-vif

check_model(juvenile_fit, check = "vif")
```

## Händisch in R

```{r}
vif_fct <- function(x) 1/(1-x)
```

```{r}
lm(K ~ Mg + CRP + Hb + BSG + M, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("K")
```

```{r}
lm(Mg ~ K + CRP + Hb + BSG + M, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("Mg")
```

```{r}
lm(CRP ~ K + Mg + Hb + BSG + M, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("CRP")
```

```{r}
lm(Hb ~ K + Mg + CRP + BSG + M, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("Hb")
```

```{r}
lm(BSG ~ K + Mg + CRP + Hb + M, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("BSG")
```

```{r}
lm(M ~ K + Mg + CRP + Hb + BSG, data = juvenile_flea_tbl) |> 
  r2() |>
  pluck("R2") |> vif_fct() |> set_names("M")
```
:::

### Adjustierung für Confounder {#sec-confounder}

Im folgenden Abschnitt wollen wir einmal auf Confounder eingehen. Was sind Confounder? Zum einen gibt es kein gutes deutsches Wort für Confounder. Du könntest Confounder in etwa mit *Verzerrer* oder *Störfakor* übersetzen. Zum Anderen können Confounder nur zuammen mit anderen Vriabln in einer multiplen Regression auftreten. Das heißt, wir brauchen mindestens zwei Variablen in einer Regression. Ein Confounder verursacht einen Effekt, den wir eigentlich nicht so erwartet hätten. Wir wollen eigentlich einen Effekt schätzen, aber der Effekt ist viel größer oder kleiner, da der Effekt eigentlich von einder anderen Variable verursacht oder aber verdeckt wird. Wir können einen Confounder in beide Richtungen haben. Wichtig ist hierbei, das wir eigentlich *nicht* an dem Effekt des Confounders interessiert sind. Wir wollen uns zum Beispiel den Effekt einer Düngung auf das Trockengewicht anschauen, aber der Effekt den wir beobachten wird durch die unterschiedlichen Pflanzorte verursacht.

Schauen wir uns das ganze mal für das Beispiel des Zusammenhangs von dem Flohgewicht mit der Sprungweite an. Dafür benötigen wir den Datensatz `flea_dog_cat_length_weight.csv`.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") |>
  select(animal, sex, weight, jump_length) |> 
  mutate(animal = as_factor(animal),
         sex = as_factor(sex))
```

In der @tbl-model-confounder ist der Datensatz `model_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Datensatz für die Confounder Adjustierung. Die Variable `jump_length` ist das $y$ und die Variable `weight` das $x$ von Interesse.
#| label: tbl-model-confounder

model_raw_tbl <- model_tbl |> 
  mutate(animal = as.character(animal),
         sex = as.character(sex))
rbind(head(model_raw_tbl),
      rep("...", times = ncol(model_raw_tbl)),
      tail(model_raw_tbl)) |> 
  kable(align = "c", "pipe")

```

Wir können uns jetzt drei verschiedene Modelle anschauen.

1)  Das Modell `jump_length ~ weight`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe *über alle* anderen Variablen hinweg.
2)  Das Modell `jump_length ~ weight + animal`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe und berücksichtigen die Tierart des Flohes. Ignorieren aber das Geschlecht des Flohes.
3)  Das Modell `jump_length ~ weight + animal + sex`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe und berücksichtigen *alle* Variablen, die wir gemessen haben.

Hierbei ist wichtig, dass es natürlich auch Confounder geben kann, die wir gar nicht in den Daten erhoben haben. Also, dass sich Gruppen finden lassen, die wir gar nicht als Variable mit in den Daten erfasst haben. Hier könnte eine Hauptkomponentenanalyse helfen.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| label: fig-stat-modeling-mult-01
#| fig-cap: "Darstellung des *counfounder* Effekts anhand des Zusammenhangs der Sprungweite in [cm] und dem Gewicht von Flöhen [mg]."
#| fig-subcap: 
#|   - "jump_length ~ weight"
#|   - "jump_length ~ weight + animal"
#|   - "jump_length ~ weight + animal + sex"
#| layout-nrow: 1


ggplot(model_tbl, aes(x = weight, y = jump_length)) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  geom_point() 

ggplot(model_tbl, aes(x = weight, y = jump_length, color = animal)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_minimal() +
  geom_point() +
  labs(color  = "Tierart")

ggplot(model_tbl, aes(x = weight, y = jump_length, color = animal, shape = sex)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_minimal() +
  geom_point() +
  labs(color  = "Tierart", shape = "Geschlecht")

```

In @fig-stat-modeling-mult-01-1 sehen wir die blaue Linie als die Ausgabe von dem Modell `jump_length ~ weight`. Wir sehen, dass mit dem Anstieg des Gewichtes der Flöhe auch die Sprungweite sich erhöht. Wir würden annehmen, dass wir hier einen signifikanten Unterschied vorliegen haben. Schauen wir uns die Koeffizienten des Modells aus dem `lm()` einmal an.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight, data = model_tbl) |> 
  model_parameters()
```

Wir sehen, dass wir einen Effekt des Gewichts auf die Sprungweite von $1.34$ vorliegen haben. Auch ist der Effekt und damit die Steigung signifikant.

Erweitern wir nun das Modell um die Tierart und erhalten die @fig-stat-modeling-mult-01-2. Zum einen sehen wir, dass der globale Effekt nicht so ganz stimmen kann. Die Tierarten haben alle einen unterschiedlichen starken Effekt von dem Gewicht auf die Sprungweite. Auch hier fitten wir einmal das lineare Modell und schauen uns die Koeffizienten an.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight + animal, data = model_tbl) |> 
  model_parameters()
```

Der Effekt des Gewichtes ist hier in etwa gleich geblieben. Wir sehen aber auch, dass die Sprungweite anscheinend bei Hunden und Füchsen höher ist. Daher haben wir hier einen Effekt on der Tierart. Wir adjustieren für den Confoundereffekt durch die Tierart und erhalten einen besseren Effektschätzer für das Gewicht.

In der letzten @fig-stat-modeling-mult-01-3 wollen wir nochmal das Geschlecht der Flöhe mit in das Modell nehmen. Wir sehen, dass in diesem Fall, das Gewicht gar keinen Einfluss mehr auf die Sprungweite hat. Den Effekt des Gewichtes war nur der Effekt des unterschiedlichen Gewichtes der weiblichen und männlichen Flöhe. Schauen wir auch hier nochmal in des Modell.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight + animal + sex, data = model_tbl) |> 
  model_parameters() |> 
  mutate(Coefficient = round(Coefficient, 2))
```

Nun können wir sehen, dass von unserem ursprünglichen Effekt von dem Gewicht auf die Sprungweite nichts mehr übrigbleibt. Wir haben gar keinen Effekt von dem Gewicht auf die Sprungweite vorliegen. Was wir gesehen haben, war der Effekt des Gewichtes der unterschiedlichen Geschlechter. Wenn wir unser Modell für die Confounder `animal` und `sex` adjustieren, haben wir einen unverzerrten Schätzer für `weight`. Wichtig ist nochmal, dafür müssen wir natürlich auch alle variablen erhoben haben. Hätten wir das Geschlecht der Flöhe nicht bestimt, hätten wir hier eventuell einen falschen Schluß getroffen.

### Vergleich von Modellen {#sec-model-basic-compare}

Im Folgenden wollen wir einmal verschiedene Modelle miteinander Vergleichen und uns statistisch wiedergeben lassen, was das beste Modell ist. Und hier holen wir auch einmal kurz Luft, denn wir entschieden *nur* was das statistisch beste Modell ist. Es kann sein, dass ein Modell biologisch mehr Sinn macht und nicht auf Platz 1 der statistischen Maßzahlen steht. Das ist vollkommen in Ordnung. Du musst abweägen, was für sich das beste Modell ist. Im Zweifel komme ruhig nochmal in meine statistische Beratung oder schreibe mir eine Mail.

Wir bauchen uns jetzt fünf Modelle von `fit_1` bis `fit_5`. Jedes dieser Modelle hat andere $x$ aber häufig das gleiche Outcome `y`. In dem Beispiel am Ende des Kapitels nutzen wir auch verschiedene $y$ dafür aber dann gleiche $x$ in dem Modell. Im Weiteren sortieren wir die Modelle von einfach nach komplex. Ich versuche immmer das einfachste Modell `fit_1` zu nennen bzw. eher die niedrige Nummer zu geben. Im Idealfall benennst du die Modellobjekte nach den Modellen, die in en Objekten gespeichert sind. Oft sind die Modelle aber sehr groß und die Objekte der Fits haben dann sehr lange Namen.

```{r}
fit_1 <- lm(jump_length ~ animal, data = model_tbl)
fit_2 <- lm(jump_length ~ animal + sex, data = model_tbl)
fit_3 <- lm(jump_length ~ animal + sex + weight, data = model_tbl)
fit_4 <- lm(jump_length ~ animal + sex + sex:weight, data = model_tbl)
fit_5 <- lm(log(jump_length) ~ animal + sex, data = model_tbl)
```

Als Ergänzung zum Bestimmtheitsmaß $R^2$ wollen wir uns noch das *Akaike information criterion* (abk. $AIC$) anschauen. Du kannst auch das $R^2$ bzw. das $R^2_{adj}$ für die Modellauswahl nehmen. Das $AIC$ ist neuer und auch für komplexere Modelle geeignet. Es gilt hierbei, je kleiner das $AIC$ ist, desto besser ist das $AIC$. Wir wollen also Modelle haben, die ein kleines $AIC$ haben. Wir gehen jetzt nicht auf die Berechnung der $AIC$'s für jedes Modell ein. Wir erhalten nur ein $AIC$ für jedes Modell. Die einzelnen Werte des $AIC$'s sagen *nichts* aus. Ein $AIC$ ist ein mathematisches Konstrukt. Wir können aber verwandte Modelle mit dem $AIC$ untereinander vergleichen. Daher berechnen wir ein $\Delta$ über die $AIC$. Dafür nehmen wir das Modell mit dem niedrigsten $AIC$ und berechnen die jeweiligen Differenzen zu den anderen $i$ Modellen. In unserem Beispiel ist $i$ dann gleich fünf, da wir fünf Modelle haben.

$$
\Delta_i = AIC_i - AIC_{min}
$$

-   wenn $\Delta_i < 2$, gibt es keinen Unterschied zwischen den Modellen. Das $i$-te Modell ist genauso gut wie das Modell mit dem $AIC_{min}$.
-   wenn $2 < \Delta_i < 4$, dann gibt es eine starke Unterstützung für das $i$-te Modell. Das $i$-te Modell ist immer noch ähnlich gut wie das $AIC_{min}$.
-   wenn $4 < \Delta_i < 7$, dann gibt es deutlich weniger Unterstützung für das $i$-te Modell;
-   Modelle mit $\Delta_i > 10$ sind im Vergleich zu dem *besten* $AIC$ Modell nicht zu verwenden.

Nehmen wir ein $AIC_1 = AIC_{min} = 100$ und $AIC_2$ ist $100,7$ an. Dann ist $\Delta_2=0,7<2$, so dass es keinen wesentlichen Unterschied zwischen den Modellen gibt. Wir können uns entscheiden, welches der beiden Modelle wir nehmen. Hier ist dann wichtig, was auch die Biologie sagt oder eben andere Kriterien, wie Kosten und Nutzen. Wenn wir ein $AIC_1 = AIC_{min} = 100000$ und $AIC_2$ ist $100700$ vorliegen haben, dann ist $\Delta_2 = 700 \gg 10$, also gibt es keinen Grund für das $2$-te Modell. Das $2$-te Modell ist substantiell schlechter als das erste Modell. Mehr dazu kannst du unter [Multimodel Inference: Understanding AIC and BIC in Model Selection](https://faculty.washington.edu/skalski/classes/QERM597/papers_xtra/Burnham%20and%20Anderson.pdf) nachlesen.

Wir können das $\Delta_i$ auch in eine Wahrscheinlichkeit umrechnen. Wir können $p_i$ berechnen und damit die relative (im Vergleich zu $AIC_{min}$) Wahrscheinlichkeit, dass das $i$-te Modell den AIC minimiert.

$$
p_i = \exp\left(\cfrac{-\Delta_i}{2}\right)
$$

Zum Beispiel entspricht $\Delta_i = 1.5$ einem $p_i$ von $0.47$ (ziemlich hoch) und ein $\Delta_i = 15$ entspricht einem $p_i =0.0005$ (ziemlich niedrig). Im ersten Fall besteht eine Wahrscheinlichkeit von 47%, dass das $i$-te Modell tatsächlich eine bessere Beschreibung ist als das Modell, das $AIC_{min}$ ergibt, und im zweiten Fall beträgt diese Wahrscheinlichkeit nur 0,05%. Wir können so einmal nachrechnen, ob sich eine Entscheidung für ein anderes Modell lohnen würde. Neben dem $AIC$ gibt es auch das Bayesian information criterion ($BIC$). Auch beim $BIC$ gilt, je kleiner das BIC ist, desto besser ist das BIC.

Du siehst schon, es gibt eine Reihe von Möglichkeiten sich mit der Güte oder Qualität eines Modells zu beschäftigen. Wir nutzen die Funktion `model_performance()` um uns die Informationen über die Güte eines Modells wiedergeben zu lassen. Im folgenden Codeblock habe ich mich nur auf das $AIC$ und das $BIC$ konzentriert.

```{r}
model_performance(fit_1) |> 
  as_tibble() |> 
  select(AIC, BIC)
```

Gut soweit. Du kannst jetzt für jedes der Modelle das $AIC$ berechnen und dann dir die Modelle entsprechend ordnen. Wir müssen das aber nicht tun. Wir können uns auch die Funktion `compare_performance()` zu nutze machen. Die Funktion gibt uns die $R^2$-Werte wieder wie auch die $AIC$ sowie die $s^2_{\epsilon}$ als `sigma` wieder. Wir haben also alles zusammen was wir brauchen. Darüber hinaus kann die Funktion auch die Modelle rangieren. Das nutzen wir natürlich gerne.

```{r}
#| message: false
#| warning: false
comp_res <- compare_performance(fit_1, fit_2, fit_3, fit_4, fit_5, rank = TRUE)

comp_res
```

Anhand der Ausgabe der Funktion `compare_performance()` sehen wir, dass unser Modell `fit_2` das beste Modell ist. Zwar ist die Streuung der Residuen nicht die Kleinste aller Modelle (`Sigma` = 1.933) aber wir haben ein hohes $R^2_{adj}$ und auch ein kleines $AIC$. Wir würden damit sagen, dass das Modell `fit_2` mit den Variablen `animal` und `sex` für $x$ das Outcome `jump_length` am besten statistisch beschreibt.

In @fig-stat-modeling-compare sehen wir die Ausgabe der Funktion `compare_performance()` nochmal visualisiert. Wir können dann die einzelnen Modelle nochmal besser vergleichen. Auch siehst du hier, ob ein Modell in einem Bereich sehr schlecht ist oder aber nur in einem Bereich sehr gut.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Graphische Darstellung der Funktion `compare_performance()` Wir sehen hier die einzelnen Gütekriterien in einer Übersicht dargestellt.
#| label: fig-stat-modeling-compare

plot(comp_res)
```

Zum Ende stellt sich die Frage nach dem statistischen Test. Können wir auch statistisch Testen, ob das Modell `fit_1` signifikant unterschiedlich ist? Ja wir können die Funktion `test_vuong()` nutzen um ein Model zu den anderen Modellen zu vergleichen. Wenn du mehrere Modell miteinander vergleichen möchtest, dann muss du die Funktion mehrfach ausführen.

```{r}
test_vuong(fit_1, fit_2, fit_3, fit_4, fit_5)
```

Nutzen wir die Modellselektion auch einmal an einem konkreten Beispiel. War die Transformation sinnvoll? Wir haben also ein Outcome $y$ vorliegen und wollen wissen, ob wir nicht lieber das Modell mit einem $y$ mit einer $log$-Transformation rechnen sollten. Wir nutzen dazu den Datensatz mit den Hunde- und Katzenflöhen und die Schlüpfdauer als Outcome. Also wie lange brauchen die Flöhe bis die Flöhe aus den Eiern geschlüpft sind.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") |>
  mutate(log_hatch_time = round(log(hatch_time), 2))
```

Wir bauen uns jetzt zwei Modelle. Zum einen das Modell `fit_raw` mit der `hatch_time` und den Variablen `ainmal` und `sex`. Das zweite Modell enthält die `log(hatch_time)` also das Outcome $y$ als $log$-Transformation. Wiederum sind die $x$ variablen die gleichen wie im untransformierten Modell. Wir fitten beide Modelle und speichern die Objekte entsprechend ab.

```{r}
fit_raw <- lm(hatch_time ~ animal + sex, data = model_tbl)
fit_log <- lm(log_hatch_time ~ animal + sex, data = model_tbl)
```

Die Funktion `compare_performance()` erlaubt uns wieder die beiden Modelle `fit_raw` und `fit_log` miteinander zu vergleichen. Wir erhalten die folgende Ausgabe der Funktion.

```{r}
#| message: false
#| warning: false
comp_res <- compare_performance(fit_raw, fit_log, rank = TRUE)

comp_res
```

In diesem Beispiel wäre das $log$-transformierte Modell das bessere statistische Modell. Wir müssen jetzt überlegen, ob wir den Preis dafür bezahlen wollen. Wenn wir nämlich alles mit der $log$-Transformation rechnen, dann erhalten wir auch alle Koeffizienten auf der $log$-Skala (eng. *log scale*). Hier kannst du nur von Fall zu Fall entscheiden.

## Referenzen {.unnumbered}
