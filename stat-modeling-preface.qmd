```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, gghalves,
               ggdist, patchwork, see)
```

# Statistisches Modellieren {#sec-stat-model-preface}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-preface.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Sei bereit, sei bereit, sonst kommst du nicht sehr weit; Dann tut's dir später leid, drum sei bereit; sei bereit sei bereit, sei clever und gescheit; so bist du gegen jeden Test gefeit" --- Jan Delay Ziegen Song (sei Bereit)*

Was ist statistisches Modellieren? In diesem und den nun folgenden Kapitel wollen wir uns mit den Grundlagen der *multiplen* linearen Regression beschäftigen. Deshalb hier nochmal die Wiederholung was eine [multiple lineare Regression](#sec-mult-reg-basic) ist. Wir erinnern uns, dass wir ein Outcome $y$, was einer Verteilung folgt, sowie mehrere Einflussvariable $x_1$ bis $x_p$ vorliegen haben. Wir wollen jetzt herausfinden, welchen Einfluss oder Effekt die $x_1, ..., x_p$ auf das $y$ hat. Sehr simple gesprochen legen wir eine Gerade durch eine *mehrdimensionale* Punktewolke.

Wir erinnern und nochmal, das ein *simples* lineares Modell nur ein $x_1$ hat:

$$
y \sim x_1
$$

Ein *multiples* lineares Modell hat von $x_1$ bis $x_p$ Einflussvariablen:

$$
y \sim x_1 + x_2 + ... + x_p
$$

Wir brauchen viele der Konzepte aus den vorherigen Kapiteln zur Modellgüte sowie Konfidenzintervallen. Vieles fällt hier zusammen. Schau dir ruhig nochmal die vorherigen Kapitel an, wenn dir etwas unklar ist. Häufig wollen wir auch etwas spezifischer sein. Wir schreiben daher einen Faktor mit einem $f$ wie folgt.

$$
y \sim f_1
$$

Wenn wir dann noch einen Block mit hinzunehmen, dann erweitern wir das Modell um einen Blockfaktor mit einem $b$ wie folgt.

$$
y \sim f_1 + b_1
$$

Es kann auch sein, dass wir noch einen zufälligen Effekt (eng. *random effect*) mit in das Modell nehmen wollen. Wir bezeichnen einen zufälligen Effekt mit einem $z$ wie folgt.

$$
y \sim f_1 + z_1
$$

Ich habe aber noch ein Video eingesprochen, dass dir eventuell helfen wird.

{{< video https://youtu.be/2fXExWzipDI >}}

## Das Regressionskreuz

In diesem Kapitel wollen wir uns mit der Grundlage der multiplen linearen Regression beschäftigen. Das heist wir schauen uns Modelle mit mehreren $x$ an. Wir haben also nicht mehr nur eine Einflussvariable auf der rechten Seite der Gleichung sondern meist mehrere. Je nachdem wie diese $x$ beschaffen sind, müssen wir die $x$ auch interpretieren. Wir unterscheiden in vier Arten von $x$.

1)  Das zu betrachtende $x$ ist eine Variable mit **kontinuierlichen Zahlen** (siehe @sec-interpret-x-cont)
2)  Das zu betrachtende $x$ ist eine Variablen mit **einem Faktor mit zwei Leveln** (siehe @sec-interpret-x-cat2).
3)  Das zu betrachtende $x$ ist eine Variablen mit **einem Faktor mit mehr als zwei Leveln** (siehe @sec-interpret-x-cat3).
4)  Das zu betrachtende $x$ ist eine Variable, die einen **Block oder Cluster** beschreibt (siehe @sec-mixed).

Wir finden die Fälle 1) bis 3) in der @fig-reg-cross in den Spalten wieder.

Neben dem $x$ müssen wir auch das $y$ in diesem Kapitel betrachten. Das $y$ kann aus verschiedenen Verteilungen kommen. Häufig nehmen wir an, dass das $y$ normalverteilt ist, das muss das $y$ aber nicht sein. Je nachdem wir das $y$ verteilt ist, rechen wir eine andere multiple Regression.

1)  Das zu betrachtende $y$ folgt einer **Normalverteilung** bzw. entstammt einer **Gaussian** Vertreilungsfamilie. Wir wollen dann eine multiple Gaussian Regression rechen.
2)  Das zu betrachtende $y$ folgt einer **Poissonverteilung** bzw. entstammt einer Poisson Vertreilungsfamilie. Wir wollen dann eine multiple Poisson Regression rechen.
3)  Das zu betrachtende $y$ folgt einer **Ordinalen- oder Multinominalenverteilung** bzw. entstammt einer Ordinalen- oder Multinominalen Vertreilungsfamilie. Wir wollen dann eine multiple ordinale oder multinominale Regression rechen.
4)  Das zu betrachtende $y$ folgt einer **Binomialverteilung** bzw. entstammt einer Binomialen Vertreilungsfamilie. Wir wollen dann eine multiple logistische Regression rechen.

Wir finden die Fälle 1) bis 4) in der @fig-reg-cross in den Zeilen wieder.

```{r}
#| echo: false
#| message: false
#| label: fig-scatter-modeling-R-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 15
#| fig-cap: "Verschiedene Ziele und Möglichkeiten des statistischen Modellierens. Grob können die Möglichkeiten in drei große thematische Zusammenhänge eingeteilt werden."

set.seed(20240329)

cross_tbl <- tibble(x_num = seq(0, 5, 0.1),
                    x_fct = gl(3, 17, labels = c("A", "B", "C")),
                    y_normal = 0 + 0.8 * x_num + rnorm(length(x_num), 0, 1),
                    y_pois = round(y_normal),
                    y_grad = ifelse(y_pois > 2, 2, y_pois))

gg_template <- ggplot() +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position = "none") +
  scale_color_okabeito() +
  scale_fill_okabeito()
  

gg_template %+%
  cross_tbl + 
  aes(x_num, y_normal) +
  geom_point() 


p11 <- gg_template %+%
  cross_tbl + 
  aes(x_num, y_pois) +
  geom_point() 

p12 <- gg_template %+%
  cross_tbl + 
  aes(x_fct, y_normal, fill = x_fct) +
  geom_boxplot(width = 0.15, outlier.shape = NA) +
  stat_dots(side = "left", justification = 1.12, binwidth = 0.25,
            dotsize = 0.7) 

p13 <- gg_template %+%
  filter(cross_tbl, x_fct != "C") + 
  aes(x_fct, y_normal, fill = x_fct) +
  geom_boxplot(width = 0.15, outlier.shape = NA) +
  stat_dots(side = "left", justification = 1.12, binwidth = 0.25,
            dotsize = 0.7) 

p11 + p12 + p13 +
  plot_layout(ncol = 3)


gg_template %+%
  filter(cross_tbl, y_grad >= 0) + 
  aes(x_num, y_grad) +
  geom_point() 
```

![Das Regressionskreuz als allgemeine Übersicht der Möglichkeiten einer multiplen linearen Regression.](images/Regressionskreut_advanced.png){#fig-reg-cross fig-align="center" width="100%"}
