```{r echo = FALSE}
#| message: false
#| echo: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, plyr,
               patchwork, ggforce, see, sjPlot, tinytable, conflicted)
set.seed(202434)
conflicts_prefer(dplyr::summarise)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(magrittr::set_names)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| cache: false
#| label: source-anova-plots
source("stat-tests-anova_plot/anova_plots.R")
```

# Die ANOVA {#sec-anova}

*Letzte Änderung am `r format(fs::file_info("stat-tests-anova2.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Yeah, I might seem so strong; Yeah, I might speak so long; I've never been so wrong." --- London Grammar, Strong*

Die ANOVA (eng. *analysis of variance*) ist wichtig. Was für ein schöner Satz um anzufangen. Historisch betrachtet ist die ANOVA, *das* statistische Verfahren was gut per Hand ohne Computer berechnet werden kann. Daher war die ANOVA von den 20zigern bis in die frühen 90ziger des letzten Jahrhunderts *das* statistische Verfahren der Wahl. Wir brauchen daher die ANOVA aus mehreren Gründen. Die Hochzeiten der ANOVA sind eigentlich vorbei, wir haben in der Statistik für viele Fälle mittlerweile besser Werkzeuge, aber als Allrounder ist die ANOVA immer noch nutzbar. Insbesondere wenn wir uns mit einem faktoriellen Design beschäftigen, dann komt die Stärke der ANOVA voll zu tragen. Da wir in den agrarwissenschaften eben dann doch sehr viele Feldexperimente in einem faktoriellen Design vorliegen haben, hat auch die ANOVA ihren Platz in der praktischen Auswertung. Wir werden immer wieder in diesem Buch auf die ANOVA inhaltlich zurück kommen und in vielen Abschlussarbeiten wird die ANOVA immer noch als integraler Bestandteil genutzt.

Was findest du in diesem Übersichtskapitel zur ANOVA?

:   Wir werden uns in diesem Kapitel auf die einfaktorielle ANOVA (eng. *one-way ANOVA*) sowie die zweifaktorielle ANOVA (eng. *two-way ANOVA*) konzentrieren. Ich gehe dann auch noch auf ein mehrfaktorielles Modell ein. Am Ende kommt dann noch die multivariate ANOVA, wenn du simultan mehr als einen Messwert $y$ in dein Modell nehmen willst. In dem [Kapitel zur ANCOVA](#sec-ancova) findest du dann alle Informationen, wenn du zusärtzlich zu deinen Faktoren noch eine numerische Kovariate mit in dein Modell nehmen willst. Häufig wird die ANOVA auch verwendet, wenn du Messwiederholungen in deinen Daten vorliegen hast. Hierfür habe ich dann das [Kapitel zur repeated & mixed ANOVA](#sec-anova-mixed) geschrieben, wo du dann einmal schauen musst.

## Allgemeiner Hintergrund

Fangen wir also mit der zentralen Idee der ANOVA an und arbeiten uns dann vor. Du kannst gerne den allgemeinen wie auch den theoretischen Teil überspringen und dir gleich das passende Datenbeispiel für deine Fragestellung raussuchen. Der Teil hier vorab dient nur dem tieferen Verständnis und du brauchst es eigentlich nicht um einfach nur eine ANOVA anzuwenden und ein Ergebnis zu erhalten. Da ist die ANOVA ziemlich gut zu interpretieren und anzuwenden. Wir fangen hier jetzt aber einmal an uns eine grundsätzliche Frage über unser experimentellen Versuch zu stellen.

Ist eine hohe Varianz in dem Messwert $\boldsymbol{y}$ zu vermeiden?

:   Es gibt eigentlich zwei Fehlannahmen (eng. *misconception*) an die ANOVA. Zum einen, dass die ANOVA die Varianzen vergleichen würde. Das stimmt nur bedingt. Die Nullhypothese der ANOVA ist die Gleichheit der Mittelwerte in den Gruppen. Zum anderen, dass wenig Varianz in den Messwerten $y$ per se gut wäre und ein angestrebtes Ziel in einem geplanten Feldexperiment.

In der folgenden Abbildung siehst du einmal vier Maisspflanzen mit jeweils einer Behandlung für ein gesteigertes Wachstum. In der linken Abbildung haben wir eine geringe Varianz udn damit auch gleiche Mittelwerte. Die Behandlungen haben überhaupt keinen Einfluß auf den Wuchs. In der rechten Abbdlung siehst du eine hohe Varianz, weil eben die Behandlungen einen Effekt auf das Wachstum haben. Wenn du also ein geplantes Experiment mit Kontrolle und Behandlungen durchführst, dann erwartest du eine hohe Varianz in dem Messwert $y$. Ansonsten würde deine Behandlung überhaupt nicht wirken.

![Feldexperiment mit vier Behandlungen zur Steigerung der Wuchshöhe von Maispflanzen. Jede Pflanze stellt vereinfacht eine Behandlung dar. **(A)** Die gepoolte Varianz $s^2_p$ über die Gruppen ist klein ($s^2_p=0$), die Behandlungen haben keinen Effekt auf das Wachstum. **(B)** Die gepoolte Varianz $s^2_p$ über die Gruppen ist groß ($s^2_p>0$), die Behandlungen haben einen Effekt auf das Wachstum der Maisspflanzen.](images/anova/anova_intro.png){#fig-anova-intro fig-align="center" width="100%"}

Arbeiten wir uns nun einmal durch die Themen der Hypothesen sowie der Idee des faktoriellen Modells. Wir brauchen eine Idee des faktoriellen Modells um die verschiednen Typen der ANOVA unterscheiden zu können. Teilweise sind es eben dann nur Erweiterungen des immer gleichen Grundgerüst. Dann schauen wir nochmal auf die Voraussetzungen der ANOVA an deine Daten. Zum einen mit dem Fokus auf die Normalverteilung deines Messwert $y$ und zum anderen die Varianzhomogenität in deinen Faktoren. Bevor wir dann nochmal als Einschub die Theorie behandlen, stelle ich dir R Pakete vor, die dir die ANOVA rechnen können.

#### Das Modell {.unnumbered .unlisted}

Beginnen wir also mit der Festlegung welche Art der Analyse wir rechnen wollen. Wichtig ist hier, dass du einen normmalverteiten Messwert $y$ vorliegen hast und ein oder mehrere Faktoren $f$. Was sind im Kontext von R Faktoren? Ein Faktor ist eine Behandlung oder eben eine Spalte in deinem Datensatz, der verschiedene Gruppen oder Kategorien beinhaltet. Wir nennen diese Kategorien Level. In den folgenden Datenbeispielen ist die Spalte `animal` ein Faktor mit drei Leveln. Wir haben dort nämlich die Sprungweiten von drei Floharten gemessen. Jetzt kann es aber auch sein, dass du neben einem Faktor noch eine numeriche Kovariate $c$ gemessen hast. Oder aber du hast zwei Messwerte, die du dann gemeinsam mit einem Faktor vergleichen willst. Diese drei Analysetypen wollen wir uns in den folgenden Tabs mal näher anschauen.

::: panel-tabset
## ANOVA (faktoriell)

Das faktorielle Modell der klassischen ANOVA beinhaltet einen Messwert $y$, der normalverteilt ist. Darüber hinaus haben wir noch ein bis mehrere Faktoren $f$. Wir bezeichnen hier die Faktoren mit den Indizes $A$, $B$ und $C$ und die jeweiligen Level des Faktors $A$ als $A.1, A.2,..., A.k$. Häufig haben wir aber zwei Faktoren in einem Modell mit zwei bis fünf Leveln. Aber hier gibt es sicherlich auch noch Fragestellungen mit mehr Gruppen und damit Leveln in einem Faktor. Wir schreiben ein faktorielles Modell wie folgt.

$$
y \sim f_A + f_B + ... + f_P + f_A \times f_B + ... + f_A \times f_B \times f_C
$$

mit

-   $y$ gleich dem Messwert oder Outcome
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung
-   $f_A \times f_B \times f_C$ gleich einem beispielhaften Interaktionsterm zweiter Ordnung

Zusätzlich können noch Interaktionsterme höherer Ordnungen entstehen, aber hier wird es extrem schwierig diese Interaktionsterme dann auch zu interpretieren. Ich würde grundsätzlich vermeiden Interaktionen zweiter und höherer Ordnungen mit ins Modell zu nehmen. Was genau eine Interaktion ist, besprechen wir in einem folgenden Abschnit. Um eine Interaktion beobachten zu können, brauchst du aber mindestens zwei Faktoren in deiner Analyse.

## ANCOVA (faktoriell und numerisch)

Wenn wir neben einem bis mehreren Faktoren $f$ noch eine numerische Kovariate $c$ mit modellieren wollen, dann nutzen wir die ANCOVA (eng. *Analysis of Covariance*). Hier kommt dann immer als erstes die Frage, was heißt den Kovariate $c$? Hier kannst du dir eine numerische Variable vorstellen, die ebenfalls im Experiment gemessen wird. Es kann das Startgewicht oder aber die kummulierte Wassergabe sein. Wir haben eben hier keinen Faktor als Kategorie vorliegen, sondern eben etwas numerisch gemessen. Daher ist unsere Modellierung etwas anders.

$$
y \sim f_A + f_B + ... + f_P + f_A \times f_B + c_1 + ... + c_p
$$

mit

-   $y$ gleich dem Messwert oder Outcome
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung
-   $c_1 + ... + c_p$ gleich einer oder mehrer numerischer Kovariaten

Hier muss ich gleich die Einschränkung machen, dass wir *normalerweise* maximal ein zweifaktorielles Modell mit einem Faktor $A$ und einem Faktor $B$ sowie einer Kovariate $c$ betrachten. Sehr selten haben wir mehr Faktoren oder gar Kovariaten in dem Modell. Wenn das der Fall sein sollte, dann könnte eine andere Modellierung wie eine multiple Regression eine bessere Lösung sein. Mehr Informationen zur der Berechnung findest du in dem [Kapitel zur ANCOVA](#sec-ancova)

## MANOVA (multivariat)

Am Ende des Kapitels schauen wir uns noch einen weiteren Spezialfall an. Nämlich den Fall, dass wir nicht nur einen Messwert $y$ vorliegen haben sondern eben mehrere die wir simultan auswerten wollen. Das klingt jetzt erstmal etwas schräg, aber es wird dann klarer, wenn wir uns die Sachlage einmal an einem Beispiel anschauen.

$$
(y_1, y_2, ..., y_j) \sim f_A + f_B + ... + f_P + f_A \times f_B 
$$

mit

-   $(y_1, y_2)$ gleich der Messwerte oder Outcomes
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung

Die ganze multivariate Analyse ist dann etwas seltener, da wir hier dann doch schon einiges an Fallzahl brauchen, damit es dann auch einen Sinn macht. Einiges an Fallzahl heißt dann hier, dass wir dann schon mehr als sechs Beobachtungen in einer Gruppe haben sollten. Wenn du weniger hast, kann es sein, dass du keine signifikanten Unterschiede findest.
:::

Daneben gibt es natürlich noch Spezialfälle wie die gemischte ANOVA (eng. *mixed ANOVA*), wenn wir Beobachtungen wiederholt messen. Dieses Modell schauen wir uns dann auch nochmal an. Der Unterschied in der Modellierung ist ein Fehlerterm (eng. *Error*), den wir dann nochmal mit angeben müssen. Dazu dann aber mehr in dem [Kapitel zur repeated & mixed ANOVA](#sec-anova-mixed).

#### Hypothesen {.unnumbered .unlisted}

Wenn wir von der ANOVA sprechen, dann kommen wir natürlich nicht an den Hypothesen vorbei. Die ANOVA ist ja auch ein klassischer statistischer Test. Hier müssen wir unterscheiden, ob wir eine Behandlung mit zwei Gruppen, also einem Faktor $A$ mit $2$ Leveln vorliegen haben. Oder aber eine Behandlung mit drei oder mehr Gruppen vorliegen haben, also einem Faktor $A$ mit $\geq 3$ Leveln in den Daten haben. Da wir schnell in einer ANOVA mehrere Faktoren haben, haben wir auch schnell viele Hypothesen zu beachten. Jeweils ein Hypothesenpaar pro Faktor muss dann betrachtet werden. Das ist immer ganz wichtig, die Hypothesenpaare sind unter den Faktoren mehr oder minder unabhängig.

::: panel-tabset
## Faktor mit $2$ Leveln

Bei einem Faktor $A$ mit nur zwei Leveln $A.1$ und $A.2$ haben wir eine Nullhypothese, die du schon aus den Gruppenvergleichen wie dem t-Test kennst. Wir wollen zwei Mittelwerte vergleichen und in unserer Nullhypothese steht somit die Gleichheit. Da wir nur zwei Gruppen haben, sieht die Nullhypothese einfach aus.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2}
$$

In der Alternativehypothese haben wir dann den Unterschied zwischen den beiden Mittelwerten. Wenn wir die Nullhypothese ablehnen können, dann wissen wir auch welche Mittelwertsunterschied signifikant ist. Wir haben ja auch nur einen Unterschied getestet.

$$
H_A: \; \bar{y}_{A.1} \neq \bar{y}_{A.2}
$$ Das Ganze wird dann etwas komplexer im Bezug auf die Alternativehypothese wenn wir mehr als zwei Gruppen haben. Hier kommt dann natürlich auch die Stärke der ANOVA zu tragen. Eben mehr als zwei Mittelwerte vergleichen zu können.

## Faktor mit $\geq 3$ Leveln

Die klassische Nullhypothese der ANOVA hat natürlich mehr als zwei Level. Hier einmal beispielhaft die Nullhypothese für den Vergleich von drei Gruppen des Faktors $A$. Wir wollen als Nullhypothese testen, ob alle Mittelwerte der drei Gruppen gleich sind.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

Wenn wir die Nullhypothese betrachten dann sehen wir auch gleich das Problem der Alternativehypothese. Wir haben eine Menge an paarweisen Vergleichen. Wenn wir jetzt die Nullhypothese ablehnen, dann wissen wir nicht welcher der drei paarweisen Mittelwertsvergleiche denn nun unterschiedlich ist. Praktisch können es auch alle drei oder eben zwei Vergleiche sein.

$$
\begin{aligned}
H_A: &\; \bar{y}_{A.1} \ne \bar{y}_{A.2}\\
\phantom{H_A:} &\; \bar{y}_{A.1} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \bar{y}_{A.2} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \mbox{für mindestens einen Vergleich}
\end{aligned}
$$

Wenn wir die Nullhypothese abgelhent haben, dann müssen wir noch einen sogenannten Post-hoc Test anschließen um die paarweisen Unterschiede zu finden, die dann signifikant sind. Das ganze machen wir dann aber in einem eigenen Kapitel zum Post-hoc Test.
:::

#### Normalverteilung und Varianzhomogenität {.unnumbered .unlisted}

> *"Soll ich's wirklich machen oder lass ich's lieber sein? Jein..." --- Fettes Brot, Jein*

Wenn wir die ANOVA nutzen wollen, dann kommen wir um die Voraussetzungen der Normalverteilung an den Messwert $y$ sowie die Varianzhomogenität in den Faktorleveln oder Behandlungsgruppen $f$ nicht herum. In dem [Kapitel zum Pre-Test oder Vortest](#sec-pretest) gehe ich nochmal detailierter auf mögliche Tests auf die Normalverteilung und die Varianzhomogenität ein. In diesem Kapitel findest du in dem Abschnitt [Test auf Normalverteilung und Varianzhomogenität](#sec-anova-test-pre) einmal ein Vorgehen für das Testen der Annahmen. Ich würde davon allgemein abraten, aber es wird immer wieder verlangt, also stelle ich es hier auch vor. Kurzfassung, die ANOVA ist realtiv robust gegen eine Abweichung von der Normalverteilung der Messwerte. Ebenso kann die ANOVA mit leichter Varianzheterogenität umgehen.

Häufig kommt jetzt die Frage, ob mein Messwert $y$ wirklich normalverteilt ist und ich nicht den Messwert auf Normalverteilung testen sollte. Die kurze Antwort lautet nein, da du meistens zu wenig Beobachtungen pro Gruppe vorliegen hast. Die etwas längere liefert @kozak2018s mit dem Artikel [What's normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions](https://onlinelibrary.wiley.com/doi/pdf/10.1111/jac.12220?casa_token=22Jm83-kW-MAAAAA:yh0EVuGiGHWDsuPiVP8ZLj51OCasdpIiVWUcYv3Q8dGaIo0yMeNZNwkHIk1ibTCsLhkxbLKZrwZSByo).

Kommen wir nun zur Varianzhomogenität oder Varianzhterogenität in den Gruppen des Behandlunsgfaktors. Wir betrachten also meistens nur den wichtigen Faktor $f_A$ und ignorieren ein wenig den zwieten Faktor. Prinzipiell kannst du natürlich auch den zweiten Fakto anschauen, aber dann werden es immer mehr Gruppen und Fakotrkombinationen. Am Ende kommt dann sowieso heraus, dass über alle Gruppen hinweg keine homogenen Varianzen vorliegen. Wenn du mehr lesen willst so gibt es auf der Seite DSFAIR noch einen Artikel zu `{emmeans}` und der Frage [Why are the StdErr all the same?](https://schmidtpaul.github.io/dsfair_quarto/ch/summaryarticles/whyseequal.html)

Wann liegt vermutlich Varianzheterogenität in deinen experimentellen Faktoren $f$ vor?

:   Es gibt so ein paar Daumenregeln, die dir helfen abzuschätzen, ob in deinen Gruppen Varianzheterogenität vorliegt. Um es kurz zu machen, vermutlich hast du mindestens leichte Varianzhterogenität in den Daten vorliegen.

1)  Du hat viele Behandlungsgruppen. Je mehr Gruppen du hast oder eben dann auch Faktorkombinationen, die du testen möchtest, desto wahrscheinlicher wird es, dass mindestens eine Gruppe eine unterschiedliche Varianz hat. Du hast Varianzheterogenität vorliegen.
2)  Du misst deine Gruppen über die Zeit. Je größer, schwerer oder allgemein höher ein Messwert wird, desto größer wird auch die Varianz. Schaust du dir deine Messwerte über die Zeit an hast du meistens Varianzheterogenität vorliegen.
3)  Deine Kontrolle ohne Behandlung verhält sich meistens nicht so, wie die Gruppen, die eine Behandlung erhalten haben. Wenn du nichts machst in deiner negativen Kontrolle, dann hast du meistens eine andere Streuung der Messwerte als unter einer Behandlung.
4)  Diene Behandlungen sind stark unterschiedlich. Wenn deine Behandlungen sich biologisch oder chemisch in der Wirkung unterscheiden, denn werden vermutlich deine Messwerte auch anders streuen. Hier spielt auch die Anwendung der Behandlung und deren Bereitstellung eine Rolle. Wenn was nicht gleich ist, dann wird es vermutlich nicht gleiche Messwerte erzeugen.
5)  Du hast wenig Fallzahl pro Gruppe oder Faktorkombination. Wenn du wenig Fallzahl in einer Gruppe hast, dann reicht schon eine (zufällige) Messabweichung und schon sind deine Varianzen heterogen.

Gut, jetzt wissen wir, dass du *vermutlich* Varianzheterogenität in deinen Daten vorliegen hast. Erstmal ist das kein so großes Problem.

Tut Varianzhterogenität anstatt Varianzhomogenität weh?

:   Nein. Meistens ist die Varianzheterogenität nicht so ausgeprägt, dass du nicht auch eine ANOVA rechnen kannst. Über alle Gruppen hinweg wird dann zwar in einer ANOVA die Varianz gemmittelt und es kann dann zu weniger signifkanten Ergebnissen führen, aber so schlimm ist es nicht. Im Post-hoc Test solltest du aber die Varianzhterogenität berücksichtigen, da du ja immer nur zwei Gruppen gleichzeitig betrachtest.

#### Welche Pakete gibt es eigentlich? {.unnumbered .unlisted}

Wenn um die Anwendung der ANOVA in R geht, dann haben wir eine Menge Pakete zur Auswahl. Wie immer macht die Fragestellung und das gewählte Modell den Großteil der Entscheidungsindung aus. Ich zeige dir später in der Anwendung dann auch alle Pakete einmal, gebe dir dann aber auch immer eine Empfehlung mit. In der folgenden Tabelle gebe ich dir einmal eine kurze Übersicht über die beiden Annahmen an die ANOVA. Normalerweise brauchen wir einen normalverteilten Messwert $y$ und Varianzhomogenität in den Faktoren. In den letzten Jahren wurden aber noch weitere Implementierungen der ANOVA entwickelt, so dass hier auch Alternativen vorliegen.

|                            | `{base}` | `{car}`  | `{afex}` | `{WRS2}` | Excel |
|:---------------------------|:--------:|:--------:|:--------:|:--------:|:-----:|
| **Normalverteilt** $y$     |    ja    |    ja    |    ja    |   nein   |  ja   |
| **Varianzhomogenität** $f$ |    ja    | optional |    ja    |   nein   |  ja   |
| **Messwiederholungen**     |   nein   |   nein   |    ja    |    ja    | nein  |

: Übersicht über Funktion der ANOVA in ausgewählten Paketen und Excel. Die Aussagen sind nicht als absolut zu verstehen sondern eher als Empfehlung und Leitplanken zur Orientierung. {#tbl-anova-übersicht}

Gehen wir jetzt mal die Pakete durch. Wir immer gibt es einiges an Möglichkeiten und ich zeige dir hier eben die Auswahl. Es gibt hier das ein oder andere noch zu beachten, aber da gehe ich dann bei den jeweiligen Methoden drauf ein. Es macht eben dann doch einen Unterschied ob ich eine einfaktorielle oder komplexere ANOVA rechnen will. Nicht alles geht in allen R Pakten oder gar Excel.

Der Standard mit der Funktion `aov()` aus `{base}`

:   Die Standardfunktion `aov()` erlaubt es eine einfaktorielle oder zweifaktorielle ANOVA direkt auf einem Datensatz zu rechnen. Hier brauchen wir nur ein Modell in der in R üblichen Formelschreibweise `y ~ f`. Du kannst diesen Ansatz als schnelle ANOVA begreifen. Dein Messwert $y$ muss hier normalverteilt sein.

Der erweiterte Standard mit der Funktion `anova()` aus `{base}`

:   Die Funktion `anova()` erlaubt es auch auf anderen Modellen eine ANOVA zu rechnen. Wi nutzen hier die Funktion `lm()`, die einen normalverteilten Messwert $y$ annimmt. Es ginge aber auch mit anderen Modellierungen und der Funktion `glm()` für Zähldaten einer Possionverteilung oder noch anderen Verteilungen. Die `anova()` Funktion ist sehr reudziert, tut aber im Sinne einer ANOVA was die Funktion machen soll.

Mit der Funktion `Anova()` aus `{car}`

:   Das [R Paket `{car}`](https://cran.r-project.org/web/packages/car/index.html) bietet eine Verbesserung der Standardfunktionen der ANOVA an. Insbesondere die Berücksichtigung und die Modellierung eines Interaktionseffektes in einer zweifaktoriellen ANOVA sticht heraus. Daher ist die Funktion hier etwas flexibeler als der Standard. In einer einfaktoriellen ANOVA bemerkst du keinen Unterschied.

Mit den ANOVA Funktionen aus `{afex}`

:   Wir können die ANOVA auch anwenden, wenn wir Messwiederholungen vorliegen haben. Daher bietet sich hier das [R Paket `{afex}`](https://github.com/singmann/afex) an. Du musst bei den Funktionen von `{afex}` immer eine ID mitlaufen lassen, die angibt welche Individuen wiederholt gemessen wurden. Also hat jede Zeile eine Nummer, die beschreibt welche Beobachtung hier vorliegt. Besonders wichtig bei Messungen über die Zeit. Darüber hinaus kann das Paket sehr gut Interaktionen schätzen und Bedarf dort keiner zusätzlichen Optionen.

> *"ANOVAs are generally robust to 'light' heteroscedasticity, but there are various other methods (not available in `{afex}`) for getting robust error estimates."* --- [Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html)

Das Paket `{afex}` kann nicht mit Varianzheterogenität umgehen, aber dafür mit Messwiederholungen. Ich würde das Paket `{afex}` nehmen, wenn ich Messwiederholungen vorliegen habe oder mich die Interaktion in einem zweifaktoriellen Modell interessiert.

Mit den ANOVA Funktionen aus `{WRS2}`

:   Eine Annahme an die ANOVA ist, dass wir es mit normalverteilten Messwerten $y$ sowie Varianzhomogenität in den Faktoren $f$ vorliegen haben. Das R Paket `{WRS2}` mit der hervorragenden Vingette [Robust Statistical Methods Using WRS2](https://cran.r-project.org/web/packages/WRS2/vignettes/WRS2.pdf) erlaubt nun aber diese beiden Annahmen zu umgehen und bietet eine robuste ANOVA an. Robust meint hier, dass wir uns nicht um die Normalverteilung und Varianzhomogenität kümmern müssen.

Mit Excel

:   Hier muss ich sagen, dass es schon etwas weh tut die einfaktorielle und zweifaktorielle ANOVA in Excel zu rechnen. Ich habe dir bei der einfaktoriellen sowie der zweifaktoriellen ANOVA ein Video für die ANOVA in Excel ergänzt. Eigentlich ist es nur der letzte Strohhalm, wenn du keine Zeit mehr hast dich in R nochmal einzuarbeiten.

::: callout-tip
## Weitere Tutorien für die ANOVA

Wir oben schon erwähnt, kann dieses Kapitel nicht alle Themen der ANOVA abarbeiten. Daher präsentiere ich hier eine Liste von Literatur und Links, die mich für dieses Kapitel hier inspiriert haben. Nicht alles habe ich genutzt, aber vielleicht ist für dich was dabei.

-   [ANOVA in R](https://www.datanovia.com/en/lessons/anova-in-r/)
-   [One-Way ANOVA Test in R](https://www.sthda.com/english/wiki/one-way-anova-test-in-r)
-   [Two-Way ANOVA Test in R](https://www.sthda.com/english/wiki/two-way-anova-test-in-r)
-   [MANOVA Test in R: Multivariate Analysis of Variance](https://www.sthda.com/english/wiki/manova-test-in-r-multivariate-analysis-of-variance)
-   [ANOVA in R \| A Complete Step-by-Step Guide with Examples](https://www.scribbr.com/statistics/anova-in-r/)
:::

## Theoretischer Hintergrund

Im folgenden Abschnitt schauen wir uns einmal den theoretischen Hintergrund zu der ANOVA an. Ich fokusiiere mich hier einmal für die Theorie auf die einfaktorielle ANOVA. Die Prinzipien lassen sich dann auch auf die zweifaktorielle und mehrfaktoriellen Algorithmen der ANOVA anwenden. Was dann später noch dazukommt sind dann die Interaktionen. Dabei ist zu bachten, dass wir natürlich eine Interaktion nur in einem zweifaktoriellen Modell beobachten können. Daher hier der Start mit der einfaktoriellen ANOVA und dann die Vertiefung zur Interaktion mit der zweifaktoriellen ANOVA.

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01_small.png){fig-align="center" width="100%"}

> In der ersten Version dieses Kapitels habe ich noch sehr viel beispielhaft für eine einfaktorielle ANOVA durchgerechnet. Wie sich dann in den Jahren herausstellte, hat es dir wenig geholfen, die ANOVA zu verstehen oder anzuwenden. Wer rechnet schon die ANOVA per Hand? Daher hier eben das klassische [lying-to-children](https://en.wikipedia.org/wiki/Lie-to-children) und ich erkläre dir die ANOVA mehr konzeptionell als rein mathematisch korrekt.
:::

Wir müssen jetzt einmal für dei Haupteffekte eines Faktors $A$ oder $B$ unterschieden sowie deren Interaktion untereinander. Deshalb besprechen wir jetzt erstmal einen Haupteffekt eines Faktors $A$ mit drei Levels $A.1$, $A.2$ sowie $A.3$ und arbeiten uns dann vor. Ich habe auf großartige Mathematik und Formeln verzichtet. Du findest die entsprechenden händischen Rechenoperation auf Wikipedia oder in einem entsprechenden statistischen [Lehrbuch zur ANOVA und Statistik](https://s3-us-west-2.amazonaws.com/mtvernon.wsu.edu/uploads/2016/12/Statistics_for_Terrified_Biologists.pdf) wie das verlinkte Buch von @van2019statistics.

### Haupteffekte $f_A$

Für die Theorie konzentrieren wir uns nur auf die einfaktoriele ANOVA. Das heißt wir haben einen Faktor $A$ mit drei Levels $A.1$, $A.2$ sowie $A.3$ vorliegen. Du kannst dir die drei Level als drei Gruppen vorstellen. Entweder sind es verschiedene Düngestufen oder aber eben drei Floharten, die unterschiedlich weit springen. Erinnere dich nochmal an die @fig-anova-intro zu Beginn des Kapitels. Wir wollen in unseren Daten Varianz haben, denn nur dann haben wir auch wirklich einen Unterschied zwischen den Gruppen in unserer Behandlung. Fangen wir also mit der wichtigste Frage einmal an.

Wann sind drei oder mehr Mittelwerte gleich?

:   Für unseren Gedankengang nehmen wir mal drei Mittelwerte für die drei Gruppen $A.1$, $A.2$ sowie $A.3$ an. Wir brauchen ja in der Nullhypothese Gleichheit. Das heißt, dass alle drei Mittelwerte $\bar{y}_{A.1}$, $\bar{y}_{A.2}$ und $\bar{y}_{A.3}$ gleich sein müssen. Wir nennen diese Mittelwerte der Gruppen daher auch lokale Mittelwerte. Wir können also wie folgt schreiben.

$$
\bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

Jetzt kommt der eigentlich Hauptgedanke. Wenn die drei Mittelwerte gleich sind, dann ist auch das globale Mittel $\beta_0$ gleich der drei Mittelwerte. Das klingt jetzt erstmal etwas schräg, aber wir hätten dann folgenden Zusammenhang.

$$
\overbrace{\cfrac{\bar{y}_{A.1} + \bar{y}_{A.2} + \bar{y}_{A.3}}{3}}^{\beta_0} \overset{?}{=} \bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

In der folgenden Abbildung wird dir es vielleicht nochmal klarer.

Deshalb sprechen wir auch von einem globalen Mittelwert $\beta_0$ sowie von lokalen Mittelwerten $\bar{y}_{A.1}$, $\bar{y}_{A.2}$ und $\bar{y}_{A.3}$ der einzelen Gruppen des Faktors $A$.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-null
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Zusammenhang zwischen dem globalen Mittelwert $\\beta_0$ und den drei Mittelwerten $\\bar{y}_{A.1}$, $\\bar{y}_{A.2}$ und $\\bar{y}_{A.3}$ der Gruppen $A.1$, $A.2$ sowie $A.3$. **(A)** Wenn die drei Mittelwerte gleich sidn und damit die Nullhypothese gilt, dann liegen die drei Mittelwerte auf dem globalen Mittelwert. **(B)** Wenn die drei Mittelwerte sich unterschieden, dann kann die Nullhypothese abgelehnt werden und die drei Mittelwerte liegen nicht auf dem globalen Mittel.  *[Zum Vergrößern anklicken]*"

set.seed(202434)
ex_intro_null_lst <- get_intro_data_tbl(mean = c(5, 5, 5), 
                                        sd = c(1, 0.5, 1), ng = c(4, 3, 5))
ex_intro_alt_lst <- get_intro_data_tbl(mean = c(4.5, 1, 8), 
                                       sd = c(1, 0.5, 1), ng = c(4, 3, 5))

get_ex_lst_intro_plot(ex_intro_null_lst) + 
  ggtitle("Nullhypothese annehmen",
          subtitle = "Die Mittelwerte sind gleich") +
  get_ex_lst_intro_plot(ex_intro_alt_lst) + 
  ggtitle("Nullhypothese ablehnen",
          subtitle = "Die Mittelwerte unterscheiden sich") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-alt-ssa
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Zu"

get_ex_lst_intro_alt_ssa_plot(ex_intro_alt_lst) + 
  ggtitle(expression(Berechnung~der~Sum~of~Quares~vom~Faktor~A~SS[A]),
          subtitle = "Die Mittelwerte unterscheiden sich")

```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-alt-sse
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Zu"

get_ex_lst_intro_alt_sse_plot(ex_intro_alt_lst) + 
  ggtitle(expression(Berechnung~der~Sum~of~Quares~vom~Faktor~A~SS[Error]),
          subtitle = "Die Mittelwerte unterscheiden sich")
```

Jetzt kommt die Idee der Teststatistik, die Null sein muss

Abstände der lokalen Mittelwerte zum globalen Mittel als Abweichungsquadrate (eng. *sum of squares*, abk. *SS*)

Würden immer größer werden mit mehr Gruppen. Mittlere Abweichungsquadrate (eng. *mean of squares*, abk. *MS*).

Jetzt gibt es aber noch einen Unterschied wie die Beobachtungen um die lokalen Mittelwerte streuen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-msa-mse
#| fig-align: center
#| fig-height: 6
#| fig-width: 7.5
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

ex_00_lst <- get_data_tbl(mean = c(5, 5, 5), sd = c(0.2, 0.2, 0.2))
ex_01_lst <- get_data_tbl(mean = c(5, 1, 9), sd = c(0.2, 0.2, 0.2))
ex_10_lst <- get_data_tbl(mean = c(5, 5, 5), sd = c(2, 2, 2))
ex_11_lst <- get_data_tbl(mean = c(5, 1, 9), sd = c(2, 2, 2))

get_ex_lst_plot(ex_00_lst) + 
  ggtitle(expression(MS[A]%~~%0~und~MS[Error]%~~%0),
          "Mittelwerte gleich und Fehler klein") +
  get_ex_lst_plot(ex_01_lst) +
  ggtitle(expression(MS[A]~">"~0~und~MS[Error]%~~%0),
          "Mittelwerte ungleich und Fehler klein") +
  get_ex_lst_plot(ex_10_lst) + 
  ggtitle(expression(MS[A]%~~%0~und~MS[Error]~">"~0),
          "Mittelwerte gleich und Fehler groß") +  
  get_ex_lst_plot(ex_11_lst) +
  ggtitle(expression(MS[A]~">"~0~und~MS[Error]~">"~0),
          "Mittelwerte ungleich und Fehler groß") +  
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

$$
F_D = \cfrac{MS_A}{MS_{Error}}
$$

text

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-fstat
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "foon."

p_f_stat
```

| Quelle | df | Sum of squares (SS) | Mean squares (MS) | Teststatistik F$_{\boldsymbol{D}}$ |
|:--:|:--:|:--:|:--:|:--:|
| $A$ | $df_A$ | $SS_A$ | $MS_A = \cfrac{SS_A}{df_A}$ | $F_{D} = \cfrac{MS_A}{MS_{Error}}$ |
| $Error$ | $df_{Error}$ | $SS_{Error}$ | $MS_{Error} = \cfrac{SS_{Error}}{df_{Error}}$ |  |
| $Total$ | $df_{total}$ | $SS_{Total}$ |  |  |

: Einfaktorielle ANOVA in der theoretischen Darstellung. Die sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac1-theo}

| Quelle | df | Sum of squares (SS) | Mean squares (MS) | Teststatistik F$_{\boldsymbol{D}}$ |
|:--:|:--:|:--:|:--:|:--:|
| $A$ | $df_A$ | $SS_{A}$ | $MS_{A} = \cfrac{SS_A}{df_A}$ | $F_{D} = \cfrac{MS_{A}}{MS_{Error}}$ |
| $B$ | $df_B$ | $SS_{B}$ | $MS_{B} = \cfrac{SS_B}{df_B}$ | $F_{D} = \cfrac{MS_{B}}{MS_{Error}}$ |
| $A \times B$ | $df_{A \times B}$ | $SS_{A \times B}$ | $MS_{A \times B} = \cfrac{SS_{A \times B}}{df_{A \times B}}$ | $F_{D} = \cfrac{MS_{A \times B}}{MS_{Error}}$ |
| $Error$ | $df_{Error}$ | $SS_{error}$ | $MS_{Error} = \cfrac{SS_{Error}}{df_{Error}}$ |  |
| $Total$ | $df_{total}$ | $SS_{total}$ |  |  |

: Zweifaktorielle ANOVA ohne Interaktionseffekt in der theoretischen Darstellung. Die Sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac2-ohne-inter}

|         |              |                |
|:-------:|:------------:|:--------------:|
|         |    $MS_A$    | $MS_{between}$ |
|         | $MS_{Error}$ | $MS_{within}$  |
| $s^2_p$ | $MS_{Total}$ |  $MS_{Total}$  |

: foot. {#tbl-anova-namen}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-single-cat-anova 
#| fig-align: center
#| fig-height: 5
#| fig-width: 8
#| fig-cap: "Visualisierung  *[Zum Vergrößern anklicken]*"

p_example_fac_1_total + p_example_fac1 +
  plot_layout(width = c(1, 5)) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-var-hetero
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

ex_hetero_lst <- get_data_tbl(mean = c(1, 5, 6), sd = c(0.5, 4, 0.5))
ex_homo_lst <- get_data_tbl(mean = c(1, 5, 6), sd = c(1.7, 1.7, 1.7))

get_ex_lst_plot(ex_hetero_lst) + 
  labs(title = "Experimentelle Daten",
       subtitle = "Varianzheterogenität in den Gruppen",
       caption = "Buchstaben zeigen Compact letter display") +
  annotate("label", x = c(5.5, 16.5, 25.5), y = c(4, 13, 9), 
           label = c("A", "AB", "B"), fill = "gray90") +
  get_ex_lst_plot(ex_homo_lst) +
  labs(title = "ANOVA Modellierung",
       subtitle = "Varianzhomogenität in den Gruppen",
       caption = "Buchstaben zeigen Compact letter display") +
  annotate("label", x = c(5.5, 15.5, 25.5), y = c(6, 9.5, 9), 
           label = c("A", "A", "A"), fill = "gray90") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

### Effektschätzer

[Effect Sizes for ANOVAs](https://easystats.github.io/effectsize/articles/anovaES.html)

#### Eta$^2$ {.unnumbered .unlisted}

[$Eta^2$](https://easystats.github.io/effectsize/articles/anovaES.html#eta2)

`interpret_eta_squared()` aus dem R Paket `{effectsize}`

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-eta-venn
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_eta_venn + p2_eta_venn +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Omega$^2$ und Epsilon$^2$ {.unnumbered .unlisted}

$\omega^2$ und $\epsilon^2$

[Other Measures of Effect Size](https://easystats.github.io/effectsize/articles/anovaES.html#other-measures-of-effect-size)

### Interaktion $f_A \times f_B$

Wenn du mehr als einen Faktor $f_A$ in deinem Modell vorliegen hast, dann kannst du eine Interaktion zwischen den Faktoren vorliegen haben. Wir schreiben in R einen Interaktionsterm mit dem `:` zwischen den Namen der beiden Faktoren. Wenn wir also die Interaktion zwischen dem Faktor $f_1$ und $f_2$ in R modellieren wollen, dann schreiben wir `fa:fb`. In der mathematischen Schreibweise haben wir dann häufig die Form $f_A \times f_B$ vorliegen. Ich schreibe hier häufig dann die mathematische Notian im Fließtext und natürlich im R Code dann die entsprechende Notation in R.

| Mathematisch     | R       |
|------------------|---------|
| $f_A \times f_B$ | `fa:fb` |

: Vergleich der Schreibweise einer Interaktion zwischen den Faktoren $f_A$ und $f_B$ einmal mathematisch und einmal in R. {#tbl-anova-inter-namen}

Der folgende Abschnitt teilt sich grob in zwei Teile. Einmal der theoretische Hintergrund zur Interaktion und was dort eigentlich die Herausforderungen in der Modellierung sind sowwie einen Abschnitt zur visuellen Überprüfung der Interaktion in einer zweifaktoriellen Analyse.

#### Theoretischer Hintergrund {.unnumbered .unlisted}

::: callout-warning
## Achtung, bitte beachten!

Dieser Abschnitt ist dann *etwas* eskaliert. Wenn du dich nicht für die statistischen Methoden und Hintergründe interessierst, dann überspringe diesen Abschnitt und gehe gleich zur visuellen Überprüfung der Interaktion.
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-circ
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p2_inter_venn + p1_inter_venn +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))  
```

[Anova – Type I/II/III SS explained](https://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html) und [How to interpret type I, type II, and type III ANOVA and MANOVA?](https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)

[Interaktionseffekte](https://methpsy.elearning.psych.tu-dresden.de/mediawiki/index.php/Interaktionseffekte)

[Adding Interactions](https://easystats.github.io/effectsize/articles/anovaES.html#adding-interactions)

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-contr-sum
#| tbl-cap: "foo"

f1_contr_sum_tbl |> 
  mutate(pos = rep(1:3,3)) |> 
  pivot_wider(names_from = fa, values_from = rsp) |> 
  select(-pos) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-contr-sum-desc
#| tbl-cap: "foo."

f1_contr_sum_tbl  |> 
  group_by(fa) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Mittelwert")) |> 
  tt(width = 0.5, align = "c", theme = "striped")
```

::: panel-tabset
## Treatment coding

```{r}
lm(rsp ~ fa, f1_contr_sum_tbl, contrasts = list(fa = "contr.treatment")) |> 
  coef() |> round(2)
```

## Effect coding

```{r}
lm(rsp ~ fa, f1_contr_sum_tbl, contrasts = list(fa = "contr.sum")) |> 
  coef() |> round(2)
```
:::

Es gibt noch mehr [Contrast codings](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/), je nachdem wie dein Messwert $y$ oder deine Faktoren $f$ beschaffen sind

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f1-effect-coding
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p2_f1_contr_sum + p1_f1_contr_sum +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

::: panel-tabset
## Effect coding ohne Interaktion

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-nointer
#| tbl-cap: "foo"

f2_contr_sum_nointer_tbl |> 
  mutate(pos = rep(1:3,6)) |> 
  select(-key) |> 
  pivot_wider(names_from = fb, values_from = rsp) |> 
  select(-pos) |> 
  set_names(c("", "B.1", "B.2")) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-nointer-desc
#| tbl-cap: "foo."

f2_contr_sum_nointer_tbl |> 
  group_by(fa, fb) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Faktor B", "Mittelwert")) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
lm(rsp ~ fa + fb + fa:fb, f2_contr_sum_nointer_tbl, 
   contrasts = list(fa = "contr.sum", fb = "contr.sum")) |> 
  coef() |> round(2)
```

| $y$  |     | $\beta_0$ | $\beta_{A1}$ | $\beta_{B1}$ | $\beta_{A1:B1}$ |
|------|-----|-----------|--------------|--------------|-----------------|
| $40$ | $=$ | $120$     | $-60$        | $+23.3$      | $-3.33$         |

: foot. {#tbl-anova-namen}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f2-effect-coding-no-inter
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p_f2_contr_sum_nointer

```

## Effect coding mit Interaktion

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-inter
#| tbl-cap: "foo"

f2_contr_sum_inter_tbl |> 
  mutate(pos = rep(1:3,6)) |> 
  select(-key) |> 
  pivot_wider(names_from = fb, values_from = rsp) |> 
  select(-pos) |> 
  set_names(c("", "B.1", "B.2")) |> 
  tt(width = 2/3, align = "c", theme = "striped") |> 
  style_tt(i = c(1:3, 7:9), j = 2, color = "#D55E00",
           bold = TRUE)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-inter-desc
#| tbl-cap: "foo."

f2_contr_sum_inter_tbl |> 
  group_by(fa, fb) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Faktor B", "Mittelwert")) |> 
  tt(width = 2/3, align = "c", theme = "striped") |> 
  style_tt(i = c(1, 5), j = 3, color = "#D55E00",
           bold = TRUE)
```

```{r}
lm(rsp ~ fa + fb + fa:fb, f2_contr_sum_inter_tbl, 
   contrasts = list(fa = "contr.sum", fb = "contr.sum")) |> 
  coef() |> round(2)
```

| $y$   |     | $\beta_0$ | $\beta_{A1}$ | $\beta_{B1}$ | $\beta_{A1:B1}$ |
|-------|-----|-----------|--------------|--------------|-----------------|
| $210$ | $=$ | $120$     | $+5$         | $+23.3$      | $+61.67$        |

: foot. {#tbl-anova-namen}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f2-effect-coding-inter
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p_f2_contr_sum_stat_inter

```
:::

#### Visuelle Überprüfung {.unnumbered .unlisted}

::: panel-tabset
## Liniendiagramm

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-line
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_line_theo + p2_inter_line_theo + p3_inter_line_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

## Boxplot

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-box
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_box_theo + p2_inter_box_theo + p3_inter_box_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## Barplot

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-bar
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_bar_theo + p2_inter_bar_theo + p3_inter_bar_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, WRS2, scales,
               readxl, see, car, patchwork, emmeans,
               interactions, effectsize, afex, report,
               performance, conflicted)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

#### Einfaktorieller Datensatz {.unnumbered .unlisted}

```{r}
#| message: false

fac1_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length) |> 
  mutate(animal = as_factor(animal))|> 
  rowid_to_column(".id")
```

Dann schauen wir uns die Daten einmal in der folgenden Tabelle als Auszug einmal an. Wichtig ist hier nochmal, dass du eben einen Faktor `animal` mit drei Leveln also Gruppen vorliegen hast. Wir wolen jetzt die drei Tierarten hinsichtlich ihrer Sprungweite in \[cm\] miteinander vergleichen. Weil wir jetzt mehr als zwei Gruppen vorliegen haben, sprechen wir von einem multiplen Vergleich.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table
#| tbl-cap: "Tabelle der Sprungweiten in [cm] als Messwert $y$ von Hunde-, Katzen- und Fuchsflöhen. Der Datensatz ist einfaktoriell, da wir nur einen Behandlungsfaktor $x$ mit `animal` vorliegen haben."

fac1_raw_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length)

rbind(head(fac1_raw_tbl, n = 3),
      rep("...", times = ncol(fac1_raw_tbl)),
      tail(fac1_raw_tbl, n = 3)) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-1fac
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "Beispielhafter einfaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten."

ggplot(data = fac1_tbl, 
       aes(x = animal, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = "point", 
               shape=23, size = 3, fill = "gray50") +
  labs(x = "Flohart", y = "Sprungweite in [cm]") +
  theme(legend.position = "none") + 
  scale_fill_okabeito() 
```

#### Zweifaktorieller Datensatz {.unnumbered .unlisted}

Neben dem einfaktoriellen Datensatz wollen wir uns noch den häufigeren Fall mit zwei Faktoren anschauen. Wir haben also nicht nur die drei Floharten vorliegen und wollen wissen ob diese unterschiedlich weit springen. Darüber hinaus haben wir noch einen zweiten Faktor gewählt. Wir haben die Sprungweiten der Hunde-, Katzen- und Fuchsflöhe nämlich an zwei Messorten, der Stadt und dem Dorf, gemessen. Dadurch haben wir jetzt den Faktor `animal` und den Faktor `site` vorliegen. Wiederum fragen wir usn, ob sich die Sprungweite in \[cm\] der drei Floharten in den beiden Messorten unterscheidet. Im Folgenden lade ich einmal den Datensatz in das Objekt `fac2_tbl`.

```{r}
#| message: false

fac2_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
  filter(site %in% c("city", "village")) |> 
  mutate(animal = as_factor(animal),
         site = as_factor(site))|> 
  rowid_to_column(".id")
```

Betrachten wir als erstes einen Auszug aus der Datentabelle. Wir haben hier als Messwert oder Outcome $y$ die Sprungweite `jump_length` vorliegen. Als ersten Faktor die Variable `animal` und als zweiten Faktor die Variable `site` festgelegt.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-table
#| tbl-cap: "Tabelle der Sprungweiten in [cm] als Messwert $y$ von Hunde-, Katzen- und Fuchsflöhen an zwei verschiedenen Messorten Stadt und Dorf. Der Datensatz ist zweifaktoriell, da wir einen Behandlungsfaktor $x$ mit `animal` und einen zweiten Faktor mit `site` vorliegen haben."

fac2_raw_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
      filter(site %in% c("city", "village")) 

rbind(head(fac2_raw_tbl, n = 3),
      rep("...", times = ncol(fac2_raw_tbl)),
      tail(fac2_raw_tbl, n = 3)) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-2fac
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Beispielhafter zweifaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten und den beiden Messorten."

ggplot(data = fac2_tbl, 
       aes(x = site, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() + 
  stat_summary(fun.y = mean, geom = "point", aes(group = animal), 
               shape=23, size = 3, fill = "gray50",
               position = position_dodge(0.75)) +
  labs(x = "Flohart", y = "Sprungweite in [cm]", fill = "Tierart") +
  scale_fill_okabeito() 
```

#### Multifaktorieller Datensatz {.unnumbered .unlisted}

```{r}
fac3_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "fac4") |> 
  select(animal, stage, site, season, jump_length) |> 
  mutate(animal = as_factor(animal),
         stage = factor(stage, level = c("juvenile", "adult")),
         site = as_factor(site),
         season = as_factor(season),
         jump_length = round(jump_length, 2))|> 
  rowid_to_column(".id")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac3-table
#| tbl-cap: "foo."

fac3_raw_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "fac4") |> 
  select(animal, stage, site, season, jump_length) |> 
  mutate_if(is.numeric, round, 2)

rbind(head(fac3_raw_tbl, n = 3),
      rep("...", times = ncol(fac3_raw_tbl)),
      tail(fac3_raw_tbl, n = 3)) |> 
  tt(width = 1, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-3fac
#| fig-align: center
#| fig-height: 6
#| fig-width: 7
#| fig-cap: "foo."

ggplot(data = fac3_tbl, 
       aes(x = stage, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() + 
  stat_summary(fun.y = mean, geom = "point", aes(group = animal), 
               shape=23, size = 3, fill = "gray50",
               position = position_dodge(0.75)) +
  labs(x = "Entwicklungsstadium", y = "Sprungweite in [cm]", fill = "Flohart") +
  facet_wrap(~ site:season) +
  scale_fill_okabeito() +
  theme(legend.position = "top")
```

## Test auf Normalverteilung und Varianzhomogenität {#sec-anova-test-pre}

In dem folgenden Abschnitt testen wir einmal auf Normalverteilung in dem Messwert $y$ und Varianzmomogenität in den Faktoren $f_A$ und $f_B$. Die hier vorhandenen Ergebnisse schreibst du meistens nicht in deine Abschlussarbeit oder zeigst dort die hier vorgestellten Abbildungen. Das dient hier nur zur Überprüfung in deinem statistischen Arbeitsprozess. Du findest noch im Tutorium [Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html#homogeneity-of-variances) ein paar mehr Informationen, wenn es um die ANOVA und die Annahmen geht.

::: callout-warning
## Achtung, bitte beachten!

Wenn du keine normalverteilten Daten hast, dann wird häufig empfholen, dass du deinen Messwert $y$ transformieren sollst. Das ist eine Lösung, wenn du dann nur bei deiner ANOVA bleiben würdest oder dich die Effekte auf der Einheit des Messwert $y$ nicht interessieren. Durch eine Transformation von $y$ verlierst du immer die direkte biologische Interpretation der Effekte aus einem statistischen Test.
:::

Ich zeige dir hier einmal die Funktionen `check_normality()` und `check_homogeneity()` aus dem R PAket `{performance}`. Beide Funktionen funktionieren super und man muss nicht so viel programmieren um die Funktionen zum laufen zu kriegen. Dammit du was testen kannst, musst du auch ein Modell haben was du testen kannst. Ich nutze hier einmal das einfaktorielle sowie zweifaktorielle Modell aus einer linearen Regression. Da sind die Annhamen die gleichen wie bei einer ANOVA.

#### Normalverteilung des Messwerts $y$ {.unnumbered .unlisted}

Die Funktion `check_normality()` nutzt den [Shapiro-Wilk-Test](https://de.wikipedia.org/wiki/Shapiro-Wilk-Test) um auf eine Abweichung von der Normalverteilung zu testen.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_normality()
```

::: panel-tabset
## Einfaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-normal-f1
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_normality()` zur Überprüfung der Normalverteilung des Messwerts in einem einfaktoriellen Modell."


lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_normality() |> 
  plot() +
  scale_fill_okabeito()
```

## Zweifaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-normal-f2
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_normality()` zur Überprüfung der Normalverteilung des Messwerts in einem zweifaktoriellen Modell."


lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  check_normality() |> 
  plot() +
  scale_fill_okabeito()
```
:::

#### Varianzhomogenität der Faktoren $f$ {.unnumbered .unlisted}

Die Funktion `check_homogeneity()` nutzt den [Bartlett-Test](https://de.wikipedia.org/wiki/Bartlett-Test) um auf eine Abweichung von der Varianzhomogenität zu testen.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_homogeneity()
```

::: panel-tabset
## Einfaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-variance-f1
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_homogeneity()` zur Überprüfung der Varianzhomogenität der Faktoren in einem einfaktoriellen Modell."


lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_homogeneity() |> 
  plot() +
  scale_fill_okabeito()
```

## Zweifaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-variance-f2
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_homogeneity()` zur Überprüfung der Varianzhomogenität der Faktoren in einem zweifaktoriellen Modell."


lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  check_homogeneity() |> 
  plot() +
  scale_fill_okabeito()
```
:::

Weder Normalverteilung noch Varianzhomogenität?

:   In dem Fall kannst du das R Paket `{WRS2}` nutzen, was ich dir in den folgenden Tabs auch immer wieder vorstelle. Das Paket `{WRS2}` kann mit getrimmten Mittelwerten mit nicht normalverteilten Daten sowie Vamrianzhterogenität umgehen. Das ist eine bessere Lösung als die nicht-parametrischen Verfahren, wenn du auf dem ANOVA Pfad bleiben willst.

## Einfaktorielle ANOVA

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal, data = fac1_tbl) |> 
  tidy()
```

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  anova() |> 
  tidy()
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  tidy()
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy()
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal + Error(.id), data = fac1_tbl) 
```

## `{WRS2}`

```{r}
t1way(jump_length ~ animal, data = fac1_tbl)
```

Values of = 0.10, 0.30, and 0.50 correspond to small, medium, and large effect sizes.

## Excel
:::

#### Effektschätzer {.unnumbered .unlisted}

```{r}
aov(jump_length ~ animal, data = fac1_tbl) |> 
  eta_squared()
```

#### `{report}` {.unnumbered .unlisted}

Das [R Paket `{report}`](https://easystats.github.io/report/)

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  report()
```

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  report_table()
```

## Zweifaktorielle ANOVA

### Haupteffekte

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  anova() |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  Anova(type = "III") |> 
  tidy()  |> 
  mutate(p.value = pvalue(p.value))
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal + site + animal:site + Error(.id), data = fac2_tbl) 

```

## `{WRS2}`

```{r}
t2way(jump_length ~ animal + site + animal:site, data = fac2_tbl)
```

## Excel
:::

#### Effektschätzer {.unnumbered .unlisted}

```{r}
aov(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  eta_squared()
```

### Interaktion

::: panel-tabset
## `{ggplot}`

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-1
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

fac2_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, group = site)) +
  theme_minimal() +
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun = mean, geom = "line") +
  scale_color_okabeito()
```

## `{interactions}`

[R Paket `{interactions}`](https://interactions.jacob-long.com/)

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-2
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  cat_plot(modx = site, pred = animal, geom = "line") +
  theme_minimal() +
  scale_color_okabeito()
```
:::

## Mehrfaktorielle ANOVA

### Haupteffekte

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*site, data = fac3_tbl,
    contrasts = list(
    animal = "contr.sum",
    stage = "contr.sum",
    site = "contr.sum"
  )) |> 
  Anova(type = "III") |> 
  tidy()  |> 
  mutate(p.value = pvalue(p.value))
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*site, data = fac3_tbl,
    contrasts = list(
    animal = "contr.sum",
    stage = "contr.sum",
    site = "contr.sum"
  )) |> 
  Anova(white.adjust = TRUE, type = "III")  |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal*stage*site + Error(.id), data = fac3_tbl) 
```

## `{WRS2}`

```{r}
t3way(jump_length ~ animal*stage*site, data = fac3_tbl)
```
:::

### Interaktion

::: panel-tabset
## `{ggplot}`

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-3a
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

fac3_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, linetype = stage, 
             group = interaction(site, stage))) +
  theme_minimal() +
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun = mean, geom = "line") +
  scale_color_okabeito()
```

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-3b
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."
fac3_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, group = site)) +
  theme_minimal() +
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun = mean, geom = "line") +
  scale_color_okabeito() +
  facet_wrap(~ stage)
```

## `{interactions}`

[R Paket `{interactions}`](https://interactions.jacob-long.com/)

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-4
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

lm(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  cat_plot(modx = site, mod2 = stage, pred = animal,  geom = "line") +
  theme_minimal() +
  scale_color_okabeito()
```
:::

@field2013discovering

```{r}
#| message: false
#| warning: false
lm(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  Anova(type = "III") |>
  epsilon_squared() |> 
  interpret_eta_squared(rules = "field2013")
```

## MANOVA

[Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html#sphericity)

[One-Way MANOVA in R](https://www.datanovia.com/en/lessons/one-way-manova-in-r/)

::: panel-tabset
## `{base}`

## `{MANOVA.RM}`

[Das R Paket `{MANOVA.RM}`](https://cran.r-project.org/web/packages/MANOVA.RM/vignettes/Introduction_to_MANOVA.RM.html)

@friedrich2019resampling

## `{car}`

## `{afex}`

## `{WRS2}`
:::

## Stuff {.unnumbered .unlisted}

https://www.datanovia.com/en/lessons/anova-in-r/#three-way-independent-anova

https://rpubs.com/JS24/853604

https://rpubs.com/krystian3000/853580

https://www.graphpad.com/guides/prism/latest/statistics/stat_what_is_three-way_anova_used_f.htm

## Der ANOVA Pfad {.unnumbered .unlisted}

Hier einmal eine Mairmaid Flowchart rein?

## Referenzen {.unnumbered}
