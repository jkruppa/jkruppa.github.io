```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, performance, parameters,
               latex2exp, see, patchwork, mfp, multcomp, emmeans, janitor, effectsize,
               broom, ggmosaic, tinytable, ggrepel, tidyplots, glue, ggtext, marginaleffects,
               mgcv, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- cb_pal
theme_marginal <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
set.seed(20250703)
modell_square_tbl <- tibble(x = rnorm(20, 5, 5),
                          y = 1.5 + 0.75 * -x^2 + rnorm(length(x), 0, 5))
modell_line_tbl <- tibble(x = rnorm(20, 2, 1),
                            y = 1.5 + 0.75 * x + rnorm(length(x), 0, 0.5))
set.seed(20250708)
enzyme_tbl <- tibble(x = rep(c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5), each = 10),
                     y = x^3 + -8*x^2 + 10*x + 10 + rnorm(length(x), 0, 10)) |> 
  group_by(x) |> 
  sample_n(size = sample(c(3:5), 1)) |> 
  ungroup() |> 
  mutate_if(is.numeric, round, 2)
enzyme_tbl |> 
  mutate(g1 = case_when(x < 2 ~ "niedrig",
                        x < 5 ~ "mittel",
                        x < 8 ~ "hoch")) |> 
  mutate(g2 = c(rep(c("Prokaryot", "Eukaryot"), times = c(8, 8)),
                rep(c("Prokaryot", "Eukaryot"), times = c(8, 7)),
                rep(c("Prokaryot", "Eukaryot"), times = c(5, 7)))) |> 
  set_names(c("ph", "activity", "grp", "type")) |> 
  writexl::write_xlsx("data/enzyme_kinetic.xlsx")
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-modeling-marginal.R")
```

# Marginal effect models {#sec-marginal}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-marginal.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Life is difficult." --- Morgan Scott Peck, The Road Less Traveled*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion (seit 07.2025)

Dieses Kapitel wird in den nächsten Wochen geschrieben und ist damit meine aktuelle Großbaustelle. Ich plane zum Beginn des WiSe 2025/26 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

Lange habe ich gebraucht um mich dazu durchzuringen das Kapitel zu den *Marginal effect models* (deu. *marginale Effektmodelle*, ungebräuchlich) zu schreiben. Ich werde hier bei dem englischen Begriff bleiben, den deutschen Begriff habe ich eher selten gehört und daher sind es für mich *Marginal effect models*. Insbesondere da der Begriff "marginal" auch sehr an gering oder minderwertig erinnert. Damit haben aber die *Marginal effect models* nicht im geringsten zu tun. Die Modelle sind sehr mächtig und können uns helfen wichtige Fragen an unsere Daten zu beantworten. Insbesondere die Dualität der beiden Pakete `{emmeans}` für experimentelle Daten und `{marginaleffects}` für beobachtete Daten ist spannend und möchte ich hier nochmal genauer betrachten. Neben diesen beiden Ecksteinen gibt es noch andere Pakete und ich werde auch hier einmal in die Pakete reinschauen. Anfangen kann ich aber nicht ohne @heiss2022 mit seinem Blogpost [Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/) zu erwähnen. Vieles entlehnt sich direkt oder indirekt an seine Ausführungen. Wie immer habe ich etwas angepasst, wenn ich der Meinung war, dass es noch besser zu verstehen ist. Fangen wir also an *Marginal effect models* zu zerforschen.

## Allgemeiner Hintergrund

> *"Statistics is all about lines, and lines have slopes, or derivatives. These slopes represent the marginal changes in an outcome. As you move an independent/explanatory variable, what happens to the dependent/outcome variable?" --- @heiss2022*

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Modellierung des nicht linearen Zusammenhangs zwischen der standardisierten Enzymeaktivität und dem standardisierten pH-Wert. Der pH-Wert ist kontinuierlich. **(A)** Berechnung der Steigung (eng. *slope*) für ausgewählte pH Werte anhand der Modellierung. **(B)** Berechnete Vorhersagewerte (eng. *prediction*) der standardisierten Enzymeaktivität für ausgewählte pH-Werte anhand der Modellierung. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-01

p1_intro_00_1 + p2_intro_00_2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

::: panel-tabset
## Interpretation Steigung

| pH  | Steigung (dy/dx) | Interpretation |
|-----|------------------|----------------|
| -1  | 29               |                |
| 2   | -10              |                |
| 6   | 22               |                |

: {#tbl-intro-inter-slope}

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
slopes(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

## Interpretation Vorhersage

| pH  | Vorhersage (y) | Interpretation |
|-----|----------------|----------------|
| -1  | -9             |                |
| 2   | 6              |                |
| 6   | -2             |                |

: test {#tbl-intro-inter-vorhersage}

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
predictions(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Modellierung des Zusammenhangs zwischen der standardisierten Enzymeaktivität und den gruppierten pH-Werten nach niedrigen, mittleren und hohen pH-Werten. Der pH-Wert ist kategorial. **(A)** Einfaktorielle Vorhersage der Gruppenmittelwerte der Enzymeaktivität. **(B)** Zweifaktorielle Vorhersage der Gruppenmittelwerte der Enzymeaktivität aufgetrennt nach der Gruppe der Eukaryoten und Prokaryoten. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-04

p3_intro_00_3 + p4_intro_00_4 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

::: panel-tabset
## Vorhersage 1-faktoriell

| pH      | Mittelwert | Interpretation |
|---------|------------|----------------|
| niedrig | 3.2        |                |
| mittel  | 2.59       |                |
| hoch    | -5.6       |                |

: test {#tbl-intro-inter-slope}

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")  |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch"))) 
enzyme_fit <-  lm(activity ~ grp, data = enzyme_tbl)
avg_predictions(enzyme_fit, by = c("grp"), vcov = "HAC")
```

## Vorhersage 2-faktoriell

| pH      | Gruppe    | Mittelwert | Interpretation |
|---------|-----------|------------|----------------|
| niedrig | Eukaryot  | 12.43      |                |
| niedrig | Prokaryot | -4.19      |                |
| mittel  | Eukaryot  | -4.73      |                |
| mittel  | Prokaryot | 9.91       |                |
| hoch    | Eukaryot  | -5.14      |                |
| hoch    | Prokaryot | -6.37      |                |

: test {#tbl-intro-inter-vorhersage}

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx") |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch"))) 
enzyme_fit <- lm(activity ~ grp * type, data = enzyme_tbl)
avg_predictions(enzyme_fit, by = c("grp", "type"), vcov = "HAC")
```
:::

## Theoretischer Hintergrund

> *"What he says?" --- Asterix Sieg über Caesar*

Wenn wir mit dem Verstehen und Zerforschen vorankommen wollen, dann können wir @heiss2022 und @heiss2024 mit der Veröffentlichung [Model to meaning --- How to Interpret Statistical Models With marginaleffects for R and Python](https://marginaleffects.com/) nicht ignorieren. Ich nutze jetzt eine etwas allgemeinere Erklärung der *Marginal effect models* und konzentriere mich erstmal auf ein normalverteiltes $x$ sowie ein normalverteiltes $y$. Daher haben wir hier in unserem $x$ keine Gruppen vorliegen sondern einen klassischen Scatterplot mit Punkten als Beobachtungen. Wir können die *Marginal effect models* auch auf beliebige kategorielle $x$ wie eben Behandlungsgruppen sowie jedes beliebige $y$ anwenden, aber hier fangen wir einmal einfach an.

Welche Frage wollen wir mit *Marginal effect models* beantworten?

:   Wenn sich das $x$ um einen Wert oder eine Einheit erhöht, um wieviele Einheiten verändert sich dann der Wert von $y$?

In der folgenden Abbildung siehst du einmal zwei Scatterplots. In dem linken Scatterplot haben wir einen linearen Zusammenhang zwischen unseren $x$-Werten und den $y$-Werten. Wir können sagen, dass wenn sich $x$ um einen Wert erhöht, dann erhöht sich auch $y$ um einen konstanten Wert. Dieser konstante Wert um den sich die $y$-Werte mit ansteigenden $x$ erhöhen, nennen wir auch die Steigung $\beta_1$. In einem linearen Zusammenhang ist die Frage damit mit der Steigung der Geraden eigentlich beantwortet. Steigt $x$ um einen Wert, dann steigt $y$ um den Wert der Steigung $\beta_1$ der Geraden. Diesen konstanten Zusammenhang haben wir aber nicht bei einem quadratischen Zusammenhang wie in der rechten Abbildung. Wir können hier nicht sagen, dass wenn sich $x$ um einen Wert erhöht, sich auch $y$ um einen konstanten Wert ändert. Hier hängt es von dem betrachteten $x$-Wert ab.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der kontinuierlichen x-Werte und kontinuierlichen y-Werte. In einem Modell wird die Abhängigkeit von y und x modellieren. **(A)** Linearer Zusammenhang. **(B)** Quadratischer Zusammenhang. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-05

p1_intro_00 + p2_intro_00 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Schauen wir mal in ein Zahlenbeispiel und lassen die Beobachtungen weg. Beginnen wir einmal mit dem linearen Zusammenhang der Funktion $f(x) = 2x-1$. Ich habe die Gerade einmal in der folgenden Abbildung eingezeichnet. Wenn usn jetzt die Steigung an jedem beliebigen Punkt von $x$ interessiert, dann bilden wir die erste Abbleitung $f'(x) = 2$. Erhöht sich also der Wert von $x$ um 1 dann steigt der Wert von $y$ um 2 an. Wir sehen aber auch, dass für jedes beliebige Punktepaar wir eine Steigung von 2 vorliegen haben.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Gerade des Modells für einen linearen Zusammenhang. In einem Modell wird die Abhängigkeit von y und x modellieren. **(A)** Lineares Modell mit Gleichung. **(B)** Steigung an der Geraden für ausgewählte Punktepaare. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-intro-06

p1_intro_01 + p2_intro_01 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Spanndender wird die Sachlage in einem quadratischen Zusammenhang in der folgenden Abbildung. Oder allgemeiner gesprochen, wenn wir keinen linearen Zusammenhang vorliegen haben. Wir haben hier den Zusammenhgang $f(x) = -0.5x^2+5x$ vorliegen. Damit haben wir dann eine erste Ableitung von $f'(x) = x+5$. Wie du siehst, ändert sich auch die Steigung in Abhänigkeit von $x$. Wenn wir $x$-Werte links betrachten, dann liegt hier eher eine positive Steigung vor. Wenn wir nach rechts laufen, dann sehen wir immer stärkere negative Steigungen. Und hier kommen dann die *Marginal effect models* ins Spiel. Wir können allgemein gesprochen uns mit den *Marginal effect models* für jedes $x$ die Steigung wiedergeben lassen.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Gerade des Modells für einen quadratischen Zusammenhang. In einem Modell wird die Abhängigkeit von y und x modellieren. **(A)** Quadratisches Modell mit Gleichung. **(B)** Steigung an der Geraden für ausgewählte Punktepaare. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-intro-07


p1_intro_02 + p2_intro_02 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Aber moment, denkst du jetzt, in dem linearen Zusammenhang ist es ja einfach mit der Steigung für jeden beliebigen $x$-Wert. Wir erhalten für jeden $x$-Wert genau die gleiche Steigung. Aber bei den nicht-linearen Zusammenhängen hat ja jeder $x$-Wert seine eigene Steigung. Wenn wir viele $x$-Werte gemessen haben, dann haben wir ja dutzende bis hunderte Steigungen durch ein *Marginal effect model* ermittelt. Das stimmt und damit kommen wir auch gleich zu dem nächsten Punkt, dem Aggregieren der Daten. Oder wie im folgenden Cartoon richtig dargestellt, müssen wir uns überlegen wie wir den den Durchschnitt der Steigungen berechnen.

!["Should I cut the red wire or the blue one!?" "WAIT! We're going to watch ALL the action movies from the '80s and '90s and then calculate the average!" Quelle: wumo.com](images/average.jpg){#fig-pretest-barplot-02 fig-align="center" width="100%"}

Wir haben uns in dem obigen Beispiel nur ein koninuierliches $x$ angeschaut. Jetzt kann es aber auch sein, dass deine $x$-Werte keine kontinuierlichen Messwerte wie das Gewicht oder die Zeit sind, sondern eben Gruppen. Also du hast verschiedene Düngestufen oder Behandlungsgruppen auf der $x$-Achse als Faktoren aufgetragen. Auch dann können wir eine lineare Regression rechnen, eine Linie durch die Punkte legen und anschließend ein *Marginal effect model* rechnen. Was ist also der Unterschied zwischen einem kontinuierlichen und einem kategoriellen $x$-Wert?

#### Unterschied zwischen kontinuierlichen und kategoriale $x$-Werte {.unnumbered .unlisted}

Wir kennen verschiedene Namen für das Gleiche. So nennen wir dann ein kontinuierliches $x$ dann auch gerne eine stetige Variable oder intervalskaliert. Nichts destotrotz, wir haben ein $x$ was in kleinen, marignalen Schritten anwachsen kann. Hier kannst du eben an das Gewicht der Flöhe oder aber Zeiteinheiten sowie das Einkommen denken. Wir verändert sich das $y$, wenn wir die $x$-Werte erhöhen?

Auf der anderen Seite haben wir dann kategoriale oder kategorielle $x$-Werte. Diese bezeichnen wir dann auch gerne diskret oder aber als Faktoren in R. Wenn wir die Werte von $x$ ändern, dann springen wir in eine neue Gruppe und es liegt hier eigentlich kein kleiner Schritt vor. Hier haben wir dann eben Düngestufen oder aber Behandlungsgruppen vorliegen. Hier fragen wir uns, wie ändert sich der Wert von $y$, wenn wir eine Gruppe in $x$ weiterspringen?

In der folgenden Abbildung von @heiss2022 siehst du nochmal schön den Unterschied dargestellt. Wir haben beider einer kategorialen Variable einen Schalter. Entweder ist der Schalter an oder eben aus. Im simpelsten Fall haben wir männliche oder eben weibliche Flöhe vorliegen. Das Geschlecht ist somit kategorial. Die Sprungweite oder das Gewicht von Flöhen ist eine kontinuierliche Variable. Wir haben einen Schieberegeler den wir ziemlich fein einstellen können.

![Unterschied zwischen einer kategorialen Variable und einer kontinuierlichen Variable in einem statistischen Modell visualisiert als Schalter und Schieberegler. Übersetzt nach @heiss2022](images/marginal/slider-switch-annotated-trans.png){#fig-utest-intro-01 fig-align="center" width="100%"}

Als wäre das nicht kompliziert genug, schauen wir uns meistens dann nicht nur eine $x$ Variable in einem Modell an, die wir dann ändern, sondern eben mehrere. Dann kombinieren wir noch gerne kontinuierliche und kategoriale $x$-Werte in einem Modell miteinander und erhalten ein Mischboard. Wir können einiges an Schiebereglern und Schaltern in einem Modell betätigen und erhalten entsprechende andere $y$-Werte. Hier helfen dann auch *Marginal effect models* um mehr Erkenntnisse aus einem Modell zu erhalten.

![Kombination verschiedener kategorialer Variablen und kontinuierlichen Variablen in einem statistischen Modell visualisiert als Mischboard. Übersetzt nach @heiss2022](images/marginal/mixer-board-annotated-trans.png){#fig-utest-intro-02 fig-align="center" width="100%"}

Somit kommen wir dann hier mal zu einer Definition, wie wir dann die beiden Arten der möglichen $x$-Werte als kontinuierliche und kategoriale Werte sprachlich unterscheiden. Wir immer, je nach wissenschaftlichen Hintergrund können sich dann die Namen ändern und anders sein. Das ist dann eben so in der Statistik.

Marginal effect (deu. *marginaler Effekt*)

:   Ein marginaler Effekt beschreibt den statistischen Effekt für kontinuierliche erklärende Variablen; die partielle Ableitung einer Variablen in einem Regressionsmodell; der Effekt eines einzelnen Schiebereglers.

Conditional effect (deu. *bedingter Effekt*) oder Gruppenkontrast (eng. *group contrast*)

:   Ein bedingter Effekt beschreibt den statistischen Effekt für kategoriale erklärende Variablen; der Unterschied in den Mittelwerten, wenn eine Bedingung eingeschaltet ist und wenn sie ausgeschaltet ist; der Effekt eines einzelnen Schalters.

#### Unterschied zwischen `{marginaleffects}` und `{emmeans}` {.unnumbered .unlisted}

Wenn wir *Marginal effect models* rechnen wollen, dann können wir im Prinzip auf zwei große Pakete zurückgreifen. Einmal das [R Paket `{marginaleffects}`](https://marginaleffects.com/) sowie das [R Paket `{emmeans}`](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents). Das [R Paket `{modelbased}`](https://easystats.github.io/modelbased/index.html) setzt sich im Prinzip auf die beiden Pakete drauf und ist mehr oder minder ein Wrapper mit anderen Funktionsnamen. Das ist eigentlich eine gute Idee und ich zeige dann auch nochmal, wie sich das R Paket `{modelbased}` verhält. Kommen wir erstmal zu dem hauptsächlichen Unterschied zwischen unseren beiden Elefanten.

Wie unterscheiden sich `{emmeans}` und `{marginaleffects}`?

:   Das R Paket `{emmeans}` erstellt Durchschnittswerte der Daten und fügt diese Durchschnittswerte dann in Modelle ein. Das R Paket `{marginaleffects}` fügt alle Werte der Daten in ein Modell ein und erstellt dann Durchschnittswerte aus der Ausgabe des Modells. Am Ende ist es vermutlich dann auch wieder ein nur kleiner Unterschied, der was ausmachen kann. Aber da kommt es dann auf die wissenschaftliche Fragestellung an.

Dabei gibt es noch einen weiteren bedeutenden Unterschied zwischen den beiden Paketen, die sich dann direkt aus der Aggregierung der Daten ableitet. Die Frage ist ja, erst den Mittelwert bilden und dann Modellieren oder umgekehrt. Das R Paket `{emmeans}` hat als philosophischen Hintergrund experimentelle Daten als Basis. Das R Paket `{marginaleffects}` hingegen nimmt beobachtete Daten an. Hier möchte ich dann einmal die Vingette des R Pakets `{emmeans}` zitieren.

> *"To start off with, we should emphasize that the underpinnings of estimated marginal means – and much of what the `{emmeans}` package offers – relate more to experimental data than to observational data. In observational data, we sample from some population, and the goal of statistical analysis is to characterize that population in some way. In contrast, with experimental data, the experimenter controls the environment under which test runs are conducted, and in which responses are observed and recorded. Thus with experimentation, the population is an abstract entity consisting of potential outcomes of test runs made under conditions we enforce, rather than a physical entity that we observe without changing it." --- [R Paket `{emmeans}`](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents)*

Was will uns nun dieser Text sagen und was bedeutet der Unterschied zwischen experimentellen und beobachteten Daten?

-   Wir nutzen `{emmeans}`, wenn wir Gruppenvergleiche aus einem experimentellen, faktoriellen Design rechnen wollen. Solche faktorielle Designs sind in den Agrarwissenschaften sehr häufig.
-   Wir nutzen `{marginaleffects}`, wenn wir beobachtete Daten vorliegen haben. Dies ist sehr häufig bei zeitlichen Verläufen der Fall. Wenn wir also wissen wollen, wie ändert sich den Messwert über die Zeit?

### Kontrafaktische Vergleiche (eng. *counterfactual*)

### Hypothesen- und Äquivalenztests

## Theoretischer Hintergrund

::: callout-tip
## Weitere Tutorien für die Marginal effects models

Wir oben schon erwähnt, kann dieses Kapitel nicht alle Themen der Marginal effects models abarbeiten. Daher präsentiere ich hier eine Liste von Literatur und Links, die mich für dieses Kapitel hier inspiriert haben. Nicht alles habe ich genutzt, aber vielleicht ist für dich was dabei.

-   Ohne den Blogpost [Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/) von @heiss2022 wäre dieses Kapitel nicht möglich gewesen.
-   Wie alles im Leben ist nichts ohne Kritik. [Is least squares means (lsmeans) statistical nonsense?](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents:~:text=found%20here%20and-,here,-.) ist dann auch eine gute Frage. Ich bin der Meinung nein und auch andere sind es, aber hier kannst du dann nochmal eine andere Meinung lesen.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, gtsummary, marginaleffects, emmeans, scales,
               janitor, conflicted)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
## 
nice_number <- label_number(style_negative = "minus", accuracy = 0.01)
nice_p <- label_pvalue(prefix = c("p < ", "p = ", "p > "))
find_intercept <- function(x1, y1, slope) {
  intercept <- slope * (-x1) + y1
  return(intercept)
}
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

#### Modellierung von Enzymen {.unnumbered .unlisted}

```{r}
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx") |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch")))  
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-margin-table-01
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

enzyme_raw_tbl <- read_excel("data/enzyme_kinetic.xlsx") 

rbind(head(enzyme_raw_tbl, n = 3),
      rep("...", times = ncol(enzyme_raw_tbl)),
      tail(enzyme_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-margin-table-02
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

enzyme_raw_tbl |> 
  tabyl(ph) |> 
  mutate(percent = scales::percent(percent)) |> 
  kable(align = "c", "pipe")
```

$$
y = x^3 - 8x^2 + 10x + 10
$$

Funktion der Steigung als erste Ableitung nach

$$
y' = 3x^2 - 16x + 10
$$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Scatterplot der *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-enzyme-01

p1_model_enzyme_01
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** gg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-enzyme-02

p1_model_enzyme_02 + p2_model_enzyme_02 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Modellierung von Flöhen {.unnumbered .unlisted}

```{r}
flea_model_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(feeding = as_factor(feeding),
         stage = as_factor(stage),
         bonitur = as.numeric(bonitur),
         infected = factor(infected, labels = c("healthy", "infected"))) |> 
  select(feeding, stage, jump_length, weight, hatched, count_leg,  bonitur, infected)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac1cov-table
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

flea_model_raw_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(bonitur = as.numeric(bonitur),
         infected = as.character(factor(infected, labels = c("healthy", "infected")))) |> 
  select(feeding, stage, jump_length, weight, count_leg, hatched, bonitur, infected) |> 
  mutate_if(is.numeric, round, 2)

rbind(head(flea_model_raw_tbl, n = 3),
      rep("...", times = ncol(flea_model_raw_tbl)),
      tail(flea_model_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10.5
#| fig-cap: "foo. **(A)** Kombinierte Darstellung in einem Scatterplot **(B)** Aufgeteilte Darstellung für beide Entwicklungsstadien. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-1

p1_model_flea + p2_model_flea + p3_model_flea +
  plot_layout(ncol = 3, widths = c(1.25, 1.25, 2.5)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-infected-model-fleas
#| tbl-cap: "Deskriptive Statistik des Infektionsstatus (0 = nein / 1 = ja) mit Flohschnupfen aufgeteilt nach den Faktoren und anderen Variablen."

flea_model_tbl |>
  select(infected, feeding, stage) |> 
  tbl_summary(
    by = infected,
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"
    ),
    digits = all_continuous() ~ 2,
    #label = count_color ~ "Anzahl Farben",
    missing_text = "(Missing)"
  )
```

## Datenraster

Das Datenraster (eng. *data grid*)

```{r}
set.seed(48103)
N = 10
dat = data.frame(
  Num = rnorm(N),
  Bin = rbinom(N, size = 1, prob = 0.5),
  Cat = sample(c("A", "B", "C"), size = N, replace = TRUE)
)
```

### Beobachtetes Raster (eng. *empirical grid*)

```{r}
dat |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-01

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5), limits = c(-2, 8)) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5),
             color = "#D55E00", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Beobachtetes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

### Interessantes Raster (eng. *interesting grid*)

```{r}
datagrid(Bin = c(0, 1), newdata = dat) |> tt()
```

```{r}
datagrid(Num = range, Bin = mean, Cat = unique, newdata = dat) |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-02

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 1, 2, 3.5, 5.5, 7), limits = c(-2, 8)) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = c(0, 1, 2, 3.5, 5.5, 7),
             color = "#0072B2", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Interessantes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

### Repräsentatives Raster (eng. *representative grid*)

```{r}
datagrid(grid_type = "mean_or_mode", newdata = dat) |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-03

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10
mean_rep_grid <- mean(c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5))

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = mean_rep_grid, limits = c(-2, 8),
                     label = expression(bar(y)[pH])) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = mean_rep_grid,
             color = "#CC79A7", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Interessantes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

### Balanciertes Raster (eng. *balanced grid*)

```{r}
datagrid(grid_type = "balanced", newdata = dat) |> tt()
```

### Kontrafaktisches Raster (eng. *counterfactual grid*)

```{r}
g = datagrid(
  Bin = c(0, 1),
  grid_type = "counterfactual",
  newdata = dat
)
nrow(g)
```

```{r}
subset(g, rowidcf %in% 1:3) |> tt()
```

## Marginal effects

### Steigung (eng. *slopes*)

::: panel-tabset
## `gam()`

```{r}
#| message: false
#| echo: false
#| warning: false

gam_fit <- gam(activity ~ s(ph), data = enzyme_tbl)
slopes(gam_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: " **(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-02

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell") +
  p1_slope_01  +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## `poly()`

```{r}
#| message: false
#| echo: false
#| warning: false

poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
slopes(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: " **(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-01

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell") +
  p1_slope_00  +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## `loess()`

```{r}
#| message: false
#| echo: false
#| warning: false
loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
slopes(loess_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: " **(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-03

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell") +
  p1_slope_02  +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

### Vorhersagen (eng. *predictions*)

```{r}
#| message: false
#| warning: false

loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
```

```{r}
predictions(loess_fit)
```

```{r}
predictions(loess_fit, by = "ph")
```

#### Kontinuierliche $x$-Werte {.unnumbered .unlisted}

::: panel-tabset
## `gam()`

```{r}
#| message: false
#| warning: false
gam_fit <- gam(activity ~ s(ph), data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false
gam_pred <- predictions(gam_fit, newdata = datagrid(ph = c(-1, 2, 6)))
gam_pred
```

## `poly()`

```{r}
#| message: false
#| warning: false
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
```

```{r}
poly_pred <- predictions(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
poly_pred
```

## `loess()`

```{r}
#| message: false
#| warning: false
loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
```

```{r}
loess_pred <- predictions(loess_fit, newdata = datagrid(ph = c(-1, 2, 6)))
loess_pred
```
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-01

p2_intro_00_2 + 
  labs(title = "Theoretisches Modell") +
  p1_predict_00 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Kategoriale $x$-Werte {.unnumbered .unlisted}

::: callout-warning
## Achtung, bitte beachten!

Ich persönlich finde die Implementierung des multiplen Testens in `{emmeans}` um Längen besser gelöst. Den Rest von `{marginaleffects}` dann eher nicht so. Daher würde ich dir hier davon abraten, deine Gruppenvergleiche mit `predictions()` zu rechnen. Es ist gut zu verstehen was die Funktion macht, aber `{emmeans}` hat den klaren Vorteil, dass wir das *Compact letter disply* berechnen können. Darüber hinaus finde ich die zweifaktorielle Analyse besser gelöst durch die beiden Zeichen Stern `*` und Strich `|` besser gelöst. In `{marginaleffects}` haben wir dann die Problematik mit den Hypothesen und Gruppennamen innerhalb der Ausgabe der Funktion `hypotheses()`. Hier nochmal die Alternativen in `{emmeans}`, die ich hier aber dann nicht ausführen lasse. Bitte schaue dann nochmal in das [Kapitel zu den Post-hoc Tests](#sec-posthoc) vorbei.

```{r}
#| eval: false
enzyme_1fac_fit |> 
  emmeans(~ grp, vcov = sandwich::vcovHAC) |> 
  contrast(method = "pairwise", adjust = "bonferroni")
```

```{r}
#| eval: false
enzyme_2fac_fit |> 
  emmeans(~ grp | type, vcov = sandwich::vcovHAC) |> 
  contrast(method = "pairwise", adjust = "bonferroni")
```
:::

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Manchmal schaue ich mir sehr lange Funktionen oder Pakete wie hier `{marginaleffects}` an und muss dann feststellen, dass für eien spezielle Orichideenanwendung dann doch ein anderes Paket besser ist. Ist nicht schlimm, dann musst du dir nicht die Arbeit machen. Für das faktorielle Experiment würde ich dann immer `{emmeans}` nehmen." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

Die Funktion `hypotheses()` ist mächtig.

::: panel-tabset
## Vorhersage 1-faktoriell

```{r}
enzyme_1fac_fit <-  lm(activity ~ grp, data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC")
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC",
            hypothesis = ~pairwise)  |> 
  hypotheses(multcomp = "bonferroni")
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC",
            hypothesis = ~pairwise) 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-02

plot_predictions(enzyme_1fac_fit, by = c("grp")) +
  theme_minimal()
```

## Vorhersage 2-faktoriell

```{r}
enzyme_2fac_fit <- lm(activity ~ grp * type, data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false

predictions(enzyme_2fac_fit, by = c("grp", "type"), vcov = "HAC",
            hypothesis = ~pairwise | type, 
            newdata = "balanced") 
```

```{r}
#| message: false
#| warning: false

predictions(enzyme_2fac_fit, by = c("grp", "type"), vcov = "HAC",
            newdata = "balanced") |> 
  hypotheses(~pairwise | type, multcomp = "bonferroni")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-03

plot_predictions(enzyme_2fac_fit, by = c("grp", "type"))
```
:::

## Referenzen {.unnumbered}
