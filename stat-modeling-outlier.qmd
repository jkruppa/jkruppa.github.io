```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Ausreißer {#sec-outlier}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

## Theoretischer Hintergrund

Was sind Ausreißer (eng. *Outlier*) in einem Datensatz? An scih schon eine schwierige Frage. Einige Wissenschaftler behaupten es gebe keine Ausreißer. Die Daten müssetn so ausgewertet werden wie die Daten erhoben wurden. Was es gäbe wären technische Artefakte, diese müssten entdeckt und entfernt werden. Andere Wissenschaftler meinen, dass Ausreißer schon existieren und entferent werden müssen, wenn diese Ausreißer nicht zu der Fragestellung oder den restlichen Daten passen. Es ist eine unbekannte Subpopulation, die sich mit einem oder zwei Vertretern in unsere Daten geschmugelt hat. Diese Subpopulation verzerrt nur das Ergebnis, da wir mit diesen wenigen anderen Beobachtungen sowieso keine Aussage treffen können. Am Ende geht es aber draum Ausreißer zu finden und diese aus den Daten zu entfernen. Wir setzen dann diese Werte der Ausreißer auf `NA` für fehlender Wert (eng. *not available*). Oder aber wir erstetzen die Ausreißer durch pasendere Werte aus unseren Daten. Im Prinzip ein wenig wie finde den Ausreißer und imputiere den Ausreißer mit einer anderen Zahl. Mehr zur Imputation von fehlenden Werten findest du in @sec-missing. Vermeide bitte eine Ausreißer/Imputationsschleife in der du immer wieder Ausreißer findest und diese dann wieder imputierst! Gerade dieses Thema Ausreißer kann sehr gut von biologischen Fachexperten diskutiert werden.

In den folgenden Abschnitten wollen wir uns verschiedene Möglichkeiten der Detektion von Ausreißern annähern. Es geht wie immer von algorithmisch einfach zu komplexer.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Bitte beiße dich nicht an der *statistischen* Auslegung eines Ausreißers fest. Du bist der Herr oder die Frau über deine Daten. Kein Algorithmus weis mehr als du. Das macht statistischen Engel natürlich traurig...
:::

Bitte beachte, dass wenn du weist, dass ein Wert nicht richtig ist, diesen dann auch entfernt. Wenn du während der Beprobung feststellst, dass du leider auf dem Feld zu wenig Erde mitgenommen hast, dann trage ein `NA` in die Tabelle ein. Unsinnige Werte einzutragen nur weil die ja so entstanden sind, macht keinen Sinn. Auch kann es sein, dass du dich mal vertippst. Das heist, du hast in die Exceltabelle eine 0 oder ein Komma falsch gesetzt. Das findest du jetzt in der explorativen Datenanalyse raus. Dann bitte korrigiere diese Werte und mache bitte nicht hier mit der Detektion von Ausreißern weiter. Wenn du selber weist, warum da so ein komischer Wert in der Tabelle steht, dann korrigiere den Wert und schreibe in deinen Bericht, was du getan hast.

::: callout-caution
## Sensitivitätsanalysen nach der Entfernung von Ausreißer

Nachdem wir Beobachtungen aus unseren Daten entfernt haben, ist es üblich noch eine Sensitivitätsanalysen durchzuführen. Wir Vergleich dann das *gereinigte* Modell mit *anderen* Modellen. Oder wir wollen die Frage beantworten, was hat eigentlich mein Entfernen von Ausreßern am Ergebnis geändert? Habe ich eine wichtige Beobachtung rausgeschmissen? Das machen wir dann gesammelt in dem @sec-sensitivity zu den Sensitivitätsanalysen.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, dlookr, conflicted, broom,
               see, performance, ggpubr)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Nachdem wir uns im vorherigen Kapitel mit einem sehr kleinen Satensatz beschäftigt haben, nehmen wir einen großen Datensatz. Bleiben aber bei einem simplen Modell. Wir brauchen dafür den Datensatz `flea_dog_cat_length_weight.xlsx`. In einer simplen linearen Regression schauen wir uns den Zusammenhang zwischen einem $y$ und einem $x_1$ an. Daher wählen wir aus dem Datensatz die beiden Spalten `jump_length` und `weight`. Wir wollen nun feststellen, ob es einen Zusammenhang zwischen der Sprungweite in \[cm\] und dem Flohgewicht in \[mg\] gibt. In dem Datensatz finden wir 400 Flöhe von Hunden und Katzen.

```{r}
#| message: false

flea_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") %>%
  select(animal, jump_length, weight)
```

In der @tbl-model-1 ist der Datensatz `model_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz mit einer normalverteilten Variable `jump_length` und der normalverteilten Variable `weight`. Wir betrachten die ersten sieben Zeilen des Datensatzes.
#| label: tbl-model-1

flea_tbl %>% head(7) %>% kable(align = "c", "pipe")
```

Im Folgenden *ignorieren* wir, dass die Sprungweiten und die Gewichte der Flöhe auch noch von den Hunden oder Katzen sowie dem unterschiedlichen Geschlecht der Flöhe abhängen könnten. Wir schmeißen alles in einen Pott und schauen nur auf den Zusammenhang von Sprungweite und Gewicht.

```{r}
#| message: false
#| warning: false
longnose_tbl <- read_csv2("data/longnose.csv") 
```

```{r}
#| message: false

gummi_tbl <- read_excel("data/gummibears.xlsx")  %>%
  select(gender, age, height, semester, most_liked) %>% 
  mutate(gender = as_factor(gender),
         most_liked = as_factor(most_liked)) %>% 
  na.omit()
```

## Ausreißer mit Cook\`s Abstand

::: column-margin
Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/influence_measures.html) erlaubt eine weitreichende Diagnostik auf Ausreißer für einem normalverteilten Outcome $y$.
:::

Die Cook'sche Distanz hat im Wesentlichen eine Aufgabe. Die Cook'sche Distanz misst, wie stark sich alle angepassten Werte im Modell ändern, wenn der i-te Datenpunkt gelöscht wird.

```{r}
#| message: false
#| echo: false
#| label: tbl-tables
#| tbl-cap: "Tables"
#| tbl-subcap:
#|   - "Cars"
#|   - "Pressure"
#| layout-ncol: 2

no_out_tbl <- tibble(weight = c(1, 2, 2, 3, 4, 5, 7, 3, 4, 5),
                     jump_length = c(22, 23, 24, 23, 19, 34, 35, 36, 23, 22))

out_tbl <- tibble(weight = c(1, 2, 2, 3, 4, 5, 7, 4, 5, 8),
                  jump_length = c(190, 23, 24, 23, 19, 24, 25, 26, 28, 180))

no_out_tbl %>% kable(align = "c", "pipe")
out_tbl %>% kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| label: fig-cooks-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Histogramm der nicht transfomierten und transformierten Daten."
#| fig-subcap: 
#|   - "Nicht transformierte, rohe Daten"
#|   - "$log$-transformierte Daten."
#| layout-nrow: 1
#| column: page

#create scatterplot for data frame with no outliers
ggplot(data = no_out_tbl, aes(x = weight, y = jump_length)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(0, 200) +
  theme_bw()

#create scatterplot for data frame with outliers
ggplot(data = out_tbl, aes(x = weight, y = jump_length)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(0, 200) +
  theme_bw()

```

```{r}
fit_2 <- lm(jump_length ~ weight, data = out_tbl)
```

```{r}
plot_tbl <- fit_2 %>% 
  augment %>% 
  select(weight, .cooksd)
```

```{r}
cooks_border <- 4/nrow(plot_tbl)
cooks_border
```

```{r}
#| echo: true
#| message: false
#| label: fig-cook-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "."

ggplot(plot_tbl, aes(weight, .cooksd)) +
  geom_point() +
  geom_hline(yintercept = cooks_border, color = "red") +
  theme_bw()
```

```{r}
#| message: false
remove_weight_id <- which(plot_tbl$.cooksd > cooks_border)
out_tbl <- out_tbl[-remove_weight_id,]

out_tbl
```

## Ausreißer mit `performance`

::: column-margin
Das R Paket \``performance` hat die Möglichkeit zur [Outliers detection (check for influential observations)](https://easystats.github.io/performance/reference/check_outliers.html).
:::

```{r}
check_outliers(flea_tbl)
```

```{r}
check_outliers(longnose_tbl)
```

```{r}
check_outliers(gummi_tbl)
```

## Ausreißer mit `dlookr`

::: column-margin
Das [R Paket `dlookr`](https://choonghyunryu.github.io/dlookr/articles/transformation.html#imputation-of-outliers) hat eine große Auswahl an simplen Algorithmen für die Anpassung von Ausreißern.
:::

```{r}
diagnose_outlier(longnose_tbl) %>% 
  filter(outliers_cnt > 0) %>% 
  arrange(desc(outliers_cnt))
```

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-miss-dlookr-plot-out
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Densityplot der Verteilungen vor und nach der Imputation."
#| fig-subcap: 
#|   - "Imputation mit dem Mittelwert."
#|   - "Imputation mit dem Median."
#| layout-nrow: 1
#| column: page

longnose_tbl %>% plot_outlier(longnose)
longnose_tbl %>% plot_outlier(area)
```

```{r}
longnose_imp_tbl <- longnose_tbl %>% 
  mutate(longnose_capping = imputate_outlier(., longnose, method = "capping"),
         longnose_median = imputate_outlier(., longnose, method = "median"))

```

predictor is numerical variable

"mean" : arithmetic mean

"median" : median

"mode" : mode

"capping" : Impute the upper outliers with 95 percentile, and Impute the lower outliers with 5 percentile.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-miss-dlookr-plot-out-imp
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Densityplot der Verteilungen vor und nach der Imputation."
#| fig-subcap: 
#|   - "Imputation mit dem Mittelwert."
#|   - "Imputation mit dem Median."
#| layout-nrow: 1
#| column: page

pluck(longnose_imp_tbl, "longnose_capping") %>% 
  plot

pluck(longnose_imp_tbl, "longnose_median") %>% 
  plot
```

## Hauptkomponentenanalyse

Damit wir uns auch eine Verteilung anschauen können bruachen wir *viele* Beobachtungen. Wir haben das ja schon bei den Histogrammen gesehen, wenn wir ein aussagekräftiges Histogramm erstellen wollen, dann brauchen wir viele Beobachtungen. Daher nehmen wir für dieses Kapitel einmal den Gummibärchendatensatz und schauen uns dort die Variablen `gender`, `height`, `count_bears` und `count_color` einmal genauer an. Wie immer nutzen wir die Funktion `select()` um die Spalten zu selektieren. Abschließend verwandeln wir das Geschlecht `gender` und das `module` noch in einen Faktor.

http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/122-multidimensional-scaling-essentials-algorithms-and-r-code/

```{r}

# Cmpute MDS
mds <- gummi_tbl %>%
  dist() %>%          
  cmdscale() %>%
  as_tibble()
colnames(mds) <- c("Dim.1", "Dim.2")
# Plot MDS
ggscatter(mds, x = "Dim.1", y = "Dim.2", 
          label = rownames(gummi_tbl),
          size = 1,
          repel = TRUE)


# K-means clustering
clust <- kmeans(mds, 5)$cluster %>%
  as.factor()
mds <- mds %>%
  mutate(groups = clust)
# Plot and color by groups
ggscatter(mds, x = "Dim.1", y = "Dim.2", 
          label = rownames(gummi_tbl),
          color = "groups",
          palette = "jco",
          size = 1, 
          ellipse = TRUE,
          ellipse.type = "convex",
          repel = TRUE)

```

```{r}




pacman::p_load(factoextra, FactoMineR)

longnose_pca_df <- longnose_tbl %>%
  select(-stream) %>% 
  as.data.frame()

row.names(longnose_pca_df) <- longnose_tbl$stream

res.pca <- PCA(longnose_pca_df,  graph = FALSE)

fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))


fviz_pca_var(res.pca, col.var = "black")


fviz_pca_ind(res.pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

https://www.datacamp.com/tutorial/pca-analysis-r

Look at library(factoextra)

http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization

http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-princomp/
