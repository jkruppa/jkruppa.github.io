```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Variablenselektion {#sec-variable-selection}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

## Theoretischer Hintergrund

Die Selektion von Variablen in einem Modell. Ein schwieriges Thema. Entweder kenne ich mein Experiment und habe das Experiment so geplant, dass nur die bedeutenden Variablen mit in dem Experiment sind oder ich habe keine Ahnung. Gut, dass ist überspitzt und gemein formuliert. Wir wollen uns in diesem Kapitel den Fall anschauen, dass du sehr viele Variablen $x$ erhoben hast und nun *statistisch* bestimmen willst, welche Variablen nun mit in das finale Modell sollen. Achtung, ich spreche hier nicht von einem Blockdesign oder aber einem Feldexperiment. Da hat die Variablenselektion nichts zu suchen. Daher tritt der Fall der Variablenselektion eher in dem Feld Verhaltensbiologie oder aber auch Ökologie auf. Ebenfalls kann die Anwendung in automatisch erfassten Daten einen Sinn machen. Wir nutzen dann die Variablenselektion (eng. *feature selection*) zu Dimensionsreduktion des Datensatzes. Der Datensatz soll damit einfacher sein... ob der Datensatz das damit auch wird, ist wieder eine andere Frage.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

In diesem Kapitel prügeln wir aber einen statistischen Engel. Wir werden hier mal schauen müssen, was alles geht und was nicht. Variablen Selektion ist faktisch nicht *ein* Kapitel sondern ein Regal(kilo)meter voll mit Büchern.
:::

Zu der Frage welches Verfahren denn nun das richtige Verfahren zur Selektion von Variablen ist, gibt es die Standardantwort in der Statistik: *Es kommt auf die Fragestellung an...*. Oder aber was ist wie gut implementiert, dass wir das Verfahren einigermaßen gut nutzen können. Wir gehen daher von einfach zu kompliziert und du musst dann schauen, was du nutzen willst und kannst. Wir müssen zum Beispiel unterscheiden, welcher Verteilung das Outcome $y$ folgt. Wenn wir ein normalverteiltes $y$ haben, dann haben wir andere Möglichkeiten, als wenn wir uns ein poissonverteiltes oder binominalverteiltes $y$ anschauen.

::: column-margin
Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/variable_selection.html) erlaubt eine weitreichende Variablen Selektion, wenn ein normalverteiltes Outcome $y$ vorliegt.
:::

Im Folgenden will ich *kurz* die fünf Mythen der Variablenselektion von @heinze2017five zusammenfassen. Wie immer ersetzt meine deutsche Zusammenfassung nicht das eigenständige Lesen der *englischen* Orgnialquelle, wenn du die Informationen in deiner Bachelorarbeit zitieren willst.

1)  Die Anzahl der Variablen in einem Modell sollte reduziert werden, bis es 10 Ereignisse pro Variable gibt.
2)  Nur Variablen mit nachgewiesener Signifikanz des univariaten Modells sollten in ein Modell aufgenommen werden.
3)  Nicht signifikante Effekte sollten aus einem Modell entfernt werden.
4)  Der berichtete P-Wert quantifiziert den Typ-I-Fehler einer fälschlich ausgewählten Variablen.
5)  Variablenauswahl vereinfacht die Analyse.

"Variable selection should always be accompanied by sensitivity analyses to avoid wrong conclusions."

Im Weiteren sei auch noch auf @heinze2018variable und @talbot2019descriptive verwiesen. Beide Veröffentlichungen liefern nochmal einen fundierten Block auf die Variablenselektion. Wiederum ist das natürlich nur ein winziger Ausschnitt aus der Literatur zur Variablenselektion. Im Zweifel einfach einmal bei [Google Scholar](https://scholar.google.com/scholar?hl=de&as_sdt=0%2C5&q=variable+selection+review&btnG=) nach Variablenselektion suchen.

::: callout-caution
## Sensitivitätsanalysen nach der Imputation von fehlenden Werten

Nachdem wir neue Daten bzw. Beobachtungen in unseren Daten erschaffen haben, ist es üblich noch eine Sensitivitätsanalysen durchzuführen. Wir Vergleich dann die Imputation mit der *complete-case* Analyse. Oder wir wollen die Frage beantworten, was hat eigentlich meine Imputation am Ergebnis geändert? Das machen wir dann gesammelt in dem @sec-sensitivity zu den Sensitivitätsanalysen.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, 
               MASS, ranger, Boruta, broom,
               scales, olsrr)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-chickpea-var
#| tbl-cap: Auszug aus dem Daten zu den Kichererbsen in Brandenburg.
#| column: page


chickpea_tbl <- read_excel("data/chickpeas.xlsx") 

rbind(head(chickpea_tbl, 3),
      rep("...", times = ncol(chickpea_tbl)),
      tail(chickpea_tbl, 3)) %>% 
  kable(align = "c", "pipe")

```

$$
3 * sand + 2 * temp + 1.5 * rained - 1.2 * forest + 1.1 * no3  
$$

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-pigs-var
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.
#| column: page

pig_tbl <- read_excel("data/infected_pigs.xlsx") 

rbind(head(pig_tbl, 3),
      rep("...", times = ncol(pig_tbl)),
      tail(pig_tbl, 3)) %>% 
  kable(align = "c", "pipe")
```

$$
2 * crp + 0.5 * sex + 0.5 * frailty + 0.2 * bloodpressure + 0.05 * creatinin +  0.01 * weight
$$

## Methoden der Variablenselektion

### Per Hand

"Oft gibt es keinen wissenschaftlichen Grund, eine Variablenauswahl durchzuführen. Insbesondere erfordern Methoden der Variablenselektion einen viel größeren Stichprobenumfang als die Schätzung eines multiplen Modells mit einem festen Satz von Prädiktoren auf der Grundlage klinischer Erfahrung."

### Univariate Vorselektion

```{r}

chickpea_tbl %>%
  select(-dryweight) %>%                   
  map(~glm(dryweight ~ .x, data = chickpea_tbl, family = gaussian)) %>%    
  map(tidy) %>%                          
  map(filter, term != "(Intercept)") %>%       
  map(select, -term, -std.error, -statistic) %>%                        
  bind_rows(.id="term") %>% 
  arrange(p.value) %>% 
  mutate(p.value = pvalue(p.value),
         estimate = round(estimate, 2))

```

```{r}

pig_tbl %>%
  select(-infected) %>%                   
  map(~glm(infected ~ .x, data = pig_tbl, family = binomial)) %>%    
  map(tidy) %>%                          
  map(filter, term != "(Intercept)") %>%       
  map(select, -term, -std.error, -statistic) %>%                        
  bind_rows(.id="term") %>% 
  arrange(p.value) %>% 
  mutate(p.value = pvalue(p.value),
         estimate = round(estimate, 2))

```

### Sonderfall Gaussian linear Regression

[Variable Selection Methods](https://olsrr.rsquaredacademy.com/articles/variable_selection.html)

```{r}
chickenpea_fit <- lm(dryweight ~ temp + rained + location + no3 + fe + sand + forest, 
                   data = chickpea_tbl)
```

```{r}
ols_step_all_possible(chickenpea_fit) %>%
  as_tibble %>%
  arrange(desc(adjr)) %>%
  filter(n <= 4) %>% 
  select(predictors, adjr, aic) 

```

### `step` und `setpAIC`

```{r}
#| echo: true
#| message: false
#| eval: true
#| warning: false

fit <- glm(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin, 
           data = pig_tbl, family = binomial)

fit_step <- stepAIC(fit, direction = "both")
```

Test

```{r}
fit_step 
```

Test

### `ranger`

@sec-class-rf

```{r}
#| echo: true
#| message: false
#| warning: false

fit <- ranger(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin, 
              data = pig_tbl, importance = "permutation")

pluck(fit, "variable.importance") %>% sort(decreasing = TRUE)
```

### `boruta`

```{r}
boruta_output <- Boruta(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin,  
                        data = pig_tbl)  

boruta_output
```

```{r}
#| echo: true
#| message: false
#| label: fig-log-pred
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Visualisierung der logistischen Gerade in einer simplen logistischen Regression mit der Variable `crp`."

plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  

```

```{r}
tent_boruta <- TentativeRoughFix(boruta_output)

tent_boruta
```

## Skalieren der Daten?

## Referenzen {.unnumbered}
