```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Maßzahlen der Modelgüte {#sec-lin-reg-quality}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

[Wir meinen mit Gütekriterien wie gut das statistische Modellieren funktioniert hat. Wir haben eine große Auswahl an Methoden und wir müssen das Ergebnis des Modellierens überprüfen.]{.aside}

Wir interpretieren keine der Gütekriterien und statistischen Maßzahlen alleine sondern in der Gesamtheit. Es gibt eine Reihe von Maßzahlen für die Güte eines Modells, wir schauen uns hier einige an. Später werden wir uns noch andere Maßzahlen anschauen, wenn wir eine multiple lineare Regression rechnen. Das [R Paket performance](https://easystats.github.io/performance/) werden wir später auch nutzen um die notwendigen Gütekriterien zu erhalten.

Wir wollen eine Gerade durch Punkte legen. Deshalb müssen wir folgende Fragen klären:

-   Läuft die Gerade durch die Mitte der Punkte? Hier hilft ein Residualplot für die Bewertung (siehe @sec-linreg-residual).
-   Liegen die Punkte alle auf der Geraden? Hier hilft das Bestimmtheitsmaß $R^2$ weiter (siehe @sec-linreg-bestimmt)
-   Folgt unser Outcome $y$ einer Normalverteilung? Hier kann der QQ-Plot helfen (siehe @sec-linreg-qq)

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Achte darauf welche Lernstufe du hast und was wir *wirklich* in der Vorlesung gemacht haben. Hier kann sich das ein oder andere überschneiden.

Was heißt überscheiden? Wir werden uns nicht in jedem Modul alle Gütekriterien anschauen. Deshalb Augen auf deine Mitschrift.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               see, performance)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Nachdem wir uns im vorherigen Kapitel mit einem sehr kleinen Satensatz beschäftigt haben, nehmen wir einen großen Datensatz. Bleiben aber bei einem simplen Modell. Wir brauchen dafür den Datensatz `flea_dog_cat_length_weight.xlsx`. In einer simplen linearen Regression schauen wir uns den Zusammenhang zwischen einem $y$ und einem $x_1$ an. Daher wählen wir aus dem Datensatz die beiden Spalten `jump_length` und `weight`. Wir wollen nun feststellen, ob es einen Zusammenhang zwischen der Sprungweite in \[cm\] und dem Flohgewicht in \[mg\] gibt. In dem Datensatz finden wir 400 Flöhe von Hunden und Katzen.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") %>%
  select(animal, jump_length, weight)
```

In der @tbl-model-1 ist der Datensatz `model_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz mit einer normalverteilten Variable `jump_length` und der normalverteilten Variable `weight`. Wir betrachten die ersten sieben Zeilen des Datensatzes.
#| label: tbl-model-1

model_tbl %>% head(7) %>% kable(align = "c", "pipe")
```

Im Folgenden *ignorieren* wir, dass die Sprungweiten und die Gewichte der Flöhe auch noch von den Hunden oder Katzen sowie dem unterschiedlichen Geschlecht der Flöhe abhängen könnten. Wir schmeißen alles in einen Pott und schauen nur auf den Zusammenhang von Sprungweite und Gewicht.

## Das simple lineare Modell

Wir fitten ein simples lineares Modell mit nur einem Einflussfaktor `weight` auf die Sprunglänge `jump_length`. Wir erhalten dann das Objekt `fit_1` was wir dann im Weiteren nutzen werden.

```{r}
fit_1 <- lm(jump_length ~ weight, data = model_tbl)
```

Wir nutzen jetzt dieses simple lineare Modell für die weiteren Gütekritierien.

## Residualplot {#sec-linreg-residual}

[In R wird in Modellausgaben die Standardabweichung der Residuen $s_{\epsilon}$ als `sigma` bezeichnet.]{.aside}

Wir wollen mit dem Residualplot die Frage beantworten, ob die Gerade *mittig* durch die Punktewolke läuft. Die Residuen $\epsilon$ sollen normalverteilt sein mit einem Mittelwert von Null $\epsilon \sim \mathcal{N}(0, s^2_{\epsilon})$.

Wir erhalten die Residuen `resid` und die angepassten Werte `.fitted` auf der Geraden über die Funktion `augment()`. Die Funktion `augment()` gibt noch mehr Informationen wieder, aber wir wollen uns jetzt erstmal auf die Residuen konzentrieren.

```{r}
resid_plot_tbl <- fit_1 %>% 
  augment() %>% 
  select(.fitted, .resid)

resid_plot_tbl %>% 
  head(5)
```

Die Daten selber interessieren uns nicht einer Tabelle. Stattdessen zeichnen wir einmal den Residualplot. Bei dem Residualplot tragen wir die Werte der Residuen `.resid` auf die y-Achse auf und die angepassten y-Werte auf der Geraden `.fitted` auf die x-Achse. Wir kippen im Prinzip die gefittete Gerade so, dass die Gerade parallel zu x-Achse läuft.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-01
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "Residualplot der Residuen des Models `fit_1`. Die rote Linie stellt die geschätzte Gerade da. Die Punkte sollen gleichmäßig und ohne eine Struktur um die Gerade verteilt sein."

ggplot(resid_plot_tbl, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw()
```

[The residual plot should look like the sky at night, with no pattern of any sort.]{.aside}

In @fig-scatter-qual-01 sehen wir den Residualplot von unseren Beispieldaten. Wir sehen, dass wir keine Struktur in der Punktewolke erkennen. Auch sind die Punkte gleichmäßig um die Gerade verteilt. Wir haben zwar einen Punkt, der sehr weit von der Gerade weg ist, das können wir aber ignorieren. Später können wir uns noch überlegen, ob wir einen Ausreißer (eng. *outlier*) vorliegen haben.

Kommen wir nochmal auf die Funktion `augment()` zurück und schauen uns einmal an, was die ganzen Spalten hier zu bedeuten haben. Dafür nutzen wir nochmal einen simpleren Datensatz in der die vierte Beobachtung mit $(4.1, 5.2)$ sehr extreme Werte im Vergleich zu den anderen drei Beobachtungen annimmt. Danach fitten wir dann wieder unser lineares Modell.

```{r}
simple_tbl <- tibble(jump_length = c(1.2, 1.8, 1.3, 5.2),
                     weight = c(0.8, 1, 1.2, 4.1))

fit_2 <- lm(jump_length ~ weight, data = simple_tbl)
```

Im Folgenden sehen wir dann die Ausgabe der Funktion `augment()`. Dabei sind die ersten beiden Spalten noch selbsterklärend. Wir haben hier mit `jump_length` und `weight` die Werte für das Outcome $y$ und die Einflussvariablen $x$ dargestellt.

```{r}
fit_2 %>% 
  augment() %>% 
  mutate(across(where(is.numeric), round, 2))
```

Die anderen Spalten sind dann wie folgt zu lesen.

-   `.fitted` sind die vorhergesagten Werte auf der Geraden. Wir bezeichnen diese Werte auch die $\hat{y}$ Werte.
-   `.resid` sind die Residuen oder auch $\epsilon$. Daher der Abstand zwischen den beobachteten $y$-Werten und den $\hat{y}$ Werten auf der Geraden.
-   `.hat` gibt den Einfluss jeder einzelnen Beobachtung auf die endgültige Gerade wieder. Also den Hebel (eng. *leverage*) jeder einzelnen Beobachtung und damit wie stark eine Beobachtung an der Geraden zieht.
-   `.sigma` beschreibt die geschätzte $s^2_{\epsilon}$ , wenn die entsprechende Beobachtung aus dem Modell herausgenommen wird.
-   `.cooksd` definiert, ob eine Beobachtung ein tendenzieller Outlier im Bezug zu den anderen Beobachtungen ist. Im Prinzip eine Standardisierung der `hat` Spalte.
-   `std.resid` sind die standardisierten Residuen. Dabei werden die Residuen durch die Standardabweichung der Residuen $s_{\epsilon}$ geteilt. Die standardisierten Residuen folgen dann einer Standardnormalverteilung.

Wir können dann der Ausgabe von `augment()` entnehmen, dass unsere vierte Beobachtung vermutlich ein Outlier ist.

## Bestimmtheitsmaß $R^2$ {#sec-linreg-bestimmt}

Nachdem wir nun wissen wie gut die Gerade durch die Punkte läuft, wollen wir noch bestimmen wie genau die Punkte auf der Geraden liegen. Das heißt wir wollen mit dem Bestimmtheitsmaß $R^2$ ausdrücken wie stark die Punkte um die Gerade variieren. Wir können folgende Aussage über das Bestimmtheitsmaß $R^2$ treffen. Die @fig-rsquare visualisiert nochmal den Zusammenhang.

-   wenn alle Punkte auf der Geraden liegen, dann ist das Bestimmtheitsmaß $R^2$ gleich 1.
-   wenn alle Punkte sehr stark um die Gerade streuen, dann läuft das Bestimmtheitsmaß $R^2$ gegen 0.

![Visualisierung des Bestimmtheitsmaßes $R^2$. Auf der linken Seite sehen wir eine perfekte Übereinstimmung der Punkte und der geschätzten Gerade. Wir haben ein $R^2$ von 1 vorliegen. Sind die Punkte und die geschätzte Gerade nicht deckungsgleich, so läuft das $R^2$ gegen 0.](images/statistical_modeling_rsquare){#fig-rsquare fig-align="center" width="100%"}

Da die Streuung um die Gerade auch gleichzeitig die Varianz wiederspiegelt, können wir auch sagen, dass wenn alle Punkte auf der Geraden liegen, die Varianz gleich Null ist. Die Einflussvariable $x_1$ erklärt die gesamte Varianz, die durch die Beobachtungen verursacht wurde.

Damit beschreibt das Bestimmtheitsmaß $R^2$ auch den Anteil der Varianz, der durch die lineare Regression, daher der Graden, erklärt wird. Wenn wir ein Bestimmtheitsmaß $R^2$ von Eins haben, wird die gesamte Varianz von unserem Modell erklärt. Haben wir ein Bestimmtheitsmaß $R^2$ von Null, wird gar keine Varianz von unserem Modell erklärt. Damit ist ein niedriges Bestimmtheitsmaß $R^2$ schlecht.

Wir können die Funktion `glance()` nutzen um uns das `r.squared` und das `adj.r.squared` wiedergeben zu lassen.

```{r}
#| message: false

fit_1 %>% 
  glance() %>% 
  select(r.squared, adj.r.squared)
```

[Wir nutzen grundsätzlich das adjustierte $R^2$`adj.r.squared` in der Anwendung.]{.aside}

Wir haben wir ein $R^2$ von $0.31$ vorliegen. Damit erklärt unser Modell bzw. die Gerade 31% der Varianz. Das ist jetzt nicht viel, aber wundert uns auch erstmal nicht. Wir haben ja die Faktoren `animal` und `sex` ignoriert. Beide Faktoren könnten ja auch einen Teil der Varianz erklären. Dafür müssten wir aber eine multiple lineare Regression mit mehren $x$ rechnen.

Wenn wir eine multiple Regression rechnen, dann nutzen wir das adjustierte $R^2$ in der Anwendung. Das hat den Grund, dass das $R^2$ automatisch ansteigt je mehr Variablen wir in das Modell nehmen. Jede neue Variable wird immer *etwas* erklären. Um dieses Überanpassen (eng. *overfitting*) zu vermeiden nutzen wir das adjustierte $R^2$. Im Falle des adjustierte $R^2$ wird ein Strafterm eingeführt, der das adjustierte $R^2$ kleiner macht je mehr Einflussvariablen in das Modell aufgenommen werdenn.

## QQ-Plot {#sec-linreg-qq}

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Das klingt hier alles etwas wage... Ja, das stimmt. Aber wir brauchen den QQ-Plot nur ganz kurz und wir müssten sehr viel Energei investieren um den QQ-Plot zu durchdringen. Deshalb hier die wage und grobe Darstellung.
:::

Mit dem Quantile-Quantile Plot oder kurz QQ-Plot können wir überprüfen, ob unser $y$ aus einer Normalverteilung stammt. Oder andersherum, ob unser $y$ approximativ normalverteilt ist. Der QQ-Plot ist ein visuelles Tool. Daher musst du immer schauen, ob dir das Ergebnis passt oder die Abweichungen zu groß sind. Es hilft dann manchmal die Daten zum Beispiel einmal zu $log$-Transformieren und dann die beiden QQ-Plots miteinander zu vergleichen.

Wir brauchen für einen QQ-Plot viele Beobachtungen. Das heißt, wir brauchen auf jeden Fall mehr als 20 Beobachtungen. Dann ist es auch häufig schwierig den QQ-Plot zu bewerten, wenn es viele Behandlungsgruppen oder Blöcke gibt. Am Ende haben wir dann zwar mehr als 20 Beobachtungen aber pro Kombination Behandlung und Block nur vier Wiederholungen. Und vier Wiederholungen sind zu wenig für eine sinnvolle Interpretation eines QQ-Plots.

Grob gesprochen vergleicht der QQ Plot die Quantile der vorliegenden Beobachtungen, in unserem Fall der Variablen `jump_length`, mir den Quantilen einer theoretischen Normalverteilung, die sich aus den Daten mit dem Mittelwert und der Standardabweichung von `jump_length` ergeben würden.

Wir können die Annahme der Normalverteilung recht einfach in `ggplot` überprüfen. Wir sehen in @fig-scatter-qual-02 den QQ-Plot für die Variable `jump_length`. Die Punkte sollten alle auf einer Diagonalen liegen. Hier dargestellt durch die rote Linie. Häufig weichen die Punkte am Anfang und Ende der Spannweite der Beobachtungen etwas ab.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-02
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "QQ-Plot der Sprungweite in \\[cm\\]. Die Gerade geht einmal durch die Mitte der Punkte und die Punkte liegen nicht exakt auf der Geraden. Eine leichte Abweichung von der Normalverteilung könnte vorliegen."

ggplot(model_tbl, aes(sample = jump_length)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw()
```

Wir werden uns später auch noch häufig die Residuen aus den Modellen anschauen. Die Residuen müssen nach dem Fit des Modells einer Normalverteilung folgen. Wir können diese Annahme an die Residuen mit einem QQ-Plot überprüfen. In @fig-scatter-qual-resid sehen wir die Residuen aus dem Modell `fit_1` in einem QQ-Plot. Wir würden sagen, dass die Residuen approximativ normalvertelt sind. Die Punkte liegen fast alle auf der roten Diagonalen.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-resid
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "QQ-Plot der Residuen aus dem Modell `fit_1`. Die Residuen müssen einer approximativen Normalverteilung folgen, sonst hat der Fit des Modelles nicht funktioniert."

ggplot(resid_plot_tbl, aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw() 

```

## Modellgüte mit dem R Paket `performance`

Abschließend möchte ich hier nochmal das [R Paket performance](https://easystats.github.io/performance/) vorstellen. Wir können mit dem Paket auch die Normalverteilungsannahme der Residuen überprüfen. Das geht ganz einfach mit der Funktion `check_normality()` in die wir einfach das Objekt mit dem Fit des Modells übergeben.

```{r}
check_normality(fit_1)
```

Wir haben auch die Möglichkeit uns einen Plot der Modellgüte anzeigen zu lassen. In @fig-scatter-qual-04 sehen wir die Übersicht von bis zu sechs Abbildungen, die uns Informationen zu der Modellgüte liefern. Wir müssen nur den Fit unseres Modells an die Funktion `check_model()` übergeben.

Das Schöne an der Funktion ist, dass jeder Subplot eine Beschreibung in Englisch hat, wie der Plot auszusehen hat, wenn alles gut mit dem Modellieren funktioniert hat.

Wir kommen dann in der multiplen linearen Regression nochmal auf das Paket `performance` zurück. Für dieses Kapitel reicht dieser kurze Abriss.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-04
#| fig-align: center
#| fig-height: 12
#| fig-width: 8
#| fig-cap: "Übersicht der Plots zu der Modellgüte aus der Funktion `check_model()`."
#| column: page

check_model(fit_1, colors = cbbPalette[6:8])

```
