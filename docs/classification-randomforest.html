<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Ein Kochbuch mit Rezepten aus der Bio Data Science, Biostatistik, Biometrie und Statistik">

<title>Bio Data Science - 73&nbsp; Decision trees</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./classification-svm.html" rel="next">
<link href="./classification-knn.html" rel="prev">
<link href="./cover2024_favi.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Bio Data Science - 73&nbsp; Decision trees">
<meta property="og:description" content="Ein Kochbuch mit Rezepten der Bio Data Science, Biostatistik, Biometrie und Statistik">
<meta property="og:image" content="https://github.com/jkruppa/jkruppa.github.io/raw/master/cover2024.png">
<meta property="og:site_name" content="Bio Data Science">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./classification-preface.html">Klassifikation oder maschinelles Lernen</a></li><li class="breadcrumb-item"><a href="./classification-randomforest.html"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Decision trees</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bio Data Science</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/jkruppa/jkruppa.github.io/" title="Quellcode" class="quarto-navigation-tool px-1" aria-label="Quellcode"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Dunkelmodus umschalten"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Suchen"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Willkommen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./organisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Organisation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./literature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bibliothek</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forschungsprozess.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Forschungsprozess</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./abschlussarbeit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Abschlussarbeit</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./example-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Datenbeispiele</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-fleas-dogs-cats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Von Flöhen auf Tieren</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-gummi-bears.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Von Gummibärchen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-complex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Von komplexeren Daten</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./programing-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Programmieren in R</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-letters-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Buchstaben und Zahlen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Operatoren, Funktionen und Pakete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-import.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Daten einlesen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Daten bearbeiten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-strings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Reguläre Ausdrücke</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-purrr-furrr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Ein <code>purrr</code> Cookbook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-quarto-shiny.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Quarto und Shiny App</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./eda-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Explorative Datenanalyse</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-descriptive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Deskriptive Statistik</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-ggplot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Visualisierung von Daten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Verteilung von Daten</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-transform.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Transformieren von Daten</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./stat-tests-preface-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Testen von Hypothesen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Die Testentscheidung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-theorie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Die Testtheorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-effect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Der Effektschätzer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-pretest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Der Pre-Test oder Vortest</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./experimental-design-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experimentelle Designs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Versuchsplanung in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Einfache Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Fortgeschrittene Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-samplesize.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Fallzahlplanung</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./stat-tests-preface-app.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistische Gruppenvergleiche</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Testen in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-ttest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Der t-Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Die ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-ancova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Die ANCOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-utest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Der Wilcoxon-Mann-Whitney-Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-kruskal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Der Kruskal-Wallis-Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-friedman.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Der Friedman Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-chi-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Der <span class="math inline">\(\mathcal{X}^2\)</span>-Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-anteil-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Der Anteilstest</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-diagnostic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Der diagnostische Test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-trendtest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Der Trendtest</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-permutationstest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Der Permutationstest</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-posthoc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Der Post-hoc-Test</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./stat-linear-reg-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Grundlagen des Modellierens</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Simple lineare Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Multiple lineare Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-quality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Modelgüte</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-corr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Korrelation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Ausreißer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-variable-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Variablenselektion</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Fehlende Werte</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-sensitivity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Sensitivitätsanalyse</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./stat-modeling-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistisches Modellieren</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Modellieren in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Gaussian Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-beta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Beta Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-multinom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Multinomiale / Ordinale Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Logistische Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-prob-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Linear Probability Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Lineare gemischte Modelle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-gee.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Generalized Estimating Equations (GEE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-non-linear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Nicht lineare Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-robust-quantile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Robuste und Quantilesregression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Überlebenszeitanalysen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-noninferiority.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Äquivalenz oder Nichtunterlegenheit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-meta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Metaanalysen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-cluster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Clusteranalysen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Multivariate Verfahren</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-survey.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Fragebogenanalyse</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./time-space-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Zeitliche und räumliche Analysen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time-space-pseudo-time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Pseudo Zeitreihen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time-space-time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Zeitreihen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time-space-spatial-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Räumliche Daten</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./classification-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Klassifikation oder maschinelles Lernen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Grundlagen der Klassifikation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Data splitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-pre-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Data preprocessing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-model-compare.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Vergleich von Algorithmen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-knn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title"><span class="math inline">\(k\)</span> nearest neighbor</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-randomforest.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Decision trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Support vector machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Neural networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./abspann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abspann</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-spielecke.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Spielecke</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
  <li><a href="#genutzte-r-pakete" id="toc-genutzte-r-pakete" class="nav-link active" data-scroll-target="#genutzte-r-pakete"><span class="header-section-number">73.1</span> Genutzte R Pakete</a></li>
  <li><a href="#daten" id="toc-daten" class="nav-link" data-scroll-target="#daten"><span class="header-section-number">73.2</span> Daten</a></li>
  <li><a href="#sec-rpart" id="toc-sec-rpart" class="nav-link" data-scroll-target="#sec-rpart"><span class="header-section-number">73.3</span> Entscheidungsbaum mit Rpart</a></li>
  <li><a href="#sec-rf" id="toc-sec-rf" class="nav-link" data-scroll-target="#sec-rf"><span class="header-section-number">73.4</span> Random Forest mit ranger</a></li>
  <li><a href="#sec-xgboost" id="toc-sec-xgboost" class="nav-link" data-scroll-target="#sec-xgboost"><span class="header-section-number">73.5</span> Gradient boosting mit xgboost</a></li>
  <li><a href="#tuning" id="toc-tuning" class="nav-link" data-scroll-target="#tuning"><span class="header-section-number">73.6</span> Tuning</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/jkruppa/jkruppa.github.io/edit/master/classification-randomforest.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li><li><a href="https://github.com/jkruppa/jkruppa.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Problem melden</a></li><li><a href="https://github.com/jkruppa/jkruppa.github.io/blob/master/classification-randomforest.qmd" class="toc-action"><i class="bi empty"></i>Quellcode anzeigen</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./classification-preface.html">Klassifikation oder maschinelles Lernen</a></li><li class="breadcrumb-item"><a href="./classification-randomforest.html"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Decision trees</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-class-tree" class="quarto-section-identifier"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Decision trees</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Gesamten Code zeigen</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Gesamten Code verbergen</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">Quellcode anzeigen</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em>Letzte Änderung am 20. May 2024 um 07:24:10</em></p>
<p>In diesem Kapitel wollen wir uns mit Entscheidungsbäumen (eng. <em>decision trees</em>) beschäftigen. Wie oft gibt es auch bei der Anwendung von Entscheidungsbäumen eine Menge Varianten. Wir wollen uns in diesem Kapitel eine erste Übersicht geben und du kannst dann ja schauen, welche Varianten es noch von den Entscheidungsbäumen gibt. Wichtig ist zu wissen, unsere Bäume spalten sich immer nur in zwei Äste auf.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/angel_01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="images/angel_01.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></a></p>
</figure>
</div>
<p>Wir werden uns hier mit der Anwendung beschäftigen. Wie immer lassen wir daher <em>tiefere</em> mathematische Überlegungen weg.</p>
</div></div><ul>
<li>In <a href="#sec-rpart" class="quarto-xref"><span>Kapitel 73.3</span></a> schauen wir uns <em>einen</em> Entscheidungsbaum an. Wir teilen nacheinander unsere Beobachtungen immer weiter anhand unser Prädiktoren in zwei Gruppen auf, bis wir nur noch Gruppen haben, die fast nur noch aus einer Klasse des Labels bestehen.</li>
<li>In <a href="#sec-rf" class="quarto-xref"><span>Kapitel 73.4</span></a> schauen wir uns ein Ensemble von Entscheidungsbäumen an. Wir lassen daher nicht einen sondern hunderte von Entscheidungsbäumen wachsen. Damit wir nicht immer den gleichen Baum auf den gleichen Daten wachsen lassen, wählen zufällig Beobachtungen und Variablen aus, die wir zum Erstellen der Bäume nutzen. Wir lassen einen Random Forest wachsen.</li>
<li>In <a href="#sec-xgboost" class="quarto-xref"><span>Kapitel 73.5</span></a> betrachten wir eine komplexere Implementierung der Random Forest. Wir nutzen hier Gradient Boosting um die Bäume noch besser anhand unseres Trainingsdatensatzes wachsen zu lassen.</li>
</ul>
<p>Alle drei Algorithmen gehen wir jetzt einmal durch. Dabei können wir bei einem Entscheidunsgbaum noch recht gut nachvollziehen, was dort eigentlich passiert. Bei mehreren Bäumen zusammen, können wir nur noch schematisch nachvollziehen was die einzelnen Schritte in der Modellbildung sind.</p>
<section id="genutzte-r-pakete" class="level2" data-number="73.1">
<h2 data-number="73.1" class="anchored" data-anchor-id="genutzte-r-pakete"><span class="header-section-number">73.1</span> Genutzte R Pakete</h2>
<p>Wir wollen folgende R Pakete in diesem Kapitel nutzen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(tidyverse, tidymodels, magrittr, </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>               janitor, vip, rpart.plot, see,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>               xgboost, Ckmeans<span class="fl">.1</span>d.dp, conflicted)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025429</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>An der Seite des Kapitels findest du den Link <em>Quellcode anzeigen</em>, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.</p>
</section>
<section id="daten" class="level2 page-columns page-full" data-number="73.2">
<h2 data-number="73.2" class="anchored" data-anchor-id="daten"><span class="header-section-number">73.2</span> Daten</h2>
<p>Bei dem vorherigen Beispielen haben wir immer unseren Datensatz zu den infizierten Ferkeln genutzt. In diesem Kapitel wolle wir uns aber mal auf einen echten Datensatz anschauen. Wir nutzen daher einmal den Gummibärchendatensatz. Als unser Label und daher als unser Outcome nehmen wir das Geschlecht <code>gender</code>. Dabei wollen wir dann die weiblichen Studierenden vorhersagen. Im Weiteren nehmen wir nur die Spalte Geschlecht sowie als Prädiktoren die Spalten <code>most_liked</code>, <code>age</code>, <code>semester</code>, und <code>height</code>.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>gummi_tbl <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"data/gummibears.xlsx"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gender =</span> <span class="fu">as_factor</span>(gender),</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">most_liked =</span> <span class="fu">as_factor</span>(most_liked)) <span class="sc">|&gt;</span> </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(gender, most_liked, age, semester, height) <span class="sc">|&gt;</span> </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>(gender)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wir dürfen keine fehlenden Werte in den Daten haben. Wir können für die Prädiktoren später die fehlenden Werte imputieren. Aber wir können keine Labels imputieren. Daher entfernen wir alle Beobachtungen, die ein <code>NA</code> in der Variable <code>gender</code> haben. Wir haben dann insgesamt <span class="math inline">\(n = 699\)</span> Beobachtungen vorliegen. In <a href="#tbl-gummi-model-rf" class="quarto-xref">Tabelle&nbsp;<span>73.1</span></a> sehen wir nochmal die Auswahl des Datensatzes in gekürzter Form.</p>
<div class="cell">
<div id="tbl-gummi-model-rf" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-gummi-model-rf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabelle&nbsp;73.1— Auszug aus dem Daten zu den Gummibärchendaten.
</figcaption>
<div aria-describedby="tbl-gummi-model-rf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: center;">gender</th>
<th style="text-align: center;">most_liked</th>
<th style="text-align: center;">age</th>
<th style="text-align: center;">semester</th>
<th style="text-align: center;">height</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">lightred</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">193</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">yellow</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">159</td>
</tr>
<tr class="odd">
<td style="text-align: center;">w</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">159</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">180</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">180</td>
</tr>
<tr class="even">
<td style="text-align: center;">m</td>
<td style="text-align: center;">green</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">180</td>
</tr>
<tr class="odd">
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
</tr>
<tr class="even">
<td style="text-align: center;">m</td>
<td style="text-align: center;">darkred</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">193</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">189</td>
</tr>
<tr class="even">
<td style="text-align: center;">m</td>
<td style="text-align: center;">darkred</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">187</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">green</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">182</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">170</td>
</tr>
<tr class="odd">
<td style="text-align: center;">w</td>
<td style="text-align: center;">green</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">180</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Unsere Fragestellung ist damit, können wir anhand unserer Prädiktoren männliche von weiblichen Studierenden unterscheiden und damit auch klassifizieren? Um die Klassifikation mit Entscheidungsbäumen rechnen zu können brauchen wir wie bei allen anderen Algorithmen auch einen Trainings- und Testdatensatz. Wir splitten dafür unsere Daten in einer 3 zu 4 Verhältnis in einen Traingsdatensatz sowie einen Testdatensatz auf. Der Traingsdatensatz ist dabei immer der größere Datensatz. Da wir aktuell nicht so viele Beobachtungen in dem Gummibärchendatensatz haben, möchte ich mindestens 100 Beobachtungen in den Testdaten. Deshalb kommt mir der 3:4 Split sehr entgegen.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">Im maschinellen Lernen sind alle Datensätze, die weniger als tausend Beobachtungen vorliegen haben, klein.</span></div></div>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>gummi_data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(gummi_tbl, <span class="at">prop =</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">4</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wir speichern uns jetzt den Trainings- und Testdatensatz jeweils separat ab. Die weiteren Modellschritte laufen alle auf dem Traingsdatensatz, wie nutzen dann erst ganz zum Schluss einmal den Testdatensatz um zu schauen, wie gut unsere trainiertes Modell auf den neuen Testdaten funktioniert.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>gummi_train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(gummi_data_split)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>gummi_test_data  <span class="ot">&lt;-</span> <span class="fu">testing</span>(gummi_data_split)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nachdem wir die Daten vorbereitet haben, müssen wir noch das Rezept mit den Vorverabreitungsschritten definieren. Wir schreiben, dass wir das Geschlecht <code>gender</code> als unser Label haben wollen. Daneben nehmen wir alle anderen Spalten als Prädiktoren mit in unser Modell, das machen wir dann mit dem <code>.</code> Symbol. Da wir noch fehlende Werte in unseren Prädiktoren haben, imputieren wir noch die numerischen Variablen mit der Mittelwertsimputation und die nominalen fehlenden Werte mit Entscheidungsbäumen. Es gibt wie immer noch andere Imputationsmöglichkeiten, ich habe mich jetzt aus praktischen Gründen für dies beiden Verfahren entschieden. Ich überspringe hier auch die Diagnose der Imputation, also ob das jetzt eine gute und sinnvolle Imputation der fehlenden Werte war oder nicht. Die Diagnoseschritte müsstest du im Anwendungsfall nochmal im <a href="stat-modeling-missing.html">Kapitel zur Imputation</a> nachlesen und anwenden. Dann müssen wir noch alle numerischen Variablen normalisieren und alle nominalen Variablen dummykodieren. Am Ende werde ich nochmal alle Variablen entfernen, sollte die Varianz in einer Variable nahe der Null sein.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>gummi_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(gender <span class="sc">~</span> ., <span class="at">data =</span> gummi_train_data) <span class="sc">|&gt;</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_mean</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_bag</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_range</span>(<span class="fu">all_numeric_predictors</span>(), <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>gummi_rec</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Recipe ──────────────────────────────────────────────────────────────────────</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Inputs </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Number of variables by role</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>outcome:   1
predictor: 4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Operations </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>• Mean imputation for: all_numeric_predictors()</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>• Bagged tree imputation for: all_nominal_predictors()</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>• Range scaling to [0,1] for: all_numeric_predictors()</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>• Dummy variables from: all_nominal_predictors()</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>• Sparse, unbalanced variable filter on: all_predictors()</code></pre>
</div>
</div>
<p>Alles in allem haben wir ein sehr kleines Modell. Wir haben ja nur ein Outcome und vier Prädiktoren. Trotzdem sollte dieser Datensatz reichen um zu erklären wie Entscheidungsbäume funktionieren.</p>
</section>
<section id="sec-rpart" class="level2" data-number="73.3">
<h2 data-number="73.3" class="anchored" data-anchor-id="sec-rpart"><span class="header-section-number">73.3</span> Entscheidungsbaum mit Rpart</h2>
<p>Wie funktioniert nun ein Entscheidungsbaum? Ein Entscheidungsbaum besteht aus Knoten (eng. <em>nodes</em>) und Ästen (eng. <em>edge</em>). Dabei hat immer ein Knoten zwei Äste. Die Beobachtungen in einem Knoten fallen nach einer Entscheidungsregel anhand eines Prädiktors in entlang zweier Äste in zwei separate Knoten. So können wir unsere <span class="math inline">\(n = 699\)</span> zum Beispiel anhand des Alters in zwei Gruppen aufteilen. Wir legen willkürlich die Altersgrenze bei 22 fest.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>gummi_tbl <span class="sc">|&gt;</span> </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">grp =</span> <span class="fu">if_else</span>(age <span class="sc">&gt;=</span> <span class="dv">22</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(grp) <span class="sc">|&gt;</span> </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tabyl</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> pull(mutate(gummi_tbl, grp = if_else(age &gt;= 22, 1, 0)), grp)   n   percent
                                                            0 306 0.4377682
                                                            1 393 0.5622318</code></pre>
</div>
</div>
<p>Wir erhalten mit diesem Split zwei Gruppen mit je <span class="math inline">\(n_0 = 207\)</span> und <span class="math inline">\(n_1 = 259\)</span> Beobachtungen. Wir haben jetzt diesen Split willkürlich gewählt. In dem Algorithmus für die Entscheidungsbäume wird dieser Schritt intern optimiert, so dass wir den besten Wert für den Alterssplit finden, der uns möglichst reine Knoten im Bezug auf das Label liefert. Wir wollen ja am Ende einen Algorithmus trainieren, der uns die Geschlechter bestmöglich auftrennt, so dass wir eine neue Beobachtung bestmöglich vorhersagen können. Wenn keine Aufteilungen in einem Knoten mehr möglich sind, dann nennen wir diesen Knoten einen Terminalknoten.</p>
<p>In <a href="#fig-class-rf-01" class="quarto-xref">Abbildung&nbsp;<span>73.5</span></a> sehen wir ein Beispiel für zwei numerische Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. Auf der linken Seite ist das Koordinatensystem mit dreizehn Beobachtungen dargestellt. Von den dreizehn Beobachtungen sind zehn Fälle (eng. <em>cases</em>) und drei Kontrollen (eng. <em>control</em>). Wir wollen uns jetzt an dem Koordinatensystem die Idee der Splits für ein Baumwachstum veranschaulichen. Auf der rechten Seite sehen wir nämlich den ersten Knoten des Entscheidungsbaums (eng. <em>root node</em>) in dem sich alle Beobachtungen befinden. Wir wollen jetzt die Beobachtungen anhand der Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> so aufspalten, dass für möglichst reine Knoten erhalten. Wir stoppen auch im Splitting wenn wir weniger oder gleich vier Beobachtungen nach einem Split in einem Knoten erhalten.</p>
<div id="fig-class-rf-01" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-rf-01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2"><img src="images/class-rf-01.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.1— Darstellung des Anwachsen des Entscheidungsbaumes. Links sind die beiden Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> als Koordinatensysten dargestellt. Die Punkte stllen die Beobachtungen mit den jeweiligen Label weiß und schwarz dar. Rechts ist der Knoten <span class="math inline">\(t_1\)</span> dargestellt, der alle Beobachtungen beinhaltet..
</figcaption>
</figure>
</div>
<p>In <a href="#fig-class-rf-02" class="quarto-xref">Abbildung&nbsp;<span>73.6</span></a> sehen wir den ersten Split des Prädiktors <span class="math inline">\(X_1\)</span> anhand des Wertes <span class="math inline">\(c_1\)</span>. Wir erhalten nach dem Split die zwei neuen Knoten <span class="math inline">\(t_2\)</span> und <span class="math inline">\(t_3\)</span>. Wir haben den Split so gewählt, dass wir einen reinen Knoten <span class="math inline">\(t_3\)</span> erhalten. Da der Knoten <span class="math inline">\(t_3\)</span> jetzt nur noch Fälle enthaält, wird dieser Knoten zu einem Terminalknoten und es finden keine weiteren Aufspaltungen mehr statt. Wir machen jetzt also mit dem Knoten <span class="math inline">\(t_2\)</span> weiter.</p>
<div id="fig-class-rf-02" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-rf-02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3"><img src="images/class-rf-02.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.2— Darstellung des ersten Splits anhand des Prädiktors <span class="math inline">\(X_1\)</span>. Wir wählen den Wert <span class="math inline">\(c_1\)</span> für den Split so, dass wir möglichst reine Knoten produzieren. Wir erhalten zwei neue Knoten <span class="math inline">\(t_2\)</span> und <span class="math inline">\(t_3\)</span>. Der Knoten <span class="math inline">\(t_3\)</span> ist maximal rein und wird daher zu einem Terminalknoten.
</figcaption>
</figure>
</div>
<p>In <a href="#fig-class-rf-03" class="quarto-xref">Abbildung&nbsp;<span>73.8</span></a> sehen wir den Split durch den Prädiktor <span class="math inline">\(X_2\)</span> nach dem Wert <span class="math inline">\(c_2\)</span>. Wir erhalten wieder zwei neue Knotenn <span class="math inline">\(t_4\)</span> und <span class="math inline">\(t_5\)</span>. Der Knoten <span class="math inline">\(t_4\)</span> wird nach unseren Regeln wieder zu einem Terminalknoten. Wir haben nur Fälle in dem Knoten <span class="math inline">\(t_4\)</span> vorliegen. Wir stoppen auch bei dem Knoten <span class="math inline">\(t_5\)</span> unsere weitere Aufteilung, da wir hier vier oder weniger Beobachtungen vorliegen haben. Damit sind wir mit dem Split zu einem Ende gekommen.</p>
<div id="fig-class-rf-03" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-rf-03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" data-glightbox="description: .lightbox-desc-4"><img src="images/class-rf-03.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.3— Darstellung des zweiten Splits anhand des Prädiktors <span class="math inline">\(X_2\)</span>. Wir wählen wiederum den Wert <span class="math inline">\(c_2\)</span> für den Split so, dass wir möglichst reine Knoten erhalten. So erhalten wir zwei neue Knoten <span class="math inline">\(t_4\)</span> und <span class="math inline">\(t_5\)</span>. Da nun <span class="math inline">\(t_4\)</span> ebenfalls ein reiner Knoten ist, wird der Knoten <span class="math inline">\(t_4\)</span> ebenfalls zu einem Terminalknoten. Wir stoppen hier das Wachstum, da mir eine mindest Anzahl von vier Beobachtungen in den Knoten erreicht haben.
</figcaption>
</figure>
</div>
<p>In <a href="#fig-class-rf-04" class="quarto-xref">Abbildung&nbsp;<span>73.12</span></a> sehen wir jetzt eine neue Beobachtung <code>?</code> die mit gegebenen Werten für <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> in den terminalen Knoten <span class="math inline">\(t_5\)</span> fällt. Wir zählen dort die Fälle und erhalten eine Klassenzugehörigkeitswahrscheinlichkeit von 25%. Daher würden wir sagen, dass die neue Beobchtung eine Kontrolle ist. Es handelt sich damit um eine weiße Beoabchtung.</p>
<div id="fig-class-rf-04" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-rf-04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" data-glightbox="description: .lightbox-desc-5"><img src="images/class-rf-04.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.4— Darstellung der Vorhersage einer neuen Beobachtung mit Werten für die Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. Unsere neue Beobachtung <code>?</code> fällt in den Terminalknoten <span class="math inline">\(t_5\)</span>. Dort zählen wir die schwarzen Kreise. Wir stellen fest, dass die neue Beobachtung mit 25% Wahrscheinlichkeit ein Fall und damit schwarz ist. Daher ist die neue Beobachtung weiß.
</figcaption>
</figure>
</div>
<p>Damit haben wir einmal den simplen Fall mit zwei numerischen Prädiktoren durchgespielt. Auch haben wir wenige Beobachtungen und sind schnell zu reinen Knoten gekommen. Wenn wir jetzt natürlich sehr viel mehr Beobachtungen haben oder sehr viele Prädiktoren dann wird die Sache sehr schnell sehr rechenintensiv. Dafür haben wir dann eben R.</p>
<p>Wenn wir in R einen Entscheidungsbaum rechnen wollen, dann nutzen wir die Funktion <code>decision_tree()</code> wir wollen nur eine maximale Tiefe von 5 Knoten haben und/oder mindestens 10 Beobachtungen in einem Knoten. Je nachdem welche Bedingung wir eher erreichen. Ebenfalls können wir das Wachstum mit dem Parameter <code>cost_complexity</code> kontrollieren. Sollte sich das Modell nicht um mindestens 0.001 verbessern, dann werden wir den nächsten Knoten nicht anlegen. Wir wählen als Engine den Algorithmus <code>rpart</code>, da wir uns diese Art von Algorithmus gut mit dem R Paket <code>{rpart.plot}</code> visualisieren können.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>rpart_mod <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>(<span class="at">tree_depth =</span> <span class="dv">5</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">cost_complexity =</span> <span class="fl">0.001</span>) <span class="sc">|&gt;</span> </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"rpart"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Jetzt kommt wieder das Modell zusammen mit dem Rezept. Wir speichern wieder beides in einen Workflow.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>rpart_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rpart_mod) <span class="sc">|&gt;</span> </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Den Workflow können wir dann mit dem Traingsdatensatz einmal durchlaufen lassen und uns das gefittete Modell wiedergeben lassen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>rpart_fit <span class="ot">&lt;-</span> rpart_wflow <span class="sc">|&gt;</span> </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nachdem wir das trainierte Modell vorliegen haben, nutzen wir die Funktion <code>augment()</code> um das Modell auf die Testdaten anzuwenden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rpart_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(rpart_fit, gummi_test_data ) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Jetzt geht es los und wir schauen uns einmal an, wie gut die Klassifizierung mit dem Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>rpart_cm <span class="ot">&lt;-</span> rpart_aug <span class="sc">|&gt;</span> </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>rpart_cm</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 75 12
         w 16 72</code></pre>
</div>
</div>
<p>Das freut einen doch. Das sieht ziemlich gut aus. Wir haben auf der Diagonalen fast alle Beoabchtungen und nur sehr wenige falsche Vorhersagen auf der Nichtdiagonalen. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>rpart_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.84 
 2 kap                  binary         0.680
 3 sens                 binary         0.824
 4 spec                 binary         0.857
 5 ppv                  binary         0.862
 6 npv                  binary         0.818
 7 mcc                  binary         0.681
 8 j_index              binary         0.681
 9 bal_accuracy         binary         0.841
10 detection_prevalence binary         0.497
11 precision            binary         0.862
12 recall               binary         0.824
13 f_meas               binary         0.843</code></pre>
</div>
</div>
<p>Wir besprechen hier nicht alle, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 83% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>rpart_aug <span class="sc">|&gt;</span> </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-01" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-01-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" data-glightbox="description: .lightbox-desc-6"><img src="classification-randomforest_files/figure-html/fig-class-rf-01-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.5— ROC Kurve für den Entscheidungsbaum mit dem <code>rpart</code> Algorithmus.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Es gibt viele Möglichkeiten sich einen Entscheidungsbaum anzuschauen. Wir nutzen hier das R Paket <code>{rpart.plot}</code> und die gleichnamige Funktion <code>rpart.plot()</code>. Die vielen Möglichkeiten der Darstellung und der Optionen findest in der Vignette <a href="http://127.0.0.1:52037/help/library/rpart.plot/doc/prp.pdf">Plotting rpart trees with the rpart.plot package.</a>. Wir gehen hier einmal auf die Variante <code>extra = 101</code> ein. Es gibt insgesamt elf verschiedene Arten plus eben noch die Möglichkeit 100 zu einer der elf genannten Varianten hinzufügen, um auch den Prozentsatz der Beobachtungen im Knoten anzuzeigen. Zum Beispiel zeigt <code>extra = 101</code> die Anzahl und den Prozentsatz der Beobachtungen in dem Knoten an.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>rpart_fit <span class="sc">|&gt;</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">|&gt;</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart.plot</span>(<span class="at">roundint =</span> <span class="cn">FALSE</span>, <span class="at">extra =</span> <span class="dv">101</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-02" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-02-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" data-glightbox="description: .lightbox-desc-7"><img src="classification-randomforest_files/figure-html/fig-class-rf-02-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.6— Visualisierung des finalen <code>rpart</code> Entscheidungsbaums.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-class-rf-02" class="quarto-xref">Abbildung&nbsp;<span>73.6</span></a> sehen wir den finalen Entscheidungsbaum. Wir sehen, dass wir nicht weiter als fünf Splits nach unten gewandert sind. Das hatten wir ja auch mit dem Parameter <code>tree_depth</code> so eingestellt. Jetzt sehen wir aber auch, dass wir mit dem Preprocessing auch eine Grube graben können. Wir haben in unserem ersten Knoten 189 Männer und 165 Frauen. Daher hat der Knoten nach Mehrheitsentscheidung den Status <code>m</code>. Jetzt spalten wir den Knoten nach der Körpergröße von <span class="math inline">\(0.48\)</span> in zwei Gruppen. Was soll jetzt <span class="math inline">\(0.48\)</span> heißen? Keine Ahnung. Wir haben die Daten normalisiert. Wenn du hier die Werte für die Splits <em>interpretieren</em> willst, dann musst du auf den Orginaldaten rechnen. Nach dem Split sehen wir zwei Knoten, in denen zum einen die Männer domiern und zum anderen die Frauen. Wir splitten wieder nach der Körpergröße und erhalten immer reinere Knoten in den fast nur noch Männer oder Frauen sind.</p>
<p>Schaue dir auch die anderen Arten der Visualisierung in <code>rpart.plot</code> an und entscheide, ob dir die anderen Varianten bessere Informationen liefern, die zu deiner wissenschaftlichen Fragestellung passen.</p>
<p>An der Stelle trifft dann immer die Klassifikation auf die Interpretation. Du kannst nicht das Modell im Nachgang wieder entnormalisieren. Das geht nicht. Wenn du auf den Orginaldaten rechnest, dann wirst du ein anderes Modell erhalten. Das Modell mag besser oder schlechter sein, auf jeden Fall anders. Wie so oft hängt es von der wissenschaftlichen Fragestellung ab.</p>
</section>
<section id="sec-rf" class="level2" data-number="73.4">
<h2 data-number="73.4" class="anchored" data-anchor-id="sec-rf"><span class="header-section-number">73.4</span> Random Forest mit ranger</h2>
<p>Bis jetzt haben wir <em>einen</em> Entscheidungsbaum wachsen lassen. Was wäre, wenn wir statt einen Baum mehrere Bäume wachsen lassen. Wir lassen einen ganzen Wald (eng. <em>forest</em>) entstehen. Nun macht es wenig Sinn, immer den gleichen Baum auf immer den selben Daten wachsen zu lassen. Daher wählen wir zufällig eine Anzahl an Zeilen und Spalten aus bevor wir einen Baum in unserem Wald wachsen lassen. Dabei bringen wir zwei den Zufall in die Generierung eines Baums mit ein.</p>
<ol type="1">
<li>Durch die zufällige Auswahl der Beobachtungen mit Zurücklegen. Wir haben also einzelne Zeilen und damit Beobachtungen mehrfach in den Daten.</li>
<li>Durch die zufällige Auswahl eines Sets an Variablen. Wir nutzen nicht immer alle Variablen in unserem Modell sondern nur ein Set an Spalten.</li>
</ol>
<p>Im maschinellen Lernen nennen wir diese Methode <em>Bagging</em>. Das Wort <em>Bagging</em> steht für <em>bootstrap aggregating</em> und ist eine Methode, um Vorhersagen aus verschiedenen Modellen zu kombinieren. In unserem Fall sind es die verschiedenen Entscheidungsböume. Dabei müssen alle Modelle mit dem gleichen Algorithmus laufen, können aber auf verschiedenen Datensätzen oder aber Variablensätzen zugreifen. Häufig haben die Modelle eine hohe Varianz in der Vorhersage und wir nutzen dann Bagging um die Modelle miteinander zu kombinieren und dadurch die Varianz zu verringern. Die Ergebnisse der Modelle werden dann im einfachsten Fall gemittelt. Das Ergebnis jeder Modellvorhersage geht mit gleichem Gewicht in die Vorhersage ein. Wir haben auch noch andere Möglichkeiten, aber du kannst dir Vorstellen wir rechnen verschiedene Modelle <span class="math inline">\(j\)</span>-mal und bilden dann ein finales Modell in dem wir alle <span class="math inline">\(j\)</span>-Modelle zusammenfassen. Wie wir die Zusammenfassung rechnen, ist dann immer wieder von Fall zu Fall unterschiedlich. Wir erhalten am Ende einen <em>Ensemble</em> Klassifizierer, da ja ein Ensemble von Modellen zusammengefasst wird. In dem Fall von den Entscheidungsbäumen ist das Ensemble ein Wald an Bäumen.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Parallele CPU Nutzung
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Wenn wir wirklich viele Bäume wachsen lassen wollen, dann bietet sich die parallele Berechnung an. Das können wir über das R Paket <code>{parallel}</code> realisieren. Wir detektieren erstmal wie viele Kerne wir auf dem Rechner zu Verfügung haben.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>cores <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>cores</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8</code></pre>
</div>
</div>
<p>Wenn wir das gemacht haben, dann können wir in <code>set_engine("ranger", num.threads = cores)</code> auswählen, dass die Berechnung parallel verlaufen soll. Besonders auf Großrechnern macht die parallele Berechnung am meisten Sinn.</p>
</div>
</div>
</div>
<p>Auch hier ist es so, dass es verschiedene Algorithmen für den Random Forest gibt. Wir nehmen hier dann den <code>ranger</code> Algorithmus. Du kannst wie immer schauen, welche Algorithmen es noch gibt und auch wiederum verschiedene Algorithmen ausprobieren. In jedem Baum sollen drei Prädiktoren (<code>mtry = 3</code>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<code>min_n = 10</code>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<code>trees = 1000</code>). Darüber hinaus wollen wir uns auch die <em>Variable Importance</em> wiedergeben lassen. Die Variable Importance beschreibt, wie gut ein Prädiktor über alle Bäume des Waldes, in der Lage war Splits in möglichst reine Knoten durchzuführen. Ein Prädiktor mit einer hohen Variable Importance, ist also besonders geeignet für gute Splits mit hoher Reinheit.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ranger_mod <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="dv">3</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>ranger_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ranger_mod) <span class="sc">|&gt;</span> </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <code>fit()</code> unser Modell anpassen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>ranger_fit <span class="ot">&lt;-</span> ranger_wflow <span class="sc">|&gt;</span> </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In der <a href="#fig-class-rf-07" class="quarto-xref">Abbildung&nbsp;<span>73.7</span></a> sehen wir dann die Variable Importance sortiert für alle Prädiktoren. Ganz wichtig, die Variable Importance ist nicht numerisch zu interpretieren und auch nicht über verschiedene Datensäze hinweg. Wir können nur die Variable Importance von einem Datensatz anschauen und dort sehen welche Variablen den meisten Einfluss haben. Wir sehen also, dass die Körpergröße eine sehr große Wichtigkeit hat um die Männer von den Frauen in den Gummibärchendaten zu trennen. Das macht auch Sinn. Frauen und Männer sind nun mal unterschiedlich groß. Nicht mehr so wichtig ist das Alter und das Semester. Beide Prädiktoren haben einen ehr geringeren Einfluss auf die Aufteilung der beiden Geschlechter. Der Lieblingsgeschmack tut bei der Einteilung in Männer und Frauen nichts zur Sache.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>ranger_fit <span class="sc">|&gt;</span> </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vip</span>(<span class="at">num_features =</span> <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-07" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-07-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" data-glightbox="description: .lightbox-desc-8"><img src="classification-randomforest_files/figure-html/fig-class-rf-07-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.7— Visualisierung der <em>Variable Importance</em> aus unseren <code>ranger</code> Algorithmus.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser Modell auf den Testdatensatz anwenden und schauen, wie gut der Random Forest unsere Geschlechter vorhersagen kann.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>ranger_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(ranger_fit, gummi_test_data ) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nun schauen wir uns an wie gut die Klassifizierung mit dem <code>ranger</code> Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ranger_cm <span class="ot">&lt;-</span> ranger_aug <span class="sc">|&gt;</span> </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>ranger_cm</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 75 12
         w 16 72</code></pre>
</div>
</div>
<p>Ja, das sieht ähnlich gut aus wie der <code>rpart</code> Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>ranger_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.84 
 2 kap                  binary         0.680
 3 sens                 binary         0.824
 4 spec                 binary         0.857
 5 ppv                  binary         0.862
 6 npv                  binary         0.818
 7 mcc                  binary         0.681
 8 j_index              binary         0.681
 9 bal_accuracy         binary         0.841
10 detection_prevalence binary         0.497
11 precision            binary         0.862
12 recall               binary         0.824
13 f_meas               binary         0.843</code></pre>
</div>
</div>
<p>Wir besprechen wie beim <code>rpart</code> Algorithmus nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 84% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. Damit sind wir mit dem Random Forest Algorithmus soweit durch und wir schauen uns jetzt einen etwas komplexeren xgboost Algorithmus an.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>ranger_aug <span class="sc">|&gt;</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-03" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-03-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" data-glightbox="description: .lightbox-desc-9"><img src="classification-randomforest_files/figure-html/fig-class-rf-03-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.8— ROC Kurve für den Random Forest mit dem <code>ranger</code> Algorithmus.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Kann ich auch eine Kreuzvalidierung und Tuning für Random Forest durchführen?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ja, kannst du. Wenn du <em>nur</em> eine Kreuzvalidierung durchführen willst, findest du alles im <a href="classification-knn.html" class="quarto-xref"><span>Kapitel 72</span></a> für den <span class="math inline">\(k\)</span>-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den Random Forest Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</p>
<p>Wenn du also den Random Forest Algorithmus auch tunen willst, dann schaue einfach weiter unten nochmal bei dem Tuning des xgboost Algorithmus rein. Es ändert sich kaum was für die Auwahl der <a href="https://parsnip.tidymodels.org/reference/details_rand_forest_ranger.html">Tuning Parameter vom Random Forest Algorithmus</a>.</p>
</div>
</div>
</section>
<section id="sec-xgboost" class="level2" data-number="73.5">
<h2 data-number="73.5" class="anchored" data-anchor-id="sec-xgboost"><span class="header-section-number">73.5</span> Gradient boosting mit xgboost</h2>
<p>Als letztes Beispiel für Entscheidungsbäume schauen wir uns das Boosting an. Auch hier haben wir es wieder mit einem Wald an Entscheidungsbäumen zu tun, die wir auch wieder zusammenfassen wollen. Wir verlassen uns also nicht auf die Klassifikation von einem Baum, sondern nehmen die Informationen von vielen Bäumen zusammen. Was ist jetzt der Unterschied zu einem Random Forest? Bei einem Random Forest bauen wir uns im Prinzip hunderte einzelne Bäume und trainieren darauf den Algorithmus. Am Ende fassen wir dann alle Bäume für die Vorhersage zusammen. Beim Boosting nutzen wir die Information des ersten Baumes für das Wachstum des zweiten Baumes und so weiter. Das Boosting verkettet also die Informationen der einzelnen Bäume zu einem kontinuierlichen Lernen. Daher sind Bossting Algorithmen meist sehr gute Klassifizierer.</p>
<p>Wir unterscheiden beim Boosting grob in zwei Kategorien. Zum einen gibt es das adaptive Boosting und das gradient Boosting. Beim adaptiven Boosting erhalten die Beobachtungen über die verschiedenen Klassifizierungsschritte unterschiedliche Gewichte für ihre Bedeutung. In <a href="#fig-class-adaboost" class="quarto-xref">Abbildung&nbsp;<span>73.9</span></a> sehen wir ein Beispiel für den <code>adaboost</code> Algorithmus. Wir haben einen ursprünglichen Datensatz mit blauen und roten Beobachtungen. Wir wollen nun diese Beobachtungen voneinander trennen und damit einen Klassifizierer bauen. Wir fangen mit einem simplen Entscheidungsbaum an, der nur einen Split durchführt. Jetzt haben wir zwei falsch klassifizierte blaue Beobachtungen und eine falsche rote Beobachtung. Nun erhöhen wir das Gewicht dieser drei Beobachtungen. Der nächste Klassifizierer soll nun insbesondere auf diese drei Beobachtungen achten. Wir erhalten daher einen anderen Split und damit zwei blaue Beobachtungen die nicht richtig klassifiziert wurden. Wir erhöhen wieder das Gewicht der beiden falsch klassifizierten blauen Beobachtungen. Der dritte Klassifizierer schafft es jetzt die beiden blauen Beobachtungen gut von den roten Beobachtungen zu trennen. Wir stoppen jetzt hier und bringen alle Klassifiziererregeln, also wo der Split liegen soll, in einen Klassifizierer zusammen.</p>
<div id="fig-class-adaboost" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-adaboost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-xgboost.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" data-glightbox="description: .lightbox-desc-10"><img src="images/class-xgboost.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-adaboost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.9— Darstellung von adaptive Boosting an drei Klassifizieren, die nacheinander auf die neu gewichteten Daten angewendet werden. Am Ende werden alle drei Klassifizierer dann in einen Klassifizierer kombiniert.
</figcaption>
</figure>
</div>
<p>In der <a href="#fig-class-gradientboost" class="quarto-xref">Abbildung&nbsp;<span>73.10</span></a> sehen wir die Idee des gradient Boosting einmal dargestellt. Die Idee ist recht simple. Wir wollen wieder nacheinander einen Klassifizierer auf schon klassifizierte Daten anwenden. Wir wollen also das unser zweiter Klassifizierer von dem ersten Klassifizier lernt. Wie machen wir das? Indem wir im ersten Schritt unsere Daten klassifizieren. Wir machen das mit einem Entscheidungsbaum, der mehrere Splits durchführt, die wir dann zu einer eckigen Graden zusammenfassen. Dann haben wir aber einen Fehler als Abstand zu den Splits oder eben zu der Graden. Diese Abstände übertragen wir dann in einen neuen Datensatz auf dem wir dann den nächsten Entscheidungsbaum wachsen lassen. Wir reduzieren also den Fehler des ersten Klassifizierers durch den zweiten Klassifizierer. Dann übertragen wir den Fehler des zweiten Klassifizierers in einen neuen Datensatz und lassen den dritten Klassifizierer den Fehler weiter reduzieren. Am Ende kombinieren wir alle drei Klassifizierer in ein Modell. Durch das gradient Boosting erhalten wir ziemlich gute Entscheidungsbäume, die in der Lage sind sehr schnell und effizient eine Vorhersage zu treffen.</p>
<div id="fig-class-gradientboost" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-gradientboost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/class-xgboost-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" data-glightbox="description: .lightbox-desc-11"><img src="images/class-xgboost-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-gradientboost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.10— Darstellung von gradient Boosting an drei Klassifizieren, die nacheinander auf die <em>Fehler</em> des vorherigen Klassifizierers angewendet werden. Beachte die Nulllinie bei dem Klassifizierer zwei und drei.
</figcaption>
</figure>
</div>
<p>Nach dieser theoretischen Einführung wollen wir uns einmal mit der Implementierung beschäftigen. Wir nutzen hier einmal die bekannten Parameter aus dem Random Forest Algorithmus um unseren <code>xgboost</code> Algorithmus zu trainieren. Wie wir gleich noch im Tuning sehen werden, hatr der <code>xgboost</code> Algorithmus noch mehr Parameter an denen du schrauben kannst. In jedem Baum sollen drei Prädiktoren (<code>mtry = 3</code>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<code>min_n = 10</code>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<code>trees = 1000</code>).</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>xgboost_mod <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">mtry =</span> <span class="dv">3</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"xgboost"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>xgboost_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(xgboost_mod) <span class="sc">|&gt;</span> </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <code>fit()</code> unser Modell anpassen. Es ist eine wahre Freude. Ich mache das ja jetzt auch schon hier eine Weile im Skript und es ist echt super, wie gut das funktioniert.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>xgboost_fit <span class="ot">&lt;-</span> xgboost_wflow <span class="sc">|&gt;</span> </span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wie auch beim Random Forest Algorithmus können wir uns beim xgboost Algorithmus die Variable Importance wiedergeben lassen. Die Wichtigkeit der Variablen wird in xgboost anhand von drei verschiedenen <em>Wichtigkeiten</em> für eine Variable berechnet. Hier unterscheidet sich dann der Algorithmus xgboost von dem Random Forest Algorithmen. Achtung, wir können nicht einfach die Variable Importance von einem Random Forest Algorithmus mit der eines xgboost Algorithmus vergleichen. Wir kriegen hier andere Werte zurück, die wir dann auch anders interpretieren können.</p>
<ul>
<li><strong>Gain</strong> ist der relative Beitrag der entsprechenden Variable zum entgültigen Modell. Wir addieren dafür den Beitrag der Variable für die Splits für jeden Baum auf. Eine höhere Punktzahl deutet darauf hin, dass die Variable für die Vorhersage des Baums wichtiger ist. Die Variable war in der Lage die Klassen gut voneinander zu trennen.</li>
<li><strong>Cover</strong> ist die relative Beobachtung, die mit einem Prädiktor verbunden ist. Also der Anteil der Beobachtungen, die mit dieser Variable zusammenhängen. Nehmen wir an Merkmal <span class="math inline">\(X_1\)</span> wird dazu verwendet, um einen Terminalknoten für 10 Beobachtungen in einem Baum zu erschaffen. Im in einem weiteren Baum ist es ein Terminalkonten mit 20 Beobachtungen. Damit haben wir 30 absolute Beobachtungen, die mit Merkmal <span class="math inline">\(X_1\)</span> verbunden sind. Die relative Beobachtung ist dann 30 geteilt durch die Summe aller absoluten Beobachtungen für alle Merkmale.</li>
<li><strong>Häufigkeit</strong> bezieht sich auf die relative Häufigkeit, mit der eine Variable in den zusammengestellten Bäumen vorkommt. Nehmen wir an Merkmal <span class="math inline">\(X_1\)</span> kommt in Baum A in einem Split und in Baum B in zwei Splits vor. Die absolute Häufigkeit von Merkmal <span class="math inline">\(X_1\)</span> ist 3 und die relative Häufigkeit ist dann 3 durch die Summe aller absoluten Vorkommen für alle Merkmale.</li>
</ul>
<p>Schauen wir uns also einmal die Kriterien der Variable Importance für unsere Gummibärchendaten einmal an. Gehen wir mal die Parameter <code>gain</code>, <code>cover</code> und <code>frequency</code> einmal für unsere Körpergröße durch. Zuerst hat die Körpergröße den höchsten Wert in <code>gain</code> mit <span class="math inline">\(0.84\)</span>. Da wir das Gain auf 1 skaliert haben, macht die Körpergröße 84% des gesamten Gain in dem Modell aus. Daher wissen wir, dass die Körpergröße einen überaus bedeutenden Anteil an der Vorhersage des Geschlechts hat. Im Weiteren sehen wir an dem Parameter <code>cover</code>, dass in 34% der Beobachtungen ein Split mit der Körpergröße <em>vorausgeht</em>. Das heißt, 34% der Beobachtungen wurden anhand der Körpergröße aufgeteilt. Da wir nicht wissen wie viele Splits es ingesamt gab, muss man dieses Wert immer etwas vorsichtig bewerten. Die <code>frequency</code> teilt uns mit, dass in 33% der der Splits auch die Körpergröße vor kam. Wir sehen, die Körpergröße ist wichtig für die Vorhersage des Geschlechts. Wenn Variablen fehlen, dann haben diese keinen Einfluss auf die Klassifikation gehabt.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>xg_imp <span class="ot">&lt;-</span> xgboost_fit <span class="sc">|&gt;</span> </span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_fit_parsnip</span>() <span class="sc">%$%</span> </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> fit) <span class="sc">|&gt;</span> </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.numeric), round, <span class="dv">2</span>))</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>xg_imp</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>              Feature  Gain Cover Frequency
               &lt;char&gt; &lt;num&gt; &lt;num&gt;     &lt;num&gt;
1:             height  0.78  0.33      0.34
2:                age  0.11  0.28      0.28
3:           semester  0.07  0.22      0.22
4: most_liked_darkred  0.02  0.11      0.12
5:   most_liked_green  0.01  0.05      0.04
6:   most_liked_white  0.00  0.00      0.00</code></pre>
</div>
</div>
<p>In der <a href="#fig-class-rf-08" class="quarto-xref">Abbildung&nbsp;<span>73.11</span></a> sehen wir dann die Variable Importance sortiert für alle Prädiktoren und eingeteilt in Cluster. Die Funktion <code>xgb.ggplot.importance()</code> versucht ähnlich bedeutende Prädiktoren in gleiche Cluster zuzuordnen.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>xg_imp <span class="sc">|&gt;</span> </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.ggplot.importance</span>() <span class="sc">+</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_okabeito</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-08" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-08-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" data-glightbox="description: .lightbox-desc-12"><img src="classification-randomforest_files/figure-html/fig-class-rf-08-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.11— Visualisierung der <em>Variable Importance</em> aus unseren <code>xgboost</code> Algorithmus. Wir sehen, dass sich grob drei Gruppen für Bedeutung der Variablen für die Klassifikation gebildet haben.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser xgboost Modell auf den Testdatensatz anwenden und schauen, wie gut das gradient Boosting unsere Geschlechter vorhersagen kann.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>xgboost_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(xgboost_fit, gummi_test_data ) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nun schauen wir uns an wie gut die Klassifizierung mit dem xgboost Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>xgboost_cm <span class="ot">&lt;-</span> xgboost_aug <span class="sc">|&gt;</span> </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>xgboost_cm</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 75 11
         w 16 73</code></pre>
</div>
</div>
<p>Ja, das sieht ähnlich gut aus wie der Random Forest Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>xgboost_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.846
 2 kap                  binary         0.692
 3 sens                 binary         0.824
 4 spec                 binary         0.869
 5 ppv                  binary         0.872
 6 npv                  binary         0.820
 7 mcc                  binary         0.693
 8 j_index              binary         0.693
 9 bal_accuracy         binary         0.847
10 detection_prevalence binary         0.491
11 precision            binary         0.872
12 recall               binary         0.824
13 f_meas               binary         0.847</code></pre>
</div>
</div>
<p>Wier vorher schon besprechen wir nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 86% richtig klassifizierter Geschlechter. Besonders die Sensitivität ist mit 92% sehr gut. Die Sensitivität gibt ja an, wie zuverlässig unser xgboost Algorithmus erkennt, ob man eine Frau ist. Die Spezifität ist etwas niedriger, also die Fähigkeit die Männer auch als Männer zu erkennen. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt sehr guter Wert. Da sind wir noch besser als beim Random Forest.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. In den folgenden Schritten wollen wir einmal den xgboost Algorithmus tunen und schauen, ob wir noch bessere Ergebnisse für die Klassifikation mit anderen Parametern für den Algorithmus hin bekommen.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>xgboost_aug <span class="sc">|&gt;</span> </span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-04" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-04-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" data-glightbox="description: .lightbox-desc-13"><img src="classification-randomforest_files/figure-html/fig-class-rf-04-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.12— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Kann ich auch eine Kreuzvalidierung für xgboost durchführen?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ja, kannst du. Wenn du <em>nur</em> eine Kreuzvalidierung durchführen willst, findest du alles im <a href="classification-knn.html" class="quarto-xref"><span>Kapitel 72</span></a> für den <span class="math inline">\(k\)</span>-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den xgboost Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</p>
</div>
</div>
</section>
<section id="tuning" class="level2" data-number="73.6">
<h2 data-number="73.6" class="anchored" data-anchor-id="tuning"><span class="header-section-number">73.6</span> Tuning</h2>
<p>Was heißt Tuning? Wie bei einem Auto können wir an verschiedenen Stellschrauben bei einem mathematischen Algorithmus schrauben. Welche Schrauben und Teile das sind, hängt dann wieder vom Algorithmus ab. Im Falle des xgboost Algorithmus können wir an folgenden Parametern drehen und jeweils schauen, was dann mit unserer Vorhersage passiert. Insgesamt hat der <a href="https://parsnip.tidymodels.org/reference/details_boost_tree_xgboost.html">xgboost Algorithmus acht Tuningparameter</a>, wir wählen jetzt für uns hier drei aus. Ich nehme hier auch nur drei Parameter, da sich dann drei Parameter noch sehr gut visuell darstellen lassen. In der Anwendung wäre dann natürlich besser alle Parameter zu tunen, aber das dauert dann auch lange.</p>
<ul>
<li><code>mtry</code>, zufällig ausgewählte Anzahl an Variablen für jeden Baum. Das heißt, für jeden Baum werden von unseren Variablen die Anzahl <code>mtry</code> zufällig ausgewählt und auf diesem kleineren Datensatz der Baum erstellt.</li>
<li><code>min_n</code>, kleinste Knotengröße, die noch akzeptiert wird. Wenn ein Knoten unter <code>min_n</code> fällt, dann endet hier das Wachstum des Baumes.</li>
<li><code>trees</code>, Anzahl der Bäume die in einem xgboost Algorithmus erstellt werden.</li>
</ul>
<p>Nun ist es so, dass wir natürlich nicht händisch alle möglichen Kombinationen von der Anzahl der ausgewählten Variablen pro Baum, der kleinsten Knotengröße und der Anzahl der Bäume berechnen wollen. Das sind ziemlich viele Kombinationen und wir kommen dann vermutlich schnell durcheinander. Deshalb gibt es die Funktion <code>tune()</code> aus dem R Paket <code>{tune}</code>, die uns einen Prozess anbietet, das Tuning automatisiert durchzuführen.</p>
<p>Als erstes müssen wir uns ein Objekt bauen, das aussieht wie ein ganz normales Modell in der Klassifikation. Aber wir ergänzen jetzt noch hinter jeder zu tunenden Option noch die Funktion <code>tune()</code>. Das sind die Parameter des Algorithmus, die wir später tunen wollen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>tune_spec <span class="ot">&lt;-</span>  <span class="fu">boost_tree</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), </span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">min_n =</span> <span class="fu">tune</span>(), </span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trees =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"xgboost"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>tune_spec</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = tune()
  min_n = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<p>Jetzt bauen wir uns den Workflow indem wir statt unserem Modell, die Tuninganweisung in den Workflow reinnehmen. Echt simpel und straightforward. Das Rezept bleibt ja das Gleiche.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>gummi_tune_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(tune_spec) <span class="sc">|&gt;</span> </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Jetzt müssen wir noch alle Kombinationen aus den drei Parametern <code>mtry</code>, <code>min_n</code> und <code>trees</code> ermitteln. Das macht die Funktion <code>grid_regular()</code>. Es gibt da noch andere Funktionen in dem R Paket <code>{tune}</code>, aber ich konzentriere mich hier auf die einfachste. Jetzt müssen wir noch die Anzahl an Kombinationen festlegen. Ich möchte für jeden Parameter fünf Werte tunen. Daher nutze ich hier die Option <code>levels = 5</code> auch damit hier die Ausführung nicht so lange läuft. Fange am besten mit <code>levels = 5</code> an und schaue, wie lange das zusammen mit der Kreuzvalidierung dann dauert. Dann kannst du die Levels noch hochschrauben. Beachte aber, dass mehr Level nur mehr <em>Zwischenschritte</em> bedeutet. Jede Option hat eine Spannweite <code>range</code>, die du dann anpassen musst, wenn du <em>höhere</em> Werte haben willst. Mehr Level würden nur mehr Zwischenschritte bedeuten. In unserem Fall weiß zum Beispiel die Funktion <code>mtry()</code> nicht, wie viele Variablen in dem Datensatz sind. Wir müssen also die <code>range</code> für die Anzahl an ausgewählten Variablen selber setzen. Ich wähle daher eine Variable bis vier Variablen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>gummi_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)),</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">trees</span>(),</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">min_n</span>(),</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">levels =</span> <span class="dv">5</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Das Tuning nur auf dem Trainingsdatensatz durchzuführen ist nicht so eine gute Idee. Deshalb nutzen wir hier auch die Kreuzvalidierung. Eigentlich ist eine 10-fache Kreuzvalidierung mit <span class="math inline">\(v=10\)</span> besser. Das dauert mir dann aber hier im Skript viel zu lange. Deshalb habe ich hier nur <span class="math inline">\(v=5\)</span> gewählt. Wenn du das Tuning rechnest, nimmst du natürlich eine 10-fach Kreuzvalidierung.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>gummi_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(gummi_train_data, <span class="at">v =</span> <span class="dv">5</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Nun bringen wir den Workflow zusammen mit dem Tuninggrid und unseren Sets der Kreuzvaidierung. Daher pipen wir den Workflow in die Funktion <code>tune_grid()</code>. Als Optionen brauchen wir die Kreuzvaldierungsdatensätze und das Tuninggrid. Wenn du <code>control_grid(verbose = TRUE)</code> wählst, dann erhälst du eine Ausgabe wie weit das Tuning gerade ist. <strong>Achtung!</strong>, das Tuning dauert seine Zeit. Im Falle des xgboost Algorithmus dauert das Tuning zwar nicht so lange, aber immer noch ein paar Minuten. Wenn du dann alle acht Parameter des xgboost Algorithmustunen wollen würdest, dann würde die Berechnung sehr viel länger dauern. Du kannst das Ergebnis des simpleren Tunings auch in der Datei <code>gummi_xgboost_tune_res.rds</code> finden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="ot">&lt;-</span> gummi_tune_wflow <span class="sc">|&gt;</span> </span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">tune_grid</span>(<span class="at">resamples =</span> gummi_folds,</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">grid =</span> gummi_grid,</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">control =</span> <span class="fu">control_grid</span>(<span class="at">verbose =</span> <span class="cn">FALSE</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Damit du nicht das Tuning durchlaufen lassen musst, habe ich das Tuning in die Datei <code>gummi_xgboost_tune_res.rds</code> abgespeichert und du kannst dann über die Funktion <code>read_rds()</code> wieder einlesen. Dann kannst du den R Code hier wieder weiter ausführen.</p>
<p>Nachdem das Tuning durchgelaufen ist, können wir uns über die Funktion <code>collect_metrics()</code>, die Ergebnisse des Tunings für jede Kombination der drei Parameter <code>mtry</code>, <code>min_n</code> und <code>trees</code> wiedergeben lassen. Diese Ausgabe ist super unübersichtlich. Ich habe mich ja am Anfange des Abschnitts auch für drei Tuningparameter entschieden, da sich dann diese drei Parameter noch gut visualisieren lassen. Deshalb einmal die Abbildung der mittleren Accuarcy und der mittleren AUC-Werte über alle Kreuzvalidierungen.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">|&gt;</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">trees =</span> <span class="fu">as_factor</span>(trees),</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">min_n =</span> <span class="fu">as_factor</span>(min_n)) <span class="sc">|&gt;</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mtry, mean, <span class="at">color =</span> min_n, <span class="at">linetype =</span> trees)) <span class="sc">+</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_number</span>()) <span class="sc">+</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_okabeito</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-05" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-05-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" data-glightbox="description: .lightbox-desc-14"><img src="classification-randomforest_files/figure-html/fig-class-rf-05-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.13— Tuning Kurven für den <code>xgboost</code> Algorithmus.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Damit wir nicht händisch uns die beste Kombination raussuchen müssen, können wir die Funktion <code>show_best()</code> nutzen.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in show_best(gummi_tune_res): No value of `metric` was given; "roc_auc"
will be used.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 9
   mtry trees min_n .metric .estimator  mean     n std_err .config              
  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
1     4   500    11 roc_auc binary     0.891     5 0.00637 Preprocessor1_Model0…
2     2  2000    11 roc_auc binary     0.890     5 0.00963 Preprocessor1_Model0…
3     4  1500    11 roc_auc binary     0.890     5 0.00626 Preprocessor1_Model0…
4     4  1000    11 roc_auc binary     0.890     5 0.00631 Preprocessor1_Model0…
5     2   500    11 roc_auc binary     0.890     5 0.00912 Preprocessor1_Model0…</code></pre>
</div>
</div>
<p>Das war die Funktion <code>show_best()</code> aber wir können uns auch die gleich die besten Parameter nach der Accuracy raus ziehen. Das Rausziehen der besten Parameter macht für uns die Funktion <code>select_best()</code>.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>best_xgboost <span class="ot">&lt;-</span> gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_best</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in select_best(gummi_tune_res): No value of `metric` was given;
"roc_auc" will be used.</code></pre>
</div>
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>best_xgboost</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
   mtry trees min_n .config               
  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 
1     4   500    11 Preprocessor1_Model082</code></pre>
</div>
</div>
<p>Wir sehen, dass wir <code>mtry = 3</code> wählen sollten. Dann müssen wir als Anzahl der Bäume <code>trees = 1000</code> nutzen. Die minimale Anzahl an Beobachtungen pro Knoten ist dann <code>11</code>. Müssen wir jetzt die Zahlen wieder in ein Modell eingeben? Nein, müssen wir nicht. Mit der Funktion <code>finalize_workflow()</code> können wir dann die besten Parameter aus unserem Tuning gleich mit dem Workflow kombinieren. Dann haben wir unseren finalen, getunten Workflow. Du siehst dann auch in der Ausgabe, dass die neuen Parameter in dem xgboost Algorithmus übernommen wurden.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>final_gummi_wf <span class="ot">&lt;-</span> gummi_tune_wflow <span class="sc">|&gt;</span> </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_xgboost)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>final_gummi_wf </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow ════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: boost_tree()

── Preprocessor ────────────────────────────────────────────────────────────────
5 Recipe Steps

• step_impute_mean()
• step_impute_bag()
• step_range()
• step_dummy()
• step_nzv()

── Model ───────────────────────────────────────────────────────────────────────
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 4
  trees = 500
  min_n = 11

Computational engine: xgboost </code></pre>
</div>
</div>
<p>Jetzt bleibt uns nur noch der letzte Fit übrig. Wir wollen unseren finalen, getunten Workflow auf die Testdaten anwenden. Dafür gibt es dann auch die passende Funktion. Das macht für uns die Funktion <code>last_fit()</code>, die sich dann die Informationen für die Trainings- und Testdaten aus unserem Datensplit von ganz am Anfang extrahiert.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>final_fit <span class="ot">&lt;-</span> final_gummi_wf <span class="sc">|&gt;</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">last_fit</span>(gummi_data_split) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Da wir immer noch eine Kreuzvaldierung rechnen, müssen wir dann natürlich wieder alle Informationen über alle Kreuzvaldierungsdatensätze einsammeln. Dann erhalten wir unsere beiden Gütekriterien für die Klassifikation des Geschlechts unser Studierenden nach dem xgboost Algorithmus. Die Zahlen sind schon gut für echte Daten. Eine Accuracy von 84% bedeutet das wir über acht von zehn Studierenden richtig klassifizieren. Die AUC ist auch schon fast hervorragend, wir bringen kaum Label durcheinander.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>final_fit <span class="sc">|&gt;</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 4
  .metric     .estimator .estimate .config             
  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy    binary         0.834 Preprocessor1_Model1
2 roc_auc     binary         0.932 Preprocessor1_Model1
3 brier_class binary         0.106 Preprocessor1_Model1</code></pre>
</div>
</div>
<p>Dann bleibt uns nur noch die ROC Kurve zu visualisieren. Da wir wieder etwas faul sind, nutzen wir die Funktion <code>autoplot()</code>. Als Alternative geht natürlich auch das <a href="https://web.expasy.org/pROC/screenshots.html">R Paket <code>{pROC}</code></a>, was eine Menge mehr Funktionen und Möglichkeiten bietet.</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>R Code [zeigen / verbergen]</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>final_fit <span class="sc">|&gt;</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_predictions</span>() <span class="sc">|&gt;</span> </span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-class-rf-06" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-class-rf-06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="classification-randomforest_files/figure-html/fig-class-rf-06-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" data-glightbox="description: .lightbox-desc-15"><img src="classification-randomforest_files/figure-html/fig-class-rf-06-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-rf-06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;73.14— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus nach der Kreuvalidierung und dem Tuning.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Eine gute ROC Kurve würde senkrecht nach oben gehen und dann waagrecht nach rechts. Dann hätten wir eine AUC von 1 und eine perfekte Separation der beiden Label durch unseren Algorithmus. Unser Algorithmus würde jedem weiblichen Studierenden in dem Testdatensatz korrekt dem Geschlecht <code>w</code> zuweisen. Da wir eine ROC Kurve hier vorliegen haben, die sehr weit weg von der Diagonalen ist, haben wir sehr viele richtig vorhergesagte Studierende in unseren Testdaten. Unser Modell funktioniert um das Geschlecht von Studierenden anhand unserer Gummibärchendaten vorherzusagen.</p>


<!-- -->

<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-2">Abbildung&nbsp;73.1— Darstellung des Anwachsen des Entscheidungsbaumes. Links sind die beiden Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> als Koordinatensysten dargestellt. Die Punkte stllen die Beobachtungen mit den jeweiligen Label weiß und schwarz dar. Rechts ist der Knoten <span class="math inline">\(t_1\)</span> dargestellt, der alle Beobachtungen beinhaltet..</span>
<span class="glightbox-desc lightbox-desc-3">Abbildung&nbsp;73.2— Darstellung des ersten Splits anhand des Prädiktors <span class="math inline">\(X_1\)</span>. Wir wählen den Wert <span class="math inline">\(c_1\)</span> für den Split so, dass wir möglichst reine Knoten produzieren. Wir erhalten zwei neue Knoten <span class="math inline">\(t_2\)</span> und <span class="math inline">\(t_3\)</span>. Der Knoten <span class="math inline">\(t_3\)</span> ist maximal rein und wird daher zu einem Terminalknoten.</span>
<span class="glightbox-desc lightbox-desc-4">Abbildung&nbsp;73.3— Darstellung des zweiten Splits anhand des Prädiktors <span class="math inline">\(X_2\)</span>. Wir wählen wiederum den Wert <span class="math inline">\(c_2\)</span> für den Split so, dass wir möglichst reine Knoten erhalten. So erhalten wir zwei neue Knoten <span class="math inline">\(t_4\)</span> und <span class="math inline">\(t_5\)</span>. Da nun <span class="math inline">\(t_4\)</span> ebenfalls ein reiner Knoten ist, wird der Knoten <span class="math inline">\(t_4\)</span> ebenfalls zu einem Terminalknoten. Wir stoppen hier das Wachstum, da mir eine mindest Anzahl von vier Beobachtungen in den Knoten erreicht haben.</span>
<span class="glightbox-desc lightbox-desc-5">Abbildung&nbsp;73.4— Darstellung der Vorhersage einer neuen Beobachtung mit Werten für die Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. Unsere neue Beobachtung <code>?</code> fällt in den Terminalknoten <span class="math inline">\(t_5\)</span>. Dort zählen wir die schwarzen Kreise. Wir stellen fest, dass die neue Beobachtung mit 25% Wahrscheinlichkeit ein Fall und damit schwarz ist. Daher ist die neue Beobachtung weiß.</span>
<span class="glightbox-desc lightbox-desc-6">Abbildung&nbsp;73.5— ROC Kurve für den Entscheidungsbaum mit dem <code>rpart</code> Algorithmus.</span>
<span class="glightbox-desc lightbox-desc-7">Abbildung&nbsp;73.6— Visualisierung des finalen <code>rpart</code> Entscheidungsbaums.</span>
<span class="glightbox-desc lightbox-desc-8">Abbildung&nbsp;73.7— Visualisierung der <em>Variable Importance</em> aus unseren <code>ranger</code> Algorithmus.</span>
<span class="glightbox-desc lightbox-desc-9">Abbildung&nbsp;73.8— ROC Kurve für den Random Forest mit dem <code>ranger</code> Algorithmus.</span>
<span class="glightbox-desc lightbox-desc-10">Abbildung&nbsp;73.9— Darstellung von adaptive Boosting an drei Klassifizieren, die nacheinander auf die neu gewichteten Daten angewendet werden. Am Ende werden alle drei Klassifizierer dann in einen Klassifizierer kombiniert.</span>
<span class="glightbox-desc lightbox-desc-11">Abbildung&nbsp;73.10— Darstellung von gradient Boosting an drei Klassifizieren, die nacheinander auf die <em>Fehler</em> des vorherigen Klassifizierers angewendet werden. Beachte die Nulllinie bei dem Klassifizierer zwei und drei.</span>
<span class="glightbox-desc lightbox-desc-12">Abbildung&nbsp;73.11— Visualisierung der <em>Variable Importance</em> aus unseren <code>xgboost</code> Algorithmus. Wir sehen, dass sich grob drei Gruppen für Bedeutung der Variablen für die Klassifikation gebildet haben.</span>
<span class="glightbox-desc lightbox-desc-13">Abbildung&nbsp;73.12— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus.</span>
<span class="glightbox-desc lightbox-desc-14">Abbildung&nbsp;73.13— Tuning Kurven für den <code>xgboost</code> Algorithmus.</span>
<span class="glightbox-desc lightbox-desc-15">Abbildung&nbsp;73.14— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus nach der Kreuvalidierung und dem Tuning.</span>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./classification-knn.html" class="pagination-link" aria-label="$k$ nearest neighbor">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title"><span class="math inline">\(k\)</span> nearest neighbor</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./classification-svm.html" class="pagination-link" aria-label="Support vector machines">
        <span class="nav-page-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Support vector machines</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Quellcode</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb75" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo = FALSE}</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="in">pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="fu"># Decision trees {#sec-class-tree}</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>*Letzte Änderung am `r format(fs::file_info("classification-randomforest.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>In diesem Kapitel wollen wir uns mit Entscheidungsbäumen (eng. *decision trees*) beschäftigen. Wie oft gibt es auch bei der Anwendung von Entscheidungsbäumen eine Menge Varianten. Wir wollen uns in diesem Kapitel eine erste Übersicht geben und du kannst dann ja schauen, welche Varianten es noch von den Entscheidungsbäumen gibt. Wichtig ist zu wissen, unsere Bäume spalten sich immer nur in zwei Äste auf.</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>::: column-margin</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/angel_01.png)</span>{fig-align="center" width="50%"}</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>Wir werden uns hier mit der Anwendung beschäftigen. Wie immer lassen wir daher *tiefere* mathematische Überlegungen weg.</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In @sec-rpart schauen wir uns *einen* Entscheidungsbaum an. Wir teilen nacheinander unsere Beobachtungen immer weiter anhand unser Prädiktoren in zwei Gruppen auf, bis wir nur noch Gruppen haben, die fast nur noch aus einer Klasse des Labels bestehen.</span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In @sec-rf schauen wir uns ein Ensemble von Entscheidungsbäumen an. Wir lassen daher nicht einen sondern hunderte von Entscheidungsbäumen wachsen. Damit wir nicht immer den gleichen Baum auf den gleichen Daten wachsen lassen, wählen zufällig Beobachtungen und Variablen aus, die wir zum Erstellen der Bäume nutzen. Wir lassen einen Random Forest wachsen.</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In @sec-xgboost betrachten wir eine komplexere Implementierung der Random Forest. Wir nutzen hier Gradient Boosting um die Bäume noch besser anhand unseres Trainingsdatensatzes wachsen zu lassen.</span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>Alle drei Algorithmen gehen wir jetzt einmal durch. Dabei können wir bei einem Entscheidunsgbaum noch recht gut nachvollziehen, was dort eigentlich passiert. Bei mehreren Bäumen zusammen, können wir nur noch schematisch nachvollziehen was die einzelnen Schritte in der Modellbildung sind.</span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## Genutzte R Pakete</span></span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>Wir wollen folgende R Pakete in diesem Kapitel nutzen.</span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo = TRUE}</span></span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a><span class="in">#| message: false</span></span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a><span class="in">pacman::p_load(tidyverse, tidymodels, magrittr, </span></span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a><span class="in">               janitor, vip, rpart.plot, see,</span></span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a><span class="in">               xgboost, Ckmeans.1d.dp, conflicted)</span></span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a><span class="in">##</span></span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(2025429)</span></span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-35"><a href="#cb75-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-36"><a href="#cb75-36" aria-hidden="true" tabindex="-1"></a>An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.</span>
<span id="cb75-37"><a href="#cb75-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-38"><a href="#cb75-38" aria-hidden="true" tabindex="-1"></a><span class="fu">## Daten</span></span>
<span id="cb75-39"><a href="#cb75-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-40"><a href="#cb75-40" aria-hidden="true" tabindex="-1"></a>Bei dem vorherigen Beispielen haben wir immer unseren Datensatz zu den infizierten Ferkeln genutzt. In diesem Kapitel wolle wir uns aber mal auf einen echten Datensatz anschauen. Wir nutzen daher einmal den Gummibärchendatensatz. Als unser Label und daher als unser Outcome nehmen wir das Geschlecht <span class="in">`gender`</span>. Dabei wollen wir dann die weiblichen Studierenden vorhersagen. Im Weiteren nehmen wir nur die Spalte Geschlecht sowie als Prädiktoren die Spalten <span class="in">`most_liked`</span>, <span class="in">`age`</span>, <span class="in">`semester`</span>, und <span class="in">`height`</span>.</span>
<span id="cb75-41"><a href="#cb75-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-44"><a href="#cb75-44" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-45"><a href="#cb75-45" aria-hidden="true" tabindex="-1"></a>gummi_tbl <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"data/gummibears.xlsx"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-46"><a href="#cb75-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gender =</span> <span class="fu">as_factor</span>(gender),</span>
<span id="cb75-47"><a href="#cb75-47" aria-hidden="true" tabindex="-1"></a>         <span class="at">most_liked =</span> <span class="fu">as_factor</span>(most_liked)) <span class="sc">|&gt;</span> </span>
<span id="cb75-48"><a href="#cb75-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(gender, most_liked, age, semester, height) <span class="sc">|&gt;</span> </span>
<span id="cb75-49"><a href="#cb75-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>(gender)</span>
<span id="cb75-50"><a href="#cb75-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-51"><a href="#cb75-51" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-52"><a href="#cb75-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-53"><a href="#cb75-53" aria-hidden="true" tabindex="-1"></a>Wir dürfen keine fehlenden Werte in den Daten haben. Wir können für die Prädiktoren später die fehlenden Werte imputieren. Aber wir können keine Labels imputieren. Daher entfernen wir alle Beobachtungen, die ein <span class="in">`NA`</span> in der Variable <span class="in">`gender`</span> haben. Wir haben dann insgesamt $n = <span class="in">`r nrow(gummi_tbl)`</span>$ Beobachtungen vorliegen. In @tbl-gummi-model-rf sehen wir nochmal die Auswahl des Datensatzes in gekürzter Form.</span>
<span id="cb75-54"><a href="#cb75-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-57"><a href="#cb75-57" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-58"><a href="#cb75-58" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb75-59"><a href="#cb75-59" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-60"><a href="#cb75-60" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-61"><a href="#cb75-61" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-gummi-model-rf</span></span>
<span id="cb75-62"><a href="#cb75-62" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Auszug aus dem Daten zu den Gummibärchendaten.</span></span>
<span id="cb75-63"><a href="#cb75-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-64"><a href="#cb75-64" aria-hidden="true" tabindex="-1"></a>gummi_raw_tbl <span class="ot">&lt;-</span> gummi_tbl <span class="sc">|&gt;</span> </span>
<span id="cb75-65"><a href="#cb75-65" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gender =</span> <span class="fu">as.character</span>(gender),</span>
<span id="cb75-66"><a href="#cb75-66" aria-hidden="true" tabindex="-1"></a>         <span class="at">most_liked =</span> <span class="fu">as.character</span>(most_liked))</span>
<span id="cb75-67"><a href="#cb75-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-68"><a href="#cb75-68" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(<span class="fu">head</span>(gummi_raw_tbl),</span>
<span id="cb75-69"><a href="#cb75-69" aria-hidden="true" tabindex="-1"></a>      <span class="fu">rep</span>(<span class="st">"..."</span>, <span class="at">times =</span> <span class="fu">ncol</span>(gummi_raw_tbl)),</span>
<span id="cb75-70"><a href="#cb75-70" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tail</span>(gummi_raw_tbl)) <span class="sc">|&gt;</span> </span>
<span id="cb75-71"><a href="#cb75-71" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">align =</span> <span class="st">"c"</span>, <span class="st">"pipe"</span>)</span>
<span id="cb75-72"><a href="#cb75-72" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-73"><a href="#cb75-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-74"><a href="#cb75-74" aria-hidden="true" tabindex="-1"></a>Unsere Fragestellung ist damit, können wir anhand unserer Prädiktoren männliche von weiblichen Studierenden unterscheiden und damit auch klassifizieren? Um die Klassifikation mit Entscheidungsbäumen rechnen zu können brauchen wir wie bei allen anderen Algorithmen auch einen Trainings- und Testdatensatz. Wir splitten dafür unsere Daten in einer 3 zu 4 Verhältnis in einen Traingsdatensatz sowie einen Testdatensatz auf. Der Traingsdatensatz ist dabei immer der größere Datensatz. Da wir aktuell nicht so viele Beobachtungen in dem Gummibärchendatensatz haben, möchte ich mindestens 100 Beobachtungen in den Testdaten. Deshalb kommt mir der 3:4 Split sehr entgegen.</span>
<span id="cb75-75"><a href="#cb75-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-76"><a href="#cb75-76" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Im maschinellen Lernen sind alle Datensätze, die weniger als tausend Beobachtungen vorliegen haben, klein.</span><span class="co">]</span>{.aside}</span>
<span id="cb75-77"><a href="#cb75-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-80"><a href="#cb75-80" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-81"><a href="#cb75-81" aria-hidden="true" tabindex="-1"></a>gummi_data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(gummi_tbl, <span class="at">prop =</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">4</span>)</span>
<span id="cb75-82"><a href="#cb75-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-83"><a href="#cb75-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-84"><a href="#cb75-84" aria-hidden="true" tabindex="-1"></a>Wir speichern uns jetzt den Trainings- und Testdatensatz jeweils separat ab. Die weiteren Modellschritte laufen alle auf dem Traingsdatensatz, wie nutzen dann erst ganz zum Schluss einmal den Testdatensatz um zu schauen, wie gut unsere trainiertes Modell auf den neuen Testdaten funktioniert.</span>
<span id="cb75-85"><a href="#cb75-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-88"><a href="#cb75-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-89"><a href="#cb75-89" aria-hidden="true" tabindex="-1"></a>gummi_train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(gummi_data_split)</span>
<span id="cb75-90"><a href="#cb75-90" aria-hidden="true" tabindex="-1"></a>gummi_test_data  <span class="ot">&lt;-</span> <span class="fu">testing</span>(gummi_data_split)</span>
<span id="cb75-91"><a href="#cb75-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-92"><a href="#cb75-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-93"><a href="#cb75-93" aria-hidden="true" tabindex="-1"></a>Nachdem wir die Daten vorbereitet haben, müssen wir noch das Rezept mit den Vorverabreitungsschritten definieren. Wir schreiben, dass wir das Geschlecht <span class="in">`gender`</span> als unser Label haben wollen. Daneben nehmen wir alle anderen Spalten als Prädiktoren mit in unser Modell, das machen wir dann mit dem <span class="in">`.`</span> Symbol. Da wir noch fehlende Werte in unseren Prädiktoren haben, imputieren wir noch die numerischen Variablen mit der Mittelwertsimputation und die nominalen fehlenden Werte mit Entscheidungsbäumen. Es gibt wie immer noch andere Imputationsmöglichkeiten, ich habe mich jetzt aus praktischen Gründen für dies beiden Verfahren entschieden. Ich überspringe hier auch die Diagnose der Imputation, also ob das jetzt eine gute und sinnvolle Imputation der fehlenden Werte war oder nicht. Die Diagnoseschritte müsstest du im Anwendungsfall nochmal im <span class="co">[</span><span class="ot">Kapitel zur Imputation</span><span class="co">](#sec-missing)</span> nachlesen und anwenden. Dann müssen wir noch alle numerischen Variablen normalisieren und alle nominalen Variablen dummykodieren. Am Ende werde ich nochmal alle Variablen entfernen, sollte die Varianz in einer Variable nahe der Null sein.</span>
<span id="cb75-94"><a href="#cb75-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-97"><a href="#cb75-97" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-98"><a href="#cb75-98" aria-hidden="true" tabindex="-1"></a>gummi_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(gender <span class="sc">~</span> ., <span class="at">data =</span> gummi_train_data) <span class="sc">|&gt;</span> </span>
<span id="cb75-99"><a href="#cb75-99" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_mean</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb75-100"><a href="#cb75-100" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_bag</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb75-101"><a href="#cb75-101" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_range</span>(<span class="fu">all_numeric_predictors</span>(), <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-102"><a href="#cb75-102" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb75-103"><a href="#cb75-103" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb75-104"><a href="#cb75-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-105"><a href="#cb75-105" aria-hidden="true" tabindex="-1"></a>gummi_rec</span>
<span id="cb75-106"><a href="#cb75-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-107"><a href="#cb75-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-108"><a href="#cb75-108" aria-hidden="true" tabindex="-1"></a>Alles in allem haben wir ein sehr kleines Modell. Wir haben ja nur ein Outcome und vier Prädiktoren. Trotzdem sollte dieser Datensatz reichen um zu erklären wie Entscheidungsbäume funktionieren.</span>
<span id="cb75-109"><a href="#cb75-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-110"><a href="#cb75-110" aria-hidden="true" tabindex="-1"></a><span class="fu">## Entscheidungsbaum mit Rpart {#sec-rpart}</span></span>
<span id="cb75-111"><a href="#cb75-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-112"><a href="#cb75-112" aria-hidden="true" tabindex="-1"></a>Wie funktioniert nun ein Entscheidungsbaum? Ein Entscheidungsbaum besteht aus Knoten (eng. *nodes*) und Ästen (eng. *edge*). Dabei hat immer ein Knoten zwei Äste. Die Beobachtungen in einem Knoten fallen nach einer Entscheidungsregel anhand eines Prädiktors in entlang zweier Äste in zwei separate Knoten. So können wir unsere $n = <span class="in">`r nrow(gummi_tbl)`</span>$ zum Beispiel anhand des Alters in zwei Gruppen aufteilen. Wir legen willkürlich die Altersgrenze bei 22 fest.</span>
<span id="cb75-113"><a href="#cb75-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-116"><a href="#cb75-116" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-117"><a href="#cb75-117" aria-hidden="true" tabindex="-1"></a>gummi_tbl <span class="sc">|&gt;</span> </span>
<span id="cb75-118"><a href="#cb75-118" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">grp =</span> <span class="fu">if_else</span>(age <span class="sc">&gt;=</span> <span class="dv">22</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb75-119"><a href="#cb75-119" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(grp) <span class="sc">|&gt;</span> </span>
<span id="cb75-120"><a href="#cb75-120" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tabyl</span>()</span>
<span id="cb75-121"><a href="#cb75-121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-122"><a href="#cb75-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-123"><a href="#cb75-123" aria-hidden="true" tabindex="-1"></a>Wir erhalten mit diesem Split zwei Gruppen mit je $n_0 = 207$ und $n_1 = 259$ Beobachtungen. Wir haben jetzt diesen Split willkürlich gewählt. In dem Algorithmus für die Entscheidungsbäume wird dieser Schritt intern optimiert, so dass wir den besten Wert für den Alterssplit finden, der uns möglichst reine Knoten im Bezug auf das Label liefert. Wir wollen ja am Ende einen Algorithmus trainieren, der uns die Geschlechter bestmöglich auftrennt, so dass wir eine neue Beobachtung bestmöglich vorhersagen können. Wenn keine Aufteilungen in einem Knoten mehr möglich sind, dann nennen wir diesen Knoten einen Terminalknoten.</span>
<span id="cb75-124"><a href="#cb75-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-125"><a href="#cb75-125" aria-hidden="true" tabindex="-1"></a>In @fig-class-rf-01 sehen wir ein Beispiel für zwei numerische Prädiktoren $X_1$ und $X_2$. Auf der linken Seite ist das Koordinatensystem mit dreizehn Beobachtungen dargestellt. Von den dreizehn Beobachtungen sind zehn Fälle (eng. *cases*) und drei Kontrollen (eng. *control*). Wir wollen uns jetzt an dem Koordinatensystem die Idee der Splits für ein Baumwachstum veranschaulichen. Auf der rechten Seite sehen wir nämlich den ersten Knoten des Entscheidungsbaums (eng. *root node*) in dem sich alle Beobachtungen befinden. Wir wollen jetzt die Beobachtungen anhand der Prädiktoren $X_1$ und $X_2$ so aufspalten, dass für möglichst reine Knoten erhalten. Wir stoppen auch im Splitting wenn wir weniger oder gleich vier Beobachtungen nach einem Split in einem Knoten erhalten.</span>
<span id="cb75-126"><a href="#cb75-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-127"><a href="#cb75-127" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung des Anwachsen des Entscheidungsbaumes. Links sind die beiden Prädiktoren $X_1$ und $X_2$ als Koordinatensysten dargestellt. Die Punkte stllen die Beobachtungen mit den jeweiligen Label weiß und schwarz dar. Rechts ist der Knoten $t_1$ dargestellt, der alle Beobachtungen beinhaltet..](images/class-rf-01.png)</span>{#fig-class-rf-01 fig-align="center" width="100%"}</span>
<span id="cb75-128"><a href="#cb75-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-129"><a href="#cb75-129" aria-hidden="true" tabindex="-1"></a>In @fig-class-rf-02 sehen wir den ersten Split des Prädiktors $X_1$ anhand des Wertes $c_1$. Wir erhalten nach dem Split die zwei neuen Knoten $t_2$ und $t_3$. Wir haben den Split so gewählt, dass wir einen reinen Knoten $t_3$ erhalten. Da der Knoten $t_3$ jetzt nur noch Fälle enthaält, wird dieser Knoten zu einem Terminalknoten und es finden keine weiteren Aufspaltungen mehr statt. Wir machen jetzt also mit dem Knoten $t_2$ weiter.</span>
<span id="cb75-130"><a href="#cb75-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-131"><a href="#cb75-131" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung des ersten Splits anhand des Prädiktors $X_1$. Wir wählen den Wert $c_1$ für den Split so, dass wir möglichst reine Knoten produzieren. Wir erhalten zwei neue Knoten $t_2$ und $t_3$. Der Knoten $t_3$ ist maximal rein und wird daher zu einem Terminalknoten.](images/class-rf-02.png)</span>{#fig-class-rf-02 fig-align="center" width="100%"}</span>
<span id="cb75-132"><a href="#cb75-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-133"><a href="#cb75-133" aria-hidden="true" tabindex="-1"></a>In @fig-class-rf-03 sehen wir den Split durch den Prädiktor $X_2$ nach dem Wert $c_2$. Wir erhalten wieder zwei neue Knotenn $t_4$ und $t_5$. Der Knoten $t_4$ wird nach unseren Regeln wieder zu einem Terminalknoten. Wir haben nur Fälle in dem Knoten $t_4$ vorliegen. Wir stoppen auch bei dem Knoten $t_5$ unsere weitere Aufteilung, da wir hier vier oder weniger Beobachtungen vorliegen haben. Damit sind wir mit dem Split zu einem Ende gekommen.</span>
<span id="cb75-134"><a href="#cb75-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-135"><a href="#cb75-135" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung des zweiten Splits anhand des Prädiktors $X_2$. Wir wählen wiederum den Wert $c_2$ für den Split so, dass wir möglichst reine Knoten erhalten. So erhalten wir zwei neue Knoten $t_4$ und $t_5$. Da nun $t_4$ ebenfalls ein reiner Knoten ist, wird der Knoten $t_4$ ebenfalls zu einem Terminalknoten. Wir stoppen hier das Wachstum, da mir eine mindest Anzahl von vier Beobachtungen in den Knoten erreicht haben.](images/class-rf-03.png)</span>{#fig-class-rf-03 fig-align="center" width="100%"}</span>
<span id="cb75-136"><a href="#cb75-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-137"><a href="#cb75-137" aria-hidden="true" tabindex="-1"></a>In @fig-class-rf-04 sehen wir jetzt eine neue Beobachtung <span class="in">`?`</span> die mit gegebenen Werten für $X_1$ und $X_2$ in den terminalen Knoten $t_5$ fällt. Wir zählen dort die Fälle und erhalten eine Klassenzugehörigkeitswahrscheinlichkeit von 25%. Daher würden wir sagen, dass die neue Beobchtung eine Kontrolle ist. Es handelt sich damit um eine weiße Beoabchtung.</span>
<span id="cb75-138"><a href="#cb75-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-139"><a href="#cb75-139" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung der Vorhersage einer neuen Beobachtung mit Werten für die Prädiktoren $X_1$ und $X_2$. Unsere neue Beobachtung `?` fällt in den Terminalknoten $t_5$. Dort zählen wir die schwarzen Kreise. Wir stellen fest, dass die neue Beobachtung mit 25% Wahrscheinlichkeit ein Fall und damit schwarz ist. Daher ist die neue Beobachtung weiß.](images/class-rf-04.png)</span>{#fig-class-rf-04 fig-align="center" width="100%"}</span>
<span id="cb75-140"><a href="#cb75-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-141"><a href="#cb75-141" aria-hidden="true" tabindex="-1"></a>Damit haben wir einmal den simplen Fall mit zwei numerischen Prädiktoren durchgespielt. Auch haben wir wenige Beobachtungen und sind schnell zu reinen Knoten gekommen. Wenn wir jetzt natürlich sehr viel mehr Beobachtungen haben oder sehr viele Prädiktoren dann wird die Sache sehr schnell sehr rechenintensiv. Dafür haben wir dann eben R.</span>
<span id="cb75-142"><a href="#cb75-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-143"><a href="#cb75-143" aria-hidden="true" tabindex="-1"></a>Wenn wir in R einen Entscheidungsbaum rechnen wollen, dann nutzen wir die Funktion <span class="in">`decision_tree()`</span> wir wollen nur eine maximale Tiefe von 5 Knoten haben und/oder mindestens 10 Beobachtungen in einem Knoten. Je nachdem welche Bedingung wir eher erreichen. Ebenfalls können wir das Wachstum mit dem Parameter <span class="in">`cost_complexity`</span> kontrollieren. Sollte sich das Modell nicht um mindestens 0.001 verbessern, dann werden wir den nächsten Knoten nicht anlegen. Wir wählen als Engine den Algorithmus <span class="in">`rpart`</span>, da wir uns diese Art von Algorithmus gut mit dem R Paket <span class="in">`{rpart.plot}`</span> visualisieren können.</span>
<span id="cb75-144"><a href="#cb75-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-147"><a href="#cb75-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-148"><a href="#cb75-148" aria-hidden="true" tabindex="-1"></a>rpart_mod <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>(<span class="at">tree_depth =</span> <span class="dv">5</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">cost_complexity =</span> <span class="fl">0.001</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-149"><a href="#cb75-149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"rpart"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-150"><a href="#cb75-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb75-151"><a href="#cb75-151" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-152"><a href="#cb75-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-153"><a href="#cb75-153" aria-hidden="true" tabindex="-1"></a>Jetzt kommt wieder das Modell zusammen mit dem Rezept. Wir speichern wieder beides in einen Workflow.</span>
<span id="cb75-154"><a href="#cb75-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-157"><a href="#cb75-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-158"><a href="#cb75-158" aria-hidden="true" tabindex="-1"></a>rpart_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-159"><a href="#cb75-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rpart_mod) <span class="sc">|&gt;</span> </span>
<span id="cb75-160"><a href="#cb75-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span>
<span id="cb75-161"><a href="#cb75-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-162"><a href="#cb75-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-163"><a href="#cb75-163" aria-hidden="true" tabindex="-1"></a>Den Workflow können wir dann mit dem Traingsdatensatz einmal durchlaufen lassen und uns das gefittete Modell wiedergeben lassen.</span>
<span id="cb75-164"><a href="#cb75-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-167"><a href="#cb75-167" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-168"><a href="#cb75-168" aria-hidden="true" tabindex="-1"></a>rpart_fit <span class="ot">&lt;-</span> rpart_wflow <span class="sc">|&gt;</span> </span>
<span id="cb75-169"><a href="#cb75-169" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span>
<span id="cb75-170"><a href="#cb75-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-171"><a href="#cb75-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-172"><a href="#cb75-172" aria-hidden="true" tabindex="-1"></a>Nachdem wir das trainierte Modell vorliegen haben, nutzen wir die Funktion <span class="in">`augment()`</span> um das Modell auf die Testdaten anzuwenden.</span>
<span id="cb75-173"><a href="#cb75-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-176"><a href="#cb75-176" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-177"><a href="#cb75-177" aria-hidden="true" tabindex="-1"></a>rpart_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(rpart_fit, gummi_test_data ) </span>
<span id="cb75-178"><a href="#cb75-178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-179"><a href="#cb75-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-180"><a href="#cb75-180" aria-hidden="true" tabindex="-1"></a>Jetzt geht es los und wir schauen uns einmal an, wie gut die Klassifizierung mit dem Modell funktioniert hat. Als erstes bauen wir uns einmal die <span class="co">[</span><span class="ot">Konfusionsmatrix</span><span class="co">](https://en.wikipedia.org/wiki/Confusion_matrix)</span> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</span>
<span id="cb75-181"><a href="#cb75-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-184"><a href="#cb75-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-185"><a href="#cb75-185" aria-hidden="true" tabindex="-1"></a>rpart_cm <span class="ot">&lt;-</span> rpart_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-186"><a href="#cb75-186" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb75-187"><a href="#cb75-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-188"><a href="#cb75-188" aria-hidden="true" tabindex="-1"></a>rpart_cm</span>
<span id="cb75-189"><a href="#cb75-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-190"><a href="#cb75-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-191"><a href="#cb75-191" aria-hidden="true" tabindex="-1"></a>Das freut einen doch. Das sieht ziemlich gut aus. Wir haben auf der Diagonalen fast alle Beoabchtungen und nur sehr wenige falsche Vorhersagen auf der Nichtdiagonalen. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <span class="co">[</span><span class="ot">Vergleich von Modellen</span><span class="co">](#sec-class-model-compare)</span> ausgeben lassen.</span>
<span id="cb75-192"><a href="#cb75-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-195"><a href="#cb75-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-196"><a href="#cb75-196" aria-hidden="true" tabindex="-1"></a>rpart_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span>
<span id="cb75-197"><a href="#cb75-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-198"><a href="#cb75-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-199"><a href="#cb75-199" aria-hidden="true" tabindex="-1"></a>Wir besprechen hier nicht alle, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 83% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</span>
<span id="cb75-200"><a href="#cb75-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-201"><a href="#cb75-201" aria-hidden="true" tabindex="-1"></a>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein.</span>
<span id="cb75-202"><a href="#cb75-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-205"><a href="#cb75-205" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-206"><a href="#cb75-206" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-207"><a href="#cb75-207" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-208"><a href="#cb75-208" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-209"><a href="#cb75-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-01</span></span>
<span id="cb75-210"><a href="#cb75-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-211"><a href="#cb75-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-212"><a href="#cb75-212" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb75-213"><a href="#cb75-213" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC Kurve für den Entscheidungsbaum mit dem `rpart` Algorithmus."</span></span>
<span id="cb75-214"><a href="#cb75-214" aria-hidden="true" tabindex="-1"></a>rpart_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-215"><a href="#cb75-215" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-216"><a href="#cb75-216" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span>
<span id="cb75-217"><a href="#cb75-217" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-218"><a href="#cb75-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-219"><a href="#cb75-219" aria-hidden="true" tabindex="-1"></a>Es gibt viele Möglichkeiten sich einen Entscheidungsbaum anzuschauen. Wir nutzen hier das R Paket <span class="in">`{rpart.plot}`</span> und die gleichnamige Funktion <span class="in">`rpart.plot()`</span>. Die vielen Möglichkeiten der Darstellung und der Optionen findest in der Vignette <span class="co">[</span><span class="ot">Plotting rpart trees with the rpart.plot package.</span><span class="co">](http://127.0.0.1:52037/help/library/rpart.plot/doc/prp.pdf)</span>. Wir gehen hier einmal auf die Variante <span class="in">`extra = 101`</span> ein. Es gibt insgesamt elf verschiedene Arten plus eben noch die Möglichkeit 100 zu einer der elf genannten Varianten hinzufügen, um auch den Prozentsatz der Beobachtungen im Knoten anzuzeigen. Zum Beispiel zeigt <span class="in">`extra = 101`</span> die Anzahl und den Prozentsatz der Beobachtungen in dem Knoten an.</span>
<span id="cb75-220"><a href="#cb75-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-223"><a href="#cb75-223" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-224"><a href="#cb75-224" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-225"><a href="#cb75-225" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-226"><a href="#cb75-226" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-227"><a href="#cb75-227" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-02</span></span>
<span id="cb75-228"><a href="#cb75-228" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-229"><a href="#cb75-229" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-230"><a href="#cb75-230" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb75-231"><a href="#cb75-231" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Visualisierung des finalen `rpart` Entscheidungsbaums."</span></span>
<span id="cb75-232"><a href="#cb75-232" aria-hidden="true" tabindex="-1"></a>rpart_fit <span class="sc">|&gt;</span></span>
<span id="cb75-233"><a href="#cb75-233" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">|&gt;</span></span>
<span id="cb75-234"><a href="#cb75-234" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart.plot</span>(<span class="at">roundint =</span> <span class="cn">FALSE</span>, <span class="at">extra =</span> <span class="dv">101</span>)</span>
<span id="cb75-235"><a href="#cb75-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-236"><a href="#cb75-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-237"><a href="#cb75-237" aria-hidden="true" tabindex="-1"></a>In @fig-class-rf-02 sehen wir den finalen Entscheidungsbaum. Wir sehen, dass wir nicht weiter als fünf Splits nach unten gewandert sind. Das hatten wir ja auch mit dem Parameter <span class="in">`tree_depth`</span> so eingestellt. Jetzt sehen wir aber auch, dass wir mit dem Preprocessing auch eine Grube graben können. Wir haben in unserem ersten Knoten 189 Männer und 165 Frauen. Daher hat der Knoten nach Mehrheitsentscheidung den Status <span class="in">`m`</span>. Jetzt spalten wir den Knoten nach der Körpergröße von $0.48$ in zwei Gruppen. Was soll jetzt $0.48$ heißen? Keine Ahnung. Wir haben die Daten normalisiert. Wenn du hier die Werte für die Splits *interpretieren* willst, dann musst du auf den Orginaldaten rechnen. Nach dem Split sehen wir zwei Knoten, in denen zum einen die Männer domiern und zum anderen die Frauen. Wir splitten wieder nach der Körpergröße und erhalten immer reinere Knoten in den fast nur noch Männer oder Frauen sind.</span>
<span id="cb75-238"><a href="#cb75-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-239"><a href="#cb75-239" aria-hidden="true" tabindex="-1"></a>Schaue dir auch die anderen Arten der Visualisierung in <span class="in">`rpart.plot`</span> an und entscheide, ob dir die anderen Varianten bessere Informationen liefern, die zu deiner wissenschaftlichen Fragestellung passen.</span>
<span id="cb75-240"><a href="#cb75-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-241"><a href="#cb75-241" aria-hidden="true" tabindex="-1"></a>An der Stelle trifft dann immer die Klassifikation auf die Interpretation. Du kannst nicht das Modell im Nachgang wieder entnormalisieren. Das geht nicht. Wenn du auf den Orginaldaten rechnest, dann wirst du ein anderes Modell erhalten. Das Modell mag besser oder schlechter sein, auf jeden Fall anders. Wie so oft hängt es von der wissenschaftlichen Fragestellung ab.</span>
<span id="cb75-242"><a href="#cb75-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-243"><a href="#cb75-243" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Forest mit ranger {#sec-rf}</span></span>
<span id="cb75-244"><a href="#cb75-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-245"><a href="#cb75-245" aria-hidden="true" tabindex="-1"></a>Bis jetzt haben wir *einen* Entscheidungsbaum wachsen lassen. Was wäre, wenn wir statt einen Baum mehrere Bäume wachsen lassen. Wir lassen einen ganzen Wald (eng. *forest*) entstehen. Nun macht es wenig Sinn, immer den gleichen Baum auf immer den selben Daten wachsen zu lassen. Daher wählen wir zufällig eine Anzahl an Zeilen und Spalten aus bevor wir einen Baum in unserem Wald wachsen lassen. Dabei bringen wir zwei den Zufall in die Generierung eines Baums mit ein.</span>
<span id="cb75-246"><a href="#cb75-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-247"><a href="#cb75-247" aria-hidden="true" tabindex="-1"></a>1)  Durch die zufällige Auswahl der Beobachtungen mit Zurücklegen. Wir haben also einzelne Zeilen und damit Beobachtungen mehrfach in den Daten.</span>
<span id="cb75-248"><a href="#cb75-248" aria-hidden="true" tabindex="-1"></a>2)  Durch die zufällige Auswahl eines Sets an Variablen. Wir nutzen nicht immer alle Variablen in unserem Modell sondern nur ein Set an Spalten.</span>
<span id="cb75-249"><a href="#cb75-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-250"><a href="#cb75-250" aria-hidden="true" tabindex="-1"></a>Im maschinellen Lernen nennen wir diese Methode *Bagging*. Das Wort *Bagging* steht für *bootstrap aggregating* und ist eine Methode, um Vorhersagen aus verschiedenen Modellen zu kombinieren. In unserem Fall sind es die verschiedenen Entscheidungsböume. Dabei müssen alle Modelle mit dem gleichen Algorithmus laufen, können aber auf verschiedenen Datensätzen oder aber Variablensätzen zugreifen. Häufig haben die Modelle eine hohe Varianz in der Vorhersage und wir nutzen dann Bagging um die Modelle miteinander zu kombinieren und dadurch die Varianz zu verringern. Die Ergebnisse der Modelle werden dann im einfachsten Fall gemittelt. Das Ergebnis jeder Modellvorhersage geht mit gleichem Gewicht in die Vorhersage ein. Wir haben auch noch andere Möglichkeiten, aber du kannst dir Vorstellen wir rechnen verschiedene Modelle $j$-mal und bilden dann ein finales Modell in dem wir alle $j$-Modelle zusammenfassen. Wie wir die Zusammenfassung rechnen, ist dann immer wieder von Fall zu Fall unterschiedlich. Wir erhalten am Ende einen *Ensemble* Klassifizierer, da ja ein Ensemble von Modellen zusammengefasst wird. In dem Fall von den Entscheidungsbäumen ist das Ensemble ein Wald an Bäumen.</span>
<span id="cb75-251"><a href="#cb75-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-252"><a href="#cb75-252" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution collapse="true"}</span>
<span id="cb75-253"><a href="#cb75-253" aria-hidden="true" tabindex="-1"></a><span class="fu">## Parallele CPU Nutzung</span></span>
<span id="cb75-254"><a href="#cb75-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-255"><a href="#cb75-255" aria-hidden="true" tabindex="-1"></a>Wenn wir wirklich viele Bäume wachsen lassen wollen, dann bietet sich die parallele Berechnung an. Das können wir über das R Paket <span class="in">`{parallel}`</span> realisieren. Wir detektieren erstmal wie viele Kerne wir auf dem Rechner zu Verfügung haben.</span>
<span id="cb75-256"><a href="#cb75-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-259"><a href="#cb75-259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-260"><a href="#cb75-260" aria-hidden="true" tabindex="-1"></a>cores <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb75-261"><a href="#cb75-261" aria-hidden="true" tabindex="-1"></a>cores</span>
<span id="cb75-262"><a href="#cb75-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-263"><a href="#cb75-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-264"><a href="#cb75-264" aria-hidden="true" tabindex="-1"></a>Wenn wir das gemacht haben, dann können wir in <span class="in">`set_engine("ranger", num.threads = cores)`</span> auswählen, dass die Berechnung parallel verlaufen soll. Besonders auf Großrechnern macht die parallele Berechnung am meisten Sinn.</span>
<span id="cb75-265"><a href="#cb75-265" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb75-266"><a href="#cb75-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-267"><a href="#cb75-267" aria-hidden="true" tabindex="-1"></a>Auch hier ist es so, dass es verschiedene Algorithmen für den Random Forest gibt. Wir nehmen hier dann den <span class="in">`ranger`</span> Algorithmus. Du kannst wie immer schauen, welche Algorithmen es noch gibt und auch wiederum verschiedene Algorithmen ausprobieren. In jedem Baum sollen drei Prädiktoren (<span class="in">`mtry = 3`</span>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<span class="in">`min_n = 10`</span>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<span class="in">`trees = 1000`</span>). Darüber hinaus wollen wir uns auch die *Variable Importance* wiedergeben lassen. Die Variable Importance beschreibt, wie gut ein Prädiktor über alle Bäume des Waldes, in der Lage war Splits in möglichst reine Knoten durchzuführen. Ein Prädiktor mit einer hohen Variable Importance, ist also besonders geeignet für gute Splits mit hoher Reinheit.</span>
<span id="cb75-268"><a href="#cb75-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-271"><a href="#cb75-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-272"><a href="#cb75-272" aria-hidden="true" tabindex="-1"></a>ranger_mod <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mtry =</span> <span class="dv">3</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-273"><a href="#cb75-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-274"><a href="#cb75-274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb75-275"><a href="#cb75-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-276"><a href="#cb75-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-277"><a href="#cb75-277" aria-hidden="true" tabindex="-1"></a>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</span>
<span id="cb75-278"><a href="#cb75-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-281"><a href="#cb75-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-282"><a href="#cb75-282" aria-hidden="true" tabindex="-1"></a>ranger_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-283"><a href="#cb75-283" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ranger_mod) <span class="sc">|&gt;</span> </span>
<span id="cb75-284"><a href="#cb75-284" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span>
<span id="cb75-285"><a href="#cb75-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-286"><a href="#cb75-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-287"><a href="#cb75-287" aria-hidden="true" tabindex="-1"></a>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <span class="in">`fit()`</span> unser Modell anpassen.</span>
<span id="cb75-288"><a href="#cb75-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-291"><a href="#cb75-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-292"><a href="#cb75-292" aria-hidden="true" tabindex="-1"></a>ranger_fit <span class="ot">&lt;-</span> ranger_wflow <span class="sc">|&gt;</span> </span>
<span id="cb75-293"><a href="#cb75-293" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span>
<span id="cb75-294"><a href="#cb75-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-295"><a href="#cb75-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-296"><a href="#cb75-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-297"><a href="#cb75-297" aria-hidden="true" tabindex="-1"></a>In der @fig-class-rf-07 sehen wir dann die Variable Importance sortiert für alle Prädiktoren. Ganz wichtig, die Variable Importance ist nicht numerisch zu interpretieren und auch nicht über verschiedene Datensäze hinweg. Wir können nur die Variable Importance von einem Datensatz anschauen und dort sehen welche Variablen den meisten Einfluss haben. Wir sehen also, dass die Körpergröße eine sehr große Wichtigkeit hat um die Männer von den Frauen in den Gummibärchendaten zu trennen. Das macht auch Sinn. Frauen und Männer sind nun mal unterschiedlich groß. Nicht mehr so wichtig ist das Alter und das Semester. Beide Prädiktoren haben einen ehr geringeren Einfluss auf die Aufteilung der beiden Geschlechter. Der Lieblingsgeschmack tut bei der Einteilung in Männer und Frauen nichts zur Sache.</span>
<span id="cb75-298"><a href="#cb75-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-301"><a href="#cb75-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-302"><a href="#cb75-302" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-303"><a href="#cb75-303" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-304"><a href="#cb75-304" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-305"><a href="#cb75-305" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-07</span></span>
<span id="cb75-306"><a href="#cb75-306" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-307"><a href="#cb75-307" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-308"><a href="#cb75-308" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb75-309"><a href="#cb75-309" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Visualisierung der *Variable Importance* aus unseren `ranger` Algorithmus."</span></span>
<span id="cb75-310"><a href="#cb75-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-311"><a href="#cb75-311" aria-hidden="true" tabindex="-1"></a>ranger_fit <span class="sc">|&gt;</span> </span>
<span id="cb75-312"><a href="#cb75-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-313"><a href="#cb75-313" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vip</span>(<span class="at">num_features =</span> <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb75-314"><a href="#cb75-314" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb75-315"><a href="#cb75-315" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-316"><a href="#cb75-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-317"><a href="#cb75-317" aria-hidden="true" tabindex="-1"></a>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser Modell auf den Testdatensatz anwenden und schauen, wie gut der Random Forest unsere Geschlechter vorhersagen kann.</span>
<span id="cb75-318"><a href="#cb75-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-321"><a href="#cb75-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-322"><a href="#cb75-322" aria-hidden="true" tabindex="-1"></a>ranger_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(ranger_fit, gummi_test_data ) </span>
<span id="cb75-323"><a href="#cb75-323" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-324"><a href="#cb75-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-325"><a href="#cb75-325" aria-hidden="true" tabindex="-1"></a>Nun schauen wir uns an wie gut die Klassifizierung mit dem <span class="in">`ranger`</span> Modell funktioniert hat. Als erstes bauen wir uns einmal die <span class="co">[</span><span class="ot">Konfusionsmatrix</span><span class="co">](https://en.wikipedia.org/wiki/Confusion_matrix)</span> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</span>
<span id="cb75-326"><a href="#cb75-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-329"><a href="#cb75-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-330"><a href="#cb75-330" aria-hidden="true" tabindex="-1"></a>ranger_cm <span class="ot">&lt;-</span> ranger_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-331"><a href="#cb75-331" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb75-332"><a href="#cb75-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-333"><a href="#cb75-333" aria-hidden="true" tabindex="-1"></a>ranger_cm</span>
<span id="cb75-334"><a href="#cb75-334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-335"><a href="#cb75-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-336"><a href="#cb75-336" aria-hidden="true" tabindex="-1"></a>Ja, das sieht ähnlich gut aus wie der <span class="in">`rpart`</span> Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <span class="co">[</span><span class="ot">Vergleich von Modellen</span><span class="co">](#sec-class-model-compare)</span> ausgeben lassen.</span>
<span id="cb75-337"><a href="#cb75-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-340"><a href="#cb75-340" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-341"><a href="#cb75-341" aria-hidden="true" tabindex="-1"></a>ranger_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span>
<span id="cb75-342"><a href="#cb75-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-343"><a href="#cb75-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-344"><a href="#cb75-344" aria-hidden="true" tabindex="-1"></a>Wir besprechen wie beim <span class="in">`rpart`</span> Algorithmus nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 84% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</span>
<span id="cb75-345"><a href="#cb75-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-346"><a href="#cb75-346" aria-hidden="true" tabindex="-1"></a>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. Damit sind wir mit dem Random Forest Algorithmus soweit durch und wir schauen uns jetzt einen etwas komplexeren xgboost Algorithmus an.</span>
<span id="cb75-347"><a href="#cb75-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-350"><a href="#cb75-350" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-351"><a href="#cb75-351" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-352"><a href="#cb75-352" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-353"><a href="#cb75-353" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-354"><a href="#cb75-354" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-03</span></span>
<span id="cb75-355"><a href="#cb75-355" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-356"><a href="#cb75-356" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-357"><a href="#cb75-357" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb75-358"><a href="#cb75-358" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC Kurve für den Random Forest mit dem `ranger` Algorithmus."</span></span>
<span id="cb75-359"><a href="#cb75-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-360"><a href="#cb75-360" aria-hidden="true" tabindex="-1"></a>ranger_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-361"><a href="#cb75-361" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-362"><a href="#cb75-362" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span>
<span id="cb75-363"><a href="#cb75-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-364"><a href="#cb75-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-365"><a href="#cb75-365" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb75-366"><a href="#cb75-366" aria-hidden="true" tabindex="-1"></a><span class="fu">## Kann ich auch eine Kreuzvalidierung und Tuning für Random Forest durchführen?</span></span>
<span id="cb75-367"><a href="#cb75-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-368"><a href="#cb75-368" aria-hidden="true" tabindex="-1"></a>Ja, kannst du. Wenn du *nur* eine Kreuzvalidierung durchführen willst, findest du alles im @sec-knn für den $k$-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den Random Forest Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</span>
<span id="cb75-369"><a href="#cb75-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-370"><a href="#cb75-370" aria-hidden="true" tabindex="-1"></a>Wenn du also den Random Forest Algorithmus auch tunen willst, dann schaue einfach weiter unten nochmal bei dem Tuning des xgboost Algorithmus rein. Es ändert sich kaum was für die Auwahl der <span class="co">[</span><span class="ot">Tuning Parameter vom Random Forest Algorithmus</span><span class="co">](https://parsnip.tidymodels.org/reference/details_rand_forest_ranger.html)</span>.</span>
<span id="cb75-371"><a href="#cb75-371" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb75-372"><a href="#cb75-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-373"><a href="#cb75-373" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient boosting mit xgboost {#sec-xgboost}</span></span>
<span id="cb75-374"><a href="#cb75-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-375"><a href="#cb75-375" aria-hidden="true" tabindex="-1"></a>Als letztes Beispiel für Entscheidungsbäume schauen wir uns das Boosting an. Auch hier haben wir es wieder mit einem Wald an Entscheidungsbäumen zu tun, die wir auch wieder zusammenfassen wollen. Wir verlassen uns also nicht auf die Klassifikation von einem Baum, sondern nehmen die Informationen von vielen Bäumen zusammen. Was ist jetzt der Unterschied zu einem Random Forest? Bei einem Random Forest bauen wir uns im Prinzip hunderte einzelne Bäume und trainieren darauf den Algorithmus. Am Ende fassen wir dann alle Bäume für die Vorhersage zusammen. Beim Boosting nutzen wir die Information des ersten Baumes für das Wachstum des zweiten Baumes und so weiter. Das Boosting verkettet also die Informationen der einzelnen Bäume zu einem kontinuierlichen Lernen. Daher sind Bossting Algorithmen meist sehr gute Klassifizierer.</span>
<span id="cb75-376"><a href="#cb75-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-377"><a href="#cb75-377" aria-hidden="true" tabindex="-1"></a>Wir unterscheiden beim Boosting grob in zwei Kategorien. Zum einen gibt es das adaptive Boosting und das gradient Boosting. Beim adaptiven Boosting erhalten die Beobachtungen über die verschiedenen Klassifizierungsschritte unterschiedliche Gewichte für ihre Bedeutung. In @fig-class-adaboost sehen wir ein Beispiel für den <span class="in">`adaboost`</span> Algorithmus. Wir haben einen ursprünglichen Datensatz mit blauen und roten Beobachtungen. Wir wollen nun diese Beobachtungen voneinander trennen und damit einen Klassifizierer bauen. Wir fangen mit einem simplen Entscheidungsbaum an, der nur einen Split durchführt. Jetzt haben wir zwei falsch klassifizierte blaue Beobachtungen und eine falsche rote Beobachtung. Nun erhöhen wir das Gewicht dieser drei Beobachtungen. Der nächste Klassifizierer soll nun insbesondere auf diese drei Beobachtungen achten. Wir erhalten daher einen anderen Split und damit zwei blaue Beobachtungen die nicht richtig klassifiziert wurden. Wir erhöhen wieder das Gewicht der beiden falsch klassifizierten blauen Beobachtungen. Der dritte Klassifizierer schafft es jetzt die beiden blauen Beobachtungen gut von den roten Beobachtungen zu trennen. Wir stoppen jetzt hier und bringen alle Klassifiziererregeln, also wo der Split liegen soll, in einen Klassifizierer zusammen.</span>
<span id="cb75-378"><a href="#cb75-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-379"><a href="#cb75-379" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung von adaptive Boosting an drei Klassifizieren, die nacheinander auf die neu gewichteten Daten angewendet werden. Am Ende werden alle drei Klassifizierer dann in einen Klassifizierer kombiniert.](images/class-xgboost.png)</span>{#fig-class-adaboost fig-align="center" width="100%"}</span>
<span id="cb75-380"><a href="#cb75-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-381"><a href="#cb75-381" aria-hidden="true" tabindex="-1"></a>In der @fig-class-gradientboost sehen wir die Idee des gradient Boosting einmal dargestellt. Die Idee ist recht simple. Wir wollen wieder nacheinander einen Klassifizierer auf schon klassifizierte Daten anwenden. Wir wollen also das unser zweiter Klassifizierer von dem ersten Klassifizier lernt. Wie machen wir das? Indem wir im ersten Schritt unsere Daten klassifizieren. Wir machen das mit einem Entscheidungsbaum, der mehrere Splits durchführt, die wir dann zu einer eckigen Graden zusammenfassen. Dann haben wir aber einen Fehler als Abstand zu den Splits oder eben zu der Graden. Diese Abstände übertragen wir dann in einen neuen Datensatz auf dem wir dann den nächsten Entscheidungsbaum wachsen lassen. Wir reduzieren also den Fehler des ersten Klassifizierers durch den zweiten Klassifizierer. Dann übertragen wir den Fehler des zweiten Klassifizierers in einen neuen Datensatz und lassen den dritten Klassifizierer den Fehler weiter reduzieren. Am Ende kombinieren wir alle drei Klassifizierer in ein Modell. Durch das gradient Boosting erhalten wir ziemlich gute Entscheidungsbäume, die in der Lage sind sehr schnell und effizient eine Vorhersage zu treffen.</span>
<span id="cb75-382"><a href="#cb75-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-383"><a href="#cb75-383" aria-hidden="true" tabindex="-1"></a><span class="al">![Darstellung von gradient Boosting an drei Klassifizieren, die nacheinander auf die *Fehler* des vorherigen Klassifizierers angewendet werden. Beachte die Nulllinie bei dem Klassifizierer zwei und drei.](images/class-xgboost-2.png)</span>{#fig-class-gradientboost fig-align="center" width="100%"}</span>
<span id="cb75-384"><a href="#cb75-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-385"><a href="#cb75-385" aria-hidden="true" tabindex="-1"></a>Nach dieser theoretischen Einführung wollen wir uns einmal mit der Implementierung beschäftigen. Wir nutzen hier einmal die bekannten Parameter aus dem Random Forest Algorithmus um unseren <span class="in">`xgboost`</span> Algorithmus zu trainieren. Wie wir gleich noch im Tuning sehen werden, hatr der <span class="in">`xgboost`</span> Algorithmus noch mehr Parameter an denen du schrauben kannst. In jedem Baum sollen drei Prädiktoren (<span class="in">`mtry = 3`</span>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<span class="in">`min_n = 10`</span>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<span class="in">`trees = 1000`</span>).</span>
<span id="cb75-386"><a href="#cb75-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-389"><a href="#cb75-389" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-390"><a href="#cb75-390" aria-hidden="true" tabindex="-1"></a>xgboost_mod <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">mtry =</span> <span class="dv">3</span>, <span class="at">min_n =</span> <span class="dv">10</span>, <span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-391"><a href="#cb75-391" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"xgboost"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-392"><a href="#cb75-392" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb75-393"><a href="#cb75-393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-394"><a href="#cb75-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-395"><a href="#cb75-395" aria-hidden="true" tabindex="-1"></a>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</span>
<span id="cb75-396"><a href="#cb75-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-399"><a href="#cb75-399" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-400"><a href="#cb75-400" aria-hidden="true" tabindex="-1"></a>xgboost_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-401"><a href="#cb75-401" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(xgboost_mod) <span class="sc">|&gt;</span> </span>
<span id="cb75-402"><a href="#cb75-402" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span>
<span id="cb75-403"><a href="#cb75-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-404"><a href="#cb75-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-405"><a href="#cb75-405" aria-hidden="true" tabindex="-1"></a>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <span class="in">`fit()`</span> unser Modell anpassen. Es ist eine wahre Freude. Ich mache das ja jetzt auch schon hier eine Weile im Skript und es ist echt super, wie gut das funktioniert.</span>
<span id="cb75-406"><a href="#cb75-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-409"><a href="#cb75-409" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-410"><a href="#cb75-410" aria-hidden="true" tabindex="-1"></a>xgboost_fit <span class="ot">&lt;-</span> xgboost_wflow <span class="sc">|&gt;</span> </span>
<span id="cb75-411"><a href="#cb75-411" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(gummi_train_data)</span>
<span id="cb75-412"><a href="#cb75-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-413"><a href="#cb75-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-414"><a href="#cb75-414" aria-hidden="true" tabindex="-1"></a>Wie auch beim Random Forest Algorithmus können wir uns beim xgboost Algorithmus die Variable Importance wiedergeben lassen. Die Wichtigkeit der Variablen wird in xgboost anhand von drei verschiedenen *Wichtigkeiten* für eine Variable berechnet. Hier unterscheidet sich dann der Algorithmus xgboost von dem Random Forest Algorithmen. Achtung, wir können nicht einfach die Variable Importance von einem Random Forest Algorithmus mit der eines xgboost Algorithmus vergleichen. Wir kriegen hier andere Werte zurück, die wir dann auch anders interpretieren können.</span>
<span id="cb75-415"><a href="#cb75-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-416"><a href="#cb75-416" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Gain** ist der relative Beitrag der entsprechenden Variable zum entgültigen Modell. Wir addieren dafür den Beitrag der Variable für die Splits für jeden Baum auf. Eine höhere Punktzahl deutet darauf hin, dass die Variable für die Vorhersage des Baums wichtiger ist. Die Variable war in der Lage die Klassen gut voneinander zu trennen.</span>
<span id="cb75-417"><a href="#cb75-417" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Cover** ist die relative Beobachtung, die mit einem Prädiktor verbunden ist. Also der Anteil der Beobachtungen, die mit dieser Variable zusammenhängen. Nehmen wir an Merkmal $X_1$ wird dazu verwendet, um einen Terminalknoten für 10 Beobachtungen in einem Baum zu erschaffen. Im in einem weiteren Baum ist es ein Terminalkonten mit 20 Beobachtungen. Damit haben wir 30 absolute Beobachtungen, die mit Merkmal $X_1$ verbunden sind. Die relative Beobachtung ist dann 30 geteilt durch die Summe aller absoluten Beobachtungen für alle Merkmale.</span>
<span id="cb75-418"><a href="#cb75-418" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Häufigkeit** bezieht sich auf die relative Häufigkeit, mit der eine Variable in den zusammengestellten Bäumen vorkommt. Nehmen wir an Merkmal $X_1$ kommt in Baum A in einem Split und in Baum B in zwei Splits vor. Die absolute Häufigkeit von Merkmal $X_1$ ist 3 und die relative Häufigkeit ist dann 3 durch die Summe aller absoluten Vorkommen für alle Merkmale.</span>
<span id="cb75-419"><a href="#cb75-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-420"><a href="#cb75-420" aria-hidden="true" tabindex="-1"></a>Schauen wir uns also einmal die Kriterien der Variable Importance für unsere Gummibärchendaten einmal an. Gehen wir mal die Parameter <span class="in">`gain`</span>, <span class="in">`cover`</span> und <span class="in">`frequency`</span> einmal für unsere Körpergröße durch. Zuerst hat die Körpergröße den höchsten Wert in <span class="in">`gain`</span> mit $0.84$. Da wir das Gain auf 1 skaliert haben, macht die Körpergröße 84% des gesamten Gain in dem Modell aus. Daher wissen wir, dass die Körpergröße einen überaus bedeutenden Anteil an der Vorhersage des Geschlechts hat. Im Weiteren sehen wir an dem Parameter <span class="in">`cover`</span>, dass in 34% der Beobachtungen ein Split mit der Körpergröße *vorausgeht*. Das heißt, 34% der Beobachtungen wurden anhand der Körpergröße aufgeteilt. Da wir nicht wissen wie viele Splits es ingesamt gab, muss man dieses Wert immer etwas vorsichtig bewerten. Die <span class="in">`frequency`</span> teilt uns mit, dass in 33% der der Splits auch die Körpergröße vor kam. Wir sehen, die Körpergröße ist wichtig für die Vorhersage des Geschlechts. Wenn Variablen fehlen, dann haben diese keinen Einfluss auf die Klassifikation gehabt.</span>
<span id="cb75-421"><a href="#cb75-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-424"><a href="#cb75-424" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-425"><a href="#cb75-425" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-426"><a href="#cb75-426" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-427"><a href="#cb75-427" aria-hidden="true" tabindex="-1"></a>xg_imp <span class="ot">&lt;-</span> xgboost_fit <span class="sc">|&gt;</span> </span>
<span id="cb75-428"><a href="#cb75-428" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_fit_parsnip</span>() <span class="sc">%$%</span> </span>
<span id="cb75-429"><a href="#cb75-429" aria-hidden="true" tabindex="-1"></a>  xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> fit) <span class="sc">|&gt;</span> </span>
<span id="cb75-430"><a href="#cb75-430" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.numeric), round, <span class="dv">2</span>))</span>
<span id="cb75-431"><a href="#cb75-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-432"><a href="#cb75-432" aria-hidden="true" tabindex="-1"></a>xg_imp</span>
<span id="cb75-433"><a href="#cb75-433" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-434"><a href="#cb75-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-435"><a href="#cb75-435" aria-hidden="true" tabindex="-1"></a>In der @fig-class-rf-08 sehen wir dann die Variable Importance sortiert für alle Prädiktoren und eingeteilt in Cluster. Die Funktion <span class="in">`xgb.ggplot.importance()`</span> versucht ähnlich bedeutende Prädiktoren in gleiche Cluster zuzuordnen.</span>
<span id="cb75-436"><a href="#cb75-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-439"><a href="#cb75-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-440"><a href="#cb75-440" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-441"><a href="#cb75-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-442"><a href="#cb75-442" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-443"><a href="#cb75-443" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-08</span></span>
<span id="cb75-444"><a href="#cb75-444" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-445"><a href="#cb75-445" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-446"><a href="#cb75-446" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb75-447"><a href="#cb75-447" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Visualisierung der *Variable Importance* aus unseren `xgboost` Algorithmus. Wir sehen, dass sich grob drei Gruppen für Bedeutung der Variablen für die Klassifikation gebildet haben."</span></span>
<span id="cb75-448"><a href="#cb75-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-449"><a href="#cb75-449" aria-hidden="true" tabindex="-1"></a>xg_imp <span class="sc">|&gt;</span> </span>
<span id="cb75-450"><a href="#cb75-450" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.ggplot.importance</span>() <span class="sc">+</span></span>
<span id="cb75-451"><a href="#cb75-451" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb75-452"><a href="#cb75-452" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_okabeito</span>()</span>
<span id="cb75-453"><a href="#cb75-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-454"><a href="#cb75-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-455"><a href="#cb75-455" aria-hidden="true" tabindex="-1"></a>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser xgboost Modell auf den Testdatensatz anwenden und schauen, wie gut das gradient Boosting unsere Geschlechter vorhersagen kann.</span>
<span id="cb75-456"><a href="#cb75-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-459"><a href="#cb75-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-460"><a href="#cb75-460" aria-hidden="true" tabindex="-1"></a>xgboost_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(xgboost_fit, gummi_test_data ) </span>
<span id="cb75-461"><a href="#cb75-461" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-462"><a href="#cb75-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-463"><a href="#cb75-463" aria-hidden="true" tabindex="-1"></a>Nun schauen wir uns an wie gut die Klassifizierung mit dem xgboost Modell funktioniert hat. Als erstes bauen wir uns einmal die <span class="co">[</span><span class="ot">Konfusionsmatrix</span><span class="co">](https://en.wikipedia.org/wiki/Confusion_matrix)</span> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</span>
<span id="cb75-464"><a href="#cb75-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-467"><a href="#cb75-467" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-468"><a href="#cb75-468" aria-hidden="true" tabindex="-1"></a>xgboost_cm <span class="ot">&lt;-</span> xgboost_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-469"><a href="#cb75-469" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(gender, .pred_class)</span>
<span id="cb75-470"><a href="#cb75-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-471"><a href="#cb75-471" aria-hidden="true" tabindex="-1"></a>xgboost_cm</span>
<span id="cb75-472"><a href="#cb75-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-473"><a href="#cb75-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-474"><a href="#cb75-474" aria-hidden="true" tabindex="-1"></a>Ja, das sieht ähnlich gut aus wie der Random Forest Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <span class="co">[</span><span class="ot">Vergleich von Modellen</span><span class="co">](#sec-class-model-compare)</span> ausgeben lassen.</span>
<span id="cb75-475"><a href="#cb75-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-478"><a href="#cb75-478" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-479"><a href="#cb75-479" aria-hidden="true" tabindex="-1"></a>xgboost_cm <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span>
<span id="cb75-480"><a href="#cb75-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-481"><a href="#cb75-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-482"><a href="#cb75-482" aria-hidden="true" tabindex="-1"></a>Wier vorher schon besprechen wir nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 86% richtig klassifizierter Geschlechter. Besonders die Sensitivität ist mit 92% sehr gut. Die Sensitivität gibt ja an, wie zuverlässig unser xgboost Algorithmus erkennt, ob man eine Frau ist. Die Spezifität ist etwas niedriger, also die Fähigkeit die Männer auch als Männer zu erkennen. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt sehr guter Wert. Da sind wir noch besser als beim Random Forest.</span>
<span id="cb75-483"><a href="#cb75-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-484"><a href="#cb75-484" aria-hidden="true" tabindex="-1"></a>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. In den folgenden Schritten wollen wir einmal den xgboost Algorithmus tunen und schauen, ob wir noch bessere Ergebnisse für die Klassifikation mit anderen Parametern für den Algorithmus hin bekommen.</span>
<span id="cb75-485"><a href="#cb75-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-488"><a href="#cb75-488" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-489"><a href="#cb75-489" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-490"><a href="#cb75-490" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-491"><a href="#cb75-491" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-492"><a href="#cb75-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-04</span></span>
<span id="cb75-493"><a href="#cb75-493" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-494"><a href="#cb75-494" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-495"><a href="#cb75-495" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb75-496"><a href="#cb75-496" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC Kurve für den Entscheidungsbaum mit dem `xgboost` Algorithmus."</span></span>
<span id="cb75-497"><a href="#cb75-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-498"><a href="#cb75-498" aria-hidden="true" tabindex="-1"></a>xgboost_aug <span class="sc">|&gt;</span> </span>
<span id="cb75-499"><a href="#cb75-499" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-500"><a href="#cb75-500" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span>
<span id="cb75-501"><a href="#cb75-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-502"><a href="#cb75-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-503"><a href="#cb75-503" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb75-504"><a href="#cb75-504" aria-hidden="true" tabindex="-1"></a><span class="fu">## Kann ich auch eine Kreuzvalidierung für xgboost durchführen?</span></span>
<span id="cb75-505"><a href="#cb75-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-506"><a href="#cb75-506" aria-hidden="true" tabindex="-1"></a>Ja, kannst du. Wenn du *nur* eine Kreuzvalidierung durchführen willst, findest du alles im @sec-knn für den $k$-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den xgboost Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</span>
<span id="cb75-507"><a href="#cb75-507" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb75-508"><a href="#cb75-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-509"><a href="#cb75-509" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tuning</span></span>
<span id="cb75-510"><a href="#cb75-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-511"><a href="#cb75-511" aria-hidden="true" tabindex="-1"></a>Was heißt Tuning? Wie bei einem Auto können wir an verschiedenen Stellschrauben bei einem mathematischen Algorithmus schrauben. Welche Schrauben und Teile das sind, hängt dann wieder vom Algorithmus ab. Im Falle des xgboost Algorithmus können wir an folgenden Parametern drehen und jeweils schauen, was dann mit unserer Vorhersage passiert. Insgesamt hat der <span class="co">[</span><span class="ot">xgboost Algorithmus acht Tuningparameter</span><span class="co">](https://parsnip.tidymodels.org/reference/details_boost_tree_xgboost.html)</span>, wir wählen jetzt für uns hier drei aus. Ich nehme hier auch nur drei Parameter, da sich dann drei Parameter noch sehr gut visuell darstellen lassen. In der Anwendung wäre dann natürlich besser alle Parameter zu tunen, aber das dauert dann auch lange.</span>
<span id="cb75-512"><a href="#cb75-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-513"><a href="#cb75-513" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`mtry`</span>, zufällig ausgewählte Anzahl an Variablen für jeden Baum. Das heißt, für jeden Baum werden von unseren Variablen die Anzahl <span class="in">`mtry`</span> zufällig ausgewählt und auf diesem kleineren Datensatz der Baum erstellt.</span>
<span id="cb75-514"><a href="#cb75-514" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`min_n`</span>, kleinste Knotengröße, die noch akzeptiert wird. Wenn ein Knoten unter <span class="in">`min_n`</span> fällt, dann endet hier das Wachstum des Baumes.</span>
<span id="cb75-515"><a href="#cb75-515" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`trees`</span>, Anzahl der Bäume die in einem xgboost Algorithmus erstellt werden.</span>
<span id="cb75-516"><a href="#cb75-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-517"><a href="#cb75-517" aria-hidden="true" tabindex="-1"></a>Nun ist es so, dass wir natürlich nicht händisch alle möglichen Kombinationen von der Anzahl der ausgewählten Variablen pro Baum, der kleinsten Knotengröße und der Anzahl der Bäume berechnen wollen. Das sind ziemlich viele Kombinationen und wir kommen dann vermutlich schnell durcheinander. Deshalb gibt es die Funktion <span class="in">`tune()`</span> aus dem R Paket <span class="in">`{tune}`</span>, die uns einen Prozess anbietet, das Tuning automatisiert durchzuführen.</span>
<span id="cb75-518"><a href="#cb75-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-519"><a href="#cb75-519" aria-hidden="true" tabindex="-1"></a>Als erstes müssen wir uns ein Objekt bauen, das aussieht wie ein ganz normales Modell in der Klassifikation. Aber wir ergänzen jetzt noch hinter jeder zu tunenden Option noch die Funktion <span class="in">`tune()`</span>. Das sind die Parameter des Algorithmus, die wir später tunen wollen.</span>
<span id="cb75-520"><a href="#cb75-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-523"><a href="#cb75-523" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-524"><a href="#cb75-524" aria-hidden="true" tabindex="-1"></a>tune_spec <span class="ot">&lt;-</span>  <span class="fu">boost_tree</span>(<span class="at">mtry =</span> <span class="fu">tune</span>(), </span>
<span id="cb75-525"><a href="#cb75-525" aria-hidden="true" tabindex="-1"></a>                         <span class="at">min_n =</span> <span class="fu">tune</span>(), </span>
<span id="cb75-526"><a href="#cb75-526" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trees =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb75-527"><a href="#cb75-527" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"xgboost"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-528"><a href="#cb75-528" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb75-529"><a href="#cb75-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-530"><a href="#cb75-530" aria-hidden="true" tabindex="-1"></a>tune_spec</span>
<span id="cb75-531"><a href="#cb75-531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-532"><a href="#cb75-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-533"><a href="#cb75-533" aria-hidden="true" tabindex="-1"></a>Jetzt bauen wir uns den Workflow indem wir statt unserem Modell, die Tuninganweisung in den Workflow reinnehmen. Echt simpel und straightforward. Das Rezept bleibt ja das Gleiche.</span>
<span id="cb75-534"><a href="#cb75-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-537"><a href="#cb75-537" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-538"><a href="#cb75-538" aria-hidden="true" tabindex="-1"></a>gummi_tune_wflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-539"><a href="#cb75-539" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(tune_spec) <span class="sc">|&gt;</span> </span>
<span id="cb75-540"><a href="#cb75-540" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(gummi_rec)</span>
<span id="cb75-541"><a href="#cb75-541" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-542"><a href="#cb75-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-543"><a href="#cb75-543" aria-hidden="true" tabindex="-1"></a>Jetzt müssen wir noch alle Kombinationen aus den drei Parametern <span class="in">`mtry`</span>, <span class="in">`min_n`</span> und <span class="in">`trees`</span> ermitteln. Das macht die Funktion <span class="in">`grid_regular()`</span>. Es gibt da noch andere Funktionen in dem R Paket <span class="in">`{tune}`</span>, aber ich konzentriere mich hier auf die einfachste. Jetzt müssen wir noch die Anzahl an Kombinationen festlegen. Ich möchte für jeden Parameter fünf Werte tunen. Daher nutze ich hier die Option <span class="in">`levels = 5`</span> auch damit hier die Ausführung nicht so lange läuft. Fange am besten mit <span class="in">`levels = 5`</span> an und schaue, wie lange das zusammen mit der Kreuzvalidierung dann dauert. Dann kannst du die Levels noch hochschrauben. Beachte aber, dass mehr Level nur mehr *Zwischenschritte* bedeutet. Jede Option hat eine Spannweite `range`, die du dann anpassen musst, wenn du *höhere* Werte haben willst. Mehr Level würden nur mehr Zwischenschritte bedeuten. In unserem Fall weiß zum Beispiel die Funktion <span class="in">`mtry()`</span> nicht, wie viele Variablen in dem Datensatz sind. Wir müssen also die <span class="in">`range`</span> für die Anzahl an ausgewählten Variablen selber setzen. Ich wähle daher eine Variable bis vier Variablen.</span>
<span id="cb75-544"><a href="#cb75-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-547"><a href="#cb75-547" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-548"><a href="#cb75-548" aria-hidden="true" tabindex="-1"></a>gummi_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)),</span>
<span id="cb75-549"><a href="#cb75-549" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">trees</span>(),</span>
<span id="cb75-550"><a href="#cb75-550" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">min_n</span>(),</span>
<span id="cb75-551"><a href="#cb75-551" aria-hidden="true" tabindex="-1"></a>                           <span class="at">levels =</span> <span class="dv">5</span>)</span>
<span id="cb75-552"><a href="#cb75-552" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-553"><a href="#cb75-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-554"><a href="#cb75-554" aria-hidden="true" tabindex="-1"></a>Das Tuning nur auf dem Trainingsdatensatz durchzuführen ist nicht so eine gute Idee. Deshalb nutzen wir hier auch die Kreuzvalidierung. Eigentlich ist eine 10-fache Kreuzvalidierung mit $v=10$ besser. Das dauert mir dann aber hier im Skript viel zu lange. Deshalb habe ich hier nur $v=5$ gewählt. Wenn du das Tuning rechnest, nimmst du natürlich eine 10-fach Kreuzvalidierung.</span>
<span id="cb75-555"><a href="#cb75-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-558"><a href="#cb75-558" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-559"><a href="#cb75-559" aria-hidden="true" tabindex="-1"></a>gummi_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(gummi_train_data, <span class="at">v =</span> <span class="dv">5</span>)</span>
<span id="cb75-560"><a href="#cb75-560" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-561"><a href="#cb75-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-562"><a href="#cb75-562" aria-hidden="true" tabindex="-1"></a>Nun bringen wir den Workflow zusammen mit dem Tuninggrid und unseren Sets der Kreuzvaidierung. Daher pipen wir den Workflow in die Funktion <span class="in">`tune_grid()`</span>. Als Optionen brauchen wir die Kreuzvaldierungsdatensätze und das Tuninggrid. Wenn du <span class="in">`control_grid(verbose = TRUE)`</span> wählst, dann erhälst du eine Ausgabe wie weit das Tuning gerade ist. **Achtung!**, das Tuning dauert seine Zeit. Im Falle des xgboost Algorithmus dauert das Tuning zwar nicht so lange, aber immer noch ein paar Minuten. Wenn du dann alle acht Parameter des xgboost Algorithmustunen wollen würdest, dann würde die Berechnung sehr viel länger dauern. Du kannst das Ergebnis des simpleren Tunings auch in der Datei <span class="in">`gummi_xgboost_tune_res.rds`</span> finden.</span>
<span id="cb75-563"><a href="#cb75-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-566"><a href="#cb75-566" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-567"><a href="#cb75-567" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb75-568"><a href="#cb75-568" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="ot">&lt;-</span> gummi_tune_wflow <span class="sc">|&gt;</span> </span>
<span id="cb75-569"><a href="#cb75-569" aria-hidden="true" tabindex="-1"></a>   <span class="fu">tune_grid</span>(<span class="at">resamples =</span> gummi_folds,</span>
<span id="cb75-570"><a href="#cb75-570" aria-hidden="true" tabindex="-1"></a>             <span class="at">grid =</span> gummi_grid,</span>
<span id="cb75-571"><a href="#cb75-571" aria-hidden="true" tabindex="-1"></a>             <span class="at">control =</span> <span class="fu">control_grid</span>(<span class="at">verbose =</span> <span class="cn">FALSE</span>))</span>
<span id="cb75-572"><a href="#cb75-572" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-573"><a href="#cb75-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-576"><a href="#cb75-576" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-577"><a href="#cb75-577" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb75-578"><a href="#cb75-578" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb75-579"><a href="#cb75-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-580"><a href="#cb75-580" aria-hidden="true" tabindex="-1"></a><span class="do">## write_rds(gummi_tune_res, "data/gummi_xboost_tune_res.rds")</span></span>
<span id="cb75-581"><a href="#cb75-581" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-582"><a href="#cb75-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-583"><a href="#cb75-583" aria-hidden="true" tabindex="-1"></a>Damit du nicht das Tuning durchlaufen lassen musst, habe ich das Tuning in die Datei <span class="in">`gummi_xgboost_tune_res.rds`</span> abgespeichert und du kannst dann über die Funktion <span class="in">`read_rds()`</span> wieder einlesen. Dann kannst du den R Code hier wieder weiter ausführen.</span>
<span id="cb75-584"><a href="#cb75-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-587"><a href="#cb75-587" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-588"><a href="#cb75-588" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb75-589"><a href="#cb75-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-590"><a href="#cb75-590" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">"data/gummi_xboost_tune_res.rds"</span>)</span>
<span id="cb75-591"><a href="#cb75-591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-592"><a href="#cb75-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-593"><a href="#cb75-593" aria-hidden="true" tabindex="-1"></a>Nachdem das Tuning durchgelaufen ist, können wir uns über die Funktion <span class="in">`collect_metrics()`</span>, die Ergebnisse des Tunings für jede Kombination der drei Parameter <span class="in">`mtry`</span>, <span class="in">`min_n`</span> und <span class="in">`trees`</span> wiedergeben lassen. Diese Ausgabe ist super unübersichtlich. Ich habe mich ja am Anfange des Abschnitts auch für drei Tuningparameter entschieden, da sich dann diese drei Parameter noch gut visualisieren lassen. Deshalb einmal die Abbildung der mittleren Accuarcy und der mittleren AUC-Werte über alle Kreuzvalidierungen.</span>
<span id="cb75-594"><a href="#cb75-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-597"><a href="#cb75-597" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-598"><a href="#cb75-598" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-599"><a href="#cb75-599" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-600"><a href="#cb75-600" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-601"><a href="#cb75-601" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-05</span></span>
<span id="cb75-602"><a href="#cb75-602" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-603"><a href="#cb75-603" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-604"><a href="#cb75-604" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb75-605"><a href="#cb75-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Tuning Kurven für den `xgboost` Algorithmus."</span></span>
<span id="cb75-606"><a href="#cb75-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-607"><a href="#cb75-607" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb75-608"><a href="#cb75-608" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">|&gt;</span></span>
<span id="cb75-609"><a href="#cb75-609" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">trees =</span> <span class="fu">as_factor</span>(trees),</span>
<span id="cb75-610"><a href="#cb75-610" aria-hidden="true" tabindex="-1"></a>         <span class="at">min_n =</span> <span class="fu">as_factor</span>(min_n)) <span class="sc">|&gt;</span></span>
<span id="cb75-611"><a href="#cb75-611" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mtry, mean, <span class="at">color =</span> min_n, <span class="at">linetype =</span> trees)) <span class="sc">+</span></span>
<span id="cb75-612"><a href="#cb75-612" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb75-613"><a href="#cb75-613" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb75-614"><a href="#cb75-614" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb75-615"><a href="#cb75-615" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb75-616"><a href="#cb75-616" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">label_number</span>()) <span class="sc">+</span></span>
<span id="cb75-617"><a href="#cb75-617" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_okabeito</span>()</span>
<span id="cb75-618"><a href="#cb75-618" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-619"><a href="#cb75-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-620"><a href="#cb75-620" aria-hidden="true" tabindex="-1"></a>Damit wir nicht händisch uns die beste Kombination raussuchen müssen, können wir die Funktion <span class="in">`show_best()`</span> nutzen.</span>
<span id="cb75-621"><a href="#cb75-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-624"><a href="#cb75-624" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-625"><a href="#cb75-625" aria-hidden="true" tabindex="-1"></a>gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb75-626"><a href="#cb75-626" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>()</span>
<span id="cb75-627"><a href="#cb75-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-628"><a href="#cb75-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-629"><a href="#cb75-629" aria-hidden="true" tabindex="-1"></a>Das war die Funktion <span class="in">`show_best()`</span> aber wir können uns auch die gleich die besten Parameter nach der Accuracy raus ziehen. Das Rausziehen der besten Parameter macht für uns die Funktion <span class="in">`select_best()`</span>.</span>
<span id="cb75-630"><a href="#cb75-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-633"><a href="#cb75-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-634"><a href="#cb75-634" aria-hidden="true" tabindex="-1"></a>best_xgboost <span class="ot">&lt;-</span> gummi_tune_res <span class="sc">|&gt;</span></span>
<span id="cb75-635"><a href="#cb75-635" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_best</span>()</span>
<span id="cb75-636"><a href="#cb75-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-637"><a href="#cb75-637" aria-hidden="true" tabindex="-1"></a>best_xgboost</span>
<span id="cb75-638"><a href="#cb75-638" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-639"><a href="#cb75-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-640"><a href="#cb75-640" aria-hidden="true" tabindex="-1"></a>Wir sehen, dass wir <span class="in">`mtry = 3`</span> wählen sollten. Dann müssen wir als Anzahl der Bäume <span class="in">`trees = 1000`</span> nutzen. Die minimale Anzahl an Beobachtungen pro Knoten ist dann <span class="in">`11`</span>. Müssen wir jetzt die Zahlen wieder in ein Modell eingeben? Nein, müssen wir nicht. Mit der Funktion <span class="in">`finalize_workflow()`</span> können wir dann die besten Parameter aus unserem Tuning gleich mit dem Workflow kombinieren. Dann haben wir unseren finalen, getunten Workflow. Du siehst dann auch in der Ausgabe, dass die neuen Parameter in dem xgboost Algorithmus übernommen wurden.</span>
<span id="cb75-641"><a href="#cb75-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-644"><a href="#cb75-644" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-645"><a href="#cb75-645" aria-hidden="true" tabindex="-1"></a>final_gummi_wf <span class="ot">&lt;-</span> gummi_tune_wflow <span class="sc">|&gt;</span> </span>
<span id="cb75-646"><a href="#cb75-646" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_xgboost)</span>
<span id="cb75-647"><a href="#cb75-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-648"><a href="#cb75-648" aria-hidden="true" tabindex="-1"></a>final_gummi_wf </span>
<span id="cb75-649"><a href="#cb75-649" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-650"><a href="#cb75-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-651"><a href="#cb75-651" aria-hidden="true" tabindex="-1"></a>Jetzt bleibt uns nur noch der letzte Fit übrig. Wir wollen unseren finalen, getunten Workflow auf die Testdaten anwenden. Dafür gibt es dann auch die passende Funktion. Das macht für uns die Funktion <span class="in">`last_fit()`</span>, die sich dann die Informationen für die Trainings- und Testdaten aus unserem Datensplit von ganz am Anfang extrahiert.</span>
<span id="cb75-652"><a href="#cb75-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-655"><a href="#cb75-655" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-656"><a href="#cb75-656" aria-hidden="true" tabindex="-1"></a>final_fit <span class="ot">&lt;-</span> final_gummi_wf <span class="sc">|&gt;</span></span>
<span id="cb75-657"><a href="#cb75-657" aria-hidden="true" tabindex="-1"></a>  <span class="fu">last_fit</span>(gummi_data_split) </span>
<span id="cb75-658"><a href="#cb75-658" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-659"><a href="#cb75-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-660"><a href="#cb75-660" aria-hidden="true" tabindex="-1"></a>Da wir immer noch eine Kreuzvaldierung rechnen, müssen wir dann natürlich wieder alle Informationen über alle Kreuzvaldierungsdatensätze einsammeln. Dann erhalten wir unsere beiden Gütekriterien für die Klassifikation des Geschlechts unser Studierenden nach dem xgboost Algorithmus. Die Zahlen sind schon gut für echte Daten. Eine Accuracy von 84% bedeutet das wir über acht von zehn Studierenden richtig klassifizieren. Die AUC ist auch schon fast hervorragend, wir bringen kaum Label durcheinander.</span>
<span id="cb75-661"><a href="#cb75-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-664"><a href="#cb75-664" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-665"><a href="#cb75-665" aria-hidden="true" tabindex="-1"></a>final_fit <span class="sc">|&gt;</span></span>
<span id="cb75-666"><a href="#cb75-666" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span>
<span id="cb75-667"><a href="#cb75-667" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-668"><a href="#cb75-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-669"><a href="#cb75-669" aria-hidden="true" tabindex="-1"></a>Dann bleibt uns nur noch die ROC Kurve zu visualisieren. Da wir wieder etwas faul sind, nutzen wir die Funktion <span class="in">`autoplot()`</span>. Als Alternative geht natürlich auch das <span class="co">[</span><span class="ot">R Paket `{pROC}`</span><span class="co">](https://web.expasy.org/pROC/screenshots.html)</span>, was eine Menge mehr Funktionen und Möglichkeiten bietet.</span>
<span id="cb75-670"><a href="#cb75-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-673"><a href="#cb75-673" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb75-674"><a href="#cb75-674" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb75-675"><a href="#cb75-675" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb75-676"><a href="#cb75-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb75-677"><a href="#cb75-677" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class-rf-06</span></span>
<span id="cb75-678"><a href="#cb75-678" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb75-679"><a href="#cb75-679" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb75-680"><a href="#cb75-680" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb75-681"><a href="#cb75-681" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "ROC Kurve für den Entscheidungsbaum mit dem `xgboost` Algorithmus nach der Kreuvalidierung und dem Tuning."</span></span>
<span id="cb75-682"><a href="#cb75-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-683"><a href="#cb75-683" aria-hidden="true" tabindex="-1"></a>final_fit <span class="sc">|&gt;</span></span>
<span id="cb75-684"><a href="#cb75-684" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_predictions</span>() <span class="sc">|&gt;</span> </span>
<span id="cb75-685"><a href="#cb75-685" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(gender, .pred_w, <span class="at">event_level =</span> <span class="st">"second"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb75-686"><a href="#cb75-686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>()</span>
<span id="cb75-687"><a href="#cb75-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb75-688"><a href="#cb75-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-689"><a href="#cb75-689" aria-hidden="true" tabindex="-1"></a>Eine gute ROC Kurve würde senkrecht nach oben gehen und dann waagrecht nach rechts. Dann hätten wir eine AUC von 1 und eine perfekte Separation der beiden Label durch unseren Algorithmus. Unser Algorithmus würde jedem weiblichen Studierenden in dem Testdatensatz korrekt dem Geschlecht <span class="in">`w`</span> zuweisen. Da wir eine ROC Kurve hier vorliegen haben, die sehr weit weg von der Diagonalen ist, haben wir sehr viele richtig vorhergesagte Studierende in unseren Testdaten. Unser Modell funktioniert um das Geschlecht von Studierenden anhand unserer Gummibärchendaten vorherzusagen.</span>
</code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Bio Data Science wurde von <a href="https://www.hs-osnabrueck.de/prof-dr-jochen-kruppa/">Jochen Kruppa-Scheetz</a> geschrieben.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/jkruppa/jkruppa.github.io/edit/master/classification-randomforest.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li><li><a href="https://github.com/jkruppa/jkruppa.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Problem melden</a></li><li><a href="https://github.com/jkruppa/jkruppa.github.io/blob/master/classification-randomforest.qmd" class="toc-action"><i class="bi empty"></i>Quellcode anzeigen</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Dieses Openbook wurde mit <a href="https://quarto.org/">Quarto</a> erstellt.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"selector":".lightbox","descPosition":"bottom","openEffect":"zoom","loop":false,"closeEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>