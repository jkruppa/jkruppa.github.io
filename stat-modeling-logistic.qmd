```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Logistische Regression {#sec-logistic}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

Die logistische Regression ist *die* Regression, wenn wir rüber in die Medizin schauen. Wohl in keinem Bereich der Wissenschaften wird so viel eine logistische Regression gerechnet wie in der Humanmedizin, Epidemiologie oder Pharmazie. Wir haben in der logistischen Regression ein $0/1$ Outcome als $y$ vorliegen. Also entweder ist eine Beobachtung erkrankt oder nicht. Meistens beschränkt sich die Betrachtung auf erkrankt ($1$, ja) oder eben nicht erkrankt ($0$, nein) bzw. gesund. Wichtig hierbei ist, dass wir eigentlich immer sagen, dass das *Schlechte* mit $1$ kodiert wird. Wenn du das machst, dann wird dir die Interpretation der Effektschätzer der logistischen Regression leichter fallen.

Gleich zu Beginn dann nochmal wir werden die logistische Regression in den Agrarwissenschaften eher selten sehen. Im Bereich der Pflanzenwissenschaften kommt die logistische Regression kaum bis gar nicht vor. Im Bereich der Tierwissenschaften schon eher, aber dort dann im Bereich der Tiermedizin und eben wieder Erkrankungen.

Wo wir hingegen dann wieder die logistische Regression brauchen, ist bei der Klassifikation oder eben der Vorhersage von einem binären Ereignis. Dafür bietet sich dann die logistische Regression wieder an. Deshalb werden wir am Ende des Kapitels nochmal was zur Klassifikation machen, obwohl das hier eigentlich nur so halb reinpasst. Wenn du nicht Klassifizieren willst, dann lasse den letzten Abschnitt einfach weg.

## Annahmen an die Daten

[Unser gemessenes Outcome $y$ folgt einer Binomialverteilung. Damit finden wir im Outcome nur $0$ oder $1$ Werte.]{.aside}

Im folgenden Kapitel zu der multiplen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Daher sieht unser Modell wie folgt aus. Wir haben ein $y$ und $p$-mal $x$. Wobei $p$ für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser $y$ einer Binomailverteilung. Damit finden wir im Outcome nur $0$ oder $1$ Werte. Das ist hier sehr wichtig, denn wir wollen ja eine multiple logistische lineare Regression rechnen.

$$
y \sim x_1 + x_2 + ... + x_p 
$$

Wir können in dem Modell auch Faktoren $f$ haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in @sec-posthoc nochmal nachlesen, wir du dann das Modell weiterverwendest.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               parameters, performance, gtsummary,
               tidymodels, cutpointr)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

In diesem Kapitel nutzen wir die infizierten Ferkel als Beispieldatensatz. Wir haben in dem Datensatz über vierhundert Ferkel untersucht und festgehalten, ob die Ferkel infiziert sind ($1$, ja) oder nicht infiziert ($0$, nein). Wir haben daneben noch eine ganze Reihe von *Risiko*faktoren erhoben. Hier sieht man mal wieder wie wirr die Sprache der Statistik ist. Weil wir rausfinden wollen welche Variable das Risiko für die Infektion erhöht, nennen wir diese Variablen Risikofaktoren. Obwohl die Variablen gar keine kategorialen Spalten sin bzw. nicht alle. So ist das dann in der Statistik, ein verwirrender Begriff jagt den Nächsten.

```{r}
pig_tbl <- read_excel("data/infected_pigs.xlsx") 
```

Schauen wir uns nochmal einen Ausschnitt der Daten in der @tbl-log-pigs an.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-log-pigs
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.
#| column: page

rbind(head(pig_tbl),
      rep("...", times = ncol(pig_tbl)),
      tail(pig_tbl)) %>% 
  kable(align = "c", "pipe")
```

In dem nächsten Abschnitt werden wir die Daten nutzen um rauszufinden welche Variablen einen Einfluss auf den Infektionsstatus der Ferkel hat.

## Theoretischer Hintergrund

Wir schaffen wir es, durch einen $0/1$ Outcome auf der y-Achse eine gerade Linie durch die Punkte zu zeichnen und die Koeffiziente dieser Gerade zu bestimmen? Immerhin gibt es ja gar keine Werte zwischen $0$ und $1$. In @fig-log-activity sehen wir beispielhaft den Zusammenhang zwischen dem Infektionsstatus und der Aktivität der Ferkel. Wir haben zwei horizontale Linien. Wie zeichen wir jetzt da eine Gerade durch?

```{r}
#| echo: true
#| message: false
#| label: fig-log-activity
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Visualisierung des Zusammenhangs zwischen dem Infektionsstatus und der Aktivität der Ferkel."


ggplot(pig_tbl, aes(x = activity, y = infected)) +
  theme_bw() +
  geom_point() 

```

Der Trick hierbei ist wieder die Transformation des *Zusammenhangs* von $y \sim x$ auf einen $\log$-scale. Das heißt wir Rechnen nicht mit den $0/1$ Werten sondern transformieren den gesamten Zusammenhang. Das ist wichtig, den es gibt einen Unterschied zwischen der Transformation von $y$ und der Transformation die hier gemeint ist. Wir halten fest, wir rechnen also nciht auf der ursprünglichen Skala der Daten sondern auf der $\log$-scale. Allgemeiner wird auch von der *link*-Funktion gesprochen, da wir ja verschiedene Möglichkeiten der Transformation des Zusammenhangs haben.

[Hier gibt es nur die Kurzfassung der *link*-Funktion. @dormann2013parametrische liefert hierzu in Kapitel 7.1.3 nochmal ein Einführung in das Thema.]{.aside}

Wir gehen wir also vor. Zuerst Modellieren wir die Wahrscheinlichkeit für den Eintritt des Ereignisses. Wir machen also aus unseren binären $0/1$ Daten eine Wahrscheinlichkeit für den Eintritt von 1.

$$
Y \rightarrow Pr(Y = 1)
$$

Damit haben wir schon was erreicht den $Pr(Y = 1)$ liegt zwischen $0$ und $1$. Damit haben wir also schon Werte *dazwischen*. Wenn wir aber normalverteilte Residuen haben wollen, dann müssen unsere Werte von $-\infty$ bis $+\infty$ laufen können. Daher rechnen wir im Weiteren die Chance.

$$
\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}
$$ Die Chance (eng. *Odds*) für das Eintreten von $Y=1$ ist eben die Wahrscheinlichkeit *für* das Eintreten geteilt durch die Gegenwahrscheinlichkeit. Das ist schon besser, denn damit liegen unsere transformierten Werte für den Zusammenhang schon zwischen $0$ und $+\infty$. Wenn wir jetzt noch den $\log$ von den Chancen rechnen, dann haben wir schon fast alles was wir brauchen.

$$
\log\left(\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}\right)
$$

Der Logarithmus der Chance liegt dann zwischen $-\infty$ und $+\infty$. Deshalb spricht man auch von den $\log$-Odds einer logistischen Regression. Auch sieht man hier woher das *logistisch* kommt. Wir beschreiben im Namen auch gleich die Transformation mit. Am ende kommen wir somit dann auf folgendes Modell.

$$
\log\left(\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}\right) = \beta_0 + \beta_1 x_1 + ...  + \beta_p x_p + \epsilon
$$ Vielleicht ist dir der Begriff Wahrscheinlichkeit und der Unterschied zur Chance nicht mehr so präsent. Deshalb hier nochmal als Wiederholung oder Auffrischung.

-   Eine *Wahrscheinlichkeit* beschreibt dem Anteil an Allen. Zum Beispiel den Anteil Gewinner an allen Teilnehmern. Den Anteil Personen mit Therapieerfolg an allen Studienteilnehmern.
-   Eine *Chance* oder (eng. *Odds*) beschreibt ein Verhältnis. Somit das Verhältnis Gewinner zu Nichtgewinner. Oder das Verhältnis Personen mit Therapieerfolg zu Personen ohne Therapieerfolg

Nochmal an einem Zahlenbeispiel. Wenn wir ein Glücksspiel haben, in dem es 2 Kombinationen gibt die gewinnen und drei 3 Kombinationen die verlieren, dann haben wir eine Wahrscheinlichkeit zu gewinnen von $2 / 5 = 0.40 = 40\%$. Wenn wir die Chance zu gewinnen ausrechnen erhalten wir $2:3 = 0.67 = 67\%$. Wir sehen es gibt einen deutlichen Unterschied zwischen Chance und Wahrscheinlichkeit. Wenn wir große Fallzahl haben bzw. kleine Wahrscheinlichkeiten, dann ist der Unterschied nicht mehr so drastisch. Aber von einer *Gleichkeit* von Wahrscheinlichkeit und Chance zu sprechen kann nicht ausgegangen werden.

Was ist nun das Problem? Wir erhalten aus einer logistischen Regression $\log$-Odds wieder. Der Effektchätzer ist also eine Chance. Wir werden aber das Ergebnis wie eine Wahrscheinlichkeit interpretieren. Diese Diskrepanz ist wenigen bekannt und ein Grund, warum wir in der Medizin immer uns daran erinnern müssen, was wir eigentlich mit der logistischen Regression *aussagen können*.

## Modellierung

Die Modellerierung der logistischen Regression ist sehr einfach. Wir nutzen wieder die Formelschreibweise im `glm()` um unsere Variablen zu definieren. Wenn unser Outcome nicht binär ist, dann jammert R und gibt uns einen Fehler aus. Ich kann hier nur dringlichst raten, das Outcome in $0/1$ zu kodieren mit dem Schlechten als $1$.

Das `glm()` muss dann noch wissen, dass es eine logistische Regression rechnen soll. Das machen wir in dem wir als Verteilungsfamilie die Binomialverteilung auswählen. Wir geben also an `family = binomial` und schon können wir das volle Modell fitten.

```{r}
#| message: false
#| warning: false
log_fit <- glm(infected ~ age + sex + location + activity + crp + 
                 frailty + bloodpressure + weight + creatinin, 
               data = pig_tbl, family = binomial)
```

Das war extrem kurz und scherzlos. Also können wir dann auch ganz kurz schauen, ob das Modell einigermaßen funktioniert hat.

## Performance des Modells

Nachdem wir das Modell gefittet haben, wollen wir uns nochmal das $R^2$ wiedergeben lassen um zu entscheiden, ob unser Modell einigermaßen funktioniert hat. Dieser Abschnitt ist sehr kurz. Wir haben leider nur sehr wenige Möglichkeiten um ein logistischen Modell zu bewerten.

```{r}
#| message: false
#| warning: false
r2(log_fit)
```

Ja, so viel Varianz erklären wir nicht, aber wenn du ein wenig im Internet suchst, dann wirst du feststellen, dass das Bestimmtheitsmaß so eine Sache in `glm()`'s ist. Wir sind aber einigermaßen zufrieden. Eventuell würde eine Variablenselektion hier helfen, aber das ist nicht Inhalt dieses Kapitels.

In @fig-log-model-check schauen wir nochmal auf die Residuen und die möglichen Ausreißer. Wieder sehen beide Plots einigermaßen in Ordnung aus. Die Abbildungen sind jetzt nicht die Besten, aber ich würde hier auch anhand der Diagnoseplots nicht die Modellierung verwerfen.

```{r}
#| echo: true
#| message: false
#| label: fig-log-model-check
#| fig-align: center
#| fig-height: 5
#| fig-width: 10
#| fig-cap: "Ausgabe ausgewählter Modelgüteplots der Funktion `check_model()`."

check_model(log_fit, colors = cbbPalette[6:8], 
            check = c("qq", "outliers")) 

```

## Interpretation des Modells

Zu Interpretation schauen wir uns wie immer nicht die rohe Ausgabe an, sondern lassen uns die Ausgabe mit der Funktion `model_parameters()` aus dem R Paket `parameters` wiedergeben. Wir müssen noch die Option `exponentiate = TRUE` wählen, damit unsere Koeffizienten nicht als $\log$-Odds sondern als Odds wiedergeben werden. Korrekterweise erhalten wir die Odds ratio wieder was wir auch als $OR$ angegeben.

```{r}
#| message: false
#| warning: false
model_parameters(log_fit, exponentiate = TRUE)
```

Wie interpretieren wir nun das $OR$ einer logistischen Regression? Wenn wir darauf gechtet haben, dass wir mit $1$ das Schlechte meinen, dann können wir wir folgt mit dem $OR$ sprechen. Wenn wir ein $OR > 1$ haben, dann haben wir ein Risiko vorliegen. Die Variable mit einem $OR$ größer als $1$ wird die Chance auf den Eintritt des schlechten Ereignisses erhöhen. Wenn wir ein $OR < 1$ haben, dann sprechen wir von einem protektiven Faktor. Die Variable mit einem $OR$ kleiner $1$ wird vor dem Eintreten des schlechten Ereignisses schützen. Schauen wir uns den Zusammenhang mal im Detail für die Ferkeldaten an.

-   `(intercept)` beschreibt den Intercept der logistischen Regression. Wenn wir mehr als eine simple Regression vorliegen haben, wie in diesem Fall, dann ist der Intercept schwer zu interpretieren. Wir konzentrieren uns auf die Effekte der anderen Variablen.
-   `sex` beschreibt den Effekt der männlichen Ferkel zu den weiblichen Ferkeln. Daher haben männliche Ferkel eine $2.75$ höhere Chance infiziert zu werden als weibliche Ferkel.
-   `location [northeast]`, `location [northwest]` und `location [west]` beschreibt den Unterschied zur `location [north]`. Alle Orte haben eine geringere Chance für eine Infektion zum Vergleich der Bauernhöfe im Norden. Zwar ist keiner der Effekte signifikant, aber ein interessantes Ergebnis ist es allemal.
-   `activity` beschreibt den Effekt der Aktivität der Ferkel. Wenn sich die Ferkel mehr bewegen, dann ist die Chance für eine Infektion gemindert.
-   `crp` beschreibt den Effekt des CRP-Wertes auf den Infektionsgrad. Pro Einheit CRP steigt die Chance einer Infektion um $2.97$ an. Das ist schon ein beachtlicher Wert.
-   `frailty` beschreibt die Gebrechlichkeit der Ferkel. Hier müssen wir wieder schauen, zu welchem Level von `frailty` wir vergleichen. Hier vergleichen wir zu `frail`. Also dem höchsten Gebrechlichkeitgrad. Ferkel die weniger gebrechlich sind, haben eine niedrigere Chance zu erkranken.
-   `bloodpressure`, `weight` und `creatinin` sind alles Variablen, mit einem $OR$ größer als $1$ und somit alles Riskovariablen. Hier sind zwar die $OR$ relativ klein, aber das muss erstmal nichts heißen, da die $OR$ ja hier die *Änderung* für eine Einheit von $x$ beschreiben. Deshalb musst du immer schauen, wie die Einheiten von kontinuierlichen kodiert Variablen sind.

Kommen wir nochmal zu den gänigen Tabellen für die Zusammenfassung eines Ergebnisses einer logistischen Regression. Teilweise sind diese Tabellen so generisch und häufiog verwendet, dass wir schon einen Begriff für diese Tabellen haben. In @tbl-tbl-summary-logreg siehst du die *table 1* für die Übersicht aller Risikovariablen aufgeteilt nach dem Infektionsstatus. Diese Art der Tabellendarstellung ist so grundlegend für eine medizinische Veröffentlichung, dass sich eben der Begriff *table 1* etabliert hat. Fast jede medizinische Veröffentlichung hat als erste Tabelle diese Art von Tabelle angegeben. Hierbei ist wichtig, dass die $p$-Werte alle nur aus einem einfachen statistischen Test stammen. Die $p$-Werte einer multiplen logistischen Regression werden daher immer anders sein.

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-summary-logreg
#| tbl-cap: "Ausgabe der Daten in einer Summary Table oder auch Table 1 genannt. In medizinischen Veröffentlichungen immer die erste Tabelle für die Zusammenfassung der Patienten (hier Ferkel) für jede erhobende Risikovariable."

pig_tbl %>% tbl_summary(by = infected) %>% add_p() %>% as_flex_table()
```

In @tbl-tbl-uni-logreg siehst du nochmal für eine Auswahl an Variablen die simplen logistischen Regressionen gerechnet. Du müsst also nicht jede simple logistische Regression selber rechnen, sondern kannst auch die Funktion `tbl_uvregression()` verwenden. Das R Paket `tbl_summary` erlaubt weitreichende Formatierungsmöglichkeiten. Am bestes schaust du einmal im Tutorial [Tutorial: tbl_regression](https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html) selber nach was du brauchst oder anpassen willst.

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-uni-logreg
#| tbl-cap: "Simple logistische Regression für eine Auswahl an Einflussvariablen. Für jede Einflussvariable wurde eine simple logistische Regression gerechnet."

pig_tbl%>%
  select(infected, age, crp, bloodpressure) %>%
  tbl_uvregression(
    method = glm,
    y = infected,
    method.args = list(family = binomial),
    exponentiate = TRUE,
    pvalue_fun = ~style_pvalue(.x, digits = 2)
  ) %>% as_flex_table()
```

nun gibt es viele Möglichkeiten sich die logistische Regression wiedergeben zu lassen In @tbl-tbl-regression-logreg siehst du nochmal die Möglichkeit, die dir das R Paket `tbl_summary()` bietet. Am Ende ist es dann eine reine Geschmacksfrage, wie wir die Daten dann aufarbeiten wollen.

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-regression-logreg
#| tbl-cap: "Ausgabe der multiplen logistischen Regression durch die Funktion `tbl_regression()`."

log_fit %>% tbl_regression(exponentiate = TRUE) %>% as_flex_table()
```

Zum Abschluss wollen wir uns einmal die Ergebnisse des Modellfits als logistischen Gerade für eine simple lineare Regression mit dem Modell $infected \sim crp$ anschauen. Wie immer können wir uns den Zusammenhang nur in einem simplen Modell anschauen. Im Fall einer multiplen linearen Regresion können wir nicht so viele Dimensionen in einer Grpahik darstellen. Wir fitten also das Modell `log_fit_crp` wie im folgenden dargestellt.

```{r}
log_fit_crp <- glm(infected ~ crp, data = pig_tbl, family = binomial)
```

Nun können wir uns mit der Funktion `predict()` die Wert auf der Geraden wiedergeben lassen. Wenn wir `predict()` nur so aufrufen, dann erhalten wir die Werte für $y$ auf der transformierten $link$-Scale wieder. Das hilft uns aber nicht weiter, wir haben ja nur 0 und 1 Werte für $y$ vorliegen.

```{r}
predict(log_fit_crp, type = "link") %>% 
  extract(1:10) %>% 
  round(2)
```

Da wir die Werte für die Wahrscheinlichkeit das ein Ferkel infiziert ist, also die Wahrscheinlichkeit $Pr(infected = 1)$, müssen wir noch die Option `type = reponse` wählen. So erhalten wir die Wahrscheinlichkeiten wiedergegeben.

```{r}
predict(log_fit_crp, type = "response") %>% 
  extract(1:10) %>% 
  round(2)

```

Abschließend können wir uns die Gerade auch in der @fig-log-pred visualisieren lassen. Auf der x-Achse sehen wir die `crp`-Werte und auf der y-Achse den Infektionsstatus. Auf der $reponse$-scale sehen wir eine S-Kurve. Auf der $link$-scale würden wir eine Gerade sehen.

```{r}
#| echo: true
#| message: false
#| label: fig-log-pred
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Visualisierung der logistischen Gerade in einer simplen logistischen Regression mit der Variable `crp`."

ggplot(pig_tbl, aes(x = crp, y = infected)) +
  theme_bw() +
  geom_point() +
  geom_line(aes(y = predict(log_fit_crp, type = "response")), color = "red") 

```

Nun haben wir das Kapitel zur logistischen Regression fast abgeschlossen. Was noch fehlt ist die Besonderheit der Prädiktion im Kontext des maschinellen Lernens. Das machen wir jetzt im folgenden Abschnitt. Wenn dich die logistische Regression nur interessiert hat um einen kausalen Zusammenhang zwischen Einflussvariablen und dem binären Outcome zu modellieren, dann sind wir hier fertig.

## Dichotomisierung

Manchmal ist es so, dass wir eine logistsiche Regression rechnen wollen. Wir fragen nicht, wie ist unser $y$ verteilt und was für eine Regression können wir dann rechnen? Sondern wir wollen mit der logistischen Regression durch die Wand. Wenn wir das wollen, dann können wir unser $y$ dichotomisieren. Das heißt, wir machen aus einer Variable, die mehr als zwei Level hat einen Faktor mit zwei Leveln. Dafür stehen uns verschiedene Möglichkeiten offen.

In dem R Paket `dplyr` haben wir mit der Funktion `recode()` die Möglichkeit eine Variable von `alt = neu` umzukodieren. Dabei müssen wir natürlich darauf achten, dass wir die alten Level der Variable richtig schreiben und bei der neuen Level nur zwei Namen eintragen. Dann sind wir auch schon durch mit der Umbenennung.

```{r}
pig_tbl %>% 
  mutate(frailty = recode(frailty, 
                          "robust" = "robust", 
                          "pre-frail" = "frail_prefrail", 
                          "frail" = "frail_prefrail")) %>% 
  pull(frailty) %>% extract(1:20)
```

Ich finde die Funktion `case_when()` etwas übersichtlicher. Das ist aber eigentlich nur eine Geschmacksfrage. Am Ende kommt jedenfalls das Gleiche heraus.

```{r}
pig_tbl %>% 
mutate(frailty = case_when(frailty == "robust" ~ "robust",
                           frailty == "pre-frail" ~ "frail",
                           frailty == "frail" ~ "frail")) %>% 
  pull(frailty) %>% extract(1:20)
```

Häufig haben wir auch den Fall, dass wir keine kontinuierlichen $x$ in unseren Daten wollen. Alles soll sich in Faktoren verwandeln, so dass wir immer eine 2x2 Tafel haben. Wenn es sein muss, liefert hier `cutpointr()` die Lösung für dieses Problem. Wir müssen dafür zum einen unser kontinuierliches $x$ angeben und dann mit `class` unser binäres $y$. Wir erhalten dann für unser $y$ den bestmöglichen Split für unser $x$. Im Beispiel wollen wir einmal die Variable `crp` für unser Outcome `infected` in zwei Gruppen aufteilen. Wir wollen eigentlich immer zwei Gruppen, da wir dann in dem Setting eines $\mathcal{X}^2$-Test und einer einfacheren Interpretation von dem $OR$ sind.

Wir immer haben wir eine große Bandbreite an Optionen, wie wir den besten Split unseres $x$ kriegen wollen. Ich gehe hier mit den Default-Werten. Damit kommt man eigentlich recht weit. Ich möchte gerne die Summe der Sensivität und der Spezifität `sum_sens_spec` über alle möglichen Cutpoints maximieren `maximize_metric`. Der Cutpoint mit der maximalen Summe an Sensivität und der Spezifität wird mir dann wiedergegeben.

::: column-margin
Natürlich hat das R Paket `cutpoint` noch viel mehr Optionen. Mehr gibt es in [An introduction to cutpointr](https://cran.r-project.org/web/packages/cutpointr/vignettes/cutpointr.html).
:::

```{r}
#| message: false
#| warning: false

cp_crp <- cutpointr(data = pig_tbl,
                    x = crp,
                    class = infected,
                    method = maximize_metric, 
                    metric = sum_sens_spec) 

cp_crp
```

In @fig-crp-bin sehe wir die Ausgabe der Funktion `cutpointr()` nochmal visualisiert. Wir sehen, dass der Split einigermaßen die `crp`-Werte im Sinne von unserem Outcome aufteilt.

```{r}
#| echo: true
#| message: false
#| label: fig-crp-bin
#| fig-align: center
#| fig-height: 6
#| fig-width: 9
#| fig-cap: "Visualisierung des Ergebnisses der Funktion `cutpointr` für die Variable `crp`."

plot(cp_crp)
```

Wir können uns jetzt noch den optimalen Cutpoint aus der Ausgabe herausziehen, wenn wir den Punkt nicht aus der Ausgabe ablesen wollen.

```{r}
pluck(cp_crp, "optimal_cutpoint")
```

Am Ende können wir dann über `case_when()` uns ein binären CRP-Wert zusammenbauen. Wir müssen dann natürlich entscheiden welche Variable wir mit ins Modell nehme, aber meistens machen wir uns ja die Mühen um dann die neue Variable zu verwenden.

```{r}
pig_tbl %>% 
mutate(crp_bin = case_when(crp >= 19.84 ~ "high",
                           crp < 19.84 ~ "low")) %>% 
select(crp, crp_bin)  
```

Damit haben wir uns dann auch mit dem Problem der Dichotomisierung in der logististischen Regression einmal beschäftigt. Somit bleibt dann noch die Prädiktion übrig.

## Prädiktion

Da wir später in dem @sec-class-basic die logistische Regression auch als Vergleich zu maschinellen Lernverfahren in der Klassifikation nutzen werden gehen wir hier auch die Prädiktion einmal für die logistische Regression durch. Wir wollen also eine Klassifikation, also eine Vorhersage, für das Outcome `infected` mit einer logistischen Regression rechnen. Wir nutzen dazu die Möglichkeiten des R Pakets `tidymodels` wodurch wir einfacher ein Modell bauen und eine Klassifikation rechnen können. Unsere Fragestellung ist, ob wir mit unseren Einflussvariablen den Infektionsstatus vorhersagen können. Das heißt wir wollen ein Modell bauen mit dem wir *zukünftige* Ferkel als potenziell krank oder gesund anhand unser erhobenen Daten einordnen bzw. klassifizieren können.

::: column-margin
Mehr zu Rezepten (eng. *recipes*) kannst du im @sec-class-basic zu den Grundlagen des maschinellen Lernens erfahren.
:::

Der erste Schritt einer Klassifikation ist immer sicherzustellen, dass unser Outcome auch wirklich aus Kategorien besteht. In R nutzen wir dafür einen Faktor und setzen dann auch gleich die Ordnung fest.

```{r}
pig_tbl <- pig_tbl %>% 
  mutate(infected = factor(infected, levels = c(0, 1)))
```

Nun bauen wir uns ein einfaches Rezept mit der Funktion `recipe()`. Dafür legen wir das Modell, was wir rechnen wollen einmal fest. Wir nehmen `infected` als Outcome und den Rest der Vairbalen `.` aus dem Datensatz `pig_tbl` als die $x$ Variablen. Dann wollen wir noch alle Variablen, die ein Faktor sind in eine Dummyvariable umwandeln.

```{r}
pig_rec <- recipe(infected ~ ., data = pig_tbl) %>% 
  step_dummy(all_nominal_predictors())
```

Wir wollen jetzt unser Modell definieren. Wir rechnen eine logistsiche Regression und deshalb nutzen wir die Funktion `logistic_reg()`. Da wir wirklich viele Möglichkeiten *hätten* die logistische Regression zu rechnen, müssen wir noch den Algorithmus wählen. Das tuen wir mit der Funktion `set_engine()`. Wir nutzen hier den simplen `glm()` Algorithmus. Es gebe aber auch andere Implementierungen.

```{r}
logreg_mod <- logistic_reg() %>% 
  set_engine("glm")
```

Jetzt müssen wir noch einen Workflow definieren. Wir wollen ein Modell rechnen und zwar mit den Informationen in unserem Rezept. Das bauen wir einmal zusammen und schauen uns die Ausgabe an.

```{r}
pig_wflow <- workflow() %>% 
  add_model(logreg_mod) %>% 
  add_recipe(pig_rec)

pig_wflow
```

Das passt alles soweit. Ja, es ist etwas kompliziert und das ginge sicherlich auch einfacher. Wir werden dann aber noch sehen, dass wir es uns mit dem Ablauf sehr viel einfacher machen, wenn wir kompliziertere Modelle schätzen wollen. Mehr dazu findest du dann im @sec-class-basic zu den maschinellen Lernverfahren.

Jetzt können wir den Workflow nutzen um den Fit zu rechnen. Bis jetzt haben wir nur Informationen gesammelt. Dadurch das wir jetzt das Objekt `pig_workflow` in die Funktion `fit()` pipen rechnen wir das Modell.

```{r}
pig_fit <- pig_wflow %>% 
  fit(data = pig_tbl)
```

Das erhaltende Modell könne wir dann in die Funktion `predict()` stecken um uns den Inektionsstatus vorhersagen zu lassen.

```{r}
predict(pig_fit, new_data = pig_tbl)
```

In der Spalte `.pred_class` finden wir dann die *vorhergesagten* Werte des Infektionsstatus anhand unseres gefitteten Modells. Eigentlich würden wir ja gerne die vorhergesagten Werte mit unseren Orginalwerten vergleichen. Hier hilft uns die Funktion `augment()`. Dank der Funktion `augment()` erhalten wir nicht nur die vorhergesagten Klassen sondern auch die Wahrscheinlichkeit für die Klassenzugehörigkeiten. Daneben dann aber auch die Originalwerte für den Infektionsstatus in der Spalte `infected`.

```{r}
pig_aug <- augment(pig_fit, new_data = pig_tbl) %>% 
  select(infected, matches("^\\."))

pig_aug
```

Wir können dann die Werte aus dem Objekt `pig_aug` nutzen um uns die ROC Kurve als Güte der Vorhersage wiedergeben zu lassen. Wir nutzen hier die schnelle Variante der Ploterstellung. In dem @sec-class-model-compare zum Vergleich von Algorithmen gehe ich noch näher auf die möglichen Optionen bei der Erstellung einer ROC Kurve ein. Hier fällt die ROC Kurve dann mehr oder minder vom Himmel. Ich musste noch der Funktion mitgeben, dass das Event bei uns das zweite Level des Faktors `infected` ist. Sonst ist unsere ROC Kurve einmal an der Diagonalen gespiegelt.

[In dem @sec-test-diag erfährst du mehr darüber was eine ROC Kurve ist und wie du die ROC Kurve interpretieren kannst.]{.aside}

```{r}
#| echo: true
#| message: false
#| label: fig-log-roc
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "ROC Kurve für die Vorhersage des Infektionsstatus der Ferkel anhand der erhobenen Daten."

pig_aug %>% 
  roc_curve(truth = infected, .pred_1, event_level = "second") %>% 
  autoplot()
```

Na das hat doch mal gut funktioniert. Die ROC Kurve verläuft zwar nicht ideal aber immerhin ist die ROC Kurve weit von der Diagnolen entfernt. Unser Modell ist also in der Lage den Infektionsstatus der Ferkel einigermaßen solide vorherzusagen. Schauen wir uns noch die *area under the curve* (abk. *AUC*) an.

```{r}
pig_aug %>% 
  roc_auc(truth = infected, .pred_1, event_level = "second")
```

Der beste Wert wäre hier eine AUC von $1$ und damit eine perfekte Vorhersage. Der schlechteste Wert wäre eine AUC von $0.5$ und damit eine nahezu zufällige Zuordnung des Infeketionsstatus zu den Ferkeln von unserem Modell. Mit einer AUC von $0.83$ können wir aber schon gut leben. Immerhin haben wir kaum am Modell rumgeschraubt bzw. ein Tuning betrieben. Wenn du mehr über Tuning und der Optimierung von Modellen zu Klassifikation wissen willst, dan musst du im @sec-class-basic zu den maschinellen Lernverfahren anfangen zu lesen.

## Referenzen {.unnumbered}
