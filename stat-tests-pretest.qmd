```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Pre-Tests oder Vortest {#sec-pretest}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Probleme mit dem Pre-Tests ist, dass die Fallzahl in unseren Daten $D$ oft **viel zu klein** ist um eine eindeutige Aussage zu treffen.
:::

Der Pre-Test, ein Kapiel was ich nicht mag. Also eher weniger das Kapitel als den Pre-Test. Auf der einen Seite sind die Pre-Tests hoffnungslos veraltet. Pre-Tests stammen aus einer Zeit in der man sich nicht einfach die Daten angucken konnte. Mit angucken meine ich dann in `ggplot` visualisieren. Die Idee hinter Pre-Test ist eigentlich die Angst selber die Entscheidung zu treffen, ob die Daten varianzhomogen oder normalverteilt sind. Eine bessere Lösung ist immer noch das Outcome $y$ zu transformieren (siehe @sec-eda-transform) und dann das untransformierte Modell mit transformierten Modell zu vergleichen (siehe @sec-model-basic-compare). Auf der anderen Seite ist der Pre-Test eine Art übermächtiger Entscheider. Dabei sind die Formel sehr trivial und das Konzept eher simpel.

Neben dieser Angst eine Entscheidung zu treffen, hilft einem der Pre-Test zur Varianzhomogenität und der Pre-Test zur Normalverteilung bei kleiner Fallzahl auch nicht wirklich weiter, wie wir gleich sehen werden. Beide Pre-Tests funktionieren erst bei wirklich hohen Fallzahlen gut. Mit hohen Fallzahlen meine ich, Fallzahlen von über 20 Beobachtungen *je Gruppe* bzw. Level des Faktors. Bei kleiner Fallzahl, also der üblichen Anzahl von weniger als zehn Wiederholungen, können wir auch nur die Boxplots oder Dotplots anschauen. Darüber hinaus können wir uns auch schnell ins Abseits testen, so dass wir gar keinen Test mehr übrig haben um unsere Daten auszuwerten.

::: column-margin
Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/intro.html) erlaubt eine weitreichende Diagnostik auf einem normalverteilten Outcome $y$. Es ist besser sich die Diagnostikplots anzuschauen, als die statistischen Pre-Tests zu rechnen. Besonders bei kleiner Fallzahl.
:::

Es ist grundsätzlich besser verschiedene Modelle zu fitten und dann sich in @sec-lin-reg-quality die Güte oder Qualität der Modelle anzuschauen. Jedenfalls ist das meiner Meinung nach die bessere Lösung. Da aber immer wieder nach den Pre-Tests gefragt wird, habe ich auch dieses Kapitel erschaffen.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted,
               broom, car, performance, see)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

## Pre-Test auf Varianzhomogenität

Was will also der Pre-Test auf Varianzhomogenität? Eigentlich ist der Test vollkommen verquer. Zum einen testet der Test auf Varianzhomogenität gar nicht die *Anwesenheit* von Homogenität. Wir können dank dem Falisifikationsprinzip nur Ablehnen. Deshalb steht in der Nullhypothese die Gleichheit der Varianzen, also Varianzhomogenität und in der Alternativen dann die Varianzheterogenität, als der Unterschied.

Ab wann sollten wir denn die Varianzhomogenität ablehnen? Wenn wir standardmäßig auf 5% testen, dann werden wir zu selten die Varianzhomogenität ablehnen. Daher ist es ratsam in diesem Fall auf ein Signifikanzniveau von $\alpha$ gleich 20% zu testen. Aber auch in diesem Fall können wir natürlich eine Varianzhomogenität übersehen oder aber eine Varianzhterogenität fälschlicherweise annehmen.

Es ergeben sich folgende Hypothesen für den Pre-Test auf Varianzhomogenität.

$$
\begin{aligned}
H_0: &\; s^2_A = s^2_B\\
H_A: &\; s^2_A \ne s^2_B\\
\end{aligned}
$$

Wir sehen, dass in der Nullhypothese die Gleichheit der Varianzen steht und in der Alternativehypothese der Unterschied, also die Varianzhterogenität.

::: callout-important
## Entscheidung zur Varianzhomogenität

Bei der Entscheidung zur Varianzhomogenität gilt folgende Regel. Ist der $p$-Wert des Pre-Tests auf Varianzhomogenität kleiner als das Signifikanzniveau $\alpha$ von 20% lehnen wir die Nullhypothese ab. Wir nehmen Varianzheterogenität an.

-   Ist $p \leq \alpha = 20\%$ so nehmen wir Varianzheterogenität an.
-   Ist $p > \alpha = 20\%$ so nehmen wir Varianzhomogenität an.

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf Varianzhomogenität nochmal visuell bestätigen.
:::

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Einigermaßen zuverlässig meint, dass wir dann in 1 von 20 Fällen eine Varianzhomogenität ablehnen, obwohl eine Varianzhomogenität vorliegt. Ebenso können wir in 1 von 5 Fällen die Nullhypothese nicht ablehnen, obwohl die Varianzen heterogen sind (siehe auch @sec-alpha-beta).
:::

Wir nutzen zum statistischen Testen den Levene-Test über die Funktion `leveneTest()` oder den Bartlett-Test über die Funktion `bartlett.test()`. Beide Tests sind in R implementiert und können über das Paket `car` genutzte werden. Wir werden uns jetzt nicht die Formel anschauen, wir nutzen wenn die beiden Tests nur in R und rechnen nicht selber die Werte nach.

Einfach ausgedrückt, überprüft der Bartlett-Test die Homogenität der Varianzen auf der Grundlage des Mittelwerts. Dementsprechend ist der Bartlett-Test empfindlicher gegen eine Abweichung von der Normalverteilung der Daten, die er überprüfen soll. Der Levene-Test überprüft die Homogenität der Varianzen auch auf der Grundlage des Mittelwerts. Wir haben aber auch die Wahl, den Median zu nutzen dann ist der Levene-Test robuster gegenüber Ausreißern.

![](images/caution.png){fig-align="center" width="50%"}

$$
W = \frac{(N-k)}{(k-1)} \cdot \frac{\sum_{i=1}^k N_i (\bar{Z}_{i\cdot}-\bar{Z}_{\cdot\cdot})^2} {\sum_{i=1}^k \sum_{j=1}^{N_i} (Z_{ij}-\bar{Z}_{i\cdot})^2}
$$

Wir haben $N = 14$ Beobachtungen für $k = 2$ Tierarten mit Hunden und Katzen.

$$
Z_{ij} = 
\begin{cases}
|Y_{ij} - \bar{Y}_{i\cdot}|, & \bar{Y}_{i\cdot} \text{ ist der Mittelwert der } i\text{-ten Gruppe}, \\
|Y_{ij} - \tilde{Y}_{i\cdot}|, & \tilde{Y}_{i\cdot} \text{ ist der Median der } i\text{-ten Gruppe}. 
\end{cases} 
$$

```{r}
#| message: false

z_tbl <- tibble(dog = c(5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6),
                cat = c(3.2, 2.2, 5.4, 4.1, 1.1, 7.9, 8.6),
                dog_abs = abs(dog - mean(dog)),
                cat_abs = abs(cat - mean(cat)))
z_tbl
```

$\bar{Z}_{i\cdot}$

```{r}
mean(z_tbl$dog_abs)
```

```{r}
mean(z_tbl$cat_abs)
```

$\bar{Z}_{\cdot\cdot}$

```{r}
(1.57 + 2.28)/2
```

$\sum_{i=1}^k \sum_{j=1}^{N_i} (Z_{ij}-\bar{Z}_{i\cdot})^2$

```{r}
sum((z_tbl$dog_abs - 1.57)^2)
sum((z_tbl$cat_abs - 2.28)^2)

```

$$
W = 
\cfrac{14-2}{2-1}\cdot
\cfrac{7 \cdot (1.57 - 1.92)^2 + 7 \cdot (2.28 - 1.92)^2}
{10.39 + 11.43} =
\cfrac{12}{1} \cdot \cfrac{1.76}{21.82} =
\cfrac{36.96}{21.82} \approx 1.69
$$

```{r}
#| message: false
#| warning: false
z_tbl %>% 
  gather(key = animal, value = jump_length) %$% 
  leveneTest(jump_length ~ animal, center = "mean")

```

Wir wollen uns nun zwei Fälle einmal näher anschauen. Zum einen den Fall, dass wir eine niedrige Fallzahl vorliegen haben und Varianzhomogenität sowie den Fall, dass wir eine niedrige Fallzahl und Varianzheterogenität vorliegen haben. Den Fall, dass wir hohe Fallzahl vorliegen haben, betrachten wir jetzt nicht weiter. In dem Fall funktionieren die Tests einigermaßen zuverlässig.

## Varianzen sind homogen, Fallzahl niedrig

Wir bauen uns nun einen Datensatz mit zwei Gruppen $A$ und $B$ zu je zehn Beobachtungen. Beide Gruppen kommen aus einer Normalverteilung mit einem Mittelwert von $\bar{y}_A = \bar{y}_A = 10$. Darüber hinaus haben wir Varianzhomogenität mit $s_A = s_B = 5$ vorliegen. Ja, wir spezifizieren hier in der Funktion `rnorm()` die Standardabweichung, aber eine homogene Standardabweichung bedingt eine homogene Varianz und umgekehrt. Abschließend verwandeln wir das Wide-Format noch in das Long-Format um.

```{r}
set.seed(202209013)
small_homogen_tbl <- tibble(A = rnorm(n = 10, mean = 10, sd = 5),
                            B = rnorm(n = 10, mean = 10, sd = 5)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In der @fig-vartest-1 sehen wir die Daten aus dem `small_homogen_tbl` einmal als Boxplot visualisiert.

```{r}
#| message: false
#| echo: false
#| label: fig-vartest-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Boxplot der beiden Treatment Level A und B. Beide Gruppen haben die gleichen Varianzen. Es liegt Varianzhomogenität vor."

ggplot(small_homogen_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_boxplot() +
  scale_fill_okabeito() +
  theme(legend.position = "none")
```

Wir wollen nun die Varianz auf Homogenität testen. Wir nutzen dafür den `leveneTest()` sowie den `bartlett.test()`. Beide Tests bieten sich an. Die Daumenregel ist, dass der Bartlett-Test etwas bessere statistische Eigenschaften hat. Dennoch ist der Levene-Test bekannter und wird häufiger angefragt und genutzt. Wir nutzen die Funktion `tidy()` aus dem Paket `broom` um die Ausgabe aufzuräumen und selektieren nur den $p$-Wert.

```{r}
leveneTest(rsp ~ trt, data = small_homogen_tbl) %>% 
  tidy %>% 
  select(p.value)

bartlett.test(rsp ~ trt, data = small_homogen_tbl) %>% 
  tidy %>% 
  select(p.value)
```

Wir sehen, dass der $p$-Wert größer ist als das Signifikanzniveau $\alpha$ von 20%. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen Varianzhomogenität an. Überdies sehen wir auch, dass sich die $p$-Werte nicht groß voneinander unterscheiden.

Wir können auch die Funktion `check_homogeneity()` aus dem Paket `performance` nutzen. Wir erhalten hier auch gleich eine Entscheidung in englischer Sprache ausgegeben. Die Funktion `check_homogeneity()` nutzt den Bartlett-Test. Wir können in Funktion auch andere Methoden mit `method = c("bartlett", "fligner", "levene", "auto")` wählen.

```{r}
lm(rsp ~ trt, data = small_homogen_tbl) %>% 
  check_homogeneity()
```

Wir nutzen das Paket `performance` für die Modellgüte im @sec-lin-reg-quality.

## Varianzen sind heterogen, Fallzahl niedrig

Nun stellt sich die Frage, wie sieht es aus, wenn wir ungleiche Varianzen vorliegen haben. Wir bauen uns nun einen Datensatz mit zwei Gruppen $A$ und $B$ zu je zehn Beobachtungen. Beide Gruppen kommen aus einer Normalverteilung mit einem Mittelwert von $\bar{y}_A = \bar{y}_A = 12$. Darüber hinaus haben wir Varianzheterogenität mit $s_A = 10 \ne s_B = 5$ vorliegen.

```{r}
set.seed(202209013)
small_heterogen_tbl <- tibble(A = rnorm(10, 10, 12),
                              B = rnorm(10, 10, 5)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In der @fig-vartest-2 sehen wir die Daten aus dem `small_heterogen_tbl` einmal als Boxplot visualisiert.

```{r}
#| message: false
#| echo: false
#| label: fig-vartest-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Boxplot der beiden Treatment Level A und B. Beide Gruppen haben ungleiche Varianzen. Es liegt Varianzheterogenität vor."

ggplot(small_heterogen_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_boxplot() +
  scale_fill_okabeito() +
  theme(legend.position = "none")
```

Wir wollen nun die Varianz auf Homogenität testen. Wir nutzen dafür den `levenTest()` sowie den `bartlett.test()`. Wir können nur die Varianzhomogenität testen, da jeder statistischer Test nur eine Aussage über die Nullhypothese erlaubt. Damit können wir hier nur die Varianzhomogenität testen.

```{r}
leveneTest(rsp ~ trt, data = small_heterogen_tbl) %>% 
  tidy %>% 
  select(p.value)

bartlett.test(rsp ~ trt, data = small_heterogen_tbl) %>% 
  tidy %>% 
  select(p.value)
```

Wir sehen, dass der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$ von 20%. Damit können wir die Nullhypothese ablehnen. Wir nehmen Varianzheterogenität an. Überdies sehen wir auch, dass sich die $p$-Werte nicht groß voneinander unterscheiden. Was wir sehen ist, dass wir zu einem Signifikanzniveau von 5% die klare Varianzheterogenität nicht erkannt hätten und immer noch Varianzhomogenität angenommen hätten.

Wir können auch die Funktion `check_homogeneity()` aus dem Paket `performance` nutzen. Wir erhalten hier auch gleich eine Entscheidung in englischer Sprache ausgegeben. Die Funktion `check_homogeneity()` nutzt den Bartlett-Test. Wir können in Funktion auch andere Methoden mit `method = c("bartlett", "fligner", "levene", "auto")` wählen.

```{r}
lm(rsp ~ trt, data = small_heterogen_tbl) %>% 
  check_homogeneity()
```

Wir sehen, dass sich die Implementierung des Bartlett-Tests in `check_homogeneity()` nicht von der Funktion `bartlett.test()` unterscheidet, aber die Entscheidung gegen die Varianzhomogenität zu einem Signifikanzniveau von 5% gefällt wird. Nicht immer hilft einem der Entscheidungtext einer Funktion.

## Pre-Test auf Normalverteilung

Wir treffen bei dem Test auf die Normalverteilung auch auf das gleiche Problem wie bei dem Pre-Test zur Varianzhomogenität. Wir haben wieder die Gleichheit, also das unser beobachtetes Outcome gleich einer Normalverteilung ist, in der Nullhypothese stehen. Den Unterschied, also das unser beobachtetes Outcome nicht aus einer Normalverteilung kommmt, in der Alternative.

$$
\begin{aligned}
H_0: &\; \mbox{y ist gleich normalverteilt}\\
H_A: &\; \mbox{y ist nicht gleich normalverteilt}\\
\end{aligned}
$$

Nun ist es aber so, dass es nicht nur *zwei* Verteilungen gibt. Es gibt mehr als die Normalverteilung und die *Nicht*-normalverteilung. Wir haben eine große Auswahl an möglichen Verteilungen und seit den 90zigern des letzten Jahrhunderts auch die Möglichkeiten andere Verteilungen des Outcomes $y$ zu modellieren. Leider fällt dieser Fortschritt häufig unter den Tisch und wir bleiben gefangen zwischen der Normalverteilung oder eben keiner Normalverteilung.

::: column-margin
Der [zentrale Grenzwertsatz](https://de.wikipedia.org/wiki/Zentraler_Grenzwertsatz) besagt, dass wenn ein $y$ von vielen Einflussfaktoren $x$ bestimmt wird, man von einem normalverteilten $y$ ausgehen.

Das Gewicht wird von vielen Einflussfaktoren wie Sport, Kalorienaufnahme oder aber Veranlagung sowie vielem mehr bestimmt. Wir können davon ausgehen, dass das Gewicht normalverteilt ist.
:::

Abschließend sei noch gesagt, dass es fast unmöglich ist, eine Verteilung mit weniger als zwanzig Beobachtungen überhaupt abzuschätzen. Selbst dann können einzelne Beobachtunge an den Rändern der Verteilung zu einer Ablehnung der Normalverteilung führen, obwohl eine Normalverteilung vorliegt.

Das R Paket `oslrr` bietet hier noch eine Funktion `ols_test_normality()`, die es erlaubt mit allen bekannten statistischen Tests auf Normalverteilung zu testen. Wenn der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$, dann können wir die Nullhypothese, dass unsere Daten gleich einer Normalverteilung wären, ablehnen. Die Anwendung kannst du dir in @sec-gaussian anschauen. Um jetzt kurz einen statistischen Engel anzufahren, wir nutzen *wenn überhaupt* den Shapiro-Wilk-Test oder den Kolmogorov-Smirnov-Test. Für die anderen beiden steigen wir jetzt hier nicht in die Therorie ab.

Am Ende sei noch auf den [QQ-plot](#sec-linreg-qq) verwiesen, mit dem wir auch visuell überprüfen können, ob eine Normalverteilung vorliegt.

::: callout-important
## Entscheidung zur Normalverteilung

Bei der Entscheidung zur Normalverteilung gilt folgende Regel. Ist der $p$-Wert des Pre-Tests auf Normalverteilung kleiner als das Signifikanzniveau $\alpha$ von 5% lehnen wir die Nullhypothese ab. Wir nehmen eine Nicht-Normalverteilung an.

-   Ist $p \leq \alpha = 5\%$ so nehmen wir Nicht-Normalverteilung von $y$ an.
-   Ist $p > \alpha = 5\%$ so nehmen wir Normalverteilung von $y$ an.

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf Normalverteilung nochmal visuell bestätigen.
:::

## Approximativ normalverteilt, niedrige Fallzahl

Auch hier schauen wir uns den Fall mit einer niedrigen Fallzahl an. Dafür bauen wir usn erstmal Daten mit der Funktion `rt()`. Wir ziehen uns zufällig Beobachtungen aus einer t-Verteilung, die approximativ normalverteilt ist. Je höher die Freiheitsgrade `df` desto näher kommt die t-Verteilung einer Normalverteilung. Mit einem Freiheitsgrad von `df = 30` sind wir sehr nah an einer Normalverteilung dran.

```{r}
set.seed(202209013)
low_normal_tbl <- tibble(A = rt(10, df = 30),
                         B = rt(10, df = 30)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In @fig-normal-1 sehen wir auf der linken Seite den Dotplot der zehn Beobachtungen aus den beiden Gruppen $A$ und $B$. Wir sehen, dass die Verteilung für das Outcome `rsp` in etwa normalverteilt ist.

```{r}
#| message: false
#| echo: false
#| label: fig-normal-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Verteilung des Outcomes `rsp` der zehn Beobachtungen aus den Gruppen $A$ und $B$. Beiden Gruppen kommen aus einer t-Verteilung."
#| fig-subcap: 
#|   - "Dotplot des Outcomes `rsp`."
#|   - "Densityplot des Outcomes `rsp`."
#| layout-nrow: 1
#| column: page

ggplot(low_normal_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  scale_fill_okabeito() +
  theme(legend.position = "none")

ggplot(low_normal_tbl, aes(rsp, fill = trt)) +
  theme_bw() +
  geom_density(alpha = 0.5) +
  scale_fill_okabeito() +
  xlim(-5, 5) +
  theme(legend.position = "none")

```

Wir können den Shapiro-Wilk-Test nutzen um statistisch zu testen, ob eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber nicht, welche *andere* Verteilung vorliegt. Wir testen natürlich für die beiden Gruppen getrennt. Die Funktion `shapiro.test()`kann nur mit einem Vektor von Zahlen arbeiten, daher übergeben wir mit `pull` die entsprechend gefilterten Werte des Outcomes `rsp`.

```{r}
low_normal_tbl %>% 
  filter(trt == "A") %>% 
  pull(rsp) %>% 
  shapiro.test()
  
low_normal_tbl %>% 
  filter(trt == "B") %>% 
  pull(rsp) %>% 
  shapiro.test()
```

Wir sehen, dass der $p$-Wert größer ist als das Signifikanzniveau $\alpha$ von 5% für beide Gruppen. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen eine Normalverteilung an.

In dem folgendem Beispiel sehen wir dann aber, was ich mit in die Ecke testen meine bzw. so lange statistisch zu Testen bis nichts mehr geht.

## Nicht normalverteilt, niedrige Fallzahl

Schauen wir uns jetzt den anderen Fall an. Wir haben jetzt wieder eine niedrige Fallzahl mit je 10 Beobachtungen je Gruppe $A$ und $B$. In diesem Fall kommen die Beobachtungen aber aus einer exponentiellen Verteilung. Wir haben also definitiv keine Normalverteilung vorliegen. Wir generieren uns die Daten mit der Funktion `rexp()`.

```{r}
set.seed(202209013)
low_nonnormal_tbl <- tibble(A = rexp(10, 1/1500),
                            B = rexp(10, 1/1500)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In @fig-normal-2 sehen wir auf der linken Seite den Dotplot der zehn Beobachtungen aus den beiden Gruppen $A$ und $B$. Wir sehen, dass die Verteilung für das Outcome für die Behandlung $B$ in etwa normalverteilt ist sowie das das Outcome für die Behandlung $A$ keiner Normalverteilung folgt *oder* zwei Ausreißer hat. Die Entscheidung was jetzt stimmt ohne zu wissen wie die Daten generiert wurden, ist in der Anwendung meist nicht möglich.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-normal-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Verteilung des Outcomes `rsp` der zehn Beobachtungen aus den Gruppen $A$ und $B$. Beiden Gruppen kommen aus einer Exponentialverteilung."
#| fig-subcap: 
#|   - "Dotplot des Outcomes `rsp`."
#|   - "Densityplot des Outcomes `rsp`."
#| layout-nrow: 1
#| column: page


ggplot(low_nonnormal_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  scale_fill_okabeito() +
  theme(legend.position = "none")

ggplot(low_nonnormal_tbl, aes(rsp, fill = trt)) +
  theme_bw() +
  geom_density(alpha = 0.5) +
  scale_fill_okabeito() +
  xlim(-1500, 4400) +
  theme(legend.position = "none")

```

Wir können wieder den Shapiro-Wilk-Test nutzen um statistisch zu testen, ob eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber nicht, welche *andere* Verteilung vorliegt. Wir testen natürlich für die beiden Gruppen getrennt.

```{r}

low_nonnormal_tbl %>% 
  filter(trt == "A") %>% 
  pull(rsp) %>% 
  shapiro.test()
  
low_nonnormal_tbl %>% 
  filter(trt == "B") %>% 
  pull(rsp) %>% 
  shapiro.test()

```

Wir sehen, dass der $p$-Wert für die Behandlung $A$ kleiner ist als das Signifikanzniveau $\alpha$ von 5%. Damit können wir die Nullhypothese ablehnen. Wir nehmen keine Normalverteilung für Gruppe $A$ an. Auf der anderen Seite sehen wir, dass der $p$-Wert für die Behandlung $B$ größer ist als das Signifikanzniveau $\alpha$ von 5%. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen eine Normalverteilung für Gruppe $A$ an.

Super, jetzt haben wir für die eine Gruppe eine Normalverteilung und für die andere nicht. Wir haben uns in die Ecke getestet. Wir können jetzt verschiedene Szenarien vorliegen haben.

1)  Wir könnten in der Gruppe $A$ zwei Ausreißer vorliegen haben.
2)  Wir könnten in der Gruppe $B$ zufällig eine Normalverteilung beobachtet haben.

[Und nochmal zum Schluß, einem statistischen Test mit 4 bis 5 Wiederholungen in einer Gruppe zu glauben, ob eine Normalverteilung vorliegt, kannst du auch würfeln...]{.aside}

Leider wissen wir im echten Leben nicht, aus welcher Verteilung unsere Daten stammen, wir können aber *annehmen*, dass die Daten einer Normalverteilung folgen oder aber die Daten so transformieren, dass die Daten einer approximativen Normalverteilung folgen. Siehe dazu auch das @sec-eda-transform zur Transformation von Daten.

Wenn deine Daten *keiner* Normalverteilung folgen, dann kann es sein, dass du mit den Effektschätzern ein Problem bekommst. Du erfährst vielleicht, dass du die Nullhypothese ablehnen kannst, aber nicht wie stark der Effekt in der Einheit des gemessenen Outcomes ist.
