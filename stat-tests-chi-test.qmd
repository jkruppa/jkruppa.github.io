```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Der $\mathcal{X}^2$-Test {#sec-chi-test}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

::: callout-note
## Was macht der $\mathcal{X}^2$-Test?

Ein $\mathcal{X}^2$-Test vergleicht die Anteile zweier oder mehrerer Gruppen.
:::

::: callout-tip
## Einführung in den $\mathcal{X}^2$-Test per Video

Du findest auf YouTube [Der Chi-Quadrat-Test erklärt](https://youtu.be/B6YNtxBsK3c) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Der $\mathcal{X}^2$-Test wird häufig verwendet, wenn wir zwei Faktoren mit jeweils zwei Leveln miteinander vergleichen wollen. Das heißt wir haben zum Beispiel unseren Faktor `animal` mit den beiden Leveln `cat` und `dog`. Wir schauen uns jetzt den Infektionsstatus mit Flöhen auf den Tieren an. Wir erhalten wiederum einen Faktor `infected` mit zwei Leveln `yes` und `no`. Wir sind bei dem $\mathcal{X}^2$-Test nicht auf nur Faktoren mit zwei Leveln eingeschränkt. Traditionell wird aber versucht ein 2x2 Setting zu erreichen.

Im Bereich der Agrarwissenschaften kommt der $\mathcal{X}^2$-Test eher selten vor. Im Bereich der Humanwissenschaften und vor allem der Epidemiologie ist der $\mathcal{X}^2$-Test weit verbreitet.

Das eigentlich besondere an dem $\mathcal{X}^2$-Test ist gra nicht mal der Test selber sondenr die Datenstruktur die der $\mathcal{X}^2$-Test zugrunde liegt: der Vierfeldertafel oder 2x2 Kreuztabelle. Wir werden diese Form von Tabelle noch später im maschinellen Lernen und in der Testdiagnostik wiederfinden.

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Wir rechnen den $\mathcal{X}^2$-Test per Hand in der Klausur. Teilweise füllen wir die $2x2$ Tabelle aus, teilweise berechnen wir nur die Randsummen.

Bitte schau dir die Aufgaben in den [gesammelten Klausurfragen auf GitHub](https://github.com/jkruppa/teaching/tree/main/Klausur) an um eine Idee zu haben, welche Fragen zum Wilcoxon-Mann-Whitney-Test drankommen.

Wenn kein $\chi^2_{\alpha=5\%}$ in der Klausur gegeben ist, setzen wir $\chi^2_{\alpha=5\%} = 3.84$.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| warning: false
#| message: false
pacman::p_load(tidyverse, magrittr, effectsize, rstatix,
               scales, parameters, conflicted)
conflicts_prefer(stats::chisq.test)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten für den $\mathcal{X}^2$-Test

Wie eben schon benannt schauen wir uns für den $\mathcal{X}^2$-Test eine Vierfeldertafel oder aber 2x2 Kreuztabelle an. In @tbl-chi-square-obs sehen wir eine solche 2x2 Kreuztabelle. Da wir eine Mindestanzahl an Zellbelegung brauchen um überhaupt mit dem $\mathcal{X}^2$-Test rechnen zu können, mutzen wir hier gleich aggrigierte Beispieldaten. Wir brauchen mindestens fünf Beobachtungen je Zelle, dass heißt mindestens 20 Tiere. Da wir dann aber immer noch sehr wenig haben, ist die Daumenregel, dass wir etwa 30 bis 40 Beobachtungen brauchen. In unserem Beispiel schauen wir uns 65 Tiere an.

|            |       |                     |                     |                     |
|:----------:|:-----:|:-------------------:|:-------------------:|:-------------------:|
|            |       |    **Infected**     |                     |                     |
|            |       |      *Yes (1)*      |      *No (0)*       |                     |
| **Animal** | *Dog* |  $23_{\;\Large a}$  |  $10_{\;\Large b}$  | $\mathbf{a+b = 33}$ |
|            | *Cat* |  $18_{\;\Large c}$  |  $14_{\;\Large d}$  | $\mathbf{c+d = 32}$ |
|            |       | $\mathbf{a+c = 41}$ | $\mathbf{b+d = 24}$ |      $n = 65$       |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen. Dargestellt sind die *beobachteten* Werte. {#tbl-chi-square-obs}

In der Tabelle sehen wir, dass in den zeieln die Level des Faktors `animal` angegeben sind und in den Spalten die Level des Faktors `infected`. Wir haben somit $23$ Hunde, die mit Flöhen infiziert sind, dann $10$ Hunde, die nicht mit Flöhen infirziert sind. Auf der Seite der Katzen haben wir $18$ Katzen, die infiziert sind und $14$ Katzen, die keine Flöhe haben. An den Rändern stehen die Randsummen. Wir haben $33$ Hunde und $32$ Katzen sowie $41$ infizierte Tiere und $24$ nicht infizierte Tiere. Somit haben wir dann in Summe $n = 65$ Tiere. Diese Form der Tabelle wird uns immer wieder begegnen.

Bevor wir jetzt diese 2x2 Kreuztabelle verwenden, müssen wir uns nochmal überlegen, welchen Schluß wir eigentlich über die Nullhypothese machen. Wie immer können wir nur die Nullhypothese ablehnen. Daher überlegen wir uns im Folgenden wie die Nullhypothese in dem $\mathcal{X}^2$-Test aussieht. Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

## Hypothesen für den $\mathcal{X}^2$-Test

Der $\mathcal{X}^2$-Test betrachtet die Zellbelegung gegeben den Randsummen um einen Unterschied nachzuweisen. Daher haben wir die Nullhypothese als Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass die Zahlen in den Zellen gegeben der Randsummen gleich sind. Wir betrachten hier nur die Hypothesen in Prosa und die mathematischen Hypothesen. Es ist vollkommen ausreichend, wenn du die Nullhypothese des $\mathcal{X}^2$-Test nur in Prosa kennst.

$$
H_0: \; \mbox{Zellbelegung sind gleichverteilt gegeben der Randsummen}
$$

Die Alternative lautet, dass sich die Zahlen in den Zellen gegeben der Randsummen unterscheiden.

$$
H_A: \; \mbox{Zellbelegung sind nicht gleichverteilt gegeben der Randsummen}
$$

Wir schauen uns jetzt einmal den $\mathcal{X}^2$-Test theoretisch an bevor wir uns mit der Anwendung des $\mathcal{X}^2$-Test in R beschäftigen.

## $\mathcal{X}^2$-Test theoretisch

In @tbl-chi-square-obs von oben hatten wir die *beobachteten* Werte. Das sind die Zahlen, die wir in unserem Experiment erhoben und gemessen haben. Der $\mathcal{X}^2$-Test vergleicht nun die *beobachteten* Werte mit den anhand der Randsummen zu *erwartenden* Werte. Daher ist die Formel für den $\mathcal{X}^2$-Test wie folgt.

$$
\chi^2_{calc} = \cfrac{(O - E)^2}{E}
$$

mit

-   $O$ für die beobachteten Werte
-   $E$ für die nach den Randsummen zu erwartenden Werte

In @tbl-chi-square-exp kannst du sehen wie wir anhand der Randsummen die erwartenden Zellbelegungen berechnen. Hierbei können auch krumme Zahlen rauskommen. Wir würden keinen Unterschied zwischen Hunde und Katzen gegeben deren Infektionsstatus erwarten, wenn die Abweichungen zwischen den beobachteten Werten und den zu erwartenden Werten klein wären. Wir berechnen nun die zu erwartenden Werte indem wir die Randsummen der entsprechenden Zelle multiplizieren und durch die Gesamtanzahl teilen.

|            |       |                                   |                                   |               |
|:----------:|:-----:|:---------------------------------:|:---------------------------------:|:-------------:|
|            |       |           **Infected**            |                                   |               |
|            |       |             *Yes (1)*             |             *No (0)*              |               |
| **Animal** | *Dog* | $\cfrac{41 \cdot 33}{65} = 20.82$ | $\cfrac{24 \cdot 33}{65} = 12.18$ | $\mathbf{33}$ |
|            | *Cat* | $\cfrac{41 \cdot 32}{65} = 20.18$ | $\cfrac{24 \cdot 32}{65} = 11.82$ | $\mathbf{32}$ |
|            |       |           $\mathbf{41}$           |           $\mathbf{24}$           |   $n = 65$    |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen. Dargestellt sind die zu *erwartenden* Werte. {#tbl-chi-square-exp}

Wir können dann die Formel für den $\mathcal{X}^2$-Test entsprechend ausfüllen. Dabei ist wichtig, dass die Abstände quadriert werden. Das ist ein Kernkonzept der Statistik, Abstände bzw. Abweichungen werden immer quadriert.

```{=tex}
\begin{aligned} 
\chi^2_{calc} &= \cfrac{(23 - 20.82)^2}{20.82} + \cfrac{(10 - 12.18)^2}{12.18} + \\
&\phantom{=}\;\; \cfrac{(18 - 20.18)^2}{20.18} + \cfrac{(14 - 11.82)^2}{11.82} = 1.25
\end{aligned}
```
Es ergibt sich ein $\chi^2_{calc}$ von $1.25$ mit der Regel, dass wenn $\chi^2_{calc} \geq \chi^2_{\alpha=5\%}$ die Nullhypothese abgelehnt werden kann. Mit einem $\chi^2_{\alpha=5\%} = `r round(qchisq(p = 0.05, df = 1, lower.tail = FALSE), 2)`$ können wir die Nullhypothese nicht ablehnen. Es besteht kein Zusammenhang zwischen den Befall mit Flöhen und der Tierart. Oder anders herum, Hunde und Katzen werden gleich stark mit Flöhen infiziert.

## $\mathcal{X}^2$-Test in R

[Der $\mathcal{X}^2$-Test wird meist in anderen Funktionen in R verwendet und nicht direkt. Wenn du Fragen dazu hast, schreib mir einfach eine Mail.]{.aside}

Wenn wir den $\mathcal{X}^2$-Test in R rechnen wollen nutzen wir die Funktion `chisq.test()`, die eine Matrix von Zahlen verlangt. Dies ist etwas umständlich.

```{r}

mat <- matrix(c(23, 10, 18, 14), 
              byrow = TRUE, nrow = 2)
chisq.test(mat, correct = FALSE)

```

Da der $\mathcal{X}^2$-Test nicht so häufig im Bereich der Agrawissenschaften auftritt belasse ich es *für das Erste* hierbei. Wenn du noch Fragen hast, komme gerne in R Tutorium oder schreibe mir eine Mail. Dann können wir das Problem nochmal diskutieren und sehen, ob wirklich ein $\mathcal{X}^2$-Test notwendig ist.

Als ein mögliches Effektmaß können wir Cramers $V$ berechnen. Wir nutzen hierzu die Funktion `cramers_v()`. Auf einer reinen 2x2 Kreuztabelle wäre aber Pearsons $\phi$ durch die Funktion `phi()` vorzuziehen. Siehe dazu auch [$\phi$ and Other Contingency Tables Correlations](https://easystats.github.io/effectsize/reference/phi.html) auf der Hilfeseite des R Paketes `effectsize`.

```{r}
cramers_v(mat) 

phi(mat)
```

Wir sehen, dass der Effekt mit einem $V = 0.14$ oder einem $\phi = 0.14$ schwach ist. Ein Wert von 0 bedeutet keine Assoziation und ein Wert von 1 einen maximalen Zusammenhang. Wir können die Werte von $V$ und $\phi$ wie eine Korrelation interpretieren.

## Test auf gleiche oder gegebene Anteile

![](images/caution.png){fig-align="center" width="50%"}

### Vergleich eines Anteils $p_1$ gegen einen gegebenen Anteil $p_0$

Nehmen wir ein etwas konstruiertes Beispiel zur Erdbeerernte. Wir haben einen neuen Roboter entwickelt, der Erdbeeren erntet. Nun stellen wir fest, dass von 100 Erdbeeren 76 heile sind. Jetzt lesen wir im Handbuch, dass der Ernteroboter eigentlich 84% der Erdbeeren heile ernten sollte. Sind jetzt 76 von 100, also 76%, signifikant unterschiedlich von 84%? Oder können wir die Nullhypothese der Gleichheit zwischen den beiden Wahrscheinlichkeiten nicht ablehnen? Damit können wir den Test auf Anteile nutzen, wenn wir eine beobachtete Wahrscheinlichkeit oder Anteil $p_1$ gegen eine gegebene Wahrscheinlichkeit oder Anteil $p_0$ vergleichen wollen.

In unserem Fall haben wir mit $p_1$ die Wahrscheinlichkeit vorliegen, dass die Erdbeeren in unserem Experiment heile sind. Wir wissen also, dass $p_1 = \cfrac{x}{n} = \cfrac{76}{100} = 0.76 = 76\%$ ist. Damit ist die Wahrscheinlichkeit $p_1$ auch die *beobachte* Wahrscheinlichkeit. Wir *erwarten* auf der anderen Seite die Wahrscheinlichkeit $p_0 = 0.84 = 84\%$. Die Roboterfirma hat uns aj zugesagt, dass 84% der Erdbeeren heile bleiben sollen.

Wir berechnen jetzt einmal die *beobachten* Werte. Zum einen haben wir $x=76$ heile Erdbeeren von $n=100$ Erdbeeren gezählt. Damit ergeben sich dann $x = 76$ heile Erdbeeren und $24$ beschädigte Erdbeeren. Die Summe muss ja am Ende wieder 100 Erdbeeren ergeben.

$$
\begin{aligned}
O &= 
\begin{pmatrix}
x &|& n - x
\end{pmatrix} 
=
\begin{pmatrix}
76 &|& 100 - 76
\end{pmatrix} \\
& = 
\begin{pmatrix}
76 &|& 24
\end{pmatrix} 
\end{aligned}
$$

Dann müssen wir uns noch die Frage stellen, welche Anzahl an heilen Erdbeeren hätten wir *erwartet*? In diesem Fall ja 84% heile Erdbeeren. Das macht dann bei 100 Erdbeeren $0.84 \cdot 100 = 84$ heile Erdbeeren und $(1 - 0.84) \cdot 100 = 16$ beschädigte Erdbeeren.

$$
\begin{aligned}
E &=
\begin{pmatrix}
n \cdot p &|& n \cdot (1 - p)
\end{pmatrix} 
=
\begin{pmatrix}
100 \cdot 0.84 &|& 100 \cdot (1 - 0.84)
\end{pmatrix} \\
& = 
\begin{pmatrix}
84 &|& 16
\end{pmatrix} 
\end{aligned}
$$

Jetzt müssen wir nur noch die *beobachteten* Anteile mit den zu *erwarteten* Anteilen durch die $\mathcal{X}^2$-Formel in Kontext setzten. Wir subtrahieren von jedem beobachten Anteil den zu erwartenden Anteil, quadrieren und addieren auf. Dann erhalten wir die $\mathcal{X}^2$-Statistik.

$$
\chi^2_{calc} = \sum\cfrac{(O-E)^2}{E} = \cfrac{(76 - 84)^2}{84} + \cfrac{(24 - 16)^2}{16} = 4.76
$$

Wir können diese einfache Berechnung dann auch schnell nochmal in R durchführen. Wir setzten dafür einfach `x`, `n` und `p` fest und berechnen dann die beobachten Anteile $O$ sowwie die zu erwartenden Anteile $E$. Wir berechnen dann hier auch den gleichen Wert für $\mathcal{X}^2$-Statistik.

```{r}
x <- 76
n <- 100
p <- 0.84
O <- cbind(x, n - x)
E <- cbind(n * p, n * (1 - p))
sum((abs(O - E))^2/E)
```

Und wie immer gibt es auch eine Funktion `prop.test()`, die uns ermöglicht einen beobachteten Anteil `x/n` zu einem erwarteten Anteil `p` zu vergleichen. Auch hier sehen wir, dass sich die $\mathcal{X}^2$-Statistik aus der R Funktion nicht von unser berechneten $\mathcal{X}^2$-Statistik unterscheidet.

```{r}
prop.test(x = 76, n = 100, p = 0.84, correct = FALSE) 
```

::: column-margin
Was ist die Yates Korrektur, die wir mit `correct = TRUE` auswählen? Die Korrektur von Yates subtrahiert von jedem Summanden des Chi-Quadrat-Tests 0.5, so dass die Chi-Quadrat-Statistik geringer ausfällt.
:::

### Vergleich zweier Anteile $p_1$ und $p_2$

Nun haben wir nicht einen Ernteroboter sondern zwei brandneue Robotertypen. Einmal die Marke *Picky* und einmal den Roboter *Colly*. Wir wollen jetzt wieder bestimmen, wie viel Erdbeeren bei der Ernte beschädigt werden. Erdbeeren sind ja auch ein sehr weiches Obst. Wir vergleichen hier also wieder zwei Anteile miteinander. Der Roboter *Picky* beschädigt 76 von 100 Erdbeeren und der Roboter *Colly* detscht 91 von 100 Erdbeeren an. Das sind ganz schön meise Werte, aber was will man machen, wir haben jetzt nur die beiden Roboter vorliegen. Die Frage ist nun, ob sich die beiden Roboter in der Häufigkeit der beschädigten Erdbeeren unterscheiden. Wir können hier eine 2x2 Kreuztabelle in der @tbl-chi-square-exp-3 aufmachen und die jeweiligen Anteile berechnen. Picky beschädigt 76% der Erdbeeren und Colly ganze 91%.

|           |         |                |               |                |
|:---------:|:-------:|:--------------:|:-------------:|:--------------:|
|           |         |  **Damaged**   |               |                |
|           |         |   *Yes (1)*    |   *No (0)*    |                |
| **Robot** | *Picky* |      $76$      |     $24$      | $\mathbf{100}$ |
|           | *Colly* |      $91$      |      $9$      | $\mathbf{100}$ |
|           |         | $\mathbf{167}$ | $\mathbf{33}$ |   $n = 200$    |

: Eine 2x2 Tabelle für die zwei Ernteroboter und der beschädigten Erdbeeren. Dargestellt sind die *beobachteten* Werte. {#tbl-chi-square-exp-3}

Wir können die erwarteten Anteile jetzt wie schon bekannt berechnen oder aber wir nutzen folgende Formel um $\hat{p}$, die Wahrscheinlichkeit für ein Ereignis, zu berechnen. Wir nutzen dann $\hat{p}$ um die erwarteten Werte $E$ aus zurechnen. Dafür addieren wir alle beobachteten $x$ zusammen und teilen diese Summe durch die gesammte Anzahl an Beobachtungen.

$$
\hat{p} = \cfrac{\sum x}{\sum n} = \cfrac{79 + 91}{100 + 100} = \cfrac{170}{200} = 0.85
$$

Im Folgenden die Rechenschritte nochmal in R aufgedröselt zum besseren nachvollziehen. Wie auch schon im obigen Beispiel berechnen wir erst die beobachten Anteil $O$ sowie die erwartenden Anteile $E$. Dann nutzen wir die Formel des $\mathcal{X}^2$-Test um die $\mathcal{X}^2$-Statistik zu berechnen.

```{r}
x <- c(76, 91)
n <- c(100, 100)
p <- sum(x)/sum(n)
O <- cbind(x, n - x)
E <- cbind(n * p, n * (1 - p))
sum((abs(O - E))^2/E)
```

Auch hier vergleichen wir nochmal unser händisches Ergebnis mit dem Ergebnis der R Funktion `prop.test()`. Der Funktion übergeben wir dann einmal die beobachteten Anteile $x$ sowie dann die jeweils Gesamtanzahlen $n$. Wichtig ist hier, dass wir als 95% Konfidenzintervall die Differenz der beiden Wahrscheinlichkeiten erhalten.

```{r}
prop.test(x = c(76, 91), n = c(100, 100), correct = FALSE) 
```

https://rpkgs.datanovia.com/rstatix/reference/prop_test.html

https://rdrr.io/r/stats/pairwise.prop.test.html

### Vergleich mehrerer Anteile $p_1$, $p_2$ bis $p_k$

Neben dem Test auf absolute Anteile, wie der $\mathcal{X}^2$-Test es rechnet, wollen wir manchmal auch relative Anteile testen. Also haben wir nicht 8 kranke Erdbeeren gezählt sondern 8 kranke von 12 Erdbeeren. Damit sind dann 66% bzw. 0.66 kranke Erdbeeren vorhanden. Wir rechnen also mit Wahrscheinlichkeiten, also *eng. proportions*. Deshalb können wir hier auch die R Funktion `prop.test()` nutzen. Wichtig ist zu wissen, dass wir trotz allem erst die Anzahl an beschädigten Erdbeeren (`damaged`) sowie die absolute Anzahl an Erdbeeren (`berries`) brauchen. Wir haben uns in einem Experiment die beschädigten Erdbeeren nach vier Erntearten, A bis D, angeschaut. Beide Vektoren können wir dann in die Funktion `prop.test()` stecken.

```{r}
#| warning: false
#| message: false
damaged  <- c(A = 105, B = 100, C = 139, D = 96)
berries <- c(106, 113, 156, 102)
prop.test(damaged, berries)
```

Wir erhalten dann einen $p$-Wert von 0.0056 wieder. Was testen wir hier eigentlich? Unsere Nullhypothese ist, dass alle paarweisen Wahrscheinlichkeiten zwischen den Gruppen gleich sind. Wie wir sehen ist das nicht der Fall. Wir haben hier vier Wahrscheinlichkeiten vorliegen und mindestens zwei unterscheiden sich. Welche das sind, ist wieder die Frage. Hierzu nutzen wir dann gleich die Funktion `pairwise.prop.test()`. Wir immer geht die Ausgabe auch schöner und aufgeräumter.

```{r}
#| warning: false
#| message: false
prop.test(damaged, berries) %>% 
  model_parameters()
```

Warum ist ein Test auf Anteile ein $\mathcal{X}^2$-Test? Hierfür brauchen wir noch die Informationen zu den nicht beschädigten Erdbeeren.

```{r}
non_damaged <- berries - damaged 
non_damaged
```

Nun können wir uns erstmal eine Tabelle bauen auf der wir dann den $\mathcal{X}^2$-Test und den `prop.test()` rechnen können. Der $\mathcal{X}^2$-Test ist nicht nur auf eine 2x2 Kreuztabelle beschränkt. Wir können in einem $\mathcal{X}^2$-Test auch andere $n \times m$ Tabellen testen. Auf der anderen Seite ist der `prop.test()` auf eine $n \times 2$ Tabelle beschränkt. Es müssen also immer zwei Spalten sein.

```{r}
#| warning: false
#| message: false
damaged_tab <- cbind(damaged, non_damaged) %>% 
  as.table()
damaged_tab
```

Wir erhalten die @tbl-chi-square-exp-2 mit den beobachteten Werten sowie die @tbl-chi-square-exp-3 mit den erwarteten Werten. Die Berechnung der erwarteten Werte kennen wir schon aus dem klassischen $\mathcal{X}^2$-Test. Hier machen wir die Berechnungen nur auf einer größeren Tabelle.

|           |     |                |               |                |
|:---------:|:---:|:--------------:|:-------------:|:--------------:|
|           |     |  **Damaged**   |               |                |
|           |     |   *Yes (1)*    |   *No (0)*    |                |
|           |     |   *damaged*    | *non_damaged* |   *berries*    |
| **Group** | *A* |     $105$      |      $1$      | $\mathbf{106}$ |
|           | *B* |     $100$      |     $13$      | $\mathbf{113}$ |
|           | *C* |     $139$      |     $17$      | $\mathbf{156}$ |
|           | *D* |      $96$      |      $6$      | $\mathbf{102}$ |
|           |     | $\mathbf{440}$ | $\mathbf{37}$ |   $n = 477$    |

: Eine 4x2 Tabelle für die vier Erntearten und der beschädigten Erdbeeren. Dargestellt sind die *beobachteten* Werte. {#tbl-chi-square-exp-2}

Jetzt können wir auch die Anteile der beschädigten Erdbeeren von allen Erdbeeren berechnen pro Ernteart berechnen.

$$
\begin{aligned} 
Pr(A) &= \cfrac{105}{106} = 0.9906 = 99.06\%\\
Pr(B) &= \cfrac{100}{113} = 0.8850 = 88.50\%\\ 
Pr(C) &= \cfrac{139}{156} = 0.8910 = 89.10\%\\ 
Pr(D) &= \cfrac{96}{102} = 0.9411 = 94.12\%
\end{aligned}
$$

|           |     |                                       |                                     |                |
|:---------:|:---:|:-------------------------------------:|:-----------------------------------:|:--------------:|
|           |     |              **Damaged**              |                                     |                |
|           |     |               *Yes (1)*               |              *No (0)*               |                |
|           |     |               *damaged*               |            *non_damaged*            |   *berries*    |
| **Group** | *A* | $\cfrac{440 \cdot 106}{477} = 97.78$  | $\cfrac{37 \cdot 106}{477} = 8.22$  | $\mathbf{106}$ |
|           | *B* | $\cfrac{440 \cdot 113}{477} = 104.23$ | $\cfrac{37 \cdot 113}{477} = 8.77$  | $\mathbf{113}$ |
|           | *C* | $\cfrac{440 \cdot 156}{477} = 143.90$ | $\cfrac{37 \cdot 156}{477} = 12.10$ | $\mathbf{156}$ |
|           | *D* | $\cfrac{440 \cdot 102}{477} = 94.09$  | $\cfrac{37 \cdot 102}{477} = 7.91$  | $\mathbf{102}$ |
|           |     |            $\mathbf{440}$             |            $\mathbf{37}$            |   $n = 477$    |

: Eine 4x2 Tabelle für die vier Erntearten und der beschädigten Erdbeeren. Dargestellt sind die zu *erwartenden* Werte, die sich aus den Randsummen ergeben würden. {#tbl-chi-square-exp-3}

Schauen wir uns nun an, ob es einen Unterschied zwischen den vier Erntearten A bis D für die Erdbeeren gibt. Einmal nutzen wir hierfür die Funktion `chisq.test()` und einmal die Funktion `prop.test()`.

```{r}
#| warning: false
#| message: false
chisq.test(damaged_tab) %>% 
  model_parameters()
prop.test(damaged_tab) %>% 
  model_parameters()
```

Nachdem wir beide Funktionen gerechnet haben, sehen wir, dass beide Tests auf der $\mathcal{X}^2$ Statistik basieren. Das macht ja auch Sinn, denn wir rechnen ja die *Proportions* indem wir die beobachteten Werte durch die Gesamtzahl berechnen.

https://stats.stackexchange.com/questions/2391/what-is-the-relationship-between-a-chi-squared-test-and-test-of-equal-proportion

$$
\begin{aligned} 
\chi^2_{calc} &= \cfrac{(105 - 97.78)^2}{97.78} + \cfrac{(1 - 8.22)^2}{8.22} + \\
&\phantom{=}\;\; \cfrac{(100 - 104.23)^2}{104.23} + \cfrac{(13 - 8.77)^2}{8.77} + \\
&\phantom{=}\;\; \cfrac{(139 - 143.90)^2}{143.90} + \cfrac{(17 - 12.10)^2}{12.10} + \\
&\phantom{=}\;\; \cfrac{(96 - 94.09)^2}{94.09} + \cfrac{(6 - 7.91)^2}{7.91} = 11.74 \approx 10.04
\end{aligned}
$$

```{r}
#| warning: false
#| message: false
tab <- matrix(c(83, 90, 129, 70), ncol = 2)
chisq.test(tab)
prop.test(tab)
```

Führen wir den Test nochmal detaillierter mit der Funktion `prop_test()` aus dem R Paket `rstatix` durch.

```{r}
#| warning: false
#| message: false
grp_size <- c(106, 113, 156, 102)
infected  <- c(50, 100, 139, 80)
non_infected <- grp_size - infected
```

```{r}
#| warning: false
#| message: false
infected_tab <- rbind(infected, non_infected) %>% 
  as.table()
```

```{r}
#| warning: false
#| message: false
dimnames(infected_tab) <- list(
  Infected = c("yes", "no"),
  Groups = c("grp1", "grp2", "grp3", "grp4")
)
infected_tab
```

```{r}
#| warning: false
#| message: false
prop_test(infected_tab, detailed = TRUE)
```

http://www.sthda.com/english/wiki/two-proportions-z-test-in-r

```{r}
## delete me
pacman::p_load(rcompanion, multcompView, multcomp)
```

```{r}
#| warning: false
#| message: false
damaged  <- c(83, 90, 129, 70)
berries <- c(86, 93, 136, 82)
pairwise.prop.test(damaged, berries) 
```

```{r}
#| warning: false
#| message: false
pairwise_prop_test(infected_tab) %>% 
  mutate(p = pvalue(p.adj),
         p.adj = pvalue(p.adj))
```

```{r}
#| warning: false
#| message: false
pairwise.prop.test(damaged, berries, 
                   p.adjust.method = "none") %>% 
  pluck("p.value") %>% 
  fullPTable() %>% 
  multcompLetters() %>% 
  pluck("Letters")
```

```{r}
#| warning: false
#| message: false

pairwise_prop_test(infected_tab, 
                   p.adjust.method = "none") %>% 
  mutate(contrast = str_c(group1, "-", group2)) %>% 
  pull(p.adj, contrast) %>% 
  multcompLetters() 

```
