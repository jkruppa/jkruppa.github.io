```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, performance, parameters,
               latex2exp, see, patchwork, mfp, multcomp, emmeans, janitor, effectsize,
               broom, ggmosaic, tinytable, ggrepel, tidyplots,
               conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- cb_pal
## 
fac1_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  select(animal, jump_length) |> 
  mutate(animal = as_factor(animal))
```

```{r}
#| eval: true
#| echo: false
#| cache: true
#| message: false
#| warning: false
#| label: sim-utest-samplesize
source("simulation/sim-stat-tests-utest.R")
```

```{r}
#| eval: true
#| echo: false
#| cache: true
#| message: false
#| warning: false
#| label: sim-utest-ttest
source("simulation/sim-stat-tests-utest-02.R")
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-tests-utest.R")
```

# Der U-Test {#sec-utest}

*Letzte Änderung am `r format(fs::file_info("stat-tests-utest.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Statisticians, like artists, have the bad habit of falling in love with their models." --- George Box*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Baustelle (seit 06.2025)

Dieses Kapitel wird überarbeitet. Ziel ist es die Nichtparametrik zum Start des Wintersemesters 2025/26 überarbeitet zu haben. Da ich hier direkt im Kapitel arbeite, kann es sein, dass mal die ein oder andere Funktion nicht funktioniert oder aber Teile im Nichts enden. Wird dann repariert.
:::

## Allgemeiner Hintergrund

Der U-Test ist auch unter den Namen Wilcoxon-Mann-Whitney-Test, Mann-Whitney-U-Test oder Wilcoxon-Rangsummentest bekannt. Aus Gründen der Kürze werde ich hier immer von dem U-Test schreiben. Der U-Test wird häufig noch in den Grundlagenwissenschaften wie Zellforschung oder bie Mäusemodellen verwendet. Gerne auch bei genetischen Knockout-Experimenten mit einer kleinen Anzahl an Mäusen. In den Agrarwissenschaften treffen wir den U-Test nicht ganz so häufig, da wir meistens dann doch auf einem normalverteilten Messwert den ANOVA Pfad durchrechnen wollen.

Wann nutzen wir den Wilcoxon-Mann-Whitney-Test? Wir nutzen den Wilcoxon-Mann-Whitney-Test wenn wir zwei Verteilungen miteinander vergleichen wollen. Das ist jetzt sehr abstrakt und auch eins der Probleme des U-Tests. Wir würden sagen, dass wenn wir zwei Gruppen haben und ein nicht normalverteiltes $y$, dann nutzen wir einen U-Test. Das ist aber stark verkürzt, mittlerweile haben wir in unserer statistischen Toolbox auch über das statistsiche Modellieren eine Lösungen für eine Vielzahl von Verteilungen. Keine Normalverteilung heißt nicht automatisch jetzt aber Nichtparametrik. Das war vielleicht Anfang der 90ziger so. Wir haben heute mehr Möglichkeiten --- im Prinzip meine ich damit, dass der U-Test seine Nische verdient hat, aber eigentlich etwas veraltet ist mit seinen Problemen. Haben wir ein normalverteiltes $y$ rechnen wir meist einen t-Test. Wir könnten aber auch einen Wilcoxon-Mann-Whitney-Test auf einer Normalverteilung rechnen.

Was ist jetzt der Unterschied zwischen einem UTest und einem t-Test? Der t-Test vergleicht die Mittelwerte zweier Normalverteilungen, also zum Beispiel die Verteilung der Sprungweiten der Hundeflöhe gegen die Verteilung der Sprungweiten der Katzenflöhe. Dazu nutzt der t-Test die Mittelwerte und die Standardabweichung. Beides sind Parameter einer Verteilung und somit ist der t-Test ein parametrischer Test. Der Wilcoxon-Mann-Whitney-Test ist die nichtparametrische Variante in dem wir die Zahlen in Ränge umwandeln, also sortieren, und mit den Rängen der Zahlen rechnen. Die deskriptiven Maßzahlen wären dann Median, Quantile und Quartile. Also im Prinzip eine Rangtransformation und dann anschließend ein statistischer Test der Ränge. In der folgenden Abbildung habe ich dir einmal den Zusammenhhang zwischen den originalen Messwerten und der Rangtransformation dargestellt.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-ranked-00
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 6
#| fig-cap: "Zusammenhang zwischen den originalen Messwerten und den rangierten Messwerten nach der Rangtransformation. Nach dem Rangieren haben alle Messwerte den gleichen Abstand."

p_rank_intro
```

Wenn wir von der Rangtransformation sprechen, dann treten auch häufiger Bindungen in den Messwerten auf. Bindungen sind kein Problem und können bei der Auswertung berücksichtigt werden. Je mehr Kommastellen ein kontinuierlicher Messwert hat, desto weniger Binden können natürlich auftreten. Bei ordinalen Daten wie Noten ist das natürlich nicht so einfach möglich.

Was sind Bindungen?

:   Bindungen treten bei der Rangtransformation auf, wenn wir gleiche originale Messwerte haben. Dann müssen wir zwei Messwerten den gleichen Rang geben. Wenn dieser Fall auftritt, dann sprechen wir von Bindungen in den Daten. Die nichtparametrischen Algorithmen haben dafür implementierte Lösungen.

Steigen wir also einmal mit einem plakativen Beispiel aus der Studie von @sugimoto2023hyperactive in die Thematik des U-Test ein. Ich habe die folgende Abbildung einmal mitgebracht in der wir die Mittewerte sowie die Standardabwichung von verschiedenen Messwerten für eien Wildtyp (WT) sowie einer genetischen Variante (Rag2) sehen. Die Sterne geben die Signifikanz des Vergleichs zwischen den Gruppen an.

![*Left: Number of GFP+ MLL-AF9 cells in peripheral blood of WT and Rag2−/− mice. PB was collected 11 days after transplantation. Data are shown as means ± s.e.m. \[n = 6 (male: n = 3, female: n = 3) for each group\]. \*\*P \< 0.01；two-tailed Mann–Whitney test. Middle/right: Weight and size of spleens collected from WT or Rag2−/− mice 11 days after transplantation. Data are shown as means ± s.e.m. (n = 3 for each group, male). \*\*\*P \< 0.001, \*\*\*\*P \< 0.0001; two-tailed Student’s t test.* Quelle: @sugimoto2023hyperactive](images/sugimoto_cell_mice.png){#fig-utest-intro fig-align="center" width="100%"}

Nachdem wir uns die @fig-utest-intro einmal genauer angeschaut haben, stellt sich die Frage warum wird in der Abbildung ganz links ein Mann-Whitney oder U-Test gerechnet und in den beiden anderen Abbildungen ein Student t-Test? Warum nicht auf alles ein U-Test rechnen? Immerhin würde ja auf das Gewicht und die Größe der Milz (eng. *spleen*) auch ein U-Test als statistischer Test auch gehen. Wir haben hier unterschiedliche Fallzahlen in den Gruppen. In der linken Abbildung haben wir pro Gruppe sechs Mäuse und in der mittleren sowie rechten Abbidlung nur drei Mäuse pro Gruppe. Macht das einen Unterschied? Ja, für den U-Test macht das einen gewaltigen Unterschied, wie wir gleich einmal sehen werden.

## Das Problem...

Es gibt ein paar Probleme, wenn wir uns mit dem U-Test im Allgemeinen beschäftigen wollen. Diese Probleme sind eigentlich nicht weitläufig bekannt. Mir waren die Probleme auch nicht bekannt bis ich angefangen habe dieses Kapitel zu schreiben. Deshalb gehen wir mal die Probleme durch und leider gibt es nicht so richtig eine Lösung dafür. Es sind Probleme, die aus dem Algorithmus und der Transformation in Ränge entstehen.

### ...der Gruppengröße

> *"Statistik fängt erst ab einer Gruppengröße von n gleich sieben überhaupt an." --- Ein anonymer Nichtparametriker*

Um das Problem der geringen Gruppengröße zu verstehen, müssen wir erstmal den Zusammenhang zwischen einem signifikanten Ergebnis und der Mittelwertsdifferenz als ein statistsiches Maß für den Effekt verstehen. Je größer der Effekt, desto eher sollte ein Vergleich zwischen zwei Gruppen signifikant unterschiedlich sein. In der folgenden Abbildung habe ich dir einmal den Zusammenhang zwischen der Mittelwerstdifferenz $\Delta$ und der Signifikanz dargestellt. Wie du siehst überlappen die Verteilungend der beiden Gruppen, wenn die Differenz der Mittelwerte klein ist. Je größer der Unterschied desto größer ist die Mittelwertsdifferenz. Soweit so klar. Damit sollten wir auch kleinere p-Werte erhalten, je größer die Mittelwertsdifferenz wird. Ich habe dir mal beispielhafte p-Werte in der Abbidung ergänzt.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-intro-sim-02
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 12
#| fig-cap: "Darstellung des Zusammenhangs zwischen der Mittelwertsdifferenz und der zu erwartenden Signifikanz aus einem statistischen Tests für einen Zweigruppenvergleich. Die p-Werte sind abgeschätzt. **(A)** Die Mittelwertsdifferenz ist klein, es ist kein signifikanter Unterschied zu erwarten. Der p-Wert ist groß. **(B)** Die Mittelwertsdifferenz ist moderat, es ist ein kleiner p-Wert zu erwarten. **(C)** Die Mittelwertsdifferenz ist groß, damit ist der p-Wert kleiner als $0.001$ und hoch signifikant. *[Zum Vergrößern anklicken]*"

p_small_d + p_mid_d + p_high_d +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Wenn wir jetzt den Zusammenhang zwischen der Mittelwertsdifferenz und dem p-Wert verstanden haben, können wir jetzt zum Problem der geringen Fallzahl in den Gruppen kommen. Wenn die Mittelwertsdifferenz ansteigt, dann sollte der p-Wert fallen. Wie du in folgender Abbildung links auch siehst, ist das der Fall. Für alle Kombinationen der Fallzahlen in den beiden Gruppen $n_1$ und $n_2$ fallen die p-Werte mit steigendem Effekt. Nur haben die p-Werte ein Plateau unter das sie nicht fallen können. Und bei einer Gruppengröße von 3 und 3 oder 4 und 3 können die p-Werte nicht kleiner als 0.05 werden egal wie groß die Mittelwertsdifferenz wird. Daher können wir mit diesen beiden Fallzahlkombinationen keinen signifkanten Unterschied nachweisen. Das sehen wir auch nochmal in der anderen Abbildung rechts, hier siehst du die minimalen p-Werte. Die p-Werte können in einem U-Test nicht unter gewisse Schranken fallen, abhängig von der Gruppenfallzahl.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-intro-sim-01
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 9
#| fig-cap: "Zusammenhang zwischen der Mittelwertsdifferenz und dem mittleren p-Wert aus einer Simulationsstudie abhängig von der Fallzahl in zwei Gruppen $n_1$ und $n_2$. Die graue Linie zeigt das 5% Signifikanzniveau an. **(A)** Mit steigender Mittelwertsdifferenz fallen die mittleren p-Werte. Die p-Werte erreichen je nach Fallzahlkombination ein Plateau. **(B)** Kleinst möglicher p-Wert in den Simulationen für jede Fallzahlkombinationen. *[Zum Vergrößern anklicken]*"

p1_sample + p2_sample +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Jetzt verstehen wir auch warum @sugimoto2023hyperactive in der @fig-utest-intro auf einen Student t-Test für die Gruppengröße $n_1 = 3$ und $n_2 = 3$ umgeschwenkt ist. Trotz des riesigen Effekts in den Barplots und damit dem Mittelwertsunterschied, wäre ein Mann-Whitney Test nie signifikant geworden. Der p-Werte wäre dann hier auf 10% begrenzt, egal wie groß der eigentliche Effekt ist. Diese harte Grenze kennt der t-Test nicht, deshalb wurde hier dann der t-Test als Ausweg gewählt.

### ...der Hypothesen

Das Problem mit den [Mann-Whitney-U-Test und den Hypothesen](https://statistikguru.de/spss/mann-whitney-u-test/mann-whitney-u-test-hypothesen.html) hat mich etwas überraschend getroffen. Ich dachte lange immer, dass der U-Test eben die Mediane miteinander vergleicht. Das macht ja auch irgendwie Sinn, denn die Mediane müssen ja auch einen Test haben und basieren ja auch auf Rängen. Oder wie es so schön sinnig in der Veröffentlichung [The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1305291#d1e1503) von @divine2018wilcoxon geschrieben steht.

> *"A major impetus to reporting medians with Mann-Whitney-U-tests results is likely the major utility of reporting a summary statistic that reflects the same scale as the data being analyzed." --- @divine2018wilcoxon*

Gut, was testet den nun der U-Test? [Kommt auf die Annahmen an die Daten und damit dem U-Test an](https://de.wikipedia.org/wiki/Wilcoxon-Mann-Whitney-Test#Annahmen). Oder konkreter an die beiden Verteilungsformen, die du miteinander vergleichst. Der U-Test kann nämlich unterschiedliche Nullhypothesen haben, je nachdem welche Annahmen du an deine Daten hast. Und hier kommt der schlechte Witz. Meistens hast du so wenig Beobachtungen, dass du selber keine Visualisierung der Verteilung erstellen kannst.

#### Gleiche Verteilungsform, unterschiedliche Lage {.unnumbered .unlisted}

Weil die beiden Verteilungsfunktionen bis auf Verschiebung gleich sind, muss insbesondere Varianzhomogenität zwischen den beiden Gruppen gelten. Wenn wir also gleiche Verteilungen haben, die auch damit varianzhomogen sind, können wir folgende Hypothesen aufstellen. Ich habe dir den Fall einmal in der folgenden Abbildung dargestellt. Die Annahmen sind sehr restriktiv. Nach @conroy2012hypotheses mit [What Hypotheses do “Nonparametric” Two-Group Tests Actually Test?](https://journals.sagepub.com/doi/10.1177/1536867X1201200202) sollte daher der U-Test nicht für den Vergleich von Medianen genutzt werden.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-intro-02
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Der U-Test kann unter der Annahme der gleichen Verteilungsform und damit angenommener Varianzhomogenität die Verschiebung a in den Medianen testen. Die Annahmen sind sehr restriktiv und treten nicht oft auf. *[Zum Vergrößern anklicken]*"

p_shift 
```

Damit ergeben sich dann die folgenden Hypothesenpaare für den Vergleich der Mediane.

::: panel-tabset
## Prosa

$H_0:$ *Die Gleichheit der Mediane der zwei Gruppen liegt vor. Die Verschiebung der Mediane ist Null.*

$H_A:$ *Die Mediane der zwei Gruppen unterscheiden sich. Die Verschiebung der Mediane ist ungleich Null.*

## Formel

$$
H_0: a = 0
$$

$$
H_A: a \neq 0
$$
:::

Die Problematik ist recht umfangreich und der U-Test kann auch bei gleichen Medianen signifkante Ergebnisse liefern. @hart2001mann diskutiert in [Mann-Whitney test is not just a test of medians: differences in spread can be important](https://www.bmj.com/content/bmj/323/7309/391.full.pdf?casa_token=GFRQ5vdBejMAAAAA:uWLUlyNzp0rDKrXcco4fvr4L35PvzDO9Y-SPDKTIUGNgcMvgtmcctzE5tIz82XB5t8TydVC7okvjDA) nochmal einige Sonderfälle. Also verbleibe ich dabei, der U-Test testet ursprünglich nicht die Unterschiede in den Median. Außer die Sterne stehen günstig, was aber keine Grundlage für sauberes wissenschaftliches Arbeiten ist.

#### Unterschiedliche Verteilungsform, unterschiedliche Lage {.unnumbered .unlisted}

Nachdem wir uns nun davon verabschiedet haben, dass wir mit dem U-Test Mediane vergleichen, kommen wir nun zu den echten Hypothesen. Oder andersherum nur in sehr seltenen Fällen die Interpretation eines Vergleiches der Mediane erlaubt. Was ist also die Nullhypothese und die Alternativhypothese, die wir mit dem U-Test überprüfen wollen? Ich habe einmal ein schönes Zitat aus Guidelines von GraphPad mitgebracht sowie dann die Hypothesen auch einmal mathematisch aufgeschrieben.

::: panel-tabset
## Prosa

Der U-Test beantwortet folgende Frage an die Daten.

> *"If the groups are sampled from populations with identical distributions, what is the chance that random sampling would result in a sum of ranks as far apart (or more so) as observed in this experiment?" --- [The Mann-Whitney test doesn't really compare medians](https://www.graphpad.com/guides/prism/5/user-guide/prism5help.html?stat_nonparametric_tests_dont_compa.htm)*

Damit haben wir dann in Prosa folgendes Hypothesenpaar vorliegen.

$H_0:$ *Es ist gleich wahrscheinlich, dass ein zufällig aus der einen Population ausgewählter Wert größer oder kleiner ist als ein zufällig ausgewählter Wert aus der anderen Population*

$H_A:$ *Es ist* ***nicht*** *gleich wahrscheinlich, dass ein zufällig aus der einen Population ausgewählter Wert größer oder kleiner ist als ein zufällig ausgewählter Wert aus der anderen Population*

## Formel

In der Formel wird es schon etwas wilder und ich muss sagen, dass mir die Formel das Verständnis nicht leichter macht. Wir vergleichen hier zwei Populationen $X$ und $Y$ miteinander.

$$
H_0:  Pr(X<Y) + \cfrac{1}{2} Pr(X = Y) = 0.5
$$

$$
H_A:  Pr(X<Y) + \cfrac{1}{2} Pr(X = Y) \neq 0.5
$$

In dem R Paket `{nparcomp}` bezeichnen wir den Wert für $Pr(X<Y) + \cfrac{1}{2} Pr(X = Y)$ auch als relativen Effekt.
:::

Da mir die Nullhypothese mit $Pr(X<Y) + \cfrac{1}{2} Pr(X = Y) = 0.5$ nicht ganz einleuchtete habe ich einmal die Sachlage visualisiert und in R nachgerechnet. Ich verstehe den Zusammenhang sonst nicht. Die Nullhypothese besagt ja, dass *es gleich wahrscheinlich ist, dass ein zufällig aus der einen Population ausgewählter Wert größer oder kleiner ist als ein zufällig ausgewählter Wert aus der anderen Population*. Daher baue ich mit einfach mal zwei Vaktoren `X` und `Y` mit jeweils den gleichen Zahlen mit $X = Y = {1, 2, 3, 4}$. Jetzt müsste ja auch der obigen Formel der Wert $0.5$ rauskommen, denn die Nullhypothese ist ja wahr. Die Werte sind ja gleich.

::: panel-tabset
## Visualisierung

Was habe ich in der folgenden Abbildung einmal den Zusammenhang der Formel mit den Werten dargestellt. Wir haben insgesamt 16 Wertepaare für unsere 4 Zahlen pro Gruppe. Davon sind vier Wertepaar gleich, dargestellt in grün. Hier kriegen wir dann den Wert für $\cfrac{1}{2} Pr(X = Y)$ mit $0.125$ raus. Dann haben wir noch sechs Wertepaare wo X kleiner ist als Y. Daher haben wir hier die Werte für $Pr(X<Y)$ mit $0.375$ raus. Jetzt müssen wir noch die beiden Werte addieren und sehen, dass wir auf die $0.5$ kommen. Das sieht doch gut aus. Was es jetzt uns sagt, ist nochmal eine andere Sache, aber immerhin haben wir mal verstanden, wie die Wahrscheinlichkeiten berechnet werden. Am Ende ist es dann doch nur ein Spiel der wilden Kombinatorik. Mehr zum Spielen im folgenden Tab.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-intro-03
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Beispielhafte Berechnung der Wahrscheinlichkeit für die Nullhypothese in einem U-Test mit vier Werten für X und Y sowie den entsprechenden sechszehn Wertepaaren. Die Nullhypothese gilt, die Werte von X und Y sind gleich. Bindungen werden ignoriert, es handelt sich ja nicht um Ränge per se. Die grünen Linien zeigen Wertepaare die gleich sind. Die roten Linien Wertepaare wo X kleiner als Y ist. *[Zum Vergrößern anklicken]*"

p_hypo_null 
```

Du findest in dem Tutorium [The Mann-Whitney U Test](https://www.statstutor.ac.uk/resources/uploaded/mannwhitney.pdf) nochmal ein anschauliches Beispiel. Und auch in der Arbeit von @conroy2012hypotheses wird versucht die Nullhypothese als Wertepaare über einen Kugelplot zu visualisieren.

## `{base}`

Wir können uns auch einmal die Sachlage in R nachbauen. Wir haben dann die zwei Vektoren `x` und `y` mit beliebigen Werten. Ich nehme hier mal wieder die Werte `1, 2, 3, 4` für beide Vektoren.

```{r}
x <- c(1, 2, 3, 4)
y <- c(1, 2, 3, 4)
```

Die Funktion `crossing()` gibt uns jetzt jedes paarweise Wertepaar der Kombinartion von `x` und `y` wieder. Dann können wir berechnen welche Wertepaare gleich sind, als `x == y` sowie die Wertepaare, wo `x` kleiner ist als `y`. Dann schauen wir uns einmal die Ausgabe an.

```{r}
pair_tbl <- crossing(x, y) |> 
  mutate(p_x_equal_y = (x == y),
         p_x_less_y = (x < y)) 
pair_tbl
```

Jetzt können wir noch die Mittelwerte berechnen, was bei Wahrscheinlichkeiten nichts anders ist als die Wahrscheinlichkeit für `TRUE` zu erhalten. Wir sehen, dass wir auf die gleichen Wert kommen. Jetzt kannst du auch mit anderen Kombinationen der Vektoren spielen und sehen, wie sich die Werte und deren Summe ändern.

```{r}
pair_tbl |> 
  summarise(mean(p_x_less_y),
            mean(p_x_equal_y)/2) 

```

## Beispiel

Dann können wir mal den Wert für $Pr(X<Y) + \cfrac{1}{2} Pr(X = Y)$ einmal für unser Datenbeispiel zu den Sprungweiten berechnen. Du findest die Daten nochmal weiter unten zum selber laden. Wir nutzen dazu den R Code aus dem vorherigen Tab. Zuerst müssen wir einmal die Sprungweiten über die beiden Floharten rangieren. Dann wieder die beiden Floharten separieren damit wir dann mit den Spalten der Ränge weiterrechnen können.

```{r}
#| message: false
#| warning: false
fac1_ranks_tbl <- fac1_tbl |> 
  mutate(ranked_jump_length = rank(jump_length)) |>
  select(animal, ranked_jump_length) |> 
  pivot_wider(names_from = animal,
              values_from = ranked_jump_length) |> 
  unnest()
fac1_ranks_tbl
```

Jetzt setzen wir die Ränge der beiden Spalten einmal in die Funktion `crossing()` und rechnen einmal die Werte für $Pr(X < Y)$ und $\cfrac{1}{2} Pr(X = Y)$ aus. Wie wir sehen, ist eine der Wahrscheinlichkeiten null. Die Summierung der beiden Werte spare ich mir, dass geht ja auch so recht flott im Kopf.

```{r}
crossing(dog = fac1_ranks_tbl$dog, 
         cat = fac1_ranks_tbl$cat) |> 
  mutate(p_x_equal_y = (dog == cat),
         p_x_less_y = (dog < cat)) |> 
  summarise(mean(p_x_less_y),
            mean(p_x_equal_y)/2) 
```

Was wissen wir also? Wenn wir alle 49 Wertepaare jeder Sprungweite eines Katzenflohs mit jeder Sprungweite eines Hundeflohs vergleichen, dann springen in 10.2% der Wertepaare die Hundeflöhe kürzer (oder gleich) weit wie die Katzenflöhe. Oder andersherum springen in fast 90% der Wertepaare die Hundeflöhe weiter als die Katzenflöhe.
:::

### ...des Effekts

Was ist der Effekt eines nichtparametrischen Tests? Oder andersherum, wenn wir eine Rangtransformation durchführen, dann verwandeln wir ja alle Zahlen mit einer Einheit in einen einheitslosen Rang. Damit rechnen wir also auf den Rängen des Messwertes. Wenn wir aber nun einheitslose Ränge haben, dann haben wir auch nur einheitslose Rangdifferenzen. Dazu kommt je mehr Beobachtungen desto mehr Ränge desto größer die Rangdifferenzen. Wir haben zwar dann die Möglichkeit wieder eine Art Cohen\`s d oder eben r zu berechnen, aber hat dieser Wert wieder keien Einheit und ist auch schwer zu interpretieren. Es gibt wieder viele Arten dies zu tun und je nach Quelle haben wir dann ein anderes Adjektiv wie "kleiner", "mittler" oder "starker" Effekt. Solche Worte können wir dann aber nicht mit Kosten/Nutzenrechnungen verbinden. Am Ende hat eben dann der nichtparametrische U-Test kein Effektmaß mit dem sich praktisch und relevant arbeiten lässt.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Es gibt Gründe die Nichtparametrik als den Ausweg für die Nichtnormalverteilung zu sehen. In gewissen Anwendungsfeldern mag das auch so stimmen. Wenn du wirklich nicht an einem Effektmaß interessiert bist und nur einen p-Wert brauchst, dann ist die Nichtparametrik eine Lösung. Heutzutage wollen wir aber auch immer wissen, ist der Effekt relevant? Und die Frage ohne ein Effektmaß zu beantworten sehe ich als unmöglich an." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

## Eine Lösung

[Wilcoxon is (almost) a one-sample t-test on signed ranks](https://lindeloev.github.io/tests-as-linear/simulations/simulate_wilcoxon.html)

[Nichtparametrik als Rangtransformation](https://lindeloev.github.io/tests-as-linear/#1_the_simplicity_underlying_common_tests)

@zimmerman1993relative [Relative Power of the Wilcoxon Test, the Friedman Test, and Repeated-Measures ANOVA on Ranks](https://www.proquest.com/docview/1299992501?pq-origsite=gscholar&fromopenview=true&sourcetype=Scholarly%20Journals&imgSeq=1)

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-ttest-ver
#| fig-align: center
#| fig-height: 3
#| fig-width: 6
#| fig-cap: "Datengrundlage für die folgende Simulation und dem Vergleich des Welch t-Test auf rangierten Daten und dem U-Test ist die log-normal Verteilung. Die log-normal Verteilung ist nicht normalverteilt. *[Zum Vergrößern anklicken]*"

p_lognormal_t_u
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-ttest
#| fig-align: center
#| fig-height: 5
#| fig-width: 9
#| fig-cap: "Gegenüberstellung des Welch t-Test auf rangtransformierten Daten und dem U-Test. Die Nullhypothese ist wahr, die zu vergleichenden Gruppen stammen aus der gleichen log-normal Verteilung. Es wurden 10000 Simulationen gerechnet. **(A)** Gegenüberstellung aller p-Werte für den Welch t-Test und dem U-Test. Die graue Linie stellt die Winkelhalbierende dar.  **(B)** Abweichung der p-Werte des Welch t-Test zum U-Test. Die gestrichelte Linie stellt das Signifikanzniveau gleich 5% dar. Die graue Linie die Winkelhalbierende in der nebenstehenden Abbildung. *[Zum Vergrößern anklicken]*"

p_p_t_u_1 + p_p_t_u_2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, tidyplots, rstatix,
               readxl, coin, ggpubr, nparcomp,
               conflicted)
conflicts_prefer(rstatix::wilcox_test)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

In den folgendne Abschnitten brauchen wir dann zwei Datensätze. Der erste Datensatz beschreibt Hunde- und Katzenflöhe, die springen und deren Sprungweite dann gemessen wurde. Wir haben hier verschiedene Flöhe vorliegen, die nur einmal springen. Wir können aber auch den Fall haben, dass wir uns wiederholt einen Floh anschauen. Der zweite Datensatz betrachtet Hundeflöhe, die vor der Fütterung und nach der Fütterung gesprungen sind.

#### Unabhängige Messungen {.unnumbered .unlisted}

Beginnen wir also mit unserem einfaktoriellen Datensatz mit zwei Gruppen. Wir haben hier die Sprungweite in \[cm\] von Hunde- und Katzenflöhen gemessen. Unser Faktor ist hierbei die Flohart. Entweder ein Hundefloh oder eben ein Katzenfloh. Wir wollen jetzt wissen, ob sich die beiden Floharten hinsichtlich ihrer Sprungweite unterscheiden.

```{r}
#| message: false

fac1_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  select(animal, jump_length) |> 
  mutate(animal = as_factor(animal))
```

In der folgenden Tabelle siehst du dann einmal einen Auszug aus den Daten der Sprungweiten für die beiden Floharten. Dabei ist dann die Spalte `animal` unser Faktor über den wir den Gruppenvergleich für die Sprungweiten als Messwert rechnen wollen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table
#| tbl-cap: "Tabelle der Sprungweiten in [cm] als Messwert $y$ von Hunde-, Katzen- und Fuchsflöhen. Der Datensatz ist einfaktoriell, da wir nur einen Faktor vorliegen haben."

fac1_raw_tbl <- read_xlsx("data/flea_dog_cat.xlsx") |>
  select(animal, jump_length) 

rbind(head(fac1_raw_tbl, n = 3),
      rep("...", times = ncol(fac1_raw_tbl)),
      tail(fac1_raw_tbl, n = 3)) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

Dann wollen wir uns auch einmal die Daten visualisieren. Ich nutze dazu dann einmal den Boixplot sowie den Violinplot. Die Daten sehen einigermaßen normalverteilt aus, so dass wir hier auch einen t-Test rechnen könnten. Wie immer geht es hier auch um die Demonstration der Algorithmen, also nutzen wir hier auch diese Daten für den U-Test. Der U-Test funktioniert auch super auf noormalverteilten Daten.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-utest-jump
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Darstellung der Sprungweiten in [cm] gruppiert nach Hunde- und Katzenflöhen. Die graue Raute stellt den entsprechnenden Mittelwert der Sprungweiten dar. **(A)** Einfaktorieller Boxplot. **(B)** Violinplot mit Dotplot. *[Zum Vergrößern anklicken]*"

p1 <- ggplot(data = fac1_tbl, 
       aes(x = animal, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = "point", 
               shape=23, size = 3, fill = "gray50") +
  labs(x = "Flohart", y = "Sprungweite in [cm]") +
  theme(legend.position = "none") + 
  scale_fill_okabeito() 


p2 <- ggplot(data = fac1_tbl, 
       aes(x = animal, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_violindot(dots_size = 7, trim = FALSE) +
  stat_summary(fun.y = mean, geom = "point", 
               shape=23, size = 3, fill = "gray50") +
  labs(x = "Flohart", y = "Sprungweite in [cm]") +
  theme(legend.position = "none") + 
  scale_fill_okabeito() 

p1 + p2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Abhängige Messungen {.unnumbered .unlisted}

Der U-Test erlaubt auch abhängige Daten zu analysieren. Das heißt wir haben die gleichen sieben Hundeflöhe wiederholt gemessen. Einmal haben wir einen Hundefloh gemessen bevor er was gegessen hat, also hungrig ist, und einmal nachdem der gleiche Floh sich satt gegessen hat. Daher haben wir hier abhängige oder verbundene Bebachtungen. Im folgenden einmal der Datensatz eingelesen im Wide-Format.

```{r}
#| message: false
paired_tbl <- read_excel("data/flea_dog_cat_repeated.xlsx") 
```

Wie du sehen kannst haben wir die sieben Flöhe wiederholt gemessen. Die Daten sind nicht im `tidy`-Format, da nicht jede Zeile nur eine Messunfg für eine Beobachtung beinhaltet. Das ändern wir dann einmal gleich in Long-Format.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Tabelle  der Sprunglängen [cm] von fünf Hundeflöhen zu zwei Zeitpunkten. Einmal wurde die Sprungweite mit den hungrigen Flöhen und einmal mit den gleichen satten Flöhen bestimmt."
#| label: tbl-data-ttest-paired-01

paired_tbl |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

Dann hier nochmal die Long-Formatvariante mit der Funktion `pivot_longer()`. Wir brauchen das Long-Format für die Auswertung in den unteren Abschnitten für das R Paket `{rstatix}`.

```{r}
paired_long_tbl <- paired_tbl |> 
  pivot_longer(cols = hungrig:satt,
               values_to = "jump_length",
               names_to = "trt") 
```

Manchmal ist es schwer zu verstehen, was jetzt wiederholt oder gepaart heißen soll. Deshalb hier nochmal die Visualiserung der Daten für die beiden Sprünge vor und nach der Fütterung. Ich habe die Messungen, die zusammengehören mit einer Linie verbunden. Dazu dann auch noch die jeweiligen IDs der Flöhe ergänzt.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Dotplot der Sprungweiten [cm] für Hundeflöhe in zwei verschiedenen Ernährungszuständen gemessen an zwei Zeitpunkten. Die Linien verbinden die Messung an dem gleichen Floh."
#| label: fig-example-paired

paired_tbl |> 
  pivot_longer(cols = hungrig:satt,
               values_to = "jump_length",
               names_to = "trt") |> 
ggplot(aes(trt, jump_length, fill = trt)) +
  theme_minimal() +
  geom_line(aes(group = id), color = "gray50") +
  geom_point(shape = 21, size = 4) +
  scale_fill_okabeito() +
  geom_text(aes(label = id), position = position_nudge(x = 0.05, y = -0.05)) +
  theme(legend.position = "none") +
  labs(x = "Ernährungszustand",
       y = "Sprungweite in [cm]")
```

## Hypothesen

::: callout-warning
## Achtung, bitte beachten!

Die Wahl der Nullhypothese durch die Annahmen an die Verteilungsfromen der beiden zu vergleichenden Gruppen hat natürlich einen gewaltigen Einfluss auf die Interpretation des p-Wertes. Also wenn man es statistisch genau nimmt. Deshalb hier auch einmal die simpelste Prosavariante für Einsteiger.
:::

Bitte lesen nochmal oben den Abschnitt zu dem Problem der Nullhypothese im U-Test nach. Je nachdem wie tief du jetzt hier einsteigen willst, habe ich dir mal die drei Varianten angebenen. Am Ende findest du die simpelste Prosavariante gar nicht so selten in Tutorien. Die fortgeschrittene Variante trifft es schon sehr gut. Die mathematische Formel mag dann mehr Fragen als Antworten liefern. Die praktische Interpretation der Nullhypothese eines U-Test bleibt mir aktuell noch verschlossen.

::: panel-tabset
## Simpelste Prosa

Wenn wir nur den p-Wert betrachten, dann können wir auch folgende simple Aussage über den U-Test machen. Das ist jetzt genau so wahr wie falsch aber hilfreich.

$H_0:$ *Die beiden Gruppen sind gleich in ihrem Messwert.*

$H_A:$ *Es liegt ein Unterschied im Messwert zwischen den Gruppen vor.*

## Fortgeschrittene Prosa

Hier dann die richtige Interpretation der Nullhypothese. Obwohl ich mir sicher bin, dass die praktische Relevanz der Nullhypothese hier auch nicht sehr viel klarer wird.

$H_0:$ *Es ist gleich wahrscheinlich, dass ein zufällig aus der einen Population ausgewählter Wert größer oder kleiner ist als ein zufällig ausgewählter Wert aus der anderen Population*

$H_A:$ *Es ist* ***nicht*** *gleich wahrscheinlich, dass ein zufällig aus der einen Population ausgewählter Wert größer oder kleiner ist als ein zufällig ausgewählter Wert aus der anderen Population*

## Formel

Wir vergleichen hier zwei Populationen oder Gruppen $X$ und $Y$ miteinander. Die Formel repräsentiert die fortgeschrittene Prosa in dem vorherigen Tab. Bitte nochmal oben nachschauen, wenn du die Nullhypothese verstehen willst.

$$
H_0:  Pr(X<Y) + \cfrac{1}{2} Pr(X = Y) = 0.5
$$

$$
H_A:  Pr(X<Y) + \cfrac{1}{2} Pr(X = Y) \neq 0.5
$$

In dem R Paket `{nparcomp}` bezeichnen wir den Wert für $Pr(X<Y) + \cfrac{1}{2} Pr(X = Y)$ auch als relativen Effekt. Faktisch ist es der Anteil an allen Wertepaaren, die kleiner oder gleich in der einen Gruppe $X$ sind als in der anderen Gruppe $Y$.
:::

## Der U-Test

Dann kommen wir zu der Implementierung des U-Tests in R. Wie immer gibt es reiche Auswahl an R Paketen, die für dich den U-Test auf unabhängigen wie auch abhängigen Daten rechnen. Wenn ich die Wahl habe, dann nehme ich die Funktionen aus dem R Paket `{rstatix}`. Das Paket hat eigentlich alles was man braucht um einen U-Test zu rechnen. Intern basiert das Paket auf dem Paket `{coin}` was von der Anwendung etwas veraltet ist. Ein neueres Paket ist die Implementierung in dem R Paket `{nparcomp}`. Hier wirst du mit viel Informationen versorgt aber dann inhaltlich etwas alleine gelassen, was die Interpretation angeht. Wir schauen aber auch hier einmal rein.

### ... mit unabhängigen Beobachtungen

Am häufigsten wirst du wohl den U-Test mit zwei Gruppen rechnen, die voneinander unabhängig sind. Das heißt, du misst deinen Messwert $y$ in zwei Gruppen und jede Messung ist unabhängig von der anderen. Wir haben so einen Fall in unserem Datensatz zu den Sprungweiten der Hunde- und Katzenflöhe vorleigen. Wir haben sieben Hundeflöhe und sieben Katzenflöhe einmal gemessen und die Sprungweiten in dem Datensatz `fac1_tbl` gespeichert. Wir schauen uns für die unabhängigen Beobachtungen auch einmal die theoretische Berechung an, bevor wir uns dann in den anderen Tabs mit der Implementierung in R beschäftigen.

::: panel-tabset
## Theorie

Der Wilcoxon-Mann-Whitney-Test berechnet die U Teststatistik auf den Rängend der Daten. Es gibt genau soviele Ränge wie es Beobachtungen im Datensatz gibt. Wir haben vierzehn Beobachtungen in unseren Daten zu der Sprungweite in \[cm\] von den Hunde- und Katzenflöhen. Somit müssen wir auch vierzehn Ränge vergeben. Die @tbl-utest-rank zeigt das Vorgehen der Rangvergabe. Wir sortieren als erstes das $y$ aufsteigend. In unserem Fall ist das $y$ die Sprunglänge. Dann vergeben wir die Ränge jweiles zugehörig zu der Position der Sprunglänge und der Tierart. Abschließend addieren wir die Rangsummmen für `cat` und `dog` zu den Rangsummen $R_{cat}$ und $R_{dog}$.

| Rank | animal | jump_length  |  Ränge `cat`   |  Ränge `dog`   |
|:----:|:------:|:------------:|:--------------:|:--------------:|
|  1   |  cat   |     2.2      |       1        |                |
|  2   |  cat   |     3.2      |       2        |                |
|  3   |  cat   |     4.1      |       3        |                |
|  4   |  cat   |     4.3      |       4        |                |
|  5   |  cat   |     5.4      |       5        |                |
|  6   |  dog   |     5.6      |                |       6        |
|  7   |  dog   |     5.7      |                |       7        |
|  8   |  cat   |     6.1      |       8        |                |
|  9   |  dog   |     7.6      |                |       9        |
|  10  |  cat   |     7.9      |       10       |                |
|  11  |  dog   |     8.2      |                |       11       |
|  12  |  dog   |     8.9      |                |       12       |
|  13  |  dog   |     9.1      |                |       13       |
|  14  |  dog   |     11.8     |                |       14       |
|      |        |  Rangsummen  | $R_{cat} = 33$ | $R_{dog} = 72$ |
|      |        | Gruppengröße |       7        |       7        |

: Datentablle absteigend sortiert nach der Sprunglänge in \[cm\]. Die Level `cat` und `dog` haben jeweils die entsprechenden Ränge zugeordnet bekommen und die Rangsummen wurden berechnet {#tbl-utest-rank}

Die Formel für die U Statistik sieht ein wenig wild aus, aber wir können eigentlich relativ einfach alle Zahlen einsetzen. Dann musst du dich etwas konzentrieren bei der Rechnung.

$$
U_{D} = n_1n_2 + \cfrac{n_1(n_1+1)}{2}-R_1
$$

mit

-   $R_1$ der *größeren* der beiden Rangsummen,
-   $n_1$ die Fallzahl der *größeren* der beiden Rangsummen
-   $n_2$ die Fallzahl der *kleineren* der beiden Rangsummen

Wir setzen nun die Zahlen ein. Da wir ein balanciertes Design vorliegen haben sind die Fallzahlen $n_1 = n_2 = 7$ gleich. Wir müssen nur schauen, dass wir mit $R_1$ die passende Rangsumme wählen. In unserem Fall ist $R_1 = R_{dog} = 72$.

$$
U_{D} = 7 \cdot 7 + \cfrac{7(7+1)}{2}-72 = 5
$$

Der kritische Wert für die U Statistik ist $U_{\alpha = 5\%} = 8$ für $n_1 = 7$ und $n_2 = 7$. Bei der Entscheidung mit der berechneten Teststatistik $U_{D}$ gilt, wenn $U_{D} \leq U_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt. Da in unserem Fall das $U_{D}$ mit $5$ kleiner ist als das $U_{\alpha = 5\%} = 8$ können wir die Nullhypothese ablehnen. Wir haben ein signifkianten Unterschied in den Medianen zwischen den beiden Tierarten im Bezug auf die Sprungweite in \[cm\] von Flöhen.

Bei grosser Stichprobe, wenn $n_1 + n_2 > 30$ ist, können wir die U Statistik auch standariseren und damit in den z-Wert transformieren.

$$
z_{D} = \cfrac{U_{D} - \bar{U}}{s_U} = \cfrac{U_{D} - \cfrac{n_1 \cdot n_2}{2}}{\sqrt{\cfrac{n_1 \cdot n_2 (n_1 + n_2 +1)}{12}}}
$$

mit

-   $\bar{U}$ dem Mittelwert der U-Verteilung ohne Unterschied zwischen den Gruppen
-   $s_U$ Standardfehler des U-Wertes
-   $n_1$ Stichprobengrösse der Gruppe mit der grösseren Rangsumme
-   $n_2$ Stichprobengrösse der Gruppe mit der kleineren Rangsumme

Wir setzen dafür ebenfalls die berechnete U Statistik ein und müssen dann wieder konzentriert rechnen.

$$
z_{D} = \cfrac{5 - \cfrac{7 \cdot 7}{2}}{\sqrt{\cfrac{7 \cdot 7 (7 + 7 +1)}{12}}} = \cfrac{-19.5}{7.83} = |-2.46|
$$

Der kritische Wert für die z-Statistik ist $z_{\alpha = 5\%} = 1.96$. Bei der Entscheidung mit der berechneten Teststatistik $z_{D}$ gilt, wenn $z_{D} \geq z_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt. Wir haben eine berechnete z Statistik von $z_{D} = 2.46$. Damit ist $z_{D}$ größer als $z_{\alpha = 5\%} = 1.96$ und wir können die Nullhypothese ablehnen. Wir haben einen signifkanten Unterschied zwischen den Medianen der beiden Floharten im Bezug auf die Sprunglänge in \[cm\].

## `{stats}`

Die Standardimplementierung in R ist die Funktion `wilxoc.test()`. Leider kann der `wilxoc.test()` nicht mit Bindungen in den Daten umgehen. Daher würde ich die Funktion nicht empfehlen, da du im Zweifel dann nochmal die Funktion aus `{coin}` anwenden musst. Dann hast du doppelte Arbeit. Wir haben hier aber keien Bindungen in den Daten vorliegen.

```{r}
wilcox.test(jump_length ~ animal, data = fac1_tbl, 
            conf.int = TRUE)
```

Der U-Test liefert uns ein signifikantes Ergebnis, da der p-Wert kleiner ist als das Signifikanzniveau $\alpha$ gleich 5%. Wir lehnen die Nullhypothese ab. Die Sprungweiten unterscheiden sich zwischen den Hunde- und Katzenflöhen.

## `{coin}`

Ich muss jetzt gleich die Funktion `wilcox_test()` aus dem R Paket `{coin}` einmal explizit laden, da die Funktion in `{rstatix}` genauso heißt. Später musst du das natürlich nicht so machen. Wir können uns in der Funktion `wilcox_test()` auch die 95% Konfidenzintervalle wiedergeben lassen. Wir erhalten hier ein 95% Konfidenzintervall für die möglichen Verschiebung $a$ in den Messwerten. Aber Achtung, dann interpretieren wir den U-Test als Mediantest, was spezielle Anforderungen an die Verteilungen der beiden Gruppen hat. Mehr dazu in dem obigen Abschnitt zu den Problemen der Hypothesen.

```{r}
coin::wilcox_test(jump_length ~ animal, data = fac1_tbl, 
                  conf.int = TRUE) 
```

Der U-Test liefert uns ein signifikantes Ergebnis, da der p-Wert kleiner ist als das Signifikanzniveau $\alpha$ gleich 5%. Wir lehnen die Nullhypothese ab. Die Sprungweiten unterscheiden sich zwischen den Hunde- und Katzenflöhen.

## `{rstatix}`

Wir können den [Wilcoxon Test in R](https://www.datanovia.com/en/lessons/wilcoxon-test-in-r/) auch mit der Funktion `wilcox_test()` aus dem R Paket `{rstatix}` rechnen. Wir verlieren hier aber die Möglichkeit das 95% Konfidenzintervall berechnen zu können. Ansonsten ist die Funktion nichts anderes als der Aufruf der gleichnamigen Funktion in `{coin}`. Wir erhalten als Wiedergabe eine praktische Datentabelle und ich habe mal etwas vorgefiltert.

```{r}
rstatix::wilcox_test(jump_length ~ animal, data = fac1_tbl) |> 
  select(group1, group2, p)
```

Der U-Test liefert uns ein signifikantes Ergebnis, da der p-Wert kleiner ist als das Signifikanzniveau $\alpha$ gleich 5%. Wir lehnen die Nullhypothese ab. Die Sprungweiten unterscheiden sich zwischen den Hunde- und Katzenflöhen.

## `{nparcomp}`

Als letztes möchte ich noch die neuste Implementierung der Nichtparametrik mit dem R Paket `{nparcomp}` vorstellen. Wir haben hier die Implementierung des U-Tests in der Funktion `npar.t.test()`. Interessanterweise steht hier schon der t-Test mit im Namen. Es handelt sich hier um die Implementierung des nichtparametrischen t-Tests. Oder sehr vereinfacht ausgedrückt, die Anwendung des t-Tests auf rangtransformierte Messwerte. Leider hat die Funktion die unangenehme Eigenschaften alles möglich wiederzugeben, auch wenn man nur den p-Wert braucht. Daher hier dann mehr Code, damit die Funktion ruhig ist.

```{r}
npar_obj <- npar.t.test(jump_length ~ animal, data = fac1_tbl,
                        info = TRUE) 
npar_obj$Analysis
```

Der U-Test liefert uns ein signifikantes Ergebnis, da der p-Wert kleiner ist als das Signifikanzniveau $\alpha$ gleich 5%. Wir lehnen die Nullhypothese ab. Die Sprungweiten unterscheiden sich zwischen den Hunde- und Katzenflöhen.

Darüber hinaus erhalten wir auch als Effektschätzer die Wahrscheinlichkeit $Pr(dog, cat)$ als `p(dog, cat)` wiedergeben. Wenn wir eine Wahrscheinlichkeit von $0.5$ vorliegen haben, dann gilt die Nullhypothese. Hier haben wir einen Wert von $0.102$ und damit springen die Hundeflöhe `a` weiter als die Katzenflöhe `b`. Die Sprungweiten sind bei den Hunden größer als bei den Katzen, da `p(dog, cat)` kleiner ist als `1/2`. Was wir auch sagen können ist, dass nur in 10.2% der Wertepaare aller Sprungweiten der Hunde- und Katzenflöhe, die Hunde kürzer springen. Mit Wertepaaren meine ich, dass wir jeden Wert der Sprungweite der Hundeflöhe mit jedem Wert der Katzenflöhe vergleichen. Wir wissen aber nicht um wie viel kürzer in einer wie auch immer gearteten Einheit. Ohne handfeste biologisch definierte Relevanz auf der Sprungweite hat dann das 95% Konfidenzintervall auch keine direkte Bedeutung.
:::

Wie du sehen kannst kommt bei allen Implementierungen des U-Tests im Prinzip das gleiche raus. Der U-Test liefert uns ein signifikantes Ergebnis, da der p-Wert kleiner ist als das Signifikanzniveau $\alpha$ gleich 5%. Wir haben nur leichte Fluktuationen im p-Wert durch die Art des Algorithmus hinter dem U-Test des jeweiligen Pakets. Am Ende unterscheiden sich die Sprungweiten zwischen den Hunde- und Katzenflöhen. Jetzt bleibt noch die Frage, wie groß der Effekt ist.

#### Effektschätzer {.unnumbered .unlisted}

Als Effektschätzer nutzen wir den rangbiserialer Korrelationskoeffizient $r$. Mehr dazu auch in der Veröffentlichung von @tomczak2014need. Wir nutzen hier die Implementierung in `{rstatix}` mit der Funktion `wilcox_effsize()`. Praktischerweise erhalten wir dann auch gleich die Interpretation mit angegeben. Dann können wir die Abschätzung dann auch gleich mit übernehmen.

```{r}
fac1_tbl |> 
  wilcox_effsize(jump_length ~ animal) |> 
  select(effsize, magnitude)
```

Leider kannst du mit dem Wert von $0.66$ nicht weiterrechnen. Der $r$-Wert ist einheitlos und kann nicht in eine Kosten/Nutzenrechnung überführt werden. Daher hast du nur die Information, dass der Effekt zwischen den Sprungweiten der Hunde- un Katzenflöhe groß ist.

Bitte nutze die Verschiebung der Mediane nur als Effektschätzer, wenn du dir sicher bist, dass die beiden Verteilungsformen der Gruppen gleich sind und Varianhomogenität zwischen deinen Gruppen vorliegt. Ansonsten ist die Medianverschiebung aus dem R Paket `{coin}` kein äquivalenter Effektschätzer.

Wir können natürlich auch als Effekctschätzer den relativen Effekt $p(a,b)$ händisch berechnen, wenn wir nicht das R Paket `{nparcomp}` nutzen wollen. Aber auch hier stellt sich die Frage, was wir mit dem Wissen machen welcher prozentualer Anteil der Messwerte in der einen Gruppe kleiner oder gleich als in der anderen Gruppe ist. Wir wissen ja am Ende wiederum nicht um wieviel kleiner. Eine Transformation in Ränge hat eben dann auch Nachteile.

#### Parametrische Lösung: Der t-Test {.unnumbered .unlisted}

```{r}
fac1_tbl |> 
  mutate(ranked_jump_length = rank(jump_length)) |> 
  t_test(ranked_jump_length ~ animal) |> 
  select(group1, group2, statistic, p)
```

### ... mit abhängigen Beobachtungen

::: panel-tabset
## `{stats}`

`wilxoc.test()`

```{r}
wilcox.test(paired_tbl$hungrig, paired_tbl$satt, paired = TRUE,
            conf.int = TRUE)
```

## `{coin}`

`wilcox_test()`

```{r}
wilcoxsign_test(paired_tbl$hungrig ~ paired_tbl$satt, 
                paired = TRUE) 
```

## `{rstatix}`

[Wilcoxon Test in R](https://www.datanovia.com/en/lessons/wilcoxon-test-in-r/)

`wilcox_test()`

```{r}
rstatix::wilcox_test(jump_length ~ trt, data = paired_long_tbl, paired = TRUE) |> 
  select(group1, group2, p)
```

## `{nparcomp}`

`npar.t.test.paired()`

```{r}
npar_obj <- npar.t.test.paired(jump_length ~ trt, data = paired_long_tbl,
                               plot.simci = FALSE)
npar_obj$Analysis
```
:::

#### Parametrische Lösung: Der paired t-Test {.unnumbered .unlisted}

```{r}
paired_long_tbl |> 
  mutate(ranked_jump_length = rank(jump_length)) |> 
  t_test(ranked_jump_length ~ trt, paired = TRUE) |> 
  select(group1, group2, statistic, p)
```

## Ergebnisse mit `{tidyplots}`

Häufig wollen wir nicht nur den p-Wert aus einem U-Test berichten sondern natürlich auch gleich die richtige Abbildung dazu haben. Hier gibt es mit dem R Paket `{tidyplots}` eine gute Möglichkeit. Das R Paket verbindet dabei die Funktionalität von `{ggplot}` und `{ggpubr}`. Dabei bleibt es aber dann sehr einfahc zu bedienen. Insbesondere in dem Fall, dass du nur zwei Gruppen in einem U-Test miteinander vergleichen willst.

::: callout-tip
## Alternativen zu `{tidyplots}`

Das R Paket `{ggpubr}` bietet auch noch andere Alternativen für die Darstellung von statistischen Vergleichen in deinen Daten unter [ggpubr: ‘ggplot2’ Based Publication Ready Plots](https://rpkgs.datanovia.com/ggpubr/). Vielleicht findest du da auch noch eine bessere Abbildung als hier. Da wir hier sehr viel ähnliches haben, bleibe ich bei `{tidyplots}`.
:::

Neben den p-Werten, die ich hier mit der Funktion `add_test_pvalue()` ergänze kannst du auch Sterne mit der Funktion `add_test_asterisks()` nutzen. Das liegt dann ganz bei dir. Es gibt auch die Möglichkeit nicht signifikante Ergebnisse auszublenden. Mehr dazu findest du dann auf der [Hilfeseite zu den statistischen Vergleichen in `{tidyplots}`](https://jbengler.github.io/tidyplots/articles/Visualizing-data.html#statistical-comparison). Ich zeige hier dir nur die Standardanwendung. Wir rechnen hier immer den U-Test aus dem R Paket `{rstatix}`.

::: panel-tabset
## Barplot

Die Standardabbildung ist sicherlich der Barplot zusammen mit der Standardabweichung als Fehlerbalken. Dann habe ich noch die einzelnen Beobachtungen ergänzt. Die Klammer über den beiden Säulen gibt den Vergleich an und die Zahl ist der p-Wert aus einem U-Test. Wir sehen hier, dass sich die beiden Floharten in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-barplot-ttest
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Einfaktorieller Barplot für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem U-Test."

tidyplot(data = fac1_tbl, 
         x = animal, y = jump_length, color = animal) |> 
  add_data_points() |>
  add_mean_bar(alpha = 0.4, width = 0.4) |> 
  add_sd_errorbar(width = 0.2) |> 
  add_test_pvalue(method = "wilcox_test", hide_info = TRUE) |>
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Flohart") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  rename_x_axis_labels(new_names = c("dog" = "Hund", "cat" = "Katze")) |> 
  adjust_size(width = NA, height = NA) 
```

## Boxplot

Es gibt auch gute Gründe ienmal den Boxplot zu wählen, wenn wir etwas besser die Verteilung der Sprungweiten darstellen wollen. Ich habe dann noch die einzelnen Beobachtungen ergänzt. Die Klammer über den beiden Säulen gibt den Vergleich an und die Zahl ist der p-Wert aus einem U-Test. Wir sehen hier, dass sich die beiden Floharten in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-boxplot-ttest
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Einfaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem U-Test."

tidyplot(data = fac1_tbl, 
         x = animal, y = jump_length, color = animal) |> 
  add_data_points() |>
  add_boxplot(alpha = 0.4, box_width = 0.3) |> 
  add_test_pvalue(method = "wilcox_test", hide_info = TRUE) |> 
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Flohart") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  rename_x_axis_labels(new_names = c("dog" = "Hund", "cat" = "Katze")) |> 
  adjust_size(width = NA, height = NA) 
```

## Gepaarter Dotplot

Am Ende wollen wir uns dann nochmal den gepaarten U-Test als Wilcoxon Test anschauen. Hier ist dann die Abbildung realtiv einfach. Wir können da die Daten `paired_tbl` aus dem gepaarten U-Test nutzen nachdem wir die Daten in das Long-Format überführt haben. Etwas schwieriger ist dann der p-Wert, den p-Wert müssen wir dann erst selber errechnen und dann ergänzen. Also fangen wir einmal an die Daten in das Long-Format zu überführen.

```{r}
paired_long_tbl <- paired_tbl |> 
  pivot_longer(cols = satt:hungrig,
               values_to = "jump_length",
               names_to = "trt")
```

Jetzt können wir den gepaarten U-Test rechnen und zwar aus dem R Paket `{rstatix}`. Dann müssen wir noch alles so umbauen, dass wir die Informationen dann in `{tidyplots}` auch nutzen können.

```{r}
stats_tbl <- paired_long_tbl |> 
  arrange(id) |> 
  wilcox_test(jump_length ~ trt, paired = TRUE) |> 
  add_significance() |> 
  add_xy_position()
```

Wir butzen hier die Funktion `stat_pvalue_manual()` um händisch die p-Werte zu den Dotplot mit den Mittelwert und Standardabweichung zu ergänzen. Die Verbindungen zwischen den Beobachtungen haben wir dann durch `add_line()` erzeugt. Ich gebe zu, dass ist etwas komplizierter. Wenn du dann die Sterne haben willst, dann musst due das Label auf `"p.signif"` setzen. Dann werden statt der p-Werte `"p"` dir die Sterne `*` angezeigt. Wir sehen hier, dass sich die beiden Fütterungslevel in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-barplot-ttest-paired
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Dotplot mit Mittelwert und Standardabweichung für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem gepaarten U-Test. Gleiche Messungen an gleichen Flöhen sind mit einer Linie verbunden."

paired_long_tbl |> 
  tidyplot(x = trt, y = jump_length, color = trt, fill = NA) |> 
  add_line(group = id, color = "grey") |> 
  add_data_points() |>
  add_mean_dash(width = 0.2) |> 
  add_sd_errorbar(width = 0.2) |> 
  add(stat_pvalue_manual(stats_tbl, size = 7/.pt, label = "p",
                         bracket.nudge.y = 0.1)) |> 
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Fütterung") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  reorder_x_axis_labels("hungrig", "satt") |>  
  rename_x_axis_labels(new_names = c("satt" = "gefüttert", "hungrig" = "ungefüttert")) |>
  adjust_size(width = NA, height = NA) 
```
:::

## Referenzen {.unnumbered}
