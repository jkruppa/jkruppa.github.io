```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Multinomiale / Ordinale logistische Regression {#sec-multinom-ordinal}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

::: callout-tip
## Einführung in die Multinomiale / Ordinale logistische Regression per Video

Du findest auf YouTube [Multinomiale / Ordinale logistische Regression](https://youtu.be/CQQEXiYASUk) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Was machen wir wenn wir ein Outcome haben mit mehr als zwei Kategorien. Wenn wir nur zwei Kategorien hätten, dann würden wir eine logistische Regression rechnen. Wenn wir mehr als zwei Kategorien haben, dann sind wir in dem Fall der multinomialen / ordinalen logistischen Regression. Wir rechnen eine multinomialen Regression, wenn wir keine Ordnung in den Kategorien in dem Outcome haben. Wenn wir eine Ordnung vorliegen haben, dann nutzen wir die ordinale Regression. Wir werden uns erstmal eine ordinale Regression anschauen mit nur drei geordenten Stufen. Dann schauen wir uns einmal wie wir eine ordinale Regression auf Boniturnoten in der Likert-Skala rechnen. Wir machen das getrennt, denn wir sind bei wenigen geordneten Kategorien meistens noch am Effekt zwischen den Kategorien interessiert. Im Gegensatz wollen wir bei einem Outcome mit Boniturnoten einen Gruppenvergleich rechnen. Dann interessiert uns der Unterschied und die Effekte zwischen den Boniturnoten nicht. Deshalb trennen wir das hier etwas auf.

Im zweiten Teil wollen wir uns dann noch eine multinominale Regression auf ungeordneten Kategorien eines Outcomes anschauen. Korrelterweise tuen wir nur so, als wäre unser vorher geordnetes Outcome dann eben ungeordnet. Das macht dann aber bei deiner Anwendung dann keinen großen Unterschied. Als eine Alternative zur multinationalen Regression stelle ich dann noch die logistsiche Regression vor. Wir können nämlich einfach unsere Daten nach dem Outcome jeweils in kleinere Datensätze mit nur jeweils zwei der Kategorien aufspalten. Das ist zwar nicht schön, aber auch eine Möglichkeit mit einem Problem umzugehen.

Ich gehe hier nicht auf die Theorie hinter der multinomialen / ordinalen logistischen Regression ein. Wenn dich dazu mehr interessiert findest du in den jeweiligen Abschnitten dann noch eine passende Referenz. Da kannst du dann schauen, welche Informationen du noch zusätzlich findest.

## Annahmen an die Daten

[Unser gemessenes Outcome $y$ folgt einer Multinomialverteilung.]{.aside}

Im folgenden Kapitel zu der multinomialen / ordinalen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Daher sieht unser Modell wie folgt aus. Wir haben ein $y$ und $p$-mal $x$. Wobei $p$ für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser $y$ einer Multinomialverteilung. Damit finden wir im Outcome im Falle der multinomialen logistischen linearen Regression *ungeordnete* Kategorien und im Falle der ordinalen logistischen linearen Regression *geordnete* Kategorien.

$$
y \sim x_1 + x_2 + ... + x_p 
$$

Wir können in dem Modell auch Faktoren $f$ haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in @sec-posthoc nochmal nachlesen.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               parameters, performance, gtsummary,
               ordinal, janitor, MASS, nnet, flextable,
               emmeans, multcomp, ordinal, see)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Im Folgenden wollen wir uns die Daten von den infizierten Ferkeln noch einmal anschauen. Wir nehmen als Outcome die Spalte `frailty` und damit die Gebrechlichkeit der Ferkel. Die Spalte ordnen wir einmal nach *robust*, *pre-frail* und *frail*. Wobei *robust* ein gesundes Ferkel beschreibt und *frail* ein gebrechliches Ferkel. Wir bauen uns dann noch einen Fakotr mit ebenfalls der Spalte `frailty` in der wir so tun, als gebe es diese Ordnung nicht. Wir werden dann die ordinale Regression mit dem Outcome `frailty_ord` rechnen und die multinominale Regression dann mit dem Outcome `frailty_fac` durchführen.

```{r}
pig_tbl <- read_excel("data/infected_pigs.xlsx") %>%
  mutate(frailty_ord = ordered(frailty, levels = c("robust", "pre-frail", "frail")),
         frailty_fac = as_factor(frailty)) %>% 
  select(-infected)

```

Schauen wir uns nochmal einen Ausschnitt der Daten in der @tbl-multinom-pigs an.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-multinom-pigs
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.
#| column: page

raw_pig_tbl <- pig_tbl %>% 
  mutate(frailty_ord = as.character(frailty_ord),
         frailty_fac = as.character(frailty_fac))

rbind(head(raw_pig_tbl),
      rep("...", times = ncol(raw_pig_tbl)),
      tail(raw_pig_tbl)) %>% 
  kable(align = "c", "pipe")
```

Das wären dann die Daten, die wir für unsere Modelle dann brauchen. Schauen wir mal was wir jetzt bei der ordinalen Regression herausbekommen.

## Ordinale logistische Regression {#sec-ordinal}

Es gibt sicherlich einiges an Paketen in R um eine ordinale Regression durchzuführen. Ich nutze gerne die Funktion `polr` aus dem R Paket `MASS`. Daneben gibt es auch noch das R Paket `ordinal` mit der Funktion `clm()`, die wir dann noch im Anschluss besprechen werden. Ich nutze jetzt erstmal die Funktion `polr`, da wir hier noch eine externe Referenz haben, die uns noch detailliertere Informationen liefern kann.

::: column-margin
Ich verweise gerne hier auf das tolle Tutorium [Ordinal Logistic Regression \| R Data Analysis Examples](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/). Hier erfährst du noch mehr über die Analyse der ordinalen logistischen Regression.
:::

Wir schon erwähnt sparen wir usn die mathematischen Details und utzen gleich die Funktion `polr` auf unserem Outcome `frailty`. Wir müssen keine Verteilungsfamilie extra angeben, dass haben wir schon mit der Auswahl der Funktion getan. Die Funktion `polr` kann nur eine ordinale Regression rechnen und wird einen Fehler ausgeben, wenn das Outcome $y$ nicht passt.

```{r}
#| message: false
#| warning: false
ologit_fit <- polr(frailty_ord ~ age + sex + location + activity + crp + 
                     bloodpressure + weight + creatinin, 
                   data = pig_tbl)
```

```{r}
#| message: false
#| warning: false
ologit_fit %>% summary()
```

```{r}
#| message: false
#| warning: false
ologit_fit %>% 
  tidy(exponentiate = TRUE, conf.int = TRUE) 
```

```{r}
#| message: false
#| warning: false
coef_df <- summary(ologit_fit) %>% coef
p_n <- pnorm(abs(coef_df[, "t value"]), lower.tail = FALSE) * 2
p_t <- pt(abs(coef_df[, "t value"]), df = 3, lower.tail = FALSE) * 2
```

```{r}
#| message: false
#| warning: false
cbind(coef_df,
      p_n = round(p_n, 3),
      p_t = round(p_t, 3))
```

```{r}
#| message: false
#| warning: false
ologit_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)
```

```{r}
#| message: false
#| warning: false

ologit_fit %>% 
  model_parameters() 
```

@tbl-tbl-regression-ordinal

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-regression-ordinal
#| tbl-cap: "."

ologit_fit %>% 
  tbl_regression(exponentiate = TRUE) %>% 
  as_flex_table()
```

## Cumulative Link Models (CLM) für ordinale Daten

::: column-margin
Wir finden auch ein Tutorial zu [Introduction to Cumulative Link Models (CLM) for Ordinal Data](https://rcompanion.org/handbook/G_01.html)
:::

```{r}
#| message: false
#| warning: false
grade_tbl <- tibble(block = rep(c("A", "B", "C"), each = 3),
  A = c(2,3,4,3,3,2,4,2,1),
                    B = c(7,9,8,9,7,8,9,6,7),
                    C = c(6,5,5,7,5,6,4,7,6),
                    D = c(2,3,1,2,1,1,2,2,1),
                    E = c(4,3,7,5,6,4,5,7,5)) %>%
  gather(key = variety, value = grade, A:E) %>% 
  mutate(grade_ord = ordered(grade))

```

```{r}
grade_tbl$grade
```

```{r}
#| echo: true
#| message: false
#| label: fig-clm-dot
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Dotplot des Datenbeispiels für die Bonitur von fünf Weizensorten."

ggplot(grade_tbl, aes(variety, grade, fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir='center', 
               position=position_dodge(0.6)) +
  scale_y_continuous(breaks = 1:9, limits = c(1,9)) +
  scale_fill_okabeito() 

```

`threshold = "symmetric"`

```{r}
#| message: false
#| warning: false
clm_fit <- clm(grade_ord ~ variety + block, data = grade_tbl,
               threshold = "symmetric")
```

```{r}
#| message: false
#| warning: false
clm_fit %>% model_parameters()
```

```{r}
#| message: false
#| warning: false
anova(clm_fit)
```

```{r}
#| message: false
#| warning: false
clm_fit %>% 
  emmeans(~ variety) %>% 
  cld(Letters = letters) %>% 
  arrange(variety)
```

## Multinomiale logistische Regression {#sec-multinom}

::: column-margin
Ich verweise gerne hier auf das tolle Tutorium [Multinomial Logistic Regression \| R Data Analysis Examples](https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/). Hier erfährst du noch mehr über die Analyse der multinominale logistischen Regression.
:::

```{r}
#| message: false
#| warning: false
pig_tbl <- pig_tbl %>% 
  mutate(frailty_fac = relevel(frailty_fac, ref = "robust"))
```

```{r}
#| message: false
#| warning: false
multinom_fit <- multinom(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, 
                         data = pig_tbl)
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% summary
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% confint %>%  exp
```

```{r}
#| message: false
#| warning: false
z_mat <- summary(multinom_fit)$coefficients/summary(multinom_fit)$standard.errors
p_n <- (1 - pnorm(abs(z_mat), 0, 1)) * 2
p_n
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% model_parameters()
```

@tbl-tbl-regression-multinom

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-regression-multinom
#| tbl-cap: "."

multinom_fit %>% 
  tbl_regression(exponentiate = TRUE) %>% 
  as_flex_table()
```

## Logistische Regression

```{r}
#| message: false
#| warning: false
pig_tbl$frailty %>% tabyl
```

```{r}
#| message: false
#| warning: false
pig_lst <- list(robust_prefrail = filter(pig_tbl, frailty_fac %in% c("robust", "pre-frail")),
                robust_frail = filter(pig_tbl, frailty_fac %in% c("robust", "frail")),
                prefrail_frail = filter(pig_tbl, frailty_fac %in% c("pre-frail", "frail")))
```

```{r}
#| message: false
#| warning: false
pig_lst %>% 
  map(~glm(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, 
           data = .x, family = binomial)) %>% 
  map(model_parameters, exponentiate = TRUE) %>% 
  map(extract, -1, )
```
