```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, openxlsx)
```

# Zeitreihen (eng. *time series*) {#sec-time-series}

*Letzte Änderung am `r format(fs::file_info("time-space-time-series.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Die Vergangenheit ist geschrieben, aber die Zukunft ist noch nicht in Stein gemeißelt." --- Jean-Luc Picard, Star Trek: The Next Generation*

![](images/caution.png){fig-align="center" width="50%"}

In diesem Kapitel wollen wir uns mit Zeitreihen (eng. *time series*) beschäftigen. Was ja auch irgendwie zu erwarten war, denn so heißt ja auch das Kapitel hier. Wir haben ganz einfach auf der $x$-Achse einer potenziellen Visualisierung die Zeit dargestellt. Wir wollen dann auswerten, ob es über den zeitlichen Verlauf einen Trend gibt oder wir ein gutes Modell für den Verlauf der Beobachtungen anpassen können. Es kann auch sein, dass wir zwei zeitliche Verläufe miteinander vergleichen wollen. Dabei haben wir dann aber meistens nicht einen super simplen Verlauf, sondern Spitzen oder Täler in den Daten, so dass wir hier die Daten entsprechend glätten (eng. *to smooth*) müssen.

Wenn du noch mehr lesen willst, dann kann ich dir folgende Literatur empfehlen. @robert2006time liefert eine gute Übersicht über die Anwendung in R, ist aber schon etwas älter. Das Gleiche gilt dann auch für das Buch von @chan2008time und @cowpertwait2009introductory. Dennoch bilden alle drei Bücher die Grundlagen der Analysen von Zeitreihen super ab. Für eine Abschlussarbeit sollten die Quellen also allemal reichen.

Wenn es um Daten geht, dann gibt es natürlich eine Reihe von möglichen Quellen. Wenn es sehr viele Daten seinen sollen, die meistens einen zeitlichen Bezug haben, dann empfehle ich die Webseite [Our World in Data](https://ourworldindata.org/). Dort gibt es so viele zeitliche Verläufe, da eigentlich alles dort als zeitlicher Verlauf dargestellt wird. Schau doch einfach dort mal rein.

::: {.callout-tip collapse="false"}
## Weitere Tutorien für die Analyse von Zeitreihen

Wir immer kann ein Kapitel hier nicht das umfangreiche Analysieren von Zeitreihen abarbeiten. Daher auch wie in anderen Kapiteln schon eine Liste von Literatur und Links, die mich für dieses Kapitel hier inspiriert haben. Nicht alles habe ich genutzt, aber vielleicht ist für dich was dabei, was dir dann mehr konkret hilft als dieses Kapitel.

-   [Welcome to a Little Book of R for Time Series!](https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/)
-   [14 Time Series Analysis](https://rc2e.com/timeseriesanalysis)
-   [Timeseries analysis in R](https://www.r-bloggers.com/2021/04/timeseries-analysis-in-r/)
-   [timetk for R](https://business-science.github.io/timetk/)
-   [Analysing Time Series Data -- Modelling, Forecasting And Data Formatting In R](https://ourcodingclub.github.io/tutorials/time/)
:::

Ich habe mich auch wieder bemüht ein Beispiel für eine Zeitreihe zu finden, die ich als Abbildung einmal zerforschen kann. Damit sich hier nicht so viel verdoppelt, schaue auch einmal gerne in das Kapitel zur Visualisierung von Daten rein, dort sammle ich alle Beispiele zum Zerforschen. Hier also eine Abbildung, bei der es um eine Zeitreihe und der Trächtigkeit von Kühen geht.

::: {.callout-caution collapse="true"}
## Zerforschen: Zeitlicher Verlauf von einem Laborwert zur Trächtigkeit

![](images/caution.png){fig-align="center" width="50%"}

{{< include zerforschen/zerforschen-time-series-cow.qmd >}}
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, janitor, see, readxl,
               lubridate, plotly, conflicted)
conflicts_prefer(dplyr::filter)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Den ersten Datensatz, den wir uns anschauen wollen, ist in einer CSH-Datei abgespeichert, die ich schon in Excel exportiert habe. Eine CSH-Datei ist ein Datenformat aus Adobe Photoshop und eigentlich nichts anders als eine Information über eine Bilddatei. Wir haben aber hier nicht Pixel oder aber ein Foto vorliegen, sondern das Bild wurde schon in einen numerischen Wert pro Bild weiter verarbeitet. Das hier so ausgedachte Experiment war ein Dronenüberflug über eine Wiese und einem Feld in Uelzen. Dabei wurden Fotos gemacht und es sollten verschiedene Grünlandwerte aus den Fotos berechnet werden. Wir haben aber den Überflug nicht an einem einzigen Tag gemacht, sondern gleich an mehreren über das Jahr verteilt. Das ist jetzt auch dann gleich unsere Zeitreihe. Jetzt können wir uns Fragen, ob es einen Unterschied zwischen den Messwerten der beiden Dronenüberflüge gibt. Wir lesen wie immer erstmal die Daten ein.

```{r}
#| message: false
#| warning: false

csh_tbl <- read_excel("data/csh_data.xlsx") %>% 
  clean_names() %>% 
  mutate_if(is.numeric, round, 2)
```

In der @tbl-time-csh siehst du einen Ausschnitt aus den `r nrow(csh_tbl)` Überflügen. Hier wurden die Daten natürlich schon zusammengefasst. Aus jedem Bild wurde dann ein Wert für zum Beispiel `kg_tm_ha` berechnet. Hier interessiert uns aber nicht die Berechnungsart. Wir wollen jetzt gleich mit den Daten weiterarbeiten. Wie immer ist das Beispiel so semi logisch, hier geht es aber auch eher um die Anwendung der Methoden.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-time-csh
#| tbl-cap: "Auszug aus den Daten der CSH-Datei von Dronenüberflügen über eine Wiese und einem Feld in Uelzen. Die Daten sind abgeändert von den Orginaldaten."

rbind(head(csh_tbl, n = 4),
      rep("...", times = ncol(csh_tbl)),
      tail(csh_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Im nächsten Datensatz schauen wir uns einmal die Daten von vier Loggern an. Hier haben wir mehr oder minder einfach jeweils einen Temperaturlogger an den jeweiligen Seiten unseres Folientunnels geworfen und dann nochmal einen Logger einfach so auf das Feld gelegt. In den Folientunneln haben wir dann Salat hochgezogen. Wir betrachten jetzt hier nur das Freiland, sonst wird es einfach zu viel an Daten.

```{r}
#| message: false
#| warning: false

salad_tbl <- read_excel("data/temperatur_salad.xlsx") %>% 
  clean_names() %>% 
  mutate_if(is.numeric, round, 2) %>% 
  select(datum, uhrzeit, matches("freiland"))
```

In der @tbl-time-temp siehst du einmal die `r nrow(salad_tbl)` automatisch erfassten Messungen der Temperatur pro Tag und dann Stunde. Hier müssen wir dann einmal schauen, wie wir die Daten dann sinnvoll zusammenfassen. Es sind wirklich viele Datenpunkte. Aber gut wir schauen uns die Daten erstmal an und entscheiden dann später weiter. Wir sehen aber schon, dass wir die Daten nochmal bearbeiten müssen, denn irgendwas stimmt mit der Uhrzeitspalte und dem Datum nicht. Dazu dann aber gleich mehr im Abschnitt zum Datumsformat.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-time-temp
#| tbl-cap: "Auszug aus den Daten zur auromatischen Erfassung von Klimadaten im Feld für Kopfsalat."

raw_salad_tbl <- salad_tbl %>% 
  mutate_all(as.character)

rbind(head(raw_salad_tbl , n = 4),
      rep("...", times = ncol(raw_salad_tbl)),
      tail(raw_salad_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Am Ende wollen wir uns dann nochmal Daten einer Wetterstation in Hagebüchen an. Auch hier haben wir wieder sehr viele Daten vorliegen und wir müssen uns überlegen, welche der Daten wir nutzen wollen. Aus Gründen der Machbarkeit wähle ich die Spalte `temp_boden_durch` und `solar_mv` aus, die wir uns dann später anschauen wollen. Sonst wird mir das zu groß und unübersichtlich.

```{r}
#| message: false
#| warning: false

station_tbl <- read_excel("data/Wetterstation_Hagebüchen.xlsx") %>% 
  clean_names() %>% 
  select(datum_uhrzeit, temp_boden_durch, solar_mv) %>% 
  mutate_if(is.numeric, round, 2)
```

Auch hier haben wir in der @tbl-time-station gut `r nrow(station_tbl)` einzelne Messungen vorliegen. Das ist dann auch unserer größter Datensatz von Klimadaten. Wir werden die Daten dann aber sehr anschaulich einmal in einer Übersicht darstellen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-time-station
#| tbl-cap: "Auszug aus den Daten zur Wetterstation in Hagebüchen."

raw_station_tbl <- station_tbl %>% 
  mutate_all(as.character)

rbind(head(raw_station_tbl , n = 4),
      rep("...", times = ncol(raw_station_tbl)),
      tail(raw_station_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Damit hätten wir uns eine Reihe von Datensätzen angeschaut. Sicherlich gibt es noch mehr, aber diese Auswahl erlaubt es uns gleich einmal die häufigsten Fragen rund um Zeitreihen einmal anzuschauen. Bitte beachte, dass es natürlich noch andere Formen von Zeitreihen und damit Datensätzen gibt. In dem folgenden Kasten findest du nochmal eine Anregung zu Klimadaten aus deiner Region.

::: callout-tip
## Mehr Wetter- und Klimadaten aus deiner Region!

Du kannst gerne die [entgeltfreien Informationen auf der DWD-Website](https://www.dwd-shop.de/index.php/default/kostenfreie-informationen.html) nutzen um mehr Informationen zu dem Klima und deiner Region zu erhalten. Wir finden dort auf der Seite die [Klimadaten für Deutschland](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html#buehneTop) und natürlich auch die Daten für Münster/Osnabrück. Sie dazu auch [Isoplethendiagramm für Münster & Osnabrück](https://jkruppa.github.io/application/example-analysis-01.html) im *Skript zu beispielhaften Anwendung*. Ich habe mir dort flux die Tageswerte runtergeladen und noch ein wenig den Header der txt-Datei angepasst. Du findest die Datei [`day_values_osnabrueck.txt`](https://github.com/jkruppa/jkruppa.github.io/tree/master/data) wie immer auf meiner GitHub Seite. Du musst dir für andere Orte die Daten nur entsprechend zusammenbauen. Am Ende brauchen wir noch die [Informationen zu den Tages- und Monatswerten](https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html) damit wir auch verstehen, was wir uns da von der DWD runtergeladen haben.
:::

## Das Datumsformat

Wenn wir von Zeitreihen sprechen dann sprechen wir auch von dem Datumsformat. Es ist eigentlich immer einer ewige Qual Daten in das richtige Zeitformat zu kriegen. Deshalb hier vorab einmal die folgende Abbildung, die nochmal die Wirrnisse des Datumsformat gut aufzeigt.

![Quelle: https://xkcd.com/](https://imgs.xkcd.com/comics/iso_8601.png){fig-align="center" width="70%"}

Wichtig ist, dass wir das richtige Datumsformat haben. Siehe dazu auch das Kapitel [Zeit und Datum](#sec-time-date). Das einzig richtige Datumsformat ist und bleibt eben `Jahr-Monat-Tag`. Häufig ist eben dann doch anders, so dass wir uns etwas strecken müssen um unser Format in das richtige Format zu überführen. Bitte beachte aber, dass du auf jeden Fall einheitlich dein Datum einträgst. Am besten auch immer zusammen mit dem Jahr, dass macht vieles einfacher. Wie immer gibt es auch noch das Tutorium zu [Date Formats in R](https://www.r-bloggers.com/2013/08/date-formats-in-r/) und natürlich das R Paket `lubridate` mit dem Einstieg [Do more with dates and times in R](https://lubridate.tidyverse.org/articles/lubridate.html).

Wir werden uns jetzt einmal am Beispiel die Transformation der Datumsformate in den jeweiligen Daten anschauen. Je nach Datensatz müssen wir da mehr oder weniger machen. Auch hier, wenn du weniger Arbeit möchtest, dann achte auf eine einheitliche Form der Datumsangabe.

### Die CSH-Daten

Das Datum in den CSH-Daten leidet unter zwei Besonderheiten. Zum einen fehlt das Jahr und zum anderen die Null vor der Zahl. Wir haben nämlich für den 28. April die Datumsangabe `428` in der Spalte `day`. Das hat zur Folge, dass Excel die Spalte als Zahl erkennt und keine vorangestellten Nullen erlaubt. Wir brauchen aber einen String und den Monat als zweistellig mit `04` für den Monat April. Deshalb nutzen wir die Funktion `str_pad()` um eine `0` an die linke Seite zu kleben, wenn der Wert in der Spalte kleiner als vier Zeichen lang ist. Somit würde der 1. Oktober mit `1001` so bleiben, aber der 1. September mit `901` zu `0901`. Dann nutzen wir die Funktion `as.Date()` um aus unserem Sting dann ein Datum zu machen. Das Format ist hier dann `%m%d` und somit Monat und Tag ohne ein Trennzeichen.

```{r}
csh_tbl <- csh_tbl %>% 
  mutate(day = as.Date(str_pad(day, 4, pad = "0", side = "left"), format = "%m%d"))
```

Und dann erhalten wir auch schon folgenden Datensatz mit dem korrekten Datumsformat mit dem wir dann weiterarbeiten werden.

```{r}
csh_tbl %>% 
  head(4)
```

Wie du siehst, wird dann automatisch das aktuelle Jahr gesetzt. Das heißt, da ich dieses Text hier im Jahr `r year(Sys.Date())` schreibe, erscheint natürlich auch eine `r year(Sys.Date())` vor dem Monat und Tag. Hier musst du dann schauen, ob das Jahr wirklich von Interesse ist oder du es dann später nochmal anpasst. Wir lassen jetzt erstmal alles so stehen. Es ist immer einfacher das Datum dann sauber in Excel zu setzen, als sich dann hier nochmal einen Abzubrechen, denn du bist ja keine Informatiker der eine generelle Lösung sucht sondern hast ja nur einen Datensatz vorliegen. Das wäre jedenfalls mein Tipp um es schneller hinzukriegen.

### Die Salatdaten

```{r}
salad_long_tbl <- salad_tbl %>% 
  mutate(uhrzeit = format(uhrzeit, format = "%H:%M:%S"),
         datum = format(datum, format = "%Y-%m-%d"),
         datum = ymd(datum) + hms(uhrzeit)) %>% 
  select(-uhrzeit) %>% 
  pivot_longer(freiland_messw:last_col(),
               names_sep = "_",
               names_to = c("location", "type"),
               values_to = "temp") 
```

Nochmal zusammenfassn für die Tage?

### Die Wetterstationsdaten

```{r}
station_tbl <- station_tbl %>% 
  mutate(datum_uhrzeit = as_datetime(datum_uhrzeit),
         month = month(datum_uhrzeit),
         day = day(datum_uhrzeit),
         hour = hour(datum_uhrzeit),
         minute = minute(datum_uhrzeit),
         second = second(datum_uhrzeit),
         format_hour = paste(hour, minute, second, sep = ":"))
```

## Visualisierung

### Das R Paket `plotly`

Hilfeseite [Plotly R Open Source Graphing Library](https://plotly.com/r/).

### Die CSH Daten

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-csh-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Eigenwerte für die beiden Datensätze."

csh_tbl %>% 
  ggplot(aes(day, g_tm_plot, color = parzelle)) +
  theme_bw() +
  geom_point() +
  stat_smooth(se = FALSE) +
  scale_color_okabeito() 

```

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-csh-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Eigenwerte für die beiden Datensätze."

p_csh <- csh_tbl %>% 
  ggplot() +
  theme_bw() +
  scale_color_okabeito() +
  stat_smooth(aes(day, g_tm_plot, color = parzelle), se = FALSE, n = 100) # <1>
```

1.  Setze `n = 1000` um wirklich eine gute Abdeckung später für die Berechung der Fläche zu haben.

```{r}
#| message: false
#| echo: true
#| warning: false
p_csh_str <- ggplot_build(p_csh)
```

```{r}
#| message: false
#| echo: true
#| warning: false
ribbon_tbl <- p_csh_str %>% 
  pluck("data", 1) %>% 
  as_tibble() %>% 
  select(x, y, group) %>% 
  mutate(group = factor(group, labels = c("Uelzen", "Wiese"))) %>% 
  split(.$group) %>% 
  bind_cols() %>% 
  clean_names() %>% 
  select(x = x_1, Uelzen = y_2, Wiese = y_5) %>%  # <1>
  mutate(x = as_date(x, origin = lubridate::origin)) # <2>
```

1.  Die `y_2` Werte sind die Werte aus Uelzen und die `y_5` Werte von der Wiese.
2.  Die `x`-Werte sind noch das Datum in numerischer Form aus `ggplot()`. Hier wieder zurück ins `yyyy-mm-dd` Format.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-csh-3
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Eigenwerte für die beiden Datensätze."
#| fig-subcap: 
#|   - "Tierdaten `animals_df`"
#|   - "Kreaturendaten `std_creature_df`"
#| layout-nrow: 1
#| column: page

p_csh + 
  geom_ribbon(data = ribbon_tbl, aes(x = x, ymin = Wiese, ymax = Uelzen),
                    fill = "grey", alpha = 0.4) +
  ylim(10, 120)

p_csh + 
  geom_ribbon(data = ribbon_tbl, aes(x = x, ymin = Wiese, ymax = Uelzen),
                    fill = "grey", alpha = 0.4) +
  geom_point(aes(day, g_tm_plot, color = parzelle)) +
  ylim(10, 120)

```

```{r}
ribbon_tbl %>% 
  mutate(diff = Uelzen - Wiese) %>% 
  pull(diff) %>% 
  sum()
```

Wenn wir oben `n = 1000` in der Funktion `stat_smooth()` gesetzt hätten, dann hätten wir hier fast eine Linie aus Punkten ohne Lücken.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-csh-4
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Eigenwerte für die beiden Datensätze."
ribbon_tbl %>% 
  pivot_longer(cols = Uelzen:Wiese,
               values_to = "g_tm",
               names_to = "parzelle") %>% 
  ggplot(aes(x, g_tm, color = parzelle)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_point()
```

### Salat Daten

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-salad-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Eigenwerte für die beiden Datensätze."
#| fig-subcap: 
#|   - "Tierdaten `animals_df`"
#|   - "Kreaturendaten `std_creature_df`"
#| layout-nrow: 1
#| column: page
p_loc <- salad_long_tbl %>% 
  ggplot(aes(datum, temp, color = type)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_line() +
  facet_wrap(~ location) +
  theme(legend.position = "none")
p_loc

p_type <- salad_long_tbl %>% 
  ggplot(aes(datum, temp, color = location)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_line() +
  facet_wrap(~ type, ncol = 1) +
  theme(legend.position = "none")
p_type
```

ggplot to plotly?

[Getting Started with Plotly in ggplot2](https://plotly.com/ggplot2/getting-started/)

```{r}
ggplotly(p_loc)
```

In der @fig-time_plotly_1 siehst du nochmal den Button *Compare data on hover* in Aktion. Du kannst dann direkt die drei Punkte miteinander vergleichen auch wenn die Punkte in der Abbilundung schlecht auseinanderzu halten sind.

![Abbildung](images/timeseries/plotly_1.png){#fig-time_plotly_1 fig-align="center" width="80%"}

### Die Wetterstationsdaten

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-time-station-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Eigenwerte für die beiden Datensätze."
p <- station_tbl %>% 
  ggplot(aes(datum_uhrzeit, temp_boden_durch)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_line() 
p
```

ggplot to plotly?

[Getting Started with Plotly in ggplot2](https://plotly.com/ggplot2/getting-started/)

```{r}
ggplotly(p)
```

Nachdem wir ordentlich an den Daten geschraubt haben können wir jetzt in @fig-weather-station-hage die drei Konturplots sehen. Wir mussten noch das Spektrum der Farben einmal drehen, damit es auch mit den Temperaturfarben passt und wir haben noch ein paar Hilfslinien miteingezeichnet. Sie dazu auch [Isoplethendiagramm für Münster & Osnabrück](https://jkruppa.github.io/application/example-analysis-01.html) im *Skript zu beispielhaften Anwendung*.

Im Folgenden spiele ich mit den Funktionen `geom_contour_filled()` und `geom_contour()` rum um zum einen die Flächen und dann die Ränder des Isoplethendiagramms zu erhalten. Die Färbung ergibt sich dann aus der Funktion `scale_fill_brewer()`. Da wir hier exakt dreizehn Farben zu Verfügung haben, habe ich dann auch entschieden dreizehn Konturen zu zeichnen. Sonst musst du mehr Farben definieren, damit du auch mehr Flächen einfärben kannst.

Darüber hinaus habe ich mich auch entschieden hier mit einem Template in `ggplot` zu arbeiten, damit ich nciht so viel Code produziere. Ich baue mir im Prinzip einmal einen leeren Plot ohne die Funktion `aes()`. Die Definition was auf die $x$-Achse kommt und was auf die $y$-Achse mache ich dann später.

```{r}
#| message: false
#| echo: true
#| warning: false

p <- ggplot(station_tbl) +
  theme_minimal() +
  geom_contour_filled(bins = 13) +
  scale_fill_brewer(palette = "Spectral", direction = -1) +
  scale_x_continuous(breaks = 1:12) +
  geom_vline(xintercept = 4:9, alpha = 0.9, linetype = 2) +
  geom_hline(yintercept = c(4, 8, 12, 16, 20, 24), 
             alpha = 0.9, linetype = 2) +
  labs(x = "Monat", y = "Stunde", fill = "Temperatur [°C]")

```

Wir können mit dem Operator `%+%` zu einem bestehenden `ggplot` neue Daten hinzufügen. Dann können wir auch wie gewohnt neue Optionen anpassen.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-weather-station-hage
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Konturplot der verschiedenen Temperaturen der Wetterstation in Hagebüchen in den Monaten April bis Mitte September. Die Temperaturen wurden jede Stunde einmal erfasst. Dargestellt sind die Durchschnittstemperaturen."
#| fig-subcap: 
#|   - "Durchschnittstemperaturen der Wetterstation über den Tag."
#|   - "Durchschnittstemperaturen der Wetterstation über den Monat."
#|   - "Solare Leistung über den Tag."
#| layout-nrow: 1
#| column: page

p %+%
  aes(month, hour, z = temp_boden_durch) +
  geom_contour(binwidth = 2, color = "black") +
  scale_y_continuous(limits = c(1, 24), breaks = c(4, 8, 12, 16, 20, 24)) +
  labs(x = "Monat", y = "Stunde", fill = "Temperatur [°C]")

p %+%
  aes(month, day, z = temp_boden_durch) +
  geom_contour(binwidth = 2, color = "black") +
  scale_y_continuous(limits = c(1, 30), breaks = c(5, 10, 15, 10, 25, 30)) +
  labs(x = "Monat", y = "Tag", fill = "Temperatur [°C]")

p %+%
  aes(month, hour, z = solar_mv) +
  scale_y_continuous(limits = c(1, 24), breaks = c(4, 8, 12, 16, 20, 24)) +
  labs(x = "Monat", y = "Stunde", fill = "Solar [MV]")

```

## Modeltime tutorial

```{r}
pacman::p_load(xgboost, tidymodels, modeltime, timetk)

# This toggles plots from plotly (interactive) to ggplot (static)
interactive <- FALSE

# Data
m750 <- m4_monthly %>% filter(id == "M750")

m750 %>%
  plot_time_series(date, value, .interactive = interactive)

splits <- initial_time_split(m750, prop = 0.9)

model_fit_arima_no_boost <- arima_reg() %>%
    set_engine(engine = "auto_arima") %>%
    fit(value ~ date, data = training(splits))

# Model 3: ets ----
model_fit_ets <- exp_smoothing() %>%
    set_engine(engine = "ets") %>%
    fit(value ~ date, data = training(splits))

# Model 5: lm ----
model_fit_lm <- linear_reg() %>%
    set_engine("lm") %>%
    fit(value ~ as.numeric(date) + factor(month(date, label = TRUE), ordered = FALSE),
        data = training(splits))

models_tbl <- modeltime_table(
    model_fit_arima_no_boost,
    model_fit_ets,
    model_fit_lm
)

calibration_tbl <- models_tbl %>%
    modeltime_calibrate(new_data = testing(splits))


calibration_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = m750
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = interactive
    )
```

```{r}
calibration_tbl %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy(
        .interactive = interactive
    )

```

-   MAE - Mean absolute error, mae()
-   MAPE - Mean absolute percentage error, mape()
-   MASE - Mean absolute scaled error, mase()
-   SMAPE - Symmetric mean absolute percentage error, smape()
-   RMSE - Root mean squared error, rmse()
-   RSQ - R-squared, rsq()

```{r}
refit_tbl <- calibration_tbl %>%
    modeltime_refit(data = m750)

refit_tbl %>%
    modeltime_forecast(h = "3 years", actual_data = m750) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = interactive
    )
```

## Referenzen {.unnumbered}
