```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, patchwork, ggimage)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
source("images/R/stat-modeling-R.R")
source("images/R/stat-modeling-basic.R")
set.seed(20250708)
theme_modeling <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(size = 12, face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

# Multiple lineare Regression {#sec-mult-reg-basic}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-basic.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"All models are approximations. Essentially, all models are wrong, but some are useful. However, the approximate nature of the model must always be borne in mind." --- George E. P. Box*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion (seit 07.2025)

Dieses Kapitel wird in den nächsten Wochen geschrieben und ist damit meine aktuelle Großbaustelle. Ich plane zum Beginn des WiSe 2025/26 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

## Allgemeiner Hintergrund

> *"This idea of “holding everything constant” though can be tricky to wrap your head around." --- [Andrew Heiss](https://www.andrewheiss.com/blog/2022/05/20/marginalia/#regression-sliders-switches-and-mixing-boards)*

[Energy expenditure and obesity across the economic spectrum](https://www.pnas.org/doi/10.1073/pnas.2420902122)

![Unterschied zwischen einer kategorialen Variable und einer kontinuierlichen Variable in einem statistischen Modell visualisiert als Schalter und Schieberegler. Übersetzt nach @heiss2022](images/marginal/slider-switch-annotated-trans.png){#fig-utest-intro-01 fig-align="center" width="100%"}

![Kombination verschiedener kategorialer Variablen und kontinuierlichen Variablen in einem statistischen Modell visualisiert als Mischboard. Übersetzt nach @heiss2022](images/marginal/mixer-board-annotated-trans.png){#fig-utest-intro-02 fig-align="center" width="100%"}

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use independent variable because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Jeder nennt in der Statistik sein Y und X wie er möchte. Da ich hier nicht nur von Y und X schreiben will, führe ich eben die Worte ein, die ich nutzen will. Damit sind die Worte dann auch richtig, da der Kontext definiert ist. Andere mögen es dann anders machen. Ich mache es eben dann so. Danke." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Testen. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren. Du kannst dann immer zu dem Kasten zurückgehen, wenn wir mal ein Wort nicht mehr ganz klar ist. Die fetten Begriffe sind die üblichen in den folgenden Kapiteln. Die anderen Worte werden immer mal wieder in der Literatur genutzt.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

## Theoretischer Hintergrund

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 1.5
#| fig-width: 7
#| fig-cap: "Der Zusammenhang von Daten, dem statistischen Modell und dem Fehler. Das Modell versucht durch ein statistisches Modell $f(x)$ den Zusammenhang zwischen den Einflussvariablen dem Messwert zu erklären. Den Anteil des unerklärten Messwert geht in den Fehlerterm. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-model-abstract

p_model_abstract 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der simplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ für die Steigung der Graden für eine Einflussvariable $x_1$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-07

p_simple_model
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der multiplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ bis $\\beta_p$ für die partielle Steigung der Graden für jede Einflussvariable $x_1$ bis $x_p$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-04

p_mult_model 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Statistische Modellschreibweise in R mit dem Messwert auf der linken Seite und den Einflussvariablen auf der rechten Seite der Tilde. Die Platzhalter $Y$ und $X$ werden durch die Spaltennamen im Datensatz ersetzt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-22

p_lhs_rhs_mult_r 
```

Oder konkreter können wir sagen, dass `jump_length` von `animal`, `sex` und `weight` abhängt und wir diesen Zusammenhang modellieren wollen.

$$
jump\_length \sim animal + sex + weight 
$$

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> *Wenn du jetzt denkst 'Hä? Was soll denn mehrdimensional bedeuten?', dann besuche doch einmal die fantastische Seite [Explained Visually \| Ordinary Least Squares Regression](https://setosa.io/ev/ordinary-least-squares-regression/) um selber zu erfahren, was eine multiple lineare Regression macht. Auf der Seite findest du interaktive Abbildungen, die dir das Konzept der linearen Regression sehr anschaulich nachvollziehen lassen.*
:::

::: callout-tip
## Weitere Tutorien für die multiple lineare Regression

Wir immer geht natürlich mehr als ich hier Vorstellen kann. Du findest im Folgenden Tutorien, die mich hier in dem Kapitel inspiriert haben. Ich habe mich ja in diesem Kapitel auf die Durchführbarkeit in R und die allgemeine Verständlichkeit konzentriert. Es geht aber natürlich wie immer auch mathematischer...

-   Wir funktioniert nun so eine lineare Regression und was sind den jetzt eigentlich die Koeffizienten $\beta_0$ und $\beta_1$ eigentlich? Hier gibt es die fantastische Seite [Explained Visually \| Ordinary Least Squares Regression](https://setosa.io/ev/ordinary-least-squares-regression/), die dir nochmal erlaubt selbe mit Punkten in einem Scatterplot zu spielen und zu sehen wie sich dann die Regressionsgleichung ändert.
-   Das Buch [Tidy Modeling with R](https://www.tmwr.org/) gibt nochmal einen tieferen Einblick in das Modellieren in R. Wir immer, es ist ein Vorschlag aber kein Muss.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom,
               see, performance, car, parameters,
               conflicted)
conflicts_prefer(magrittr::set_names)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

#### Modellierung von Flöhen {.unnumbered .unlisted}

![In unseren Daten zu der Modellierung der Flöhe schauen wir auf verschiedene Ernährungsformen sowie Entwicklungsstadien und fragen uns, ob sich die Sprungweiten und andere Messwerte unterscheiden.](images/flea_feeding_stage.png){#fig-flea-yedi fig-align="center" width="60%"}

```{r}
flea_model_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(feeding = as_factor(feeding),
         stage = as_factor(stage),
         bonitur = as.numeric(bonitur),
         infected = as.numeric(infected))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table
#| tbl-cap: "Tabelle der foo."

model_raw_tbl <- read_excel("data/fleas_model_data.xlsx")

rbind(head(model_raw_tbl, n = 3),
      rep("...", times = ncol(model_raw_tbl)),
      tail(model_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

#### Theoretischer Datensatz {.unnumbered .unlisted}

![In unseren theoretischen Datensatz schauen wir uns die Körperlängen von verschiedenen Schlangen mit unterschiedlichen Einflussvariablen an. Wir schauen uns die Körperfarbe sowie die Regionen der Messung an.](images/snakes_region.png){#fig-flea-yedi fig-align="center" width="100%"}

Abschließend kommen wir noch zu einem theoretischen Datensatz dem ich @kery2010introduction entlehnt habe. Ich möchte nochmal zeigen, wie R intern mit der Modellmatrix die Berechnungen durchführt. Das hat mich interessiert und deshalb habe ich es einmal für mein Verständnis aufgeschrieben. Wenn es dich auch interessiert, dann kannst du in den entsprechenden Tabs weiter unten einmal nachschauen. Hier also erstmal ein sehr simpler theoretischer Datensatz zu Körperlängen von Schlangen. Wir müssen hier dann noch die Faktoren einmal umwandeln, damit wir auch später die Modellmatrix sauber vorliegen haben. Deshalb hier die explizite Benennung der Level in der Funktion `factor()`.

```{r}
#| message: false
snake_tbl <- read_xlsx("data/regression_data.xlsx", sheet = "theory_mult") |> 
  mutate(region = factor(region, levels = c("west", "nord")),
         color = factor(color, levels = c("schwarz", "rot", "blau")))
```

In der folgenden Tabelle ist der Datensatz `snake_tbl` nochmal dargestellt. Wir haben die Schlangenlänge `svl` als Messwert $y$ sowie das Gewicht der Schlangen `mass` als kontinuierliche Einflussvariable sowie den Durchmesser der Schlange $diameter$, die Sammelregion `region` und die Farbe der Schlangen `color` und als kategoriale Einflussvariablen mit unterschiedlichen Anzahlen an Gruppen. Die Region `region` ist also ein Faktor mit zwei Leveln und die Schlangenfarbe `color` ein Faktor mit drei Leveln. Ich nutze den Datensatz also einmal als einen Spieldatensatz um die Modellierung theoretisch besser nachvollziehen zu können.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz zu den Körperlängen als Messwert von acht Schlangen mit verschiedenen Einflussvariablen. Die Einflussvariablen haben verschiedene Eigenschaften und müssen daher unterschiedliche modelliert werden."
#| label: tbl-snakes

snake_tbl |> 
  kable(align = "c", "pipe")
```

## Kausales Modell

### Mehrkovariates Modell

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-12

p_2cov_model
```

::: panel-tabset
## Praktisch in R

```{r}
cov2_fit <- lm(jump_length ~ weight + count_leg, data = flea_model_tbl) 
```

```{r}
cov2_fit |> 
  coef() |> round(2)
```

Einmal die Ausgabe

```{r}
#| eval: true
cov2_fit |> summary()
```

Einmal die annotierte Ausgabe der Zusammenfassung

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "Annotierte Ausgabe der Funktion `summary()` aus einer linearen Modellanpassung mit der Funktion `lm()`. Die Ausgabe der Funktion teilt sich grob in drei informative Bereiche: Informationen zu den Residuen, Informationen zu den Koeffizienten und Informationen zu der Modelgüte. *[Zum Vergrößern anklicken]*"
#| label: fig-model-c2-summary

p_lm_summary_cov2_explained
```

## Theoretisch

```{r}
cov2_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   c_2 = rnorm(10, 0, 1),
                   y = 2 + 
                       1 * c_1 + 
                       2 * c_2 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2, cov2_tbl) |> 
  coef() |> round(2)
```

## Theoretisch in R
:::

### Mehrfaktorielles Modell

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln und deren Interaktion $f_A \\times f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-13

p_2fac_model  +
  labs(title = "") 
```

::: panel-tabset
## Praktisch in R

```{r}
fac2_fit <- lm(jump_length ~ feeding + stage + stage:feeding, data = flea_model_tbl) 
```

```{r}
fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
fac2_fit |> summary()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "Annotierte Ausgabe der Funktion `summary()` aus einer linearen Modellanpassung mit der Funktion `lm()`. Die Ausgabe der Funktion teilt sich grob in drei informative Bereiche: Informationen zu den Residuen, Informationen zu den Koeffizienten und Informationen zu der Modelgüte. Die Erklärung der Schätzer (eng. *estimate*) kann in der folgenden Tabelle nachvollzogen werden. *[Zum Vergrößern anklicken]*"
#| label: fig-model-f2-summary

p_lm_summary_fac2_explained
```

text

text

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac2
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = rep(c("sugar", "blood", "ketchup"), each = 2),
       "$f_{stage}$" = rep(c("adult", "juvenile"), 3),
       "$\\bar{Y}$" = c(78.9, 61.03, 99.71, 116.03, 92.15, 111.24), 
       "$\\boldsymbol{\\beta_{0}}$" = 78.98,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, NA, 20.73, 20.73, NA, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, NA, NA, 13.17, 13.17),
       "$\\boldsymbol{\\beta_{juvenile}}$" = c(NA, -17.94, NA, -17.94, NA, -17.94),
       "$\\boldsymbol{\\beta_{blood \\times juvenile}}$" = c(NA, NA, NA, 34.26, NA, NA),
       "$\\boldsymbol{\\beta_{ketchup \\times juvenile}}$" = c(NA, NA, NA, NA, NA, 37.03)) |> 
  kable(align = "c", "pipe")
```

text

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe.  *[Zum Vergrößern anklicken]*"
#| label: fig-model-basis-fac2

ggplot(flea_model_tbl, aes(feeding, jump_length, color = stage)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 78.98, linewidth = 0.5, color = "#CC79A7") +
  geom_point(position = position_dodge(0.2)) +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y.., 2)), 
               position = position_nudge(c(-0.3, 0.3, -0.3, 0.3, -0.3, 0.3)),
               show.legend = FALSE) +
  scale_x_discrete(labels = c("Zuckerwasser", "Blut", "Ketchup")) +
  labs(title = "Zweifaktorielles Modell mit Interaktion",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der\nBehandlung Zuckerwasser bei den adulten Flöhen",
       x = "Fütterungsart", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top")
```

## Theoretisch

```{r}
fac2_tbl <- tibble(f_a = rep(gl(3, 5), 2),
                   f_b = gl(2, 15),
                   y = 2 + 
                       2 * as.numeric(f_a) + 
                       3 * as.numeric(f_b) + 
                           rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + f_b + f_a:f_b, fac2_tbl) |> 
  coef() |> round(2)
```

## Theoretisch in R
:::

### Kombinierte Modelle

Wenn wir eine Kovariate mit einem Faktor kombinieren, dann kippen wir den Intercept der Graden um die Steigung der Kovariate. Die Level der Faktoren liegen dann auf den Mittelwerten der Kovariaten für das entsprechende Level des Fakotrs. Wenn wir dann noch eine Interaktion hinzunehmen, dann erlauben wir jedem Level des Faktors eine eigene Steigung der Kovariaten.

#### $f_A + c_1$ {.unnumbered .unlisted}

Hier rechnen wir eigentlich eine klassische [einfaktorielle ANCOVA](#sec-ancova) (eng. *analysis of covariance*)

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-14

p_fa_c1_model
```

::: panel-tabset
## Praktisch in R

#### Ohne Interaktion {.unnumbered .unlisted}

```{r}
cov1_fac1_fit <- lm(jump_length ~ feeding + K, data = flea_model_tbl) 
```

```{r}
cov1_fac1_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov1_fac1_fit |> summary()
```

```{r}
flea_model_tbl |> 
  group_by(feeding) |> 
  summarise(mean(jump_length),
            mean(K))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac1-cov1
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = c("sugar", "blood", "ketchup"),
       "$\\bar{c}_{K}$" = c(33.69, 29.47, 25.06), 
       "$\\bar{Y}$" = c(70.01, 107.87, 101.69), 
       "$\\boldsymbol{\\beta_{0}}$" = 58.48,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, 39.31, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, 34.64),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{K}}$" = c("$11.45 = 33.69 \\cdot 0.34$",
                                             "$10.02 = 29.47 \\cdot 0.34$",
                                             "$8.52 = 25.06 \\cdot 0.34$")) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6.5
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe. *[Zum Vergrößern anklicken]*"
#| label: fig-model-basic-cov1-fac1-01

ggplot(flea_model_tbl, aes(K, jump_length, color = feeding)) +
  theme_modeling() +
  geom_vline(xintercept = 33.69, linewidth = 0.5, color = "#E69F00") +
  geom_vline(xintercept = 29.46, linewidth = 0.5, color = "#56B4E9") +
  geom_vline(xintercept = 25.05, linewidth = 0.5, color = "#009E73") +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 58.48, linewidth = 0.5, color = "#CC79A7", linetype = 11) +
  geom_point(position = position_dodge(0.2)) +
  geom_function(fun = \(x) 58.48 + 0.342 * x, color = "#CC79A7") +
  xlim(c(0, NA)) + ylim(c(40, 150)) +
  annotate("point", x = c(25.05, 29.46, 33.69), y = c(70.0, 107.8, 101.7), 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 1, size = 2, shape = 23) +
  annotate("label", x = c(25.05, 29.46, 33.69)+c(2,3,3), y = c(70.0, 107.8, 101.7)+5, 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 0.5, size = 3) +
  labs(title = "Modell mit Kovariate und Faktor",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der Behandlung Zuckerwasser.\nDer Intercept ist um die Steigung der Kovariate gekippt",
       x = "Gewicht in [mg]", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top") +
  geom_segment(aes(x = 40, xend = 40, y = 58.48, yend = 58.48 + 40 * 0.3420),
               color = "#CC79A7") +
  annotate("text", hjust = "left", x = 41, y = 58.48 + (40 * 0.3420)/2,
           label = expression(beta[K]*"="~40%.%0.34)) +
  scale_x_continuous(breaks = c(10, 20, 25.05, 29.46, 33.69, 40, 50),
                     guide = guide_axis(n.dodge = 2))
```

#### Mit Interaktion {.unnumbered .unlisted}

```{r}
cov1_fac1_fit <- lm(jump_length ~ feeding + K + feeding:K, data = flea_model_tbl) 
```

```{r}
#| eval: true
cov1_fac1_fit |> summary()
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-table-fac1-cov1-inter
#| tbl-cap: "Zusammensetzung der Mittelwerte der Sprungweiten $\\bar{Y}$ für jede Faktorkombination aus der Ernährungsart und dem Entwicklungsstand aus den Koeffizienten des zweifaktoriellen Modells."
options(knitr.kable.NA = '')

tibble("$f_{feeding}$" = c("sugar", "blood", "ketchup"),
       "$\\bar{c}_{K}$" = c(33.69, 29.47, 25.06), 
       "$\\bar{Y}$" = c(70.01, 107.87, 101.69), 
       "$\\boldsymbol{\\beta_{0}}$" = 44.13,
       "$\\boldsymbol{\\beta_{blood}}$" = c(NA, 44.59, NA),
       "$\\boldsymbol{\\beta_{ketchup}}$" = c(NA, NA, 81.63),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{K}}$" = c("$25.94 = 33.69 \\cdot 0.77$",
                                             "$22.69 = 29.47 \\cdot 0.77$",
                                             "$19.29 = 25.06 \\cdot 0.77$"),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{blood\\times K}}$" = c(NA,
                                                          "$-3.54 = 29.47 \\cdot -0.12$",
                                                          NA),
       "$\\boldsymbol{\\bar{c}_{K}\\cdot\\beta_{ketchup\\times K}}$" = c(NA, NA,
                                                          "$-43.35 = 25.06 \\cdot -1.73$"),
       ) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6.5
#| fig-cap: "Scatterplot der Sprungweiten der Hunde-,  Katzen- und Fuchsflöhe. foo. *[Zum Vergrößern anklicken]*"
#| label: fig-model-basic-cov1-fac1-02

ggplot(flea_model_tbl, aes(K, jump_length, color = feeding)) +
  theme_modeling() +
  geom_vline(xintercept = 33.69, linewidth = 0.5, color = "#E69F00") +
  geom_vline(xintercept = 29.46, linewidth = 0.5, color = "#56B4E9") +
  geom_vline(xintercept = 25.05, linewidth = 0.5, color = "#009E73") +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 44.1255, linewidth = 0.5, color = "#CC79A7", linetype = 11) +
  geom_point(position = position_dodge(0.2)) +
  geom_function(fun = \(x) 44.1255 + 0.7681 * x, color = "#CC79A7") +
  xlim(c(0, NA)) + ylim(c(40, 150)) +
  annotate("point", x = c(25.05, 29.46, 33.69), y = c(70.0, 107.8, 101.7), 
           label = c(70.0, 107.8, 101.7), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 1, size = 2, shape = 23) +
  annotate("label", x = c(25.05, 29.46, 33.69)+c(2,3,3), y = c(70.0, 107.8, 101.7)+5, 
           label = c(70.01, 107.87, 101.69), fill = c("#009E73", "#56B4E9", "#E69F00"),
           alpha = 0.5, size = 3) +
  labs(title = "Modell mit Kovariate und Faktor sowie Interaktion",
       subtitle = "Intercept ist der Mittelwert der Sprungweiten der Behandlung Zuckerwasser.\nDer Intercept ist um die Steigung der Kovariate gekippt",
       x = "Fütterungsart", y = "Sprungweite in [cm]", color = "Entwicklungsstand") +
  scale_color_okabeito() +
  theme(legend.position = "top") +
  geom_segment(aes(x = 40, xend = 40, y = 44.1255, yend = 44.1255 + 40 * 0.7681),
               color = "#CC79A7") +
  annotate("text", hjust = "left", x = 41, y = 44.1255 + (40 * 0.7681)/2,
           label = expression(beta[K]*"="~40%.%0.77)) +
  scale_x_continuous(breaks = c(10, 20, 25.05, 29.46, 33.69, 40, 50),
                     guide = guide_axis(n.dodge = 2))
```

## Theoretisch

```{r}
cov1_fac1_tbl <- tibble(c_1 = rnorm(15, 0, 1),
                        f_a = gl(3, 5),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + c_1, cov1_fac1_tbl) |> 
  coef() |> round(2)
```

## Theoretisch in R
:::

#### $c_1 + f_A + f_B$ {.unnumbered .unlisted}

Hier rechnen wir eigentlich eine klassische [zweifaktorielle ANCOVA](#sec-ancova) (eng. *analysis of covariance*)

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-16

p_c1_fa_2lvl_fb_3lvl_model
```

::: panel-tabset
## Praktisch in R

```{r}
cov1_fac2_fit <- lm(jump_length ~ weight + feeding + stage, data = flea_model_tbl) 
```

```{r}
cov1_fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov1_fac2_fit |> summary()
```

## Theoretisch

```{r}
cov1_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + f_a + f_b, cov1_fac2_tbl) |> 
  coef() |> round(2)
```

## Theoretisch in R

Im letzten Schritt wollen wir uns einmal das volle Modell anschauen. Wir bauen uns ein Modell mit allen Variablen in dem Datensatz `snake_tbl`. Die Funktion `model.matrix()` gibt uns die Modelmatrix wieder.

```{r}
model.matrix(svl ~ mass + region + color, data = snake_tbl) |> as_tibble() 
```

In der ersten Spalte ist der Intercept angegeben, danach folgt dann die Spalte `mass` als kontenuierliche Variable. In der Spalte `regionnord` steht die Dummykodierung für die Variable `region`. Die ersten drei Schlangen kommen nicht aus der Region `nord` und werden deshalb mit einen Wert von 0 versehen. Die nächsten vier Schlangen kommen aus der Region `nord` und erhalten daher eine 1 in der Spalte. Die nächsten beiden Spalten sind etwas komplizierter. Die Spalten `colorrot` und `colorblau` geben jeweils an, ob die Schlange das Level `rot` hat oder `blau` oder keins von beiden. Wenn die Schlange weder rot noch blau ist, dann sind beide Spalten mit einer 0 versehen. Dann ist die Schlange schwarz.

Wir können die Modellmatrix auch mathematisch schreiben und die $y$ Spalte für das Outcome `svl` ergänzen. Eben so ergänzen wir die $\beta$-Werte als mögliche Koeefizienten aus der linearen Regression sowie die Residuen als Abweichung von der gefitteten Gerade.

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 6 & 0 & 0 & 0 \\
  1 & 8 & 0 & 0 & 0\\
  1 & 5 & 0 & 1 & 0\\
  1 & 7 & 1 & 1 & 0\\
  1 & 9 & 1 & 1 & 0\\
  1 & 11& 1 & 0 & 1\\
  1 & 12& 1 & 0 & 1\\
  1 & 10& 1 & 0 & 1\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} \\
  \beta^{region}_{nord} \\
  \beta^{color}_{rot} \\
  \beta^{color}_{blau} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
$$

Jetzt brauche wir die Koeffizienten aus dem linearen Modell, welches wir wie folgt fitten. Wir nutzen dann die Funktion `coef()` um uns die Koeffizienten wiedergeben zu lassen.

```{r}
fit_4 <- lm(svl ~ mass + region + color, data = snake_tbl) 
fit_4 |> coef() |> round(2)
```

Die Funktion `residuals()` gibt uns die Residuen der Geraden aus dem Objekt `fit_4` wieder.

```{r}
fit_4 |> residuals() |> round(2)
```

Wir können jetzt die Koeffizienten ergänzen mit $\beta_0 = 25$ für den Intercept. Weiter ergänzen wir die Koeffizienten für `mass` mit $\beta_{mass}=2.5$, für Region und das Level `nord` mit $\beta^{region}_{nord} = 5$, für die Farbe und das Level `rot` mit $\beta^{color}_{rot} = 1.5$ und für die Farbe und das Level `blau` mit $\beta^{color}_{blau} = -2.83$. Ebenfalls setzen wir Werte für die Residuen für jede der Beobachtungen in die Gleichung ein.

$$
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  25 & \phantom{0}6 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83 \\
  25 & \phantom{0}8 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}5 \cdot 2.5 & 0 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}7 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}9 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & 11\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 12\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 10\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
 \end{pmatrix} +
  \begin{pmatrix}
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  +2.00 \\
  -2.00 \\
  +2.33 \\
  +0.83 \\
  -3.17 \\
 \end{pmatrix}
$$

Wir können jetzt diese gewaltige Sammlung an Matrixen einmal auflösen. Steht denn nun wirklich rechts das Gleiche wie links von der Gleichung? Wir bauen uns die Zahlen von der rechten Seite der Gleichung einmal in R nach und schauen auf das Ergebnis.

```{r}
c(25 +  6*2.5 + 0*5 + 0*1.5 + 0*-2.83 + 0.00,
  25 +  8*2.5 + 0*5 + 0*1.5 + 0*-2.83 + 0.00,
  25 +  5*2.5 + 0*5 + 1*1.5 + 0*-2.83 + 0.00,
  25 +  7*2.5 + 1*5 + 1*1.5 + 0*-2.83 + 2.00,
  25 +  9*2.5 + 1*5 + 1*1.5 + 0*-2.83 - 2.00,
  25 + 11*2.5 + 1*5 + 0*1.5 + 1*-2.83 + 2.33,
  25 + 12*2.5 + 1*5 + 0*1.5 + 1*-2.83 + 0.83,
  25 + 10*2.5 + 1*5 + 0*1.5 + 1*-2.83 - 3.17) 
```

Die Zahlen, die wir rauskriegen, sind die gleichen Werte die unser Outcome $y$ hat. Was haben wir gelernt?

-   In einem Modell gibt es immer ein Faktorlevel weniger als ein Faktor Level hat. Die Information des *alphanumerisch* ersten Levels steckt dann mit in dem Intercept.
-   In einem Modell geht eine kontinuierliche Variable als eine Spalte mit ein.
-   In einem Modell gibt es immer nur eine Spalte für die Residuen und damit nur eine Residue für jede Beobachtung, egal wie viele Variablen ein Modell hat.
:::

#### $c_1 + c_2 + f_A + f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-21

p_c2_fa_2lvl_fb_3lvl_model 
```

::: panel-tabset
## Praktisch in R

```{r}
cov2_fac2_fit <- lm(jump_length ~ weight + count_leg + feeding + stage, data = flea_model_tbl) 
```

```{r}
cov2_fac2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov2_fac2_fit |> summary()
```

## Theoretisch

```{r}
cov2_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        c_2 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            -1 * c_2 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2 + f_a + f_b, cov2_fac2_tbl) |> 
  coef() |> round(2)
```

## Theoretisch in R
:::

## Prädiktives Modell

## Weiteres von Interesse

### Die Einheit

![foo](images/flea_yedi.png){#fig-flea-yedi fig-align="center" width="60%"}

Manche Flöhe haben hohe Werte der [Midi-Chlorianer](https://www.jedipedia.net/wiki/Midi-Chlorianer) oder einfach M-Werte. Damit sind diese Flöhe insbesondere sensitiv für die Macht und somit auch in etwa Jediflöhe.

```{r}
lm(jump_length ~ M, data = flea_model_tbl) |> 
  summary()
```

### Korrelation

```{r}
cov2_fit <- lm(jump_length ~ count_leg + count_leg_left + count_leg_right, data = flea_model_tbl) 
```

```{r}
cov2_fit |> 
  coef() |> round(2)
```

```{r}
 1.37 -1.15 -0.12 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der Sprungweite in [cm] und dem Gewicht in [mg] von sieben Hundeflöhen. Die lineare Grade und die Gradengleichung wurden ergänzt. *[Zum Vergrößern anklicken]*"
#| label: fig-mult-count-leg

ggplot(flea_model_tbl, aes(x = count_leg, y = jump_length)) +
  geom_point() +
  geom_point(aes(x = count_leg_left), color = "red") +
  geom_point(aes(x = count_leg_right), color = "blue") 
  

```

```{r}
#| eval: true
cov2_fit |> summary()
```

```{r}
cov2_fit <- lm(jump_length ~ count_leg, data = flea_model_tbl) 
```

```{r}
cov2_fit |> 
  coef() |> round(2)
```

```{r}
#| eval: true
cov2_fit |> summary()
```

### Adjustierung für Confounder {#sec-confounder}

Im folgenden Abschnitt wollen wir einmal auf Confounder eingehen. Was sind Confounder? Zum einen gibt es kein gutes deutsches Wort für Confounder. Du könntest Confounder in etwa mit *Verzerrer* oder *Störfakor* übersetzen. Zum Anderen können Confounder nur zuammen mit anderen Vriabln in einer multiplen Regression auftreten. Das heißt, wir brauchen mindestens zwei Variablen in einer Regression. Ein Confounder verursacht einen Effekt, den wir eigentlich nicht so erwartet hätten. Wir wollen eigentlich einen Effekt schätzen, aber der Effekt ist viel größer oder kleiner, da der Effekt eigentlich von einder anderen Variable verursacht oder aber verdeckt wird. Wir können einen Confounder in beide Richtungen haben. Wichtig ist hierbei, das wir eigentlich *nicht* an dem Effekt des Confounders interessiert sind. Wir wollen uns zum Beispiel den Effekt einer Düngung auf das Trockengewicht anschauen, aber der Effekt den wir beobachten wird durch die unterschiedlichen Pflanzorte verursacht.

Schauen wir uns das ganze mal für das Beispiel des Zusammenhangs von dem Flohgewicht mit der Sprungweite an. Dafür benötigen wir den Datensatz `flea_dog_cat_length_weight.csv`.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") |>
  select(animal, sex, weight, jump_length) |> 
  mutate(animal = as_factor(animal),
         sex = as_factor(sex))
```

In der @tbl-model-confounder ist der Datensatz `model_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Datensatz für die Confounder Adjustierung. Die Variable `jump_length` ist das $y$ und die Variable `weight` das $x$ von Interesse.
#| label: tbl-model-confounder

model_raw_tbl <- model_tbl |> 
  mutate(animal = as.character(animal),
         sex = as.character(sex))
rbind(head(model_raw_tbl),
      rep("...", times = ncol(model_raw_tbl)),
      tail(model_raw_tbl)) |> 
  kable(align = "c", "pipe")

```

Wir können uns jetzt drei verschiedene Modelle anschauen.

1)  Das Modell `jump_length ~ weight`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe *über alle* anderen Variablen hinweg.
2)  Das Modell `jump_length ~ weight + animal`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe und berücksichtigen die Tierart des Flohes. Ignorieren aber das Geschlecht des Flohes.
3)  Das Modell `jump_length ~ weight + animal + sex`. Wir modellieren die Abhängigkeit von der Sprungweite von dem Gewicht der Flöhe und berücksichtigen *alle* Variablen, die wir gemessen haben.

Hierbei ist wichtig, dass es natürlich auch Confounder geben kann, die wir gar nicht in den Daten erhoben haben. Also, dass sich Gruppen finden lassen, die wir gar nicht als Variable mit in den Daten erfasst haben. Hier könnte eine Hauptkomponentenanalyse helfen.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| label: fig-stat-modeling-mult-01
#| fig-cap: "Darstellung des *counfounder* Effekts anhand des Zusammenhangs der Sprungweite in [cm] und dem Gewicht von Flöhen [mg]."
#| fig-subcap: 
#|   - "jump_length ~ weight"
#|   - "jump_length ~ weight + animal"
#|   - "jump_length ~ weight + animal + sex"
#| layout-nrow: 1


ggplot(model_tbl, aes(x = weight, y = jump_length)) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  geom_point() 

ggplot(model_tbl, aes(x = weight, y = jump_length, color = animal)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_minimal() +
  geom_point() +
  labs(color  = "Tierart")

ggplot(model_tbl, aes(x = weight, y = jump_length, color = animal, shape = sex)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_minimal() +
  geom_point() +
  labs(color  = "Tierart", shape = "Geschlecht")

```

In @fig-stat-modeling-mult-01-1 sehen wir die blaue Linie als die Ausgabe von dem Modell `jump_length ~ weight`. Wir sehen, dass mit dem Anstieg des Gewichtes der Flöhe auch die Sprungweite sich erhöht. Wir würden annehmen, dass wir hier einen signifikanten Unterschied vorliegen haben. Schauen wir uns die Koeffizienten des Modells aus dem `lm()` einmal an.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight, data = model_tbl) |> 
  model_parameters()
```

Wir sehen, dass wir einen Effekt des Gewichts auf die Sprungweite von $1.34$ vorliegen haben. Auch ist der Effekt und damit die Steigung signifikant.

Erweitern wir nun das Modell um die Tierart und erhalten die @fig-stat-modeling-mult-01-2. Zum einen sehen wir, dass der globale Effekt nicht so ganz stimmen kann. Die Tierarten haben alle einen unterschiedlichen starken Effekt von dem Gewicht auf die Sprungweite. Auch hier fitten wir einmal das lineare Modell und schauen uns die Koeffizienten an.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight + animal, data = model_tbl) |> 
  model_parameters()
```

Der Effekt des Gewichtes ist hier in etwa gleich geblieben. Wir sehen aber auch, dass die Sprungweite anscheinend bei Hunden und Füchsen höher ist. Daher haben wir hier einen Effekt on der Tierart. Wir adjustieren für den Confoundereffekt durch die Tierart und erhalten einen besseren Effektschätzer für das Gewicht.

In der letzten @fig-stat-modeling-mult-01-3 wollen wir nochmal das Geschlecht der Flöhe mit in das Modell nehmen. Wir sehen, dass in diesem Fall, das Gewicht gar keinen Einfluss mehr auf die Sprungweite hat. Den Effekt des Gewichtes war nur der Effekt des unterschiedlichen Gewichtes der weiblichen und männlichen Flöhe. Schauen wir auch hier nochmal in des Modell.

```{r}
#| message: false
#| warning: false

lm(jump_length ~ weight + animal + sex, data = model_tbl) |> 
  model_parameters() |> 
  mutate(Coefficient = round(Coefficient, 2))
```

Nun können wir sehen, dass von unserem ursprünglichen Effekt von dem Gewicht auf die Sprungweite nichts mehr übrigbleibt. Wir haben gar keinen Effekt von dem Gewicht auf die Sprungweite vorliegen. Was wir gesehen haben, war der Effekt des Gewichtes der unterschiedlichen Geschlechter. Wenn wir unser Modell für die Confounder `animal` und `sex` adjustieren, haben wir einen unverzerrten Schätzer für `weight`. Wichtig ist nochmal, dafür müssen wir natürlich auch alle variablen erhoben haben. Hätten wir das Geschlecht der Flöhe nicht bestimt, hätten wir hier eventuell einen falschen Schluß getroffen.

### Variance inflation factor (VIF) {#sec-vif}

Wenn wir sehr viele Daten erheben, dann kann es sein, dass die Variablen stark miteinander korrelieren. Wir können aber stark mieinander korrelierte Variablen nicht zusammen in ein Modell nehmen. Die Effekte der beiden Variablen würden sich gegenseitig aufheben. Wir hätten eigentlich zwei getrennt signifikante Variablen. Nehmen wir aber beide Variablen mit ins Modell, sind beide Variablen nicht mehr signifikant.

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Wir kürzen hier stark ab. Wenn du mehr über Variablen in einem Modell wissen willst, gibt es dann in den Kapitel zur Variablen Selektion mehr Informationen. Wenn du nur Outcomes und Blöcke vorliegen hast, dann ist das VIF für dich uninteressant.
:::

Um Variablen zu finden, die sich sehr ähnlich verhalten, können wir den Variance inflation factor (VIF) nutzen. Wir können den VIF jedoch *nicht* für kategoriale Daten verwenden. Statistisch gesehen würde es keinen Sinn machen. Die Anwendung ist recht einfach. Wir fitten als erstes unser Modell und dann können wir die Funktion `vif()` aus dem R Paket `{car}` verwenden.

```{r}
gummi_tbl <- read_excel("data/gummibears.xlsx")
model <- lm(height ~ semester + age + count_color + count_bears, data = gummi_tbl)
```

Wir sehen im Folgenden das Eregbnis der Funktion `vif()`. Wenn der berechnete Wert für den VIF größer als 5 ist, dann liegt mit der Variable *ein Problem* vor. Wir vermuten dann, dass eine andere variable sehr stark mit dieser Variable korreliert. Wir sehen an den Werten keine Aufälligkeiten.

```{r}
vif(model)
```

Wir können uns mit der Funcktion `check_model()` aus dem R Paket `{performance}` auch die Unsicherheit mit angeben lassen. In unserem Beispiel hieft dies gerade nicht sehr viel weiter. Wir bleiben bei den geschätzen Werten und ignorieren das Intervall.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Graphische Darstellung des VIF mit der Funktion `check_model()`.
#| label: fig-stat-modeling-vif

check_model(model, check = "vif")
```

In @fig-stat-modeling-vif sehen wir nochmal die Visualisierung. Wie immer, manchmal helfen solche Abbildungen, manchmal verwirren die Abbildungen mehr. Wir konzentrieren uns hier auf die Werte des VIF's und ignorieren die Streuung.

### Vergleich von Modellen {#sec-model-basic-compare}

Im Folgenden wollen wir einmal verschiedene Modelle miteinander Vergleichen und uns statistisch wiedergeben lassen, was das beste Modell ist. Und hier holen wir auch einmal kurz Luft, denn wir entschieden *nur* was das statistisch beste Modell ist. Es kann sein, dass ein Modell biologisch mehr Sinn macht und nicht auf Platz 1 der statistischen Maßzahlen steht. Das ist vollkommen in Ordnung. Du musst abweägen, was für sich das beste Modell ist. Im Zweifel komme ruhig nochmal in meine statistische Beratung oder schreibe mir eine Mail.

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Wir kürzen hier stark ab bzw. gehen nicht im Detail auf jedes Gütekriterium ein. Wichtig ist, dass du Modelle *statistisch* vergleichen kannst. Bedenke immmer, dass die *statistische* Bewertung nicht immer ausreicht! Auch was die Biologie über das Modell sagt ist wichtig.
:::

Wir bauchen uns jetzt fünf Modelle von `fit_1` bis `fit_5`. Jedes dieser Modelle hat andere $x$ aber häufig das gleiche Outcome `y`. In dem Beispiel am Ende des Kapitels nutzen wir auch verschiedene $y$ dafür aber dann gleiche $x$ in dem Modell. Im Weiteren sortieren wir die Modelle von einfach nach komplex. Ich versuche immmer das einfachste Modell `fit_1` zu nennen bzw. eher die niedrige Nummer zu geben. Im Idealfall benennst du die Modellobjekte nach den Modellen, die in en Objekten gespeichert sind. Oft sind die Modelle aber sehr groß und die Objekte der Fits haben dann sehr lange Namen.

```{r}
fit_1 <- lm(jump_length ~ animal, data = model_tbl)
fit_2 <- lm(jump_length ~ animal + sex, data = model_tbl)
fit_3 <- lm(jump_length ~ animal + sex + weight, data = model_tbl)
fit_4 <- lm(jump_length ~ animal + sex + sex:weight, data = model_tbl)
fit_5 <- lm(log(jump_length) ~ animal + sex, data = model_tbl)
```

Als Ergänzung zum Bestimmtheitsmaß $R^2$ wollen wir uns noch das *Akaike information criterion* (abk. $AIC$) anschauen. Du kannst auch das $R^2$ bzw. das $R^2_{adj}$ für die Modellauswahl nehmen. Das $AIC$ ist neuer und auch für komplexere Modelle geeignet. Es gilt hierbei, je kleiner das $AIC$ ist, desto besser ist das $AIC$. Wir wollen also Modelle haben, die ein kleines $AIC$ haben. Wir gehen jetzt nicht auf die Berechnung der $AIC$'s für jedes Modell ein. Wir erhalten nur ein $AIC$ für jedes Modell. Die einzelnen Werte des $AIC$'s sagen *nichts* aus. Ein $AIC$ ist ein mathematisches Konstrukt. Wir können aber verwandte Modelle mit dem $AIC$ untereinander vergleichen. Daher berechnen wir ein $\Delta$ über die $AIC$. Dafür nehmen wir das Modell mit dem niedrigsten $AIC$ und berechnen die jeweiligen Differenzen zu den anderen $i$ Modellen. In unserem Beispiel ist $i$ dann gleich fünf, da wir fünf Modelle haben.

$$
\Delta_i = AIC_i - AIC_{min}
$$

-   wenn $\Delta_i < 2$, gibt es keinen Unterschied zwischen den Modellen. Das $i$-te Modell ist genauso gut wie das Modell mit dem $AIC_{min}$.
-   wenn $2 < \Delta_i < 4$, dann gibt es eine starke Unterstützung für das $i$-te Modell. Das $i$-te Modell ist immer noch ähnlich gut wie das $AIC_{min}$.
-   wenn $4 < \Delta_i < 7$, dann gibt es deutlich weniger Unterstützung für das $i$-te Modell;
-   Modelle mit $\Delta_i > 10$ sind im Vergleich zu dem *besten* $AIC$ Modell nicht zu verwenden.

Nehmen wir ein $AIC_1 = AIC_{min} = 100$ und $AIC_2$ ist $100,7$ an. Dann ist $\Delta_2=0,7<2$, so dass es keinen wesentlichen Unterschied zwischen den Modellen gibt. Wir können uns entscheiden, welches der beiden Modelle wir nehmen. Hier ist dann wichtig, was auch die Biologie sagt oder eben andere Kriterien, wie Kosten und Nutzen. Wenn wir ein $AIC_1 = AIC_{min} = 100000$ und $AIC_2$ ist $100700$ vorliegen haben, dann ist $\Delta_2 = 700 \gg 10$, also gibt es keinen Grund für das $2$-te Modell. Das $2$-te Modell ist substantiell schlechter als das erste Modell. Mehr dazu kannst du unter [Multimodel Inference: Understanding AIC and BIC in Model Selection](https://faculty.washington.edu/skalski/classes/QERM597/papers_xtra/Burnham%20and%20Anderson.pdf) nachlesen.

Wir können das $\Delta_i$ auch in eine Wahrscheinlichkeit umrechnen. Wir können $p_i$ berechnen und damit die relative (im Vergleich zu $AIC_{min}$) Wahrscheinlichkeit, dass das $i$-te Modell den AIC minimiert.

$$
p_i = \exp\left(\cfrac{-\Delta_i}{2}\right)
$$

Zum Beispiel entspricht $\Delta_i = 1.5$ einem $p_i$ von $0.47$ (ziemlich hoch) und ein $\Delta_i = 15$ entspricht einem $p_i =0.0005$ (ziemlich niedrig). Im ersten Fall besteht eine Wahrscheinlichkeit von 47%, dass das $i$-te Modell tatsächlich eine bessere Beschreibung ist als das Modell, das $AIC_{min}$ ergibt, und im zweiten Fall beträgt diese Wahrscheinlichkeit nur 0,05%. Wir können so einmal nachrechnen, ob sich eine Entscheidung für ein anderes Modell lohnen würde. Neben dem $AIC$ gibt es auch das Bayesian information criterion ($BIC$). Auch beim $BIC$ gilt, je kleiner das BIC ist, desto besser ist das BIC.

Du siehst schon, es gibt eine Reihe von Möglichkeiten sich mit der Güte oder Qualität eines Modells zu beschäftigen. Wir nutzen die Funktion `model_performance()` um uns die Informationen über die Güte eines Modells wiedergeben zu lassen. Im folgenden Codeblock habe ich mich nur auf das $AIC$ und das $BIC$ konzentriert.

```{r}
model_performance(fit_1) |> 
  as_tibble() |> 
  select(AIC, BIC)
```

Gut soweit. Du kannst jetzt für jedes der Modelle das $AIC$ berechnen und dann dir die Modelle entsprechend ordnen. Wir müssen das aber nicht tun. Wir können uns auch die Funktion `compare_performance()` zu nutze machen. Die Funktion gibt uns die $R^2$-Werte wieder wie auch die $AIC$ sowie die $s^2_{\epsilon}$ als `sigma` wieder. Wir haben also alles zusammen was wir brauchen. Darüber hinaus kann die Funktion auch die Modelle rangieren. Das nutzen wir natürlich gerne.

```{r}
#| message: false
#| warning: false
comp_res <- compare_performance(fit_1, fit_2, fit_3, fit_4, fit_5, rank = TRUE)

comp_res
```

Anhand der Ausgabe der Funktion `compare_performance()` sehen wir, dass unser Modell `fit_2` das beste Modell ist. Zwar ist die Streuung der Residuen nicht die Kleinste aller Modelle (`Sigma` = 1.933) aber wir haben ein hohes $R^2_{adj}$ und auch ein kleines $AIC$. Wir würden damit sagen, dass das Modell `fit_2` mit den Variablen `animal` und `sex` für $x$ das Outcome `jump_length` am besten statistisch beschreibt.

In @fig-stat-modeling-compare sehen wir die Ausgabe der Funktion `compare_performance()` nochmal visualisiert. Wir können dann die einzelnen Modelle nochmal besser vergleichen. Auch siehst du hier, ob ein Modell in einem Bereich sehr schlecht ist oder aber nur in einem Bereich sehr gut.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Graphische Darstellung der Funktion `compare_performance()` Wir sehen hier die einzelnen Gütekriterien in einer Übersicht dargestellt.
#| label: fig-stat-modeling-compare

plot(comp_res)
```

Zum Ende stellt sich die Frage nach dem statistischen Test. Können wir auch statistisch Testen, ob das Modell `fit_1` signifikant unterschiedlich ist? Ja wir können die Funktion `test_vuong()` nutzen um ein Model zu den anderen Modellen zu vergleichen. Wenn du mehrere Modell miteinander vergleichen möchtest, dann muss du die Funktion mehrfach ausführen.

```{r}
test_vuong(fit_1, fit_2, fit_3, fit_4, fit_5)
```

Nutzen wir die Modellselektion auch einmal an einem konkreten Beispiel. War die Transformation sinnvoll? Wir haben also ein Outcome $y$ vorliegen und wollen wissen, ob wir nicht lieber das Modell mit einem $y$ mit einer $log$-Transformation rechnen sollten. Wir nutzen dazu den Datensatz mit den Hunde- und Katzenflöhen und die Schlüpfdauer als Outcome. Also wie lange brauchen die Flöhe bis die Flöhe aus den Eiern geschlüpft sind.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") |>
  mutate(log_hatch_time = round(log(hatch_time), 2))
```

Wir bauen uns jetzt zwei Modelle. Zum einen das Modell `fit_raw` mit der `hatch_time` und den Variablen `ainmal` und `sex`. Das zweite Modell enthält die `log(hatch_time)` also das Outcome $y$ als $log$-Transformation. Wiederum sind die $x$ variablen die gleichen wie im untransformierten Modell. Wir fitten beide Modelle und speichern die Objekte entsprechend ab.

```{r}
fit_raw <- lm(hatch_time ~ animal + sex, data = model_tbl)
fit_log <- lm(log_hatch_time ~ animal + sex, data = model_tbl)
```

Die Funktion `compare_performance()` erlaubt uns wieder die beiden Modelle `fit_raw` und `fit_log` miteinander zu vergleichen. Wir erhalten die folgende Ausgabe der Funktion.

```{r}
#| message: false
#| warning: false
comp_res <- compare_performance(fit_raw, fit_log, rank = TRUE)

comp_res
```

In diesem Beispiel wäre das $log$-transformierte Modell das bessere statistische Modell. Wir müssen jetzt überlegen, ob wir den Preis dafür bezahlen wollen. Wenn wir nämlich alles mit der $log$-Transformation rechnen, dann erhalten wir auch alle Koeffizienten auf der $log$-Skala (eng. *log scale*). Hier kannst du nur von Fall zu Fall entscheiden.

## Referenzen {.unnumbered}
