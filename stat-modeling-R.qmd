```{r echo = FALSE}
#| warning: false
#| message: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, see,
               latex2exp, patchwork, parsnip, conflicted)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
conflicts_prefer(dplyr::filter)
set.seed(20250701)
theme_modeling <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(size = 12, face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-modeling-R.R")
```

# Modellieren in R {#sec-modeling-R}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-R.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Ich weiß nicht weiter; Ich will mich verändern; Doch wie fang ich's an?" --- Tocotronic, Die Unendlichkeit*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion (seit 07.2025)

Dieses Kapitel wird in den nächsten Wochen geschrieben und ist damit meine aktuelle Großbaustelle. Ich plane zum Ende des Wintersemesters 2025/26 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

Dieses Startkapitel gibt dir nochmal eine Übersicht über das statistische Modellieren in R. Hier liegt vor allem der Fokus auf R. Es gibt eben eine Reihe von *zusätzlichen* Pakten, die es dir erlauben noch mehr aus einem statistischen Modell rauszuholen. Am Ende wurde es mir dann aber zu detailliert alle Pakete in jedem Kapitel vorzustellen und anzuwenden. Das ist auch nicht immer sinnig. Häufig willst du erstmal *nur* das Modell rechnen. Später kannst du dann noch tiefer ins Detail gehen oder aber komplexere Verfahren nutzen. Ich tue mich also etwas schwer dieses Kapitel einzuordnen. Entweder packen wir es ans Ende vom statistischen Modellieren und schauen, dann wie wir alles in R machen. Das steht aber etwas der Intuition entgegen, dass wir in jedem Kapitel zum statistischen Modellieren ja schon was selber machen wollen. In R gibt es dazu dann noch sehr gute Pakete, die das Modellieren sehr viel einfacher machen, dabei dann aber auch für den Anfänger etwas komplexer sind. Ich habe mich daher entschieden, diese aktuelle und komplexere Modellierung einmal hier am Anfang vorzustellen und in den folgenden Kapiteln teilweise darauf zu verweisen, wenn ich es sinnig fand. Du kannst alle Modelle auf althergebrachte Art und Weise rechnen ohne was zu verpassen. Aber manchmal möchte man dann auch effizienter Modellieren. Dafür ist dann dieses Kapitel da: Eine erweiterte Idee von der statistischen Modellierung zu erlangen. Fangen wir also erstmal mit der naheliegenden Frage an.

## Allgemeiner Hintergrund

![Alles ist ein Modell und wird es auch immer sein. Daher können wir viele statistsiche Tests und Algorithmen als ein Spezialfall des statistischen Modellierens ansehen. Quelle: https://easystats.github.io/modelbased](images/allregressions.png){#fig-all-regression fig-align="center" width="100%"}

Modelle sollten visualisiert werden. Oder andersherum, wenn wir etwas in Zusammenhang setzen wollen, dann sollten wir diesen Zusammenhang auch darstellen können. Manchmal scheint es nicht möglich, aber dann lohnt sich das ausprobieren und nachdenken, wie Variablen miteinander visualisiert werden können. Oder wie wir allgemeiner wie folgt als eine Art Flowchart schreiben können.

::: panel-tabset
## The Modelisation Approach in `{modelbased}`

Das R Paket `{modelbased}` schlägt folgenden [Weg für das Modellieren](https://easystats.github.io/modelbased/articles/modelisation_approach.html) vor. Dabei sind es nur fünf Schritte, die wir iterativ durchführen können.

1)  Zeichne zuerst, was du visualisieren möchtest. Nutze hierzu auch erstmal nur eine Skizze und danach die echten Daten.
2)  Erstelle ein Modell für deine Visualisierung.
3)  Wähle das beste Modell nach statistischen Maßzahlen aus.
4)  Visualisiere das beste Modell in deiner Visualisierung. Bringe also Modell und Daten zusammen.
5)  Untersuchen die Parameter des Modells um mehr über die Zusammenhänge zu erfahren.

## Statistical Thinking for the 21st Century

In dem Buch [Statistical Thinking for the 21st Century --- Practical statistical modeling?](https://statsthinking21.github.io/statsthinking21-core-site/practical-example.html#the-process-of-statistical-modeling) findest du dann nochmal einen anderen Prozess vorgeschlagen. Die Idee ist ähnlich, aber ergänzt noch um ein paar Punkte.

1)  Formuliere deine wissenschaftliche Fragestellung.
2)  Identifiziere oder sammle die entsprechenden Daten.
3)  Bereite die Daten für die statistische Analyse vor.
4)  Bestimme das geeignete statistische Modell. Nehme im Zweifel mehrere Modelle in deine Betrachtung.
5)  Passen das statistische Modell an die Daten an.
6)  Überprüfe das statistische Modell kritisch, um sicherzustellen, dass das Modell richtig passt.
7)  Teste die Hypothese und quantifizieren mögliche Effektgrößen.
:::

Am Ende bauen wir immer ein *Modell der Wirklichkeit* aus unseren Daten. Wir messen selten alles was es zu messen gibt oder wert wäre gemessen zu werden. Daher sind unsere Modelle der Daten immer falsch, aber manchmal eben dann doch nützlich. Wenig Beobachtungen decken weniger Wirklichkeit ab und daher sind diese Modell schon intuitiv schlechter als Modelle mit mehr Beobachtungen. Aber lasse dich nicht abschrecken. auch mit weniger Daten lassen sich Schlüsse über Zusammenhänge finden. Nachdem wir einmal kurz klären, was genau ich immer meine, wenn ich von Faktoren und Kovariaten schreibe, gehen wir nochmal auf das Modell als Idee ein.

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use "independent variable" because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Testen. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

#### Was ist ein Modell {.unnumbered .unlisted}

> *"Doch in Wahrheit muss Wissen immer zuerst vermutet und dann überprüft werden." --- David Deutsch, Der Anfang der Unendlichkeit*

Was ist ein Modell? Da sich unser Modell auf Daten bezieht, denn nichts anderes haben wir ja in R vorliegen, ist unser Modell immer eine Zusammenstellung von Einflussvariablen und häufig einem Messwert. Es gibt einfache Arten der Modellierung wo wir eine Linie durch eine Punktewolke zweier Kovariaten zeichnen. Es gibt aber auch komplexere Modelle, die wie Netze oder Bäume aussehen. Am Ende haben aber alle Modelle eine Basis. Nämlich deine Daten, die du in diese Modelle hinsteckst.

Was modellieren wir jetzt eigentlich?

:   Wir modellieren die Varianz in den Daten. Dabei versuchen wir die Varianz im Messwert durch die Einflussvariablen zu minimiere. Oder anders formuliert, wir versuchen die Varianz in den Daten den jeweiligen Quellen zuzuordnen und darüber dann neue Erkenntnisse zu erlangen. Meistens ist es dann einfach eine Linie durch die Punkte zu zeichnen.

Somit haben wir immer unsere Daten vorliegen. Wir versuchen jetzt unsere Daten durch unser Modell als statistisches Modell zu verstehen. Wir zerlegen somit die Daten in zwei Komponenten. Den Teil der Messwerte, den wir durch das Modell erklären können und noch den Rest, den wir als Fehler oder unbekannten Messwert erklären. Mehr dazu dann in dem Buch zu [Statistical Thinking for the 21st Century --- What is a model?](https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html#what-is-a-model)

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 1.5
#| fig-width: 7
#| fig-cap: "Der Zusammenhang von Daten, dem statistischen Modell und dem Fehler. Das Modell versucht durch ein statistisches Modell $f(x)$ den Zusammenhang zwischen den Einflussvariablen dem Messwert zu erklären. Den Anteil des unerklärten Messwert geht in den Fehlerterm. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-model-abstract

p_model_abstract 
```

Oder um es etwas anders zu formulieren, [*"Models are about what changes, and what doesn't"*](https://magesblog.com/post/modelling-change/). Wir wollen also wissen was sich in den Daten ändert und wie wir diese Änderung beschreiben können. Somit wollen wir uns die Frage stellen, was ist eigentlich das Ziel des Modellierens? Wir wollen ja mit der Modellierung der Varianz irgendwas erreichen. In der folgenden Abbilundung siehst du einmal die drei großen Fragefelder, die wir mit einer Modellierung bearbeiten können. Du musst dir dann überlegen, wie du deine wissenschaftliche Fragestellung dann dort unterbringen kannst.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-scatter-modeling-R-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 15
#| fig-cap: "Verschiedene Ziele und Möglichkeiten des statistischen Modellierens. Grob können die Möglichkeiten in drei große thematische Zusammenhänge eingeteilt werden. **(A)** *Kausales Modell* -- Wie verändert sich $y$, wenn sich $x_1$ ändert? Wie ist der numerische Zusammenhang zwischen $y$ und $x$? **(B)** *Prädikitives Modell* -- Wenn $y$ und $x$ gemessen wurden, wie sehen dann die Werte von $y$ für neue $x$-Werte aus? Können wir mit $x$ die Werte in $y$ vorhersagen? **(C)** *Clusteranalyse* -- Haben wir in unseren Variablen $x_1$ und $x_2$ eine oder mehrere unbekannte Cluster vorliegen? Wie gehören die Beobachtungen gegeben $x_1$ und $x_2$ zusammen? *[Zum Vergrößern anklicken]*"

source("images/R/stat-modeling-R-01.R")

p11 + p12 + p13 +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

#### Dummykodierung {.unnumbered .unlisted}

[R Library Contrast Coding Systems for categorical variables](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

[Dummykodierung](https://de.wikipedia.org/wiki/Dummy-Variable)

[fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from Categorical Variables](https://cran.r-project.org/web/packages/fastDummies/)

#### R Pakete zum Modellieren {.unnumbered .unlisted}

Neben den R Paketen, die wir in den jeweiligen Kapiteln brauchen, kommen noch folgende R Pakete immer wieder dran. Deshalb sind die R Pakete hier schon mal mit den jeweiligen Internetseiten aufgeführt.

-   Das Buch [Tidy Modeling with R](https://www.tmwr.org/) gibt nochmal einen tieferen Einblick in das Modellieren in R. Wir immer, es ist ein Vorschlag aber kein Muss.
-   Das [R Paket `{parameters}`](https://easystats.github.io/parameters/index.html) nutzen wir um die Parameter eines Modells aus den Fits der Modelle zu extrahieren. Teilweise sind die Standardausgaben der Funktionen sehr unübersichtich. Hier hilft das R Paket.
-   Das [R Paket `{performance}`](https://easystats.github.io/performance/) hilft uns zu verstehen, ob die Modelle, die wir gefittet haben, auch funktioniert haben. In einen mathematischen Algorithmus können wir alles reinstecken, fast immer kommt eine Zahl wieder raus.
-   Das [R Paket `{tidymodels}`](https://tidymodels.tidymodels.org/) nutzen wir als *das* R Paket um mit Modellen umgehen zu können und eine *Vorhersage neuer Daten* zu berechnen. Das Paket `{tidymodels}` ist wie das Paket `{tidyverse}` eine Sammlung an anderen R Paketen, die wir brauchen werden.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, emmeans, multcomp, ggpmisc, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(ggplot2::annotate)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Theoretisches Modellieren in R

@wilkinson1973symbolic with [Symbolic Description of Factorial Models for Analysis of Variance](https://www.jstor.org/stable/2346786)

Fangen wir also erstmal allgemeiner an ein Modell und deren Schreibweise zu verstehen. Da wir uns natürlich in R bewegen für die praktische Anwendung, nutzen wir auch die Modellschreibweise, die in R üblich ist. In R wird diese Schreibweise auch `formula()` genannt. Im Folgenden siehst du einmal ein Modell in einer abstrakten Form. Wir haben den Messwert $Y$ auf der linken Seite (eng. *left hand side*, abk. *LHS*) der Tilde und die Einflussvariablen $X$ auf der rechten Seite (eng. *right hand side*, abk. *RHS*). Dabei steht dann das $X$ hier einmal als Platzhalter und Sammelbegriff für verschiedene Arten von möglichen Variablen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Statistische Modellschreibweise mit dem Messwert auf der linken Seite und den Einflussvariablen auf der rechten Seite der Tilde. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-03

p_lhs_rhs
```

In R sieht es dann etwas anders aus, da wir die Platzhalter $Y$ für den Messwert und $X$ für die Einflussvariable durch die Namen der Spalten in unserem Datensatz ersetzen. Der Satendatz liegt dann als `tibble()` in R vor. Mehr dann dazu in den folgenden Beispielen in den jeweiligen Kapiteln zum Modellieren. Dann sieht das Modell wie in der folgenden Abbildung aus.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Statistische Modellschreibweise in R mit dem Messwert auf der linken Seite und den Einflussvariablen auf der rechten Seite der Tilde. Die Platzhalter $Y$ und $X$ werden durch die Spaltennamen im Datensatz ersetzt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-20

p_lhs_rhs_r
```

Dann wäre es ja schön, wenn wir nur die linke und rechte Seite neben einer Tilde hätten. Das ist aber nur eine sehr abstrakte Darstellung. Es ha ja auch seinen Grund, warum wir sehr viele Kapitel in diesem Openbook dem Thema des statistischen Modellieren widmen. Wir haben nämlich eine richtig schrecklich nette Familie an Möglichkeiten zusammen.

In der folgenden Abbildung siehst du einmal wie alles mit allem zusammenhängt. Auf der linken Seite siehst du den Messwert $Y$ der einer Verteilunsgfamilie entstammt. Je nachdem was du wie gemessen hast, folgt dein Messwert $Y$ einer anderen Verteilung. Konkreter noch, welche Zahlen du für deinen Messwert $Y$ bestimmt hast. Auf der rechten Seite findest du die Einflussvariable $X$, die aus mehren Variablen bestehen kann aber nicht muss. Wenn du eine kontinuierliche Einflussvariable vorliegen hast, dann sprechen wir von Kovariaten. Hast du dagegen kategoriale Einflussvariablen, dann sprechen wir von Faktoren mit Leveln als die Gruppen. Je nach Kombination aus Verteilungsfamilie und Einflussvariable hast du dann eine andere Interpretation der Modellierung vorliegen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.7
#| fig-width: 7
#| fig-cap: "Erweiterte Darstellung der statistischen Modellierung. Die Messwerte $Y$ folgen einer Verteilung. Die Einflussvariablen liegen kontinuierlich als Kovariaten oder aber kategorial als Faktoren vor. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-09

p_lhs_rhs_detail
```

Da wir die *schrecklich nette Familie* ja auch irgendiwe bezeichnen müssen, hat sich folgende Semantik mehr oder minder durchgesetzt. Ich nutze jedenfalls den folgenden Aufbau um zu benennen was ich eigentlich analysieren und modellieren will. Zuerst kommt, ob wir eine Einflussvariable oder mehrere Einflussvariablen betrachten. Wir nennen dann eben die Modellierung eine simple oder multiple Modellierung. Dann kommt die Verteilunsgfamilie des Messwerts als Wort um dann noch zu sagen, ob wir es mit einem gemischten Modell zu tun haben. Haben wir kein gemischtes Modell, dann lassen ignorieren wir den Teil. Häufig sprechen wir auch von einer linearen Regression, wenn wir eine Gaussian linear Regression meinen. Das finde ich aber sehr verwirrend und nicht klar. Deshalb vermeide ich diesen Sprachgebrauch, wenn wir es mit komplexeren Modellen zu tun haben.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.5
#| fig-width: 9.5
#| fig-cap: "Semantische Zusammensetzung der Beschreibung einer linearen Regression als statistische Modellierung. Zu erst wird definert wie viele Einflussvariablen betrachtet werden. Dann kommt die Verteilungsfamilie des Messwertes. Optional kann noch festgelegt werden, ob ein gemischtes Modell gerechnet wird. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-01

p_regression_wording 
```

## Praktisches Modellieren in R

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Statistische Modellschreibweise mit dem Messwert auf der linken Seite und den Einflussvariablen auf der rechten Seite der Tilde. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-intro

p_lhs_rhs
```

```{r}
reformulate(termlabels = "hase",
            response = "igel")
```

Neben dem Symbol + gibt es noch weitere Symbole, die Ihren Formeln eine besondere Bedeutung verleihen können:

-   `+` für die Ergänzung von Termen

-   `-` zum Entfernen von Termen;

-   `:` für Wechselwirkungen;

-   `*` für Kreuzungen;

-   `%in%` für Verschachtelungen; und

-   `^` für Grenzüberschreitungen bis zum angegebenen Grad.

-   You use the `I()` or `as-is` operator: `y ~ x + I(x^2)`

::: callout-tip
## Weitere Tutorien für Formelschreibweise in R

-   [Model Formulae in R](https://www.oreilly.com/library/view/the-r-book/9780470510247/ch009-sec009.html)
-   [R Formula Tutorial](https://www.datacamp.com/tutorial/r-formula-tutorial)
-   [`formula()` in `{stats}`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html)
-   [The R Formula Cheatsheet](https://www.econometrics.blog/post/the-r-formula-cheatsheet/)
-   [Formulae in R -- ANOVA and other models, mixed and fixed](https://conjugateprior.org/2013/01/formulae-in-r-anova/?utm_source=rss&utm_medium=rss&utm_campaign=formulae-in-r-anova)
-   [ ]()
-   [ ]()
:::

### Right-hand side (abk. RHS)

```{r}
#| eval: false

lm(y ~ f_A + f_B + f_A:f_B)
```

Bei der Durchführung der binomialen oder quasibinomialen GLM geben Sie entweder eine Erfolgswahrscheinlichkeit, eine zweispaltige Matrix mit den Spalten für die Anzahl der Erfolge und Misserfolge oder einen Faktor an, bei dem die erste Stufe für Misserfolg und die anderen für Erfolg auf der linken Seite der Gleichung stehen.

### Left-hand side (abk. LHS)

Die rechte Seite der Modellformel zeigt:

die Anzahl der erklärenden Variablen und ihre Identitäten – ihre Attribute (z. B. kontinuierlich oder kategorial) werden in der Regel vor der Modellanpassung definiert; die Wechselwirkungen zwischen den erklärenden Variablen (falls vorhanden); nichtlineare Terme in den erklärenden Variablen. Rechts von der Tilde besteht in einigen Sonderfällen auch die Möglichkeit, Offsets oder Fehlerterme anzugeben. Wie bei der Antwortvariablen können die erklärenden Variablen als Transformationen, Potenzen oder Polynome auftreten.

### Hilfreiche Funktionen

`terms()` Funktion

`all.vars()`

`update()`

#### Generalisierung von `lm()` zu `glm()` und `[g]lmer()` {.unnumbered .unlisted}

-   Die Funktion `lm()` nutzen wir, wenn das Outcome $y$ einer Normalverteilung folgt.
-   Die Funktion `glm()` nutzen wir, wenn das Outcome $y$ einer *andere* Verteilung folgt.
-   Die Funktion `lmer()` nutzen wir, wenn das Outcome $y$ einer Normalverteilung folgt *und* wir noch einen Block- oder Clusterfaktor vorliegen haben.
-   Die Funktion `glmer()` nutzen wir, wenn das Outcome $y$ einer *andere* Verteilung folgt *und* wir noch einen Block- oder Clusterfaktor vorliegen haben.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.5
#| fig-width: 7
#| fig-cap: "Übersicht über die semantische Erweiterung der Standardfunktion `lm()` für eine lineare Regression zur generalisierten Variante `glm()` und der beiden Varianten für die gemischten linearen Modellen `lmer()` und `glmer()`. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-00

p_glmer
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der simplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ für die Steigung der Graden für eine Einflussvariable $x_1$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-07

p_simple_model
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der multiplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ bis $\\beta_p$ für die partielle Steigung der Graden für jede Einflussvariable $x_1$ bis $x_p$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-04

p_mult_model 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.75
#| fig-width: 7
#| fig-cap: "Abstrakte Formelschreibweise eines linearen, gemischten Regression beinhaltend die festen Effekt $X_1$ bis $X_p$ sowie einen zufälligen Effekt $Z$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-08

p_mixed_model 
```

## Kovariate Modelle

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-18

p_1cov_model +
  labs(title = "Modell mit einer Kovariate")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-19

p_2cov_model +
  labs(title = "Modell mit zwei Kovariaten")
```

## Faktorielle Modelle

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-06

p_1fac_model
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kategoriale Einflussvariablen als Faktor $f_A$ und Faktor $f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-05

p_2fac_model
```

## Interpretation

### Simple Modelle

::: panel-tabset
## $c_1$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-10

p_1cov_model 
```

```{r}
cov1_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   y = 2 + 
                       2 * c_1 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1, cov1_tbl) |> coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-c1

ggplot(cov1_tbl, aes(c_1, y)) +
  theme_modeling() +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_point() +
  stat_poly_line(color = "#E69F00", linewidth = 0.5) +
  stat_poly_eq(use_label("eq"), size = 8) +
  scale_x_continuous(breaks = -1:2) +
  scale_y_continuous(breaks = c(0, 2, 4, 6)) +  
  labs(title = "Simple lineare Regression",
       subtitle = "Intercept ist der y-Achsenabschnitt",
       x = "Covariate 1", y = "Messwert Y")
```

## $f_A$ mit 2 Leveln

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-15

p_1fac_2lvl_model
```

```{r}
fac1_tbl <- tibble("1" = rnorm(5, 3, 0.001),
                   "2" = rnorm(5, 6, 0.001)) |> 
  gather(key = "f_a", value = "y")
```

```{r}
lm(y ~ f_a, fac1_tbl) |> coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-1

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 3, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Treatment coding",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert Y")
```

## $f_A$ mit \>2 Leveln

Hier dann mal mit drei Leveln oder Gruppen

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-11

p_1fac_3lvl_model
```

```{r}
fac1_tbl <- tibble("1" = rnorm(5, 2, 0.001),
                   "2" = rnorm(5, 6, 0.001),
                   "3" = rnorm(5, 4, 0.001)) |> 
  gather(key = "f_a", value = "y")
```

#### *Treatment coding* mit `contr.treatment` (default) {.unnumbered .unlisted}

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.treatment")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-21

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 2, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Treatment coding",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert Y")
```

#### *Effect coding* mit `contr.sum` {.unnumbered .unlisted}

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.sum")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-22

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 4, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Effect coding",
       subtitle = "Intercept ist der globale Mittelwert",
       x = "Faktor A", y = "Messwert Y")
```
:::

### Kombinierte Modelle

::: panel-tabset
## $c_1 + c_2$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-12

p_2cov_model
```

```{r}
cov2_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   c_2 = rnorm(10, 0, 1),
                   y = 2 + 
                       1 * c_1 + 
                       2 * c_2 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2, cov2_tbl) |> 
  coef() |> round(2)
```

## $f_A + c_1$

Einfaktorielle ANCOVA

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-14

p_fa_c1_model
```

```{r}
cov1_fac1_tbl <- tibble(c_1 = rnorm(15, 0, 1),
                        f_a = gl(3, 5),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + c_1, cov1_fac1_tbl) |> 
  coef() |> round(2)
```

## $c_1 + f_A + f_B$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-16

p_c1_fa_2lvl_fb_3lvl_model
```

```{r}
cov1_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + f_a + f_b, cov1_fac2_tbl) |> 
  coef() |> round(2)
```

## $c_1 + c_2 + f_A + f_B$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ sowie einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln und einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-21

p_c2_fa_2lvl_fb_3lvl_model 
```

```{r}
cov2_fac2_tbl <- tibble(c_1 = rnorm(30, 0, 1),
                        c_2 = rnorm(30, 0, 1),
                        f_a = rep(gl(3, 5), 2),
                        f_b = gl(2, 15),
                        y = 2 + 
                            1 * c_1 + 
                            -1 * c_2 + 
                            2 * as.numeric(f_a) + 
                            3 * as.numeric(f_b) + 
                                rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2 + f_a + f_b, cov2_fac2_tbl) |> 
  coef() |> round(2)
```

## $f_A + f_B + f_A \times f_B$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln und deren Interaktion $f_A \\times f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-13

p_2fac_model  +
  labs(title = "") 
```

```{r}
fac2_tbl <- tibble(f_a = rep(gl(3, 5), 2),
                   f_b = gl(2, 15),
                   y = 2 + 
                       2 * as.numeric(f_a) + 
                       3 * as.numeric(f_b) + 
                           rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + f_b + f_a:f_b, fac2_tbl) |> 
  coef() |> round(2)
```
:::

In sehen wir wie wir den Namen einer Regression bilden. Zuerst entscheiden wir, ob wir nur ein $x$ haben oder mehrere. Mit einem $x$ sprechen wir von einem simplen Modell, wenn wir mehrere $x$ haben wir ein multiples Modell. Im nächsten Schritt benennen wir die Verteilung für das Outcome $y$. Dann müssen wir noch entscheiden, ob wir ein gemischtes Modell vorliegen haben, dann schreiben wir das hin. Sonst lassen wir den Punkt leer. Anschließend kommt noch lineares Modell hinten ran.

[Das R Paket `{tidymodels}`](https://www.tidymodels.org/)

[Tidy Modeling with R](https://www.tmwr.org/)

Veraltet aber manchmal ganz nützlich das [R Paket `{modelr}`](https://modelr.tidyverse.org/)

## Konfidenzintervall vs. Prädiktionsintervall

Ein Konfidenzintervall gibt den Wertebereich für einen gesuchten Parameter der Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit an. Ein Prognoseintervall gibt den Wertebereich für einen individuellen, zukünftig zu beobachtenden Wert mit einer bestimmten Wahrscheinlichkeit an.

#### Konfidenzintervall {.unnumbered .unlisted}

Text

Konfidenzintervall

:   Ein Konfidenzintervall gibt den Wertebereich für einen gesuchten Parameter der Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit an.

#### Prädiktionsintervall {.unnumbered .unlisted}

Text

Prädiktionsintervall

:   Ein Prädiktionsintervall (auch Vorhersageintervall oder Prognoseintervall) gibt den Wertebereich für einen individuellen, zukünftig zu beobachtenden Wert mit einer bestimmten Wahrscheinlichkeit an.

[Quantile Regression Forests for Prediction Intervals](https://www.bryanshalloway.com/2021/04/21/quantile-regression-forests-for-prediction-intervals/)

[The difference between prediction intervals and confidence intervals](https://robjhyndman.com/hyndsight/intervals/)

[P-values for prediction intervals](https://robjhyndman.com/hyndsight/forecasting-pvalues.html) machen keinen Sinn

[How NASA didn’t discover the hole in the ozone layer](https://robjhyndman.com/hyndsight/ozone-hole-anomaly.html)

## Praktisches Modellieren in R

### Marginal Effect Models

[R Paket `{ggeffects}`](https://strengejacke.github.io/ggeffects/articles/ggeffects.html)

[R Paket `{modelbased}`](https://easystats.github.io/modelbased/)

[R Paket `{marginaleffects}`](https://marginaleffects.com/)

### Visualisierung

[R Paket `{ggeffects}`](https://strengejacke.github.io/ggeffects/articles/ggeffects.html)

[R Paket `{gtsummary}`](https://www.danieldsjoberg.com/gtsummary/index.html)

[Display univariate regression model results in table](https://www.danieldsjoberg.com/gtsummary/reference/tbl_uvregression.html)

### ...mit `{purrr}`

`map()` für mehrere Endpunkte wie bei den Spinatdaten in Application gezeigt.

`map2()` mit Familie für `glm` zeigen, wenn wir unterschiedliche Outcomes haben.

```{r}
#| warning: false
#| message: false
cutting_tbl <- read_excel("data/multiple_outcomes.xlsx") |> 
  mutate(trt = as_factor(trt),
         block = as_factor(block)) |> 
  mutate_if(is.numeric, round, 2)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-r-multiple-out
#| tbl-cap: "Auszug aus den Daten ."

cutting_raw_tbl <- cutting_tbl |>
  mutate_all(as.character)
  

rbind(head(cutting_raw_tbl, 4),
      rep("...", times = ncol(cutting_raw_tbl)),
      tail(cutting_raw_tbl, 4)) |>
  kable(align = "c", "pipe")

```

```{r}
family_lst <- lst(shoot = binomial(),
                  leaf = quasipoisson(),
                  flower = quasipoisson(),
                  fruit = quasipoisson(),
                  ca = gaussian(), 
                  drymatter = gaussian(), 
                  freshweight = gaussian(), 
                  height = gaussian())
```

```{r}
cutting_long_tbl <- cutting_tbl |>
  pivot_longer(cols = shoot:last_col(),
               names_to = "outcome",
               values_to = "rsp") |>
  arrange(outcome, trt, block)
```

```{r}
cutting_lst <- cutting_long_tbl |>
  split(~outcome)
```

```{r}
#| message: false
#| warning: false
glm_lst <- cutting_lst %>% 
  map2(family_lst, 
       ~glm(rsp ~ trt + block + trt:block, 
            data = .x, family = .y))  
  
glm_lst %>% 
  map(pluck, "family")

glm_lst %>% 
  map(car::Anova)

emm_lst <- glm_lst %>% 
  map(~emmeans(.x, specs = ~ trt, type = "response")) 

emm_lst %>% 
  map(~contrast(.x, method = "pairwise", adjust = "bonferroni")) %>% 
  map(as_tibble) %>% 
  bind_rows(.id = "outcome")

emm_lst %>% 
  map(~cld(.x, Letters = letters, adjust = "bonferroni")) %>% 
  map(as_tibble) %>% 
  bind_rows(.id = "outcome") %>% 
  select(outcome, trt, .group)  %>% 
  print(n = 28)
```

## Verschiebebahnhof

[R Paket `{parsnip}`](https://parsnip.tidymodels.org/)

in diesem Kapitel wollen Fokus auf `{parsnip}` und dann als Kasten in allen anderen möglichen Modellierungen ergänzen?

[Tidymodels, interactions and anova - a short tutorial](https://www.thomasvanhoey.com/posts/2021-10-12-tidymodels-interactions/index.html)

:::: callout-note
## XX Regression in `{parsnip}`

Auch hier können wir die XX Regression in dem R Paket `{parsnip}` realisieren. Ein Vorteil von `{parsnip}` ist, dass wir die Funktionen sehr gut mit dem `|>`-Operator nutzen können. Das ist bei den Funktionen `glm()` und `lm()` in der ursprünglichen Implementierung ja leider nur etwas umständlicher möglich. Deshalb hier einmal die *bessere* Implementierung.

::: panel-tabset
## `{parsnip}`

```{r}
linreg_reg_fit <- linear_reg() |> 
  set_engine("lm") |> 
  fit(jump_length ~ grp, data = simple_tbl) 
```

Dann die ANOVA

```{r}
linreg_reg_fit|>  
  extract_fit_engine() |> 
  anova()
```

## `{base}`

```{r}
linreg_reg_fit <- lm(jump_length ~ grp, data = simple_tbl)
```

```{r}
linreg_reg_fit|>  
  anova()
```
:::

Eine detailliertere Einführung mit mehr Beispielen für die Nutzung vom [R Paket `{parsnip}`](https://parsnip.tidymodels.org/articles/Examples.html) findest du im Kapitel [Modellieren in R](#sec-modeling-R). Hier soll es dann bei der kurzen Gegenüberstellung bleiben.
::::

## Referenzen {.unnumbered}
