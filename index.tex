% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
]{scrbook}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0666666666667in,textwidth=4.1333333333333in,marginparsep=0.3in]{geometry}
\usepackage[normalem]{ulem}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Inhaltsverzeichnis}
\else
  \newcommand\contentsname{Inhaltsverzeichnis}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Abbildungsverzeichnis}
\else
  \newcommand\listfigurename{Abbildungsverzeichnis}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Tabellenverzeichnis}
\else
  \newcommand\listtablename{Tabellenverzeichnis}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Abbildung}
\else
  \newcommand\figurename{Abbildung}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabelle}
\else
  \newcommand\tablename{Tabelle}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{Listingverzeichnis}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{ngerman}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Skript Bio Data Science},
  pdfauthor={Prof.~Dr.~Jochen Kruppa},
  pdflang={de},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Skript Bio Data Science}
\author{Prof.~Dr.~Jochen Kruppa}
\date{13. September 2022}

\begin{document}
\frontmatter
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[interior hidden, borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt, enhanced, frame hidden, sharp corners, breakable]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Inhaltsverzeichnis}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\mainmatter
\bookmarksetup{startatroot}

\hypertarget{willkommen}{%
\chapter*{Willkommen}\label{willkommen}}
\addcontentsline{toc}{chapter}{Willkommen}

Auf den folgenden Seiten wirst du eine Menge Ã¼ber Statistik oder Data
Science lernen. Du musst dafÃ¼r nicht eine meiner Veranstaltungen
besuchen. Gerne kannst du hier und dort einmal schauen, ob etwas fÃ¼r
dich dabei ist. Das Skript wird fortlaufend von mir ergÃ¤nzt. Neben dem
Skript gibt es auch noch die erklÃ¤renden YouTube Videos. Ich freue mich,
dass du Lust hast hier etwas zu lernen\ldots{} oder aber du \emph{musst}
-- da bald eine Klausur ansteht. Wie auch immer -- schau dich einfach
mal um. Im Anhang findest du auch einen kleinen Leitfaden fÃ¼r das
Schreiben einer Abschlussarbeit. Vielleicht hilft dir die Anleitung ja
beim Schreiben.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Gesammelte Klausurfragen Bio Data Science}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Du findest die
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub}. Die Klausurfragen zu den einzelnen
Vorlesungen in einem Modul werden in den entsprechenden Ãbungen
besprochen. Bitte komme in die Ãbungen.
\end{tcolorbox}

\hypertarget{lernen}{%
\section*{Lernen\ldots{}}\label{lernen}}
\addcontentsline{toc}{section}{Lernen\ldots{}}

Du liest hier gerade das Skript fÃ¼r
\protect\hyperlink{sec-vorlesungen-hs}{meine Vorlesungen} an der
Hochschule OsnabrÃ¼ck an der FakultÃ¤t Agrarwissenschaften und
Landschaftsarchitektur (AuL). Wie immer Leben kannst du auf verschiedene
Arten und Weisen den Stoff, den ich vermitteln will, lernen. Daher gibt
es noch zwei andere MÃ¶glichkeiten. Zum einen Lernen auf YouTube, mit
meinen Lernvideos oder du schaust dir das Material auf GitHub an. Auf
GitHub habe ich auch Informationen, die du vielleicht brauchen kannst.
Ebenso findest du im Kapitel~\ref{sec-literatur} noch andere
Literaturempfehlungen.

\hypertarget{auf-youtube}{%
\subsection*{\ldots{} auf YouTube}\label{auf-youtube}}
\addcontentsline{toc}{subsection}{\ldots{} auf YouTube}

\begin{figure}

{\centering \includegraphics[width=3.125in,height=\textheight]{./images/youtube.png}

}

\end{figure}

Wenn du mÃ¶chtest kannst du auf YouTube unter
\url{https://www.youtube.com/c/JochenKruppa} noch einige Lehrvideos als
ErgÃ¤nzung schauen. In den Videos wiederhole ich Inhalte und du kannst
auf Pause drÃ¼cken um nochmal Programmierschritte nachverfolgen zu
kÃ¶nnen.

\hypertarget{auf-github}{%
\subsection*{\ldots{} auf GitHub}\label{auf-github}}
\addcontentsline{toc}{subsection}{\ldots{} auf GitHub}

\begin{figure}

{\centering \includegraphics[width=3.125in,height=\textheight]{./images/github.png}

}

\end{figure}

Alle Materialien von mir findest du immer auf GitHub unter
\url{https://github.com/jkruppa/teaching}. Selbst wenn du nicht mehr in
einem meiner Kurse bist, kannst du so auf die Lehrinhalte immer nochmal
zugreifen und die aktuellen Versionen haben. Auf GitHub liegt auch immer
eine semesteraktuelle Version der
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen} fÃ¼r meine Module.

\hypertarget{sec-contact-mail}{%
\section*{Kontakt}\label{sec-contact-mail}}
\addcontentsline{toc}{section}{Kontakt}

Wie erreichst du mich? Am einfachsten Ã¼ber die gute, alte E-Mail. Bitte
bachte, dass gerade kurz vor den PrÃ¼fungen ich mehr E-Mails kriege.
Leider kann es dann einen Tick dauern.

\begin{figure}

{\centering \includegraphics[width=2.08333in,height=\textheight]{./images/mail.png}

}

\end{figure}

Einfach an
\href{mailto:j.kruppa@hs-osnabrueck.de}{\nolinkurl{j.kruppa@hs-osnabrueck.de}}
schreiben. Du findest hier auch eine kurze Formulierungshilfe. Einfach
auf den Ausklapppfeil klicken.

\textbf{Bitte gib immer in deiner E-Mail dein Modul - was du belegst -
mit an.} Pro Semester unterrichte ich immer \emph{drei} sehr Ã¤hnlich
klingende Module. Daher schau nochmal
\protect\hyperlink{sec-vorlesungen-hs}{hier in der Liste}, wenn du
unsicher bist.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{E-Mailvorlage mit beispielhafter Anrede}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Hallo Herr Kruppa,

\ldots{} ich belege gerade Ihr Modul \texttt{Modulname} und hÃ¤tte eine
Bitte/Frage/Anregung\ldots{}

\ldots{} ich benÃ¶tige Hilfe bei der Planung/Auswertung meiner
Bachelorarbeit\ldots{}

Mit freundlichen GrÃ¼Ãen

M. Muster
\end{tcolorbox}

\bookmarksetup{startatroot}

\hypertarget{organisation}{%
\chapter{Organisation}\label{organisation}}

\emph{Version vom September 14, 2022 um 08:44:28}

Den Teil kannst du hier Ã¼berspringen, wenn es dich nicht so richtig
interessiert, was ich alles an Vorlesungen an der Hochschule OsnabrÃ¼ck
anbiete. Wenn es dir um \emph{statistische} Inhalte geht, dann gehe
einfach weiter in die nÃ¤chsten Kapitel. In diesem Kapitel geht es
nochmal Orientierung Ã¼ber meine Vorlesungen zu geben, wenn dich noch
mehr als nur der Pflichtkurs interessiert.

\hypertarget{statistische-beratung}{%
\section{Statistische Beratung}\label{statistische-beratung}}

Neben der klassischen Vorlesung biete ich auch Termine fÃ¼r die
statistische Beratung von Abschlussarbeiten sowie Projekten an. Dieses
Angebot gilt es fÃ¼r alle Mitglieder der Hochschule OsnabrÃ¼ck. PrimÃ¤r fÃ¼r
FakultÃ¤t Agrarwissenschaften und Landschaftsarchitektur (AuL), aber
ntÃ¼rlich auch fÃ¼r alle anderen FakultÃ¤ten. DafÃ¼r musst du mir einfach
nur eine \protect\hyperlink{sec-contact-mail}{E-Mail schreiben} und dann
erhÃ¤lst du einen Termin innerhalb der nÃ¤chsten zwei Wochen.

Die Beratung ist grundsÃ¤tzlich anonym und vertraulich. Wenn du willst
kannst du gerne noch dein:e Betreuer:in mitbringen. Das ist aber keine
Voraussetzung oder Notwendigkeit. Meistens finden mehrere Besprechungen
statt, wir versuchen aber natÃ¼rlich zusammen zÃ¼gig dein Problem zu
lÃ¶sen. Ziel ist der Beratung ist es dich in die Lage zu versetzen
selbststÃ¤ndig deine Analyse zu rechnen.

\hypertarget{sec-r-tutorium}{%
\section{R Tutorium}\label{sec-r-tutorium}}

ZusÃ¤tzlich zu der statistischen Beratung bieten wir auch ein R Tutorium
fÃ¼r alle Mitglieder der FakultÃ¤t Agrarwissenschaften und
Landschaftsarchitektur (AuL) an. Theoretisch kÃ¶nnen auch hier andere
Mitglieder der anderen FaklutÃ¤ten vorbeischauen, der Ort ist aber
aktuell ein Raum auf dem GelÃ¤nde in Haste. Die aktuellen Termine findest
du in Tabelle~\ref{tbl-r-tutorium}.

Im R Tutorium besprechen wir aktuelle Themen der Teilnehmer:innen. Meist
sind dies aktuelle Fragen zu den Bachelorarbeiten. Auch wenn du kein
dringendes Problem hast, kannst du gerne kommen und dir die
Fragestellungen anhÃ¶ren. Meistens ist es auch interessant mal die
Fragestellungen der anderen Studierenden sich anzuhÃ¶ren oder aber schon
mal zu Ãben ein anderes Experiment zu verstehen.

Bitte beachte folgende Hinweise zu den Terminen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hinweise zu dem R Tutorium}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Das R Tutorium findet \textbf{nicht} im PrÃ¼fungszeitraum der FakultÃ¤t
Agrarwissenschaften und Landschaftsarchitektur (AuL) statt.

Das R Tutorium findet \textbf{nicht} im \emph{Februar} und \emph{MÃ¤rz}
statt.

Das R Tutorium findet \textbf{nicht} im \emph{August} und
\emph{September} statt.
\end{tcolorbox}

\hypertarget{tbl-r-tutorium}{}
\begin{longtable}[]{@{}llll@{}}
\caption{\label{tbl-r-tutorium}Aktuelle Termine des R Tutoriums im
Semester}\tabularnewline
\toprule()
Termin & Uhrzeit & Raum & Anmerkung \\
\midrule()
\endfirsthead
\toprule()
Termin & Uhrzeit & Raum & Anmerkung \\
\midrule()
\endhead
\emph{nÃ¤chste} & \emph{Termine} & \emph{ab} & \emph{Oktober 2022} \\
\bottomrule()
\end{longtable}

\hypertarget{sec-vorlesungen-hs}{%
\section{Vorlesungen an der Hochschule
OsnabrÃ¼ck}\label{sec-vorlesungen-hs}}

Von mir angebotene Vorlesungen werden an der Hochschule OsnabrÃ¼ck an der
FakultÃ¤t Agrarwissenschaften und Landschaftsarchitektur (AuL) in ILIAS
verwaltet. Alle notwendigen Informationen und Materialien sind auf ILIAS
unter \url{https://lms.hs-osnabrueck.de/} zu finden. Wenn du in dem Kurs
nicht angemeldet bist, dann kontaktiere mich bitte
\protect\hyperlink{sec-contact-mail}{per Mail}. Auch die Kommunikation
erfolgt von meiner Seite aus Ã¼ber ILIAS.

{\marginnote{\begin{footnotesize}Auf ILIAS findest du alle aktuellen
Kursinformationen und erhÃ¤lst auch die Mails, wenn Ãnderungen im
Kursablauf stattfinden.\end{footnotesize}}}

Wenn du nicht in der FakultÃ¤t Agrarwissenschaften und
Landschaftsarchitektur (AuL) studierst oder aber in einem Studiengang,
der meine Module nicht anbietet, steht es dir natÃ¼rlich frei, sich in
meine Vorlesungen zu setzten. Du findest in Tabelle~\ref{tbl-angebot}
eine Ãbersicht der angebotenen Module und auch die inhaltliche Ordnung
nach Lernstufe. Bitte informiere dich in deinem Studierendensekretariat
Ã¼ber die ModalitÃ¤ten zur PrÃ¼fungsteilnahme.

Eine inhaltliche Ãbersicht findet sich auf dem
\href{https://docs.google.com/spreadsheets/d/1WCTnJnofz5OrGZth6LKyPGQvQUUw31t7OfnAE6yz-ww/edit?usp=sharing}{Google
Spreadsheet}. Die Planung ist aktuell (Stand Herbst/Winter 2022) noch
nicht abgeschlossen. Im Zweifel einfach bei mir einmal
\protect\hyperlink{sec-contact-mail}{per Mail} anfragen.

\begin{figure*}

\hypertarget{tbl-angebot}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0206}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2588}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2794}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1824}}@{}}
\caption{\label{tbl-angebot}Angebotene Statistik Module an der FakultÃ¤t
Agrarwissenschaften und Landschaftsarchitektur (AuL). Die Stufe gibt das
Lernniveau an.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Stufe
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Landwirtschaft; Angewandte Pflanzenbiologie -- Gartenbau,
Pflanzentechnologie}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Wirtschafts- ingenieurwesen Agrar / Lebensmittel}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Bioverfahrenstechnik in Agrar- und Lebensmittelwirtschaft}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Angewandte Nutztier- und Pflanzenwissenschaften}
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Stufe
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Landwirtschaft; Angewandte Pflanzenbiologie -- Gartenbau,
Pflanzentechnologie}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Wirtschafts- ingenieurwesen Agrar / Lebensmittel}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Bioverfahrenstechnik in Agrar- und Lebensmittelwirtschaft}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Angewandte Nutztier- und Pflanzenwissenschaften}
\end{minipage} \\
\midrule()
\endhead
\textbf{1} &
\href{https://www.hs-osnabrueck.de/module/44b0266/}{Mathematik und
Statistik} &
\href{https://www.hs-osnabrueck.de/module/44b0568/}{Statistik} &
\href{https://www.hs-osnabrueck.de/module/44b0567/}{Angewandte Statistik
fÃ¼r Bioverfahrenstechnik} & \\
\textbf{2} &
\href{https://www.hs-osnabrueck.de/module/44b0400/}{Angewandte Statistik
und Versuchswesen} &
\href{https://www.hs-osnabrueck.de/module/44b0400/}{Angewandte Statistik
und Versuchswesen} & & \\
\textbf{3} &
\href{https://www.hs-osnabrueck.de/module/44b0390/}{Spezielle Statistik
und Versuchswesen} & & &
\href{https://www.hs-osnabrueck.de/module/44m0161/}{Biostatistik} \\
\bottomrule()
\end{longtable}

\end{figure*}

\bookmarksetup{startatroot}

\hypertarget{sec-literatur}{%
\chapter{Literatur}\label{sec-literatur}}

\emph{Version vom September 14, 2022 um 08:44:32}

Was ist gute Literatur? Immer schwer zu beurteilen. Im Folgenden liste
ich einige Literaturquellen auf. Zum einen basiert eine Menge von dem R
Code auf Wickham (2016) zum Anderen mÃ¶chtest du dich vielleicht nochmal
rechts oder links weiter bilden. Du musst aber nicht um die Klausur
bestehen zu kÃ¶nnen. Siehe es eher als ein Angebot.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Die Frage nach der Klausur\ldots{}}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Und daher hier nochmal gleich zu Anfang, es ist nicht notwendig mehr als
das Skript durchzuarbeiten und bei den Ãbungen zu sein um die Klausur zu
bestehen. FÃ¼r deine Bachelorarbeit wirst du aber Programmieren in R
kÃ¶nnen mÃ¼ssen.
\end{tcolorbox}

Neben diesem Modul musst du vermutlich noch andere Module belegen.
Deshalb hier eine Auswahl Literatur, die dir helfen mag. Zum einen ist
die Literatur anders geschrieben und zum anderen sind dort andere
Inhalte.

\hypertarget{parametrische-statistik}{%
\section{Parametrische Statistik}\label{parametrische-statistik}}

\begin{figure}

{\centering \includegraphics[width=2.08333in,height=\textheight]{./images/dormann.jpg}

}

\end{figure}

Dormann (2013) liefert ein tolles deutsches Buch fÃ¼r die Vertiefung in
die Statistik. Insbesondere wenn du wissenschaftlich Arbeiten willst
weit Ã¼ber die Bachelorarbeit hinaus. Dormann baut in seinem Buch eine
hervorragende Grundlage auf. Das Buch ist an der Hochschule OsnabrÃ¼ck
kostenlos
\href{https://link.springer.com/book/10.1007/978-3-662-54684-0}{Ã¼ber den
Link} zu erhalten.

\hypertarget{experimental-methods-in-agriculture}{%
\section{Experimental methods in
agriculture}\label{experimental-methods-in-agriculture}}

\begin{figure}

{\centering \includegraphics[width=2.08333in,height=\textheight]{./images/cover_stat_for_biology.jpeg}

}

\end{figure}

Onofri und Sacco (2021) haben das Buch
\href{https://www.statforbiology.com/_statbookeng/}{Experimental methods
in agriculture} geschrieben. Wir werden auf dieses englische Buch ab und
zu mal verweisen. Insbesondere der Einleitungstext zur Wissenschaft und
dem Design von Experiementen ist immer wieder lesenswert. SpÃ¤tere Teile
des Buches sind etwas mathematischer und nicht fÃ¼r den Einstieg
unbedingt geeignet. Aber schaue es dir selber an.

\hypertarget{r-for-data-science}{%
\section{R for Data Science}\label{r-for-data-science}}

\begin{figure}

{\centering \includegraphics[width=2.08333in,height=\textheight]{./images/hadley.png}

}

\end{figure}

Wickham (2016) ist die Grundlage fÃ¼r die R Programmierung. Das Material
von Wickahm findet sich kostenlos online unter
\url{https://r4ds.had.co.nz/} und \url{https://www.tidyverse.org/}. Wir
werden uns hauptsÃ¤chlich mit R wie es Wickham lehrt beschÃ¤ftigen. Somit
ist Wickham unsere Grundlage fÃ¼r R.

\hypertarget{practical-statistics-for-data-scientists}{%
\section{Practical Statistics for Data
Scientists}\label{practical-statistics-for-data-scientists}}

\begin{figure}

{\centering \includegraphics[width=2.08333in,height=\textheight]{./images/practical.jpg}

}

\end{figure}

Bruce (2020) schreibt ein Buch fÃ¼r den Anwender. Ohne Vorkenntnisse ist
das Buch vermutlich etwas schwer zu lesen. DafÃ¼r bietet das Buch aber
\emph{nach} einem Statistikkurs sehr gute AnknÃ¼pfungspunkte Richtung
maschinelles Lernen und somit der Klassifikation. Das Buch ist auch hier
in der
\href{https://ebookcentral.proquest.com/lib/hs-osnabrueck/detail.action?docID=6173908}{englischen
Version} und hier in der
\href{http://www.content-select.com/index.php?id=bib_view\&ean=9783960104674}{deutschen
Version} zu erhalten. \emph{Beide Links benÃ¶tigen den Zugang Ã¼ber die
Hochschule OsnabrÃ¼ck}.

\hypertarget{data-science-for-agriculture-in-r}{%
\section{Data Science for Agriculture in
R}\label{data-science-for-agriculture-in-r}}

\begin{figure}

{\centering \includegraphics{./images/dsfair.png}

}

\end{figure}

Schmidt liefert auf der Webseite
\url{https://schmidtpaul.github.io/DSFAIR/index.html} eine tolle
Sammlung an experimentellen Designs bzw. Versuchsanlagen samt der
Auswertung in R. Ohne Vorkenntnisse schwer zu verstehen. Sollte aber
nach einem Kurs Statistik dann mÃ¶glich sein. Gerne hier auch mich
fragen, dann kÃ¶nnen wir gemeinsam das passende Design raussuchen und
besprechen.

\hypertarget{odds-ends}{%
\section{Odds \& Ends}\label{odds-ends}}

\begin{figure}

{\centering \includegraphics{./images/odds_and_ends.PNG}

}

\end{figure}

Am Ende dann noch eine Mathebuch von Weisberg zu finden unter
\url{https://jonathanweisberg.org/vip/}. Eigentlich eher ein Buch Ã¼ber
Wahrscheinlichkeiten und wenn ein Buch am Ende stehen muss, dann ist es
dieses Buch. Ich finde es sehr spannend zu lesen, aber das ist dann
vermutlich \emph{special intrest}.

\hypertarget{referenzen}{%
\section*{Referenzen}\label{referenzen}}
\addcontentsline{toc}{section}{Referenzen}

\bookmarksetup{startatroot}

\hypertarget{einfuxfchrung}{%
\chapter{EinfÃ¼hrung}\label{einfuxfchrung}}

\emph{Version vom September 14, 2022 um 08:44:40}

In diesem Kapitel nenne ich die wichtigsten Lernziele, die nach dem
Lesen des Skriptes im Rahmen deiner Lehrveranstaltung von dir erreicht
worden sein sollten. Je nach besuchten Kurs kann natÃ¼rlich nicht
\emph{alles} geschafft worden sein. Viele Kapitel haben noch eine
Abschnitt in dem du mehr Ã¼ber die Klausur erfÃ¤hrst. So sehe diese
Ãbersicht als EinfÃ¼hrung fÃ¼r das was spÃ¤ter an Lehrinhalten kommt. Wenn
du die Lernziele hier verstehst, dann hast du eine gute und solide
Grundlage in Statistik und Bio Data Science. Damit solltest du dann auch
gut durch die AnfÃ¤nge deiner Bachelorarbeit kommen.

\hypertarget{ein-wort-der-warnung}{%
\section*{Ein Wort der Warnung\ldots{}}\label{ein-wort-der-warnung}}
\addcontentsline{toc}{section}{Ein Wort der Warnung\ldots{}}

Wenn du dieses Bild eines niedergeschlagenen \emph{Engels der Statistik}
siehst\ldots{}

\begin{figure}

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{figure}

\ldots{} dann bedeutet der niedergeschlagene Engel der Statistik:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir opfern Genauigkeit fÃ¼r Anwendbarkeit. Ja, manchmal ist es eben
  statstisch nicht richtig was hier steht, aber aus GrÃ¼nden der
  Anwendung fahren wir mal Ã¼ber den Engel drÃ¼ber. \emph{Schade}.
\item
  Wir sind hier AnfÃ¤nger und Anwender. SpÃ¤ter kannst du noch tiefer ins
  Detail gehen. Hier wollen wir die Grundlagen lernen. Das hat dann
  einen Preis an \emph{Richtigkeit}.
\item
  Wir wollen fertig werden. Durch geschicktes ManÃ¶vrieren kÃ¶nnen wir an
  einen Punkt kommen, wo kein statistischer Test mehr passt. Das wollen
  wir nicht. Deshalb zahlen wir hier auch einen Preis. Passt aber.
\end{enumerate}

Deshalb konzentrieren wir uns auf einige wichtige Lernziele, die wir
jetzt einmal nacheinander durchgehen.

\hypertarget{lernziel-1-eine-explorative-datananalyse-durchfuxfchren}{%
\section{Lernziel 1: Eine explorative Datananalyse
durchfÃ¼hren}\label{lernziel-1-eine-explorative-datananalyse-durchfuxfchren}}

Gleich zu Beginn R Code zu zeigen und eine entsprechende Abbildung ist
vielleicht ungewÃ¶hnlich, aber wir wollen zu dieser
Abbildung~\ref{fig-boxplot-preface} hin. In
Abbildung~\ref{fig-boxplot-preface} siehst du einen Boxplot. Und wie wir
aus den Daten \texttt{flea\_dog\_cat.xlsx} einen Boxplot erstellen, das
soll uns in den nÃ¤chsten Kapitel beschÃ¤ftigen. DafÃ¼r mÃ¼ssen wir nÃ¤mlich
eine Menge in dem Codeblock verstehen und dann auch Anwenden kÃ¶nnen. Und
natÃ¼rlich lernen was eigentlich ein Boxplot ist und was in einem Boxplot
eigentlich dargestellt ist.

\begin{figure}

{\centering \includegraphics{./preface_files/figure-pdf/fig-boxplot-preface-1.pdf}

}

\caption{\label{fig-boxplot-preface}Boxplot der Sprungweiten {[}cm{]}
von Hunden und Katzen.}

\end{figure}

Hier ist der Codeblock der in R die Abbildung~\ref{fig-boxplot-preface}
erstellt.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Einlesen von Daten aus Excel}
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}

\DocumentationTok{\#\# Umformen der \textless{}chr\textgreater{} Spalte in einen Factor \textless{}fct\textgreater{}}
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}

\DocumentationTok{\#\# AuswÃ¤hlen der wichtigen Spalten fÃ¼r den Boxplot}
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, jump\_length) }

\DocumentationTok{\#\# Generieren des Boxplots in ggplot()}
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length, }
                     \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Sprungweite in [cm]"}\NormalTok{, }
       \AttributeTok{fill =} \StringTok{"Tierart"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Hund"}\NormalTok{, }\StringTok{"Katze"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Wir mÃ¼ssen nun folgende Dinge lernen um den Codeblock zu verstehen:

\begin{itemize}
\tightlist
\item
  Wir mÃ¼ssen das Datenbeispiel verstehen. Was sind das eigentlich fÃ¼r
  Daten, die wir da abbilden? Was sind Ã¼berhaupt Daten im Sinne der
  Statistik bzw. fÃ¼r R.
\item
  Wir mÃ¼ssen den R Code verstehen. Von einzelnen wichtigen Operatoren
  wie \texttt{-\textgreater{}} und
  \texttt{\%\textbackslash{}\textgreater{}\%} zu dem den Unterschieden
  von Worten und Objekten.
\item
  Wie kriegen wir Daten aus Excel in R hinein? Wir kÃ¶nnen die Daten ja
  nicht einfach in R eintragen sondern haben die Daten ja meist in einer
  (Excel) Datei wie \texttt{flea\_dog\_cat.xlsx}.
\item
  Was ist eigentlich ein Boxplot und welche statistischen MaÃzahlen
  werden hier eigentlich abgebildet?
\item
  Wie funktioniert eigentlich die Funktionalen \texttt{ggplot()} mit der
  wir den Boxplot erstellt haben?
\end{itemize}

All diese Fragen und weitere Fragen, die sich diesen Fragen anschlieÃen,
wollen wir uns in den nÃ¤chsten Kapitel anschauen. Leider kann ich hier
nur \emph{linear} schreiben. Deshalb musst du eventuell mal ein Kapitel
wiederholen oder etwas quer lesen. Du kannst dir ja auch nicht immer
alles auf einmal merken.

\hypertarget{lernziel-2-rstudio-und-r}{%
\section{Lernziel 2: RStudio und R}\label{lernziel-2-rstudio-und-r}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Was ist eigentlich RStudio und woher kriege ich das?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/krF7TJVb-UA}{EinfÃ¼hrung in
R - Teil 01 - Installation von RStudio und R} als Video. Ich gehe in dem
Video einmal alle wichtigen Schritte durch und so kannst du dir Rstudio
und R installieren.
\end{tcolorbox}

Um Data Science durchfÃ¼hren zu kÃ¶nnen musst du etwas Programmieren
kÃ¶nnen. Wir programmieren in R und nutzen die Software um Abbildungen zu
erstellen und Analysen zu rechnen.

Wir arbeiten in R und nutzen dafÃ¼r das RStudio. FÃ¼hre einfach folgende
Schritte aus um erst R zu installieren und dann das RStudio.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  R installieren unter \url{https://cran.rstudio.com/}
\item
  RStudio installieren unter
  \url{https://www.rstudio.com/products/rstudio/download/\#download}
\end{enumerate}

Bitte die Reihenfolge beachten. Beide Schritte kannst du dir auch
nochmals im Video anschauen oder aber du kommst in das R Tutorium was
regelmÃ¤Ãig an der Hochschule OsnabrÃ¼ck von mir angeboten wird. Die
Termine findest du im Kapitel~\ref{sec-r-tutorium}.

\hypertarget{lernziel-3-falsifikationsprinzip}{%
\section{Lernziel 3:
Falsifikationsprinzip}\label{lernziel-3-falsifikationsprinzip}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Grundlagen der Wissenschaft und Falsifikationsprinzip}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/h45ftLNsspM}{Grundlagen
der Wissenschaft und Falsifikationsprinzip} als Video Reihe.
\end{tcolorbox}

Wie funktioniert ein \emph{statistischer} Versuch? Ich kÃ¶nnte auch
wissenschaftliches Experiment schreiben, aber ein wissenschaftliches
Experiment ist sehr abstrakt. Wir wollen ja einen Versuch durchfÃ¼hren
und danach - ja was eigentlich? Was wollen wir nach dem Versuch haben?
Meistens eine neue Erkenntnis. Um diese Erkenntnis zu validieren oder
aber abzusichern nutzen wir Statistik. Dazu musst du noch wissen, dass
wir eine spezielle Form der Statistik nutzen: die \emph{frequentistische
Statistik}.

{\marginnote{\begin{footnotesize}Eine \textbf{biologische Wiederholung}
beinhaltet ein neues Tier, Pflanze oder Mensch. Eine \textbf{technische}
Wiederholung ist die gleiche Messung an dem gleichen Tier, Pflanze oder
Mensch.\end{footnotesize}}}

{\marginnote{\begin{footnotesize}Wir nennen das \textbf{Outcome} auch
\textbf{Endpunkt}, \textbf{Response} oder kurz
\(y\).\end{footnotesize}}}

Die \emph{frequentistische Statistik} basiert - wie der Name andeutet -
auf Wiederholungen in einem Versuch. Daher der Name frequentistisch.
Also eine Frequenz von Beobachtungen. Ist ein wenig gewollt, aber daran
gewÃ¶hnen wir uns schon mal. Konkret, ein Experiment welches wir
frequentistisch Auswerten wollen besteht immer aus biologischen
Wiederholungen. Wir mÃ¼ssen also ein Experiment planen in dem wir
wiederholt ein Outcome an vielen Tieren, Pflanzen oder Menschen messen.
Auf das Outcome gehen wir noch spÃ¤ter ein. Im Weiteren konzentrieren wir
uns hier auf die \emph{parametrische} Statistik. Die parametrische
Statistik beschÃ¤ftigt sich mit Parametern von Verteilungen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Wie gehen wir nun vor, wenn wir ein Experiment durchfÃ¼hren wollen?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir mÃ¼ssen auf jeden Fall wiederholt ein Outcome an verschiedenen
  Tieren, Pflanzen oder Menschen messen.
\item
  Wir Ã¼berlegen uns aus welcher Verteilungsfamilie unser Outcome stammt,
  damit wir dann die entsprechende Verfahren zur Analyse nehmen kÃ¶nnen.
\end{enumerate}

\end{tcolorbox}

Wenn wir nun ein Experiment durchfÃ¼hren dann erheben wir einmalig Daten
\(D_1\). Wir kÃ¶nnten das Experiment wiederholen und erneut Daten \(D_2\)
erheben. Wir kÃ¶nnen das Experiment \(j\)-mal wiederholen und haben dann
Daten von \(D_1,..., D_j\). Dennoch werden wir nie \emph{alle} Daten
erheben kÃ¶nnen, die mit einem Experiment verbunden sind.

{\marginnote{\begin{footnotesize}\textbf{Strukturgleichkeit} erreichen
wir durch \textbf{Randomisierung}.\end{footnotesize}}}

Nehmen wir das Beispiel, dass wir die Sprungweite von Hunde- und
KatzenflÃ¶hen vergleichen wollen. Wir kÃ¶nnen nicht \emph{alle} Hunde- und
KatzenflÃ¶he messen. Wir kÃ¶nnen nur eine Stichprobe an Daten \(D_1\)
erheben. Ãber diese Daten \(D_1\) kÃ¶nnen wir dann spÃ¤ter durch
statistische Algorithmen eine Aussage treffen. Wichtig ist hier sich zu
merken, dass wir eine Grundgesamtheit haben aus der wir eine Stichprobe
ziehen. Wir mÃ¼ssen darauf achten, dass die Stichprobe
\emph{reprÃ¤sentativ} ist und damit \emph{strukturgleich} zur
Grundgesamtheit ist. Die Strukturgleichkeit erreichen wir durch
Randomisierung. Wir veranschaulichen diesen Zusammenhang in
Abbildung~\ref{fig-grundgesamtheit-schema}. Ein RÃ¼ckschluÃ von der
Stichprobe ist nur mÃ¶glich, wenn die Stichprobe die Grundgesamtheit
reprÃ¤sentiert. Auch eine Randomisierung mag dieses Ziel nicht immer
erreichen. Im Beispiel der HundeflÃ¶he kÃ¶nnte wir eine Art an FlÃ¶hen
Ã¼bersehen und diese Flohart nicht mit in die Stichprobe aufnehmen. Ein
RÃ¼ckschluÃ auf diese Flohart wÃ¤re dann mit unserem Experiment nicht
mÃ¶glich.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/preface-grundgesamtheit.png}

}

\caption{\label{fig-grundgesamtheit-schema}Abbildung Ã¼ber die
Grundgesamtheit und die Stichprobe(n) \(D_1\) bis \(D_j\). Durch
Randomisierung wird Sturkturgleichheit erreicht, die dann einen
RÃ¼ckschluÃ von der Stichprobe auf die Grundgesamtheit erlaubt. Jede
Stichprobe ist anders und nicht jede Randomisierung ist erfolgreich was
die Strukturgleicheit betrifft.}

\end{figure}

Tabelle~\ref{tbl-grundgesamtheit-stichprobe} zeigt nochmal die
Zusammenfassung von der Grundgesamtheit un der Stichprobe im Vergleich.
Wichtig ist zu merken, dass wir mit unserem kleinen Experiment Daten
\(D\) generieren mit denen wir einen RÃ¼ckschluÃ und somit eine
Verallgemeinerung erreichen wollen.

\hypertarget{tbl-grundgesamtheit-stichprobe}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5221}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4779}}@{}}
\caption{\label{tbl-grundgesamtheit-stichprobe}Vergleich von
Grundgesamtheit und Stichprobe.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Grundgesamtheit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stichprobe
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Grundgesamtheit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stichprobe
\end{minipage} \\
\midrule()
\endhead
\ldots{} \(n\) ist riesig bis unfassbar. & \ldots{} \(n\) von \(D\) ist
klein. \\
\ldots{} der Mittelwert wird mit \(\mu_y\) beschrieben. & \ldots{} der
Mittelwert wird mit \(\bar{y}\) beschrieben. \\
\ldots{} die Varianz wird mit \(\sigma^2\) beschrieben. & \ldots{} die
Varianz wird mit \(s^2\) beschrieben. \\
\ldots{} die Standardabweichung wird mit \(\sigma\) beschrieben. &
\ldots{} die Standardabweichung wird mit \(s\) beschrieben. \\
\bottomrule()
\end{longtable}

\part{Datenbeispiele}

\emph{Version vom September 14, 2022 um 08:44:50}

Wir brauchen am Anfang erstmal ein simples Beispiel. Konkrete Zahlen mit
denen wir arbeiten kÃ¶nnen und Grundlagen aufbauen kÃ¶nnen. Was liegt da
nÃ¤her als sich einmal am Kopf zu kratzen und zu fragen, was juckt den
da? Genau! FlÃ¶he. Wir schauen uns einmal FlÃ¶he auf Hunden und Katzen an.
Daran kÃ¶nnen wir viel Ã¼ber Zahlen und Buchstaben in der Statistik und
dann im Programmieren lernen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zahlen, Buchstaben und WÃ¶rter}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Mir ist bewusst, dass du die Unterschiede kennst. Nur leider ist eine
Zahl nicht nur eine Zahl und ein Wort nicht immer ein Wort. Das hat mit
der eingeschrÃ¤nkten KommunikationsfÃ¤higkeit von Computerprogrammen zu
tun. R braucht da deine Mithilfe und dein \emph{neues} VerstÃ¤ndnis von
Buchstaben und Zahlen. Eben wie ein Computer denkt.
\end{tcolorbox}

\hypertarget{von-fluxf6hen-und-hunden}{%
\section*{Von FlÃ¶hen und Hunden}\label{von-fluxf6hen-und-hunden}}
\addcontentsline{toc}{section}{Von FlÃ¶hen und Hunden}

In unserem ersten Beispiel in Kapitel~\ref{sec-example-1} geht es darum
einmal ein GefÃ¼hl fÃ¼r Daten zu kriegen. Also was sind diese Zahlen und
Buchstaben eigentlich? Wie sind Daten aufgebaut und wie musst du Daten
bauen, so dass wir auch mit den Daten arbeiten kÃ¶nnen? Wir schauen uns
dafÃ¼r einmal FlÃ¶he auf Hunden an und fragen uns welche Typen von Zahlen
kÃ¶nnen wir erheben?

\hypertarget{von-fluxf6hen-hunden-und-katzen}{%
\section*{Von FlÃ¶hen, Hunden und
Katzen}\label{von-fluxf6hen-hunden-und-katzen}}
\addcontentsline{toc}{section}{Von FlÃ¶hen, Hunden und Katzen}

In unserem zweiten Beispiel in Kapitel~\ref{sec-example-2} erweitern wir
unserer erstes Beispiel um die Katzen. Das heist, dass eigentlich alles
gleich bleibt. Wir schauen usn \emph{zusÃ¤tlich} noch als zweite Gruppe
die Katzen an. Nun kÃ¶nnen wir die Frage stellen, unterscheiden sich
FlÃ¶he auf Hunden und Katzen gegeben von gemessenen Eigenschaften?

\hypertarget{von-fluxf6hen-auf-tieren}{%
\section*{Von FlÃ¶hen auf Tieren}\label{von-fluxf6hen-auf-tieren}}
\addcontentsline{toc}{section}{Von FlÃ¶hen auf Tieren}

In unserem dritten Beispiel in Kapitel~\ref{sec-example-3} erweitern wir
das Beispiel um den Fuchs mit einem weiteren Tier. Dadurch haben wir
nicht mehr einen Faktor mit zwei Leveln vorliegen sondern einen mit drei
Leveln. Die Fragestrellung erweitert sich jetzt auf einen
\emph{multiplen} Gruppenvergleich. Wir vergleichen nicht mehr nur noch
zwei Gruppen miteinander sondern drei.

\hypertarget{von-fluxf6hen-auf-tieren-in-habitaten}{%
\section*{Von FlÃ¶hen auf Tieren in
Habitaten}\label{von-fluxf6hen-auf-tieren-in-habitaten}}
\addcontentsline{toc}{section}{Von FlÃ¶hen auf Tieren in Habitaten}

In unserem vierten Beispiel in Kapitel~\ref{sec-example-4} schauen wir
uns zusÃ¤tzlich zu dem dritten Beispiel noch verschiedene Habitate (eng.
\emph{site}) an. Wir haben nÃ¤mlich die Hunde-, Katzen-, und FuchsflÃ¶he
nicht nur an einem Ort sondern an verschiedenen Orten gesammelt und
gemessen. Wir haben einen zweiten Faktor vorliegen.

\hypertarget{von-vielen-fluxf6hen-auf-hunden-und-katzen}{%
\section*{Von vielen FlÃ¶hen auf Hunden und
Katzen}\label{von-vielen-fluxf6hen-auf-hunden-und-katzen}}
\addcontentsline{toc}{section}{Von vielen FlÃ¶hen auf Hunden und Katzen}

Im fÃ¼nften Beispiel in Kapitel~\ref{sec-example-5} schauen wir uns
wiederum nur noch zwei Tierarten an: Hunde und Katzen. DafÃ¼r aber eine
groÃe Anzahl an Tieren. Wir schauen uns hier die Daten von 400 Tiere an.
Auf diesen Tierarten messen wir mehrere Variablen unn wollen uns diese
Daten spÃ¤ter in der Regression anschauen.

\hypertarget{gummibuxe4rchen}{%
\section*{GummibÃ¤rchen}\label{gummibuxe4rchen}}
\addcontentsline{toc}{section}{GummibÃ¤rchen}

Im Beispiel mit den GummibÃ¤rchen in Kapitel~\ref{sec-example-gummibears}
geht es um die Darstellung verschiedener Verteilungen. Wir brauchen den
Datensatz um zu verstehen, wie Daten verteilt sind. Sonst kÃ¶nnen wir den
Datensatz auch gut nutzen um einmal in R zu filtern und zu selektieren.
Auch fÃ¼r die Erstellung von Abbilungen eignet sich der Datensatz sehr
gut.

\hypertarget{sec-example-1}{%
\chapter{Von FlÃ¶hen und Hunden}\label{sec-example-1}}

\emph{Version vom September 14, 2022 um 08:44:58}

In unserem ersten Beispiel wollen wir uns verschiedene Daten \(D\) von
Hunden und HundeflÃ¶hen anschauen. Unter anderem sind dies die
Sprungweite, die Anzahl an FlÃ¶hen, die Boniturnoten auf einer Hundemesse
sowie der Infektionsstatus. Hier nochmal detailiert, was wir uns im
folgenden im Kapitel einmal anschauen wollen.

\begin{itemize}
\item
  \textbf{Sprungweite} in {[}cm{]} von verschiedenen FlÃ¶hen \[
  Y_{jump} = \{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\}.
  \]
\item
  \textbf{Anzahl an FlÃ¶hen} auf verschiedenen Hunden \[
    Y_{count} = \{18, 22, 17, 12, 23, 18, 21\}.
    \]
\item
  \textbf{Boniturnoten} {[}1 = schlechteste bis 9 = beste Note{]} von
  verschiedenen Hunden \[
    Y_{grade} = \{8, 8, 6, 8, 7, 7, 9\}.
    \]
\item
  \textbf{Infektionstatus} {[}0 = gesund, 1 = infiziert{]} mit FlÃ¶hen
  von verschiedenen Hunden \[
    Y_{infected} = \{0, 1, 1, 0, 1, 0, 0\}.
    \]
\end{itemize}

Je nachdem was wir messen, nimmt \(Y\) andere ZahlenrÃ¤ume an. Wir sagen,
\(Y\) folgt einer Verteilung. Die Sprungweite ist normalverteilt, die
Anzahl an FlÃ¶hen folgt einer Poisson Verteilung, die Boniturnoten sind
multinominal/ordinal bzw. kategorial verteilt. Der Infektionsstatus ist
binomial verteilt. Wir werden uns spÃ¤ter die Verteilungen anschauen und
visualisieren. Das kÃ¶nnen wir hier aber noch nicht. Wichtig ist, dass du
schon mal gehÃ¶rt hast, dass \(Y\) unterschiedlich \emph{verteilt} ist,
je nachdem welche Dinge wir messen.

Tabelle~\ref{tbl-dog-long} zeigt dir die Darstellung der Daten von oben
in einer einzigen Tabelle. Bitte bachte, dass genau eine Zeile fÃ¼r eine
Beobachutng, in diesem Fall einem Hund, vorgesehen ist.

\hypertarget{tbl-dog-long}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-dog-long}SprunglÃ¤ngen {[}cm{]} fÃ¼r HundeflÃ¶he. Die
Tabelle ist im Long-Format dargestellt.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
\bottomrule()
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von FlÃ¶hen und Hunden}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{flea\_dog.xlsx} auf GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV.
\end{tcolorbox}

\hypertarget{sec-example-2}{%
\chapter{Von FlÃ¶hen, Hunden und Katzen}\label{sec-example-2}}

\emph{Version vom September 14, 2022 um 08:45:07}

Wir wollen jetzt das Beispiel von den Hunden und FlÃ¶hen um eine Spezies
erweitern. Wir nehmen noch die Katzen mit dazu und fragen uns, wie sieht
es mit der SprungfÃ¤higkeit von Katzen und HundeflÃ¶hen aus? Konzentrieren
wir uns hier einmal auf die Sprungweite. Wir kÃ¶nnen wie in dem
vorherigen Beispiel mit den HundeflÃ¶hen die Sprungweiten {[}cm{]} der
KatzenflÃ¶he wieder in der gleichen Weiese aufschreiben:

\[
Y_{jump} = \{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\}.
\]

Wenn wir jetzt die Sprungweiten der HundeflÃ¶he mit den KatzenflÃ¶hen
vergleichen wollen haben wir ein Problem. Beide Zahlenvektoren heiÃen
gleich, nÃ¤mlich \(Y_{jump}\). Wir kÃ¶nnten jeweils in die Indizes noch
\(dog\) und \(cat\) schreiben als \(Y_{jump,\, dog}\) und
\(Y_{jump,\, cat}\) und erhalten folgende Vektoren.

\[
Y_{jump,\, dog} = \{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\}
\]

\[
Y_{jump,\, cat} = \{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\}
\]

Dadurch werden die Indizes immer lÃ¤nger und unÃ¼bersichticher. Auch das
\(Y\) einfach \(Y_{dog}\) oder \(Y_{cat}\) zu nennen ist keine LÃ¶sung -
wir wollen uns vielleicht spÃ¤ter nicht nur die Sprungweite vergleichen,
sondern vielleicht auch die Anzahl an FlÃ¶hen oder den Infektionsstatus.
Dann stÃ¤nden wir wieder vor dem Problem die \(Y\) fÃ¼r die verschiedenen
Outcomes zu unterscheiden. Daher erstellen wir uns die
Tabelle~\ref{tbl-dog-cat-wide}. Wir haben jetzte eine
\emph{Daten}tabelle.

\hypertarget{tbl-dog-cat-wide}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-dog-cat-wide}SprunglÃ¤ngen {[}cm{]} fÃ¼r Hunde- und
KatzenflÃ¶he. Die Tabelle ist im Wide-Format dargestellt.}\tabularnewline
\toprule()
dog & cat \\
\midrule()
\endfirsthead
\toprule()
dog & cat \\
\midrule()
\endhead
5.7 & 3.2 \\
8.9 & 2.2 \\
11.8 & 5.4 \\
8.2 & 4.1 \\
5.6 & 4.3 \\
9.1 & 7.9 \\
7.6 & 6.1 \\
\bottomrule()
\end{longtable}

Intuitiv ist die Tabelle~\ref{tbl-dog-cat-wide} Ã¼bersichtlich und
beinhaltet die Informationen die wir wollten. Dennoch haben wir das
Probem, das wir in dieser Tabelle~\ref{tbl-dog-cat-wide} nicht noch
weitere Outcomes angeben kÃ¶nnen. Wir kÃ¶nnen die Anzahl an FlÃ¶hen auf den
Hunde und Katzen nicht darstellen. Als LÃ¶sung Ã¤ndern wir die
Tabelle~\ref{tbl-dog-cat-wide} in das Long-Format. Dargestellt in
Tabelle~\ref{tbl-dog-cat-long}. Jede Beobachtung belegt nun eine Zeile.
Dies ist sehr wichtig im Kopf zu behalten, wenn du eigene Daten in z.B.
Excel eingibts.

\hypertarget{tbl-dog-cat-long}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-dog-cat-long}Tabelle der SprunglÃ¤ngen {[}cm{]},
Anzahl an FlÃ¶hen, Boniturnote sowie der Infektionsstatus von Hunde- und
KatzenflÃ¶he. Die Tabelle ist im Long-Format dargestellt.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
cat & 3.2 & 12 & 7 & 1 \\
cat & 2.2 & 13 & 5 & 0 \\
cat & 5.4 & 11 & 7 & 0 \\
cat & 4.1 & 12 & 6 & 0 \\
cat & 4.3 & 16 & 6 & 1 \\
cat & 7.9 & 9 & 6 & 0 \\
cat & 6.1 & 7 & 5 & 0 \\
\bottomrule()
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von FlÃ¶hen, Hunden und Katzen}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{flea\_dog\_cat.xlsx} auf GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV.
\end{tcolorbox}

\hypertarget{sec-example-3}{%
\chapter{Von FlÃ¶hen auf Tieren}\label{sec-example-3}}

\emph{Version vom September 14, 2022 um 08:45:16}

Wir wollen jetzt das Beispiel von den Hunde- und KatzenflÃ¶hen um eine
\emph{weitere} Spezies erweitern. Wir nehmen noch die FÃ¼chse mit dazu
und fragen uns, wie sieht es mit der SprungfÃ¤higkeit von Hunde-, Katzen-
und FuchsflÃ¶hen aus?

\hypertarget{tbl-dog-cat-fox}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-dog-cat-fox}SprunglÃ¤ngen {[}cm{]} fÃ¼r Hunde-,
Katzen- und FuchsflÃ¶he.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
cat & 3.2 & 12 & 7 & 1 \\
cat & 2.2 & 13 & 5 & 0 \\
cat & 5.4 & 11 & 7 & 0 \\
cat & 4.1 & 12 & 6 & 0 \\
cat & 4.3 & 16 & 6 & 1 \\
cat & 7.9 & 9 & 6 & 0 \\
cat & 6.1 & 7 & 5 & 0 \\
fox & 7.7 & 21 & 5 & 1 \\
fox & 8.1 & 25 & 4 & 1 \\
fox & 9.1 & 31 & 4 & 1 \\
fox & 9.7 & 12 & 5 & 1 \\
fox & 10.6 & 28 & 4 & 0 \\
fox & 8.6 & 18 & 4 & 1 \\
fox & 10.3 & 19 & 3 & 0 \\
\bottomrule()
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von FlÃ¶hen auf Tieren}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{flea\_dog\_cat\_fox.xlsx} auf GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV.
\end{tcolorbox}

\hypertarget{sec-example-4}{%
\chapter{Von FlÃ¶hen auf Tieren in Habitaten}\label{sec-example-4}}

\emph{Version vom September 14, 2022 um 08:45:27}

Wir schauen uns in diesem Beispiel wiederum drei Tierarten an: Hunde,
Katzen und FÃ¼chse. Auf diesen Tierarten messen wir die SprunglÃ¤nge von
jeweils zehn Tieren. Im Vergleich zu dem vorherigen Beispiel erweitern
wir die Daten um eine Spalte \texttt{site} in der wir vier verschiedene
Messorte protokollieren. Es ergibt sich folgende
Tabelle~\ref{tbl-example-4} und die dazugehÃ¶rige
Abbildung~\ref{fig-example-4}.

\hypertarget{tbl-example-4}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-example-4}SprunglÃ¤ngen {[}cm{]} fÃ¼r Hunde-, Katzen-
und FuchsflÃ¶he in verschiedenen Habitaten.}\tabularnewline
\toprule()
animal & site & rep & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & site & rep & jump\_length \\
\midrule()
\endhead
cat & city & 1 & 12.04 \\
cat & city & 2 & 11.98 \\
cat & city & 3 & 16.10 \\
cat & city & 4 & 13.42 \\
cat & city & 5 & 12.37 \\
cat & city & 6 & 16.36 \\
cat & city & 7 & 14.91 \\
cat & city & 8 & 11.17 \\
cat & city & 9 & 12.38 \\
cat & city & 10 & 15.06 \\
cat & smalltown & 1 & 15.24 \\
cat & smalltown & 2 & 13.36 \\
cat & smalltown & 3 & 15.08 \\
cat & smalltown & 4 & 12.83 \\
cat & smalltown & 5 & 14.68 \\
cat & smalltown & 6 & 10.73 \\
cat & smalltown & 7 & 13.35 \\
cat & smalltown & 8 & 14.54 \\
cat & smalltown & 9 & 12.99 \\
cat & smalltown & 10 & 14.51 \\
cat & village & 1 & 17.59 \\
cat & village & 2 & 11.24 \\
cat & village & 3 & 12.44 \\
cat & village & 4 & 13.63 \\
cat & village & 5 & 14.92 \\
cat & village & 6 & 17.43 \\
cat & village & 7 & 18.30 \\
cat & village & 8 & 16.35 \\
cat & village & 9 & 16.34 \\
cat & village & 10 & 14.23 \\
cat & field & 1 & 13.70 \\
cat & field & 2 & 15.13 \\
cat & field & 3 & 17.99 \\
cat & field & 4 & 14.60 \\
cat & field & 5 & 16.16 \\
cat & field & 6 & 14.26 \\
cat & field & 7 & 15.39 \\
cat & field & 8 & 16.85 \\
cat & field & 9 & 19.02 \\
cat & field & 10 & 18.76 \\
dog & city & 1 & 19.35 \\
dog & city & 2 & 17.10 \\
dog & city & 3 & 19.85 \\
dog & city & 4 & 15.33 \\
dog & city & 5 & 15.15 \\
dog & city & 6 & 19.57 \\
dog & city & 7 & 15.44 \\
dog & city & 8 & 16.09 \\
dog & city & 9 & 15.91 \\
dog & city & 10 & 13.01 \\
dog & smalltown & 1 & 17.72 \\
dog & smalltown & 2 & 17.11 \\
dog & smalltown & 3 & 17.57 \\
dog & smalltown & 4 & 17.12 \\
dog & smalltown & 5 & 16.02 \\
dog & smalltown & 6 & 22.61 \\
dog & smalltown & 7 & 16.49 \\
dog & smalltown & 8 & 18.64 \\
dog & smalltown & 9 & 17.21 \\
dog & smalltown & 10 & 19.90 \\
dog & village & 1 & 16.60 \\
dog & village & 2 & 15.28 \\
dog & village & 3 & 16.91 \\
dog & village & 4 & 15.08 \\
dog & village & 5 & 18.56 \\
dog & village & 6 & 16.34 \\
dog & village & 7 & 17.61 \\
dog & village & 8 & 14.80 \\
dog & village & 9 & 17.52 \\
dog & village & 10 & 16.93 \\
dog & field & 1 & 15.78 \\
dog & field & 2 & 17.02 \\
dog & field & 3 & 15.41 \\
dog & field & 4 & 15.61 \\
dog & field & 5 & 19.87 \\
dog & field & 6 & 19.24 \\
dog & field & 7 & 17.65 \\
dog & field & 8 & 18.83 \\
dog & field & 9 & 17.60 \\
dog & field & 10 & 14.67 \\
fox & city & 1 & 19.50 \\
fox & city & 2 & 18.49 \\
fox & city & 3 & 19.78 \\
fox & city & 4 & 19.45 \\
fox & city & 5 & 21.56 \\
fox & city & 6 & 21.37 \\
fox & city & 7 & 18.64 \\
fox & city & 8 & 20.08 \\
fox & city & 9 & 21.62 \\
fox & city & 10 & 20.68 \\
fox & smalltown & 1 & 19.81 \\
fox & smalltown & 2 & 17.78 \\
fox & smalltown & 3 & 19.65 \\
fox & smalltown & 4 & 16.38 \\
fox & smalltown & 5 & 17.46 \\
fox & smalltown & 6 & 17.02 \\
fox & smalltown & 7 & 19.38 \\
fox & smalltown & 8 & 15.89 \\
fox & smalltown & 9 & 17.15 \\
fox & smalltown & 10 & 17.43 \\
fox & village & 1 & 15.32 \\
fox & village & 2 & 17.59 \\
fox & village & 3 & 15.70 \\
fox & village & 4 & 18.58 \\
fox & village & 5 & 16.85 \\
fox & village & 6 & 18.25 \\
fox & village & 7 & 18.75 \\
fox & village & 8 & 16.96 \\
fox & village & 9 & 13.38 \\
fox & village & 10 & 18.38 \\
fox & field & 1 & 16.85 \\
fox & field & 2 & 13.55 \\
fox & field & 3 & 13.89 \\
fox & field & 4 & 15.67 \\
fox & field & 5 & 16.38 \\
fox & field & 6 & 14.59 \\
fox & field & 7 & 14.03 \\
fox & field & 8 & 13.63 \\
fox & field & 9 & 14.09 \\
fox & field & 10 & 15.52 \\
\bottomrule()
\end{longtable}

{\marginnote{\begin{footnotesize}Ãber die explorative Datenanalyse
erfÃ¤hrst du mehr im Kapitel~\ref{sec-eda-ggplot}\end{footnotesize}}}

Die Datentabelle ist in dieser Form schon fast nicht mehr Ã¼berschaubar.
Daher hilft hier die explorative Datenanalyse weiter. Wir schauen uns
daher die Daten einmal als einen Boxplot in
Abbildung~\ref{fig-example-4} an. Wir sehen hier, dass wir drei
Tierarten an vier Orten die Sprungweite in {[}cm{]} gemessen haben.

\begin{figure}

{\centering \includegraphics{./example-fleas-dogs-cats-foxes-site_files/figure-pdf/fig-example-4-1.pdf}

}

\caption{\label{fig-example-4}Boxplot der Sprungweiten {[}cm{]} fÃ¼r
Hunde-, Katzen- und FuchsflÃ¶he in verschiedenen Habitaten.}

\end{figure}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von FlÃ¶hen auf Tieren in Habitaten}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{flea\_dog\_cat\_fox\_site.xlsx} auf GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV.
\end{tcolorbox}

\hypertarget{sec-example-5}{%
\chapter{Von vielen FlÃ¶hen auf Hunden und Katzen}\label{sec-example-5}}

\emph{Version vom September 14, 2022 um 08:45:38}

Wir schauen uns in diesem Beispiel wiederum nur zwei Tierarten an: Hunde
und Katzen. Auf diesen Tierarten messen wir wieder die SprunglÃ¤nge in
{[}cm{]} von jeweils 400 Tieren. Im Vergleich zu dem vorherigen Beispiel
erweitern wir die Daten um eine Spalte \texttt{jump\_weight} in {[}mg{]}
sowie \texttt{sex} {[}male, female{]}. Bei Versuch wurde noch in der
Variable \texttt{hatch\_time} gemessen, wie lange die FlÃ¶he in Stunden
zum SchlÃ¼mpfen brauchen. Es ergibt sich folgende
Tabelle~\ref{tbl-example-5} mit den ersten zehn Beobachtungen und die
dazugehÃ¶rige Abbildung~\ref{fig-example-5}.

\hypertarget{tbl-example-5}{}
\begin{longtable}[]{@{}cccccc@{}}
\caption{\label{tbl-example-5}SprunglÃ¤ngen {[}cm{]}, Gewichte {[}mg{]},
Geschecht {[}sex{]} und SchlÃ¼pfzeit {[}h{]} fÃ¼r Hunde- und
KatzenflÃ¶he.}\tabularnewline
\toprule()
animal & sex & weight & jump\_length & flea\_count & hatch\_time \\
\midrule()
\endfirsthead
\toprule()
animal & sex & weight & jump\_length & flea\_count & hatch\_time \\
\midrule()
\endhead
cat & male & 6.02 & 15.79 & 5 & 483.60 \\
cat & male & 5.99 & 18.33 & 1 & 82.56 \\
cat & male & 8.05 & 17.58 & 1 & 296.73 \\
cat & male & 6.71 & 14.09 & 3 & 140.90 \\
cat & male & 6.19 & 18.22 & 1 & 162.20 \\
cat & male & 8.18 & 13.49 & 1 & 167.47 \\
cat & male & 7.46 & 16.28 & 1 & 291.20 \\
cat & male & 5.58 & 14.54 & 0 & 112.58 \\
cat & male & 6.19 & 16.36 & 1 & 143.97 \\
cat & male & 7.53 & 15.08 & 1 & 766.31 \\
\bottomrule()
\end{longtable}

{\marginnote{\begin{footnotesize}Ãber die explorative Datenanalyse
erfÃ¤hrst du mehr im Kapitel~\ref{sec-eda-ggplot}\end{footnotesize}}}

Die Datentabelle ist in dieser Form schon fast nicht mehr Ã¼berschaubar.
Daher hilft hier die explorative Datenanalyse weiter. Wir schauen uns
daher die Daten einmal als einen Scatterplot in
Abbildung~\ref{fig-example-5} an. Wir sehen hier, dass wir das mit dem
Gewicht {[}mg{]} der FlÃ¶he auch die Sprungweite in {[}cm{]} steigt.

\begin{figure}

{\centering \includegraphics{./example-fleas-dogs-cats-length-weight_files/figure-pdf/fig-example-5-1.pdf}

}

\caption{\label{fig-example-5}Scatterplot der SprunglÃ¤ngen {[}cm{]} und
Gewichte {[}mg{]} fÃ¼r Hunde- und KatzenflÃ¶he.}

\end{figure}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von vielen FlÃ¶hen auf Hunden und Katzen}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{flea\_dog\_cat\_length\_weight.xlsx} auf
GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV.
\end{tcolorbox}

\hypertarget{sec-example-gummibears}{%
\chapter{GummibÃ¤rchen}\label{sec-example-gummibears}}

\emph{Version vom September 14, 2022 um 08:45:45}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{GummibÃ¤rchen Daten und die explorative Datenanalyse}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube die
\href{https://youtu.be/gEwOmvWvdxo}{GummibÃ¤rchen Daten und die
explorative Datenanalyse} als Video. Vielleicht interessiert es dich mal
so eine Auswertung im Video anzuschauen.
\end{tcolorbox}

\marginnote{\begin{footnotesize}

Wenn dich der Ablauf technisch interssiert findet du unter Kruppa und
Sieg (2021) mehr Informationen dazu.

\end{footnotesize}}

Im Folgenden sehen wir in Tabelle~\ref{tbl-gummi} den GummibÃ¤rchen
Datensatz, der im Laufe der letzten Jahre entstanden ist. Dabei wÃ¤chst
der Datensatz von Semester zu Semester immer ein wenig weiter. Jedes
Semester darf TÃ¼tchen aufreiÃen und schauen was da so drin ist.

\hypertarget{tbl-gummi}{}
\begin{table*}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0397}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.1788}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0596}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0662}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0530}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0530}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0464}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0464}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0861}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0861}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0795}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0530}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0331}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0530}}
  >{\centering\arraybackslash}p{(\columnwidth - 28\tabcolsep) * \real{0.0662}}@{}}
\caption{\label{tbl-gummi}Auszug aus dem Daten zu den
GummibÃ¤rchendaten.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
year
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
module
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
darkred
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
lightred
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
orange
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
yellow
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
green
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
white
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
count\_bears
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
count\_color
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
most\_liked
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
gender
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
age
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
height
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
semester
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
year
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
module
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
darkred
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
lightred
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
orange
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
yellow
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
green
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
white
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
count\_bears
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
count\_color
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
most\_liked
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
gender
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
age
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
height
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
semester
\end{minipage} \\
\midrule()
\endhead
2018 & NA & 0 & 0 & 5 & 4 & 0 & 0 & 9 & 3 & lightred & m & 35 & 193 &
10 \\
2018 & NA & 0 & 3 & 1 & 4 & 1 & 1 & 10 & 5 & yellow & w & 21 & 159 &
6 \\
2018 & NA & 1 & 2 & 2 & 2 & 1 & 1 & 9 & 6 & white & w & 21 & 159 & 6 \\
2018 & NA & 2 & 0 & 2 & 1 & 2 & 3 & 10 & 5 & white & w & 36 & 180 &
10 \\
2018 & NA & 2 & 1 & 1 & 2 & 2 & 2 & 10 & 6 & white & m & 22 & 180 & 3 \\
2018 & NA & 2 & 4 & 1 & 2 & 0 & 1 & 10 & 5 & white & m & NA & NA & NA \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} &
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} &
\ldots{} & \ldots{} & \ldots{} \\
2022 & Fakultaetsinformationstag & 2 & 1 & 1 & 2 & 4 & 2 & 12 & 5 &
darkred & w & 46 & 165 & 0 \\
2022 & Fakultaetsinformationstag & 2 & 0 & 0 & 5 & 0 & 3 & 10 & 2 &
darkred & w & 55 & 177 & 0 \\
2022 & Fakultaetsinformationstag & 2 & 2 & 2 & 2 & 0 & 1 & 9 & 5 & green
& w & 46 & 173 & 0 \\
2022 & Fakultaetsinformationstag & 4 & 1 & 1 & 1 & 1 & 4 & 12 & 6 &
white & w & 21 & 168 & 0 \\
2022 & Fakultaetsinformationstag & 1 & 0 & 1 & 2 & 2 & 2 & 8 & 5 & green
& m & 24 & 183 & 0 \\
2022 & Fakultaetsinformationstag & 0 & 3 & 2 & 1 & 0 & 2 & 9 & 5 &
darkred & w & 21 & 171 & 0 \\
\bottomrule()
\end{longtable}

\end{table*}

Wir erheben folgende Variablen im Datensatz. Dabei unterscheiden wir
einmal in Daten, die technischer Natur sind:

\begin{itemize}
\tightlist
\item
  \textbf{year}, das Jahr in dem die Daten erhoben wurden.
\item
  \textbf{module}, das Module in welchem die Daten erhoben wurden. Am
  Anfang wurde das Modul noch nicht erfasst.
\item
  \textbf{darkred} bis \textbf{white}, die Anzahl an GummibÃ¤rchen in der
  jeweiligen Farbe.
\item
  \textbf{count\_bears}, die Anzahl an GummibÃ¤rchen in der
  entsprechenden TÃ¼te.
\item
  \textbf{count\_color}, die Anzahl an Farben und damit
  Geschmacksrichtungen in einer TÃ¼te.
\end{itemize}

Dann wollen wir aber auch noch etwas Ã¼ber den Studierenden wissen, der
die TÃ¼te aufgemacht hat. Wir erheben hier noch einge demographische
Informationen:

\begin{itemize}
\tightlist
\item
  \textbf{most\_liked}, der Lieblingsgeschmack des Studierenden.
\item
  \textbf{gender}, das Geschlecht des Studierenden. Aktuell gibt es nur
  mÃ¤nnlich oder weiblich Studierende.
\item
  \textbf{age}, das Alter in Jahren {[}y{]} der Studierenden.
\item
  \textbf{height}, die KÃ¶rpergrÃ¶Ãe des Studierenden in {[}cm{]}
\item
  \textbf{semester}, das aktuelle Semester des Studierenden. Wir
  unterscheiden nicht zwischen Bachelor und Master
\end{itemize}

Aktuell hat der Datensatz \(n = 315\) Beobachtungen. Da der Datensatz
aber immer weiter wÃ¤chst brauchen wir wirklich R dazu um den Datensatz
uns anschauen zu kÃ¶nnen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Datei fÃ¼r von FlÃ¶hen, Hunden und Katzen}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest die Datei \texttt{gummibears.xlsx} auf GitHub
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel Datei.
\end{tcolorbox}

\hypertarget{referenzen-1}{%
\section*{Referenzen}\label{referenzen-1}}
\addcontentsline{toc}{section}{Referenzen}

\part{Programmieren in R}

\emph{Version vom September 14, 2022 um 08:45:52}

Was solltest du nun zuerst Lesen? Es ist sehr schwierig die
Programmierung exakt so zu schreiben, dass das Programmieren
\emph{linear} verstÃ¤ndlich ist. Du brauchst im Prinzip das Wissen aus
Kapitel~\ref{sec-basics} \emph{Operatoren, Funktionen und Pakete} um die
Grundlagen zu verstehen. Auf der anderen Seite fehlt dir vielleicht noch
das VerstÃ¤ndnis von Buchstaben und Zahlen in R. Diesen Zusammenhang
zwischen Buchstaben und Zahlen erklÃ¤re ich als erstes im folgenden
Kapitel~\ref{sec-letter-number} \emph{Von Buchstaben und Zahlen}.

Im vorherigen Kapitel zu den Beispielen haben wir die Datentabelle
Tabelle~\ref{tbl-dog-cat-long} mit den Hunde- und KatzenflÃ¶hen
erschaffen. Bevor wir uns weiter mit statistischen Kennzahlen
beschÃ¤ftigen, wollen wir uns einmal die Realisierung der Tabelle
Tabelle~\ref{tbl-dog-cat-long} mit den Hunde- und KatzenflÃ¶hen in R
anschauen. Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben
lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu
kÃ¶nnen. Wir wollen spÃ¤ter R nutzen um die explorative Datenanalyse
anzuwenden. Ãber die explorative Datenanalyse lernen wir in spÃ¤teren
Kapiteln mehr.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in R per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube
\href{https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC}{Grundlagen
in R} als Video Reihe. Ich werde zwar alles nochmal hier als Text
aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

\hypertarget{sec-letter-number}{%
\chapter{Von Buchstaben und Zahlen}\label{sec-letter-number}}

\emph{Version vom September 14, 2022 um 08:45:59}

Im Kapitel~\ref{sec-example-2} haben wir uns die Sprungweiten und andere
Eigenschaften von Hunden und Katzen angeschaut. Bevor wir uns weiter mit
statistischen Kennzahlen beschÃ¤ftigen, wollen wir uns einmal die
Realisierung der Tabelle~\ref{tbl-dog-cat-letter} in R anschauen. Das
heist, wie ist eine Tabelle in R aufgebaut und was sehen wir da
eigentlich?

\hypertarget{tbl-dog-cat-letter}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-dog-cat-letter}SprunglÃ¤ngen {[}cm{]} fÃ¼r Hunde- und
KatzenflÃ¶he.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & FALSE \\
dog & 8.9 & 22 & 8 & TRUE \\
dog & 11.8 & 17 & 6 & TRUE \\
dog & 8.2 & 12 & 8 & FALSE \\
dog & 5.6 & 23 & 7 & TRUE \\
dog & 9.1 & 18 & 7 & FALSE \\
dog & 7.6 & 21 & 9 & FALSE \\
cat & 3.2 & 12 & 7 & TRUE \\
cat & 2.2 & 13 & 5 & FALSE \\
cat & 5.4 & 11 & 7 & FALSE \\
cat & 4.1 & 12 & 6 & FALSE \\
cat & 4.3 & 16 & 6 & TRUE \\
cat & 7.9 & 9 & 6 & FALSE \\
cat & 6.1 & 7 & 5 & FALSE \\
\bottomrule()
\end{longtable}

Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen,
die notwendig sind um mit einem Programm wie R kommunizieren zu kÃ¶nnen.
Nun haben wir in der Tabelle~\ref{tbl-dog-cat-letter} mit Daten zu
verschiedenen Oucomes, wie Sprungweite {[}cm{]}, Anzahl an FlÃ¶hen auf
Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus. Die
Tabelle ist zwar nicht groÃ aber auch nicht wirklich klein. Wir wollen
uns nun damit beschÃ¤ftigen, die Zahlen sinnvoll in R darzustellen. Wir
wollen mit der Darstellung einer Datentabelle in R beginnen, einem
\texttt{tibble()}.

\hypertarget{daten-in-r-sind-tibble}{%
\section{\texorpdfstring{Daten in R sind
\texttt{tibble()}}{Daten in R sind tibble()}}\label{daten-in-r-sind-tibble}}

Im folgenden sehen wir die Daten aus der
Tabelle~\ref{tbl-dog-cat-letter} in R als \texttt{tibble} dargestellt.
Was ist nun ein \texttt{tibble}? Ein \texttt{tibble} ist zu aller erst
ein Speicher fÃ¼r Daten in R. Das heist wir haben Spalten und Zeilen.
Jede Spalte reprÃ¤sentiert eine Messung oder Variable und die Zeilen
jeweils eine Beobachtung.

\begin{verbatim}
# A tibble: 14 x 5
   animal jump_length flea_count grade infected
   <chr>        <dbl>      <int> <dbl> <lgl>   
 1 dog            5.7         18     8 FALSE   
 2 dog            8.9         22     8 TRUE    
 3 dog           11.8         17     6 TRUE    
 4 dog            8.2         12     8 FALSE   
 5 dog            5.6         23     7 TRUE    
 6 dog            9.1         18     7 FALSE   
 7 dog            7.6         21     9 FALSE   
 8 cat            3.2         12     7 TRUE    
 9 cat            2.2         13     5 FALSE   
10 cat            5.4         11     7 FALSE   
11 cat            4.1         12     6 FALSE   
12 cat            4.3         16     6 TRUE    
13 cat            7.9          9     6 FALSE   
14 cat            6.1          7     5 FALSE   
\end{verbatim}

Als erstes erfahren wir, dass wir einen \texttt{A\ tibble:\ 14\ x\ 5}
vorliegen haben. Das heist, wir haben 14 Zeile und 5 Spalten. In einem
\texttt{tibble} wird immer in der ersten Zeile angezeigt wieviele
Beobachtungen wir in dem Datensatz haben. Wenn das \texttt{tibble} zu
groÃ wird, werden wir nicht mehr das ganze \texttt{tibble} sehen sondern
nur noch einen Ausschnitt. Im Weiteren hat jede Spalte noch eine
Eigenschaft unter dem Spaltennamen:

\begin{itemize}
\tightlist
\item
  \texttt{\textless{}chr\textgreater{}} bedeutet \texttt{character}. Wir
  haben also hier Worte vorliegen.
\item
  \texttt{\textless{}dbl\textgreater{}} bedeutet \texttt{double}. Ein
  \texttt{double} ist eine Zahl mit Kommastellen.
\item
  \texttt{\textless{}int\textgreater{}} bedeutet \texttt{integer}. Ein
  \texttt{integer} ist eine ganze Zahl ohne Kommastellen.
\item
  \texttt{\textless{}lgl\textgreater{}} bedeutet \texttt{logical} oder
  \texttt{boolean}. Hier gibt es nur die AusprÃ¤gung \emph{wahr} oder
  \emph{falsch}. Somit \texttt{TRUE} oder \texttt{FALSE}. Statt den
  Worten \texttt{TRUE} oder \texttt{FALSE} kann hier auch 0 oder 1
  stehen.
\item
  \texttt{\textless{}str\textgreater{}} bedeutet \texttt{string} der aus
  verschiedenen \texttt{character} besteht kann, getrennt durch
  Leerzeichen.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Zahlen, Buchstaben, Skalenniveau - Was ist das eigentlich?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/OnRaSmybhOQ}{EinfÃ¼hrung in
R - Teil 06 - Zahlen, Buchstaben, Skalenniveau - Was ist das
eigentlich?} als Video. Hier erklÃ¤re ich den Zusammenhang nochmal in
einem Video.
\end{tcolorbox}

\hypertarget{faktoren-als-wuxf6rter-zu-zahlen}{%
\section{Faktoren als WÃ¶rter zu
Zahlen}\label{faktoren-als-wuxf6rter-zu-zahlen}}

{\marginnote{\begin{footnotesize}Ein \textbf{Faktor} ist eine Variable
mit mehrern \textbf{Faktorstufen} oder \textbf{Leveln}. FÃ¼r uns sieht
der Faktor wie ein Wort aus, hinter jedem Wort steht aber eine Zahl mit
der gerechnet werden kann.\end{footnotesize}}}

Ein Computer und somit auch eine Programmsprache wie R kann keine
Buchstaben \emph{verrechnen}. Ein Programm kann nur mit Zahlen rechnen.
Wir haben aber in der Tabelle~\ref{tbl-dog-cat-letter} in der Spalte
\texttt{animal} Buchstaben stehen. Da wir hier einen Kompromiss eingehen
mÃ¼ssen fÃ¼hren wir Faktoren ein. Ein Faktor kombiniert Buchstaben mit
Zahlen. Wir als Anwender sehen die Buchstaben, die WÃ¶rter bilden. Intern
steht aber jedes Wort fÃ¼r eine Zahl, so dass R mit den Zahlen rechnen
kann. Klingt ein wenig kryptisch, aber wir schauen uns einen
\texttt{factor} einmal an.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl}\SpecialCharTok{$}\NormalTok{animal[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog" "dog" "dog" "dog" "dog" "dog" "dog" "cat"
\end{verbatim}

Was haben wir gemacht? Als erstes haben wir die Spalte \texttt{animal}
aus dem Datensatz \texttt{data\_tbl} mit dem Dollarzeichen \texttt{\$}
\emph{herausgezogen}. Mit dem \texttt{\$} Zeichen kÃ¶nnen wir uns eine
einzelne Spalte aus dem Datensatz \texttt{data\_tbl} rausziehen. Du
kannst dir das \texttt{\$} wie einen KleiderbÃ¼gel und das
\texttt{data\_tbl} als einen Schrank fÃ¼r KleiderbÃ¼gel verstellen. An dem
KleiderbÃ¼gel hÃ¤ngen dann die einzelnen Zahlen und Worte. Wir nehmen aber
nicht den ganzen Vektor sondern nur die Zahlen 1 bis 8, dargestellt
durch \texttt{{[}1:8{]}}. Die GÃ¤nsefÃ¼Ãe \texttt{"} um \texttt{dog}
zeigen uns, dass wir hier WÃ¶rter oder \texttt{character}vorliegen haben.
Schauen wir auf das Ergebnis, so erhalten wir sieben Mal \texttt{dog}
und einmal \texttt{cat}. Insgesamt die ersten acht EintrÃ¤ge der
Datentabelle. Wir wollen diesen Vektor uns nun einmal als Faktor
anschauen. Wir nutzen die Funktion \texttt{as\_factor()}.
{\marginnote{\begin{footnotesize}Ãber Funktionen kannst du im
Kapitel~\ref{sec-R-function} mehr erfahren.\end{footnotesize}}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.factor}\NormalTok{(data\_tbl}\SpecialCharTok{$}\NormalTok{animal[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] dog dog dog dog dog dog dog cat
Levels: cat dog
\end{verbatim}

Im direkten vergleich verschwinden die GÃ¤nsefÃ¼Ãe \texttt{"} um
\texttt{dog} und zeigen usn, dass wir hier keine \texttt{character} mehr
vorliegen haben. DarÃ¼ber hinaus sehen wir auch, dass die der Faktor
jetzt \texttt{Levels} hat. Exakt zwei StÃ¼ck. Jeweils einen fÃ¼r
\texttt{dog} und einen fÃ¼r \texttt{cat}. Wir werden spÃ¤ter Faktoren
benÃ¶tigen, wenn wir zum Beispiel eine einfaktorielle ANOVA rechnen. Hier
siehst du schon den Begriff \emph{Faktor} wieder.

\marginnote{\begin{footnotesize}

Wir brauchen spÃ¤ter zum Modellieren einen Datensatz, der \emph{meist}
aus einer \textbf{Outcome}-Spalte, einer \textbf{Faktor}-Spalte mit der
\emph{Behandlung} und einer \textbf{Faktor}-Spalte mit dem \emph{Block}
oder \emph{Cluster} besteht.

\[
{\small Outcome \sim Behandlung + Block}
\]

\end{footnotesize}}

\hypertarget{von-wuxf6rtern-und-objekten}{%
\section{Von WÃ¶rtern und Objekten}\label{von-wuxf6rtern-und-objekten}}

Das mag etwas verwirrend sein, denn es gibt in R WÃ¶rter
\texttt{string\ \textless{}str\textgreater{}} oder
\texttt{character\ \textless{}chr\textgreater{}}. WÃ¶rter sind was
anderes als Objekte. Streng genommen sind beides WÃ¶rter, aber in
Objekten werden Dinge gespeichert wohin gegen das Wort einfach ein Wort
ist. Deshalb kennezeichnen wir WÃ¶rter auch mit GÃ¤nsefÃ¼Ãchen als win
\texttt{"wort"} und zeigen damit, dass es sich hier um einen String
handelt.

Wir tippen \texttt{"animal"} in R und erhalten \texttt{"animal"} als
Wort zurÃ¼ck. Das sehen wir auch an dem Ausdruck mit den GÃ¤nsefÃ¼Ãchen.

\begin{Shaded}
\begin{Highlighting}[]
\StringTok{"animal"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "animal"
\end{verbatim}

{\marginnote{\begin{footnotesize}Ãber den Zuweisungspfeil
\texttt{\textless{}-} kannst du im Kapitel~\ref{sec-R-pfeil} mehr
erfahren.\end{footnotesize}}}

Wir tippen \texttt{animal} ohne die AnfÃ¼hrungszeichen in R und erhalten
den Inhalt von \texttt{animal} ausgegeben. DafÃ¼r mÃ¼ssen wir aber das
Objekt \texttt{animal} erst einmal Ã¼ber den Zuweisungspfeil
\texttt{\textless{}-}erschaffen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{animal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"fox"}\NormalTok{)}
\NormalTok{animal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog" "cat" "fox"
\end{verbatim}

Sollte es das Objekt \texttt{animal} nicht geben, also nicht Ã¼ber den
Zuweisungspfeil \texttt{\textless{}-} erschaffen worden, dann wird eine
Fehlermeldung von R ausgegeben:

\texttt{Fehler\ in\ eval(expr,\ envir,\ enclos)\ :\ Objekt\ \textquotesingle{}animal\textquotesingle{}\ nicht\ gefunden}

\hypertarget{zusammenfassung}{%
\section{Zusammenfassung}\label{zusammenfassung}}

{\marginnote{\begin{footnotesize}\textbf{Variablennamen} meint hier
immer den \textbf{Namen der Spalte} im Datensatz bzw.
\texttt{tibble}\end{footnotesize}}}

Tabelle~\ref{tbl-skalenniveau} zeigt eine Ãbersicht wie einzelne
Variablennamen und deren zugehÃ¶rigen Beispielen sowie den Namen in R,
der Informatik allgemein, als Skalenneivau und welcher
Verteilungsfamilie die Variable angehÃ¶ren wÃ¼rde. Leider ist es so, dass
wieder gleiche Dinge unterschiedliche benannt werden. Aber an dieses
doppelte Benennen kÃ¶nnen wir uns in der Statistik schonmal gewÃ¶hnen.

\begin{figure*}

\hypertarget{tbl-skalenniveau}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1200}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2320}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0880}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1440}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2560}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1600}}@{}}
\caption{\label{tbl-skalenniveau}Zusammenfassung und Ãbersicht von
Variablennamen und deren Bennung in R, in der Informatik allgemein, als
Skalenniveau und die dazugehÃ¶rige Verteilungsfamilie.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Variablenname
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiel
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Infomatik
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Skalenniveau
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Verteilungsfamilie
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Variablenname
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Beispiel
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Infomatik
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Skalenniveau
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Verteilungsfamilie
\end{minipage} \\
\midrule()
\endhead
weight & 12.3, 12.4, 5.4, 21.3, 13.4 & numeric & double & continuous &
Gaussian \\
count & 5, 0, 12, 23, 1, 4, 21 & integer & integer & discrete &
Poisson \\
dosis & low, mid, high & ordered & & categorical / ordinal & Ordinal \\
field & mainz, berlin, kiel & factor & & categorical & Multinomial \\
cancer & 0, 1 & factor & & dichotomous / binary / nominal & Binomial \\
treatment & ``placebo'', ``aspirin'' & character & character/string &
dichotomous / binary / nominal & Binomial \\
birth & 2001-12-02, 2005-05-23 & date & & & \\
\bottomrule()
\end{longtable}

\end{figure*}

\hypertarget{sec-basics}{%
\chapter{Operatoren, Funktionen und Pakete}\label{sec-basics}}

\emph{Version vom September 14, 2022 um 08:46:11}

Es ist immer schwierig, wann die Grundlagen von R einmal gelehrt werden
sollte. Wenn du nichts von Programmierung bis jetzt gehÃ¶rt hast, dann
mag es keinen Sinn ergeben mit Operatoren, wie dem Zuweisungspfeil
\texttt{\textless{}-} und der Pipe \texttt{\%\textgreater{}\%} zu
beginnen. Wir brauchen aber fÃ¼r die Programmierung folgende zentrale
Konzepte.

\begin{itemize}
\tightlist
\item
  Wir mÃ¼ssen zusÃ¤tzliche Pakete in R installieren und laden kÃ¶nnen
  (siehe Kapitel~\ref{sec-R-packages}).
\item
  Wir mÃ¼ssen verstehen wie wir uns einen Vektor mit \texttt{c()} bauen
  (siehe Kapitel~\ref{sec-R-vector}).
\item
  Wir mÃ¼ssen wissen was eine Funktion in R ist (siehe
  Kapitel~\ref{sec-R-function}).
\item
  Wir mÃ¼ssen den Operator Zuweisungspfeil \texttt{\textless{}-}
  verstehen und anwenden kÃ¶nnen (siehe Kapitel~\ref{sec-R-pfeil}).
\item
  Wir mÃ¼ssen den Operator Pipe \texttt{\%\textgreater{}\%} verstehen und
  anwenden kÃ¶nnen (siehe Kapitel~\ref{sec-R-pipe}).
\item
  Wir mÃ¼ssen den Operator \texttt{\$} verstehen, da manche Funktionen in
  R nicht mit DatensÃ¤tzen sondenr nur mit Vektoren arbeiten kÃ¶nnen
  (siehe Kapitel~\ref{sec-dollar}).
\item
  Wir mÃ¼ssen verstehen wie wir ein Modell in R mit der Tilde
  \texttt{\textasciitilde{}} definieren (siehe
  Kapitel~\ref{sec-formula}).
\item
  Wir mÃ¼ssen wissen und verstehen wie wir mit \texttt{?} englische
  Hilfeseiten Ã¶ffnen kÃ¶nnen (siehe Kapitel~\ref{sec-R-help}).
\end{itemize}

Nicht alle Konzepte brauchst du \emph{unmittelbar} aber ich nutze diese
Konzepte wiederholt in allen Kapiteln, so dass du hier immer wieder mal
schauen kannst, was die Grundlagen sind.

\hypertarget{sec-R-packages}{%
\section{\texorpdfstring{Pakete und
\texttt{library()}}{Pakete und library()}}\label{sec-R-packages}}

{\marginnote{\begin{footnotesize}Als Vanilla beschreibt man in der
Informatikerwelt ein Programm, was keine zusÃ¤tzlichen Pakete geladen
hat. Also die reinst Form ohne zusÃ¤tzlichen
Geschmack.\end{footnotesize}}}

In der \emph{Vanilla}-Variante hat R sehr wenige Funktionen. Ohne
zusÃ¤tzliche Pakete ist R mehr ein sehr potenter Taschenrechner. Leider
mit der FunktionalitÃ¤t aus den 90'zigern, was die Programmierumgebung
und die Funktionen angeht. Das wollen wir aber nicht. Wir wollen auf den
aktuellen Stand der Technik und auch Sprache programmieren. Daher nutzen
wir zusÃ¤tzliche R Pakete.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/programing_01.PNG}

}

\caption{\label{fig-pro-01}Auf den Reiter \emph{Packages} klicken und
dann \emph{Install}. In der deutschen version vom RStudio mÃ¶gen die
Begriffe leicht anders sein.}

\end{figure}

In Abbildung~\ref{fig-pro-01} wird gezeigt wie du ein zusÃ¤tzliches Paket
installieren kannst. Hierbei ist nochmal wichtig den semantischen
Unterschied zu wissen. Es gibt das Paket \texttt{tidyverse} was wir viel
nutzen. Wir isnatllieren \emph{einmalig} Pakete der Funktion
\texttt{install.packages()} oder eben wie in Abbildung~\ref{fig-pro-01}
gezeigt. Wir nutzen die Funktion \texttt{library()} um ein Paket in R zu
laden. Ja, es mÃ¼sste anders heisen, tut es aber nicht.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Das Paket tidyverse installieren {-} einmalig}
\FunctionTok{install.packages}\NormalTok{(tidyverse)}

\DocumentationTok{\#\# Das Paket tidyverse laden {-} jedes Mal}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Nun muss man sich immer merken, ob das Paket schon installiert ist oder
man schreibt relativ viele \texttt{library()} untereinander. Das
passiert schnell, wenn du viele Pakete laden willst. DafÃ¼r erlaubt dir
das Paket \texttt{pacman} eine Vereinfachung. Die Funktion
\texttt{p\_load()} installiert Pakete, wenn die Pakete nicht installiert
sind. Sollten die Pakete installiert sein, so werden die Pakete geladen.
Du musst nur einmal \texttt{install.packages(pacman)} ausfÃ¼hren um das
Paket \texttt{pacman} zu installieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, readxl)}
\end{Highlighting}
\end{Shaded}

Schlussendlich gibt es noch die MÃ¶glichkeit sich alles nochmal bei
YouTube anzuschauen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Unterschied von Packages und Libraries in R}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/TWimhd3ZyMM}{EinfÃ¼hrung in
R - Teil 03 - Unterschied Packages und Libraries in R} als Video. Hier
erklÃ¤re ich nochmal den Ablauf zwischen Installieren eines Paketes und
dem Laden eines Paketes.
\end{tcolorbox}

\hypertarget{sec-R-vector}{%
\section{\texorpdfstring{Einen Vektor bauen
\texttt{c()}}{Einen Vektor bauen c()}}\label{sec-R-vector}}

Wir kÃ¶nnen mit der Funktion \texttt{c()} Zahlen und WÃ¶rter zu einem
Vektor kombinieren.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"fox"}\NormalTok{, }\StringTok{"fox"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog" "dog" "cat" "cat" "fox" "fox"
\end{verbatim}

Hier werden die WÃ¶rter ``dog'', ``cat'' und ``fox'' miteinader in einen
Vektor kombiniert. Wir erinnern uns an das \texttt{\$} Zeichen, was uns
erlaubt eine Variable als Vektor aus einem
\texttt{tibble()}herauszuziehen.

\hypertarget{sec-R-function}{%
\section{Funktionen}\label{sec-R-function}}

Wir haben schon einige Funktion nebenbei in R kennengelernt. Zum einen
\texttt{as.factor()} um einen Faktor zu erstellen oder aus dem
Kapitel~\ref{sec-R-packages}, wo wir die Funktion
\texttt{install.packages()} nutzen um ein Paket zu installieren oder
aber die Funktion \texttt{library()} um ein Paket in R zu laden.

Funktionen sehen aus wie WÃ¶rter. Haben aber keine GÃ¤nsefÃ¼Ãchen und
beinhalten auch keine Daten oder Vektoren. Funktionen kÃ¶nnen mit Daten
und Vektoren rechnen und geben das Berechnete dann wieder. Nehmen wir
als Beispiel die Funktion \texttt{mean()}, die den Mittelwert von einer
Reihe Zahlen berechnet.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{1.2}\NormalTok{, }\FloatTok{3.4}\NormalTok{, }\FloatTok{2.1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{4.3}\NormalTok{)}
\FunctionTok{mean}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.4
\end{verbatim}

Wir sehen, dass wir mit der Funktion \texttt{c()} die Zahlen
\(1.2, 3.4, 2.1, 6, 4.3\) zusammenkleben. Danach speichern wir die
Zahlen in den Objekt \texttt{y} als einen Vektor ab. Wir mÃ¼ssen
\texttt{y}nicht erst erschaffen, das Erschaffen und Speichern passiert
in R in einem Schritt. Wir stecken nun den Vektor \texttt{y} in die
Funktion \texttt{mean()} und erhalten den Mittelwert von \(3.4\) der
Zahlen wiedergegeben.

{\marginnote{\begin{footnotesize}Eigentlich mÃ¼ssen in der Programmierung
Objekte erst \textbf{deklariert} werden und somit erschaffen. Erst dann
kÃ¶nnen Objekte \textbf{initalisiert} und somit befÃ¼llt bzw. etwas
zugewiesen werden.\end{footnotesize}}}

\hypertarget{sec-R-pfeil}{%
\section{\texorpdfstring{Zuweisungspfeil
\texttt{\textless{}-}}{Zuweisungspfeil \textless-}}\label{sec-R-pfeil}}

Mit dem Zuweisungspfeil speichern wir \emph{Dinge} in Objekte in R. Das
heist wir speichern damit intern in R DatensÃ¤tze und viele andere
Sachen, die wir dan spÃ¤ter wieder verwenden wollen. Schauen wir uns das
einmal im Beispiel an. Schrieben wir nur den Vektor \texttt{c()} mit
Hunden und Katzen darin, so erscheint eine Ausgabe in R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"fox"}\NormalTok{, }\StringTok{"fox"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog" "dog" "cat" "cat" "fox" "fox"
\end{verbatim}

Schreiben wir den gleichen Vektor und nutzen den Zuweisungspfeil, dann
wird der Vektor in dem Objekt \texttt{animal} gespeichert.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{animal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"fox"}\NormalTok{, }\StringTok{"fox"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Wie kommen wir jetzt an die Sachen, die in \texttt{animal} drin sind?
Wir kÃ¶nnen einfach \texttt{animal} in R schreiben und dann wird uns der
Inhalt von \texttt{animal} ausgegeben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{animal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog" "dog" "cat" "cat" "fox" "fox"
\end{verbatim}

{\marginnote{\begin{footnotesize}Der Zuweisungspfeil
\texttt{\textless{}-} ist zentral fÃ¼r die Nutzung von
R.\end{footnotesize}}}

Wir nutzen den Zuweisungspfeil \texttt{\textless{}-} ist zentral fÃ¼r die
Nutzung von R. Wir brauchen den Zuweisungspfeil \texttt{\textless{}-} um
Objekte in R zu erschaffen und Ergebnisse intern abzuspeichern. Zusammen
mit Funktionen nutzen wir nur noch die Pipe \texttt{\%\textgreater{}\%}
Ã¶fter.

\hypertarget{sec-R-pipe}{%
\section{\texorpdfstring{Pipe
\texttt{\%\textgreater{}\%}}{Pipe \%\textgreater\%}}\label{sec-R-pipe}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Pipes in R}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/6u4RR26eqNw}{EinfÃ¼hrung in
R - Teil 11 - Pipes in R} als Video. Hier erklÃ¤re ich den Zusammenhang
nochmal in einem Video.
\end{tcolorbox}

Im Weiteren nutzen wir den Pipe Operator dargestellt als
\texttt{\%\textbackslash{}\textgreater{}\%}. Du kannst dir den Pipe
Operator als eine Art RÃ¶hre vorstellen in dem die Daten verÃ¤ndert werden
und dann an die nÃ¤chste Funktion weitergeleitet werden. Im folgenden
siehst du viele Funktionen, die aneinander Ã¼ber Objekte miteinander
verbunden werden. Im Kapitel~\ref{sec-dplyr} erfÃ¤hrst du mehr Ã¼ber die
Funktionen \texttt{select()}und \texttt{filter()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}
\NormalTok{animal\_1\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{select}\NormalTok{(data\_tbl, animal, jump\_length)}
\NormalTok{animal\_2\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(animal\_1\_tbl, jump\_length }\SpecialCharTok{\textgreater{}=} \DecValTok{4}\NormalTok{)}
\FunctionTok{sort}\NormalTok{(animal\_2\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, jump\_length) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(jump\_length }\SpecialCharTok{\textgreater{}=} \DecValTok{4}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(jump\_length) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  sort}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8
\end{verbatim}

Im unteren Beispiel siehst du die Nutzung des Pipe Operators
\texttt{\%\textgreater{}\%}. Das Ergebnis ist das gleiche, aber der Code
ist einfacher zu lesen. Wir nehmen den Datensatz \texttt{data\_tbl}
leiten den Datensatz in den Funktion \texttt{select()} und wÃ¤hlen die
Spalten \texttt{animal} sowie \texttt{jump\_length}. Dann filtern wir
noch nach \texttt{jump\_length}grÃ¶Ãer als 4 cm. Dann ziehen wir uns mit
der Funktion \texttt{pull()} die Spalte \texttt{jump\_length} aus dem
Datensatz. Den Vektor leiten wir dann weiter in die Funktion
\texttt{sort()} und erhalten die sortierten SprunglÃ¤ngen zurÃ¼ck.

\hypertarget{sec-dollar}{%
\section{\texorpdfstring{Spalte extrahieren
\texttt{\$}}{Spalte extrahieren \$}}\label{sec-dollar}}

Wir nutzen eigentlich die Funktion \texttt{pull()} um eine Spalte bzw.
Vektor aus einem Datensatz zu extrahieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "dog" "dog" "dog" "dog" "dog" "dog" "dog" "cat" "cat" "cat" "cat" "cat"
[13] "cat" "cat"
\end{verbatim}

Manche Funktionen in R, besonders die Ã¤lteren Funktionen, benÃ¶tigen
keinen Datensatz sondern meist zwei bis drei Vektoren. Das heiÃt, wir
kÃ¶nnen nicht einfach einen Datensatz in eine Funktion Ã¼ber
\texttt{data\ =\ data\_tbl} stecken sondern mÃ¼ssen der Funktion Vektoren
Ã¼bergeben. DafÃ¼r nutzen wir den \texttt{\$} Operator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl}\SpecialCharTok{$}\NormalTok{animal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "dog" "dog" "dog" "dog" "dog" "dog" "dog" "cat" "cat" "cat" "cat" "cat"
[13] "cat" "cat"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  5.7  8.9 11.8  8.2  5.6  9.1  7.6  3.2  2.2  5.4  4.1  4.3  7.9  6.1
\end{verbatim}

Wir werden versuchen diese Schreibweise zu vermeiden, aber manchmal ist
es sehr nÃ¼tzlich die MÃ¶glichkeit zu haben auf diese Weise eine Spalte zu
extrahieren.

\hypertarget{sec-formula}{%
\section{\texorpdfstring{Modelle definieren mit
\texttt{formula}}{Modelle definieren mit formula}}\label{sec-formula}}

Wir mÃ¼ssen spÃ¤ter Modelle in R definieren um zum Beispiel den t Test
oder aber eine lineare Regression rechnen zu kÃ¶nnen. Wir nutzen dazu in
R die \texttt{formula} Syntax. Das heiÃt links von der Tilde
\texttt{\textasciitilde{}} steht das \(y\), also der Spaltenname aus dem
Datensatz \texttt{data\ =} den wir nutzen, der das Outcome
reprÃ¤sentiert. Rechts von der Tilde \texttt{\textasciitilde{}} stehen
alle \(x_1, ..., x_p\), also alle Spalten aus dem Datensatz
\texttt{data\ =} den wir nutzen, der die Einflussfaktoren reprÃ¤sentiert.

In unserem Beispiel mit den Hunde- und KatzenflÃ¶hen aus
Kapitel~\ref{sec-example-2} wÃ¤re das \(y\) die Spalte
\texttt{jump\_length} und das \(x\) der Faktor \texttt{animal}. Wir
erstellen mit der Funktion \texttt{formula()} das Modell in R. Wir
brauchen spÃ¤ter die Funktion \texttt{formula} nur implizit, aber hier
ist es gut, das du einmal siehst, wie so eine Formula in R aussieht.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{formula}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
jump_length ~ animal
\end{verbatim}

Wenn die Formel sehr lang wird bzw. wir die Namen der Spalten aus
anderen Funktionen haben, kÃ¶nnen wir auch die Funktion
\texttt{reformulate()} nutzen. Wir brauchen die Funktion aber eher im
Bereich des maschinellen Lernens. Hier ist die Funktion
\texttt{reformulate()} aufgefÃ¼hrt, da es inhaltlich passt.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{reformulate}\NormalTok{(}\AttributeTok{termlabels =} \FunctionTok{c}\NormalTok{(}\StringTok{"animal"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"site"}\NormalTok{),}
            \AttributeTok{response =} \StringTok{"jump\_length"}\NormalTok{,}
            \AttributeTok{intercept =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
jump_length ~ animal + sex + site
\end{verbatim}

\hypertarget{sec-R-help}{%
\section{\texorpdfstring{Hilfe mit
\texttt{?}}{Hilfe mit ?}}\label{sec-R-help}}

Das Fragezeichen \texttt{?} vor einem Funktionsnamen erlaubt die
Hilfeseite zu Ã¶ffnen. Die Hilfsseiten findest du auch in einem der
Reiter im RStudio.

\begin{figure}

{\centering \includegraphics{./images/basics-help.png}

}

\caption{\label{fig-basic-01}Neben den Paketen in R findet sich auch der
Reiter Help, wo du Hilfe fÃ¼r die einzelnen Funktionen findets..}

\end{figure}

\hypertarget{sec-programming-import}{%
\chapter{Daten einlesen}\label{sec-programming-import}}

\emph{Version vom September 14, 2022 um 08:46:20}

\marginnote{\begin{footnotesize}

Im Anhang~\ref{sec-beispiel-auswertung} findest du Beispiele fÃ¼r die
Auswertung von Daten. Du kannst dir dort das Format anschauen und dann
entsprechend deine Daten formatieren. Du findest auch alle Dateien auf
GitHub unter
\href{https://github.com/jkruppa/jkruppa.github.io/tree/master/data}{jkruppa.github.io/data/}
als Excel oder auch als CSV. Schau dir die Beispiele einmal an.

\end{footnotesize}}

Die Daten aus unserem Experiment mÃ¼ssen rein in R. Das heiÃt, wir haben
meist unsere Daten in einer Exceldatei vorliegen und wollen diese Daten
nun in R einlesen.

GÃ¤ngige Fehler beim Einlesen von Dateien in R sind folgende Probelem.
Wir wollen diese Probeleme nacheinander einmal durchgehen. Aber keine
Sorge, das Einlesen von Daten in R ist immer am Anfang etwas frickelig.
Du kannst gerne in das R Tutorium (siehe Kapitel~\ref{sec-r-tutorium}
fÃ¼r Raum und Zeiten) kommen, dann kÃ¶nnen wir dir da beim Einlesen der
Daten helfen.

\begin{itemize}
\tightlist
\item
  das Format der Daten ist nicht richtig (Kapitel~\ref{sec-format})
\item
  der Pfad zur Datei ist falsch (Kapitel~\ref{sec-pfad})
\item
  in der Datei sind komische Zeichen, wie Umlaute und
  Co.~(Kapitel~\ref{sec-umlaute})
\item
  in der Datei sind Leerzeichen in den Spaltennamen
  (Kapitel~\ref{sec-spalten})
\end{itemize}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, janitor)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{sec-format}{%
\section{Dateiformat}\label{sec-format}}

\marginnote{\begin{footnotesize}

Das Buch \emph{Cookbook for R} stellt auch Beispiele fÃ¼r die Funktion
\texttt{gather()} zu VerfÃ¼gung fÃ¼r die Umwandlung von Wide zu Long
Format:
\href{http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/}{Converting
data between wide and long format}

\end{footnotesize}}

Wir unterschieden bei Datenformaten zwischen den Wide Format und dem
Long Format. Meistens gibst du die Daten intuitv im Wide Format in Excel
ein. Das ist in Excel auch Ã¼bersichtlicher. R und spÃ¤ter die Funktion
\texttt{ggplot()} zur Visualisierung der Daten kann aber nur mit dem
Long Format arbeiten. Wir kÃ¶nnen aber mit der Funktion \texttt{gather()}
das Wide Format in das Long Format umwandeln.

\hypertarget{wide-format}{%
\subsection{Wide Format}\label{wide-format}}

In Tabelle~\ref{tbl-imp-cat-dog-wide} sehen wir eine typische
Datentabelle in einem Wide Format. Die Spalten egeben jeweils die
Tierart wieder und die EintrÃ¤ge in den Spalten sind die Sprungweiten in
{[}cm{]}.

\hypertarget{tbl-imp-cat-dog-wide}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-imp-cat-dog-wide}Eine Datentabelle mit Sprungweiten
in {[}cm{]} von Hunde- und KatzenflÃ¶hen im Wide Format.}\tabularnewline
\toprule()
dog & cat \\
\midrule()
\endfirsthead
\toprule()
dog & cat \\
\midrule()
\endhead
5.2 & 10.1 \\
4.9 & 9.4 \\
12.1 & 11.8 \\
8.2 & 6.7 \\
5.6 & 8.2 \\
9.1 & 9.1 \\
7.4 & 7.1 \\
\bottomrule()
\end{longtable}

Wir kÃ¶nnen diese Datentablle auch in R erstellen und uns als
\texttt{tibble()} wiedergeben lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{jump\_wide\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{dog =} \FunctionTok{c}\NormalTok{(}\FloatTok{5.2}\NormalTok{, }\FloatTok{4.9}\NormalTok{, }\FloatTok{12.1}\NormalTok{, }\FloatTok{8.2}\NormalTok{, }\FloatTok{5.6}\NormalTok{, }\FloatTok{9.1}\NormalTok{, }\FloatTok{7.4}\NormalTok{),}
                        \AttributeTok{cat =} \FunctionTok{c}\NormalTok{(}\FloatTok{10.1}\NormalTok{, }\FloatTok{9.4}\NormalTok{, }\FloatTok{11.8}\NormalTok{, }\FloatTok{6.7}\NormalTok{, }\FloatTok{8.2}\NormalTok{, }\FloatTok{9.1}\NormalTok{, }\FloatTok{7.1}\NormalTok{))}
\NormalTok{jump\_wide\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 7 x 2
    dog   cat
  <dbl> <dbl>
1   5.2  10.1
2   4.9   9.4
3  12.1  11.8
4   8.2   6.7
5   5.6   8.2
6   9.1   9.1
7   7.4   7.1
\end{verbatim}

{\marginnote{\begin{footnotesize}Wenn du schon Daten hast, dann macht es
eventuell mehr Sinn eine \textbf{neue} Exceldatei anzulegen in der du
dann die Daten in das Long Format kopierst.\end{footnotesize}}}

Wir kÃ¶nnen aber mit einem Wide-Format nicht mit \texttt{ggplot()} die
Daten aus der Tabelle~\ref{tbl-imp-cat-dog-wide} visualisieren. Deshalb
mÃ¼ssen wir entweder das Wide Format in das Long Format umwandeln oder
die Daten gleich in Excel im Long Format erstellen.

\hypertarget{long-format}{%
\subsection{Long Format}\label{long-format}}

Wenn du Daten erstellst ist es wichtig, dass du die Daten in Excel im
Long-Format erstellst. Dabei muss eine Beobachtung eine Zeile sein. Du
siehst in Abbildung~\ref{fig-imp-long} ein Beispiel fÃ¼r eine Tabelle in
Excel, die dem Long Format folgt.

\begin{figure}

{\centering \includegraphics{./images/import_03.PNG}

}

\caption{\label{fig-imp-long}Beispiel fÃ¼r eine Exceldatentabelle in Long
Format.}

\end{figure}

Im Folgenden sehen wir einmal wie die Funktion \texttt{gather()} das
\texttt{tibble()} in Wide Format in ein \texttt{tibble()} in Long Format
umwandelt. Wir mÃ¼ssen dafÃ¼r noch die Spalte benennen mit der Option
\texttt{key\ =} in die die Namen der Spalten aus dem Wide Format
geschrieben werden sowie den Spaltennamen fÃ¼r die eigentlichen Messwerte
mit der Option \texttt{value\ =}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{jump\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{dog =} \FunctionTok{c}\NormalTok{(}\FloatTok{5.2}\NormalTok{, }\FloatTok{4.9}\NormalTok{, }\FloatTok{12.1}\NormalTok{, }\FloatTok{8.2}\NormalTok{, }\FloatTok{5.6}\NormalTok{, }\FloatTok{9.1}\NormalTok{, }\FloatTok{7.4}\NormalTok{),}
                   \AttributeTok{cat =} \FunctionTok{c}\NormalTok{(}\FloatTok{10.1}\NormalTok{, }\FloatTok{9.4}\NormalTok{, }\FloatTok{11.8}\NormalTok{, }\FloatTok{6.7}\NormalTok{, }\FloatTok{8.2}\NormalTok{, }\FloatTok{9.1}\NormalTok{, }\FloatTok{7.1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"animal"}\NormalTok{, }\AttributeTok{value =} \StringTok{"jump\_length"}\NormalTok{)}
\NormalTok{jump\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 14 x 2
   animal jump_length
   <chr>        <dbl>
 1 dog            5.2
 2 dog            4.9
 3 dog           12.1
 4 dog            8.2
 5 dog            5.6
 6 dog            9.1
 7 dog            7.4
 8 cat           10.1
 9 cat            9.4
10 cat           11.8
11 cat            6.7
12 cat            8.2
13 cat            9.1
14 cat            7.1
\end{verbatim}

Wir sehen, dass ein Long Format viel mehr Paltz benÃ¶tigt. Das ist aber
in R kein Problem. Wir sehen die Daten kaum sondern nutzen Funktionen
wie \texttt{ggplot()} um die Daten zu visualisieren. Wichtig ist, dass
du die Daten in Excel sauber abgelegt hast.

Im Folgenden schauen wir uns noch komplexere Daten in
Tabelle~\ref{tbl-imp-complex-long} an. Das Datenbeispiel ist im Wide
Format mit einem Behandlungsfaktor \texttt{treatment} einem
Clusterfaktor \texttt{block} sowie mehreren Messwiederholungen zu
unterschiedichen Zeitpunkten \texttt{t\_1} bis \texttt{t\_6} angelegt.

\hypertarget{tbl-imp-complex-long}{}
\begin{longtable}[]{@{}cccccccc@{}}
\caption{\label{tbl-imp-complex-long}Komplexeres Datenbeispiel im Wide
Format mit einem Behandlungsfaktor \texttt{treatment} einem
Clusterfaktor \texttt{block} sowie mehreren Messwiederholungen zu
unterschiedichen Zeitpunkten \texttt{t\_1} bis
\texttt{t\_6}.}\tabularnewline
\toprule()
treatment & block & t\_1 & t\_2 & t\_3 & t\_4 & t\_5 & t\_6 \\
\midrule()
\endfirsthead
\toprule()
treatment & block & t\_1 & t\_2 & t\_3 & t\_4 & t\_5 & t\_6 \\
\midrule()
\endhead
A & 1 & 12.54 & 16.90 & 17.72 & 14.72 & 17.28 & 18.99 \\
A & 2 & 14.18 & 17.51 & 17.60 & 14.27 & 17.70 & 18.64 \\
A & 3 & 13.63 & 19.28 & 17.77 & 13.42 & 20.87 & 18.25 \\
A & 4 & 14.63 & 13.44 & 16.81 & 16.05 & 17.80 & 19.15 \\
B & 1 & 15.92 & 15.75 & 12.50 & 15.95 & 15.40 & 20.47 \\
B & 2 & 15.41 & 15.13 & 16.04 & 13.45 & 16.29 & 18.18 \\
B & 3 & 14.26 & 16.41 & 17.73 & 17.71 & 18.49 & 16.91 \\
B & 4 & 17.57 & 15.52 & 17.37 & 16.94 & 18.02 & 18.69 \\
C & 1 & 16.64 & 19.33 & 17.23 & 17.80 & 22.37 & 21.54 \\
C & 2 & 16.05 & 16.19 & 15.81 & 16.66 & 18.79 & 12.98 \\
C & 3 & 14.87 & 17.08 & 12.12 & 15.53 & 16.61 & 20.36 \\
C & 4 & 14.75 & 13.04 & 17.48 & 19.01 & 20.73 & 19.34 \\
D & 1 & 13.11 & 14.86 & 17.50 & 16.56 & 17.35 & 16.15 \\
D & 2 & 17.72 & 15.08 & 17.86 & 13.83 & 20.43 & 12.77 \\
D & 3 & 18.60 & 15.08 & 16.12 & 17.32 & 16.54 & 17.37 \\
D & 4 & 12.44 & 16.64 & 19.34 & 19.00 & 18.93 & 19.87 \\
\bottomrule()
\end{longtable}

Im Folgenden Codeblock sehen wir, wie die Funktion \texttt{gather()} die
Daten in Tabelle Tabelle~\ref{tbl-imp-complex-long} in ein Long Format
umwandelt. Die Funktion fasst die Messwiederholungen der Spalten
\texttt{t\_1} bis \texttt{t\_6} zusammen, in dem die Werte alle in der
Spalte \texttt{drymatter} untereinander geklebt werden. Die Spalten
\texttt{treatment} und \texttt{block} werden dann sechs Mal wiederholt
untereinander geklebt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"time\_point"}\NormalTok{, }\AttributeTok{value =} \StringTok{"drymatter"}\NormalTok{, t\_1}\SpecialCharTok{:}\NormalTok{t\_6) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(treatment, block)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 96 x 4
   treatment block time_point drymatter
   <fct>     <int> <chr>          <dbl>
 1 A             1 t_1             12.5
 2 A             1 t_2             16.9
 3 A             1 t_3             17.7
 4 A             1 t_4             14.7
 5 A             1 t_5             17.3
 6 A             1 t_6             19.0
 7 A             2 t_1             14.2
 8 A             2 t_2             17.5
 9 A             2 t_3             17.6
10 A             2 t_4             14.3
# ... with 86 more rows
\end{verbatim}

\hypertarget{importieren-mit-rstudio}{%
\section{Importieren mit RStudio}\label{importieren-mit-rstudio}}

Wir kÃ¶nnen das RStudio nutzen um Daten mit Point-and-Klick rein zuladen
und dann den Code wieder in den Editor kopieren. Im Prinzip ist dieser
Weg der einfachste um einmal zu sehen, wie ein pfad funktioniert und der
Code lautet. SpÃ¤ter benÃ¶tigt man diese `KrÃ¼cke' nicht mehr. Wir nutzen
dann direkt den Pfad zu der Datei. Abbildung~\ref{fig-imp-01} zeigt
einen Ausschnitt, wo wir im RStudio die \emph{Import Dataset}
FunktionalitÃ¤t finden.

\begin{figure}

{\centering \includegraphics[width=3.125in,height=\textheight]{./images/import_01.PNG}

}

\caption{\label{fig-imp-01}Auf den Reiter \emph{Einviroment} klicken und
dann \emph{Import Dataset}. In der deutschen version vom RStudio mÃ¶gen
die Begriffe leicht anders sein.}

\end{figure}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Importieren mit RStudio als Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/tdRWkBcGAzk}{EinfÃ¼hrung in
R - Teil 21.0 - Daten importieren mit RStudio - Point and Klick} als
Video. Point and Klick ist als Video einfacher nachzuvollziehen als
Screenshots in einem FlieÃtext.
\end{tcolorbox}

\hypertarget{sec-pfad}{%
\section{Importieren per Pfad}\label{sec-pfad}}

In Abbildung~\ref{fig-imp-02} kÃ¶nnen wir sehen wie wir den Pfad zu
unserer Excel Datei \texttt{flea\_dog\_cat.xlsx} finden. NatÃ¼rlich
kannst du den Pfad auch anders herausfinden bzw. aus dem Explorer oder
Finder kopieren.

\begin{figure}

{\centering \includegraphics[width=3.64583in,height=\textheight]{./images/import_02.PNG}

}

\caption{\label{fig-imp-02}Durch den Rechts-Klick auf die Eigenschaften
einer Datei kann man sich den Pfad zur Datei anzeigen lassen.
\textbf{Achtung!} Unter Windows muss der Slash \texttt{\textbackslash{}}
noch in den Backslash \texttt{/} gedreht werden.}

\end{figure}

Nachdem wir den Pfad gefunden haben, kÃ¶nnen wir den Pfad in die Funktion
\texttt{read\_excel()} kopieren und die Datei in das Objekt
\texttt{data\_tbl} einlesen. Ja, es wird nichts in der R Console
ausgegeben, da sich die Daten jetzt in dem Object \texttt{data\_tbl}
befinden.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Ganzer Pfad zur Datei flea\_dog\_cat.xlsx}
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Unterschied zwischen \texttt{\textbackslash{}} in Windows und \texttt{/}
in R}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Achte einmal auf den Slash im Pfad in R und einem im Pfsd in Windows.
Einmal ist es der Slash \texttt{\textbackslash{}} im Dateipfad und
einmal der Backslash \texttt{/}. Das ist sehr Ã¤rgerlich, aber dieses
Problem geht zurÃ¼ck in die 80'ziger. Bill hat entschieden fÃ¼r sein
Windows \texttt{/} zu nutzen und Steve (und Unix) eben \texttt{/}. Und
mit dieser Entscheidung mÃ¼ssen wir jetzt leben\ldots{}
\end{tcolorbox}

\hypertarget{sec-umlaute}{%
\section{Auf ein englisches Wort in Dateien}\label{sec-umlaute}}

Ein groÃes Problem in Datein sind Umlaute (Ã¤,Ã¶,Ã¼) oder aber andere
(Sonder)zeichen (Ã, ?, oder \#). Als dies sollte vermieden werden. Eine
gute Datei fÃ¼r R beinhaltet nur \emph{ganze} WÃ¶rter, Zahlen oder aber
leere Felder. Ein leeres Feld ist ein fehlender Wert.
Abbildung~\ref{fig-imp-03} zeigt eine gute Exceldatentablle. Wir
schreiben \texttt{jump\_length} mit Unterstrich um den Namen besser zu
lesen zu kÃ¶nnen. Sonst ist auch alles in Englisch geschrieben. Wir
vermeiden durch die neglische Schreibweise \emph{aus versehen} einen
Umlaut oder anderweitig problematische Zeichen zu verwenden. SpÃ¤ter
kÃ¶nnen wir alles noch fÃ¼r Abbildungen anpassen.

\begin{figure}

{\centering \includegraphics{./images/import_03.PNG}

}

\caption{\label{fig-imp-03}Beispiel fÃ¼r eine gute (Excel)Datentabelle.
Keine Umlaute sind vorhanden und die Spaltennamen haben keine
Leerzeichen oder Sonderzeichen.}

\end{figure}

\hypertarget{sec-spalten}{%
\section{Spaltennamen in der (Excel)-Datei}\label{sec-spalten}}

Die Funktion \texttt{clean\_names()} aus dem R Paket \texttt{janitor}
erlaubt es die Spaltennamen einer eingelesenen Datei in eine fÃ¼r R gute
Form zu bringen.

\begin{itemize}
\tightlist
\item
  Keine Leerzeichen in den Spaltennamen.
\item
  Alle Spaltennamen sind klein geschrieben.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{clean\_names}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 14 x 5
   animal jump_length flea_count grade infected
   <chr>        <dbl>      <dbl> <dbl>    <dbl>
 1 dog            5.7         18     8        0
 2 dog            8.9         22     8        1
 3 dog           11.8         17     6        1
 4 dog            8.2         12     8        0
 5 dog            5.6         23     7        1
 6 dog            9.1         18     7        0
 7 dog            7.6         21     9        0
 8 cat            3.2         12     7        1
 9 cat            2.2         13     5        0
10 cat            5.4         11     7        0
11 cat            4.1         12     6        0
12 cat            4.3         16     6        1
13 cat            7.9          9     6        0
14 cat            6.1          7     5        0
\end{verbatim}

\hypertarget{sec-dplyr}{%
\chapter{Daten bearbeiten}\label{sec-dplyr}}

\emph{Version vom September 14, 2022 um 08:46:32}

Wir haben in dem vorherigen Kapitel Daten eingelesen. Jetzt wollen wir
die Daten aufrÃ¤umen (eng. \emph{tidy}). Es ist notwendig, dass wir die
Daten so aufarbeiten, dass R damit umgehen kann. Insbesondere das
Erstellen von Faktoren ist wichtig, wenn die Spalte ein Faktor ist. R
muss wissen was fÃ¼r Eigenschaften eine Spalte hat. Sonst funktionieren
spÃ¤tere Anwendungen in R nicht richtig oder geben einen Fehler wieder.

Es gibt zwei MÃ¶glichkeiten wie du mit deinen Daten umgehst:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Du Ã¤nderst all deine Daten in Excel. Das mag bei einem kleinen
  Datensatz gut funktionieren. Dann musst du dich nicht mit dem
  \emph{Programmieren} beschÃ¤ftigen.
\item
  Du willst lernen die Daten auch in R zu verÃ¤ndern. Dann hilft dir
  dieses Kapitel. Auch in den folgenden Kapiteln werde ich immer wieder
  Funktionen wie \texttt{select()}, \texttt{filter()} und
  \texttt{mutate()}nutzen. Dann kannst du hier nochmal schauen, was die
  Funktionen machen.
\end{enumerate}

Im Folgenden wollen wir den Datensatz \texttt{data\_tbl} in R
bearbeiten. Das heiÃt wir wollen Spalten auswÃ¤hlen mit \texttt{select()}
oder Zeilen auswÃ¤hlen mit \texttt{filter()}. Schlussendlich wollen wir
auch die Eigenschaften von Spalten mit der Funktion \texttt{mutate}
Ã¤ndern. Wir laden also den Datensatz \texttt{flea\_dog\_cat.xlsx} einmal
in R.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Es ergibt sich folgende Tabelle~\ref{tbl-dog-cat-dplyr}, die wir schon
aus vorherigen Kapiteln kennen.

\hypertarget{tbl-dog-cat-dplyr}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-dog-cat-dplyr}Tabelle der SprunglÃ¤ngen {[}cm{]},
Anzahl an FlÃ¶hen, Boniturnote sowie der Infektionsstatus von Hunden,
Katzen und FÃ¼chsen.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
cat & 3.2 & 12 & 7 & 1 \\
cat & 2.2 & 13 & 5 & 0 \\
cat & 5.4 & 11 & 7 & 0 \\
cat & 4.1 & 12 & 6 & 0 \\
cat & 4.3 & 16 & 6 & 1 \\
cat & 7.9 & 9 & 6 & 0 \\
cat & 6.1 & 7 & 5 & 0 \\
fox & 7.7 & 21 & 5 & 1 \\
fox & 8.1 & 25 & 4 & 1 \\
fox & 9.1 & 31 & 4 & 1 \\
fox & 9.7 & 12 & 5 & 1 \\
fox & 10.6 & 28 & 4 & 0 \\
fox & 8.6 & 18 & 4 & 1 \\
fox & 10.3 & 19 & 3 & 0 \\
\bottomrule()
\end{longtable}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-1}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-1}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, readxl, magrittr, janitor)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{spalten-wuxe4hlen-mit-select}{%
\section{\texorpdfstring{Spalten wÃ¤hlen mit
\texttt{select()}}{Spalten wÃ¤hlen mit select()}}\label{spalten-wuxe4hlen-mit-select}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{YouTube - Spalten auswÃ¤hlen mit select()}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/oV_7A2nMIrM}{EinfÃ¼hrung in
R - Teil 12 - Spalten auswÃ¤hlen mit select()} als Video zum nochmal
anschauen.
\end{tcolorbox}

{\marginnote{\begin{footnotesize}Wir nutzen die Funktion
\texttt{select()}um Spalten zu wÃ¤hlen.\end{footnotesize}}}

Der Datensatz, den wir im Experiment erschaffen, ist meist riesig. Jetzt
kÃ¶nnten wir natÃ¼rlich eine Exceltabelle mit unterschiedlichen Sheets
bzw. Reitern erstellen oder aber die \emph{Spalten} die wir brauchen in
R selektieren. Wir nutzen die Funktion \texttt{select()}um Spalten zu
wÃ¤hlen. Im folgenden Codeblock wÃ¤hlen wir die Spalten \texttt{animal},
\texttt{jump\_length} und \texttt{flea\_count}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, jump\_length, flea\_count)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 21 x 3
   animal jump_length flea_count
   <chr>        <dbl>      <dbl>
 1 dog            5.7         18
 2 dog            8.9         22
 3 dog           11.8         17
 4 dog            8.2         12
 5 dog            5.6         23
 6 dog            9.1         18
 7 dog            7.6         21
 8 cat            3.2         12
 9 cat            2.2         13
10 cat            5.4         11
# ... with 11 more rows
\end{verbatim}

Wir kÃ¶nnen die Spalten beim selektieren auch umbenennen und in eine
andere Reihenfolge bringen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{Sprungweite =}\NormalTok{ jump\_length, flea\_count, animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 21 x 3
   Sprungweite flea_count animal
         <dbl>      <dbl> <chr> 
 1         5.7         18 dog   
 2         8.9         22 dog   
 3        11.8         17 dog   
 4         8.2         12 dog   
 5         5.6         23 dog   
 6         9.1         18 dog   
 7         7.6         21 dog   
 8         3.2         12 cat   
 9         2.2         13 cat   
10         5.4         11 cat   
# ... with 11 more rows
\end{verbatim}

Du findest auf der englischen
\href{https://dplyr.tidyverse.org/reference/select.html}{Hilfeseite fÃ¼r
select()} noch weitere Beispiele fÃ¼r die Nutzung.

\hypertarget{zeilen-wuxe4hlen-mit-filter}{%
\section{\texorpdfstring{Zeilen wÃ¤hlen mit
\texttt{filter()}}{Zeilen wÃ¤hlen mit filter()}}\label{zeilen-wuxe4hlen-mit-filter}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{YouTube - Zeilen auswÃ¤hlen mit filter()}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/Pw_KnGWZjpM}{EinfÃ¼hrung in
R - Teil 13 - Zeilen auswÃ¤hlen mit filter()} als Video zum nochmal
anschauen.
\end{tcolorbox}

{\marginnote{\begin{footnotesize}Wir nutzen die Funktion
\texttt{filter()} um Zeilen nach Kriterien zu
wÃ¤hlen.\end{footnotesize}}}

WÃ¤hrend wir die Auswahl an Spalten gut und gerne auch in Excel
durchfÃ¼hren kÃ¶nnen, so ist dies bei der Auswahl der Zeilen nicht so
einfach. Wir kÃ¶nnen in R hier auf die Funktion \texttt{filter()}
zurÃ¼ckgreifen. Wir nutzen die Funktion \texttt{filter()} um Zeilen nach
Kriterien zu wÃ¤hlen.

Im folgenden Codeblock wÃ¤hlen wir die Zeilen aus in denen die Worte
\texttt{dog} und \texttt{fox} stehen. Wir nutzen dazu den Operator
\texttt{\%in\%} um auszudrÃ¼cken, dass wir alle EintrÃ¤ge in der Spalte
\texttt{animal} wollen die in dem Vektor \texttt{c("dog",\ "fox")}
beschrieben sind.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(animal }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"fox"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 14 x 5
   animal jump_length flea_count grade infected
   <chr>        <dbl>      <dbl> <dbl>    <dbl>
 1 dog            5.7         18     8        0
 2 dog            8.9         22     8        1
 3 dog           11.8         17     6        1
 4 dog            8.2         12     8        0
 5 dog            5.6         23     7        1
 6 dog            9.1         18     7        0
 7 dog            7.6         21     9        0
 8 fox            7.7         21     5        1
 9 fox            8.1         25     4        1
10 fox            9.1         31     4        1
11 fox            9.7         12     5        1
12 fox           10.6         28     4        0
13 fox            8.6         18     4        1
14 fox           10.3         19     3        0
\end{verbatim}

Es stehen dir Folgende logische Operatoren zu VerfÃ¼gung wie in
Tabelle~\ref{tbl-logical-operators} gezeigt. Am Anfang ist es immer
etwas schwer sich in den logischen Operatoren zurechtzufinden. Daher
kann ich dir nur den Tipp geben einmal die Operatoren selber
auszuprobieren und zu schauen, was du da so rausfilterst.

\hypertarget{tbl-logical-operators}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2927}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7073}}@{}}
\caption{\label{tbl-logical-operators}Logische Opertairen und R und
deren Beschreibung}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Logischer Operator}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Beschreibung}
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Logischer Operator}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Beschreibung}
\end{minipage} \\
\midrule()
\endhead
\textbf{\textless{}} & kleiner als (eng. \emph{less than}) \\
\textbf{\textless=} & kleiner als oder gleich (eng. \emph{less than or
equal to}) \\
\textbf{\textgreater{}} & grÃ¶Ãer als (eng. \emph{greater than}) \\
\textbf{\textgreater=} & grÃ¶Ãer als oder gleich (eng. \emph{greater than
or equal to}) \\
\textbf{==} & exact gleich (eng. \emph{exactly equal to}) \\
\textbf{!=} & nicht gleich (eng. \emph{not equal to}) \\
\textbf{!x} & nicht (eng. \emph{not x}) \\
\textbf{x \textbar{} y} & oder (eng. \emph{x or y}) \\
\textbf{x \& y} & und (eng. \emph{x and y}) \\
\bottomrule()
\end{longtable}

Hier ein paar Beispiele. Probiere gerne auch mal Operatoren selber aus.
Im folgenden Codeblock wollen wir nur die Zeilen haben, die eine Anzahl
an FlÃ¶hen grÃ¶Ãer von 15 haben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(flea\_count }\SpecialCharTok{\textgreater{}} \DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 13 x 5
   animal jump_length flea_count grade infected
   <chr>        <dbl>      <dbl> <dbl>    <dbl>
 1 dog            5.7         18     8        0
 2 dog            8.9         22     8        1
 3 dog           11.8         17     6        1
 4 dog            5.6         23     7        1
 5 dog            9.1         18     7        0
 6 dog            7.6         21     9        0
 7 cat            4.3         16     6        1
 8 fox            7.7         21     5        1
 9 fox            8.1         25     4        1
10 fox            9.1         31     4        1
11 fox           10.6         28     4        0
12 fox            8.6         18     4        1
13 fox           10.3         19     3        0
\end{verbatim}

Wir wollen nur die infizierten Tiere haben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(infected }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 10 x 5
   animal jump_length flea_count grade infected
   <chr>        <dbl>      <dbl> <dbl>    <dbl>
 1 dog            8.9         22     8        1
 2 dog           11.8         17     6        1
 3 dog            5.6         23     7        1
 4 cat            3.2         12     7        1
 5 cat            4.3         16     6        1
 6 fox            7.7         21     5        1
 7 fox            8.1         25     4        1
 8 fox            9.1         31     4        1
 9 fox            9.7         12     5        1
10 fox            8.6         18     4        1
\end{verbatim}

Wir wollen nur die infizierten Tiere haben UND die Tiere mit einer
Flohanzahl grÃ¶Ãer als 20.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(infected }\SpecialCharTok{==} \ConstantTok{TRUE} \SpecialCharTok{\&}\NormalTok{ flea\_count }\SpecialCharTok{\textgreater{}} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 5
  animal jump_length flea_count grade infected
  <chr>        <dbl>      <dbl> <dbl>    <dbl>
1 dog            8.9         22     8        1
2 dog            5.6         23     7        1
3 fox            7.7         21     5        1
4 fox            8.1         25     4        1
5 fox            9.1         31     4        1
\end{verbatim}

Du findest auf der englischen
\href{https://dplyr.tidyverse.org/reference/filter.html\%3E}{Hilfeseite
fÃ¼r filter()} noch weitere Beispiele fÃ¼r die Nutzung.

\hypertarget{spalten-uxe4ndern-mit-mutate}{%
\section{\texorpdfstring{Spalten Ã¤ndern mit
\texttt{mutate()}}{Spalten Ã¤ndern mit mutate()}}\label{spalten-uxe4ndern-mit-mutate}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{YouTube - Eigenschaften von Variablen Ã¤ndern mit mutate()}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/P6eum3wy9Ek}{EinfÃ¼hrung in
R - Teil 14 - Eigenschaften von Variablen Ã¤ndern mit mutate()} als Video
zum nochmal anschauen.
\end{tcolorbox}

\marginnote{\begin{footnotesize}

Wir nutzen die Funktion \texttt{mutate()} um die Eigenschaften von
Spalten daher Variablen zu Ã¤ndern.

Die Reihenfolge der Funktionen ist wichtig um unliebsame Effekte zu
vermeiden.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Erst wÃ¤hlen wir die Spalten mit \texttt{select()}
\item
  Dann filtern wir die Zeilen mit \texttt{filter()}
\item
  AbschlieÃend Ã¤ndern wir die Eigenschaften der Spalten mit
  \texttt{mutate()}
\end{enumerate}

\end{footnotesize}}

Nachdem wir die Spalten mit \texttt{select()} udn eventuell die Zeieln
mit \texttt{filter()} gewÃ¤hlt haben. mÃ¼ssen wir jetzt noch die
Eigenschaften der Spalten Ã¤ndern. Das Ãndern mÃ¼ssen wir nicht immer tun,
aber hÃ¤ufig mÃ¼ssen wir noch einen Faktor erschaffen. Wir nutzen noch die
Funktion \texttt{pull()} um uns die Spalte \texttt{animal} aus dem
Datensatz zu ziehen. Nur so sehen wir die vollen Eigenschaften des
Faktors. SpÃ¤ter nutzen wir \texttt{pull} seltener und nur um zu
kontrollieren, was wir gemacht haben.

Im folgenden Codeblock verwandeln wir die Variable \texttt{animal} in
einen Faktor durch die Funktion \texttt{as\_factor}. Wir sehen, dass die
Level des Faktoes so sortiert sind, wie das Auftreten in der Spalte
\texttt{animal}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] dog dog dog dog dog dog dog cat cat cat cat cat cat cat fox fox fox fox fox
[20] fox fox
Levels: dog cat fox
\end{verbatim}

Wollen wir die Sortierung der Level Ã¤ndern, kÃ¶nnen wir die Funktion
\texttt{factor()} nutzen. Wir Ã¤ndern die Sortierung des Faktors zu
\texttt{fox}, \texttt{dog} und \texttt{cat}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{factor}\NormalTok{(animal, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"fox"}\NormalTok{, }\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] dog dog dog dog dog dog dog cat cat cat cat cat cat cat fox fox fox fox fox
[20] fox fox
Levels: fox dog cat
\end{verbatim}

Wir kÃ¶nnen auch die Namen (eng. \emph{labels}) der Level Ã¤ndern. Hier
musst du nur aufpassen wie du die alten Labels Ã¼berschreibst. Wenn ich
\emph{gleichzeitig} die Level und die Labels Ã¤ndere komme ich hÃ¤ufig
durcheinander. Da muss du eventuell nochmal schauen, ob auch alles so
geklappt hat wie du wolltest.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{factor}\NormalTok{(animal, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Hund"}\NormalTok{, }\StringTok{"Katze"}\NormalTok{, }\StringTok{"Fuchs"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] Katze Katze Katze Katze Katze Katze Katze Hund  Hund  Hund  Hund  Hund 
[13] Hund  Hund  Fuchs Fuchs Fuchs Fuchs Fuchs Fuchs Fuchs
Levels: Hund Katze Fuchs
\end{verbatim}

Du findest auf der englischen
\href{https://dplyr.tidyverse.org/reference/mutate.html}{Hilfeseite fÃ¼r
mutate()} noch weitere Beispiele fÃ¼r die Nutzung. Insbesondere die
Nutzung von \texttt{mutate()} Ã¼ber mehrere Spalten gleichzeitig erlaubt
sehr effiezientes Programmieren. Aber das ist fÃ¼r den Anfang etwas viel.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Die Funktionen select(), filter() und mutate() in R}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Bitte schaue dir auch die Hilfeseiten der Funktionen an. In diesem
Skript kann ich nicht alle FunktionalitÃ¤ten der Funktionen zeigen. Oder
du kommst in das R Tutorium welches ich anbiete und fragst dort nach den
MÃ¶glichkeiten Daten in R zu verÃ¤ndern.
\end{tcolorbox}

\hypertarget{gruppieren-mit-group_by}{%
\section{\texorpdfstring{Gruppieren mit
\texttt{group\_by()}}{Gruppieren mit group\_by()}}\label{gruppieren-mit-group_by}}

Sobald wir einen Faktor erschaffen haben, kÃ¶nnen wir die Daten in R auch
nach dem Faktor \emph{gruppieren}. Das heiÃt wir nutzen die Funktion
\texttt{group\_by()} um R mitzuteilen, dass nun folgende Funktionen
\emph{getrennt} fÃ¼r die einzelen Gruppen erfolgen sollen. Im folgenden
Codeblock siehst du die Anwendung.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 21 x 5
# Groups:   animal [3]
   animal jump_length flea_count grade infected
   <fct>        <dbl>      <dbl> <dbl>    <dbl>
 1 dog            5.7         18     8        0
 2 dog            8.9         22     8        1
 3 dog           11.8         17     6        1
 4 dog            8.2         12     8        0
 5 dog            5.6         23     7        1
 6 dog            9.1         18     7        0
 7 dog            7.6         21     9        0
 8 cat            3.2         12     7        1
 9 cat            2.2         13     5        0
10 cat            5.4         11     7        0
# ... with 11 more rows
\end{verbatim}

Auf den ersten Blick Ã¤ndert sich nicht viel. Es entsteht aber die Zeile
\texttt{\#\ Groups:\ animal\ {[}3{]}}. Wir wissen nun, dass wir nach der
Variable \texttt{animal} mit drei Gruppen die Datentabelle gruppiert
haben. Die Anwendung siehst du in Kapitel~\ref{sec-desc-group-by} bei
der Berechung von deskriptiven MaÃzahlen.

\hypertarget{mehr-informationen-durch-glimpse-und-str}{%
\section{\texorpdfstring{Mehr Informationen durch \texttt{glimpse()} und
\texttt{str()}}{Mehr Informationen durch glimpse() und str()}}\label{mehr-informationen-durch-glimpse-und-str}}

Am Ende noch zwei Funktionen zur Kontrolle, was wir hier eigentlich
gerade tun. Mit der Funktion \texttt{glimpse()} kÃ¶nnen wir uns einen
Einblick in die Daten geben lassen. Wir sehen dann nochmal kurz und
knapp wieviel Zeieln und Spalten wir haben und welche Inhalte in den
Spalten stehen. Die gleichen Informationen erhalten wir auch durch die
Funktion \texttt{str()}. Die Funktion \texttt{str()}geht aber noch einen
Schritt weiter und nennt uns auch Informationen zu dem Objekt. Daher wir
wissen jetzt, dass es sich beim dem Objekt \texttt{data\_tbl} um ein
\texttt{tibble()} handelt.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(data\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 21
Columns: 5
$ animal      <chr> "dog", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "c~
$ jump_length <dbl> 5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6, 3.2, 2.2, 5.4, 4.1, 4.~
$ flea_count  <dbl> 18, 22, 17, 12, 23, 18, 21, 12, 13, 11, 12, 16, 9, 7, 21, ~
$ grade       <dbl> 8, 8, 6, 8, 7, 7, 9, 7, 5, 7, 6, 6, 6, 5, 5, 4, 4, 5, 4, 4~
$ infected    <dbl> 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(data\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
tibble [21 x 5] (S3: tbl_df/tbl/data.frame)
 $ animal     : chr [1:21] "dog" "dog" "dog" "dog" ...
 $ jump_length: num [1:21] 5.7 8.9 11.8 8.2 5.6 9.1 7.6 3.2 2.2 5.4 ...
 $ flea_count : num [1:21] 18 22 17 12 23 18 21 12 13 11 ...
 $ grade      : num [1:21] 8 8 6 8 7 7 9 7 5 7 ...
 $ infected   : num [1:21] 0 1 1 0 1 0 0 1 0 0 ...
\end{verbatim}

\part{Explorative Datenanalyse}

\emph{Version vom September 14, 2022 um 08:46:38}

{\marginnote{\begin{footnotesize}Wir kÃ¼rzen die \textbf{e}xplorative
\textbf{D}aten\textbf{a}nalyse hÃ¤ufig als \textbf{EDA}
ab.\end{footnotesize}}}

Wir haben die Daten jetzt in R Eingelesen und im Zweifel noch angepasst.
Nun wollen wir uns die Daten einmal angucken. Nicht in dem Sinne, dass
wir auf die Daten\emph{tabelle} schauen. Sondern wir wollen die Daten
visualisieren. Wir erstellen Abbildungen von den Daten und versuchen so
mehr Ã¼ber die Daten zu erfahren. Sehen wir ZusammenhÃ¤nge zwischen
verschiedenen Variablen bzw. Spalten? Wir fÃ¼hren eine explorative
Datenanalyse durch. Ãber die explorative Datenanalyse wollen wir uns in
diesem Kapitel einmal Gedanken machen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in R per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube
\href{https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC}{Grundlagen
in R} als Video Reihe. Du musst die Grundlagen in R verstanden haben,
damit du dem R Code folgen kannst.
\end{tcolorbox}

\hypertarget{sec-desc-stat}{%
\chapter{Deskriptive Statistik}\label{sec-desc-stat}}

\emph{Version vom September 14, 2022 um 08:46:50}

{\marginnote{\begin{footnotesize}Eigentlich \emph{schÃ¤tzen} wir die
\textbf{Parameter einer Verteilung}. Aber das kommt nochmal spÃ¤ter
genauer, wenn wir wissen was Verteilungen sind.\end{footnotesize}}}

Wir nutzen die deskriptive Statistik um Zahlen zusammenzufassen. Das
heiÃt wir haben einen Datensatz vorliegen wie den Datensatz
\texttt{flea\_dog\_cat.xlsx}. Wir wollen jetzt den groÃen Datensatz in
wenige Zahlen wiedergeben. Warum wenige Zahlen? Wenn wir das Ergebnis
\emph{prÃ¤sentieren} wollen, dann mÃ¼ssen es wenige Zahlen sein, die den
Datensatz gut zusammenfassen. Daher ist es wichtig zu wissen, dass wir
\emph{dutzende bis hunderte Zahlen} durch meist eine oder zwei Zahlen
beschreiben wollen. Wir brauchen die statistischen MaÃzahlen aus diesem
Kapitel spÃ¤ter um teilweise noch extrem grÃ¶Ãere DatensÃ¤tze darstellen zu
kÃ¶nnen. Ebenso werden wir die MaÃzahlen aus diesem Kapitel dafÃ¼r
verwenden statistische Tests und Modelle zu rechnen.

Nehmen wir nun als Beispiel die Sprungweiten in {[}cm{]} von
HundeflÃ¶hen. Wir messen sieben Sprungweiten von sieben HundeflÃ¶hen und
messen dabei folgende Werte in {[}cm{]}: 5.7, 8.9, 11.8, 8.2, 5.6, 9.1
und 7.6. Wir schreiben nun y als einen Vektor in der Form

\[
y = \{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\}.
\]

In R wÃ¼rde der Vektor wie etwas anders aussehen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{5.7}\NormalTok{, }\FloatTok{8.9}\NormalTok{, }\FloatTok{11.8}\NormalTok{, }\FloatTok{8.2}\NormalTok{, }\FloatTok{5.6}\NormalTok{, }\FloatTok{9.1}\NormalTok{, }\FloatTok{7.6}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Wir wollen nun die Zahlen in \(y\) beschrieben und durch wenige andere
Zahlen zusammenfassen. Einige der statistischen MaÃzahlen sind dir
vermutlich schon bekannt, andere eher neu.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Parametrik versus Nicht-Parametrik}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]

Wenn wir einen Zahlenvektor wie durch
\(y = \{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\}\) beschrieben
zusammenfassen wollen, haben wir zwei MÃ¶glichkeiten.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Die \textbf{parametrische Variante} indem wir \emph{mit den Zahlen}
  rechnen und deskriptive MaÃzahlen wie Mittelwert, Varianz und
  Standardabweichung berechnen. Diese MaÃzahlen kommen aber in den
  Zahlen nicht vor.
\item
  Die \textbf{nicht-parametrische} Variante indem wir die Zahlen in
  RÃ¤nge umwandeln, also sortieren, und \emph{mit den RÃ¤ngen} der Zahlen
  rechnen. Die deskriptiven MaÃzahlen wÃ¤ren dann Median, Quantile und
  Quartile.
\end{enumerate}

\end{tcolorbox}

\hypertarget{mittelwert}{%
\section{Mittelwert}\label{mittelwert}}

Der Mittelwert einer Zahlenreihe beschreibt den Schwerpunkt der Zahlen.
Der Mittelwert wird auch als Lageparameter benannt.
{\marginnote{\begin{footnotesize}Der \textbf{Mittelwert} und der
\textbf{Median} sind zwei Lageparameter einer Verteilung. Beide
beschreiben die Stelle, wo die Verteilungskurve am hÃ¶chsten
ist.\end{footnotesize}}} Wir schreiben den Mittelwert mit einem Strich
Ã¼ber den Vektor, der die Zahlen enthÃ¤lt. Im folgenden ist die Formel fÃ¼r
den Mittelwert der Sprungweite in {[}cm{]} der Hunde gezeigt. Der
Mittelwert ist in dem Sinne eine kÃ¼nstliche Zahl, da der Mittlwert
hÃ¤ufig nicht in den beobachteten Zahlen vorkommt.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Wir werden immer mal wieder \textbf{Formeln vereinfachen}. Zum Beispiel
nur \(\sum\) schreiben anstatt \(\sum_i^n\), wenn wir einen Vektor
aufsummieren und uns die Indizes sparen\ldots{}

\[
\bar{y} = \sum_{i=1}^{n}\cfrac{x_i}{n} =
\cfrac{5.7 + 8.9 + 11.8 + 8.2 + 5.6 + 9.1 + 7.6}{7} =
8.13
\]

Im Durchschnitt oder im Mittel springen HundeflÃ¶he 8.13 cm weit.

In der Abbildung~\ref{fig-index-drawn} wollen wir die Formel nochmal
visualisieren. Vielleicht fÃ¤llt dir dann der Zusammenhang von dem Index
\(i\) und der gesamten Fallzahl \(n\) leichter.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/index-drawn.png}

}

\caption{\label{fig-index-drawn}Zusamenhang zwischen \(y\) sowie dem
Index \(i\) in der Formel fÃ¼r den Mittelwert.}

\end{figure}

In R kÃ¶nnen wir den Mittelwert einfach mit der Funktion \texttt{mean()}
berechnen. Wir wollen dann den Mittelwert noch auf die zweite
Kommastelle runden. Das machen wir dann mit der Funktion
\texttt{round()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ mean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8.13
\end{verbatim}

Wir erhalten das gleiche Ergebnis wie oben in unserer hÃ¤ndischen
Rechnung. Die HundeflÃ¶he springen im Mittel 8.13 cm weit.

Der Mittelwert ist eine bedeutende MaÃzahl der Normalverteilung. Daher
merken wir uns hier schon mal, dass wir den Mittelwert brauchen werden.
Auch wenn wir darÃ¼ber nachdenken ob sich zwei Gruppen unterscheiden, so
nutzen wir hierzu den Mitelwert. Unterscheiden sich die \emph{mittleren}
Sprungweiten in {[}cm{]} von Hunde- und KatzenflÃ¶hen?

\hypertarget{spannweite}{%
\section{Spannweite}\label{spannweite}}

Die \emph{Spannweite} erlaubt uns zu Ã¼berprÃ¼fen was die kleinste Zahl
und die grÃ¶Ãte Zahl ist. Also uns das Minimum und das Maximum einer
Zahlenreihe anzuschauen. Auf den ersten Blick mag das nicht so sinnig
sein, aber wenn wir uns hunderte von Beobachtungen anschauen, wollen wir
wissen, ob wir nicht einen Fehler bei Eintragen der Daten gemacht haben.
Wir wissen eigentlich, dass z.B keine negativen Zuwachsraten auftreten
kÃ¶nnen.

{\marginnote{\begin{footnotesize}Die Spannweite dient dazu in einem
Datensatz zu Ã¼bersprÃ¼fen ob die \textbf{Spalte}, oder auch
\textbf{Variable} genannt, den richtigen Zahlenraum aufweist. Das machen
wir durch die Funktion \texttt{range()}.\end{footnotesize}}}

\[
y_{range} = y_{max} - y_{min} = 12.1 - 4.9 = 7.2
\] Die HundeflÃ¶he springen in einer Spannweite von 7.2 cm. Das kommt
einem \emph{normal} vor. Die Spannweite ist nicht Ã¼bertrieben groÃ. Der
minimale Wert ist 4.9 und der maximale Wert it 12.1 und somit sind beide
Zahlen in Ordnung. Keine der beiden Zahlen ist Ã¼bertrieben groÃ oder gar
negativ.

In R kÃ¶nnen wir die Spannweite mit \texttt{range()} wie folgt berechnen.
Wir erhalten den minmialen udn maximalen Wert.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(y) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  5.6 11.8
\end{verbatim}

Wir merken uns, dass die Spannweite eine MaÃzahl fÃ¼r die ValiditÃ¤t der
Daten ist. Hat das Experiment geklappt oder kamen da nur komische Zahlen
bei raus, die wir so in der RealitÃ¤t nicht erwarten wÃ¼rden. Zum Beispiel
negative Sprungweiten, weil wir einmalauf das Minuszeichen gekommen
sind.

\hypertarget{varianz}{%
\section{Varianz}\label{varianz}}

Bis jetzt kÃ¶nnen wirmit dem Mittelwert \(\bar{y}\) die Lage oder den
Mittelpunkt unserer Zahlenreihe beschreiben. Uns fehlt damit aber die
Information Ã¼ber die Streuung der Zahlen. Sind die Zahlen alle eher
gleich oder sehr verschieden? Liegen die Zahlen daher alle bei dem
Mittelwert oder sind die Zahlen weit um den Mittelwert gestreut.

Die Streuung der Zahlen um den Mittelwert beschreibt die Varianz oder
auch \(s^2\). Wir berechnen die Varianz indem wir von jeder Zahl den
Mittelwert aller Zahlen abziehen und dann das Ergebnis quadrieren. Das
machen wir fÃ¼r alle Zahlen und addieren dann die Summe auf. Wir erhalten
die \emph{Quadratsumme} von \(y\).

{\marginnote{\begin{footnotesize}\textbf{Abweichungsquadrate} sind ein
wichtiges Konzept in der Statistik. Wenn wir wissen wollen, wie groÃ
eine Abweichung von einer Zahl zu einer anderen ist, dann nutzen wir
immer das Quadrat der Abweichung und bilden die
Quadratsumme..\end{footnotesize}}}

\[
s^2 = \sum_{i=1}^n\cfrac{(y_i - \bar{y})^2}{n-1} = \cfrac{(5.7 -
8.13)^2 + ... + (7.6 - 8.13)^2}{7-1} = 4.6
\]

Die Varianz berschreibt also die Streuung der Zahlen \emph{im Quadrat}
um den Mittelwert. Das heiÃt in unserem Beispiel, dass die Sprungweite
eine Varianz von 4.6 cm\(^2\) hat. Wir kÃ¶nnen Quadratzentimeter schlecht
interpretieren. Deshalb fÃ¼hren wir gleich die Wuzel der Varianz ein: die
Standardabweichung.

In R lÃ¤sst sich die Varianz einfach durch die Funktion \texttt{var()}
berechnen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ var }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.6
\end{verbatim}

Wir benÃ¶tigen die Varianz hÃ¤ufig nur als Zwischenschritt um die
Standardabweichung zu berechnen. Das Konzept der Abweichungsquadrate
benÃ¶tigen wir aber in der Varianzanalyse (ANOVA) und fÃ¼r die
Beschreibung einer Normalverteilung.

\hypertarget{standardabweichung}{%
\section{Standardabweichung}\label{standardabweichung}}

Die \emph{Standardabweichugn} ist die Wurzel der Varianz. Wo die Varianz
die Abweichung der Sprungweite in {[}cm\(^2\){]} beschreibt, beschreibt
die Standardabweichung die Streung der Sprungweite in {[}cm{]}.

\[
s = \sqrt{s^2} = \sqrt{4.6} = 2.14
\] {\marginnote{\begin{footnotesize}Wir schreiben immer den Mittelwert
plusminus die Standardabweichung. Also immer
\(\bar{y} \pm s\).\end{footnotesize}}}

Wir kÃ¶nnen also schreiben, dass die FlÃ¶he im Mittel 8.13 \(\pm\) 2.14cm
weit springen. Somit haben wir die Lage und die Streuung der Zahlenreihe
\(y\) der Sprungweite in {[}cm{]} mit zwei Zahlen beschrieben.

In R kÃ¶nnen wir die Standardabweichung einfach mit der Funktion
\texttt{sd()} berechnen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ sd }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.14
\end{verbatim}

\hypertarget{mittelwert-und-varianz---eine-herleitung}{%
\section{Mittelwert und Varianz - eine
Herleitung}\label{mittelwert-und-varianz---eine-herleitung}}

Was ist der Mitelwert und die Varianz genau? Schauen wir uns das einmal
in Abbildung~\ref{fig-mean-drawn} an. Die graue Linie oder Grade
beschreibt den Mittelwert der fÃ¼nf Beobachtungen. Die fÃ¼nf Beobachtungen
sind als blaue Punkt dargestellt. Auf der x-Achse ist nur der Index des
Punktes. Das heiÃt \(y_1\) ist der erste Punkte, das der Index \(i\)
gleich 1 ist.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/mean-drawn.png}

}

\caption{\label{fig-mean-drawn}Die graue Linie beschreibt den Mittelwert
der genau so durch die blauen Punkte geht, dass die AbstÃ¤nde der Punkte
oberhalb und unterhalb zu Null aufaddieren. Die Linie liegt in der Mitte
der Punkte. Die quadrierten AbstÃ¤nde sind die Varainz der blauen Punkte.
Auf der x-Achse ist der Index des Punktes eingetragen.}

\end{figure}

Wenn wir die Summe der Abweichungen von \(y_1\) bis \(y_5\) zu dem
Mittelwert bilden, so wird diese Summe 0 sein. Der Mittelwert liegt
genau in der Mitte der Punkte. In unserem Beispiel ist der Mittelwert
\(\bar{y} = 5.8\). Wi kÃ¶nnen jetzt die AbstÃ¤nde wie in der folgenden
Tabelle berechnen.

\begin{figure*}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1170}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0638}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3191}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2340}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2660}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Index \(i\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
y
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{y_i - \bar{y}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Wert
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\epsilon}\)
\end{minipage} \\
\midrule()
\endhead
1 & 5.7 & \(y_1 - \bar{y}\) & \(5.7 - 8.13 = -2.43\) & \(\epsilon_1\) \\
2 & 8.9 & \(y_2 - \bar{y}\) & \(8.9 - 8.13 = 0.77\) & \(\epsilon_2\) \\
3 & 11.8 & \(y_3 - \bar{y}\) & \(11.8 - 8.13 = 3.67\) &
\(\epsilon_3\) \\
4 & 8.2 & \(y_4 - \bar{y}\) & \(8.2 - 8.13 = 0.07\) & \(\epsilon_4\) \\
5 & 5.6 & \(y_5 - \bar{y}\) & \(5.6 - 8.13 = -2.53\) & \(\epsilon_5\) \\
6 & 9.1 & \(y_4 - \bar{y}\) & \(9.1 - 8.13 = 0.97\) & \(\epsilon_4\) \\
7 & 7.6 & \(y_5 - \bar{y}\) & \(7.6 - 8.13 = -0.53\) & \(\epsilon_5\) \\
\bottomrule()
\end{longtable}

\end{figure*}

Wir nennen die AbstÃ¤nde \(y_i - \bar{y}\) nach dem griechischen
Buchstaben Epsilon \(\epsilon\). Das \(\epsilon\) soll an das \(e\) von
\emph{Error} erinnern. So meint dann \emph{Error} eben auch Abweichung.
Ja, es gibt hier viele Worte fÃ¼r das gleiche Konzept.

Wir berechnen einen Mittelwert von den Epsilons mit
\(\bar{\epsilon} = 0\). Ein Mittelwert nahe Null bzw. von Null wundert
uns nicht. Wir haben die Gerade ja so gebaut, das nach oben und unten
die gleichen AbstÃ¤nde sind. Die Varianz \(s^2\) der \(y\) ist
\(s_y^2 = 4.599\) und die Varianz von \(\epsilon\) ist
\(s_{\epsilon}^2 = 4.599\). In beiden FÃ¤llen ist die Zahl gleich.

\hypertarget{standardfehler-oder-standard-error-se}{%
\section{Standardfehler oder Standard Error
(SE)}\label{standardfehler-oder-standard-error-se}}

Wenn wir den Mittelwert der Sprungweiten berichten dann gehÃ¶rt die
Standardabweichung der Sprungweiten mit als beschreibendes MaÃ dazu. Wir
berichten keinen Mittelwert ohne Standardabweichung.

Nun ist es aber so, dass der Mittelwert und die Standardabweichung von
der Fallzahl abhÃ¤ngen. Je mehr Fallzahl bzw. Beoabchtungen wir haben,
desto genauer wird der Mittelwert sein. Oder anders ausgedrÃ¼ckt
\(\bar{y}\) wird sich \(\mu_y\) annÃ¤hern. Das gleiche gilt auch fÃ¼r die
Standardabweichung \(s_y\), die sich \(\sigma_y\) mit steigender
Fallzahl annÃ¤hert.

Aus diesem Grund brauchen wir noch einen Fehler bzw. eine MaÃzahl fÃ¼r
die Streuung, die unabhÃ¤ngig von der Fallzahl ist. Wir skalieren also
die Standardabweichung mit der Fallzahl indem wir die Standardbweichung
durch die Wurzel der Fallzahl teilen.

\[
SE = \cfrac{s}{\sqrt{n}} = \cfrac{2.14}{2.65} = 0.81
\]

Wir mÃ¼ssten ein Paket in R laden um den Standardfehler zu berechnen. Das
Laden von zusÃ¤tzlichen Paketen wollen wir hier aber vermeiden; wir
kÃ¶nnen den Standardfehler auch einfach selber berechnen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(y))}
\NormalTok{se }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.81
\end{verbatim}

Wir erhalten einen Standardfehler von 0.81. Diese Zahl ist in dem Sinne
nicht zu interpretieren, da wir hier nur Experimente losgelÃ¶st von deren
Fallzahl miteinander vergleichen kÃ¶nnen. Auf der anderen Seite kÃ¶nnen
wir ohne die berichtete Fallzahl nicht vom Standardfehler auf die
Standardabweichung schlieÃen.

{\marginnote{\begin{footnotesize}Wir berichten den
\textbf{Standardfehler} immer zusammen mit der Fallzahl, so dass die
Standardabweichung berechnet werden kann.\end{footnotesize}}}

Wir benÃ¶tigen den Standardfehler eigentlich nicht zum Berichten von
Ergebnissen. Der Standardfehler ist nicht als Zahl interpretierbar und
somit eine reine statistische GrÃ¶Ãe. Tabelle~\ref{tbl-comp-stand-sem}
zeigt die Zusammenfassung und den Vergleich von Standardabweichung und
Standardfehler.

\hypertarget{tbl-comp-stand-sem}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{\label{tbl-comp-stand-sem}Zusammenfassung und Vergleich von
Standardabweichung und Standardfehler}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Standardabweichung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Standardfehler
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Standardabweichung
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Standardfehler
\end{minipage} \\
\midrule()
\endhead
\ldots{} ist eine Aussage Ã¼ber die Streuung der erhobenen Werte einer
Stichprobe. & \ldots{} ist eine Aussage Ã¼ber die Genauigkeit des
Mittelwertes einer Stichprobe. \\
\ldots{} hÃ¤ngt von der biologischen VariabilitÃ¤t ab. & \ldots{} abhÃ¤ngig
von der Messgenauigkeit \\
\ldots{} ist ein beschreibendes MaÃ. & \ldots{} ist ein statistisches
MaÃ. \\
\ldots{} ist nur wenig durch die GrÃ¶Ãe der Stichprobe beineinflussbar. &
\ldots{} steht im direkten VerhÃ¤ltnis zur GrÃ¶Ãe der Stichprobe. \\
\bottomrule()
\end{longtable}

\marginnote{\begin{footnotesize}

Der Standardfehler oder Standard Error (SE) oder Standard Error of the
Mean (SEM) wird uns wieder beim statistischen Testen und dem t-Test
begegnen.

\[
T_{calc} = \cfrac{\bar{y_1} - \bar{y_2}}{s_p \cdot \sqrt{\tfrac{2}{n}}} \approx \cfrac{\bar{y_1} - \bar{y_2}}{SEM}
\]

Der Nenner beim t-Test kann als Standardfehler gesehen werden. Wir
benÃ¶tigen den Standardfehler also im Kontext des statistischen Testen
als eine statististische MaÃzahl.

\end{footnotesize}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Standardfehler wird in der Metaanalyse genutzt}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Der Standardfehler ist bedeutend in der Metaanalyse. Also dem
gemeinsamen Auswerten von mehreren \emph{klinischen} Studien. Du kannst
im Buch
\href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html}{Doing
Meta-Analysis with R: A Hands-On Guide} mehr darÃ¼ber erfahren. Wir
nutzen keine Metaanalysen in den Grundlagenveranstaltungen.
\end{tcolorbox}

\hypertarget{median}{%
\section{Median}\label{median}}

Wir wollen uns jetzt noch eine andere Art der Zusammenfassung von Zahlen
anschauen. Anstatt \emph{mit den Zahlen} zu rechnen, sortieren wir jetzt
die Zahlen aus dem Vektor \(y = \{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\}\)
nach dem Rang. Wir rechnen dann \emph{mit den RÃ¤ngen}. Die kleinste Zahl
kriegt den kleinsten Rang. Wir kÃ¶nnen R nutzen Ã¼ber due Funktion
\texttt{sort()} um den Vektor \(y\) zu sortieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sort}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  5.6  5.7  7.6  8.2  8.9  9.1 11.8
\end{verbatim}

Der Median \(\tilde{y}\) ist die mittlere Zahl eines Zahlenvektors. Wir
haben hier sieben Zahlen, also ist der Median die vierte Zahl. Wir
mÃ¼ssen hier aber zwischen einr ungeraden Anzahl und einer geraden Anzahl
unterscheiden.

\begin{itemize}
\tightlist
\item
  \textbf{Ungerade Anzahl} von Zahlen, der Median ist die mittlere Zahl
  des Vektors \(y\): \[
  5.6,  5.7,  7.6,  \underbrace{8.2,}_{Median}  8.9,  9.1, 11.8
  \]
\end{itemize}

In R kÃ¶nnen wir den Median einfach mit der Funktion
\texttt{median()}berechnen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{median}\NormalTok{(y) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8.2
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{Gerade Anzahl} von Zahlen, der Median ist der Mittelwert der
  \emph{beiden} mittleren Zahlen des Vektors \(y\): \[
  5.6,  5.7,  7.6,  \underbrace{8.2, 8.9,}_{Median = \tfrac{8.2+8.9}{2}=8.55} 9.1, 11.8, \color{blue}{13.1}
  \]
\end{itemize}

In R kÃ¶nnen wir den Median wieder einfach mit der Funktion
\texttt{median()}berechnen. Wir mÃ¼ssen nur die Zahl 13.1 zu dem Vektor
\texttt{y} mit der Funktion \texttt{c()} hinzufÃ¼gen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(y, }\FloatTok{13.1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{median}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8.55
\end{verbatim}

{\marginnote{\begin{footnotesize}Wenn der \textbf{Mittelwert} stark von
dem \textbf{Median} abweicht, deutet dies auf eine schiefe Verteilung
oder aber AusreiÃer in den Daten hin. Wir mÃ¼ssen dann in der
explorativen Datenanalyse der Sachlage nachgehen\end{footnotesize}}}

Der Median ist eine Alternative zu dem Mitelwert. Insbesondere in
FÃ¤llen, wo es sehr groÃe Zahlen gibt, die den Mittelwert in der Aussage
\emph{verzerren}, kann der Median sinnvoll sein.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Median versus Mittelwert}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Zur Veranschaulichung des Unterschiedes zwischen Median und Mittelwert
nehmen wir die Mietpreise in New York. Der \emph{mittlere} Mietpreis fÃ¼r
eine 2-Zimmerwohnung in Manhattan liegt bei 5000\$ pro Monat. In den
\emph{mittleren} Mietpreis gehen aber auch die Mieten der Billionaires'
Row mit ein. Der \emph{mediane} Mietpreis liegt bei 4000\$. Die hohen
Mieten \emph{ziehen} den Mittelwert nach rechts.
\end{tcolorbox}

\hypertarget{quantile-und-quartile}{%
\section{Quantile und Quartile}\label{quantile-und-quartile}}

Bei dem Mittelwert beschreibt die Standardabweichung die Streuung der
Daten um den Mitelwert. Bei dem Median sind dies die \emph{Quartile}.
Die Quartile beschreiben die Streuung der Daten um den Median. Um die
Quartile bestimmen zu kÃ¶nnen, teilen wir die Daten in 100 Quantile. Du
kannst dir Quantile wie Prozente vorstellen. Wir schneiden die Daten
also in 100 Scheiben. Das geht natÃ¼rlich erst wirklich, wenn wir hundert
Zahlen haben. Deshalb hilft man sich mit Qua\textbf{r}tilen - von
Quarta, ein Viertel - aus. Tabelle~\ref{tbl-quart-quant} zeigt den
Zusammenhang.

\hypertarget{tbl-quart-quant}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-quart-quant}Zusammenfassung und Vergleich von
Quantilen, Quartilen und Median}\tabularnewline
\toprule()
Quantile & Quartile & Median \\
\midrule()
\endfirsthead
\toprule()
Quantile & Quartile & Median \\
\midrule()
\endhead
25\% Quantile & 1\(^{st}\) Quartile & \\
50\% Quantile & 2\(^{nd}\) Quartile & Median \\
75\% Quantile & 3\(^{rd}\) Quartile & \\
\bottomrule()
\end{longtable}

Wir bestimmen die Quartile wie den Median. Wir mÃ¼ssen unterscheiden, ob
wir eine ungerade Anzahl an Zahlen oder eine gerade Anzahl an Zahlen
vorliegen haben.

\begin{itemize}
\item
  \textbf{Ungerade Anzahl} von Zahlen, das 1\(^{st}\) Quartile ist die
  mittlere Zahl des unteren Mittels und das 3\(^{rd}\) Quartile ist die
  mittlere Zahl des oberen Mittels des Vektors \(y\): \[
  5.6,  \underbrace{5.7,}_{1st\ Quartile}  7.6,  8.2,  8.9,  \underbrace{9.1,}_{3rd\ Quartile} 11.8
  \]
\item
  \textbf{Gerade Anzahl} von Zahlen, das 1\(^{st}\) Quartile ist der
  Mittelwert der beiden mittleren Zahl des unteren Mittels und das
  3\(^{rd}\) Quartile ist der Mitelwert der beiden mittleren Zahlen des
  oberen Mittels des Vektors \(y\): \[
  5.6,  \underbrace{5.7, 7.6,}_{1st\ Quartile = \tfrac{5.7+7.6}{2}=6.65}    8.2,  8.9,  \underbrace{9.1, 11.8}_{3rd\ Quartile = \tfrac{9.1+11.8}{2}=10.45} \color{blue}{13.1}
  \]
\end{itemize}

{\marginnote{\begin{footnotesize}Das \textbf{95\% Quantile} und das
\textbf{97.25\% Quantile} werden wir spÃ¤ter nochmal im statistischen
Testen brauchen. Auch hier ist die Idee, dass wir die Daten in hundert
Teile schneiden und uns dann die extremen Zahlen
anschauen.\end{footnotesize}}}

In R kÃ¶nnen wir den Median einfach mit der Funktion \texttt{quantile()}
berechnen. Wir berechnen hier das 25\% Quantile also das 1\(^{st}\)
Quartile sowie das 50\% Quantile also den Median und das 75\% Quantile
also das 3\(^{rd}\) Quartile.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{quantile}\NormalTok{(}\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 25%  50%  75% 
6.65 8.20 9.00 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(y, }\FloatTok{13.1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{quantile}\NormalTok{(}\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 25%  50%  75% 
7.12 8.55 9.77 
\end{verbatim}

Warum unterscheiden sich die hÃ¤ndisch berechneten Quartile von den
Quartilen aus R? Es gibt verschiedene Arten der Berechnung. In der
Klausur nutzen wir die Art und Weise wie die hÃ¤ndische Berechnung hier
beschrieben ist. SpÃ¤ter in der Anwendung nehmen wir die Werte, die R
ausgibt. Die Abweichungen sind so maginal, dass wir diese Abweichungen
in der praktischen Anwendung ignorieren wollen.

\hypertarget{interquartilesabstand-iqr}{%
\section{Interquartilesabstand (IQR)}\label{interquartilesabstand-iqr}}

Der Interquartilesabstand (IQR) beschreibt den Abstand zwischen dem
1\(^{st}\) Quartile und dem 3\(^{rd}\) Quartile. Daher ist der
Interquartilesabstand (IQR) Ã¤hnlich der Spannweite zwischen dem
maximalen und minimalen Wert. Wir benÃ¶tigen das Interquartilesabstand
(IQR) in der explorativen Datenanalyse wenn wir einen Boxplot erstellen
wollen.

\[
IQR = 3^{rd}\,\mbox{Quartile} - 1^{st}\,\mbox{Quartile} = 9.1 - 5.7 = 3.4
\]

\hypertarget{sec-desc-group-by}{%
\section{Zusammenfassen von Daten per Faktor}\label{sec-desc-group-by}}

Gut und soll ich jetzt fÃ¼r jeden Faktorlevel Ã¼berall den Mittelwert mit
\texttt{mean()} berechnen? Geht das nicht einfacher? Ja, geht es. Im
folgenden siehst du, wie du den verschiedene deskriptive MaÃzahlen in
einem Rutsch berechnen kannst.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(animal) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(jump\_length),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(jump\_length),}
            \AttributeTok{median =} \FunctionTok{median}\NormalTok{(jump\_length),}
            \AttributeTok{quantiles =} \FunctionTok{quantile}\NormalTok{(jump\_length, }
                                 \AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), round, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 5
# Groups:   animal [2]
  animal  mean    sd median quantiles
  <fct>  <dbl> <dbl>  <dbl>     <dbl>
1 dog     8.13  2.14    8.2      6.65
2 dog     8.13  2.14    8.2      8.2 
3 dog     8.13  2.14    8.2      9   
4 cat     4.74  1.9     4.3      3.65
5 cat     4.74  1.9     4.3      4.3 
6 cat     4.74  1.9     4.3      5.75
\end{verbatim}

\hypertarget{sec-eda-ggplot}{%
\chapter{Visualisierung von Daten}\label{sec-eda-ggplot}}

\emph{Version vom September 14, 2022 um 08:47:09}

{\marginnote{\begin{footnotesize}Wir nennen eine Abbildung auch hÃ¤ufig
Plot. Das ist der englische Begriff und hat nichts in unserem Kontext
mit einer FlÃ¤che zu tun.\end{footnotesize}}}

Ein wichtiger Teil in der Analyse von Daten ist die Visualisierung. Wir
glauben keine Auswertung eines mathematischen Algorithmus, wenn wir
nicht die BestÃ¤tigung in einer Abbildung sehen. Daher ist die
Visualisierung die Grundlage fÃ¼r ein fundiertes, wissenschaftliches
Arbeiten. In diesem Kapitel stelle ich dir verschiedene Abbilungen vor,
die uns helfen werden zu Verstehen ob es einen Zusammenhang zwischen Y
und X gibt. Wir haben ein \(y\) vorliegen, was wir auf die y-Achse eines
Graphen legen und daneben dann mehrere Variablen bzw. Spalten die wir
\(x\) nennen. Eine der Variablen legen wir auf die x-Achse des Graphen.
Nach den anderen \(x\) fÃ¤rben wir die Abbildung ein.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-2}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-2}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, readxl, ggmosaic, }
\NormalTok{               janitor, see, patchwork)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{grundlagen-in-ggplot}{%
\section{Grundlagen in ggplot()}\label{grundlagen-in-ggplot}}

{\marginnote{\begin{footnotesize}Im Gegensatz zu dem Pipe-Operator
\texttt{\%\textgreater{}\%} nutzt ggplot den Operator \texttt{+} um die
verschiedenen ggplot Funktionen (\texttt{geom\_}) miteinander zu
verbinden.\end{footnotesize}}}

Wir nutzen in R das R Paket \texttt{ggplot2} um unsere Daten zu
visualisieren. Die zentrale Idee von \texttt{ggplot2} ist, dass wir uns
eine Abbildung wie ein Sandwich bauen. Zuerst legen wir eine Scheibe
Brot hin und legen uns dann Scheibe fÃ¼r Scheibe weitere Schichten
Ã¼bereinander. Oder die Idee eines Bildes, wo wir erst die Leinwand
definieren und dann Farbschicht Ã¼ber Farbschicht auftragen. Das Konzept
von \texttt{ggplot2}ist schlecht zu be\emph{schreiben} deshalb habe ich
auch noch zwei Videos hierfÃ¼r gemacht. Um den Prozess von
\texttt{ggplot2} zu visualisieren\ldots{}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Grundlagen von ggplot() im Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/SGwSVzJ9C-s}{EinfÃ¼hrung in
R - Teil 16.0 - TrockenÃ¼bung ggplot2 simpel und einfach erklÃ¤rt} als
Video.

Sowie auch auf YouTube \href{https://youtu.be/SRRQQO3DXtc}{EinfÃ¼hrung in
R - Teil 16.1 - Abbildungen mit ggplot in R erstellen. Idee und Konzept
von ggplot} als Video. Also alles nochmal als Video - vielleicht
einfacher nachzuvollziehen als in einem FlieÃtext.
\end{tcolorbox}

Die Funktion \texttt{ggplot()} ist die zentrale Funktion, die die
Leinwand erschafft auf der wir dann verschiedene Schichten aufbringen
werden. Diese Schichten heiÃen \texttt{geom}. Es gibt nicht nur ein
\texttt{geom} sondern mehrere. Zum Beispiel das \texttt{geom\_boxplot}
fÃ¼r die Erstellung von Boxplots, das \texttt{geom\_histogram} fÃ¼r die
Erstellung von Histogrammen.
\href{https://ggplot2.tidyverse.org/reference/index.html}{Die Auswahl
ist riesig}. Die einzelnen Schichten werden dann Ã¼ber den Operator
\texttt{+} miteinander verbunden. Soviel erstmal zur TrockenÃ¼bung.
Schauen wir uns das ganze einmal an einem Beispiel an.

\hypertarget{datenbeispiel}{%
\subsection{Datenbeispiel}\label{datenbeispiel}}

Wir importieren den Datensatz \texttt{flea\_cat\_dog.xlsx} und wollen
einzelne Variablen visualisieren. Wir kennen den Datensatz schon aus dem
Kapitel~\ref{sec-example-2}. Dennoch nochmal hier der Datensatz in
Tabelle~\ref{tbl-cat-dog-ggplot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flea\_dog\_cat\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

{\marginnote{\begin{footnotesize}Spaltennamen sind in \textbf{Englisch}
und haben \textbf{keine Leerzeichen}. Die Funktion
\texttt{clean\_names()} aus dem R Paket \texttt{janitor} ist hier eine
Hilfe.\end{footnotesize}}}

Im folgenden ist es wichtig, dass du dir die Spaltennamen merkst. Wir
kÃ¶nnen nur die exakten, wortwÃ¶rtlichen Spaltennamen verwenden. Sonst
erhalten wir einen Fehler. Deshalb haben wir auch keine Leerzeichen in
den Spaltennamen.

\hypertarget{tbl-cat-dog-ggplot}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-cat-dog-ggplot}Beispieldatensatz fÃ¼r Eigenschaften
von FlÃ¶hen von zwei Tierarten.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
cat & 3.2 & 12 & 7 & 1 \\
cat & 2.2 & 13 & 5 & 0 \\
cat & 5.4 & 11 & 7 & 0 \\
cat & 4.1 & 12 & 6 & 0 \\
cat & 4.3 & 16 & 6 & 1 \\
cat & 7.9 & 9 & 6 & 0 \\
cat & 6.1 & 7 & 5 & 0 \\
\bottomrule()
\end{longtable}

\hypertarget{erste-abbildung-in-ggplot}{%
\subsection{Erste Abbildung in
ggplot()}\label{erste-abbildung-in-ggplot}}

Der folgende R Code erstellt die Leinwand in der
Abbildung~\ref{fig-ggplot-1} fÃ¼r die folgende, zusÃ¤tzliches Schichten
(\texttt{geom}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal , }\AttributeTok{y =}\NormalTok{ jump\_length))}
\end{Highlighting}
\end{Shaded}

Wir schauen uns einmal den Code im Detail an.

\begin{itemize}
\tightlist
\item
  \texttt{ggplot} ruft die Funktion auf. Die Funktion ist dafÃ¼r da den
  Plot zu zeichnen.
\item
  \texttt{data\ =\ flea\_dog\_cat\_tbl} bennent den Datensatz aus dem
  der Plot gebaut werden soll.
\item
  \texttt{aes()}ist die AbkÃ¼rzung fÃ¼r \emph{aesthetics} und beschreibt,
  was auf die x-Achse soll, was auf die y-Achse soll sowie ob es noch
  andere Faktoren in den Daten gibt.

  \begin{itemize}
  \tightlist
  \item
    \texttt{x} braucht den Spaltennamen fÃ¼r die Variable auf der
    x-Achse.
  \item
    \texttt{y} braucht den Spaltennamen fÃ¼r die Variable auf der
    y-Achse.
  \end{itemize}
\end{itemize}

{\marginnote{\begin{footnotesize}\textbf{Faktoren} meint hier andere
Gruppenvariablen. Variablen sind ein anderes Wort fÃ¼r Spalten. Also
Variablen die wir mit \texttt{as\_factor}erschaffen
haben.\end{footnotesize}}}

\begin{figure}

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-ggplot-1-1.pdf}

}

\caption{\label{fig-ggplot-1}Leere ggplot() Leinwand mit den Spalten
\texttt{animal} und \texttt{jump\_length} aus dem Datensatz
\texttt{flea\_dog\_cat\_tbl}.}

\end{figure}

Wir sehen, dass wir nichts sehen in Abbildung~\ref{fig-ggplot-1}. Der
Grund ist, dass wir noch kein \texttt{geom} hinzugefÃ¼gt haben. Das
\texttt{geom} beschreibt nun wie die Zahlen in der Datentabelle
\texttt{flea\_dog\_cat\_tbl} visualisiert werden sollen.

\hypertarget{huxe4ufig-verwendete-abbildungen}{%
\section{HÃ¤ufig verwendete
Abbildungen}\label{huxe4ufig-verwendete-abbildungen}}

In diesem Kapitel wollen wir durch die hÃ¤ufigsten und wichtigsten
Abbildungen in der explorativen Datenanalyse durchghen. Das wÃ¤ren im
folgenden diese Abbildungen:

\begin{itemize}
\tightlist
\item
  \textbf{Histogramm} in Kapitel~\ref{sec-eda-histogramm} fÃ¼r mehr als
  20 Beobachtungen (pro Gruppe). Wir nutzen ein Histogramm um die
  Verteilung einer Variable zu visualisieren.
\item
  \textbf{Boxplot} in Kapitel~\ref{sec-eda-boxplot} fÃ¼r 5 bis 20
  Beobachtungen (pro Gruppe). Ebenso wie bei einem Histogramm, geht es
  bei einem Boxplot auch um die Verteilung der einer Variable.
\item
  \textbf{Barplot} in Kapitel~\ref{sec-eda-barplot} fÃ¼r 5 und mehr
  Beobachtungen (pro Gruppe). Der Barplot oder das
  \textbf{Balkendiagramm} stellt den Mitelwert und die
  Standardabweichung da.
\item
  \textbf{Dotplot} in Kapitel~\ref{sec-eda-dotplot} fÃ¼r 3 bis 5
  Beobachtungen (pro Gruppe). Hier geht es weniger um die Verteilung der
  Variable, sondern darum die wenigen Beobachtungen zu visualisieren.
\item
  \textbf{Scatterplot} in Kapitel~\ref{sec-eda-scatter} fÃ¼r zwei
  kontinuierliche Variablen. Auch \textbf{xy-Plot} genannt. Die
  Abbildung, die dir bekannt sein mÃ¼sste. Wir zeichnen hier eine Grade
  durch eine Punktewolke.
\item
  \textbf{Mosaicplot} in Kapitel~\ref{sec-eda-mosaic} fÃ¼r zwei diskrete
  Variablen. Eine etwas seltene Abbildung, wenn wir Variablen abbilden
  wollen, die diskret sind bzw. aus Kategorien bestehen.
\end{itemize}

{\marginnote{\begin{footnotesize}Konkret ist eine \textbf{Variable}
gleich einer \textbf{Spalte} in einem Datensatz.\end{footnotesize}}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Histogramm, Boxplot, Scatterplot und Mosaicplot im Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/Zdw6NlLauNw}{EinfÃ¼hrung in
R - Teil 16.2 - Histogramm, Boxplot, Scatterplot und Mosaicplot mit
ggplot in R} als Video. Weitere Videos werden dann noch folgen und
ergÃ¤nzt.
\end{tcolorbox}

\hypertarget{sec-eda-histogramm}{%
\subsection{Histogramm}\label{sec-eda-histogramm}}

Wir nutzen fÃ¼r die Erstellung eines Histogramms den Datensatz
\texttt{dog\_fleas\_hist.csv}. Wir brauchen fÃ¼r ein anstÃ¤ndiges
Histogramm, wo du auch was erkennen kannst, mindestens 20 Beobachtung.
Am besten mehr noch mhr Beobachtungen. Deshalb schauen wir uns jetzt
einmal 39 Hunde an und zÃ¤hlen wieviele FlÃ¶he die Hunde jeweils haben,
dargestellt in der Spalte\texttt{flea\_count}. DarÃ¼ber hinaus bestimmen
wir auch noch das mittlere Gewicht der FlÃ¶he auf dem jeweiligen Hund,
dargestellt in der Spalte \texttt{flea\_weight}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dog\_fleas\_hist\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/dog\_fleas\_hist.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{tbl-cat-dog-histogram}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-cat-dog-histogram}Beispieldatensatz fÃ¼r die Anzahl
an FlÃ¶hen auf 39 Hunden. GezÃ¤hlt wurde die Anzahl an FlÃ¶hen
\texttt{flea\_count} und das gemittelte Gewicht der FlÃ¶he
\texttt{flea\_weight}.}\tabularnewline
\toprule()
flea\_count & flea\_weight \\
\midrule()
\endfirsthead
\toprule()
flea\_count & flea\_weight \\
\midrule()
\endhead
0 & 0.00 \\
1 & 7.43 \\
4 & 21.04 \\
2 & 20.07 \\
1 & 21.90 \\
0 & 0.00 \\
2 & 24.96 \\
1 & 27.08 \\
5 & 16.58 \\
1 & 19.92 \\
0 & 0.00 \\
0 & 0.00 \\
2 & 24.63 \\
4 & 21.64 \\
3 & 20.97 \\
1 & 23.15 \\
0 & 0.00 \\
3 & 14.91 \\
1 & 19.39 \\
2 & 17.66 \\
1 & 19.15 \\
1 & 25.10 \\
2 & 26.38 \\
2 & 19.33 \\
2 & 13.29 \\
1 & 17.81 \\
0 & 0.00 \\
2 & 23.56 \\
1 & 18.64 \\
1 & 15.64 \\
3 & 19.88 \\
1 & 18.40 \\
1 & 25.17 \\
0 & 0.00 \\
0 & 0.00 \\
\bottomrule()
\end{longtable}

Tabelle~\ref{tbl-cat-dog-histogram} zeigt den Datensatz
\texttt{dog\_fleas\_hist.csv}. Wir wollen jetzt die Variable
\texttt{flea\_count} und \texttt{flea\_weight} jeweils abbilden. Wir
beginnen mit der diskreten Variable \texttt{flea\_count}. Im Gegensatz
zu der Variable \texttt{flea\_weight} haben wir bei der Anzahl gleiche
Zahlen vorliegen, die wir dann zusammen darstellen kÃ¶nnen.
Abbildung~\ref{fig-dotplot-flea-1} zeigt die Darstellung der Tabelle.
Auf der x-Achse ist die Anzahl an FlÃ¶hen dargestellt. Auf der y-Achse
die Anzahl der jeweiligen Anzahl an FlÃ¶hen. Das klingt jetzt etwas
schief, aber schauen wir uns die Abbilung nÃ¤her an.

\begin{figure}

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-dotplot-flea-1-1.pdf}

}

\caption{\label{fig-dotplot-flea-1}Die Anzahl von FlÃ¶hen auf 39 Hunden.
Jeder Punkt entspricht einem Hund und der entsprechenden Anzahl an
FlÃ¶hen auf dem Hund.}

\end{figure}

Wir sehen in Abbildung~\ref{fig-dotplot-flea-1} das acht Hunde keine
FlÃ¶he hatten - also eine Anzahl an FlÃ¶hen von 0. Auf der anderen Seite
hatten zwei Hunde vier FlÃ¶he und ein Hund hatte sogar fÃ¼nf FlÃ¶he. Wir
sehen also die \emph{Verteilung} der Anzahl an FlÃ¶hen Ã¼ber alle unsere
39 Hundebeobachtungen.

Wir schauen uns aber die Verteilung der Anzahl an FlÃ¶hen meist nicht in
der Form von gestapelten Punkten an, sondern in der Form eines
Histogramms also einem Balkendiagramm.
Abbildung~\ref{fig-hist-flea-count} zeigt das Histogramm fÃ¼r die Anzahl
der FlÃ¶he.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Anzahl FlÃ¶he"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Anzahl"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-hist-flea-count-1.pdf}

}

\caption{\label{fig-hist-flea-count}Histogramm der Anzahl von FlÃ¶hen auf
39 Hunden.}

\end{figure}

Was sehen wir in der Abbildung~\ref{fig-hist-flea-count}? Anstatt von
gestapelten Punkten sehen wir jetzt Balken, die die jeweilige Anzahl an
FlÃ¶hen zusammenfassen. Der Unterschied ist bei einer diskreten Variable
wie der Anzahl (eng. \emph{count}) relativ gering.

Anders sieht es fÃ¼r kontenuierliche Variablen mit Kommazahlen aus.
Schauen wir uns das Gewicht der FlÃ¶he an, so sehen wir, dass es sehr
viele Zahlen gibt, die nur einmal vorkomen.
Abbildung~\ref{fig-hist-flea-1} zeigt das Histogramm fÃ¼r das Geicht der
FlÃ¶he.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_weight)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Gewicht [mg]"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Anzahl"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-hist-flea-1-1.pdf}

}

\caption{\label{fig-hist-flea-1}Histogramm des Gewichts von FlÃ¶hen auf
39 Hunden.}

\end{figure}

Wie entsteht nun ein Hisotgramm fÃ¼r konetnierliche Zahlen? Schauen wir
uns dafÃ¼r einmal ein kleineres Datenbeispiel an, in dem wir nur FlÃ¶he
mit einem Gewicht grÃ¶Ãer als 11 und kleiner als 19 wÃ¤heln. Wir nutzen
dazu die Funktion
\texttt{filter(flea\_weight\ \textgreater{}\ 11\ \&\ flea\_weight\ \textless{}\ 19)}.
Wir erhalten folgende Zahlen und das entsprechende Histogramm.

\begin{verbatim}
[1] 13.29 14.91 15.64 16.58 17.66 17.81 18.40 18.64
\end{verbatim}

\begin{figure}

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-hist-flea-2-1.pdf}

}

\caption{\label{fig-hist-flea-2}Zusammenhang zwischen den einzelnen
Beobachtungen und der HÃ¶he der einzelnen Balken am Beispiel von acht
Hunden.}

\end{figure}

Abbildung~\ref{fig-hist-flea-2} zeigt das Histogramm der reduzierten
Daten. Die roten vertikalen Linien zeigen die Position der einzelnen
Flohgewichte auf der x-Achse. Die blauen Hilfslinien machen nochmal
klarer, wie hoch die einzelnen Balken sind sowie welche Beobachtungen
auf der x-Achse in den jeweiligen Balken mit eingehen. Wir sehen, dass
wir einen Hund mit FlÃ¶hen haben, die zwischen 12.5 und 13.5 wiegen - der
entsprechende Balken erhÃ¤lt die Anzahl von eins. Auf der anderen Seite
sehen wir, dass es drei Hunde mit FlÃ¶hen, die zwischen 17.5 und 18.5
wiegen. Daher wÃ¤chst der Balken auf eine Anzahl von drei.

Wir kÃ¶nnen mit der Option \texttt{binwidth} in dem
\texttt{geom\_histogram()} einstellen, wie breit auf der x-Achse die
jeweiligen Balken sein sollen. Hier empfiehlt es sich verschiedene
Zahlen fÃ¼r \texttt{binwidth}auszuprobieren.

\hypertarget{density-plot}{%
\subsection{Density Plot}\label{density-plot}}

Eine weitere MÃ¶glichkeit sich eine Verteilung anzuschauen, ist die Daten
nicht als Balkendiagramm sondern als Densityplot - also Dichteverteilung
- anzusehen. Im Prinzip verwandeln wir die Balken in eine Kurve. Damit
wÃ¼rden wir im Prinzip unterschiedliche BalkenhÃ¶hen ausgleichen udn eine
``glattere'' Darstellung erreichen. Wir wir aber gleich sehen werden,
benÃ¶tigen wir dazu eine Menge an Beoabchtungen und auch dann ist das
Ergebnis eventuell nicht gut zu interpretieren.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Anzahl FlÃ¶he"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Anzahl"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Anzahl FlÃ¶he"}\NormalTok{, }\AttributeTok{y =} \StringTok{"HÃ¤ufigkeit"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-ggplot_files/figure-pdf/fig-dens-flea-1-1.pdf}

}

}

\subcaption{\label{fig-dens-flea-1-1}Histogramm}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-ggplot_files/figure-pdf/fig-dens-flea-1-2.pdf}

}

}

\subcaption{\label{fig-dens-flea-1-2}Densityplot}
\end{minipage}%

\caption{\label{fig-dens-flea-1}Zusammenhang von Histogramm und
Densityplot an der Anzahl der FlÃ¶he auf 39 Hunden.}

\end{figure*}

Abbildung~\ref{fig-dens-flea-1} zeigt auf der linken Seite erneut die
Abbildung des Histogramms als Balkendiagramm fÃ¼r die Anzahl der FlÃ¶he
auf den 39 Hunden. Auf der rechten Seite die entsprechenden gleichen
Daten als Denistyplot. Klar ist die Wellenbewegung des Densityplots zu
erkennen. Hier leigen zu wenige Beobachtungen und Kategorien auf der
x-Achse vor, so dass der Densityplot nicht zu empfehlen ist.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_weight)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{, }\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Gewicht [mg]"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Anzahl"}\NormalTok{) }

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dog\_fleas\_hist\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_weight)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{fill =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Gewicht [mg]"}\NormalTok{, }\AttributeTok{y =} \StringTok{"HÃ¤ufigkeit"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-ggplot_files/figure-pdf/fig-dens-flea-2-1.pdf}

}

}

\subcaption{\label{fig-dens-flea-2-1}Histogramm}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-ggplot_files/figure-pdf/fig-dens-flea-2-2.pdf}

}

}

\subcaption{\label{fig-dens-flea-2-2}Densityplot}
\end{minipage}%

\caption{\label{fig-dens-flea-2}Zusammenhang von Histogramm und
Densityplot am Gewicht der FlÃ¶he auf 39 Hunden.}

\end{figure*}

Abbildung~\ref{fig-dens-flea-2} zeigt auf der linken Seite erneut die
Abbildung des Histogramms als Balkendiagramm fÃ¼r das Gewicht der FlÃ¶he
auf den 39 Hunden. Insbesondere bei dieser Abbildung erkennst du die
Nachteile des Densityplot. Dadurch das es einen Peak von acht Hunden mit
einem Flohgewicht von 0 gibt, zeigt der Densityplot eine seltsame
Wellenform. Es emppfielt sich daher die Daten zuerst als Histogramm zu
betrachten.

\hypertarget{sec-eda-boxplot}{%
\subsection{Boxplot}\label{sec-eda-boxplot}}

In Kapitel~\ref{sec-desc-stat} haben wir den Median und die Quartile
kennengelernt. Mit dem Boxplot kÃ¶nnen wir den Median und die Quartile
visualisieren. In Abbildung~\ref{fig-boxplot-drawn} sehen wir einen
Boxplot, der den Median und die Quartile visualisiert. Die Box wird aus
dem IQR gebildet. Der Median wird als Strich in der Box gezeigt. Die
Schnurrhaare (eng. \emph{Whiskers}) sind das 1.5 fache des IQR. Punkte
die auÃerhalb der Schnurrhaare liegen werden als einzelne Punkte
dargestellt. Diese einzelnen Punkte werden auch als AusreiÃer (eng.
\emph{Outlier}) bezeichnet.

\begin{figure*}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/boxplot-drawn.png}

}

\caption{\label{fig-boxplot-drawn}Ein Boxplot der die statistischen
MaÃzahlen Median und Quartile visualisiert. Die Box wird aus dem IQR
gebildet. Der Median wird als Strich in der Box gezeigt. Die
Schnurrhaare sind das 1.5 fache des IQR. Punkte die auÃerhalb der
Schnurrhaare liegen werden als einzele Punkte dargestellt.}

\end{figure*}

In Abbildung~\ref{fig-boxplot-drawn-distribution} sehen wir den
Zusammenhang zwischen einem Histogramm, Densityplot und dem Boxplot. Der
Median \(\tilde{y}\) im Boxplot zeigt die hÃ¶chste Stelle des
Densityplots an. Durch einen Boxplot kann die Verteilung der
entsprechenden Zahlen abgeschÃ¤tzt werden.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/boxplot-drawn-distribution.png}

}

\caption{\label{fig-boxplot-drawn-distribution}Der Zusammenhang von
Histogram, Densityplot und Boxplot.}

\end{figure}

Die ``liegende'' Darstellung des Boxplots dient nur der
Veranschaulichung und dem VerstÃ¤ndnis des Zusammenhangs von Histogramm
und Boxplot. In der Abbildung~\ref{fig-boxplot-drawn-flipped} sehen wir
drei Boxplots fÃ¼r einen Faktor mit drei Leveln. Jedes Level wird duch
einen Boxplot dargestellt. Zum Beispiel eine DÃ¼ngerbehandlung mit drei
Konzentrationen. Auf der x-Achse wÃ¼rden wir die Behandelung finden und
auf der y-Achse das Trockengewicht in {[}kg/ha{]}.

\begin{figure}

{\centering \includegraphics[width=0.6\textwidth,height=\textheight]{./images/boxplot-drawn-flipped.png}

}

\caption{\label{fig-boxplot-drawn-flipped}Typische Darstellung von drei
Gruppen jeweils dargestellt durch einen Boxplot. Boxplots werden in der
Anwendung stehtend dargestellt. Insbesondere wenn die Boxplots mehrere
Gruppen reprÃ¤sentieren.}

\end{figure}

Wie erstellen wir nun einen Boxplot in R? Zuerst laden wir die Daten mit
der Funktion \texttt{read\_excel()} in R, wenn du die Daten als
\texttt{.xlsx} Datei vorliegen hast. Im XX kannst du nochmal das
Importieren von Daten wiederholen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flea\_dog\_cat\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-boxplot-flea-0-1.pdf}

}

\caption{\label{fig-boxplot-flea-0}An 39 Hunden wurde die Anzahl an
FlÃ¶hen gezÃ¤hlt.}

\end{figure}

In Abbildung~\ref{fig-boxplot-flea-0} ist der Boxplot fÃ¼r die Daten aus
der Datei \texttt{flea\_dog\_cat.xlsx} dargestellt. Auf der x-Achse
finden wir die Tierart als \texttt{cat} und \texttt{dog}. Auf der
y-Achse ist die Sprungweite in {[}cm{]} dargestellt.

Wir erkennen auf einen Blick, dass die Sprungweite von den HundeflÃ¶hen
weiter ist als die Sprungweite der KatzenflÃ¶he. Im Weiteren kÃ¶nnen wir
abschÃ¤tzen, dass die Streuung etwa gleich groÃ ist. Die Boxen sind in
etwa gleich groÃ und die Whiskers in etwa gleich lang.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
                                    \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{width =} \FloatTok{0.25}\NormalTok{, }\AttributeTok{shape =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Sprungweite [cm]"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-boxplot-freshmatter-2-1.pdf}

}

\caption{\label{fig-boxplot-freshmatter-2}An 39 Hunden wurde die Anzahl
an FlÃ¶hen gezÃ¤hlt.}

\end{figure}

Wir neigen dazu die Boxplots Ã¼berzuinterpretieren, wenn die Anzahl der
Beobachtungen klein ist. Deshalb kÃ¶nnen wir mit dem
\texttt{geom\_jitter()} noch die Beobachtungen zu den Boxplot ergÃ¤nzen,
dargestellt in Abbildung~\ref{fig-boxplot-freshmatter-2}. Die Funktion
\texttt{geom\_jitter()} streut die Punkte zufÃ¤llig, so dass keine Punkte
Ã¼bereinanderliegen. Wir haben hier die Streuuweite durch die Option
\texttt{width\ =\ 0.25} etwas eingeschrÃ¤nkt. DarÃ¼ber hinaus habe wir das
Aussehen der Punkte mit \texttt{shape\ =\ 1} geÃ¤ndert, so dass wir die
Jitter-Punkte von den potenziellen AusreiÃer-Punkten unterscheiden
kÃ¶nnen. Du kannst auch andere Zahlen hinter \texttt{shape} eintragen um
verschiedene Punktesymbole durchzuprobieren. Eine Ãbersicht an
\texttt{shapes} findest du auch hier unter
\href{http://www.cookbook-r.com/Graphs/Shapes_and_line_types/}{Cookbook
for R \textgreater{} Graphs \textgreater{} Shapes and line types}.

\hypertarget{sec-eda-barplot}{%
\subsection{Barplot oder Balkendiagramm}\label{sec-eda-barplot}}

Der Barplot oder das Balkendiagramm ist eigentlich veraltet. Wir haben
mit dem Boxplot eine viel bessere Methode um eine Verteilung und
\emph{gleichzeitig} auch die Gruppenunterschiede zu visualisieren. Warum
nutzen wir jetzt so viel den Braplot? Das hat damit zu tun, dass frÃ¼her
- oder besser bis vor kurzem - in Excel kein Boxplot mÃ¶glich war. Daher
nutzte jeder der mit Excel seine Daten auswertet den Barplot. Und was
der Bauer nicht kennt\ldots{}

\marginnote{\begin{footnotesize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Alles was es schon gab, als Du geboren wurdest, ist normal und
  gewÃ¶hnlich. Diese Dinge werden als natÃ¼rlich wahrgenommen und halten
  die Welt am Laufen.
\item
  Alles was zwischen Deinem 16ten und 36ten Lebensjahr erfunden wird ist
  neu, aufregend und revoltionÃ¤r. Und vermutlich kannst Du in dem
  Bereich sogar Karriere machen.
\item
  Alles was nach dem 36ten Lebensjahr erfunden wird ist gegen die
  natÃ¼rliche Ordnung der Dinge.
\end{enumerate}

-- Douglas Adams aus \emph{Per Anhalter durch die Galaxis}

\end{footnotesize}}

Deshalb ist hier auch der Barplot dargestellt. Ich persÃ¶nlich mag den
Barplot Ã¼brhaupt nicht. Der Barplot ist einfach schlechter als der
Boxplot. Aber gut, hÃ¤ufog musst du den Barplot in deiner Abschlussarbeit
machen. Also dann hier der Barplot.

Wie erstellen wir nun einen Barplot in R? Zuerst laden wir die Daten mit
der Funktion \texttt{read\_excel()} in R, wenn du die Daten als
\texttt{.xlsx} Datei vorliegen hast. Im
Kapitel~\ref{sec-programming-import} kannst du nochmal das Importieren
von Daten wiederholen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flea\_dog\_cat\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Wir mÃ¼ssen jetzt fÃ¼r \texttt{ggplot()} noch den Mittelwert und die
Streuung fÃ¼r die Gruppen berechnen. Ein komplexeres Beispiel fÃ¼r einen
Barplot findets du in Kapitel~\ref{sec-beispiel-auswertung}. Du kanst
als Streuung die Standardabweichung oder den Standardfehler nehmen. Ich
wÃ¼rde die Standardabweichung bei kleinen Fallzahlen kleiner als 20
Beobachtungen nehmen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ flea\_dog\_cat\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(animal) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(jump\_length),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(jump\_length),}
            \AttributeTok{se =}\NormalTok{ sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

Wir nutzen nun das Objekt \texttt{stat\_tbl} um den Barplot mit der
Funktion \texttt{ggplot()} zu erstellen. Dabei mÃ¼ssen wir zum einen
schauen, dass die Balken nicht Ã¼bereinander angeordnet sind.
Nebeneinander angeordnete Balken kriegen wir mit der Option
\texttt{stat\ =\ "identity"} in dem \texttt{geom\_bar()}. Dann mÃ¼ssen
wir noch die Fehlerbalken ergÃ¤nzen mit dem \texttt{geom\_errorbar}. Hier
kann nochmal mit der Option \texttt{width\ =} an der LÃ¤nge der
Fehlerenden gedreht werden.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(stat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ mean, }\AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean}\SpecialCharTok{{-}}\NormalTok{sd, }\AttributeTok{ymax =}\NormalTok{ mean}\SpecialCharTok{+}\NormalTok{sd),}
                  \AttributeTok{width =} \FloatTok{0.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/unnamed-chunk-20-1.pdf}

}

\end{figure}

Im Zweifel muss du nochmal googlen und schauen welche Form dir am besten
zusgat. Es gibt sehr viele MÃ¶glichkeiten einen Barplot zu erstellen.
Daher komm im Zweifel einmal ins R Tutorium.

\hypertarget{sec-eda-dotplot}{%
\subsection{Dotplot}\label{sec-eda-dotplot}}

Wenn wir weniger als fÃ¼nf Beobachtungen haben, dann ist meist ein
Boxplot verzerrend. Wir sehen eine Box und glauben, dass wir viele
Datenpunkte vorliegen haben. Bei 3 bis 7 Beobachtungen je Gruppe bietet
sich der Dotplot als eine LÃ¶sung an. Wir stellen hier alle Beobachtungen
als einzelne Punkte dar.

Wie erstellen wir nun einen Dotplot in R? Zuerst laden wir die Daten mit
der Funktion \texttt{read\_excel()} in R, wenn du die Daten als
\texttt{.xlsx} Datei vorliegen hast. Im XX kannst du nochmal das
Importieren von Daten wiederholen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flea\_dog\_cat\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ grade,}
                                    \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_dotplot}\NormalTok{(}\AttributeTok{binaxis =} \StringTok{"y"}\NormalTok{, }\AttributeTok{stackdir =} \StringTok{"center"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Boniturnote [1{-}9]"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-dotplot-flea-eda-0-1.pdf}

}

\caption{\label{fig-dotplot-flea-eda-0}Der Dotplot fÃ¼r die Anzahl der
FlÃ¶he fÃ¼r die beiden Tierarten Hund und Katze.}

\end{figure}

In Abbildung~\ref{fig-dotplot-flea-eda-0} sehen wir den Dotplot aus der
Datei \texttt{flea\_dog\_cat.xlsx}. Auf der x-Achse sind die Level des
Faktors \texttt{animal} dargestellt und auf der y-Achse die
Notenbewertung \texttt{grade} der einzelnen Hunde und Katzen. Die
Funktion \texttt{geom\_dotplot()} erschafft das Layer fÃ¼r die Dots bzw.
Punkte. Wir mÃ¼ssen in der Funktion noch zwei Dinge angeben, damit der
Plot so aussieht, dass wir den Dotplot gut interpretieren kÃ¶nnen. Zum
einen mÃ¼ssen wir die Option \texttt{binaxis\ =\ y} wÃ¤hlen, damit die
Punkte horizontal geordent werden. Zum anderen wollen wir auch, dass die
Punkte zentriert sind und nutzen dafÃ¼r die Option
\texttt{stackdir\ =\ center}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ grade,}
                            \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_dotplot}\NormalTok{(}\AttributeTok{binaxis =} \StringTok{"y"}\NormalTok{, }\AttributeTok{stackdir =} \StringTok{"center"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ median, }\AttributeTok{fun.min =}\NormalTok{ median, }\AttributeTok{fun.max =}\NormalTok{ median,}
               \AttributeTok{geom =} \StringTok{"crossbar"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Boniturnote [1{-}9]"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-dotplot-flea-eda-1-1.pdf}

}

\caption{\label{fig-dotplot-flea-eda-1}Der Dotplot fÃ¼r die Anzahl der
FlÃ¶he fÃ¼r die beiden Tierarten Hund und Katze. Die schwarze Linie stelt
den Median fÃ¼r die beiden Tierarten dar.}

\end{figure}

Nun macht es wenig Sinn bei sehr wenigen Beobachtungen noch statistische
MaÃzahlen mit in den Plot zu zeichnen. Sonst hÃ¤tten wir auch gleich
einen Boxplot als Visualisierung der Daten wÃ¤hlen kÃ¶nnen. In
Abbildung~\ref{fig-dotplot-flea-eda-1} sehen wir die ErgÃ¤nzung des
Medians. Hier mÃ¼ssen wir etwas mehr angeben, aber immerhin haben wir so
eine Idee, wo die ``meisten'' Beobachtungen wÃ¤ren. Aber auch hier ist
Vorsicht geboten. Wir haben sehr wenige Beobachtungen, so dass eine
Beobachtung mehr oder weniger groÃe Auswirkungen auf den Median und die
Interpretation hat.

\hypertarget{sec-eda-scatter}{%
\subsection{Scatterplot}\label{sec-eda-scatter}}

Der Scatterplot wird auch xy-Plot genannt. Wir stellen in einem
Scatterplot zwei kontenuierliche Variablen dar. Dann wollen wir eine
Linie durch die Punkte legen. Im Prinzip fragen wir uns, wie hÃ¤nge die
Werte auf der y-Achse von den Werten auf der x-Achse ab? Wenn sich also
die Werte auf der x-Achse erhÃ¶hen, wie verhalten sich dann die Werte auf
der y-Achse?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_count, }\AttributeTok{y =}\NormalTok{ jump\_length)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Anzahl der FlÃ¶he"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Sprungweite in [cm]"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-scatter-flea-0-1.pdf}

}

\caption{\label{fig-scatter-flea-0}Zusammenhang zwischen der Sprungweite
in {[}cm{]} und der Anzahl an FlÃ¶hen auf den 39 Hunden. Jeder Punkt
stellt einen Hund dar.}

\end{figure}

Abbildung~\ref{fig-scatter-flea-0} zeigt den Scatterplot fÃ¼r die Spalte
\texttt{flea\_count} auf der x-Achse und \texttt{jump\_length} auf der
y-Achse. Mit der Funktion \texttt{geom\_point()} kÃ¶nnen wir die
Punktepaare fÃ¼r jede Beobachtung zeichnen. In unserem Fall zeichnen wir
mit der Funktion \texttt{stat\_smooth()} noch die entsprechende Grade
durch die Punkte. Es handelt sich hierbei um eine Regression. Du kannst
im Kapitel XX mehr darÃ¼ber erfahren.

\hypertarget{sec-eda-mosaic}{%
\subsection{Mosaic Plot}\label{sec-eda-mosaic}}

Wenn wir zwei Spalten visualisieren wollen, die aus zwei Faktoren
bestehen mit jeweils zwei Leveln, dann nutzen wir den Mosaic Plot. Wir
nutzen den Datensatz \texttt{flea\_dog\_cat.xlsx} mit vierzehn
Beobachtungen. Schauen wir uns einmal die 2x2 Kreuztabelle der beiden
Spalten \texttt{animal} and \texttt{infected} an.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flea\_dog\_cat\_tbl }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{factor}\NormalTok{(animal, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tabyl}\NormalTok{(animal, infected) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 animal 0 1
    dog 4 3
    cat 5 2
\end{verbatim}

Wir sehen in der Tabelle, dass wir mehr uninfizierte Tiere (n = 9) als
infizierte Tiere haben (n = 5). Die Aufteilung zwischen den beiden
Tierarten ist nahezu gleich. Im folgenden wollen wir diese Tabelle durch
einen Mosaic Plot einmal visualisieren.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl) }\SpecialCharTok{+}
  \FunctionTok{geom\_mosaic}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{product}\NormalTok{(animal, infected), }\AttributeTok{fill =}\NormalTok{ animal)) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-mosaic-flea-0-1.pdf}

}

\caption{\label{fig-mosaic-flea-0}Visualisierung einer 2x2 Tabelle als
Mosaic Plot. Die unterschiedlich groÃen FlÃ¤chen geben die VerhÃ¤ltnisse
wieder.}

\end{figure}

Abbildung~\ref{fig-mosaic-flea-0} zeigt den Mosaic Plot fÃ¼r die Variable
\texttt{animal} and \texttt{infected}. Die untrschiedlich groÃen FlÃ¤chen
bilden die VerhÃ¤ltnisse der 2x2 Tabelle ab. So sehen wir, dass es mehr
uninfizierte Tiere als infizierte Tiere gibt. Am meisten gibt es
uninfizierte Katzen. Am wenigstens treten infizierte Katzen auf.

\hypertarget{uxfcberschriften-achsen-und-legenden}{%
\section{Ãberschriften, Achsen und
Legenden}\label{uxfcberschriften-achsen-und-legenden}}

Wenn du mehr machen willst, also die Ãberschriften anpassen oder aber
die Achsenbeschriftung Ã¤ndern, dann gibt es hier global Hilfe im
\href{https://ggplot2.tidyverse.org/reference/index.html}{ggplot
Manual}. Die Webseite
\href{https://ggplot2.tidyverse.org/reference/index.html}{R Cookbook}
hat auch spezielle Hilfe fÃ¼r ggplot().

\begin{itemize}
\tightlist
\item
  \href{http://www.cookbook-r.com/Graphs/Titles_(ggplot2)/}{Ãberschriften
  von Abbildungen}
\item
  \href{http://www.cookbook-r.com/Graphs/Axes_(ggplot2)/}{Achsenbeschriftung}
\item
  \href{http://www.cookbook-r.com/Graphs/Legends_(ggplot2)/}{Legende}
\item
  \href{http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/}{Farben}
\end{itemize}

{\marginnote{\begin{footnotesize}Im Kapitel~\ref{sec-r-tutorium} findest
du Informationen zum R Tutorium, wann und wo es
stattfindet.\end{footnotesize}}}

In Abbildung~\ref{fig-labels-0} siehst du eine Abbildung mit Titel und
verÃ¤nderten Beschriftungen. Die MÃ¶glichkeiten sind nahezu unbegrenzt und
sprengen auch hier den Rahmen. Im Zweifel im R Tutorium vorbeischauen
oder aber in der Vorlesung fragen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
                                    \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Frischgewicht in AbhÃ¤ngigkeit von der Behandlung"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Frischgewicht in kg/ha"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Katze"}\NormalTok{, }\StringTok{"Hund"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Katze"}\NormalTok{, }\StringTok{"Hund"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-labels-0-1.pdf}

}

\caption{\label{fig-labels-0}Beispielhafte Abbildung mit Titel und
geÃ¤nderter Achsenbeschrittung}

\end{figure}

\hypertarget{die-okabe-ito-farbpalette}{%
\section{Die Okabe-Ito Farbpalette}\label{die-okabe-ito-farbpalette}}

\marginnote{\begin{footnotesize}

Mehr zum R Paket \texttt{see} auf der
\href{https://easystats.github.io/see/index.html}{Hilfeseite des
Paketes}

\end{footnotesize}}

Neben den klassischen Farben im R Paket \texttt{ggplot}gibt es noch
weit, weit mehr Farbpaletten. Wir nutzen in der Folge immer wieder die
Okabe-Ito Farbpalette aus dem R Paket \texttt{see}. Die Okabe-Ito
Farbpalette ist speziell so gebaut, dass die Farben sich gut fÃ¼r
farbenblinde Personen unterscheiden. Der Kontrast zwischen den Farben
ist sehr gut. Wenn du eine andere Farbpalette nutzen willst, findest du
hier noch andere
\href{https://easystats.github.io/see/articles/seecolorscales.html}{Color
Scales}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
           \AttributeTok{fill =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-labels-see-0-1.pdf}

}

\caption{\label{fig-labels-see-0}Beispielhafte Abbildung der Okabe-Ito
Farbpalette fÃ¼r Boxplots.}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
           \AttributeTok{color =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-labels-see-1-1.pdf}

}

\caption{\label{fig-labels-see-1}Beispielhafte Abbildung der Okabe-Ito
Farbpalette fÃ¼r Punkte.}

\end{figure}

\hypertarget{abbildungen-nebeneinander}{%
\section{Abbildungen nebeneinander}\label{abbildungen-nebeneinander}}

Das
\href{https://patchwork.data-imaginist.com/articles/patchwork.html}{R
Paket patchwork} erlaubt es mehrere \texttt{ggplot} Abbildungen
nebeneinander oder in einem beliebigen Layout miteinander zu verbinden.
Das tolle ist, dass die Idee sehr intutiv ist. Wir nutzen wieder das
\texttt{+} um verschiedene Plots miteinander zu verbinden.

Im Folgenden erschaffen wir uns zwei \texttt{ggplots} und speichern die
Plots in den Objekten \texttt{p1} und \texttt{p2}. Das ist wie wir es
bisher kennen, nur das jetzt keine Abbildung erscheint sondern beide
Plots in zwei Objekten gespeichert sind.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flea\_count, }\AttributeTok{y =}\NormalTok{ jump\_length,}
                 \AttributeTok{color =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}

\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ flea\_dog\_cat\_tbl, }
                \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
                    \AttributeTok{color =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Wie kÃ¶nnen wir nun die beiden Abbildungen nebeneinander zeichnen? Wir
nutzen einfach das \texttt{+} Symbol.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\SpecialCharTok{+}\NormalTok{ p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./eda-ggplot_files/figure-pdf/fig-labels-patchwork-1-1.pdf}

}

\caption{\label{fig-labels-patchwork-1}Beispielhafte Abbildung der
zweier Plots nebeneinander.}

\end{figure}

Auf der Seite des
\href{https://patchwork.data-imaginist.com/articles/patchwork.html}{R
Paket patchwork} findest du viel mehr MÃ¶glichkeiten das Layout
anzupassen und auch die einzelnen
\href{https://patchwork.data-imaginist.com/articles/guides/annotation.html}{Subplots
zu beschriften}.

\hypertarget{sec-eda-transform}{%
\chapter{Transformieren von Daten}\label{sec-eda-transform}}

\emph{Version vom September 14, 2022 um 08:47:40}

\marginnote{\begin{footnotesize}

Ich verweise hier auch nochmal auf das tolle Tutorial von Matus Seci auf
dem
\href{https://ourcodingclub.github.io/tutorials/data-scaling/}{Coding
Club}

\end{footnotesize}}

Warum mÃ¼ssen wir Daten transformieren? Meistens hat dies zwei
HauptgrÃ¼nde.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir wollen eine ANOVA oder eine Gaussian lineare Regression rechen und
  benÃ¶tigen ein normalverteiltes Outcome \(y\)
\item
  Wir wollen einen Algorithmus zur PrÃ¤diktion (deu. \emph{Vorhersage})
  nutzen und haben sehr viele Einflussvariablen \(x\) in sehr
  unterschiedlichen Einheiten.
\end{enumerate}

Im ersten Fall wollen wir meist unsere Daten \(log\)-Transformieren um
aus einem \emph{nicht}-normalverteilten Outcome \(y\) ein
\(log\)-normalverteiltes \(y\) zu erschaffen. Im zweiten Fall wollen wir
unsere Daten Standardisieren oder Normalisieren. Wir brauchen
normalisierte Daten spÃ¤ter beim Klassifizieren im Rahmen von
maschinellen Lernverfahren.

Wir wollen uns nun die Verfahren zur Transformation von Daten in den
folgenden Abschnitten einmal alle anschauen.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-3}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-3}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten}{%
\section{Daten}\label{daten}}

Wir wollen uns in diesem Kapitel mit der normalverteilten Variable
\texttt{jump\_length} gemessen in {[}cm{]} und der
nicht-normalverteilten Variable \texttt{hatch\_time} gemessen in {[}h{]}
aus dem Datensatz \texttt{flea\_dog\_cat\_length\_weight.csv"}
beschÃ¤ftigen. Wir wÃ¤hlen Ã¼ber die Funktion \texttt{select()} nur die
beiden Spalten aus dem Datensatz, die wir benÃ¶tigen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(jump\_length, hatch\_time)}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-trans-1} ist der Datensatz \texttt{data\_tbl}
nochmal dargestellt. Wir zeigen hier nur die ersten sieben zeilen des
Datensatzes.

\hypertarget{tbl-trans-1}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-trans-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} und der
nicht-normalverteilten Variable \texttt{hatch\_time}. Wir betrachten die
ersten sieben Zeilen des Datensatzes.}\tabularnewline
\toprule()
jump\_length & hatch\_time \\
\midrule()
\endfirsthead
\toprule()
jump\_length & hatch\_time \\
\midrule()
\endhead
15.79 & 483.60 \\
18.33 & 82.56 \\
17.58 & 296.73 \\
14.09 & 140.90 \\
18.22 & 162.20 \\
13.49 & 167.47 \\
16.28 & 291.20 \\
\bottomrule()
\end{longtable}

Im Folgenden nutzen wir oft die Funktion \texttt{mutate()}. Schau dir im
Zweifel nochmal im Kapitel zu Programmierung die Funktion
\texttt{mutate()} an.

\hypertarget{log-transformation}{%
\section{\texorpdfstring{\(log\)-Transformation}{log-Transformation}}\label{log-transformation}}

Wir nutzen die \(log\)-Transformation, wenn wir aus einem
nicht-normalverteiltem Outcome \(y\) ein approxomativ normalverteiltes
Outcome \(y\) machen wollen. Dabei ist wichtig, dass wir natÃ¼rlich auch
die Einheit mit \(log\)-transformieren.

Im Folgenden sehen wir die \(log\)-Transformation der Variable
\texttt{hatch\_time} mit der Funktion \texttt{log()}. Wir erschaffen
eine neue Spalte im \texttt{tibble} damit wir die beiden Variable vor
und nach der \(log\)-Transformation miteinander vergleichen kÃ¶nnen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{log\_hatch\_time =} \FunctionTok{log}\NormalTok{(hatch\_time))}
\end{Highlighting}
\end{Shaded}

Wir kÃ¶nnen dann Ã¼ber ein Histogramm die beiden Verteilungen anschauen.
In Abbildung~\ref{fig-log-scale-1-1} sehen wir die nicht transformierte,
rohe Daten. Es gibt einen klaren Peak SchlÃ¼pfzeiten am Anfang. Dann
lÃ¤uft die Verteilung langsam aus. Wir kÃ¶nnen nicht annehmen, dass die
SchlÃ¼pfzeiten normalverteilt sind. Abbildung~\ref{fig-log-scale-1-2}
zeigt die \(log\)-transmutierten Daten. In diesem Fall sehen wir
normalverteilte Daten. Wir haben also ein \(log\) normalverteiltes
Outcome \(y\) mit dem wir jetzt weiterechnen kÃ¶nnen.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-1-1.pdf}

}

}

\subcaption{\label{fig-log-scale-1-1}Nicht transformierte, rohe Daten}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-1-2.pdf}

}

}

\subcaption{\label{fig-log-scale-1-2}\(log\)-transformierte Daten.}
\end{minipage}%

\caption{\label{fig-log-scale-1}Histogramm der nicht transfomierten und
transformierten Daten.}

\end{figure*}

\hypertarget{quadratwurzel-transformationen}{%
\section{Quadratwurzel-Transformationen}\label{quadratwurzel-transformationen}}

Die Quadratwurzel-Transformationen ist eine etwas seltenere
Transformation. Meist wird die Quadratwurzel-Transformationen als die
schwÃ¤chere \(log\)-Transformation bezeichnet. Wir sehen in
Abbildung~\ref{fig-log-scale-2-2} den Grund dafÃ¼r. Aber zuerst mÃ¼ssen
wir aber Ã¼ber die Funktion \texttt{sqrt()} unsere Daten transformieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqrt\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sqrt\_hatch\_time =} \FunctionTok{sqrt}\NormalTok{(hatch\_time))}
\end{Highlighting}
\end{Shaded}

In Abbildung~\ref{fig-log-scale-2-1} sehen wir die nicht transformierte,
rohe Daten. Es gibt einen klaren Peak SchlÃ¼pfzeiten am Anfang. Dann
lÃ¤uft die Verteilung langsam nach rechts aus. Wir kÃ¶nnen nicht annehmen,
dass die SchlÃ¼pfzeiten normalverteilt sind.
Abbildung~\ref{fig-log-scale-2-2} zeigt die Wurzel-transmutierten Daten.
Unser Ziel besser normalverteilte Daten vorliegen zu haben, haben wir
aber mit der Quadratwurzel-Transformationen nicht erreicht. Die Daten
sind immer noch rechtsschief. Wir wÃ¼rden also die \(log\)-Transformation
bevorzugen.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-2-1.pdf}

}

}

\subcaption{\label{fig-log-scale-2-1}Nicht transformierte, rohe Daten}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-2-2.pdf}

}

}

\subcaption{\label{fig-log-scale-2-2}Wurzel-transformierte Daten.}
\end{minipage}%

\caption{\label{fig-log-scale-2}Histogramm der nicht transfomierten und
transformierten Daten.}

\end{figure*}

\hypertarget{standardisierung}{%
\section{Standardisierung}\label{standardisierung}}

Die Standardisierung wird auch \(z\)-Transformation genannt. In dem Fall
der Standardisierung schieben wir die Daten auf den Ursprung, in dem wir
von jedem Datenpunkt \(y_i\) den Mittelwert \(\bar{y}\) abziehen. Dann
setzen wir noch die Standardabweichung auf Eins in dem wir durch die
Standardabweichung \(y_s\) teilen. Unser standardisiertes \(y\) ist nun
standard normalverteilt mit \(\mathcal{N(0,1)}\). Wir nutzen fÃ¼r die
Standardisiwerung folgende Formel.

\[
y_z = \cfrac{y_i - \bar{y}}{s_y} 
\] In R kÃ¶nnen wir fÃ¼r die Standardisierung die Funktion
\texttt{scale()} verwenden. Wir mÃ¼ssen auch nichts weiter in den
Optionen von \texttt{scale()} angeben. Die Standardwerte der Funktion
sind so eingestellt, dass eine Stanardnormalverteilung berechnet wird.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scale\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{scale\_jump\_length =} \FunctionTok{scale}\NormalTok{(jump\_length))}
\end{Highlighting}
\end{Shaded}

In Abbildung~\ref{fig-log-scale-3-1} sehen wir nochmal die nicht
transformierten, rohen Daten. Wir haben in diesem Beispiel die
normalvertielte Variable \texttt{jump\_length} gewÃ¤hlt. Der Mittelwert
von \texttt{jump\_length} ist 20.51 und die Standardabweichung ist 3.77.
Ziehen wir nun von jedem Wert von \texttt{jump\_length} den Mittelwert
mit 19.3 ab, so haben wir einen neuen Schwerpunkt bei Null. Teilen wir
dann jede Zahl durch 3.36 so haben wir eine reduzierte Spannweite der
Verteilung. Es ergibt sich die Abbildung~\ref{fig-log-scale-3-2} als
Standardnormalverteilung. Die Zahlen der auf der x-Achse haben jetzt
aber keine Bedeutung mehr. Wie kÃ¶nnen die Sprungweite auf der
\(z\)-Skala nicht mehr biologisch interpretieren.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-3-1.pdf}

}

}

\subcaption{\label{fig-log-scale-3-1}Nicht transformierte, rohe Daten}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-3-2.pdf}

}

}

\subcaption{\label{fig-log-scale-3-2}\(z\)-transformierte Daten.}
\end{minipage}%

\caption{\label{fig-log-scale-3}Histogramm der nicht transfomierten und
transformierten Daten.}

\end{figure*}

\hypertarget{normalisierung}{%
\section{Normalisierung}\label{normalisierung}}

AbschlieÃend wollen wir uns nochmal die Normalisierung anschauen. In
diesem Fall wollen wir die Daten so transformieren, dass die Daten nur
noch in der Spannweite 0 bis 1 vorkommen. Egal wie die Einheiten vorher
waren, alle Variablen haben jetzt nur noch eine AusprÃ¤gung von 0 bis 1.
Das ist besonders wichtig wenn wir viele Variablen haben und anhand der
Variablen eine Vorhersage machen wollen. Uns interessieren die Werte in
den Variablen an sich nicht, sondern wir wollen ein Outcome vorhersagen.
Wir brauchen die Normalisierung spÃ¤ter fÃ¼r das maschinelle Lernen und
die Klassifikation. Die Formel fÃ¼r die Normalisierung lautet wie folgt.

\[
y_n = \cfrac{y_i - \min(y)}{\max(y) - \min(y)} 
\]

In R gibt es die Normalisierungsfunktion nicht direkt. Wir kÃ¶nnten hier
ein extra Paket laden, aber bei so einer simplen Formel kÃ¶nnen wir auch
gleich die Berechnung in der Funktion \texttt{mutate()} machen. Wir
mÃ¼ssen nur etwas mit den Klammern aufpassen.

\begin{figure*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{norm\_jump\_length =}\NormalTok{ (jump\_length }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(jump\_length))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{max}\NormalTok{(jump\_length) }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(jump\_length)))}
\end{Highlighting}
\end{Shaded}

\end{figure*}

In Abbildung~\ref{fig-log-scale-4-1} sehen wir nochmal die nicht
transformierten, rohen Daten. In Abbildung~\ref{fig-log-scale-4-2} sehen
wir die normalisierten Daten. Hier fÃ¤llt dann auf, dass die
normalisierten Sprungweiten nur noch Werte zwischen Null und Eins
annehmen. Die Zahlen der auf der x-Achse haben jetzt aber keine
Bedeutung mehr. Wie kÃ¶nnen die normalisierten Sprungweiten nicht mehr
biologisch interpretieren.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-4-1.pdf}

}

}

\subcaption{\label{fig-log-scale-4-1}Nicht transformierte, rohe Daten}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-transform_files/figure-pdf/fig-log-scale-4-2.pdf}

}

}

\subcaption{\label{fig-log-scale-4-2}Normalisierte Daten}
\end{minipage}%

\caption{\label{fig-log-scale-4}Histogramm der nicht transfomierten und
transformierten Daten.}

\end{figure*}

\hypertarget{verteilung-von-daten}{%
\chapter{Verteilung von Daten}\label{verteilung-von-daten}}

\emph{Version vom September 14, 2022 um 08:48:02}

\marginnote{\begin{footnotesize}

Wir besuchen gerne die R Shiny App
\href{https://ben18785.shinyapps.io/distribution-zoo/}{The distribution
zoo} um mehr Ã¼ber die verschiedenen Verteilungen und deren Parameter zu
erfahren.

\end{footnotesize}}

In diesem Kapitel wollen wir uns mit Verteilungen beschÃ¤ftigen. Dormann
(2013) liefert eine weitreichende Ãbersicht Ã¼ber verschiedene
Verteilungen. Wir wollen uns in diesem Kapitel mit folgenden
Verteilungen beginnen.

\begin{itemize}
\tightlist
\item
  der \textbf{Normalverteilung}, die Glockenkurve oder auch
  \textbf{Gaussian} im englischen Sprachgebrauch genannt, die
  kontinuierliche Zahlen reprÃ¤sentiert
\item
  der \textbf{Poissonverteilung}, die diskrete ZÃ¤hldaten reprÃ¤sentiert.
\end{itemize}

Wir wollen uns jetzt die verschiedenen Verteilungen einmal in der
Anwendung anschauen. Dabei lassen wir viel Mathematik recht und links
liegen. Du kannst bei Dormann (2013) mehr zu dem Thema statistische
Verteilungen anlesen.

In diesem Kapitel geht es erstmal um das GrundverstÃ¤ndnis, das Daten
einer Verteilung folgen. Oder noch konkreter, dass unser Outcome \(y\)
einer Verteilung folgt. Wir mÃ¼ssen spÃ¤ter unseren Alogrithmen sagen,
welcher Verteilung \(y\) entspringt, sonst kÃ¶nnen wir keine
\emph{korrekte} Analyse unser Daten rechnen.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Wir halten den mathematischen Teil zu den Verteilungen sehr kurz oder
Ã¼berspringen den Teil ganz. Wir brauchen die Idee der Verteilungen, weil
wir spÃ¤ter den Methoden sagen mÃ¼ssen wie unser Outcome \(y\) verteilt
ist. Nur dann kÃ¶nnen wir die Daten richtig auswerten.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-4}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-4}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, see, readxl)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-fuxfcr-verteilungen}{%
\section{Daten fÃ¼r Verteilungen}\label{daten-fuxfcr-verteilungen}}

Damit wir uns auch eine Verteilung anschauen kÃ¶nnen bruachen wir
\emph{viele} Beobachtungen. Wir haben das ja schon bei den Histogrammen
gesehen, wenn wir ein aussagekrÃ¤ftiges Histogramm erstellen wollen, dann
brauchen wir viele Beobachtungen. Daher nehmen wir fÃ¼r dieses Kapitel
einmal den GummibÃ¤rchendatensatz und schauen uns dort die Variablen
\texttt{gender}, \texttt{height}, \texttt{count\_bears} und
\texttt{count\_color} einmal genauer an. Wie immer nutzen wir die
Funktion \texttt{select()} um die Spalten zu selektieren. Wir mÃ¼ssen
jetzt nochmal alle fehlenden Werte mit der Funktion \texttt{na.omit()}
entfernen, dass macht uns die Sache etwas leichter. AbschlieÃend
verwandeln wir das Geschlecht \texttt{gender} noch in einen Faktor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gummi\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/gummibears.xlsx"}\NormalTok{)  }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(gender, height, count\_bears, count\_color) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{na.omit}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gender =} \FunctionTok{as\_factor}\NormalTok{(gender))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{gummi\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-dist-gummi} nochmal dargestellt.

\hypertarget{tbl-data-dist-gummi}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-data-dist-gummi}Auszug aus den selektierten Daten zu
den GummibÃ¤rchendaten.}\tabularnewline
\toprule()
gender & height & count\_bears & count\_color \\
\midrule()
\endfirsthead
\toprule()
gender & height & count\_bears & count\_color \\
\midrule()
\endhead
m & 193 & 9 & 3 \\
w & 159 & 10 & 5 \\
w & 159 & 9 & 6 \\
w & 180 & 10 & 5 \\
m & 180 & 10 & 6 \\
m & 180 & 10 & 5 \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} \\
w & 165 & 12 & 5 \\
w & 177 & 10 & 2 \\
w & 173 & 9 & 5 \\
w & 168 & 12 & 6 \\
m & 183 & 8 & 5 \\
w & 171 & 9 & 5 \\
\bottomrule()
\end{longtable}

Wir nutzen jetzt die Daten einmal um uns die Normalverteilung und die
Poissonverteilung am Beispiel nÃ¤her anzuschauen.

\hypertarget{sec-normal}{%
\section{Die Normalverteilung}\label{sec-normal}}

{\marginnote{\begin{footnotesize}Wir sprechen in der Statistik auch von
Verteilungs\emph{familien}. Daher schreiben wir in R auch
\texttt{family\ =\ gaussian}, wenn wir sagen wollen, dass unsere Daten
einer Normalverteilung entstammen.\end{footnotesize}}}

Wenn wir von de Normalverteilung sprechen, dann schreiben wir ein
\(\mathcal{N}\) Symbol - also ein groÃes N mit Serifen. Die
Normalverteilung sieht aus wie eine Glocke, deshalb wird die
Normalverteilung auch Glockenkurve genannt. Im englischen Sprachgebrauch
und auch in R nutzen wir dagegen die Bezeichnung nach dem ``Endecker''
der Normalverteilung, Carl Friedrich GauÃ (1777 - 1985). Wir nennen
daher die Normalverteilung auch Gaussian-Verteilung.

{\marginnote{\begin{footnotesize}\textbf{Parameter} sind Zahlen, die
eine Verteilungskurve beschreiben.\end{footnotesize}}}

Eine Normalverteilung wird ruch zwei Verteilungs\emph{parameter}
definiert. Eine Verteilung hat Parameter. Parameter sind die
Eigenschaften einer Verteilung, die notwendig sind um eine Verteilung
vollstÃ¤ndig zu beschreiben. Im Falle der Normalverteilung brauchen wir
zum einen den Mittelwert \(\bar{y}\), der den hÃ¶chsten Punkt unserer
Glockenkurve beschreibt. Zum anderen brauchen wir auch die
Standardabweichung \(s^2_y\), die die Ausbreitung oder Breite der
Glockenkurve bestimmt. Wir beschreiben eine Normalverteilung wie folgt.

\[
\mathcal{N}(\bar{y}, s^2_y)
\] Im Falle der Normalverteilung brauchen wir einen Paramter fÃ¼r den
hÃ¶chsten Punkt der Kurve, sowie einen Parameter fÃ¼r die Ausbreitung,
also wie weit geht die Kurve nach links und nach rechts. Je nach
\(\bar{y}\) und \(s^2_y\) kÃ¶nnen wir verschiedenste Normalverteilungen
vorliegen haben. Eine Sammlung von Normalverteilungen nennen wir auch
Familie (eng. \emph{family}).

{\marginnote{\begin{footnotesize}Wir haben VarianzhomogenitÃ¤t vorliegen,
wenn \(s^2_{1} = s^2_{2} = s^2_{3}\) sind. Wir haben
VarianzheterogenitÃ¤t vorliegen, wenn
\(s^2_{1} \neq s^2_{2} \neq s^2_{3}\) sind.\end{footnotesize}}}

In Abbildung~\ref{fig-normal-02} sehen wir verschiedene
Normalverteilungen mit unterschiedlichen Mittelwerten. In
Abbildung~\ref{fig-normal-02-1} sehen wir eine VarianzhomogenitÃ¤t
vorliegen, da die Varianzen in allen drei Normalverteilungen gleich
sind. Wir kÃ¶nnen auch schreiben, dass
\(s^2_{1} = s^2_{2} = s^2_{3} = 2\). In Abbildung~\ref{fig-normal-02-2}
haben wir VarianzheterogenitÃ¤t vorliegen, da die Varianzen der
Normalverteilungen ungleich sind. Wir kÃ¶nnen hier dann schreiben, dass
\(s^2_{1} = 6 \neq s^2_{2} = 1 \neq s^2_{3} = 3\) sind. HÃ¤ufig gehen
statistische Verfahren davon aus, dass wir VarianzhomogenitÃ¤t Ã¼ber die
Gruppen und daher auch die Normalverteilungen vorliegen haben. Konkret,
wenn wir die Sprungweiten in{[}cm{]} von Hunde- und KatzenflÃ¶hen mit
einander vergleichen wollen, dann gehen wir erstmal davon aus, dass die
Mittelwerte verschieden sind, aber die Varianzen gleich sind.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-02-1.pdf}

}

}

\subcaption{\label{fig-normal-02-1}Drei Normalverteilungen mit
VarianzhomogenitÃ¤t.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-02-2.pdf}

}

}

\subcaption{\label{fig-normal-02-2}Drei Normalverteilungen unter
VarianzheterogenitÃ¤t.}
\end{minipage}%

\caption{\label{fig-normal-02}Histogramm verschiedener
Normalverteilungen mit unterschiedlichen Mittelwerten.}

\end{figure*}

{\marginnote{\begin{footnotesize}In einer Normalverteilung liegen 68\%
der Werte innerhalb \(\bar{y}\pm 1 \cdot s_y\) und 95\% der Werte
innerhalb \(\bar{y}\pm 2 \cdot s_y\)\end{footnotesize}}}

Wenn wir eine Normalverteilung vorliegen haben, dann liegen 68\% der
Werte plus/minus einer Standardabweichung vom Mittelwert. Ebenso liegen
95\% der Werte plus/minus zwei Standabweichungen vom Mittelwert. Ãber
99\% der Werte befinden sich innerhalb von drei Standardabweichungen vom
Mittelwert. Diese Eigenschaft einer Normalverteilung kÃ¶nnen wir spÃ¤ter
noch nutzen um abzuschÃ¤tzen, ob wir einen relevanten Gruppenunterschied
vorliegen haben oder aber ob unsere Daten \emph{unnatÃ¼rlich} breit
streuen.

{\marginnote{\begin{footnotesize}Wir nutzen das Wort
\textbf{approximativ} wenn wir sagen wollen, dass ein Outcome
nÃ¤herungsweise normalverteilt ist.\end{footnotesize}}}

Schauen wir uns die Normalverteilung einmal am Beispiel unserer
GummibÃ¤rchendaten und der KÃ¶rpergrÃ¶Ãe der Studierenden an. Wir fÃ¤rben
das Histogramm nach dem Geschlecht ein. In Abbildung~\ref{fig-normal-01}
sehen wir das Ergebnis einmal als Histogramm und einmal als Densityplot
dargestellt. Wir kÃ¶nnen annehmen, dass die GrÃ¶Ãe \emph{approximativ}
normalverteilt ist.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-01-1.pdf}

}

}

\subcaption{\label{fig-normal-01-1}Histogramm.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-01-2.pdf}

}

}

\subcaption{\label{fig-normal-01-2}Densityplot.}
\end{minipage}%

\caption{\label{fig-normal-01}Darstellung der KÃ¶rpergrÃ¶Ãe in {[}cm{]}
fÃ¼r die Geschlechter getrennt.}

\end{figure*}

Wir kÃ¶nnen die Funktion \texttt{rnorm()} nutzen um uns zufÃ¤llige Zahlen
aus der Normalverteilung ziehen zu lassen. Dazu mÃ¼ssen wir mit
\texttt{n\ =} spezifizieren wie viele Beobachtungen wir wollen und den
Mittelwert \texttt{mean\ =} und die gewÃ¼nschte Standardabweichung mit
\texttt{sd\ =} angeben. Im Folgenden einmal ein Beispiel fÃ¼r die Nutzung
der Funktion \texttt{rnorm()} mit zehn Werten.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 6.97 6.24 5.59 5.27 6.30 4.91 4.13 4.92 3.67 4.42
\end{verbatim}

Du kannst ja mal den Mittelwert und die Standardabweichung der zehn
Zahlen ausrechnen. Da wir es hier mit einer Stichprobe mit zehn
Beobachtungen zu tun haben, wird der Mittelwert \(\bar{y}\) und die
Standardabweichung \(s_y\) sich von den vorher definierten Mittelwert
\(\mu_y = 5\) und Standardabweichung \(\sigma_y = 2\) der
Grundgesamtheit unterscheiden.

Wir kÃ¶nnen auch aus unseren GummibÃ¤rchendaten fÃ¼r die KÃ¶rpergrÃ¶Ãe in
{[}cm{]} jeweils den Mittelwert und die Standardabweichung getrennt fÃ¼r
die Geschlechter berechnen und dann die theoretische Normalverteilung
zeichenen. In Abbildung~\ref{fig-normal-03-2} und
Abbildung~\ref{fig-normal-03-4} sehen wir die Verteilung der
theoretischen Werte, wenn wir die Mittelwerte und die Standardabweichung
aus den Verteilungen in Abbildung~\ref{fig-normal-03-1} schÃ¤tzen.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-03-1.pdf}

}

}

\subcaption{\label{fig-normal-03-1}Verteilung der beobachteten Werte.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-03-2.pdf}

}

}

\subcaption{\label{fig-normal-03-2}Verteilung der theoretischen Werte.}
\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-03-3.pdf}

}

}

\subcaption{\label{fig-normal-03-3}Verteilung der beobachteten Werte.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-normal-03-4.pdf}

}

}

\subcaption{\label{fig-normal-03-4}Verteilung der theoretischen Werte.}
\end{minipage}%

\caption{\label{fig-normal-03}Darstellung der KÃ¶rpergrÃ¶Ãe in {[}cm{]}
fÃ¼r die Geschlechter getrennt. Auf der linken Seite die beobachteten
Werte und auf der rechten Seite die theoretischen Werte. Einmal
dargestellt als Histogramm und einmal als Densityplot.}

\end{figure*}

\hypertarget{die-standardnormalverteilung}{%
\section{Die
Standardnormalverteilung}\label{die-standardnormalverteilung}}

Es gibt viele Normalverteilungen. Aber es gibt eine besondere
Normalverteilung, so dass diese Verteilung einen eigenen Namen hat. Wir
sprechen von der Standardnormalverteilung, wenn der Mittelwert gleich
Null ist und die Standardabweichung gleich Eins. Du siehst hier nochmal
die Standardnormalverteilung ausgeschrieben.

\[
\mathcal{N}(0, 1)
\]

Folgende Eigenschaften sind der Standardnormalverteilung gegeben. Die
Standardnormalverteilung hat eine FlÃ¤che von \(A = 1\) unter der Kurve.
DarÃ¼ber hinaus liegen 95\% der Werte zwischen -2 und 2. Die einzelnen
Werte einer Standardnormalverteilung nennen wir \(z\)-Werte. Wenn wir
eine beliebige Normalverteilung in eine Standardnormalverteilung
Ã¼berfÃ¼hren wollen so machen wir die Umwandlung mit der
\(z\)-Transformation.

\hypertarget{sec-poisson}{%
\section{Die Poissonverteilung}\label{sec-poisson}}

Eine weitere wichtige Verteilung ist die Poissonverteilung. Die
Poissonverteilung ist eine diskrete Verteilung. Daher kommen nur ganze
Zahlen vor. Damit bildet die Poissonverteilung die ZÃ¤hldaten ab. Wenn
wir also etwas ZÃ¤hlen, dann ist diese Variable mit den gezÃ¤hlten
Ergebnissen poissonverteilt. Im Folgenden sehen wir die
Poissonverteilung einmal dargestellt.

\[
\mathcal{Pois}(\lambda)
\]

Im Gegensatz zur Normalverteilung hat die Poissonverteilung nur einen
Parameter. Den Lageparameter \(\lambda\) ausgedrÃ¼ckt durch den
griechischen Buchstaben Lambda. Eine Poissonverteilung mit
\(\mathcal{Pois}(4)\) hat den hÃ¶chsten Punkt bei vier. Nun hat die
Poissonverteilung hat mehrere Besonderheiten. Da die Poissonverteilung
keinen Streuungsparameter hat, steigt mit dem \(\lambda\) auch die
Streuung. Daher haben Poissonverteilungen mit einem groÃen \(\lambda\)
auch eine groÃe Streuung. ie Ausbreitung der Kurve ist eine Funktion von
\(\lambda\) und steigt mit \(\lambda\) an. Du kannst diesen Zusammenhang
in Abbildung~\ref{fig-pois-00} beobachten.

DarÃ¼ber hinaus kann eine Poissonverteilung nicht negativ werden. Es kann
keine kleinere Zahl als die Null geben. Durch die diskreten Zahlen haben
wir auch immer mal LÃ¼cken zwischen den Balken der Poissonverteilung. Das
passiert besonders, wenn wir eine kleine Anzahl an Beobachtungen haben.
AbschlieÃend konvergiert die Poissonverteilung bei groÃen \(\lambda\)
hin zu einer Normalverteilung.

\begin{figure}

{\centering \includegraphics{./eda-distribution_files/figure-pdf/fig-pois-00-1.pdf}

}

\caption{\label{fig-pois-00}Histogramm verschiedener
Poissonverteilungen.}

\end{figure}

Schauen wir uns nun einmal die Poissonverteilung im Beispiel an. In
Abbildung~\ref{fig-pois-01} sehen wir die Histogramme der Anzahl an
GummibÃ¤rchen in einer TÃ¼te und die Anzahl an Farben in einer TÃ¼te. Da
wir es hier mit ZÃ¤hldaten zu tun haben, kÃ¶nnte es sich um eine
Poissonverteilung handeln. Wie mÃ¼ssen uns nun die Frage stellen, ob die
GummibÃ¤rchen in einer TÃ¼te und die Anzahl an Farben in einer TÃ¼te
\emph{wirklich} eine zufÃ¤llige Realistierung sind. Daher eine zufÃ¤llige
Stichprobe der Grundgesamtheit. Wir kÃ¶nnen diese Annahme Ã¼berprÃ¼fen in
dem wir die theoretischen Werte fÃ¼r die beiden Poissonverteilung mit
\(\mathcal{Pois}(10)\) und \(\mathcal{Pois}(5)\) genieren.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-01-1.pdf}

}

}

\subcaption{\label{fig-pois-01-1}Anzahl an BÃ¤rchen}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-01-2.pdf}

}

}

\subcaption{\label{fig-pois-01-2}Anzahl an Farben}
\end{minipage}%

\caption{\label{fig-pois-01}Histogramme der Anzahl an GummibÃ¤rchen und
die Anzahl an Farben in einer TÃ¼te. Es gibt nicht mehr als sechs
Farben.}

\end{figure*}

Wir kÃ¶nnen die Funktion \texttt{rpois()} nutzen um uns zufÃ¤llige Zahlen
aus der Poissonverteilung ziehen zu lassen. Dazu mÃ¼ssen wir mit
\texttt{n\ =} spezifizieren wie viele Beobachtungen wir wollen und den
Mittelwert \texttt{lambda\ =} angeben. Im Folgenden einmal ein Beispiel
fÃ¼r die Nutzung der Funktion \texttt{rpois()} mit zehn Werten.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpois}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 3 5 4 5 3 3 9 3 5 5
\end{verbatim}

{\marginnote{\begin{footnotesize}Es gibt neben der Poissonverteilung
auch die negative Binomialverteilung sowie die Quasi-Poissonverteilung,
die es erlauben einen Streuungsparameter fÃ¼r die Poissonverteilung zu
schÃ¤tzen.\end{footnotesize}}}

Wir kÃ¶nnen nun auch aus unseren GummibÃ¤rchendaten fÃ¼r die Anzahl an
BÃ¤rchen in einer TÃ¼te sowie die Anzahl an Farben in einer TÃ¼te die
theoretische Poissonverteilung berechnen. In Abbildung~\ref{fig-pois-03}
sehen wir die Verteilung der beobachteten Werte fÃ¼r Anzahl an BÃ¤rchen in
einer TÃ¼te sowie die Anzahl an Farben in einer TÃ¼te und deren
theoretischen Verteilung nach dem geschÃ¤tzen \(\lambda = 10\) und
\(\lambda = 5\). Wir sehen ganz klar, dass die beide Variablen
\emph{keine} Zufallsrealisierung sind. Zum einen haben wir das auch
nicht erwartet, es gibt nicht mehr als sechs Farben und zum anderen ist
zu vermuten, dass Haribo technisch in den Auswahlprozess eingreift. Wir
haben auf jeden Fall eine sehr viel kleinere Streuung als bei einer
\emph{klassischen} Poissonverteilung anzunehmen wÃ¤re.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-03-1.pdf}

}

}

\subcaption{\label{fig-pois-03-1}Verteilung der beobachteten Anzahl an
BÃ¤rchen.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-03-2.pdf}

}

}

\subcaption{\label{fig-pois-03-2}Verteilung der theoretischen Anzahl an
BÃ¤rchen.}
\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-03-3.pdf}

}

}

\subcaption{\label{fig-pois-03-3}Verteilung der beobachteten Anzahl an
Farben.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./eda-distribution_files/figure-pdf/fig-pois-03-4.pdf}

}

}

\subcaption{\label{fig-pois-03-4}Verteilung der theoretischen Anzahl an
Farben.}
\end{minipage}%

\caption{\label{fig-pois-03}Darstellung Anzahl an BÃ¤rchen und Anzahl an
Farben. Es gibt nicht mehr als sechs Farben. Auf der linken Seite die
beobachteten Werte und auf der rechten Seite die theoretischen Werte.}

\end{figure*}

\hypertarget{weitere-verteilungen}{%
\section{Weitere Verteilungen}\label{weitere-verteilungen}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\marginnote{\begin{footnotesize}

Wir besuchen gerne die R Shiny App
\href{https://ben18785.shinyapps.io/distribution-zoo/}{The distribution
zoo} um mehr Ã¼ber die verschiedenen Verteilungen und deren Parameter zu
erfahren.

\end{footnotesize}}

In der nÃ¤chsten Zeit werden noch weitere gÃ¤ngige Verteilungen ergÃ¤nzt.
Bis dahin kÃ¶nnen die
\href{https://rstudio-pubs-static.s3.amazonaws.com/100906_8e3a32dd11c14b839468db756cee7400.html}{Basic
Probability Distributions in R} nochmal extern nachgeschaut werden.

Im Weiteren liefert Dormann (2013) eine gute Ãbersicht Ã¼ber verschiedene
Verteilungen.

\hypertarget{referenzen-2}{%
\section*{Referenzen}\label{referenzen-2}}
\addcontentsline{toc}{section}{Referenzen}

\part{Frequentistische Hypothesentests}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Grundlagen der Wissenschaft und Falsifikationsprinzip}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/h45ftLNsspM}{Grundlagen
der Wissenschaft und Falsifikationsprinzip} als Video.
\end{tcolorbox}

Das statistische Testen - eine Geschichte voller MissverstÃ¤ndnisse. Wir
wollen uns in den folgenden Kapiteln mit den Grundlagen des
frequentistischen Hypothesentestens beschÃ¤ftigen. Wenn ich hier einen
Unterschied mache, dann muss es ja auch noch ein anderes
Hypothesentesten geben. Ja, das nennt man dann bayesianische Statistik
und kommt eventuell mal spÃ¤ter. Wir konzentrieren uns aber zuerst auf
frequentistische Hypothesentesten was seit gut hundert Jahren genutzt
wird. Ich werde hier textlich nur einen kurzen Einstieg liefern.
Vielleicht wird es in den folgenden Jahren lÃ¤nger aber aktuell (Ende
2022) bleiben wir hier bei einem kurzen Einstieg.

{\marginnote{\begin{footnotesize}Forschung basiert auf dem
Falsifikationsprinzip. Wir kÃ¶nnen \textbf{nur ablehnen} und behalten das
weniger schlechte Modell bei.\end{footnotesize}}}

Beginnen wir mit der Logik der Forschung oder allgemeiner formuliert,
als die Grundlage der Wissenschaft. Wir basieren all unsere
Entscheidungen in der Wissenschaft auf dem Falsifikationsprinzip. Also
bitte merken, wir kÃ¶nnen nur ablehnen (eng. \emph{reject}).

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Logik der Forschung}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
âDas ist die Logik der Forschung, die nie verifizieren, sondern immer
nur jene ErklÃ¤rungen beibehalten kann, die beim derzeitigen
Erkenntnisstand am wenigsten falsifiziert sind.'' -- WÃ¶Ãmann, L.

Wir ersetzen schlechte Modelle (der Wirklichkeit) durch weniger
schlechte Modelle (der Wirklichkeit).
\end{tcolorbox}

Wir wollen hier auf keinen Fall die Leistungen von Altvorderen
schmÃ¤lern. Dennoch hatten
\href{https://en.wikipedia.org/wiki/Ronald_Fisher}{Ronald Fischer (1890
- 1962)}, als der BegrÃ¼nder der Statistik, andere Vorraussetzungen als
wir heutzutage. Als wichtigster Unterschied sei natÃ¼rlich das GerÃ¤t
genannt, an dem du gerade diese Zeilen liest: dem Computer. Selbst die
Erstellung einfachster Abbildungen war sehr, sehr zeitaufwendig. Die
Berechnung von Zahlen lohnte sich mehr, als die Zahlen zu visualisieren.
Insbesondere wenn wir die Explorative Datenanalyse nach
\href{https://en.wikipedia.org/wiki/John_Tukey}{John Tukey (1915 -
2000)} durchfÃ¼hren. Undenkbar zu den Zeiten von Ronald Fischer mehrere
Abbildungen unterschiedlich nach Faktoren einzufÃ¤rben und sich die Daten
\emph{anzugucken}.

{\marginnote{\begin{footnotesize}Ãber die Nullhypothese erfÃ¤hrst du mehr
in dem folgenden Kapitel~\ref{sec-hypothesen}\end{footnotesize}}}

Neben dieser Begrenzung von moderner RechenkapazitÃ¤t um 1900 gab es noch
eine andere ungÃ¼nstige Entwicklung. Stark vereinfacht formuliert
entwickelte Ronald Fischer statistische Werkzeuge um abzuschÃ¤tzen wir
wahrscheinlich die Nullhypothese unter dem Auftreten der beobachteten
Daten ist. Nun ist es aber so, dass wir ja auch eine Entscheidung
treffen wollen. Nach der Logik der Forschung wollen wir ja eine
Hypothese falsifizieren, in unserem Fall die Nullhypothese. Die
Entscheidungsregeln, also die statistische Testtheorie, kommen nun von
\href{https://en.wikipedia.org/wiki/Jerzy_Neyman}{Jerzy Neyman (1894 -
1981)} und \href{https://en.wikipedia.org/wiki/Egon_Pearson}{Egon
Pearson (1895 - 1980)}, beide als die BegrÃ¼nder der frequentistischen
Hypothesentests.

Schlussendlich gibt es noch eine andere StrÃ¶mung in der Statistik, die
auf den mathematischen Formeln von
\href{https://en.wikipedia.org/wiki/Thomas_Bayes}{Thomas Bayes (1701 -
1761)} basieren. In sich eine geschlossene Theorie, die auf der
\emph{inversen} Wahrscheinlichkeit basiert. Das klingt jetzt etwas
schrÃ¤g, aber eigentlich ist die bayesianische Statistik die Statistik,
die die Fragen um die Alternativehypothese beantwortet. Der Grund warum
die bayesianische Statistik nicht angewendet wurde, war der Bedarf an
Rechenleistung. Die bayesiansiche Statistik lÃ¤sst sich nicht hÃ¤ndisch in
endlicher Zeit lÃ¶sen. Dieses \emph{technische} Problem haben wir aber
nicht mehr. Eigentlich kÃ¶nnten wir also die bayesiansiche Statistik
verwenden. Wir wollen hier aber (noch) nicht auf die bayesianische
Statistik eingehen, das werden wir spÃ¤ter tun.

Wenn du allgemein Interesse hast an der Geschichte der Statistik dann
sei auf Salsburg (2001) verwiesen. Ein sehr schÃ¶nes Buch, was die
\emph{geschichtlichen} ZusammenhÃ¤nge nochmal aufzeigt.

Kommen wir aber nun zu den wichtigeren Punkten. Die folgenden Kapitel
ist sehr umfangreich und enthalten viele Informationen, die wir
teilweise spÃ¤ter nochmal brauchen. DarÃ¼ber hinaus mÃ¼ssen wir noch das
\emph{Lernen und Verstehen} von der \emph{Anwendung} unterscheiden. Wir
teilen dabei die Test\emph{entscheidung} und die Test\emph{theorie} in
zwei Kapitel auf.

Du erfÃ¤hrst im Kapitel~\ref{sec-stat-entscheidung} mehr zur
Testentscheidung und welche Konzepte wir dort nutzen:

\begin{itemize}
\tightlist
\item
  Wir verstehen die statistischen Testentscheidung nutzen wir das
  Konzept der Teststatistik \(T\) (siehe
  Kapitel~\ref{sec-teststatistik})
\item
  Wir kÃ¶nnen die statistischen Testentscheidung anwenden, da wir das
  Konzept des p-Wertes \(Pr(T|H_0)\) (siehe Kapitel~\ref{sec-pwert}) und
  das Konzept der 95\% Konfidenzintervalle verstanden haben (siehe
  Kapitel~\ref{sec-ki})
\end{itemize}

Du erfÃ¤hrst im Kapitel~\ref{sec-stat-theorie} mehr zur Testtheorie und
welche Konzepte wir dort nutzen:

\begin{itemize}
\tightlist
\item
  Wir verstehen den Unterschied zwischen dem \(\alpha\)-Fehler und der
  \(\beta\)-Fehler (siehe Kapitel~\ref{sec-alpha-beta})
\item
  Wir wissen um den Unterschied des einseitigen und zweiseitigen
  statistischen Testens (siehe Kapitel~\ref{sec-einseitig-zweiseitig})
\item
  Wir verstehen die Adjustierung fÃ¼r multiple Vergleiche (siehe
  Kapitel~\ref{sec-statistisches-testen-alpha-adjust})
\end{itemize}

\hypertarget{referenzen-3}{%
\section*{Referenzen}\label{referenzen-3}}
\addcontentsline{toc}{section}{Referenzen}

\hypertarget{sec-stat-entscheidung}{%
\chapter{Die Testentscheidung}\label{sec-stat-entscheidung}}

\emph{Version vom September 14, 2022 um 08:48:31}

{\marginnote{\begin{footnotesize}Forschung basiert auf dem
Falsifikationsprinzip. Wir kÃ¶nnen \textbf{nur ablehnen} und behalten das
weniger schlechte Modell bei.\end{footnotesize}}}

Du erfÃ¤hrst im diesem Kapitel mehr zur Testentscheidung und welche
Konzepte wir dort nutzen:

\begin{itemize}
\tightlist
\item
  Wir verstehen die statistischen Testentscheidung nutzen wir das
  Konzept der Teststatistik \(T\) (siehe
  Kapitel~\ref{sec-teststatistik})
\item
  Wir kÃ¶nnen die statistischen Testentscheidung anwenden, da wir das
  Konzept des p-Wertes \(Pr(T|H_0)\) (siehe Kapitel~\ref{sec-pwert}) und
  das Konzept der 95\% Konfidenzintervalle verstanden haben (siehe
  Kapitel~\ref{sec-ki})
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
AbhÃ¤ngig von der Lernstufe - daher welche
\protect\hyperlink{sec-vorlesungen-hs}{Veranstaltung} du gerade bei mir
besuchst - kommt nicht \emph{alles} aus diesem Kapitel dran in der
Klausur. Bitte gleiche die Inhalte, die ich in der aktuellen Vorlesung
unterrichte, mit dem Material hier ab. Als Faustregel gilt, je hÃ¶her die
Lernstufe desto mehr musst du von dem statistischen Testen Wissen und
Verstehen. Beachte auch die Probeklausur in deiner Veranstaltung und die
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub}.
\end{tcolorbox}

\hypertarget{sec-hypothesen}{%
\section{Die Hypothesen}\label{sec-hypothesen}}

\marginnote{\begin{footnotesize}

Im Anhang~\ref{sec-beispiel-auswertung} findest du verschiedene
Beispiele zu Auswertungen von Datenbeispielen.

\end{footnotesize}}

Wir kÃ¶nnen auf allen Daten einen statistischen Test rechnen und erhalten
statistische MaÃzahlen wie eine Teststatistik oder einen p-Wert. Nur
leider kÃ¶nnen wir mit diesen statistischen MaÃzahlen nicht viel anfangen
ohne die Hypothesen zu kennen. Jeder statistische Test testet eine
Nullhypothese. Ob diese Hypothese dem Anwender nun bekannt ist oder
nicht, ein statistischer Test testet eine Nullhypothese. Daher mÃ¼ssen
wir uns immer klar sein, was die entsprechende Nullhypothese zu unserer
Fragestellung ist. Wenn du hier stockst, ist das ganz normal. Eine
Fragestellung mit einer statistischen Hypothese zu verbinden ist nicht
immer so einfach gemacht.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Die Nullhypothese \(H_0\) und die Alternativehypothese \(H_A\)}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Die Nullhypothese \(H_0\) nennen wir auch die Null oder
Gleichheitshypothese. Die Nullhypothese sagt aus, dass zwei Gruppen
gleich sind oder aber kein Effekt zu beobachten ist.

\[
H_0: \bar{y}_{1} = \bar{y}_{2}
\]

Die Alternativehypothese \(H_A\) oder \(H_1\) auch Alternative genannt
nennen wir auch Unterschiedshypothese. Die Alternativehypothese besagt,
dass ein Unterschied vorliegt oder aber ein Effekt vorhanden ist.

\[
H_A: \bar{y}_{1} \neq \bar{y}_{2}
\]
\end{tcolorbox}

Als Veranschaulichung nehmen wir das Beispiel aus
Kapitel~\ref{sec-example-2}. Wir formulieren als erstes die
Fragestellung. Eine Fragestellung endet mit einem Fragezeichen.

\emph{Liegt ein Unterschied zwischen den Sprungweiten von Katzen und
HundeflÃ¶hen vor?}

Wir kÃ¶nnen die Frage auch anders formulieren.

\emph{Springen Hunde und KatzenflÃ¶he unterschiedlich weit?}

Wichtig ist, dass wir eine primÃ¤re Fragestellung formulieren. Wir kÃ¶nnen
auch mehrere Fragen an einen Datensatz haben. Das ist auch vollkommen
normal. Nur hat \emph{jede} Fragestellung ein eigenes Hypothesenpaar.
Wir bleiben aber bei dem simplen Beispiel.

Wie sieht nun die statistische Hypothese in diesem Beispiel aus? Wir
wollen uns die Sprungweite in {[}cm{]} anschauen. In diesem Fall wollen
wir die \emph{mittlere} Sprungweite der HundeflÃ¶he \(\bar{y}_{dog}\) mit
der \emph{mittleren} Sprungweite der KatzenflÃ¶he \(\bar{y}_{cat}\)
vergleichen. Es ergibt sich folgendes Hypothesenpaar.

\begin{align*} 
H_0: \bar{y}_{dog} &= \bar{y}_{cat} \\  
H_A: \bar{y}_{dog} &\neq \bar{y}_{cat} \\   
\end{align*}

{\marginnote{\begin{footnotesize}Das \textbf{Falisifkationsprinzip} -
wir kÃ¶nnen nur Ablehnen - kommt hier zusammen mit der
\textbf{frequentistischen Statistik} in der wir nur eine
Wahrscheinlichkeitsaussage Ã¼ber das Auftreten der Daten \(D\) - unter
der Annahme \(H_0\) gilt - treffen kÃ¶nnen.\end{footnotesize}}}

Es ist wichtig sich in Erinnerung zu rufen, dass wir nur und
ausschlieÃlich Aussagen Ã¼ber die Nullhypothese treffen werden. Das
\emph{frequentistische} Hypothesentesten kann nichts anders. Wir kriegen
keine Aussage Ã¼ber die Alternativhypothese sondern nur eine AbschÃ¤tzung
der Wahrscheinlichkeit des Auftretens der Daten im durchgefÃ¼hrten
Experiment, wenn die Nullhypothese wahr wÃ¤re.

\hypertarget{die-testentscheidung}{%
\section{Die Testentscheidung\ldots{}}\label{die-testentscheidung}}

In den folgenden Kapiteln werden wir verschiedene statistische Tests
kennenlernen. Alle statistischen Tests haben gemein, dass ein Test eine
Teststatistik \(T_{calc}\) berechnet. DarÃ¼ber hinaus liefert jeder Test
auch einen p-Wert (eng. \emph{p-value}). Manche statistischen Test geben
auch ein 95\% Konfidenzintervall wieder. Eine Testentscheidung gegen die
Nullhypothese \(H_0\) kann mit jedem der drei statistischen MaÃzahlen
durchgefÃ¼hrt werden. Die Regel fÃ¼r die Entscheidung, ob die
Nullhypothese \(H_0\) abgelehnt werden kann, ist nur jeweils anders. In
Tabelle~\ref{tbl-comp-t-p-ki} sind die Entscheidungsregeln einmal
zusammengefasst.

\begin{figure*}

\hypertarget{tbl-comp-t-p-ki}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1135}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2411}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2695}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3759}}@{}}
\caption{\label{tbl-comp-t-p-ki}Zusammenfassung der statistischen
Testentscheidung unter der Nutzung der Teststatistik, dem p-Wert und dem
95\% Konfidenzintervall. Die Entscheidung nach der Teststatistik ist
veraltet und dient nur dem konzeptionellen VerstÃ¤ndnisses. In der
Forschung angewandt wird der p-Wert und das 95\% Konfidenzintervall. Im
Fall des 95\% Konfidenzintervalls mÃ¼ssen wir noch unterschieden, ob wir
einen Mittelwertsunterschied \(\Delta_{A-B}\) oder aber einen
Anteilsunterschied \(\Delta_{A/B}\) betrachten.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Teststatistik}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{p-Wert}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{95\% Konfidenzintervall}
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Teststatistik}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{p-Wert}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{95\% Konfidenzintervall}
\end{minipage} \\
\midrule()
\endhead
& \(\boldsymbol{T_{calc}}\) & \(\boldsymbol{Pr(\geq T_{calc}|H_0)}\) &
\(\boldsymbol{KI_{1-\alpha}}\) \\
H\(_0\) ablehnen & \(T_{calc} \geq T_{\alpha = 5\%}\) &
\(Pr(\geq T_{calc}| H_0) \leq \alpha\) & \(\Delta_{A-B}\): enthÃ¤lt
\uline{\emph{nicht}} \textbf{0} \\
H\(_0\) ablehnen & & & \(\Delta_{A/B}\): enthÃ¤lt \uline{\emph{nicht}}
\textbf{1} \\
\bottomrule()
\end{longtable}

\end{figure*}

Wir wollen in den folgenden Abschnitten die jeweiligen
Entscheidungsregeln eines statistisches Tests einmal durchgehen.

\begin{itemize}
\tightlist
\item
  Die Testentscheidung gegen die Nullhypothese anhand der Teststatistik
  in Kapitel~\ref{sec-teststatistik}
\item
  Die Testentscheidung gegen die Nullhypothese anhand dem p-Wert in
  Kapitel~\ref{sec-pwert}
\item
  Die Testentscheidung gegen die Nullhypothese anhand des 95\%
  Konfidenzintervall in Kapitel~\ref{sec-ki}
\end{itemize}

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Streng genommen gilt die Regel \(T_{calc} \geq T_{\alpha = 5\%}\) nur
fÃ¼r eine Auswahl an statistischen Tests siehe dazu auch
Kapitel~\ref{sec-teststatistik}. Bei manchen statistischen Tests ist die
Entscheidung gedreht. Hier lassen wir das aber mal so stehen\ldots{}

\hypertarget{sec-teststatistik}{%
\subsection{\ldots{} anhand der Teststatistik}\label{sec-teststatistik}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Prinzip des statistischen Testens I - Die Teststatistik}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/28QjGfR_SPQ}{Prinzip des
statistischen Testens I - Die Teststatistik} als Video. Ich werde zwar
alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen
und HÃ¶ren dann einfacher.
\end{tcolorbox}

Wir wollen uns dem frequentistischen Hypothesentesten Ã¼ber die Idee der
Teststatistik annÃ¤hern. Im folgenden sehen wir die Formel fÃ¼r den
t-Test. Den t-Test werden wir im Kapitel~\ref{sec-ttest} uns nochmal
detaillierter anschauen. Hier nutzen wir die vereinfachte Formel um das
Konzept zu verstehen.

\[
T_{calc}=\cfrac{\bar{y}_1-\bar{y}_2}{s_{p} \cdot \sqrt{2/n_g}}
\]

mit

\begin{itemize}
\tightlist
\item
  \(\bar{y}_1\) dem Mittelwert fÃ¼r die erste Gruppe.
\item
  \(\bar{y}_2\) dem Mittelwert fÃ¼r die zweite Gruppe.
\item
  \(s_{p}\) der gepoolten Standardabweichung mit
  \(s_p = \tfrac{s_A + s_B}{2}\).
\item
  \(n_g\) der GruppengrÃ¶Ãe der gruppen. Wir nehmen an beide Gruppen sind
  gleich groÃ.
\end{itemize}

Wir benÃ¶tigen also zwei Mittelwerte \(\bar{y}_1\) und \(\bar{y}_2\) und
deren gepoolte Standardabweichung \(s_p\) sowie die Anzahl der
Beobachtungen je Gruppe \(n_g\). Wenden wir die Formel des t-Tests
einmal auf den folgenden Beispieldatensatz an. In
Tabelle~\ref{tbl-dog-cat-small-delta} ist eine Datenbeispiel gegeben.

\hypertarget{tbl-dog-cat-small}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-dog-cat-small}Beispiel fÃ¼r die Berechnung von einem
Mittelwertseffekt an der SprunglÃ¤nge {[}cm{]} von Hunde und
KatzenflÃ¶hen.}\tabularnewline
\toprule()
animal & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length \\
\midrule()
\endhead
cat & 8.5 \\
cat & 9.9 \\
cat & 8.9 \\
cat & 9.4 \\
dog & 8.0 \\
dog & 7.2 \\
dog & 8.4 \\
dog & 7.5 \\
\bottomrule()
\end{longtable}

Wir berechnen nun die Mittelwerte und die Standardabweichungen aus der
obigen Datentabelle. Die Werte setzen wir dann in die Formel ein.

\[
T_{calc}=\cfrac{9.2 - 7.8}{\cfrac{(0.6 + 0.5)}{2} \cdot \sqrt{2/4}} = 3.6
\]

mit

\begin{itemize}
\tightlist
\item
  \(\bar{y}_{cat} = 9.2\) dem Mittelwert fÃ¼r die Gruppe \emph{cat}.
\item
  \(\bar{y}_{dog} = 7.8\) dem Mittelwert fÃ¼r die Gruppe \emph{dog}.
\item
  \(s_p = 0.55\) der gepoolten Standardabweichung mit
  \(s_p = \tfrac{0.6 + 0.5}{2}\).
\item
  \(n_g = 4\) der GruppengrÃ¶Ãe der Gruppe A und B. Wir nehmen an beide
  Gruppen sind gleich groÃ.
\end{itemize}

Wir haben nun die Teststatistik \(T_{calc} = 3.6\) berechnet. In der
ganzen Rechnererei verliert man manchmal den Ãberblick. Erinnern wir
uns, was wir eigentlich wollten. Die Frage war, ob sich die mittleren
Sprungweiten der Hunde- und KatzenflÃ¶he unterschieden. Wenn die \(H_0\)
wahr wÃ¤re, dann wÃ¤re der Unterschied \(\Delta\) der beiden Mittelwerte
der Hunde- und KatzenflÃ¶he gleich null. Oder nochmal in der Analogie der
t-Test Formel, dann wÃ¤re im ZÃ¤hler
\(\Delta = \bar{y}_{cat} - \bar{y}_{dog} = 0\). Wenn die Mittelwerte der
Sprungweite {[}cm{]} der Hunde- und KatzenflÃ¶he gleich wÃ¤re, dann wÃ¤re
die berechnete Teststatistik \(T_{calc} = 0\), da im ZÃ¤hler Null stehen
wÃ¼rde. Die Differenz von zwei gleichen Zahlen ist Null.

Je grÃ¶Ãer die berechnete Teststatistik \(T_{calc}\) wird, desto
unwahrscheinlicher ist es, dass die beiden Mittelwerte per Zufall gleich
sind. Wie groÃ muss nun die berechnete Teststatistik \(T_{calc}\) werden
damit wir die Nullhypothese ablehnen kÃ¶nnen?

\begin{figure*}

{\centering \includegraphics{./images/t-verteilung_01.png}

}

\caption{\label{fig-teststatistik-01}Die t-Verteilung aller mÃ¶glichen
\(T_{calc}\) wenn die Nullhypothese wahr ist. Der Mittelwert der
t-Verteilun ist \(T=0\). Wenn wir keinen Effekt erwarten wÃ¼rden dann
wÃ¤ren die beiden Mittelwerte \(\bar{y}_1\) und \(\bar{y}_2\) gleich
groÃ. Die Differenz wÃ¤re 0. Je grÃ¶Ãer der \(T_{calc}\) wird desto
weniger kÃ¶nnen wir davon ausgehen, dass die beiden Mittelwerte gleich
sind. Liegt der \(T_{calc}\) Ã¼ber dem kritischen Wert von
\(T_{\alpha = 5\%}\) dann wir die Nullhypothese abgelehnt.}

\end{figure*}

In Abbildung~\ref{fig-teststatistik-01} ist die Verteilung aller
mÃ¶glichen \(T_{calc}\) Werte unter der Annahme, dass die Nullhypothese
wahr ist, dargestellt. Wir sehen, dass die t-Verteilung am hÃ¶chsten bei
\(T_{calc} = 0\) ist und niedrigeren Werte mit steigenden t-Werten
annimmt. Wenn \(T = 0\) dann sind auch die Mittelwerte gleich. Je grÃ¶Ãer
unsere berechnete Teststatistik \(T_{calc}\) wird, desto
unwahrscheinlicher ist es, dass die Nullhypothese gilt. Die t-Verteilug
ist so gebaut, dass die FlÃ¤che \(A\) unter der Kurve gleich \(A=1\) ist.
Wir kÃ¶nnen nun den kritschen Wert \(T_{\alpha = 5\%}\) berechnen an dem
rechts von dem Wert eine FlÃ¤che von 0.05 oder 5\% liegt. Sommit liegt
dann links von dem kritischen Wert die FlÃ¤che von 0.95 oder 95\%. Den
kritischen Wert \(T_{\alpha = 5\%}\) kÃ¶nnen wir statistischen Tabellen
entnehmen. Oder wir berechnen den kritischen Wert direkt in R mit
\(T_{\alpha = 5\%} = 2.78\).

Kommen wir zurÃ¼ck zu unserem Beispiel. Wir haben in unserem
Datenbeispiel fÃ¼r den Vergleich von der Sprungweite in {[}cm{]} von
Hunde- und KatzenflÃ¶hen eine Teststatistik von \(T_{calc} = 3.6\)
berechnet. Der kritische Wert um die Nullhypothese abzulehnen liegt bei
\(T_{\alpha = 5\%} = 2.78\). Wenn \(T_{calc} \geq T_{\alpha = 5\%}\)
wird die Nullhypothese (H\(_0\)) abgelehnt. In unserem Fall ist
\(3.6 \geq 2.78\). Wir kÃ¶nnen die Nullhypothese ablehnen. Es gibt einen
Unterschied zwischen der mittleren Sprungweite von Hunde- und
KatzenflÃ¶hen.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

\emph{Es gibt einen Unterschied zwischen der mittleren Sprungweite von
Hunde- und KatzenflÃ¶hen.} Die Aussage ist \textbf{statistisch} falsch.
Wir kÃ¶nnen im frequentistischen Hypothesentesten keine Aussage Ã¼ber die
\(H_A\) treffen. Im Sinne der Anwendbarkeit soll es hier so stehen
bleiben.

Nun ist es leider so, dass jeder statistische Test seine eigene
Teststatistik \(T\) hat. Daher ist es etwas mÃ¼hselig sich immer neue und
andere kritische Werte fÃ¼r jeden Test zu merken. Es hat sich daher
eingebÃ¼rgert, sich nicht die Teststatistik fÃ¼r die Testentscheidung
gegen die Nullhypothese zu nutzen sondern den p-Wert. Den p-Wert wollen
wir uns in dem folgenden Abschnitt anschauen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit der berechneten Teststatistik}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung mit der Teststatistik mÃ¼ssen wir zwei FÃ¤lle
unterschieden.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Bei einem t-Test und einem \(\mathcal{X}^2\)-Test gilt, wenn
  \(T_{calc} \geq T_{\alpha = 5\%}\) wird die Nullhypothese (H\(_0\))
  abgelehnt.
\item
  Bei einem Wilcoxon-Mann-Whitney-Test gilt, wenn
  \(T_{calc} < T_{\alpha = 5\%}\) wird die Nullhypothese (H\(_0\))
  abgelehnt.
\end{enumerate}

\textbf{Achtung --} Wir nutzen die Entscheidung mit der Teststatistik
\emph{nur und ausschlieÃlich} in der Klausur. In der praktischen
Anwendung hat die Betrachtung der berechneten Teststatistik \emph{keine}
Verwendung mehr.
\end{tcolorbox}

\hypertarget{sec-pwert}{%
\subsection{\ldots{} anhand dem p-Wert}\label{sec-pwert}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Prinzip des statistischen Testens II - Der p-Wert}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/Zr8gdWZrSPc}{Prinzip des
statistischen Testens II - Der p-Wert} als Video Reihe. Ich werde zwar
alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen
und HÃ¶ren dann einfacher.
\end{tcolorbox}

In dem vorherigen Abschnitt haben wir gelernt, wie wir zu einer
Entscheidung gegen die Nullhypothese anhand der Teststatistik kommen.
Wir haben einen kritischen Wert \(T_{\alpha = 5\%}\) definiert bei dem
rechts von dem Wert 5\% der Werte liegen. Anstatt nun den berechneten
Wert \(T_{calc}\) mit dem kritischen Wert \(T_{\alpha = 5\%}\) zu
vergleichen, vergleichen wir jetzt die FlÃ¤chen rechts von den jeweiligen
Werten.

{\marginnote{\begin{footnotesize}Wir schreiben \(\boldsymbol{Pr}\) und
meinen damit eine Wahrscheinlichkeit (eng. \emph{probability}). HÃ¤ufig
wird auch nur das \(P\) verwendet, aber dann kommen wir wieder mit
anderen Konzepten in die Quere.\end{footnotesize}}}

In Abbildung~\ref{fig-teststatistik-01} sind die FlÃ¤chen auch
eingetragen. Da die gesamte FlÃ¤che unter der t-Verteilung mit \(A = 1\)
ist, kÃ¶nnen wir die FlÃ¤chen auch als Wahrscheinlichkeiten lesen. Die
FlÃ¤che rechts von der berechneten Teststatistik \(T_{calc}\) wird
\(Pr(T_{calc}|H_0)\) oder \(p\)-Wert genannt. Die \emph{gesamte} FlÃ¤che
rechts von dem kritischen Wert \(T_{\alpha = 5\%}\) wird \(\alpha\)
genannt und liegt bei 5\%. Wir kÃ¶nnen also die Teststatistiken oder den
p-Wert mit dem \(\alpha\)-Niveau von 5\% vergleichen.

\hypertarget{tbl-t-und-A}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-t-und-A}Zusammenhang zwischen der Teststatistik
\(T\) und der FlÃ¤che \(A\) rechts von der Teststatistik. Die FlÃ¤che
rechts von der berechneten Teststatistik \(T_{calc}\) wird \(Pr(T|H_0)\)
oder \(p\)-Wert genannt. Die FlÃ¤che rechts von dem kritischen Wert
\(T_{\alpha = 5\%}\) wird \(\alpha\) genannt und liegt bei
5\%.}\tabularnewline
\toprule()
Teststatistik \(T\) & FlÃ¤che \(A\) \\
\midrule()
\endfirsthead
\toprule()
Teststatistik \(T\) & FlÃ¤che \(A\) \\
\midrule()
\endhead
\(T_{calc}\) & \(Pr(T_{calc}|H_0)\) oder \(p\)-Wert \\
\(T_{\alpha = 5\%}\) & \(\alpha\) \\
\bottomrule()
\end{longtable}

Der p-Wert oder \(Pr(T|H_0)\) ist eine Wahrscheinlichkeit. Eine
Wahrscheinlichkeit kann die Zahlen von 0 bis 1 annehmen. Dabei sind die
Grenzen einfach zu definieren. Eine Wahrscheinlichkeit von \(Pr(A) = 0\)
bedeutet, dass das Ereignis A nicht auftritt; eine Wahrscheinlichkeit
von \(Pr(A) = 1\) bedeutet, dass das Ereignis A eintritt. Der Zahlenraum
dazwischen stellt jeden von uns schon vor groÃe Herausforderungen. Der
Unterschied zwischen 40\% und 60\% fÃ¼r den Eintritt des Ereignisses A
sind nicht so klar zu definieren, wie du auf den ersten Blick meinen
magst.

Ein frequentistischer Hypothesentest beantwortet die Frage, mit welcher
Wahrscheinlichkeit \(Pr\) die Teststatistik \(T\) aus dem Experiment mit
den Daten \(D\) zu beobachten wÃ¤ren, wenn es keinen Effekt gÃ¤be (\(H_0\)
ist wahr).

{\marginnote{\begin{footnotesize}\textbf{Likelihood} heiÃt PlausibilitÃ¤t
und \textbf{Probability} heiÃt Wahrscheinlichkeit.\end{footnotesize}}}

Im Englischen gibt es die Begrifflichkeiten einer \emph{Likelihood} und
einer \emph{Probability} in der Statistik. Meist wird beides ins
Deutsche ungenau mit Wahrscheinlichkeit Ã¼bersetzt oder wir nutzen
einfach \emph{Likelihood}. Was aber auch nicht so recht weiterhilft. Es
handelt sich hierbei aber um zwei unterschiedliche Konzepte. Deshalb
Ãbersetzen wir \emph{Likelihood} mit PlausibilitÃ¤t und
\emph{Probability} mit Wahrscheinlichkeit.

Im Folgenden berechnen wir den \(p\)-Wert in R mit der Funktion
\texttt{t.test()}. Mehr dazu im Kapitel~\ref{sec-ttest}, wo wir den
t-Test und deren Anwendung im Detail besprechen.

\begin{verbatim}
# A tibble: 1 x 2
  statistic p.value
      <dbl>   <dbl>
1      2.81  0.0309
\end{verbatim}

{\marginnote{\begin{footnotesize}Wir sagen, dass wir ein
\textbf{signifikantes} Ergebnis haben, wenn der \(p\)-Wert kleiner ist
als die Signifikanzschwelle \(\alpha\) von 5\%.\end{footnotesize}}}

Wir erhalten einen \(p\)-Wert von 0.031 und vergleichen diesen Wert zu
einem \(\alpha\) von 5\%. Ist der \(p\)-Wert kleiner als der
\(\alpha\)-Wert von 5\%, dann kÃ¶nnen wir die Nullhypothese ablehnen. Da
0.031 kleiner ist als 0.05 kÃ¶nnen wir die Nullhypothese und damit die
Gleichheit der mittleren Sprungweiten in {[}cm{]} ablehnen. Wir sagen,
dass wir ein signifikantes Ergebnis vorliegen haben.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit dem p-Wert}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Wenn der p-Wert \(\leq \alpha\) dann wird die Nullhypothese (H\(_0\))
abgelehnt. Das Signifikanzniveau \(\alpha\) wird als Kulturkonstante auf
5\% oder 0.05 gesetzt. Die Nullhypothese (H\(_0\)) kann auch
Gleichheitshypothese gesehen werden. Wenn die H\(_0\) gilt, liegt kein
Unterschied zwischen z.B. den Behandlungen vor.
\end{tcolorbox}

\hypertarget{sec-ki}{%
\subsection{\ldots{} anhand des 95\% Konfidenzintervall}\label{sec-ki}}

Ein statistischer Test der eine Teststatistik \(T\) berechnet liefert
auch immer einen \(p\)-Wert. Nicht alle statistischen Tests ermÃ¶glichen
es ein 95\% Konfidenzintervall zu berechnen. Abbildung~\ref{fig-ki-00}
zeigt ein 95\% konfidenzintervall.

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{./images/ci-00.png}

}

\caption{\label{fig-ki-00}Ein 95\% Konfidenzintervall. Der Punkt in der
Mitte entspricht dem Unterschied oder Effekt \(\Delta\).}

\end{figure}

{\marginnote{\begin{footnotesize}Mit \textbf{p-Werten} haben wir
Wahrscheinlichkeitsaussagen und damit Ã¼ber die \textbf{Signifikanz}.
Damit haben wir noch keine Aussage Ã¼ber die \textbf{Relevanz} des
beobachtenten Effekts.\end{footnotesize}}}

Mit der Teststatistik \(T\) und dem damit verbundenen \(p\)-Wert haben
wir uns \emph{Wahrscheinlichkeiten} angeschaut und erhalten eine
\emph{Wahrscheinlichkeitsaussage}. Eine Wahrscheinlichkeitsaussage sagt
aber nichts Ã¼ber den Effekt \(\Delta\) aus. Also wie groÃ ist der
mittlere Sprung\emph{unterschied} zwischen Hunde- und KatzenflÃ¶hen.

Die Idee von 95\% Kondifenzintervallen ist es jetzt den Effekt mit der
Wahrscheinlichkeitsaussage zusammenzubringen und beides in einer
\emph{Visualisierung} zu kombinieren. Im Folgenden sehen wir die
vereinfachte Formel fÃ¼r das 95\% Konfidenzintervall eines t-Tests.

\[
\left[
(\bar{y}_1-\bar{y}_2) - 
T_{\alpha = 5\%} \cdot \frac {s_p}{\sqrt{n}}; \;
(\bar{y}_1-\bar{y}_2) + 
T_{\alpha = 5\%} \cdot \frac {s_p}{\sqrt{n}};
\right]
\]

Die Formel ist ein wenig komplex, aber im Prinzip einfach. Der linke und
der rechte Teil neben dem Semikolon sind fast gleich, bis auf das Plus-
und Minuszeichen. Abbildung~\ref{fig-ki-01} visualisert die Formel
einmal. Wir sehen Folgendes in der Formel und dann in der entsprechenden
Abbildung:

\begin{itemize}
\tightlist
\item
  \((\bar{y}_{1}-\bar{y}_{2})\) ist der Effekt \(\Delta\). In diesem
  Fall der Mittelwertsunterschied. Wir finden den Effekt als Punkt in
  der Mitte des Intervals.
\item
  \(T_{\alpha = 5\%} \cdot \frac {s}{\sqrt{n}}\) ist der Wert, der die
  Arme des Intervals bildet. Wir vereinfachen die Formel mit \(s_p\) fÃ¼r
  die gepoolte Standardabweichung und \(n_g\) fÃ¼r die Fallzahl der
  beiden Gruppen. Wir nehmen an das beide Gruppen die gleiche Fallzahl
  \(n_1 = n_2\) haben.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/ci-01.png}

}

\caption{\label{fig-ki-01}Zusammenhang zwischen der vereinfachten Formel
fÃ¼r das 95\% Konfidenzintervall und der Visualisierung des 95\%
Konfidenzintervalls. Der EffektschÃ¤tzer wird als Punkt in der Mitte des
Intervalls dargestellt. Der EffektschÃ¤ter \(\Delta\) kann entweder ein
Mittelwertsunterschied sein oder ein Anteilsunterschied. Bei einem
Mittelwertsunterschied kann die Nullhypothese abgelehnt werden, wenn die
0 nicht im Konfidenzintervall ist; bei einem Anteilsunterschied wenn die
1 nicht im Konfidenzintervall ist. Die Arme werden lÃ¤nger oder kÃ¼rzer je
nachdem wie sich die statistischen MaÃzahlen \(s\) und \(n\) verÃ¤ndern.}

\end{figure}

{\marginnote{\begin{footnotesize}Die Funktion \texttt{factor()} in R
erlaubt es dir die Level eines Faktors zu sortieren und so festzulegen
ob Level \texttt{cat} minus Level \texttt{dog} oder umgekehrt von R
gerechnet wird.\end{footnotesize}}}

Wir kÃ¶nnen eine biologische Relevanz definieren, dadurch das ein 95\%
Konfidenzintervall die Wahrscheinlichkeitsaussage Ã¼ber die Signifkanz,
daher ob die Nullhypothese abgelehnt werden kann, mit dem Effekt
zusammenbringt. Wo die Signifikanzschwelle klar definiert ist, hÃ¤ngt die
Relevanzschwelle von der wissenschaftlichen Fragestellung und weiteren
externen Faktoren ab. Die Signifikanzschwelle liegt bei 0, wenn wir
Mittelwerte miteinander vergleichen und bei 1, wenn wir Anteile
vergleichen. Abbildung~\ref{fig-relevanz} zeigt fÃ¼nf 95\%
Konfidenzintervalle (a-e), die sich anhand der Signifikanz und Relevanz
unterscheiden. Bei der Relevanz ist es wichtig zu wissen in welche
\emph{Richtung} der Effekt gehen soll. Erwarten wir einen positiven
Effekt wenn wir die Differenz der beiden Gruppen bilden oder einen
negativen Effekt?

\begin{figure}

{\centering \includegraphics{./images/ci-02.png}

}

\caption{\label{fig-relevanz}Verschiedene signifikante und relevante
Konfidenzintervalle: (a) nicht signifikant und nicht relevant; (b)
signifikant und nicht relevant; (c) signifikant und relevant; (d)
signifikant und nicht relevant, der Effekt ist zu klein; (e) signifikant
und potenziell relevant, Effekt zeigt in eine unerwartete Richtung
gegeben der Relevanzschwelle.}

\end{figure}

Wir wollen uns nun einmal anschauen, wie sich ein 95\%
Konfidenzintervall berechnet. Wir nehmen dafÃ¼r die vereinfachte Formel
und setzen die berechneten statistischen MaÃzahlen ein. In der Anwendung
werden wir die Konfidenzintervalle nicht selber berechnen. Wenn ein
statistisches Verfahren konfidenzintervalle berechnen kann, dann liefert
die entsprechende Funktion in R das Konfidenzintervall.

Es ergibt sich Folgende ausgefÃ¼llte, vereinfachte Formel fÃ¼r das 95\%
Konfidenzintervalls eines t-Tests fÃ¼r das Beispiel des
Sprungweitenunterschieds {[}cm{]} zwischen Hunde- und KatzenflÃ¶hen.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Wir nutzen hier eine \textbf{vereinfachte Formel} fÃ¼r das
Konfidenzintervall um das Konzept zu verstehen. SpÃ¤ter berechnen wir das
Konfidenzintervall in R.

\[
\left[
(9.2-7.8) - 
2.78 \cdot \frac {0.55}{\sqrt{4}}; \;
(9.2-7.8) + 
2.78 \cdot \frac {0.55}{\sqrt{4}};
\right]
\]

mit

\begin{itemize}
\tightlist
\item
  \(\bar{y}_{cat} = 9.2\) dem Mittelwert fÃ¼r die Gruppe \emph{cat}.
\item
  \(\bar{y}_{dog} = 7.8\) dem Mittelwert fÃ¼r die Gruppe \emph{dog}.
\item
  \(T_{\alpha = 5\%} = 2.78\) dem kritischen Wert.
\item
  \(s_p = 0.55\) der gepoolten Standardabweichung mit
  \(s_p = \tfrac{0.6 + 0.5}{2}\).
\item
  \(n_g = 4\) der GruppengrÃ¶Ãe der Gruppe A und B. Wir nehmen an beide
  Gruppen sind gleich groÃ.
\end{itemize}

LÃ¶sen wir die Formel auf, so ergibt sich folgendes 95\%
Konfidenzintervall des Mittelwertsunterschiedes der Hunde- und
KatzenflÃ¶he.

\[[0.39; 2.20]\]

Wir kÃ¶nnen sagen, dass mit 95\% Wahrscheinlichkeit das
Konfidenzintervall den wahren Effektunterschied \(\Delta\) Ã¼berdeckt.
Oder etwas mehr in Prosa, dass wir eine Sprungweiten\emph{unterschied}
von 0.39 cm bis 2.20 cm zwischen Hunde- und KatzenflÃ¶hen erwarten
wÃ¼rden.

Die Entscheidung gegen die Nullhypothese bei einem
Mittelwertsunterschied erfolgt bei einem 95\% Konfidenzintervall danach
ob die Null mit im Konfidenzintervall liegt oder nicht. In dem Interval
\([0.39; 2.20]\) ist die Null nicht enthalten, also kÃ¶nnen wir die
Nullhypothese ablehnen. Es ist mit einem Unterschied zwischen den
mittleren Sprungweiten von Hunde- und KatzenflÃ¶hen auszugehen.

In unserem Beispiel, kÃ¶nnten wir die Relevanzschwelle fÃ¼r den mittleren
Sprungweitenunterschied zwischen Hund- und KatzenflÃ¶hen auf 2 cm setzen.
In dem Fall wÃ¼rden wir entscheiden, dass der mittlere
Sprungweitenunterschied nicht relevant ist, da die 2 cm im
Konfidenzintervall enthalten sind. Was wÃ¤re wenn wir die
Relevanzschwelle auf 4 cm setzen? Dann wÃ¤re zwar die Relevanzschwelle
nicht mehr im Konfidenzintervall, aber wir hÃ¤tten Fall (d) in der
Abbildung~\ref{fig-relevanz} vorliegen. Der Effekt ist einfach zu klein,
dass der Effekt relevant sein kÃ¶nnte.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit dem 95\% Konfidenzintervall}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]

Bei der Entscheidung mit dem 95\% Konfidenzinterval mÃ¼ssen wir zwei
FÃ¤lle unterscheiden.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Entweder schauen wir uns einen Mittelwertsunterschied
  (\(\Delta_{y_1-y_2}\)) an, dann kÃ¶nnen wir die Nullhypothese (H\(_0\))
  \emph{nicht} ablehnen, wenn die \textbf{0} im 95\% Konfidenzinterval
  ist.
\item
  Oder wir schauen uns einen Anteilsunterschied (\(\Delta_{y_1/y_2}\))
  an, dann kÃ¶nnen wir die Nullhypothese (H\(_0\)) \emph{nicht} ablehnen,
  wenn die \textbf{1} im 95\% Konfidenzinterval ist.
\end{enumerate}

\end{tcolorbox}

\hypertarget{sec-delta-n-s}{%
\section{Auswirkung des Effektes, der Streuung und der
Fallzahl}\label{sec-delta-n-s}}

Wir wollen einmal den Zusammenhang zwischen dem Effekt \(\Delta\), der
Streuung als Standardabweichung \(s\) und Fallzahl \(n\) uns nÃ¤her
anschauen. Wir kÃ¶nnen die Formel des t-Tests wie folgt vereinfachen.

\[
T_{calc}=\cfrac{\bar{y}_1-\bar{y}_1}{s_{p} \cdot \sqrt{2/n_g}}
\]

FÃ¼r die Betrachtung der ZusammenhÃ¤nge wandeln wir \(\sqrt{2/n_g}\) in
\(1/n\) um. Dadurch wandert die Fallzahl \(n\) in den ZÃ¤hler. Die
Standardabweichung verallgemeinern wir zu \(s\) und damit allgemein zur
Streuung. AbschlieÃend betrachten wir \(\bar{y}_A-\bar{y}_B\) als den
Effekt \(\Delta\). Es ergibt sich folgende vereinfachte Formel.

\[
T_{calc} = \cfrac{\Delta \cdot n}{s}
\]

Wir kÃ¶nnen uns nun die Frage stellen, wie Ã¤ndert sich die Teststatistik
\(T_{calc}\) in AbhÃ¤ngigkeit vom Effekt \(\Delta\), der Fallzahl \(n\)
und der Streuung \(s\) in den Daten. Die Tabelle~\ref{tbl-t-und-p} zeigt
die ZusammenhÃ¤nge auf. Die Aussagen in der Tabelle lassen sich
generalisieren. So bedeutet eine steigende Fallzahl meist mehr
signifikante Ergebnisse. Eine stiegende Streuung reduziert die
Signifikanz eines Vergleichs. Ein Ansteigen des Effektes fÃ¼hrt zu mehr
signifikanten Ergebnissen. Ebenso verschiebt eine VerÃ¤nderung des Effekt
das Konfidenzintervall, eine ErhÃ¶hung der Streuung macht das
konfidenzintervall breiter, eine sinkende Streeung macht das
konfidenzintervall schmaller. bei der Fallzahl verhÃ¤lt es sich
umgekehrt. Eine ErhÃ¶hung der Fallzahl macht das Konfidenzintervall
schmaller und eine sinkende Fallzahl das Konfidenzintervall breiter.

\begin{figure*}

\hypertarget{tbl-t-und-p}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0950}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1250}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1900}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0850}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1050}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1250}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1900}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0850}}@{}}
\caption{\label{tbl-t-und-p}Zusammenhang von der Teststatistik
\(T_{calc}\) und dem p-Wert \(Pr(\geq T_{calc}|H_0)\) sowie dem
\(KI_{1-\alpha}\) in AbhÃ¤ngigkeit vom Effekt \(\Delta\), der Fallzahl
\(n\) und der Streuung \(s\).}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{T_{calc}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Pr(\geq T_{calc}|H_0)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(KI_{1-\alpha}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{T_{calc}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Pr(\geq T_{calc}|H_0)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(KI_{1-\alpha}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{T_{calc}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Pr(\geq T_{calc}|H_0)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(KI_{1-\alpha}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{T_{calc}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Pr(\geq T_{calc}|H_0)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(KI_{1-\alpha}\)
\end{minipage} \\
\midrule()
\endhead
\(\Delta \uparrow\) & steigt & sinkt & verschoben &
\(\Delta \downarrow\) & sinkt & steigt & verschoben \\
\(s \uparrow\) & sinkt & steigt & breiter & \(s \downarrow\) & steigt &
sinkt & schmaller \\
\(n \uparrow\) & steigt & sinkt & schmaller & \(n \downarrow\) & sinkt &
steigt & breiter \\
\bottomrule()
\end{longtable}

\end{figure*}

\hypertarget{sec-stat-theorie}{%
\chapter{Die Testtheorie}\label{sec-stat-theorie}}

\emph{Version vom September 14, 2022 um 08:48:39}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Prinzip der statistischen Testentscheidung - H\(_0\) und H\(_A\)}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/ttkGnexSXHw}{Prinzip der
statistischen Testentscheidung - \(H_0\) und \(H_A\)} als Video Reihe.
Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal
ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

Wir kÃ¶nnen auf allen Daten einen statistischen Test rechnen und erhalten
statistische MaÃzahlen wie eine Teststatistik, einen p-Wert oder ein
95\% Konfidenzintervall. Wie wir aus dem vorherigen Kapitel wissen
testet jeder statistische Test eine Nullhypothese. Ob diese Hypothese
dem Anwender nun bekannt ist oder nicht, ein statistischer Test testet
eine Nullhypothese. Daher mÃ¼ssen wir uns immer klar sein, was die
entsprechende Nullhypothese zu unserer Fragestellung ist.

In diesem Kapitel wollen wir uns nochmal tiefer mit der Testtherorie und
dem \(\alpha\)-Fehler und der \(\beta\)-Fehler beschÃ¤ftigen. Was heiÃt
eigentlich einseitig oder zweiseitig Testen? Auch mÃ¼ssen wir nochmal
einen Blick auf das mutliple Testen und die \(\alpha\)-Adjustierung
werfen.

Wir wieder holen nochmal. Die Nullhypothese \(H_0\) nennen wir auch die
Null oder Gleichheitshypothese. Die Nullhypothese sagt aus, dass zwei
Gruppen gleich sind oder aber kein Effekt zu beobachten ist.

\[
H_0: \bar{y}_{1} = \bar{y}_{2}
\]

Die Alternativehypothese \(H_A\) oder \(H_1\) auch Alternative genannt
nennen wir auch Unterschiedshypothese. Die Alternativehypothese besagt,
dass ein Unterschied vorliegt oder aber ein Effekt vorhanden ist.

\[
H_A: \bar{y}_{1} \neq \bar{y}_{2}
\]

{\marginnote{\begin{footnotesize}Das \textbf{Falisifkationsprinzip} -
wir kÃ¶nnen nur Ablehnen - kommt hier zusammen mit der
\textbf{frequentistischen Statistik} in der wir nur eine
Wahrscheinlichkeitsaussage Ã¼ber das Auftreten der Daten \(D\) - unter
der Annahme \(H_0\) gilt - treffen kÃ¶nnen.\end{footnotesize}}}

Es ist wichtig sich in Erinnerung zu rufen, dass wir nur und
ausschlieÃlich Aussagen Ã¼ber die Nullhypothese treffen kÃ¶nnen. Das
\emph{frequentistische} Hypothesentesten kann nichts anders. Wir kriegen
keine Aussage Ã¼ber die Alternativhypothese sondern nur eine AbschÃ¤tzung
der Wahrscheinlichkeit des Auftretens der Daten im durchgefÃ¼hrten
Experiment, wenn die Nullhypothese wahr wÃ¤re.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
AbhÃ¤ngig von der Lernstufe - daher welche
\protect\hyperlink{sec-vorlesungen-hs}{Veranstaltung} du gerade bei mir
besuchst - kommt nicht \emph{alles} aus diesem Kapitel dran in der
Klausur. Bitte gleiche die Inhalte, die ich in der aktuellen Vorlesung
unterrichte, mit dem Material hier ab. Als Faustregel gilt, je hÃ¶her die
Lernstufe desto mehr musst du von dem statistischen Testen Wissen und
Verstehen. Beachte auch die Probeklausur in deiner Veranstaltung und die
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub}.
\end{tcolorbox}

\hypertarget{sec-alpha-beta}{%
\section{\texorpdfstring{Der \(\alpha\)-Fehler und der
\(\beta\)-Fehler}{Der \textbackslash alpha-Fehler und der \textbackslash beta-Fehler}}\label{sec-alpha-beta}}

Vielleicht ist die Idee der Testtheorie und der Testentscheidung besser
mit der Analogie des Rauchmelders zu verstehen. Wir nehmen an, dass der
Rauchmelder der statistische Test ist. Der Rauchmelder hÃ¤ngt an der
Decke und soll entscheiden, ob es brennt oder nicht. Daher muss der
Rauchmelder entscheiden, die Nullhypothese ``kein Feuer'' abzulehnen
oder die Hypothese ``kein Feuer'' beizubehalten.

\[
\begin{align*} 
H_0&: \mbox{kein Feuer im Haus}  \\  
H_A&: \mbox{Feuer im Haus}  \\   
\end{align*}
\]

Wir kÃ¶nnen jetzt den Rauchmelder einstellen, so dass der Rauchmelder bei
einer Kerze losgeht oder erst bei einem Stubenbrand. Wie sensibel auf
Rauch wollen wir den Rauchmelder einstellen? Soll der Rauchmelder sofort
die Nullhypothese ablehnen? Wenn also nur eine Kerze brennt. Soll also
der \(\alpha\)-Fehler groÃ sein? Das wÃ¤re nicht sehr sinnvoll. Due
Feuerwehr wÃ¼rde schon bei einer Kerze kommen oder wenn wir mal was
anbrennen. Wir dÃ¼rfen also den \(\alpha\)-Fehler nicht zu groÃ
einstellen.

Intuitiv wÃ¼rde man meinen, ein sehr kleiner \(\alpha\)-Fehler nun
sinnvoll sei. Wenn wir aber den Rauchmelder sehr unsensibel einstellen,
also der Rauchmelder erst bei sehr viel Rauch die Nullhypothese ablehnt,
kÃ¶nnte das Haus schon unrettbar in Flammen stehen. Dieser Fehler, Haus
steht in Flammen und der Rauchmelder geht nicht, wird als
\(\beta\)-Fehler bezeichnet. Wie du siehst hÃ¤ngen die beiden Fehler
miteinander zusammen. Wichtig hierbei ist immmer, dass wir uns einen
Zustand vorstellen, das Haus brent nicht (\(H_0\) ist wahr) oder das
Haus brennt nicht (\(H_A\) ist wahr). An diesem Zustand entscheiden wir
dann, wie hoch der Fehler jeweils sein soll diesen Zustand zu Ã¼bersehen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Der \(\alpha\)-Fehler und \(\beta\)-Fehler als Rauchmelderanalogie}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]

HÃ¤ufig verwirrt die etwas theoretische Herangehensweise an den
\(\alpha\)-Fehler und \(\beta\)-Fehler. Wir versuchen hier nochmal die
Analogie eines Rauchmelders und dem Feuer im Haus.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/t-verteilung_05.png}

}

\caption{\label{fig-teststatistik-05}Andere Art der Darstellung des
\(\alpha\)-Fehlers als \emph{Alarm without fire} und dem
\(\beta\)-Fehler als \emph{Fire without alarm}. Je nachdem wie
empfindlich wir den Alarm des Rauchmelders (den statistischen Test) Ã¼ber
das \(\alpha\) einstellen, desto mehr Alarm bekommen wir ohne das ein
Effekt vorhanden wÃ¤re. Drehen wir den Alarm zu niedrig, dann kriegen wir
kein Feuer mehr angezeigt, den \(\beta\)-Fehler.}

\end{figure}

\begin{itemize}
\tightlist
\item
  \(\boldsymbol{\alpha}\)\textbf{-Fehler}: Alarm without fire. Der
  statistische Test schlÃ¤gt Alarm und wir sollen die \(H_0\) ablehnen,
  obwohl die \(H_0\) in Wahrheit gilt und kein Effekt vorhanden ist.
\item
  \(\boldsymbol{\beta}\)\textbf{-Fehler}: Fire without alarm. Der
  statistische Test schlÃ¤gt \emph{nicht} an und wir sollen die \(H_0\)
  beibehalten, obwohl die \(H_0\) in Wahrheit \emph{nicht} gilt und
  \emph{ein} Effekt vorhanden ist.
\end{itemize}

\end{tcolorbox}

Wie sieht nun die LÃ¶sung, erstmal fÃ¼r unseren Rauchmelder, aus? Wir
mÃ¼ssen Grenzen fÃ¼r den \(\alpha\) und \(\beta\)-Fehler festlegen.

{\marginnote{\begin{footnotesize}\textbf{Wir setzen den}
\(\alpha\)-Fehler auf 5\%.\end{footnotesize}}}

\begin{itemize}
\tightlist
\item
  Wir setzen den \(\alpha\)-Fehler auf 5\%. Somit haben wir in 1 von 20
  FÃ¤llen das Problem, dass uns der Rauchmelder angeht obwohl gar kein
  Feuer da ist. Wir lehnen die Nullhypothese ab, obwohl die
  Nullhypothese gilt.
\end{itemize}

{\marginnote{\begin{footnotesize}\textbf{Wir setzen den}
\(\beta\)-Fehler auf 20\%.\end{footnotesize}}}

\begin{itemize}
\tightlist
\item
  Auf der anderen Seite setzen wir den \(\beta\)-Fehler auf 20\%. Damit
  brennt uns die Bude in 1 von 5 FÃ¤llen ab ohne das der Rauchmelder
  einen Pieps von sich gibt. Wir behalten die Nullhypothese bei, obwohl
  die Nullhypothese nicht gilt.
\end{itemize}

Nachdem wir uns die Testentscheidung mit der Analogie des Rauchmelders
angesehen haben, wollen wir uns wieder der Statistik zuwenden.
Betrachten wir das Problem nochmal von der theoretischen Seite mit den
statistischen Fachbegriffen.

Soweit haben wir es als gegeben angesehen, dass wir eine
Testentscheidung durchfÃ¼hren. Entweder mit der Teststatistik, dem
\(p\)-Wert oder dem 95\% Konfidenzintervall. Immer wenn wir eine
Entscheidung treffen, kÃ¶nnen wir auch immer eine falsche Entscheidung
treffen. Wie wir wissen hÃ¤ngt die berechnete Teststatistik \(T_{calc}\)
nicht nur vom Effekt \(\Delta\) ab sondern auch von der Streuung \(s\)
und der Fallzahl \(n\). Auch kÃ¶nnen wir den falschen Test wÃ¤hlen oder
Fehler im Design des Experiments gemacht haben. Schlussendlich gibt es
viele Dinge, die unsere \emph{simple} mathematischen Formeln
beeinflussen kÃ¶nnen, die wir nicht kennen. Ein frequentistischer
Hypothesentest gibt immer nur eine Aussage Ã¼ber die Nullhypothese
wieder. Also ob wir die Nullhypothese ablehnen kÃ¶nnen oder nicht.

Abbildung~\ref{fig-teststatistik-03} zeigt die theoretische Verteilung
der Nullyhypothese und der Alternativehypothese. Wenn die beiden
Verteilungen sehr nahe beieinander sind, wird es schwer fÃ¼r den
statistischen Test die Hypothesen klar voneinander zu trennen. Die
Verteilungen Ã¼berlappen. Es gibt einen sehr kleinen Unterschied in den
Sprungweiten zwischen Hunde- und KatzenflÃ¶hen.

\begin{figure*}

{\centering \includegraphics{./images/t-verteilung_03.png}

}

\caption{\label{fig-teststatistik-03}Darstellung der Null- und
Alternativehypothese. Mit steigendem \(T_{calc}\) wird die
Wahrscheinlichkeit fÃ¼r die \(H_0\) immer kleiner. Leider ist uns nichts
Ã¼ber \(H_A\) und deren Lage bekannt. Sollte die \(H_A\) Verteilung zu
weit nach links ragen, kÃ¶nnten wir die \(H_0\) beibehalten, obwohl die
\(H_A\) gilt.}

\end{figure*}

{\marginnote{\begin{footnotesize}\textbf{Achtung} In der Regression wird
uns auch wieder das \(\beta\) als Symbol begegnen. In der
\emph{statistischen Testtheorie} ist das \(\beta\) ein Fehler; in der
Regression ist das \(\beta\) ein Koeffizient der Regression. Hier ist
der Kontext wichtig.\end{footnotesize}}}

Wir kÃ¶nnen daher bei statistischen Testen zwei Arten von Fehlern machen.
Zum einen den \(\alpha\) Fehler oder auch Type I Fehler genannt. Zum
anderen den \(\beta\) Fehler oder auch Type II Fehler genannt. Die
Grundidee basiert darauf, dass wir eine Testentscheidung gegen die
Nullhypothese machen. Diese Entscheidung kann richtig sein, da in
Wirklichkeit die Nullhypothese gilt oder aber falsch sein, da in
Wirklichkeit die Nullhypothese nicht gilt. In
Abbildung~\ref{fig-teststatistik-04} wird der Zusammenhang in einer 2x2
Tafel veranschaulicht.

\begin{figure*}

{\centering \includegraphics{./images/t-verteilung_04.png}

}

\caption{\label{fig-teststatistik-04}Zusammenhang zwischen der
Testentscheidung gegen die \(H_0\) Hypothese sowie dem Beibehalten der
\(H_0\) Hypothese und der unbekannten Wahrheit in der die \(H_0\) falsch
sein kann oder die \(H_0\) wahr sein kann. Wir kÃ¶nnen mit unserer
Testenstscheidung richtig liegen oder falsch. Mit welcher
Wahrscheinlichkeit geben der \(\alpha\) Fehler und \(\beta\) Fehler
wieder. Unten rechts ist der Zusammenhang zu der
Abbildung~\ref{fig-teststatistik-03} gezeigt.}

\end{figure*}

\marginnote{\begin{footnotesize}

Die Diskussion Ã¼ber den \(p\)-Wert und dem Vergleich mit dem
\(\alpha\)-Fehler wird in der Statistik seit 2019 verstÃ¤rkt diskutiert
(Wasserstein, Schirm, und Lazar 2019). Das Nullritual wird schon lamge
kritisiert (Gigerenzer, Krauss, und Vitouch 2004). Siehe dazu auch
\href{https://www.tandfonline.com/toc/utas20/73/sup1}{The American
Statistician, Volume 73, Issue sup1 (2019)}.

\end{footnotesize}}

Beide Fehler sind Kulturkonstanten. Das heiÃt, dass sich diese Zahlen
von 5\% und 20\% so ergeben haben. Es gibt keinen rationalen Grund diese
Zahlen so zu nehmen. Man kann eigentlich sagen, dass die 5\% und die
20\% eher einem Zufall entsprungen sind, als einer tieferen Rationalen.
Wir behalten diese beiden Zahlen bei aus den beiden schlechtesten GrÃ¼nde
Ã¼berhaupt: i) es wurde schon immer so gemacht und ii) viele machen es
so.

Eine weitere wichtige statistische MaÃzahl im Kontext der Testtheorie
ist die \(Power\) oder auch \(1-\beta\). Die \(Power\) ist die
Gegenwahrscheinlichkeit von dem \(\beta\)-Fehler. In der Analogie des
Rauchmelders wÃ¤re die \(Power\) daher \emph{Alarm with fire}. Das heiÃt,
wie wahrscheinlich ist es einen wahren Effekt - also einen Unterschied -
mit dem statistischen Test auch zu finden. Oder anders herum, wenn wir
wÃ¼ssten, dass die Hunde- und KatzenflÃ¶he unterschiedliche weit springen,
mit welcher Wahrscheinlichkeit wÃ¼rde diesen Unterschied ein
statistsicher Test auch finden? Mit eben der \(Power\), also gut 80\%.
Tabelle~\ref{tbl-power} zeigt die AbhÃ¤ngigkeit der \(Power\) vom Effekt
\(\Delta\), der Streuung \(s\) und der Fallzahl \(n\).

{\marginnote{\begin{footnotesize}Die \(Power\) ist eine
Wahrscheinlichkeit und sagt \emph{nichts} Ã¼ber die Relevanz des Effektes
aus.\end{footnotesize}}}

\hypertarget{tbl-power}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1827}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3077}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2019}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3077}}@{}}
\caption{\label{tbl-power}AbhÃ¤ngigkeit der \(Power (1-\beta)\) vom
Effekt \(\Delta\), der Fallzahl \(n\) und der Streuung \(s\). Die
\(Power\) ist eine Wahrscheinlichkeit und sagt nichts Ã¼ber die Relevanz
des Effektes aus.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Power (1-\beta)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Power (1-\beta)}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Power (1-\beta)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{Power (1-\beta)}\)
\end{minipage} \\
\midrule()
\endhead
\(\Delta \uparrow\) & steigt & \(\Delta \downarrow\) & sinkt \\
\(s \uparrow\) & sinkt & \(s \downarrow\) & steigt \\
\(n \uparrow\) & steigt & \(n \downarrow\) & sinkt \\
\bottomrule()
\end{longtable}

\hypertarget{sec-einseitig-zweiseitig}{%
\section{Einseitig oder zweiseitig?}\label{sec-einseitig-zweiseitig}}

Manchmal kommt die Frage auf, ob wir \emph{einseitig} oder
\emph{zweiseitig} einen statistischen Test durchfÃ¼hren wollen. Beim Fall
des zweiseitigen Testens verteilen wir den \(\alpha\)-Fehler auf beide
Seiten der Testverteilung mit jeweils \(\cfrac{\alpha}{2}\). In dem Fall
des einseitigen Tests liegt der gesamte \(\alpha\)-Fehler auf der
rechten \emph{oder} linken Seite der Testverteilung. In
Abbildung~\ref{fig-teststatistik-02} wird der Zusammenhang beispielhaft
an der t-Verteilung gezeigt.

\begin{figure*}

{\centering \includegraphics{./images/t-verteilung_02.png}

}

\caption{\label{fig-teststatistik-02}Zusammenhang zwischen dem
einseitigen und zweiseitigen Testen. Im Falle des zweiseitigen Testens
teilen wir den \(\alpha\)-Fehler auf beide Seiten der beispielhaften
t-Verteilung auf. Im Falle des einseitigen Testen leigt der gesamte
\(\alpha\)-Fehler auf der rechten \emph{oder} der linken Seite der
t-Verteilung.}

\end{figure*}

{\marginnote{\begin{footnotesize}In der Anwendung testen wir immer
zweiseitig.\end{footnotesize}}}

In der Anwendung testen wir immer zweiseitig. Der Grund ist, dass das
Vorzeichen von der Teststatik davon abhÃ¤ngt, welche der beiden Gruppen
den grÃ¶Ãeren Mittelwert hat. Da wir die Mittelwerte vor der Auswertung
nicht kennen, kÃ¶nnen wir auch nicht sagen in welche Richtung der Effekt
und damit die Teststatistik laufen wird.

Es gibt theoretisch GrÃ¼nde, die fÃ¼r ein einseitiges Testen unter
bestimmten Bedingungen sprechen, aber wir nutzen in der Anwendung nur
das zweiseite Testen. Wir mÃ¼ssen dazu in R auch nichts weiter angeben.
Ein durchgefÃ¼hrter statistischer Test in R testet automatisch immer
zweiseitig.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Einseitig oder zweiseitig im Spiegel der RegulierungsbehÃ¶rden}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
In den
\href{https://www.iqwig.de/ueber-uns/methoden/methodenpapier/}{allgemeinen
Methoden des IQWiG}, einer RegulierungsbehÃ¶rde fÃ¼r klinische Studien,
wird grundsÃ¤tzlich das zweiseitige Testen empfohlen. Wenn einseitig
getestet werden sollte, so soll das \(\alpha\)-Niveau halbiert werden.
Was wiederum das gleiche wÃ¤re wie zweiseitiges Testen - nur mit mehr
Arbeit.

\emph{Zur besseren Vergleichbarkeit mit 2-seitigen statistischen
Verfahren wird in einigen Guidelines fÃ¼r klinische Studien eine
Halbierung des Ã¼blichen Signifikanzniveaus von 5 \% auf 2,5 \%
gefordert.} --
\href{https://www.iqwig.de/methoden/allgemeine-methoden-v6-1.pdf}{Allgemeine
Methoden Version 6.1 vom 24.01.2022, p.~180}
\end{tcolorbox}

\hypertarget{sec-statistisches-testen-alpha-adjust}{%
\section{Adjustierung fÃ¼r multiple
Vergleiche}\label{sec-statistisches-testen-alpha-adjust}}

{\marginnote{\begin{footnotesize}Das simultane Testen von mehreren
Hypothesen fÃ¼hrt zu einer \(\alpha\)-Fehler
Inflation\end{footnotesize}}}

Im Kapitel~\ref{sec-posthoc} werden wir mehrere multiple
Gruppenvergleiche durchfÃ¼hren. Das heiÃt, wir wollen nicht nur die
Sprungweite von Hunde- und KatzenflÃ¶hen miteinander vergleichen, sondern
auch die Sprungweite von Hunde- und FuchsflÃ¶hen sowie Katzen- und
FuchsflÃ¶hen. Wir wÃ¼rden also \(k = 3\) t-Tests fÃ¼r die
Mittelwertsvergleiche rechnen.

Dieses mehrfache Testen fÃ¼hrt aber zu einer Inflation des
\(\alpha\)-Fehlers oder auch Alphafehler-Kumulierung genannt. Daher ist
die Wahrscheinlichkeit, dass mindestens eine Nullhypothese
fÃ¤lschlicherweise abgelehnt wird, nicht mehr durch das Signifikanzniveau
\(\alpha\) kontrolliert, sondern kann sehr groÃ werden.

Gehen wir von einer Situation mit \(k\) Null- und Alternativhypothesen
aus. Wir rechnen also \(k\) statistische Tests und alle Nullhypothesen
werden zum lokalen Niveau \(\alpha_{local} = 0.05\) getestet. Im
Weiteren nehmen wir an, dass tatsÃ¤chlich alle Nullhypothesen gÃ¼ltig
sind. Wir rechnen also \(k\) mal einen t-Test und machen jedes mal einen
\emph{5\% Fehler Alarm zu geben, obwohl kein Effekt vorhanden ist}.

Die Wahrscheinlichkeit fÃ¼r einen einzelnen Test korrekterweise \(H_0\)
abzulehnen ist \((1 â \alpha)\). Da die \(k\) Tests unabhÃ¤ngig sind, ist
die Wahrscheinlichkeit alle \(k\) Tests korrekterweise abzulehnen
\((1 â \alpha)^k\). Somit ist die Wahrscheinlichkeit, dass mindestens
eine Nullhypothese fÃ¤lschlicherweise abgelehnt wird \(1-(1-\alpha)^k\).
In der Tabelle~\ref{tbl-mult-alpha} wird dieser Zusammenhang nochmal mit
Zahlen fÃ¼r verschiedene \(k\) deutlich.

\hypertarget{tbl-mult-alpha}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-mult-alpha}Inflation des \(\alpha\)-Fehlers. Wenn 50
Hypothesen getestet werden, ist die Wahrscheinlichkeit \emph{mindestens}
eine falsche Testentscheidung zu treffen fast sicher.}\tabularnewline
\toprule()
Anzahl Test \(\boldsymbol{k}\) & \(\boldsymbol{1-(1-\alpha)^k}\) \\
\midrule()
\endfirsthead
\toprule()
Anzahl Test \(\boldsymbol{k}\) & \(\boldsymbol{1-(1-\alpha)^k}\) \\
\midrule()
\endhead
1 & 0.05 \\
2 & 0.10 \\
10 & 0.40 \\
50 & 0.92 \\
\bottomrule()
\end{longtable}

Aus Tabelle~\ref{tbl-mult-null} kÃ¶nnen wir entnehmen, dass wenn 100
Hypothesen getestet werden, werden 5 Hypothesen im Schnitt
fÃ¤lschlicherweise abgelehnt. Die Tabelle~\ref{tbl-mult-null} ist nochmal
die Umkehrung der vorherigen Tabelle~\ref{tbl-mult-alpha}.

\hypertarget{tbl-mult-null}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-mult-null}Inflation des \(\alpha\)-Fehlers.
Erwartete Anzahl fÃ¤lschlich abgelehnter Nullhypothesen abhÃ¤ngig von der
Anzahl der durchgefÃ¼hrten Tests}\tabularnewline
\toprule()
Anzahl Test \(\boldsymbol{k}\) & \(\boldsymbol{\alpha \cdot k}\) \\
\midrule()
\endfirsthead
\toprule()
Anzahl Test \(\boldsymbol{k}\) & \(\boldsymbol{\alpha \cdot k}\) \\
\midrule()
\endhead
1 & 0.05 \\
20 & 1 \\
100 & 5 \\
200 & 10 \\
\bottomrule()
\end{longtable}

Nachdem wir verstanden haben, dass wiederholtes statistisches Testen
irgendwann immer ein signifikantes Ergebnis produziert, mÃ¼ssen wir fÃ¼r
diese \(\alpha\) Inflation unsere Ergebnisse adjustieren. Ich folgenden
stelle ich verschiedene Adjustierungsverfahren vor.

Wie kÃ¶nnen wir nun die p-Werte in R adjustieren? Zum einen passiert dies
teilweise automatisch zum anderen mÃ¼ssen wir aber wissen, wo wir
Informationen zu den Adjustierungsmethoden finden. Die Funktion
\texttt{p.adjust()} ist hier die zentrale Anlaufstelle. Hier finden sich
alle implementierten Adjustierungsmethoden in R.

Im folgenden Code erschaffen wir uns 50 \(z\)-Werte von denen 25 aus
einer Normalverteilung \(\mathcal{N}(0, 1)\) und 25 aus einer
Normalverteilung mit \(\mathcal{N}(3, 1)\) kommen. Die FlÃ¤che unter
allen Normalverteilungen ist Eins, da die Standatdabweichung Eins ist.
Wir berechnen die \(p-Wert\) anhand der FlÃ¤che rechts von dem
\(z\)-Wert. Wir testen zweiseitig, deshalb multiplizieren wir die
\(p\)-Werte mit Zwei. Diese \(p\)-Werte kÃ¶nnen wir nun im Folgenden fÃ¼r
die Adjustierung nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{, }\AttributeTok{mean =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{25}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{25}\NormalTok{)))}
\NormalTok{p }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\FunctionTok{pnorm}\NormalTok{(}\FunctionTok{sort}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{abs}\NormalTok{(z)))}
\end{Highlighting}
\end{Shaded}

Ãber die eckigen Klammern \texttt{{[}{]}} und das \texttt{:} kÃ¶nnen wir
uns die ersten zehn p-Werte wiedergeben lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.00000 0.00001 0.00007 0.00009 0.00027 0.00050 0.00124 0.00251 0.00324
[10] 0.00442
\end{verbatim}

Wir sehen, dass die ersten fÃ¼nf p-Werte hoch signifikant sind. Das
wÃ¼rden wir auch erwarten, immerhin haben wir ja auch 25 \(z\)-Werte mit
einem Mittelwert von Drei. Du kannst dir den \(z\)-Wert wie den
\(t\)-Wert der Teststatistik vorstellen.

\hypertarget{bonferroni-korrektur}{%
\subsection{Bonferroni Korrektur}\label{bonferroni-korrektur}}

Die Bonferroni Korrektur ist die am weitesten verbreitete Methode zur
\(\alpha\) Adjustierung, da die Bonferroni Korrektur einfach
durchzufÃ¼hren ist. Damit die Wahrscheinlichkeit, dass mindestens eine
Nullhypothese fÃ¤lschlicherweise abgelehnt wird beim simultanen Testen
von \(k\) Hypothesen durch das globale (und multiple) Signifikanzniveau
\(\alpha = 5\%\) kontrolliert ist, werden die Einzelhypothesen zum
lokalen Signifikanzniveau \(\alpha_{local} = \tfrac{\alpha_{5\%}}{k}\)
getestet.

Dabei ist das Problem der Bonferroni Korrektur, dass die Korrektur sehr
konservativ ist. Wir meinen damit, dass das tatsÃ¤chliche globale (und
multiple) \(\sum\alpha_{local}\) Niveau liegt deutlich unter
\(\alpha_{5\%}\) und somit werden die Nullhypothesen zu oft beibehalten.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Adjustierung des \(\boldsymbol{\alpha}\)-Fehlers}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]

\begin{itemize}
\tightlist
\item
  Das globale \(\alpha\)-Level wird durch die Anzahl \(k\) an
  durchgefÃ¼hrten statistischen Tests geteilt.
\item
  \(\alpha_{local} = \tfrac{\alpha}{k}\) fÃ¼r die Entscheidung
  \(p < \alpha_{local}\)
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Adjustierung des \(\boldsymbol{p}\)-Wertes}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]

\begin{itemize}
\tightlist
\item
  Die p-Werte werden mit der Anzahl an durchgefÃ¼hrten statistischen
  Tests \(k\) multipliziert.
\item
  \(p_{adjust} = p_{raw} \cdot k\) mit \(k\) gleich Anzahl der
  Vergleiche.
\item
  wenn \(p_{adjust} > 1\), wird \(p_{adjust}\) gleich 1 gesetzt, da
  \(p_{adjust}\) eine Wahrscheinlichkeitist.
\end{itemize}

\end{tcolorbox}

Wir schauen uns die ersten zehn nach Bonferroni adjustierten p-Wert nach
der Anwendung der Funktion \texttt{p.adjust()} einmal an.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{p.adjust}\NormalTok{(p, }\StringTok{"bonferroni"}\NormalTok{)[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.000 0.000 0.004 0.005 0.014 0.025 0.062 0.126 0.162 0.221
\end{verbatim}

Nach der Adjustierung erhalten wir weniger signifikante \(p\)-Werte als
vor der Adjustierung. Wir sehen aber, dass wir \emph{weit} weniger
signifikante Ergebnisse haben, als wir eventuell erwarten wÃ¼rden. Wir
haben immerhin 25 \(z\)-Werte mit einem Mittelwert von Drei. Nach der
Bonferroni-Adjustierung hgaben wir nur noch sechs signifikante
\(p\)-Werte.

\hypertarget{benjamini-hochberg}{%
\subsection{Benjamini-Hochberg}\label{benjamini-hochberg}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

http://www.biostathandbook.com/multiplecomparisons.html

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{p.adjust}\NormalTok{(p, }\StringTok{"BH"}\NormalTok{)[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.000 0.000 0.001 0.001 0.003 0.004 0.009 0.016 0.018 0.022
\end{verbatim}

\hypertarget{referenzen-4}{%
\section*{Referenzen}\label{referenzen-4}}
\addcontentsline{toc}{section}{Referenzen}

\hypertarget{sec-effect}{%
\chapter{Der EffektschÃ¤tzer}\label{sec-effect}}

\emph{Version vom September 14, 2022 um 08:48:55}

\marginnote{\begin{footnotesize}

Eine wunderbare Ãbersicht Ã¼ber den Begriff \emph{EffektschÃ¤tzer} liefert
das englische Buch
\href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html}{Doing
Meta-Analysis with R: A Hands-On Guide}.

\end{footnotesize}}

Der EffektschÃ¤tzer. Ein seltsames Kapitel, denn ich tue mich sehr
schwer, dieses Kapitel irgendwo in die LinearitÃ¤t dieses Buches hier
einzuordnen. Deshalb ist dieses Kapitel eigentlich immer an der falschen
Stelle. Entweder hast du schon die statistischen Tests gelesen und du
wÃ¼sstest gerne was die EffektschÃ¤tzer sind \emph{oder} du suchst hier
nochmal die Beschreibung der EffektschÃ¤tzer zum Beispiel aus der
multiple Regression heraus. Also steht jetzt dieses Kapitel hier im Raum
und du musst schauen, was du wirklich brauchst. Oder ob du dieses
Kapitel erst Ã¼berspringst und dann spÃ¤ter nochmal hier liest.

{\marginnote{\begin{footnotesize}Der EffektschÃ¤tzer wird auch gerne
Theta \(\boldsymbol{\theta}\) genannt. Da wir dann aber spÃ¤ter noch mit
anderen Konzepten in die Quere kommen, nutze ich das etwas intuitivere
Delta \(\boldsymbol{\Delta}\).\end{footnotesize}}}

Wenn wir einen der vielen EffektschÃ¤tzer berechnen wollen, dann nutzen
wir dafÃ¼r die EffektschÃ¤tzer aus dem
\href{https://easystats.github.io/effectsize/index.html}{R Paket
effectsize}. Das R Paket \texttt{effectsize} liefert EffektschÃ¤tzer fÃ¼r
fast alle statistischen Gelegenheiten. Wir werden hier wie immer nur den
groben Ãberblick abdecken. Vermutlich wird das Kapitel dann noch
Anwachsen. Streng genommen gehÃ¶rt das Kapitel~\ref{sec-test-diag} zu den
diagnostischen Tests auf einer 2x2 Kreuztabelle auch irgendwie zu
EffektschÃ¤tzern. Wenn du SpezifitÃ¤t und SensitivitÃ¤t suchst bist du in
dem Kapitel zu diagnostischen Tests richtig.

Wir unterscheiden hier erstmal grob in zwei Arten von EffektschÃ¤tzern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  EffektschÃ¤tzer, die einen \textbf{Mittelwertsunterschied} beschreiben.
\item
  EffektschÃ¤tzer, die einen \textbf{Anteilsunterschied} beschreiben.
\end{enumerate}

Daneben gibt es wie noch die Korrelation wie in
Kapitel~\ref{sec-lin-reg-corr} beschrieben. Die Korrelation wollen wir
aber in diesem Kapitel nicht vorgreifen bzw. wiederholen.

Am Ende muss du immer den Effekt im Kontext der Fragestellung bzw. des
Outcomes \(y\) bewerten. Der numerische Unterschied von \(0.1\) cm kann
in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein
Unterschied von \(0.1\) cm viel sein. Oder aber sehr wenig, wenn wir uns
das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den
Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage,
ob ein Unterschied von 6\% viel oder wenig ist.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EffektschÃ¤tzer}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Wenn wir uns einen Unterschied eines \textbf{Mittelwerts} anschauen,
dann haben wir \emph{keinen} Effekt vorliegen, wenn der
Mittlwertsunterschied \(\Delta\) zwischen der Gruppe \(A\) und der
Gruppe \(B\) gleich 0 ist. Die Nullhypothese gilt. Beide Gruppen \(A\)
und \(B\) haben den gleichen Mittelwert.

\[
\Delta_{A-B} = A - B = 0
\]

Wenn wir uns einen Unterschied eines \textbf{Anteils} anschauen, dann
haben wir \emph{keinen} Effekt vorliegen, wenn der Anteilsunterschied
\(\Delta\) zwischen der Gruppe \(A\) und der Gruppe \(B\) gleich 1 ist.
Die Nullhypothese gilt. Beide Gruppen \(A\) und \(B\) haben den gleichen
Anteil.

\[
\Delta_{A/B} = \cfrac{A}{B} = 1
\]

Dieses Wissen brauchen wir um die Signifikanzschwelle bei einem 95\%
Konfidenzintervall richtig zu setzen und interpretieren zu kÃ¶nnen. Siehe
dazu auch nochmal das Kapitel~\ref{sec-ki}.
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-5}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-5}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, see, effectsize)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{unterschied-zweier-mittelwerte}{%
\section{Unterschied zweier
Mittelwerte}\label{unterschied-zweier-mittelwerte}}

Wir berechnen zwei Mittelwerte \(\bar{y}_1\) und \(\bar{y}_2\). Wenn wir
wissen wollen wie groÃ der Effekt zwischen den beiden Mittelwerten ist,
dann bilden wir die Differenz. Wir berechnen das \(\Delta_{y_1-y_2}\)
fÃ¼r \(y_1\) und \(y_2\) indem wir die beiden Mittelwerte voneinander
abziehen.

\[
\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2
\]

{\marginnote{\begin{footnotesize}Warum schreiben wir hier vermutlich?
Ein statistischer Test ist eine Funktion von \(\Delta\), \(s\) und
\(n\). Wir kÃ¶nnen auch mit kleinem \(\Delta\) die Nullhypothese
ablehnen, wenn \(s\) und \(n\) eine passende Teststatistik generieren.
Siehe dazu auch das Kapitel~\ref{sec-delta-n-s}.\end{footnotesize}}}

Wenn es keinen Unterschied zwischen den beiden Mittelwerten
\(\bar{y}_1\) und \(\bar{y}_2\) gibt, dann ist die Differenz
\(\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2\) gleich 0. Wir sagen, die
Nullhypothese \emph{vermutlich} gilt, wenn die Differenz klein ist. Was
wir besser annehmen kÃ¶nnen ist, dass die Relevanz klein ist. Effekt mit
einem geringen Mittelwertsunterschied sind meistens nicht relevant. Aber
diese EinschÃ¤tzung hÃ¤ngt stark von der Fragestellung ab.

\[
H_0: \Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2 = 0
\]

In Tabelle~\ref{tbl-dog-cat-small-delta} ist nochmal ein sehr simples
Datenbeispiel gegeben an dem wir den Zusammenhang nochmal nachvollziehen
wollen.

\hypertarget{tbl-dog-cat-small-delta}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-dog-cat-small-delta}Beispiel fÃ¼r die Berechnung von
einem Mittelwertseffekt an der SprunglÃ¤nge {[}cm{]} von Hunde und
KatzenflÃ¶hen.}\tabularnewline
\toprule()
animal & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length \\
\midrule()
\endhead
cat & 8.0 \\
cat & 7.9 \\
cat & 8.3 \\
cat & 9.1 \\
dog & 8.0 \\
dog & 7.8 \\
dog & 9.2 \\
dog & 7.7 \\
\bottomrule()
\end{longtable}

Nehmen wir an, wir berechnen fÃ¼r die Sprungweite {[}cm{]} der HundeflÃ¶he
einen Mittelwert von \(\bar{y}_{dog} = 8.2\) und fÃ¼r die Sprungweite
{[}cm{]} der KatzenflÃ¶he einen Mittelwert von \(\bar{y}_{cat} =8.3\).
Wie groÃe ist nun der Effekt? Oder anders gesprochen, welchen
Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu
sein? Was ist also der Effekt von \texttt{animal}? Wir rechnen
\(\bar{y}_{dog} - \bar{y}_{cat} = 8.2 - 8.3 = -0.1\). Zum einen wissen
wir jetzt ``die Richtung''. Da wir ein Minus vor dem
Mittelwertsunterschied haben, mÃ¼ssen die KatzenflÃ¶he weiter springen als
die HundeflÃ¶he, nÃ¤mlich 0.1 cm. Dennoch ist der Effekt sehr klein.

\hypertarget{cohens-d}{%
\subsection{Cohen's d}\label{cohens-d}}

Da der Mittlwertsunterschied \emph{alleine} nnur eine eingeschrÃ¤nkte
Aussage Ã¼ber den Effekt erlaubt, gibt es noch EffektschÃ¤tzer, die den
Mittelwertsunterschied \(\Delta_{y_1-y_2}\) mit der Streuung \(s^2\)
sowie der Fallzahl zusammenbringt. Der bekannteste EffektschÃ¤tzer fÃ¼r
einen Mittelwertsunterschied bei groÃer Fallzahl mit mehr als 20
Beobachtungen ist Cohen's d.~Wir kÃ¶nnen Cohen's d wie folgt berechnen.

\[
|d| = \cfrac{\bar{y}_1-\bar{y}_2}{\sqrt{\cfrac{s_1^2+s_2^2}{2}}}
\]

Wenn wir die berechneten Mittelwerte und die Varianz der beiden Gruppen
in die Formel einsetzten ergibt sich ein absolutes Cohen's d von 0.24
fÃ¼r den Gruppenvergleich.

\[
|d| = \cfrac{8.2 - 8.3}{\sqrt{(0.5^2+0.3^2) /2}} = \cfrac{-0.1}{0.41} = \lvert-0.24\rvert
\]

\marginnote{\begin{footnotesize}

Mehr Informationen zu Cohen's d gibt es auf der Hilfeseite von
\texttt{effectsize}:
\href{https://easystats.github.io/effectsize/reference/interpret_cohens_d.html}{Interpret
standardized differences}

\end{footnotesize}}

Was denn nun Cohen's d \emph{exakt} aussagt, kann niemand sagen. Aber
wir haben einen Wust an mÃ¶glichen Grenzen. Hier soll die Grenzen von
Cohen (1988) einmal angegeben werden. Cohen (1988) hat in seiner Arbeit
folgende Grenzen in Tabelle~\ref{tbl-cohen-d} fÃ¼r die Interpretation von
\(d\) vorgeschlagen.

\hypertarget{tbl-cohen-d}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-cohen-d}Interpretation der EffektstÃ¤rke nach Cohen
(1988).}\tabularnewline
\toprule()
Cohen's d & Interpretation des Effekts \\
\midrule()
\endfirsthead
\toprule()
Cohen's d & Interpretation des Effekts \\
\midrule()
\endhead
\(d < 0.2\) & Sehr klein \\
\(0.2 \leq d < 0.5\) & Klein \\
\(0.5 \leq d < 0.8\) & Mittel \\
\(d \geq 0.8\) & Stark \\
\bottomrule()
\end{longtable}

Wir kÃ¶nnen auch Ã¼ber die Funktion \texttt{cohens\_d()} Cohen's d einfach
in R berechnen. Die Funktion \texttt{cohens\_d()} akzeptiert die
Formelschreibweise. Die 95\% Konfidenzintervalle sind mit Vorsicht zu
interpretieren. Denn die Nullhypothese ist hier nicht so klar
formuliert. Wir lassen also die 95\% Konfidenzintervalle erstmal hier so
stehen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cohens\_d}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{pooled\_sd =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cohen's d |        95% CI
-------------------------
0.24      | [-1.16, 1.62]

- Estimated using pooled SD.
\end{verbatim}

Dankenswerterweise gibt es noch die Funktion
\texttt{interpret\_cohens\_d}, die es uns erlaubt auszusuchen nach
welche Literturquelle wir den Wert von Cohen's d interpretieren wollen.
Ob dieser Effekt relevant zur Fragestellung ist musst du selber
entscheiden.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{interpret\_cohens\_d}\NormalTok{(}\FloatTok{0.24}\NormalTok{, }\AttributeTok{rules =} \StringTok{"cohen1988"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "small"
(Rules: cohen1988)
\end{verbatim}

\hypertarget{hedges-g}{%
\subsection{Hedges' g}\label{hedges-g}}

Soweit haben wir uns mit sehr groÃen Fallzahlen beschÃ¤ftigt. Cohen's d
ist dafÃ¼r auch sehr gut geeigent und wenn wir mehr als 20 Beobachtungen
haben, kÃ¶nnen wir Cohen's d auch gut anwenden. Wenn wir weniger Fallzahl
vorliegen haben, dann kÃ¶nnen wir Hedges' g nutzen. Hedges' g bietet eine
Verzerrungskorrektur fÃ¼r kleine StichprobengrÃ¶Ãen (\(N < 20\)) sowie die
MÃ¶glichkeit auch fÃ¼r \emph{unbalanzierte} GruppengrÃ¶Ãen einen
EffektschÃ¤tzeer zu berechnen. Die Formel sieht mit dem Korrekturterm
recht mÃ¤chtig aus.

\[
g = \cfrac{\bar{y}_1 - \bar{y}_2}{s^*} \cdot \left(\cfrac{N-3}{N-2.25}\right) \cdot \sqrt{\cfrac{N-2}{N}}
\]

mit

\[
s^* = \sqrt{\cfrac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}
\]

Wir kÃ¶nnen aber einfach die Mittelwerte und die Varianzen aus unserem
beispiel einsetzen. Da unsere beiden Gruppen gleich groÃ sind
\(n_1 = n_2\) und damit ein balanziertes Design vorliegt, sind Cohen's d
und Hedges' g numerisch gleich. Wir kÃ¶nnen dann noch fÃ¼r die geringe
Fallzahl korrigieren und erhalten ein hÃ¤ndisches \(g = 0.18\).

\[
g = \cfrac{8.2 - 8.3}{0.41} \cdot \left(\cfrac{8-3}{8-2.25}\right) \cdot \sqrt{\cfrac{8-2}{8}} = \lvert-0.24\rvert \cdot 0.87 \cdot 0.87 \approx 0.18
\]

mit

\[
s^* = \sqrt{\cfrac{(4-1)\cdot0.5^2 + (4-1)\cdot0.3^2}{4+4-2}} = \sqrt{\cfrac{0.75 + 0.27}{6}} = 0.41
\]

In R gibt es die Funktion \texttt{hedges\_g()} die uns erlaubt in der
Formelschreibweise direkt Hedges' g zu berechnen. Wir sehen hier eine
Abweichung von unserer hÃ¤ndischen Rechnung. Das ist aber in soweit nicht
ungewÃ¶hnlich, da es noch eine Menge Varianten der Anpassung fÃ¼r die
geringe Fallzahl gibt. In der Anwendung nutzen wir die Funktion aus dem
Paket \texttt{effectsize} wie hier durchgefÃ¼hrt.

Wir ignorieren wie auch bei Cohen's d das 95\% Konfidenzintervall, da
die Interpretation ohne die Nullhypothese nicht mÃ¶glich ist. Die
Nullhypothese ist in diesem Fall komplexer. Wir lassen daher das 95\%
Konfidenzintervall erstmal einfach hier so stehen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hedges\_g}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{pooled\_sd =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Hedges' g |        95% CI
-------------------------
0.21      | [-1.01, 1.41]

- Estimated using pooled SD.
\end{verbatim}

Auch fÃ¼r Hedges' g gibt es die MÃ¶glichkeit sich Ã¼ber die Funktion
\texttt{interpret\_hedges\_g()} den Wert von \(g=0.21\) interpretieren
zu lassen. Nach Sawilowsky (2009) haben wir hier einen kleinen Effekt
vorliegen. Ob dieser Effekt relevant zur Fragestellung ist musst du
selber entscheiden.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{interpret\_hedges\_g}\NormalTok{(}\FloatTok{0.21}\NormalTok{, }\AttributeTok{rules =} \StringTok{"sawilowsky2009"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "small"
(Rules: sawilowsky2009)
\end{verbatim}

\href{https://easystats.github.io/effectsize/reference/interpret_cohens_d.html}{Die
Hilfeseite zu dem Paket \texttt{effectsize}} bietet eine Liste an
mÃ¶glichen Referenzen fÃ¼r die Wahl der Interpretation der EffektstÃ¤rke.
Du musst dann im Zweifel schauen, welche der Quellen und damit Grenzen
du nutzen willst.

\hypertarget{unterschied-zweier-anteile}{%
\section{Unterschied zweier Anteile}\label{unterschied-zweier-anteile}}

{\marginnote{\begin{footnotesize}Eine Wahrscheinlichkeit und eine Chance
sind nicht das Gleiche. Mehr in diesem Abschnitt.\end{footnotesize}}}

Neben den Unterschied zweier Mittelwerte ist auch hÃ¤ufig das Interesse
an dem Unterschied zwischen zwei Anteilen. Nun unterscheiden wir
zwischen Wahrscheinlichkeiten und Chancen. Beide MaÃzahlen, die
Wahrscheinlichkeit wie auch die Chance, beschreiben einen Anteil. Hier
tritt hÃ¤ufig Verwirrung auf, daher hier zuerst ein Beispiel.

Wir behandelt \(n = 65\) Hunde mit dem Antiflohmittel \emph{FleaEx}. Um
die Wirkung von \emph{FleaEx} auch bestimmen zu kÃ¶nnen haben wir uns
zwei Gruppen von Hunden ausgesucht. Wir haben Hunde, die mit FlÃ¶he
infiziert sind und Hunde, die nicht mit FlÃ¶hen infiziert sind. Wir
schauen nun in wie weit \emph{FleaEx} gegen FlÃ¶he hilft im Vergleich zu
einer Kontrolle.

\hypertarget{tbl-2x2-ratio-delta}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-2x2-ratio-delta}Eine 2x2 Tabelle als Beispiel fÃ¼r
unterschiedliche Flohinfektionen bei nach einer Behandlung mit
\emph{FleaEx} fÃ¼r die Berechnung von EffektschÃ¤tzern eines
Anteils.}\tabularnewline
\toprule()
\endhead
& & \textbf{Group} & \\
& & \emph{FleaEx} & \emph{Control} \\
\textbf{Infected} & \emph{Yes (1)} & \(18_{\;\Large a}\) &
\(23_{\;\Large b}\) \\
& \emph{No (0)} & \(14_{\;\Large c}\) & \(10_{\;\Large d}\) \\
\bottomrule()
\end{longtable}

Aus der Tabelle~\ref{tbl-2x2-ratio-delta} kÃ¶nnen wir entnehmen, dass 18
behandelte Hunde mit FlÃ¶hen infiziert sind und 14 Hunde keine Infektion
aufweisen. Bei den Hunden aus der Kontrolle haben wir 23 infizierte und
10 gesunde Tiere beobachtet.

{\marginnote{\begin{footnotesize}Es gibt verschiedene Typen von
klinischen Studien, also Untersuchungen an Menschen. Einige Studien
liefern nur \(OR\) wieder andere Studientypen liefern
\(RR\).\end{footnotesize}}}

Wir kÃ¶nnen nun zwei Arten von Anteilen berechnen um zu beschreiben, wie
sich der Anteil an infizierten Hunden verhÃ¤lt. Das bekanntere ist die
Frequenz oder Wahrscheinlichkeit oder Risk Ratio (\(RR\)). Das andere
ist das ChancenverhÃ¤ltnis oder Odds Ratio (\(OR\)). Beide kommen in der
Statistik vor und sind unterschiedlich zu interpretieren.

Um die die Odds Ratio und die Risk Ratios auch in R berechnen zu kÃ¶nnen
mÃ¼ssen wir einmal die 2x2 Kreuzabelle in R nachbauen. Wir nutzen dafÃ¼r
die Funktion \texttt{matrix()} und mÃ¼ssen schauen, dass die Zahlen in
der 2x2 Kreuztabelle in R dann auch so sind, wie in der Datentabelle.
Das ist jetzt ein schÃ¶ner Codeblock, ist aber dafÃ¼r da um
sicherzustellen, dass wir die Zahlen richtig eintragen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cross\_mat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{10}\NormalTok{),}
  \AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{Infected =} \FunctionTok{c}\NormalTok{(}\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{),}
    \AttributeTok{Group =} \FunctionTok{c}\NormalTok{(}\StringTok{"FleaEx"}\NormalTok{, }\StringTok{"Control"}\NormalTok{)}
\NormalTok{  )}
\NormalTok{)}

\NormalTok{cross\_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        Group
Infected FleaEx Control
     Yes     18      23
     No      14      10
\end{verbatim}

\marginnote{\begin{footnotesize}

George, Stead, und Ganti (2020) liefert eine gute Ãbersicht Ã¼ber
\emph{What's the risk: differentiating risk ratios, odds ratios, and
hazard ratios?}

\end{footnotesize}}

SpÃ¤ter werden wir das \(OR\) und \(RR\) wieder treffen. Das \(OR\) kommt
in der logistsichen Regression als EffektschÃ¤tzer vor. Wir nutzen das
\(RR\) als EffektschÃ¤tzer in der Poissonregression.

\hypertarget{wahrscheinlichkeitsverhuxe4ltnis-oder-risk-ratio-rr}{%
\subsection{WahrscheinlichkeitsverhÃ¤ltnis oder Risk Ratio
(RR)}\label{wahrscheinlichkeitsverhuxe4ltnis-oder-risk-ratio-rr}}

Wir berechnen wir nun das WahrscheinlichkeitsverhÃ¤ltnis oder Risk Ratio
(RR)? Das Risk Ratio ist das VerhÃ¤ltnis von den infizierten Hunden in
der Behandlung (\(a\)) zu allen infizierten Hunden (\(a+c\)) zu dem
VerhÃ¤ltnis der gesunden Hunde in der Behandlung (\(b\)) zu allen
gesunden Hunden (\(b+d\)). Das klingt jetzt etwas wirr, deshlab helfen
manchaml wirklich Formeln, den Zusammenhang besser zu verstehen.

{\marginnote{\begin{footnotesize}\(Pr(\mbox{FleaEx}|\mbox{infected})\)
ist die Wahrscheinlichkeit infiziert zu sein, wenn der Hund mit
\emph{FleaEx} behandelt wurde.\end{footnotesize}}}

\[
Pr(\mbox{FleaEx}|\mbox{infected}) = \cfrac{a}{a+c} = \cfrac{18}{18+14} \approx 0.56
\]

{\marginnote{\begin{footnotesize}\(Pr(\mbox{Control}|\mbox{infected})\)
ist die Wahrscheinlichkeit infiziert zu sein, wenn der Hund mit in der
Kontrolle war.\end{footnotesize}}}

\[
Pr(\mbox{Control}|\mbox{infected}) = \cfrac{b}{b+d} = \cfrac{23}{23 + 10} \approx 0.70
\]

Das Risk Ratio ist mehr oder minder das VerhÃ¤ltnis von der beiden
Spalten der Tabelle~\ref{tbl-2x2-ratio-delta} fÃ¼r die Behandlung. Wir
erhalten also ein \(RR\) von \(0.76\). Damit mindert die Gabe von
\emph{FleaEx} die Wahrscheinlichkeit sich mit FlÃ¶hen zu infizieren.

\[
\Delta_{y_1/y_2} = RR = \cfrac{Pr(\mbox{FleaEx}|\mbox{infected})}{Pr(\mbox{Control}|\mbox{infected})} =  \cfrac{0.56}{0.70} \approx 0.80 
\]

Wir Ã¼berprÃ¼fen kurz mit der Funktion \texttt{riskratio()} ob wir richtig
gerechnet haben. Das 95\% Konfidenzintervall kÃ¶nnen wir interpretieren,
dafÃ¼r brauchen wir aber noch einmal eine Idee was ``kein Effekt'' bei
einem Risk Ratio heist.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{riskratio}\NormalTok{(cross\_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Risk ratio |       95% CI
-------------------------
0.81       | [0.32, 2.01]
\end{verbatim}

Wann liegt nun kein Effekt bei einem Anteil wie dem RR vor? Wenn der
Anteil in der einen Gruppe genauso groÃ ist wie der Anteil der anderen
Gruppe.

\[
H_0: RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} = 1
\]

Wir interpretieren das \(RR\) nun wie folgt. Unter der Annahme, dass ein
kausaler Effekt zwischen der Behandlung und dem Outcome besteht, kÃ¶nnen
die Werte des relativen Risikos auf folgende Art und Weise interpretiert
werden:

\begin{itemize}
\tightlist
\item
  \(RR = 1\) bedeutet, dass die Behandlung keinen Einfluss auf das
  Outcome hat
\item
  \(RR < 1\) bedeutet, dass das Risiko fÃ¼r das Outcome durch die
  Behandlung verringert wird, was ein ``Schutzfaktor'' ist
\item
  \(RR > 1\) bedeutet, dass das Risiko fÃ¼r das Outcome durch die
  Behandlung erhÃ¶ht wird, was ein ``Risikofaktor'' ist.
\end{itemize}

Das heist in unserem Fall, dass wir mit einem RR von \(0.80\) eine
protektive Behandlung vorliegen haben. Die Gabe von \emph{FleaEx}
reduziert das Risiko mit FlÃ¶hen infiziert zu werden. Durch das 95\%
Konfidenzintervall wissen wir auch, dass das \(RR\) nicht signifikant
ist, da die 1 im 95\% Konfidenzintervall enthalten ist.

\hypertarget{chancenverhuxe4ltnis-oder-odds-ratio-or}{%
\subsection{ChancenverhÃ¤ltnis oder Odds Ratio
(OR)}\label{chancenverhuxe4ltnis-oder-odds-ratio-or}}

Neben dem Risk Ratio gibt es noch das Odds Ratio. Das Odds Ratio ist ein
ChancenverhÃ¤ltnis. Wenn der Mensch an sich schon Probleme hat fÃ¼r sich
Wahrscheinlichkeiten richtig einzuordnen, scheitert man allgemein an der
Chance vollkommen. Dennoch ist das Odds Ratio eine gute MaÃzahl um
abzuschÃ¤tzen wie die Chancen stehen, einen infizierten Hund vorzufinden,
wenn der Hund behandelt wurde.

Scaheun wir uns einmal die Formeln an. Im Gegensatz zum Risk Ratio,
welches die Spalten miteinander vergleicht, vergleicht das Odds Ratio
die Zeilen. Als erstes berechnen wir die Chance unter der Gabe von
\emph{FleaEx} infiziert zu sein wie folgt.

\[
Odds(\mbox{FleaEx}|\mbox{infected}) = a:b = 18:23 = \cfrac{18}{23} = 0.78
\] Dann berechnen wir die Chance in der Kontrollgruppe infiziert zu sein
wie folgt.

\[
Odds(\mbox{Control}|\mbox{infected}) = c:d = 14:10 = \cfrac{14}{10} \approx 1.40 
\] AbschlieÃend bilden wir das ChancenverhÃ¤ltnis der Chance unter der
Gabe von \emph{FleaEx} infiziert zu sein zu der Chance in der
Kontrollgruppe infiziert zu sein. Es ergbit sich das Odds Ratio wie
folgt.

\[
\Delta_{y_1/y_2} = OR =  \cfrac{Odds(\mbox{Flea}|\mbox{infected})}{Odds(\mbox{Control}|\mbox{infected})} = \cfrac{a \cdot d}{b \cdot c} = \cfrac{0.78}{1.40} \approx 0.56
\]

Wir Ã¼berprÃ¼fen kurz mit der Funktion \texttt{oddsratio()} ob wir richtig
gerechnet haben. Das 95\% Konfidenzintervall kÃ¶nnen wir interpretieren,
dafÃ¼r brauchen wir aber noch einmal eine Idee was ``kein Effekt'' bei
einem Odds Ratio heist.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oddsratio}\NormalTok{(cross\_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Odds ratio |       95% CI
-------------------------
0.56       | [0.20, 1.55]
\end{verbatim}

Wann liegt nun kein Effekt bei einem Anteil wie dem OR vor? Wenn der
Anteil in der einen Gruppe genauso groÃ ist wie der Anteil der anderen
Gruppe.

\[
H_0: OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = 1
\]

Wir interpretieren das \(OR\) nun wie folgt. Unter der Annahme, dass ein
kausaler Effekt zwischen der Behandlung und dem Outcome besteht, kÃ¶nnen
die Werte des Odds Ratio auf folgende Art und Weise interpretiert
werden:

\begin{itemize}
\tightlist
\item
  \(OR = 1\) bedeutet, dass die Behandlung keinen Einfluss auf das
  Outcome hat
\item
  \(OR < 1\) bedeutet, dass sich die Chance das Outcome zu bekommen
  durch die Behandlung verringert wird, was ein ``Schutzfaktor'' ist
\item
  \(OR > 1\) bedeutet, dass sich die Chance das Outcome zu bekommen
  durch die Behandlung erhÃ¶ht wird, was ein ``Risikofaktor'' ist.
\end{itemize}

Das heist in unserem Fall, dass wir mit einem OR von \(0.56\) eine
protektive Behandlung vorliegen haben. Die Gabe von \emph{FleaEx}
reduziert die Chance mit FlÃ¶hen infiziert zu werden. Durch das 95\%
Konfidenzintervall wissen wir auch, dass das \(OR\) nicht signifikant
ist, da die 1 im 95\% Konfidenzintervall enthalten ist.

\hypertarget{referenzen-5}{%
\section*{Referenzen}\label{referenzen-5}}
\addcontentsline{toc}{section}{Referenzen}

\hypertarget{sec-ttest}{%
\chapter{Der t-Test}\label{sec-ttest}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht der t-Test?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Der t-Test vergleicht zwei Mittelwerte gewichtet bei der
Standardabweichung und der Fallzahl miteinander. Etwas statistisch
genauer vergleicht der t-Test die Parameter zweier Normalverteilungen
miteinander.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in den t-Test per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/iECcenEDzOM}{Der Two
Sample t-Test erklÃ¤rt} als Video Reihe. Ich werde zwar alles nochmal
hier als Text aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann
einfacher.
\end{tcolorbox}

Der t-Test ist \emph{der} bedeutende Test, wenn es um das VerstÃ¤ndnis
der Algorithmen und Konzepte in der Statistik geht. Wir haben den t-test
schon genutzt um die Idee des statistischen Testens zu verstehen und wir
werdend den t-Test auch im statistischen Modellieren wiedertreffen.

Was macht also der t-Test? Der t-Test vergleicht die Mitfellwerte zweier
Gruppen miteinander. Das heiÃt wir haben zwei Gruppen, wie Hunde und
Katzen, und wollen nun wissen wie sich die Sprungweiten der HundeflÃ¶he
im Mittel von den KatzenflÃ¶hen unterscheiden.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Wir nutzen folgende Formel in der Klausur wenn ein Zweistichproben
t-Test verlangt wird:

\[
T_{calc} = \cfrac{\bar{y}_1-\bar{y}_2}{s_{p} \cdot \sqrt{\cfrac{2}{n_{group}}}}
\]

Wir nutzen folgende Formel in der Klausur fÃ¼r einen gepaarten t-Test:

\[
T_{calc} = \sqrt{n}\cfrac{\bar{d}}{s_d}
\]

Wenn nicht anders in der Klausuraufgabe angegeben dann ist
\(T_{\alpha = 5\%} = 1.96\) oder \(\alpha = 5\%\).
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-6}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-6}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, broom, readxl)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-fuxfcr-den-t-test}{%
\section{Daten fÃ¼r den t-Test}\label{daten-fuxfcr-den-t-test}}

Wichtig ist, dass wir schon jetzt die Modellschreibweise lernen um die
Daten richtig nutzen zu kÃ¶nnen. Wir werden die Modelschreibweise immer
wieder sehen und diese Art eine AbhÃ¤ngigkeit zu beschreiben ist sehr
wichtig in den folgenden Kapiteln.

\begin{figure}

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./images/statistical_modeling_0.png}

}

\caption{\label{fig-ttest-0}Modellschreibweise \(y\) hÃ¤ngt ab von \(x\).
Das \(y\) reprÃ¤sentiert eine Spalte im Datensatz und das \(x\)
reprÃ¤sentiert ebenso eine Spalte im Datensatz. Wir brauchen also zwei
Variablen \(y\) und \(x\), die natÃ¼rlich nicht so heiÃen mÃ¼ssen.}

\end{figure}

{\marginnote{\begin{footnotesize}Etwas unbefriedigend, dass der t-Test
nur \textbf{zwei} Gruppen miteinander Vergleichen kann. Mehr Gruppen
gehen in der ANOVA im Kapitel~\ref{sec-anova}\end{footnotesize}}}

Was brauchen wir dafÃ¼r in R? Wir brauchen dafÃ¼r eine Spalte \(y\) mit
kontinuierlichen Zahlen und einer Spalte \(x\) in dem wir einen Faktor
mit zwei Leveln finden. Jedes Level steht dann fÃ¼r eine der beiden
Gruppen. Das war es schon. Schauen wir uns nochmal den Datensatz
\texttt{flea\_dog\_cat.xlsx} in Tabelle~\ref{tbl-data-ttest} an und
Ã¼berlegen, wie wir das realisieren kÃ¶nnen.

\hypertarget{tbl-data-ttest}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-data-ttest}Tabelle der SprunglÃ¤ngen {[}cm{]}, Anzahl
an FlÃ¶hen, Boniturnote sowie der Infektionsstatus von Hunden und
Katzen.}\tabularnewline
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & flea\_count & grade & infected \\
\midrule()
\endhead
dog & 5.7 & 18 & 8 & 0 \\
dog & 8.9 & 22 & 8 & 1 \\
dog & 11.8 & 17 & 6 & 1 \\
dog & 8.2 & 12 & 8 & 0 \\
dog & 5.6 & 23 & 7 & 1 \\
dog & 9.1 & 18 & 7 & 0 \\
dog & 7.6 & 21 & 9 & 0 \\
cat & 3.2 & 12 & 7 & 1 \\
cat & 2.2 & 13 & 5 & 0 \\
cat & 5.4 & 11 & 7 & 0 \\
cat & 4.1 & 12 & 6 & 0 \\
cat & 4.3 & 16 & 6 & 1 \\
cat & 7.9 & 9 & 6 & 0 \\
cat & 6.1 & 7 & 5 & 0 \\
\bottomrule()
\end{longtable}

In \textbf{?@fig-ttest-1} sehen wir einmal den Zusammenhang zwischen den
Schreibweise \(y \sim x\) und den beiden Variablen \texttt{jump\_length}
als \(y\) und \texttt{animal} als \(x\) aus dem Datensatz
\texttt{flea\_dog\_cat.xlsx}. Wir haben also die \texttt{formula}
Schreibweise in R als \texttt{jump\_length\ \textasciitilde{}\ animal}.

\includegraphics[width=0.8\textwidth,height=\textheight]{./images/statistical_modeling_1.png}
Wir benÃ¶tigen fÃ¼r den t-Test ein normalverteiltes \(y\) und einen Faktor
mit zwei Leveln als \(x\). Wir nehmen daher mit \texttt{select()}die
Spalte \texttt{jump\_length} und \texttt{animal} aus dem Datensatz
\texttt{flea\_dog\_cat.xlsx}. Wichtig ist, dass wir die Spalte
\texttt{animal} mit der Funktion \texttt{as\_factor()} in einen Faktor
umwandeln. AnschlieÃend speichern wir die Auswahl in dem Objekt
\texttt{data\_tbl}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, jump\_length)}

\NormalTok{data\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 14 x 2
   animal jump_length
   <fct>        <dbl>
 1 dog            5.7
 2 dog            8.9
 3 dog           11.8
 4 dog            8.2
 5 dog            5.6
 6 dog            9.1
 7 dog            7.6
 8 cat            3.2
 9 cat            2.2
10 cat            5.4
11 cat            4.1
12 cat            4.3
13 cat            7.9
14 cat            6.1
\end{verbatim}

Wir haben jetzt die Daten richtig vorbereiten und kÃ¶nnen uns nun mit dem
t-Test beschÃ¤ftigen. Bevor wir den t-Test jedoch rechnen kÃ¶nnen, mÃ¼ssen
wir uns nochmal Ã¼berlegen, was der t-Test eigentlich testet und uns die
Daten einmal visualisieren.

\hypertarget{visualiserung-der-daten}{%
\section{Visualiserung der Daten}\label{visualiserung-der-daten}}

Bevor wir einen statistischen Test rechnen, wollen wir uns erstmal die
Daten, die dem Test zugrundeliegen, visualisieren. Wir schauen uns in
Abbildung~\ref{fig-boxplot-ttest} einmal den Boxplot fÃ¼r die
Sprungweiten getrennt nach Hund und Katze an.

Wir sehen, dass sich die Boxen nicht Ã¼berschneiden, ein Indiz fÃ¼r einen
signifikanten Unterschied zwischen den beiden Gruppen. Im Weiteren liegt
der Median in etwa in der Mitte der beiden Boxen. Die Whisker sind
ungefÃ¤hr gleich bei Hunden und Katzen. Ebenso sehen wir bei beiden
Gruppen keine AusreiÃer.

Wir schlieÃen daher nach der Betrachtung der Boxplots auf Folgendes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Die Sprungweite ist fÃ¼r beide Gruppen ist annÃ¤herend bzw. approximativ
  normalverteilt.
\item
  Die Standardabweichungen und damit die Varianzen
  \(s^2_{dog} = s^2_{cat}\) der beiden Gruppen sind gleich. Es liegt
  somit VarianzhomogenitÃ¤t vor.
\end{enumerate}

\begin{figure}

{\centering \includegraphics{./stat-tests-ttest_files/figure-pdf/fig-boxplot-ttest-1.pdf}

}

\caption{\label{fig-boxplot-ttest}Boxplot der Sprungweiten {[}cm{]} von
Hunden und Katzen.}

\end{figure}

Manchmal ist es etwas verwirrend, dass wir uns in einem Boxplot mit
Median und IQR die Daten fÃ¼r einen t-Test anschauen. Immerhin rechnet ja
ein t-Test mit den Mittelwerten und der Standardabweichung. Hier
vergleichen wir etwas Ãpfel mit Birnen. Deshalb in der
Abbildung~\ref{fig-dotplot-ttest} der Dotplot mit dem Mittelwert und den
entsprechender Standardabweichung als Fehlerbalken.

\begin{figure}

{\centering \includegraphics{./stat-tests-ttest_files/figure-pdf/fig-dotplot-ttest-1.pdf}

}

\caption{\label{fig-dotplot-ttest}Dotplot der Sprungweiten {[}cm{]} von
Hunden und Katzen zusammen mit dem Mittelwert und der Stanardabweichung
als Fehlerbalken.}

\end{figure}

Wir nutzen aber spÃ¤ter hÃ¤ufig den Boxplot zur Visualisierung der
einzelnen Gruppen. Ãber den Boxplot kÃ¶nnen wir auch gut abschÃ¤tzen, ob
wir eine annÃ¤hrende bzw. approximative Normalverteilung vorliegen haben.

\hypertarget{hypothesen-fuxfcr-den-t-test}{%
\section{Hypothesen fÃ¼r den t-Test}\label{hypothesen-fuxfcr-den-t-test}}

Ohne eine Hypothese ist das Ergebnis eines statistischen Tests wie auch
der t-Test nicht zu interpretieren. Wir berechenen eine Teststatistik
und einen p-Wert. Beide statistischen MaÃzahlen machen eine Aussage Ã¼ber
die beobachteten Daten \(D\) unter der Annahme, das die Nullhypothese
\(H_0\) gilt.

Wie lautet nun das Hypothesenpaar des t-Tests? Der t-Test vergleicht die
Mittelwerte von zwei Gruppen. Die Nullhypothese ist auch die
Gleichheitshypothese. Die Alternativehypothese haben wir auch als
Unterschiedshypothese bezeichnet.

Daher ergibt sich fÃ¼r unser Beispiel mit den Sprungweiten fÃ¼r Hunde- und
KatzenflÃ¶hen folgende Hypothesen. Die Nullhypothese sagt, dass die
mittleren Sprungweite fÃ¼r die HundeflÃ¶he gleich der mittleren
Sprungweite der KatzenflÃ¶he ist. Die Alternativehypothese sagt aus, dass
sich die mittlere Sprungweite von Hunde- und KatzenflÃ¶hen unterscheidet.

\[
\begin{align*} 
H_0: \bar{y}_{dog} &= \bar{y}_{cat} \\  
H_A: \bar{y}_{dog} &\neq \bar{y}_{cat} \\   
\end{align*}
\]

Wir testen grundsÃ¤tzlich auf ein zweiseitiges \(\alpha\)-Niveau von 5\%.

\hypertarget{der-student-t-test}{%
\section{Der Student t-Test}\label{der-student-t-test}}

Liegt ein normalverteiltes \(y\) vor und sind die Varianzen fÃ¼r die
beiden zu vergleichenden Gruppen homogen \(s^2_{cat} = s^2_{dog}\),
kÃ¶nnen wir einen Student t-Test rechnen. Wir nutzen dazu die
folgendeFormel des Student t-Tests.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Eigentlich wÃ¤re hier folgende Formel richtig\ldots{}

\[
s_{p} = \sqrt{\frac{1}{2} (s^2_{dog} + s^2_{cat})}
\] \ldots aber auch hier erwischen wir einen Statistikengel um es etwas
einfacher zu machen.

\[
T_{calc} = \cfrac{\bar{y}_{dog}-\bar{y}_{cat}}{s_{p} \cdot \sqrt{\cfrac{2}{n_{group}}}}
\]

mit der vereinfachten Formel fÃ¼r die gepoolte Standardabweichung \$s\_p.

\[
s_{p} = \cfrac{s_{dog} + s_{cat}}{2}
\]

Wir wollen nun die Werte fÃ¼r \(\bar{y}_{dog}\), \(\bar{y}_{cat}\) und
\(s_{p}\) berechnen. Wir nutzen hierfÃ¼r R auf die etwas komplizierte Art
und Weise. Es gibt in R auch die Funktion \texttt{t.test()}, die fÃ¼r uns
alles auf einmal macht, aber hier nochaml zu FuÃ.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(animal) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(jump\_length), }\DecValTok{2}\NormalTok{), }
            \AttributeTok{sd =} \FunctionTok{round}\NormalTok{(}\FunctionTok{sd}\NormalTok{(jump\_length), }\DecValTok{2}\NormalTok{)) }

\NormalTok{sum\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 3
  animal  mean    sd
  <fct>  <dbl> <dbl>
1 dog     8.13  2.14
2 cat     4.74  1.9 
\end{verbatim}

Wir erhalten durch die Funktion \texttt{group\_by()} den Mittelwert und
die Standardabweichung fÃ¼r die Sprungweite getrennt fÃ¼r die Hunde- und
KatzenflÃ¶he. Wir kÃ¶nnen damit die beiden obigen Formeln fÃ¼llen.

Wir berechnen \(s_p\) wie folgt.

\[
s_{pooled} = \cfrac{2.14 + 1.9}{2} = 2.02
\]

AnschlieÃend kÃ¶nnen wir jetzt \(s_p\) und die Mittelwerte sowie die
GruppengrÃ¶Ãe \(n_g = 7\) in die Formel fÃ¼r den Student t-Test einsetzen
und die Teststatistik \(T_{calc}\) berechnen.

\[
T_{calc} = \cfrac{8.13- 4.74}{2.02 \cdot \sqrt{\cfrac{2}{7}}} = 3.14
\]

Wir erhalten eine Teststatistik \(T_{calc} = 3.14\) die wir mit dem
kritischen Wert \(T_{\alpha = 5\%} = 2.17\) vergleichen kÃ¶nnen. Da
\(T_{calc} > T_{\alpha = 5\%}\) ist, kÃ¶nnen wir die Nullhypothese
ablehnen. Wir haben ein signifikanten Unterschied zwischen den mittleren
Sprungweiten von Hunde- und KatzenflÃ¶hen nachgewiesen.

Soweit fÃ¼r den Weg zu FuÃ. Wir rechnen in der Anwendung keinen Student
t-Test per Hand. Wir nutzen die Formel \texttt{t.test()}. Da wir den
Student t-Test unter der Annahme der VarainzhomogenitÃ¤t nutzen wollen,
mÃ¼ssen wir noch die Option \texttt{var.equal\ =\ TRUE} wÃ¤hlen.

Die Funktion \texttt{t.test()} benÃ¶tigt erst die das \(y\) und \(x\) in
Modellschreibweise mit den Namen, wie die beiden Variablen auch im
Datensatz \texttt{data\_tbl} stehen. In unserem Fall ist die
Modellschreibweise dann
\texttt{jump\_length\ \textasciitilde{}\ animal}. Im Weiteren mÃ¼ssen wir
noch den Datensatz angeben den wir verwenden wollen durch die Option
\texttt{data\ =\ data\_tbl}. Dann kÃ¶nnen wir die Funktion
\texttt{t.test()} ausfÃ¼hren.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }
       \AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Two Sample t-test

data:  jump_length by animal
t = 3.12528, df = 12, p-value = 0.0087684
alternative hypothesis: true difference in means between group dog and group cat is not equal to 0
95 percent confidence interval:
 1.0253394 5.7460892
sample estimates:
mean in group dog mean in group cat 
        8.1285714         4.7428571 
\end{verbatim}

Wir erhalten eine sehr lange Ausgabe, die aucb etwas verwirrend
aussieht. Gehen wir die Ausgabe einmal durch. Ich gehe nicht auf alle
Punkte ein, sondern konzentriere mich hier auf die wichtigsten Aspekte.

\begin{itemize}
\tightlist
\item
  \texttt{t\ =\ 3.12528} ist die berechnete Teststatistik \(T_{calc}\).
  Der Wert unterscheidet sich leicht von unserem berechneten Wert. Der
  Unterschied war zu erwarten, wir haben ja auch die t-Test Formel
  vereinfacht.
\item
  \texttt{p-value\ =\ 0.0087684} ist der berechnete p-Wert
  \(Pr(T_{calc}|H_0)\) aus der obigen Teststatistik. Daher die FlÃ¤che
  rechts von der Teststatistik.
\item
  \texttt{95\ percent\ confidence\ interval:\ 1.0253394\ 5.7460892} ist
  das 95\% Konfidenzintervall. Die erste Zahl ist die untere Grenze, die
  zweite Zahl ist die obere Grenze.
\end{itemize}

Wir erhalten hier dreimal die MÃ¶glichkeit eine Aussage Ã¼ber die \(H_0\)
zu treffen. In dem obigen Output von R fehlt der kritische Wert
\(T_{\alpha = 5\%}\). Daher ist die berechnete Teststatistik fÃ¼r die
Testentscheidung nicht verwendbar. Wir nutzen daher den p-Wert und
vergleichen den p-Wert mit dem \(\alpha\)-Niveau von 5\%. Da der p-Wert
kleiner ist als das \(\alpha\)-Niveau kÃ¶nnen wir wie Nullhypothese
ablehnen. Wir haben einen signifikanten Unterschied. Die Entscheidung
mit dem Konfidentintervall benÃ¶tigt die Signifikanzschwelle. Da wir hier
einen Mittelwertsvergleich vorliegen haben ist die Signifikanzschwelle
gleich 0. Wenn die 0 im Konfidenzintervall liegt kÃ¶nnen wir die
Nullhypothese nicht ablehnen. In unserem Fall ist das nicht der Fall.
Das Konfidenzintervall lÃ¤fut von 1.025 bis 5.75. Damit ist die 0 nicht
im Konfidenzuntervall enthalten und wir kÃ¶nnen die Nullhypothese
ablehnen. Wir haben ein signifikantes Konfidenznintervall vorliegen.

Wie wir sehen fehlt der Mittelwertsuntschied als Effekt \(\Delta\) in
der Standardausgabe des t-Tests in R. Wir kÃ¶nnen den
Mittelwertsunterschied selber berechnen oder aber die Funktion
\texttt{tidy()} aus dem R Paket \texttt{broom} nutzen. Da der Funktion
\texttt{tidy()} kriegen wir die Informationen besser sortiert und
einheitich wiedergegeben. Da \texttt{tidy} eine Funktion ist, die mit
vielen statistischen Tests funktioniert mÃ¼ssen wir wissen was die
einzelnen \texttt{estimate} sind. Es hilft in diesme Fall sich die
Visualisierung der Daten anzuschauen und die Abbildung mit den
berechneten Werten abzugleichen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }
       \AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 10
  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>
1     3.39      8.13      4.74      3.13 0.00877        12     1.03      5.75
# ... with 2 more variables: method <chr>, alternative <chr>
\end{verbatim}

Wir erkennen als erstes den Mittelwertsunterschied zwischen den beiden
Gruppen von 3.39 cm. Danach folgen die einzelnen Mittelwerte der
Sprungweiten der Hunde und KatzenflÃ¶he mit jeweils 8.13 cm und 4.74 cm.
Darauf folgt noch der p-Wert als \texttt{p.value} mit 0.00891 und die
beiden Grenzen des Konfidenzintervalls {[}1.03; 5.75{]}.

\hypertarget{der-welch-t-test}{%
\section{Der Welch t-Test}\label{der-welch-t-test}}

Der t-Test ist auch in der Lage mit VarianzhetrogenitÃ¤t umzugehen. Das
heiÃt, wenn die Varianzen der beiden Gruppen nicht gleich sind. Dadurch
Ã¤ndert sich die Formel fÃ¼r den t-Test wie folgt. Dann nennen wir den
statistsichen Test Welch t-Test.

\[
T_{calc} = \cfrac{\bar{y_1} - \bar{y_2}}{\sqrt{\cfrac{s^2_{y_1}}{n_1} + \cfrac{s^2_{y_2}}{n_2}}}
\]

Wir sehen, dass sich die Formel etwas andert. Da wir nicht mehr
annhemen, dass die Varianzen homogen und daher gleich sind, kÃ¶nnen wir
auch keinen gepoolten VarianzschÃ¤tzer \(s_p\) berechnen. Die Varianzen
gehen einzeln in die Formel des Welch t-Tests ein. Ebenso mÃ¼ssen die
beiden Gruppen nicht mehr gleich groÃ sein. Statt einen Wert \(n_g\) fÃ¼r
die GruppengrÃ¶Ãe kÃ¶nnen wir auch die beiden GruppengrÃ¶Ãen separat
angeben.

\marginnote{\begin{footnotesize}

Hier muss man noch bedenken, dass die Freiheitsgrade anders berechnte
werden Die Freiheitsgrade werden wie folgt berechnet.

\[
df = \cfrac{\left(\cfrac{s^2_{y_1}}{n} +
    \cfrac{s^2_{y_2}}{m}\right)^2}{\cfrac{\left(\cfrac{s^2_{y_1}}{n}\right)^2}{n-1} + \cfrac{\left(\cfrac{s^2_{y_2}}{m}\right)^2}{m-1}}
\]

\end{footnotesize}}

Es ergibt keinen tieferen Sinn die obige Formel nochmal hÃ¤ndisch
auszurechnen. Die Zahlen Ã¤ndern sich leicht, aber konzeptionell erhalten
wir hier keinen Mehrwert. Deshalb schauen wir uns gleich die Umsetzung
in R an. Wir nutzen erneut die Funtktion \texttt{t.test()} und zwar
diesmal mit der Option \texttt{var.equal\ =\ FALSE}. Damit geben wir an,
dass die Varianzen heterogen zwischen den beiden Gruppen sind. Wir
nutzen in unserem Beispiel die gleichen Zahlen und Daten wie schon im
obigen Student t-Test Beispiel.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }
       \AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{var.equal =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  jump_length by animal
t = 3.12528, df = 11.8307, p-value = 0.008906
alternative hypothesis: true difference in means between group dog and group cat is not equal to 0
95 percent confidence interval:
 1.0215869 5.7498416
sample estimates:
mean in group dog mean in group cat 
        8.1285714         4.7428571 
\end{verbatim}

Wir sehen das viele Zahlen nahezu gleich sind. Das liegt auch daran,
dass wir in unserem Daten keine groÃe Abweichung von der
VarianzhomogenitÃ¤t haben. Wirerhalten die gleichen Aussagen wie auch
schon im Student t-Test.

Schauen wir uns nochmal die Ausgabe der Funkton \texttt{tidy()} an.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }
       \AttributeTok{data =}\NormalTok{ data\_tbl, }\AttributeTok{var.equal =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 10
  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>
1     3.39      8.13      4.74      3.13 0.00891      11.8     1.02      5.75
# ... with 2 more variables: method <chr>, alternative <chr>
\end{verbatim}

{\marginnote{\begin{footnotesize}FÃ¼r das Erkennen von Normalverteilung
und VarianzhterogenitÃ¤t werden hÃ¤ufig sogenannte Vortest empfohlen. Aber
auch hier gilt, bei kleiner Fallzahl liefern die Vortests keine
verlÃ¤sslichen Ergebnisse. In diesem Fall ist weiterhin die Beurteilung
Ã¼ber einen Boxplot sinnvoller.\end{footnotesize}}}

Wir sehen hier etwas besser, dass es kaum Abweichungen gibt. Alles egal?
Nicht unbedingt. Das Problem ist eher \emph{das Erkennen} von
VarianzheterogenitÃ¤t in sehr kleinen DatensÃ¤tzen. Kleine DatensÃ¤tze
meint DatensÃ¤tze unter 30 Beobachtungen je Gruppe. Erst aber dieser
Anzahl lassen sich unverzerrte Histogramme zeichnen und so
aussagekrÃ¤ftige AbschÃ¤tzungen der VarianzhomogenitÃ¤t oder
VarianzheterogenitÃ¤t treffen.

\hypertarget{der-verbundene-t-test-paired-t-test}{%
\section{Der verbundene t-Test (Paired
t-Test)}\label{der-verbundene-t-test-paired-t-test}}

Im folgenden Datenbespiel in Tabelle~\ref{tbl-data-ttest-paired} haben
wir eine verbundene Stichprobe. Das heiÃt wir haben nicht zehn FlÃ¶he
gemessen sondern fÃ¼nf FlÃ¶he. Einmal im ungefÃ¼tterten Zustand
\texttt{unfed} und einmal im gefÃ¼tterten Zustand \texttt{fed}. Wir
wollen nun wissen, ob der FÃ¼tterungszustand Auswirkungen auf die
Sprungweite in {[}cm{]} hat.

\hypertarget{tbl-data-ttest-paired}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-ttest-paired}Tabelle der SprunglÃ¤ngen {[}cm{]}
von fÃ¼nf FlÃ¶hen zu zwei Zeitpunkten. Einmal wurde die Sprungweite
ungefÃ¼ttert und einmal gefÃ¼ttert bestimmt. Die Daten liegen im Wide
Format vor.}\tabularnewline
\toprule()
unfed & fed & diff \\
\midrule()
\endfirsthead
\toprule()
unfed & fed & diff \\
\midrule()
\endhead
5.2 & 6.1 & 0.9 \\
4.1 & 5.2 & 1.1 \\
3.5 & 3.9 & 0.4 \\
3.2 & 4.1 & 0.9 \\
4.6 & 5.3 & 0.7 \\
\bottomrule()
\end{longtable}

Wir nutzen folgende Formel fÃ¼r den paired t-Test fÃ¼r verbundene
Stichproben.

\[
T_{calc} = \sqrt{n}\cfrac{\bar{d}}{s_d}
\]

Wir kÃ¶nnen \(\bar{d}\) als Mittelwert der Differenzen der Variablen
\texttt{diff} berechnen. Ebenso verfahren wir mit der Standardabweichung
der Differenzen \(s_d\).

\[
T_{calc} = \sqrt{10}\cfrac{0.8}{0.26} = 6.88
\] Um den die Funktion \texttt{t.test()}in R mit der Option
\texttt{paired\ =\ TRUE} fÃ¼r den paired t-Test zu nutzen, mÃ¼ssen wir die
Daten nochmal Ã¼ber die Funktion \texttt{gather()} in das Long Format
umwandeln. Wir wollen nun wissen, ob der FÃ¼tterungszustand
\texttt{food\_status} Auswirkungen auf die Sprungweite in {[}cm{]} hat.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ food\_status, }
       \AttributeTok{data =}\NormalTok{ paired\_tbl, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Paired t-test

data:  jump_length by food_status
t = 6.76123, df = 4, p-value = 0.0024959
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 0.47148658 1.12851342
sample estimates:
mean difference 
            0.8 
\end{verbatim}

Die Ausgabe des paired t-Test Ã¤hnelt stark der Ausage des Student
t-Test. Wir erhalten ebenfalls den wichtigen p-Wert mit 0.0025 sowie das
95\% Konfidenzintervall mit {[}0.47; 1.13{]}. Zum einen ist
\(0.0025 < \alpha\) und somit kÃ¶nnen wir die Nullhypothese ablehnen, zum
anderen ist auch die 0 nicht mit in dem Konfidentintervall, womit wir
auch hier die Nullhypothese ablehnen kÃ¶nnen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ food\_status, }
       \AttributeTok{data =}\NormalTok{ paired\_tbl, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 8
  estimate statistic p.value parameter conf.low conf.high method     alternative
     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>      
1      0.8      6.76 0.00250         4    0.471      1.13 Paired t-~ two.sided  
\end{verbatim}

Die Funktion \texttt{tidy()} gibt uns in diesem Fall keine neuen
zusÃ¤tzlichen Informationen.

\hypertarget{freiheitsgrade-im-t-test}{%
\section{Freiheitsgrade im t-Test}\label{freiheitsgrade-im-t-test}}

Der t-Verteilung der Teststatistiken des t-Tests verhÃ¤lt sich nicht wie
eine klassische Normalverteilung, die durch den Mittelwert und die
Standardabweichung definiert ist. Die t-Verteilung ist nur durch die
Freiheistgrade definiert. Der Freiheitsgrade in einem t-Test mit zwei
Stichproben ist gegeben durch \(df = n_1 + n_2 -2\). Damit beschreiben
die Freiheitsgrade grob die Fallzahl. Je mehr Fallzahl desto groÃer der
Freiheitsgrad eines t-Tests.

Abbildung~\ref{fig-ttest-06} visualisert diesen Zusammenhang von
Freiheitsgraden und der Form der t-Verteilung. Je kleiner die
Freiheitgarde und damit die Fallzahl, desto weiter sind die
VerteilungsschwÃ¤nze. Daher benÃ¶tigen wir auch grÃ¶Ãere \(T_{calc}\) Werte
um ein signifikantes Ergebnis zu erhalten. Die FlÃ¤che unter der
t-Verteilung ist immer gleich.

\begin{figure}

{\centering \includegraphics{./images/t-verteilung_06.png}

}

\caption{\label{fig-ttest-06}Die t-Verteilung fÃ¼r drei beispielhafte
Freiheitsgrade. Je grÃ¶Ãer die Freiheitsgrade und dammit die Fallzahl,
desto nÃ¤her komtm die t-Verteilung einer Normalverteilung nahe. Da eine
geringe Fallzahl weiter nach AuÃen geht, mÃ¼ssen grÃ¶Ãere \(T_{calc}\)
Werte erreicht werden um eine signifikantes Ergebnis zu erhalten.\$}

\end{figure}

\hypertarget{sec-anova}{%
\chapter{Die ANOVA}\label{sec-anova}}

\emph{Version vom September 14, 2022 um 08:49:34}

{\marginnote{\begin{footnotesize}Historisch betrachtet ist die ANOVA,
\emph{das} statistische Verfahren was gut per Hand ohne Computer
berechnet werden kann. Daher war die ANOVA von den 20zigern bis in die
frÃ¼hen 90ziger des letzten Jahrhunderts \emph{das} statistische
Verfahren der Wahl.\end{footnotesize}}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in die ANOVA per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube
\href{https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC}{Grundlagen
in R} als Video Reihe. Ich werde zwar alles nochmal hier als Text
aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

Die ANOVA (eng. \emph{analysis of variance}) ist wichtig. Was fÃ¼r ein
schÃ¶ner Satz um anzufangen. Wir brauchen die ANOVA aus mehreren GrÃ¼nden.
Die Hochzeiten der ANOVA sind eigentlich vorbei, wir haben in der
Statistik fÃ¼r viele FÃ¤lle mittlerweile besser Werkzeuge, aber als
Allrounder ist die ANOVA immer noch nutzbar.

\marginnote{\begin{footnotesize}

Die tolle Webseite
\href{https://schmidtpaul.github.io/DSFAIR/index.html}{Data Science for
Agriculture in R} liefert eine Vielzahl von experimentellen Designs
sowie deren Auswertung. Neben anderen komplexeren Designs, auch diese
einfacheren Designs, die jeder kennen sollte.

\begin{itemize}
\item
  \href{https://schmidtpaul.github.io/DSFAIR/CRD_Mead1993.html}{Completely
  randomized design}, ist das Standarddesign fÃ¼r ein Feldexperiment.
\item
  \href{https://schmidtpaul.github.io/DSFAIR/RCBD_ClewerScarisbrick2001.html}{Randomized
  complete block design (RCBD) with 1 factor}, beschreibt ein Experiment
  mit BlÃ¶cken und einem Behandlungsfaktor.
\item
  \href{https://schmidtpaul.github.io/DSFAIR/RCBD_2f_rice.html}{Randomized
  complete block design (RCBD) with 2 factors}, beschreibt ein
  Experiment mit BlÃ¶cken und einem Behandlungsfaktor sowie einem
  weiteren Faktor.
\item
  \href{https://schmidtpaul.github.io/DSFAIR/latsquare_Bridges1989.html}{Latin
  square design}, ist ein etwas spezielleres Design, wird aber auch viel
  genutzt.
\end{itemize}

Wir gehen in einem spÃ¤teren Kapitel nochmal auf die experimentellen
Designs ein.

\end{footnotesize}}

WofÃ¼r brauchen wir die ANOVA?

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir brauchen die ANOVA um mehr als zwei Gruppen \emph{gleichzeitig}
  miteinander zu vergleichen. Das heiÃt wir haben einen Faktor mit mehr
  als zwei Levels und wollen wissen, ob sich \emph{mindestens} zwei
  Level bzw. Gruppen im mittelwert unterscheiden.
\item
  Wir brauchen die ANOVA und deren Varianzzerlegung in der ZÃ¼chtung.
  Hier speilt die ANOVA eine gewichtige Rolle bei der AbschÃ¤tzung des
  genetischen Effekts. Wir werden aktuell (Stand Ende 2022) hierauf noch
  nicht tiefer eingehen.
\item
  Wir nutzen die ANOVA in vielen Anwendunsggebieten als eine Arte
  Vortest um zu schauen, ob sich ein Effekt in den Daten verbirgt.
  Eigentlich stammt dieses Ritual aus ANOVA als Vortest und dann ein
  Posthoc Test noch aus der Zeit, wo wir keine moderen Rechner zu
  VerfÃ¼gung hatten. Damals machte diese Reihenfolge noch Sinn. Wir
  werdend arÃ¼ber aber spÃ¤ter nochmal lesen.
\item
  Experimentelle Designs sind darauf ausgelegt mit der ANOVA ausgewertet
  zu werden. Insbesondere in den Agrawissenschaften hat die ANOVA daher
  eine historische Bedeutung. Insbesondere durch die enge Verzahnung vom
  Experiment auf dem Feld und der eigentlichen Auswertung mit der ANOVA.
\end{enumerate}

Wir sehen also, dass die ANOVA zum einen alt ist, aber auch heute noch
viel verwendet wird. Daher werden wir in diesem \emph{langem} Kapitel
uns einmal mit der ANOVA ausgiebig beschÃ¤ftigen. Fangen wir also an,
dieses groÃartige Schwerzeitaschenmesser der Statistik besser zu
verstehen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht die ANOVA?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Die \emph{einfaktorielle} ANOVA vergleicht die Parameter mehrerer
Normalverteilungen miteinander. Oder etwas anders formuliert, vergleicht
die ANOVA die Mittlelwerte von mehreren Gruppen bzw. Behandlungen
miteinander.

Die \emph{zweifaktorielle} ANOVA vergleicht die Parameter mehrerer
Normalverteilungen miteinander von zwei Faktoren. Oder etwas anders
formuliert, vergleicht die ANOVA die Mittlelwerte von mehreren Gruppen
bzw. Behandlungen miteinander. Dabei kann die \emph{zweifaktorielle}
ANOVA auch die Interaktion zwischen zwei Variablen abbilden.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Wir rechnen keine ANOVA in der Klausur \emph{per Hand} sondern
interpretieren die Ausgabe der R Funktionen einer einfaktoriellen oder
zweifaktoriellen ANOVA. Auch hier gilt, Ã¼berprÃ¼fe was du in der
Vorlesung gehÃ¶rt hast!

Bitte schau dir unbedingt die Aufgaben in den
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub} an um eine Idee zu haben, welche Fragen zu der
ANOVA drankommen.

Wenn kein \(F_{\alpha = 5\%}\) in der Klausur gegeben ist, setzen wir
\(F_{\alpha = 5\%} = 3.55\).
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-7}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-7}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, broom, }
\NormalTok{               readxl, effectsize, ggpubr)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{sec-fac1}{%
\section{Einfaktorielle ANOVA}\label{sec-fac1}}

Die einfaktorielle ANOVA ist die simpelste Form der ANOVA. Wir nutzen
einen Faktor mit mehr als zwei Leveln. Im Rahmen der einfaktoriellen
ANOVA wollen wir usn auch die ANOVA theoretisch einmal anschauen. Danach
wie die einfaktorielle ANOVA in R genutzt wird. Ebenso wie wir die
einfaktorielle ANOVA visualsieren. AbschlieÃend mÃ¼ssen wir uns noch
Ã¼berlegen, ob es einen EffektschÃ¤tzer fÃ¼r die einfaktorielle ANOVA gibt.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Die einfaktorielle ANOVA verlangt ein normalverteiltes \(y\) sowie
VarianzhomogenitÃ¤t Ã¼ber den Behandlungsfaktor \(x\). Daher alle Level
von \(x\) sollen die gleiche Varianz haben.

Unsere Annahme an die Daten \(D\) ist, dass das dein \(y\)
normalverteilt ist und das die Level vom \(x\) homogen in den Varianzen
sind. SpÃ¤ter mehr dazu, wenn wir beides nicht vorliegen haben\ldots{}

\hypertarget{daten-fuxfcr-die-einfaktorielle-anova}{%
\subsection{Daten fÃ¼r die einfaktorielle
ANOVA}\label{daten-fuxfcr-die-einfaktorielle-anova}}

Wir wollen uns nun erstmal den einfachsten Fall anschauen mit einem
simplen Datensatz. Wir nehmen ein normalverteiltes \(y\) aus den
Datensatz \texttt{flea\_dog\_cat\_fox.csv} und einen Faktor mit mehr als
zwei Leveln. HÃ¤tten wir nur zwei Level, dann kÃ¶nnen wir auch einen
t-Test rechnen kÃ¶nnen.

Im Folgenden selektieren mit der Funktion \texttt{select()} die beiden
Spalten \texttt{jump\_length} als \(y\) und die Spalte \texttt{animal}
als \(x\). Danach mÃ¼ssen wir noch die Variable \texttt{animal} in einen
Faktor mit der Funktion \texttt{as\_factor()} umwandeln.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac1\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, jump\_length) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{fac1\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-anova-1} nochmal dargestellt.

\hypertarget{tbl-data-anova-1}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-data-anova-1}Selektierter Datensatz fÃ¼r die
einfaktorielle ANOVA mit einer normalverteilten Variable
\texttt{jump\_length} und einem Faktor \texttt{animal} mit drei
Leveln.}\tabularnewline
\toprule()
animal & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length \\
\midrule()
\endhead
dog & 5.7 \\
dog & 8.9 \\
dog & 11.8 \\
dog & 8.2 \\
dog & 5.6 \\
dog & 9.1 \\
dog & 7.6 \\
cat & 3.2 \\
cat & 2.2 \\
cat & 5.4 \\
cat & 4.1 \\
cat & 4.3 \\
cat & 7.9 \\
cat & 6.1 \\
fox & 7.7 \\
fox & 8.1 \\
fox & 9.1 \\
fox & 9.7 \\
fox & 10.6 \\
fox & 8.6 \\
fox & 10.3 \\
\bottomrule()
\end{longtable}

Wir bauen daher mit den beiden Variablen mit dem Objekt
\texttt{fac1\_tbl} folgendes Modell fÃ¼r spÃ¤ter:

\[
jump\_length \sim animal
\]

Bevor wir jetzt das Modell verwenden, mÃ¼ssen wir uns nochmal Ã¼berlegen,
welchen SchluÃ wir eigentlich Ã¼ber die Nullhypothese machen. Wir immer
kÃ¶nnen wir nur die Nullhypothese ablehnen. Daher Ã¼berlegen wir uns im
Folgenden wie die Nullhypothese in der einfaktoriellen ANOVA aussieht.
Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

\hypertarget{hypothesen-fuxfcr-die-einfaktorielle-anova}{%
\subsection{Hypothesen fÃ¼r die einfaktorielle
ANOVA}\label{hypothesen-fuxfcr-die-einfaktorielle-anova}}

Die ANOVA betrachtet die Mittelwerte und nutzt die Varianzen um einen
Unterschied nachzuweisen. Daher haben wir in der Nullhypothese als
Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass
die Mittelwerte jedes Levels des Faktors \texttt{animal} gleich sind.

\[
\begin{align*}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
\end{align*}
\]

Die Alternative lautet, dass sich mindestens ein paarweiser Vergleich in
den Mittelwerten unterschiedet. Hierbei ist das \emph{mindestens ein
Vergleich} wichtig. Es kÃ¶nnen sich alle Mittelwerte unterschieden oder
eben nur ein Paar. Wenn eine ANOVA die \(H_0\) ablehnt, also ein
signifikantes Ergebnis liefert, dann wissen wir nicht, welche
Mittelwerte sich unterscheiden.

\[
\begin{align*}
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{fÃ¼r mindestens ein Paar}
\end{align*}
\]

Wir schauen uns jetzt einmal die ANOVA theoretisch an bevor wir uns mit
der Anwendung der ANOVA in R beschÃ¤ftigen.

\hypertarget{einfaktoriellen-anova-theoretisch}{%
\subsection{Einfaktoriellen ANOVA
theoretisch}\label{einfaktoriellen-anova-theoretisch}}

Kommen wir zurÃ¼ck zu den Daten in Tabelle~\ref{tbl-data-anova-1}. Wenn
wir die ANOVA per Hand rechnen wollen, dann ist nicht das Long Format
die beste Wahl sondern das Wide Format. Wir haben ein balanciertes
Design vorliegen, dass heiÃt in jeder Level sind die gleiche Anzahl
Beobachtungen. Wir schauen uns jeweils sieben FlÃ¶he von jeder Tierart
an. FÃ¼r eine ANOVA ist aber ein balanciertes Design nicht notwendig, wir
kÃ¶nnen auch mit ungleichen GruppengrÃ¶Ãen eine ANOVA rechnen.

{\marginnote{\begin{footnotesize}Statt einer einfaktoriellen ANOVA
kÃ¶nnten wir auch gleich einen \texttt{pairwise.t.test()}rechnen.
Historisch ebtrachtet ist die einfaktorielle ANOVA die Visualsierung des
paarweisen t-Tests.\end{footnotesize}}}

Eien einfaktorielle ANOVA macht eigentlich keinen groÃen Sinn, wenn wir
anschlieÃend sowieso paarweise Vergleich, wie in
Kapitel~\ref{sec-posthoc} beschrieben, rechnen. Aus der Hisotrie stellte
sich die Frage, ob es sich lohnt die ganze Arbeit fÃ¼r die paarweisen
t-Tests per Hand zu rechnen. Daher wurde die ANOVA davorgeschaltet. War
die ANOVA nicht signifikant, dann konnte man sich dann auch die
Rechnerei fÃ¼r die paaweisen t-Tests sparen.

In Tabelle~\ref{tbl-fac1-wide-01} sehen wir die Daten einmal als Wide
Format dargestellt.

\hypertarget{tbl-fac1-wide-01}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-fac1-wide-01}Wide Format der Beispieldaten
\texttt{fac1\_tbl} fÃ¼r die jeweils \(j=7\) Beobachtungen fÃ¼r den Faktor
\texttt{animal}.}\tabularnewline
\toprule()
j & dog & cat & fox \\
\midrule()
\endfirsthead
\toprule()
j & dog & cat & fox \\
\midrule()
\endhead
1 & 5.7 & 3.2 & 7.7 \\
2 & 8.9 & 2.2 & 8.1 \\
3 & 11.8 & 5.4 & 9.1 \\
4 & 8.2 & 4.1 & 9.7 \\
5 & 5.6 & 4.3 & 10.6 \\
6 & 9.1 & 7.9 & 8.6 \\
7 & 7.6 & 6.1 & 10.3 \\
\bottomrule()
\end{longtable}

Wir kÃ¶nnen jetzt fÃ¼r jedes de Level den Mittelwert Ã¼ber all \(j=7\)
Beobachtungen berechnen.

\[
\begin{align*}
\bar{y}_{dog} &= 8.13 \\
\bar{y}_{cat} &= 4.74 \\
\bar{y}_{fox} &= 9.16 \\
\end{align*}
\]

Wir tuen jetzt fÃ¼r einen Moment so, als gebe es den Faktor
\texttt{animal} nicht in den Daten und schauen uns die Verteilung der
einzelnen Beobachtungen in Abbildung~\ref{fig-anova-exp-1-1} einmal an.
Wir sehen das sich die Beobachtungen von ca. 2.2cm bis 11 cm streuen.
Woher kommt nun diese Streuung bzw. Varianz? Was ist die Quelle der
Varianz? In Abbildung~\ref{fig-anova-exp-1-2} haben wir die Punkte
einmal nach dem Faktor \texttt{animal} eingefÃ¤rbt. Wir sehen, dass die
blauen Beobachtungen eher weitere SprunglÃ¤ngen haben als die grÃ¼nen
Beobachtungen. Wir gruppieren die Beobachtungen in
Abbildung~\ref{fig-anova-exp-1-3} nach dem Faktor \texttt{animal} und
sehen, dass ein Teil der Varianz der Daten von dem Faktor
\texttt{animal} ausgelÃ¶st wird.

\begin{figure*}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-1-1.pdf}

}

}

\subcaption{\label{fig-anova-exp-1-1}Die Sprungweite in {[}cm{]} ohne
den Faktor \texttt{animal} betrachtet.}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-1-2.pdf}

}

}

\subcaption{\label{fig-anova-exp-1-2}Die Sprungweite in {[}cm{]} mit den
Faktor \texttt{animal} eingefÃ¤rbt.}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-1-3.pdf}

}

}

\subcaption{\label{fig-anova-exp-1-3}Die Sprungweite in {[}cm{]} mit den
Faktor \texttt{animal} eingefÃ¤rbt und gruppiert.}
\end{minipage}%

\caption{\label{fig-anova-exp-1}Die Spungweite in {[}cm{]} in
AbhÃ¤ngigkeit von dem Faktor \texttt{animal} dargestellt.}

\end{figure*}

Gehen wir einen Schritt weiter und zeichnen einmal das globale Mittel in
die Abbildung~\ref{fig-anova-exp-5-1} von \(\bar{y}_{..} = 7.34\) und
lassen die Beobachtungen gruppiert nach dem Faktor \texttt{animal}. Wir
sehen, dass die Level des Faktors \texttt{animal} um das globale Mittel
streuen. Was ja auch bei einem Mittelwert zu erwarten ist. Wir kÃ¶nnen
jetzt in Abbildung~\ref{fig-anova-exp-5-2} die lokalen Mittel fÃ¼r die
einzelnen Level \texttt{dog}, \texttt{cat}und \texttt{fox} ergÃ¤nzen. Und
abschlieÃend in Abbildung~\ref{fig-anova-exp-5-3} die Abweichungen
\(\\beta_i\) zwischen dem globalen Mittel \(\bar{y}_{..} = 7.34\) und
den einzelnen lokalen Mittel berechnen. Die Summe der Abweichungen
\(\\beta_i\) ist \(0.79 + (-2.6) + 1.81 \approx 0\). Das ist auch zu
erwarten, den das globale Mittel muss ja per Definition als Mittelwert
gleich groÃen Abstand ``nach oben'' wie ``nach unten'' haben.

\begin{figure*}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-5-1.pdf}

}

}

\subcaption{\label{fig-anova-exp-5-1}Die Sprungweite in {[}cm{]} mit den
Faktor \texttt{animal} gruppiert und das globale Mittel
\(\bar{y}_{..} = 7.34\) ergÃ¤nzt.}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-5-2.pdf}

}

}

\subcaption{\label{fig-anova-exp-5-2}Die Sprungweite in {[}cm{]} mit den
Faktor \texttt{animal} gruppiert und die lokalen Mittel \(\bar{y}_{i.}\)
fÃ¼r jedes Level ergÃ¤nzt.}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-5-3.pdf}

}

}

\subcaption{\label{fig-anova-exp-5-3}Die Sprungweite in {[}cm{]} mit den
Faktor \texttt{animal} gruppiert und die Abweichungen \(\beta_i\)
ergÃ¤nzt.}
\end{minipage}%

\caption{\label{fig-anova-exp-5}Dotplot der Spungweite in {[}cm{]} in
AbhÃ¤ngigkeit von dem Faktor \texttt{animal}.}

\end{figure*}

Wir tragen die Werte der lokalen Mittlwerte \(\bar{y}_{i.}\) und deren
Abweichungen \(\beta_i\) vom globalen Mittelwert \(\bar{y}_{..} = 7.34\)
noch in die Tabelle~\ref{tbl-fac1-wide-02} ein. Wir sehen in diesem
Beispiel warum das Wide Format \emph{besser} ist, wenn wir die lokalen
Mittelwerte und die Abweichungen per Hand berechnen. Da wir in der
Anwendung aber \emph{nie} die ANOVA per Hand rechnen, liegen unsere
Daten immer in R als Long Format vor.

\hypertarget{tbl-fac1-wide-02}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-fac1-wide-02}Wide Format der Beispieldaten
\texttt{fac1\_tbl} fÃ¼r die jeweils \(j=7\) Beobachtungen fÃ¼r den Faktor
\texttt{animal}. Wir ergÃ¤nzen die lokalen Mittlwerte \(\bar{y}_{i.}\)
und deren Abweichungen \(\beta_i\) vom globalen Mittelwert
\(\bar{y}_{..} = 7.34\).}\tabularnewline
\toprule()
j & dog & cat & fox \\
\midrule()
\endfirsthead
\toprule()
j & dog & cat & fox \\
\midrule()
\endhead
1 & 5.7 & 3.2 & 7.7 \\
2 & 8.9 & 2.2 & 8.1 \\
3 & 11.8 & 5.4 & 9.1 \\
4 & 8.2 & 4.1 & 9.7 \\
5 & 5.6 & 4.3 & 10.6 \\
6 & 9.1 & 7.9 & 8.6 \\
7 & 7.6 & 6.1 & 10.3 \\
\(\bar{y}_{i.}\) & \(8.13\) & \(4.74\) & \(9.16\) \\
\(\beta_i\) & \(-2.6\) & \(0.79\) & \(1.81\) \\
\bottomrule()
\end{longtable}

Wie kriegen wir nun die ANOVA rechnerisch auf die StraÃe? Schauen wir
uns dazu einmal die Abbildung~\ref{fig-anova-exp-6} an. Auf der linken
Seiten sehen wir vier Gruppen, die keinen Effekt haben. Die Gruppen
liegen alle auf der gleichen HÃ¶he. Es ist mit keinem Unterschied
zwischen den Gruppen zu rechnen. Alle Gruppen\emph{mittel} liegen auf
dem globalen Mittel. Die Abweichungen der einzelnen Gruppen\emph{mittel}
zum globalen Mittel ist damit gleich null. Auf der rechten Seite sehen
wir vier Gruppen mit einem Effekt. Die Gruppen unterscheiden sich in
ihren Gruppen\emph{mitteln}. Dadurch unterscheide sich aber auch die
Gruppen\emph{mittel} von dem globalen Mittel.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-6-1.pdf}

}

}

\subcaption{\label{fig-anova-exp-6-1}Kein Effekt}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-exp-6-2.pdf}

}

}

\subcaption{\label{fig-anova-exp-6-2}Leichter bis mittlerer Effekt}
\end{minipage}%

\caption{\label{fig-anova-exp-6}Darstellung von keinem Effekt und
leichtem bis mittleren Effekt in einer einfaktoriellen ANOVA mit einem
Faktor mit vier Leveln A - D.}

\end{figure*}

Wir kÃ¶nnen daher wie in Tabelle~\ref{tbl-sum-anova-eff} geschrieben die
Funktionsweise der ANOVA zusammenfassen.

\hypertarget{tbl-sum-anova-eff}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2800}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0500}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.6700}}@{}}
\caption{\label{tbl-sum-anova-eff}Zusammenfassung der ANOVA
Funktionsweise.}\tabularnewline
\toprule()
\endhead
All level means are equal. & = & The differences between level means and
the total mean are small. \\
\bottomrule()
\end{longtable}

Nun kommen wir zum eigentlichen Schwenk und warum eigentlich die ANOVA
meist etwas verwirrt. Wir wollen eine Aussage Ã¼ber die Mittelwerte
machen. Die Nullhypothese lautet, dass alle Mittelwerte gleich sind. Wie
wir in Tabelle~\ref{tbl-sum-anova-eff} sagen, heiÃt alle Mittelwerte
gleich auch, dass die Abweichungen von den Gruppenmitteln zum globalen
Mittel klein ist.

Wie weit die Gruppenmittel von dem globalen Mittel weg sind, dazu nutzt
die ANOVA die Varianz. Die ANOVA vergleicht somit

\begin{itemize}
\tightlist
\item
  die Varianz der einzelnen Mittelwerte der (Gruppen)Level zum globalen
  Mittel (eng. \emph{variability between levels})
\item
  und die Varianz der Beobachtungen zu den einzelnen Mittelwerten der
  Level (eng. \emph{variability within one level})
\end{itemize}

{\marginnote{\begin{footnotesize}Die \emph{sum of squares} sind nichts
anderes als die Varianz. Wir nennen das hier nur einmal
anders\ldots{}\end{footnotesize}}}

Wir berechnen also wie die Beobachtungen jeweils um das globale Mittel
streuen (\(SS_{total}\)), die einzelnen Beobachtungen um die einzelnen
Gruppenmittel \(SS_{error}\) und die Streuung der Gruppenmittel um das
globale Mittel (\(SS_{animal}\)). Wir nennen die Streuung
Abstandquadrate (eng. \emph{sum of squares}) und damit sind die
\emph{Sum of Square} \((SS)\) nichts anderes als die Varianz. Die
Tabelle~\ref{tbl-sumsquares} zeigt die Berechnung des Anteils jeder
einzlenen Beobachtung an den jeweiligen \emph{Sum of Squares}.

\begin{figure*}

\hypertarget{tbl-sumsquares}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0857}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1214}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2071}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1929}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1929}}@{}}
\caption{\label{tbl-sumsquares}Berechnung der \(SS_{animal}\),
\(SS_{error}\) und \(SS_{total}\) anhand der einzelnen gemessenen Werte
\(y\) fÃ¼r durch die jeweiligen Gruppenmittel \(\bar{y}_{i.}\) und dem
globalen Mittel \(\bar{y}_{..}\) Ã¼ber alle Beobachtungen}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
animal (x)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length (y)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\bar{y}_{i.}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{animal}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{error}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{total}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
animal (x)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length (y)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\bar{y}_{i.}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{animal}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{error}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
SS\(_{\boldsymbol{total}}\)
\end{minipage} \\
\midrule()
\endhead
dog & \(5.7\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((5.7 - 8.13)^2 = 5.90\) & \((5.7 - 7.34)^2 = 2.69\) \\
dog & \(8.9\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((8.9 - 8.13)^2 = 0.59\) & \((8.9 - 7.34)^2 = 2.43\) \\
dog & \(11.8\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((11.8 - 8.13)^2 = 13.47\) & \((11.8 - 7.34)^2 = 19.89\) \\
dog & \(8.2\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((8.2 - 8.13)^2 = 0.00\) & \((8.2 - 7.34)^2 = 0.74\) \\
dog & \(5.6\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((5.6 - 8.13)^2 = 6.40\) & \((5.6 - 7.34)^2 = 3.03\) \\
dog & \(9.1\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((9.1 - 8.13)^2 = 0.94\) & \((9.1 - 7.34)^2 = 3.10\) \\
dog & \(7.6\) & \(8.13\) & \((8.13 - 7.34)^2 = 0.62\) &
\((7.6 - 8.13)^2 = 0.28\) & \((7.6 - 7.34)^2 = 0.07\) \\
cat & \(3.2\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((3.2 - 4.74)^2 = 2.37\) & \((3.2 - 7.34)^2 = 17.14\) \\
cat & \(2.2\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((2.2 - 4.74)^2 = 6.45\) & \((2.2 - 7.34)^2 = 26.42\) \\
cat & \(5.4\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((5.4 - 4.74)^2 = 0.44\) & \((5.4 - 7.34)^2 = 3.76\) \\
cat & \(4.1\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((4.1 - 4.74)^2 = 0.41\) & \((4.1 - 7.34)^2 = 10.50\) \\
cat & \(4.3\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((4.3 - 4.74)^2 = 0.19\) & \((4.3 - 7.34)^2 = 9.24\) \\
cat & \(7.9\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((7.9 - 4.74)^2 = 9.99\) & \((7.9 - 7.34)^2 = 0.31\) \\
cat & \(6.1\) & \(4.74\) & \((4.74 - 7.34)^2 = 6.76\) &
\((6.1 - 4.74)^2 = 1.85\) & \((6.1 - 7.34)^2 = 1.54\) \\
fox & \(7.7\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((7.7 - 9.16)^2 = 2.13\) & \((7.7 - 7.34)^2 = 0.13\) \\
fox & \(8.1\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((8.1 - 9.16)^2 = 1.12\) & \((8.1 - 7.34)^2 = 0.58\) \\
fox & \(9.1\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((9.1 - 9.16)^2 = 0.00\) & \((9.1 - 7.34)^2 = 3.10\) \\
fox & \(9.7\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((9.7 - 9.16)^2 = 0.29\) & \((9.7 - 7.34)^2 = 5.57\) \\
fox & \(10.6\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((10.6 - 9.16)^2 = 2.07\) & \((10.6 - 7.34)^2 = 10.63\) \\
fox & \(8.6\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((8.6 - 9.16)^2 = 0.31\) & \((8.6 - 7.34)^2 = 1.59\) \\
fox & \(10.3\) & \(9.16\) & \((9.16 - 7.34)^2 = 3.31\) &
\((10.3 - 9.16)^2 = 1.30\) & \((10.3 - 7.34)^2 = 8.76\) \\
& & & \(74.68\) & \(56.53\) & \(131.21\) \\
\bottomrule()
\end{longtable}

\end{figure*}

Die ANOVA wird deshalb auch Varianz\emph{zerlegung} genannt, da die
ANOVA versucht den Abstand der Beoabchtungen auf die Variablen im Modell
zu zerlegen. Also wieviel der Streuung von den Beobachtungen kann von
dem Faktor \texttt{animal} erklÃ¤rt werden? Genau der Abstand von den
Gruppenmitteln zu dem globalen Mittlelwert.

Du kannst dir das ungefÃ¤hr als eine Reise von globalen Mittelwert zu der
einzelnen Beobachtung vorstellen. Nehmen wir als Beispiel die kleinste
Sprungweite eines KatzenflÃ¶hes von 2.2 cm und visualisieren wir uns die
Reise wie in Abbildung~\ref{fig-single-cat-anova} zu sehen. Wie kommen
wir jetzt \emph{numerisch} vom globalen Mittel mit \(7.34\) zu der
Beobachtung? Wir kÃ¶nnen zum einen den direkten Abstand mit
\(2.2 - 7.34\) gleich \(-5.14\) cm berechnen. Das wÃ¤re der \emph{total}
Abstand. Wie sieht es nun aus, wenn wir das Gruppenmittel mit beachten?
In dem Fall gehen wir vom globalen Mittel zum Gruppenmittel \texttt{cat}
mit \(\bar{y}_{cat} - \bar{y}_{..} = 4.74 -7.34\) gleich
\(\beta_{cat} = -2.6\) cm. Jetzt sind wir aber noch nicht bei der
Beobachtung. Wir haben noch einen Rest von
\(y_{cat,2} - \bar{y}_{cat} = 2.2 - 4.74\) gleich
\(\epsilon_{cat, 2} = -2.54\) cm, die wir noch zurÃ¼cklegen mÃ¼ssen. Das
heiÃt, wir kÃ¶nnen einen Teil der Strecke mit dem Gruppenmittelwert
erklÃ¤ren. Oder anders herum, wir kÃ¶nnen die Strecke vom globalen
Mittelwert zu der Beobachtung in einen Teil fÃ¼r das Gruppenmittel und
einen unerklÃ¤rten Rest zerlegen.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/anova-pre-01.png}

}

\caption{\label{fig-single-cat-anova}Visualisierung der Varianzzerlegung
des Weges vom globalen Mittel zu der einzelnen Beoabchtung. Um zu einer
einzelnen Beobachtung zu kommen legen wir den Weg vom globalen
Mittelwert Ã¼ber den Abstand vom globalen Mittel zum Gruppenmittel
\(\beta\) zurÃ¼ck. Dann fehlt noch der Rest oder Fehler oder Residuum
\(\epsilon\).}

\end{figure*}

Wir rechnen also eine ganze Menge an AbstÃ¤nden und quadrieren dann diese
AbsatÃ¤nde zu den Sum of Squares. Oder eben der Varianz. Dann fragen wir
uns, ob der Faktor in unserem Modell einen Teil der AbstÃ¤nde erklÃ¤ren
kann. Wir bauen uns dafÃ¼r eine ANOVA Tabelle.
Tabelle~\ref{tbl-anova-fac1-theo} zeigt eine theoretische,
einfaktorielle ANOVA Tabelle. Wir berechnen zuerst die AbstÃ¤nde als
\(SS\). Nun ist es aber so, dass wenn wir in einer Gruppe viele Level
und/oder Beoabchtungen haben, wir auch grÃ¶Ãere Sum of Squares bekommen.
Wir mÃ¼ssen also die Sum of Squares in mittlere Abweichungsqudrate (eng.
\emph{mean squares}) mitteln. AbschlieÃend kÃ¶nnen wir die F Statistik
berechnen, indem wir die \(MS\) des Faktors durch die \(MS\) des Fehlers
teilen. Das VerhÃ¤ltnis von erklÃ¤rter Varianz vom Faktor zu dem
unerklÃ¤rten Rest.

\begin{figure*}

\hypertarget{tbl-anova-fac1-theo}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0824}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0385}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3956}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2308}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2527}}@{}}
\caption{\label{tbl-anova-fac1-theo}Einfaktorielle ANOVA in der
theoretischen Darstellung. Die sum of squares mÃ¼ssen noch zu den Mean
squares gemittelt werden. AbschlieÃend wird die F Statistik als
PrÃ¼fgrÃ¶Ãe berechnet.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(k-1\) &
\(SS_{animal} = \sum_{i=1}^{k}n_i(\bar{y}_{i.} - \bar{y}_{..})^2\) &
\(MS_{animal} = \cfrac{SS_{animal}}{k-1}\) &
\(F_{calc} = \cfrac{MS_{animal}}{MS_{error}}\) \\
error & \(n-k\) &
\(SS_{error} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{i.})^2\)
& \(MS_{error} = \cfrac{SS_{error}}{N-k}\) & \\
total & \(n-1\) &
\(SS_{total} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{..})^2\)
& & \\
\bottomrule()
\end{longtable}

\end{figure*}

Wir fÃ¼llen jetzt die Tabelle~\ref{tbl-anova-fac1-example} einmal mit den
Werten aus. Nachdem wir das getan haben oder aber die Tabelle in R
ausgegeben bekommen haben, kÃ¶nnen wir die Zahlen interpretieren.

\begin{figure*}

\hypertarget{tbl-anova-fac1-example}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1136}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0606}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1742}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3182}}@{}}
\caption{\label{tbl-anova-fac1-example}Einfaktorielle ANOVA mit den
ausgefÃ¼llten Werten. Die \(SS_{total}\) sind die Summe der
\(SS_{animal}\) und \(SS_{error}\). Die \(MS\) berechnen sich dan direkt
aus den \(SS\) und den Freiheitsgraden (\(df\)). AbschlieÃend ergibt
sich dann die F Statistik.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(3-1\) & \(SS_{animal} = 74.68\) &
\(MS_{animal} = \cfrac{74.68}{3-1} = 37.34\) &
\(F_{calc} = \cfrac{37.34}{3.14} = 11.89\) \\
error & \(21-3\) & \(SS_{error} = 56.53\) &
\(MS_{error} = \cfrac{56.53}{18} = 3.14\) & \\
total & \(21-1\) & \(SS_{total} = 131.21\) & & \\
\bottomrule()
\end{longtable}

\end{figure*}

Zu erst ist die berechnete F Statistik \(F_{calc}\) von Interesse. Wir
haben hier eine \(F_{calc}\) von 11.89. Wir vergleichen wieder die
berechnete F Statistik mit einem kritsichen Wert. Der kritische F Wert
\(F_{\alpha = 5\%}\) lautet fÃ¼r die einfaktorielle ANOVA in diesem
konkreten Beispiel mit \(F_{\alpha = 5\%} = 3.55\). Die
Enstscheidungsregel nach der F Testatitik lautet, die \(H_0\)
abzulehnen, wenn \(F_{calc} > F_{\alpha = 5\%}\).

Wir kÃ¶nnen also die Nullhypothese \(H_0\) in unserem Beispiel ablehnen.
Es liegt ein signifikanter Unterschied zwischen den Tiergruppen vor.
Mindestens ein Mittelwertsunterschied in den Sprungweiten liegt vor.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit der berechneten Teststatistik \(F_{\boldsymbol{calc}}\)}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung mit der berechneten Teststatistik \(F_{calc}\)
gilt, wenn \(F_{calc} \geq F_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt.

\textbf{Achtung --} Wir nutzen die Entscheidung mit der Teststatistik
\emph{nur und ausschlieÃlich} in der Klausur. In der praktischen
Anwendung hat die Betrachtung der berechneten Teststatistik \emph{keine}
Verwendung mehr.
\end{tcolorbox}

\hypertarget{einfaktoriellen-anova-in-r}{%
\subsection{Einfaktoriellen ANOVA in
R}\label{einfaktoriellen-anova-in-r}}

{\marginnote{\begin{footnotesize}Um eine ANOVA zu rechnen nutzen wir
\emph{zuerst} die Funktion \texttt{lm()}, warum das so ist kannst du im
Kapitel~\ref{sec-modeling-simple-stat} nachlesen. Du brauchst das Wissen
aber hier nicht unbedingt.\end{footnotesize}}}

Wir rechnen keine ANOVA per Hand sondern nutzen R. Dazu mÃ¼ssen wir als
erstes das Modell definieren. Das ist im Falle der infaktoriellen ANOVA
relativ einfach. Wir haben unseren Datensatz \texttt{fac1\_tbl} mit
einer kontinuierlichen Variable \texttt{jump\_lemgth} als \(y\)
vorliegen sowie einen Faktor \texttt{animal} mit mehr als zwei Leveln
als \(x\). Wir definieren das Modell in R in der Form
\texttt{jump\_length\ \textasciitilde{}\ animal}. Um das Modell zu
rechnen nutzen wir die Funktion \texttt{lm()} - die AbkÃ¼rzung fÃ¼r
\emph{linear model}. Danach pipen wir die Ausgabe vom \texttt{lm()}
direkt in die Funktion \texttt{anova()}. Die Funktion \texttt{anova}
berechnet uns dann die eigentliche einfaktorielle ANOVA. Wir speichern
die Ausgabe der ANOVA in \texttt{fit\_1}. Schauen wir uns die ANOVA
Ausgabe einmal an.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}}  \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  anova}

\NormalTok{fit\_1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: jump_length
          Df  Sum Sq Mean Sq F value     Pr(>F)    
animal     2 74.6829 37.3414 11.8904 0.00051129 ***
Residuals 18 56.5286  3.1405                       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Wir erhalten die Information was wir gerechnet haben, eine
Varianzanalyse. Darunter steht, was das \(y\) war nÃ¤mlich die
\texttt{jump\_length}. Wir erhalten eine Zeile fÃ¼r den Faktor
\texttt{animal} und damit die \(SS_{animal}\) und eine Zeile fÃ¼r den
Fehler und damit den \(SS_{error}\). In R heiÃen die \(SS_{error}\) dann
\texttt{Residuals}. Die Zeile fÃ¼r die \(SS_{total}\) fehlt.

Neben der berechneten F Statistik \(F_{calc}\) von \(11.89\) erhalten
wir auch den p-Wert mit \(0.005\). Wir ignorieren die F Statistik, da
wir in der Anwendung nur den p-Wert berÃ¼cksichtigen. Die Entscheidung
gegen die Nulhypothese lautet, dass wenn der p-Wert kleiner ist als das
Signifkanzniveau \(\alpha\) von 5\% wir die Nullhypothese ablehnen.

Wir haben hier ein signifikantes Ergebnis vorliegen. Mindestens ein
Gruppenmittelerstunterschied ist signifikant.
Abbildung~\ref{fig-boxplot-anova-1} zeigt nochmal die Daten
\texttt{fac1\_tbl} als Boxplot. Wir Ã¼berprÃ¼fen visuell, ob das Ergebnis
der ANOVA stimmen kann. Ja, die Boxplots und das Ergebnis der ANOVA
stimmen Ã¼berein. Die Boxplots liegen nicht alle auf einer Ebene, so dass
hier auch ein signifikanter Unterschied zu erwarten war.

\begin{figure}

{\centering \includegraphics{./stat-tests-anova_files/figure-pdf/fig-boxplot-anova-1-1.pdf}

}

\caption{\label{fig-boxplot-anova-1}Boxplot der Sprungweiten {[}cm{]}
von Hunden-, Katzen- und FuchsflÃ¶hen.}

\end{figure}

AbschlieÃend kÃ¶nnen wir noch die Funktion \texttt{eta\_squared()} aus
dem R Paket \texttt{effectsize} nutzen um einen EffektschÃ¤tzer fÃ¼r die
einfaktorielle ANOVA zu berechnen. Wir kÃ¶nnen mit \(\eta^2\) abschÃ¤tzen,
welchen Anteil der Faktor \texttt{animal} an der gesamten Varianz
erklÃ¤rt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ eta\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
For one-way between subjects designs, partial eta squared is equivalent to eta squared.
Returning eta squared.
\end{verbatim}

\begin{verbatim}
# Effect Size for ANOVA

Parameter | Eta2 |       95% CI
-------------------------------
animal    | 0.57 | [0.27, 1.00]

- One-sided CIs: upper bound fixed at [1.00].
\end{verbatim}

Das \(\eta^2\) kÃ¶nnen wir auch einfach hÃ¤ndisch berechnen.

\[
\eta^2 = \cfrac{SS_{animal}}{SS_{total}} = \cfrac{74.68}{131.21} = 0.57 = 57\%
\]

Wir haben nun die Information, das 57\% der Varianz der Beobachtungen
durch den Faktor \texttt{animal} rklÃ¤rt wird. Je nach Anwendungsgebiet
kann die Relevanz sehr stark variieren. Im Bereich der ZÃ¼chtung mÃ¶gen
erklÃ¤rte Varianzen von unter 10\% noch sehr relevant sein. Im Bereich
des Feldexperiments erwarten wir schon hÃ¶here Werte fÃ¼r \(\eta^2\).
Immerhin sollte ja unsere Behandlung maÃgeblich fÃ¼r die z.B. grÃ¶Ãeren
oder kleineren Pflanzen gesorgt haben.

\hypertarget{sec-fac2}{%
\section{Zweifaktorielle ANOVA}\label{sec-fac2}}

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Die zweifaktorielle ANOVA verlangt ein normalverteiltes \(y\) sowie
VarianzhomogenitÃ¤t jeweils separat Ã¼ber beide Behandlungsfaktor \(x_1\)
und \(x_2\). Daher alle Level von \(x_1\) sollen die gleiche Varianz
haben. Ebenso sollen alle Level von \(x_2\) die gleiche Varianz haben.

Unsere Annahme an die Daten \(D\) ist, dass das dein \(y\)
normalverteilt ist und das die Level vom \(x_1\) und \(x_2\) jewiels fÃ¼r
sich homogen in den Varianzen sind. SpÃ¤ter mehr dazu, wenn wir beides
nicht vorliegen haben\ldots{}

Die zweifaktorielle ANOVA ist eine wunderbare Methode um herauszufinden,
ob zwei Faktoren einen Einfluss auf ein normalverteiltes \(y\) haben.
Die StÃ¤rke der zweifaktoriellen ANOVA ist hierbei, dass die ANOVA
\emph{beide} Effekte der Faktoren auf das \(y\) simultan modelliert.
DarÃ¼ber hinaus kÃ¶nnen wir auch noch einen Interaktionsterm mit in das
Modell aufnehmen um zu schauen, ob die beiden Faktoren untereinander
auch interagieren. Somit haben wir mit der zweifaktoriellen ANOVA die
Auswertungsmehode fÃ¼r ein randomiziertes Blockdesign vorliegen.

\hypertarget{daten-fuxfcr-die-zweifaktorielle-anova}{%
\subsection{Daten fÃ¼r die zweifaktorielle
ANOVA}\label{daten-fuxfcr-die-zweifaktorielle-anova}}

Wir wollen uns nun einen etwas komplexes Modell anschauen mit einem
etwas komplizierteren Datensatz \texttt{flea\_dog\_cat\_fox\_site.csv}.
Wir brauchen hierfÃ¼r ein normalverteiltes \(y\) und sowie zwei Faktoren.
Das macht auch soweit Sinn, denn wir wollen ja auch eine zweifaktorielle
ANOVA rechnen.

Im Folgenden selektieren mit der Funktion \texttt{select()} die beiden
Spalten \texttt{jump\_length} als \(y\) und die Spalte \texttt{animal}
sowie die Spalte \texttt{site} als \(x\). Danach mÃ¼ssen wir noch die
Variable \texttt{animal} sowie die Variable \texttt{site} in einen
Faktor mit der Funktion \texttt{as\_factor()} umwandeln.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac2\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox\_site.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, site, jump\_length) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal),}
         \AttributeTok{site =} \FunctionTok{as\_factor}\NormalTok{(site))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{fac2\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-anova-2} nochmal dargestellt.

\hypertarget{tbl-data-anova-2}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-anova-2}Selektierter Datensatz fÃ¼r die
zweifaktorielle ANOVA mit einer normalverteilten Variable
\texttt{jump\_length} und einem Faktor \texttt{animal} mit drei Leveln
sowie dem Faktor \texttt{site} mit vier Leveln.}\tabularnewline
\toprule()
animal & site & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & site & jump\_length \\
\midrule()
\endhead
cat & city & 12.04 \\
cat & city & 11.98 \\
cat & city & 16.10 \\
cat & city & 13.42 \\
cat & city & 12.37 \\
cat & city & 16.36 \\
cat & city & 14.91 \\
cat & city & 11.17 \\
cat & city & 12.38 \\
cat & city & 15.06 \\
cat & smalltown & 15.24 \\
cat & smalltown & 13.36 \\
cat & smalltown & 15.08 \\
cat & smalltown & 12.83 \\
cat & smalltown & 14.68 \\
cat & smalltown & 10.73 \\
cat & smalltown & 13.35 \\
cat & smalltown & 14.54 \\
cat & smalltown & 12.99 \\
cat & smalltown & 14.51 \\
cat & village & 17.59 \\
cat & village & 11.24 \\
cat & village & 12.44 \\
cat & village & 13.63 \\
cat & village & 14.92 \\
cat & village & 17.43 \\
cat & village & 18.30 \\
cat & village & 16.35 \\
cat & village & 16.34 \\
cat & village & 14.23 \\
cat & field & 13.70 \\
cat & field & 15.13 \\
cat & field & 17.99 \\
cat & field & 14.60 \\
cat & field & 16.16 \\
cat & field & 14.26 \\
cat & field & 15.39 \\
cat & field & 16.85 \\
cat & field & 19.02 \\
cat & field & 18.76 \\
dog & city & 19.35 \\
dog & city & 17.10 \\
dog & city & 19.85 \\
dog & city & 15.33 \\
dog & city & 15.15 \\
dog & city & 19.57 \\
dog & city & 15.44 \\
dog & city & 16.09 \\
dog & city & 15.91 \\
dog & city & 13.01 \\
dog & smalltown & 17.72 \\
dog & smalltown & 17.11 \\
dog & smalltown & 17.57 \\
dog & smalltown & 17.12 \\
dog & smalltown & 16.02 \\
dog & smalltown & 22.61 \\
dog & smalltown & 16.49 \\
dog & smalltown & 18.64 \\
dog & smalltown & 17.21 \\
dog & smalltown & 19.90 \\
dog & village & 16.60 \\
dog & village & 15.28 \\
dog & village & 16.91 \\
dog & village & 15.08 \\
dog & village & 18.56 \\
dog & village & 16.34 \\
dog & village & 17.61 \\
dog & village & 14.80 \\
dog & village & 17.52 \\
dog & village & 16.93 \\
dog & field & 15.78 \\
dog & field & 17.02 \\
dog & field & 15.41 \\
dog & field & 15.61 \\
dog & field & 19.87 \\
dog & field & 19.24 \\
dog & field & 17.65 \\
dog & field & 18.83 \\
dog & field & 17.60 \\
dog & field & 14.67 \\
fox & city & 19.50 \\
fox & city & 18.49 \\
fox & city & 19.78 \\
fox & city & 19.45 \\
fox & city & 21.56 \\
fox & city & 21.37 \\
fox & city & 18.64 \\
fox & city & 20.08 \\
fox & city & 21.62 \\
fox & city & 20.68 \\
fox & smalltown & 19.81 \\
fox & smalltown & 17.78 \\
fox & smalltown & 19.65 \\
fox & smalltown & 16.38 \\
fox & smalltown & 17.46 \\
fox & smalltown & 17.02 \\
fox & smalltown & 19.38 \\
fox & smalltown & 15.89 \\
fox & smalltown & 17.15 \\
fox & smalltown & 17.43 \\
fox & village & 15.32 \\
fox & village & 17.59 \\
fox & village & 15.70 \\
fox & village & 18.58 \\
fox & village & 16.85 \\
fox & village & 18.25 \\
fox & village & 18.75 \\
fox & village & 16.96 \\
fox & village & 13.38 \\
fox & village & 18.38 \\
fox & field & 16.85 \\
fox & field & 13.55 \\
fox & field & 13.89 \\
fox & field & 15.67 \\
fox & field & 16.38 \\
fox & field & 14.59 \\
fox & field & 14.03 \\
fox & field & 13.63 \\
fox & field & 14.09 \\
fox & field & 15.52 \\
\bottomrule()
\end{longtable}

Die Beispieldaten sind in Abbildung~\ref{fig-boxplot-anova-2}
abgebildet. Wir sehen auf der x-Achse den Faktor \texttt{animal} mit den
drei Leveln \texttt{dog}, \texttt{cat} und \texttt{fox}. Jeder dieser
Faktorlevel hat nochmal einen Faktor in sich. Dieser Faktor lautet
\texttt{site} und stellt dar, wo die FlÃ¶he gesammelt wurden. Die vier
Level des Faktors \texttt{site} sind \texttt{city}, \texttt{smalltown},
\texttt{village} und \texttt{field}.

\begin{figure}

{\centering \includegraphics{./stat-tests-anova_files/figure-pdf/fig-boxplot-anova-2-1.pdf}

}

\caption{\label{fig-boxplot-anova-2}Boxplot der Sprungweiten {[}cm{]}
von Hunden und Katzen.}

\end{figure}

Wir bauen dann mit den beiden Variablen bzw. Faktoren \texttt{animal}
und \texttt{site} aus dem Objekt \texttt{fac2\_tbl} folgendes Modell fÃ¼r
die zweifaktorielle ANOVA:

\[
jump\_length \sim animal + site
\]

Bevor wir jetzt das Modell verwenden, mÃ¼ssen wir uns nochmal Ã¼berlegen,
welchen SchluÃ wir eigentlich Ã¼ber die Nullhypothese machen. Wir immer
kÃ¶nnen wir nur die Nullhypothese ablehnen. Daher Ã¼berlegen wir uns im
Folgenden wie die Nullhypothese in der zweifaktoriellen ANOVA aussieht.
Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

\hypertarget{hypothesen-fuxfcr-die-zweifaktorielle-anova}{%
\subsection{Hypothesen fÃ¼r die zweifaktorielle
ANOVA}\label{hypothesen-fuxfcr-die-zweifaktorielle-anova}}

Wir haben fÃ¼r jeden Faktor der zweifaktoriellen ANOVA ein
Hypothesenpaar. Im Folgenden sehen wir die jeweiligen Hypothesenpaare.

Einmal fÃ¼r \texttt{animal}, als Haupteffekt. Wir nennen einen Faktor den
Hauptfaktor, weil wir an diesem Faktor am meisten interessiert sind.
Wenn wir spÃ¤ter einen Posthoc Test durchfÃ¼hren wÃ¼rden, dann wÃ¼rden wir
diesen Faktor nehmen. Wir sind primÃ¤r an dem Unterschied der
Sprungweiten in {[}cm{]} in Gruppen Hund, Katze und Fuchs interessiert.

\[
\begin{align*}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{fÃ¼r mindestens ein Paar}
\end{align*}
\]

Einmal fÃ¼r \texttt{site}, als Nebeneffekt oder Blockeffekt oder
Clustereffekt. Meist eine Variable, die wir auch erhoben haben und
\emph{vermutlich} auch einen Effekt auf das \(y\) haben wird. Oder aber
wir haben durch das exprimentelle Design noch eine Aufteilungsvariable
wie Block vorliegen. In unserem Beispiel ist es \texttt{site} oder der
Ort, wo wir die Hunde-, Katzen, und FuchsflÃ¶he gefunden haben.

\[
\begin{align*}
H_0: &\; \bar{y}_{city} = \bar{y}_{smalltown} = \bar{y}_{village} = \bar{y}_{field}\\
H_A: &\; \bar{y}_{city} \ne \bar{y}_{smalltown}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{village} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \mbox{fÃ¼r mindestens ein Paar}
\end{align*}
\]

Einmal fÃ¼r die Interaktion \texttt{animal:site} - die eigentliche StÃ¤rke
der zweifaktoriellen ANOVA. Wir kÃ¶nnen uns anschauen, ob die beiden
Faktoren miteinander interagieren. Das heiÃt, ob eine Interaktion
zwischen dem Faktor \texttt{animal} und dem Faktor \texttt{site}
vorliegt.

\[
\begin{align*}
H_0: &\; \mbox{keine Interaktion}\\
H_A: &\; \mbox{eine Interaktion zwischen animal und site}
\end{align*}
\]

Wir haben also jetzt die verschiedenen Hypothesenpaare definiert und
schauen uns jetzt die ANOVA in R einmal in der Anwendung an.

\hypertarget{zweifaktoriellen-anova-in-r}{%
\subsection{Zweifaktoriellen ANOVA in
R}\label{zweifaktoriellen-anova-in-r}}

Bei der einfaktoriellen ANOVA haben wir die Berechnungen der Sum of
squares nochmal nachvollzogen. Im Falle der zweifaktoriellen ANOVA
verzichten wir darauf. Das Prinzip ist das gleiche. Wir haben nur mehr
Mitelwerte und mehr Abweichungen von diesen Mittelwerten, da wir ja
nicht nur einen Faktor \texttt{animal} vorliegen haben sondern auch noch
den Faktor \texttt{site}. Da wir aber die ANOVA nur Anwenden und dazu R
nutzen, mÃ¼ssen wir jetzt nicht per Hand die zweifaktorielle ANOVA
rechnen. Du musst aber die R Ausgabe der ANOVA verstehen. Und diese
Ausgabe schauen wir uns jetzt einmal ohne und dann mit Interaktionsterm
an.

\hypertarget{ohne-interaktionsterm}{%
\subsubsection{Ohne Interaktionsterm}\label{ohne-interaktionsterm}}

Wir wollen nun einmal die zweifaktorielle ANOVA ohne Interaktionsterm
rechnen die in Tabelle~\ref{tbl-anova-fac2-ohne-inter} dargestellt ist.
Die \(SS\) und \(MS\) fÃ¼r die zweifaktorielle ANOVA berechnen wir nicht
selber sondern nutzen die Funktion \texttt{anova()} in R.

\begin{figure*}

\hypertarget{tbl-anova-fac2-ohne-inter}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1389}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1389}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.4259}}@{}}
\caption{\label{tbl-anova-fac2-ohne-inter}Zweifaktorielle ANOVA ohne
Interaktionseffekt in der theoretischen Darstellung. Die Sum of squares
mÃ¼ssen noch zu den Mean squares gemittelt werden. AbschlieÃend wird die
F Statistik als PrÃ¼fgrÃ¶Ãe berechnet.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(a-1\) & \(SS_{animal}\) & \(MS_{animal}\) &
\(F_{calc} = \cfrac{MS_{animal}}{MS_{error}}\) \\
site & \(b-1\) & \(SS_{site}\) & \(MS_{site}\) &
\(F_{calc} = \cfrac{MS_{site}}{MS_{error}}\) \\
error & \(n-(a-1)(b-1)\) & \(SS_{error}\) & \(MS_{error}\) & \\
total & \(n-1\) & \(SS_{total}\) & & \\
\bottomrule()
\end{longtable}

\end{figure*}

{\marginnote{\begin{footnotesize}Du kannst mehr Ã¼ber Geraden sowie
lineare Modelle und deren Eigenschaften im
Kapitel~\ref{sec-modeling-simple-stat} erfahren.\end{footnotesize}}}

Im Folgenden sehen wir nochmal das Modell ohne Interaktionsterm. Wir
nutzen die Schreibweise in R fÃ¼r eine Modellformel.

\[
jump\_length \sim animal + site
\]

Wir bauen nun mit der obigen Formel ein lineares Modell mit der Funktion
\texttt{lm()} in R. Danach pipen wir das Modell in die Funktion
\texttt{anova()} wie auch in der einfaktoriellen Variante der ANOVA. Die
Funktion bleibt die Gleiche, was sich Ã¤ndert ist das Modell in der
Funktion \texttt{lm()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}}  \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ site, }\AttributeTok{data =}\NormalTok{ fac2\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  anova}

\NormalTok{fit\_2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: jump_length
           Df  Sum Sq Mean Sq  F value         Pr(>F)    
animal      2 180.033 90.0165 19.88083 0.000000039196 ***
site        3   9.126  3.0419  0.67183        0.57104    
Residuals 114 516.170  4.5278                            
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Wir erhalten wiederrum die ANOVA Ergebnistabelle. Ansatt nur die Zeile
\texttt{animal} fÃ¼r den Effekt des Faktors \texttt{animal} sehen wir
jetzt auch noch die Zeile \texttt{site} fÃ¼r den Effekt des Faktors
\texttt{site}. Zuerst ist weiterhin der Faktor \texttt{animal}
signifikant, da der \(p\)-Wert mit \(0.000000039196\) kleiner ist als
das Signifikanzniveau \(\alpha\) von 5\%. Wir kÃ¶nnen von mindestens
einem Gurppenunterschied im Faktor \texttt{animal} ausgehen. Im Weiteren
ist der Faktor \texttt{site} nicht signifikant. Es scheint keinen
Untrschied zwischend den einzelnen Orten und der SprunglÃ¤nge von den
Hunde-, Katzen- und FuchsflÃ¶hen zu geben.

Neben der Standausgabe von R kÃ¶nnen wir auch die \texttt{tidy} Variante
uns ausgeben lassen. In dem Fall sieht die Ausgabe etwas mehr aufgerÃ¤umt
aus.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 6
  term         df  sumsq meansq statistic       p.value
  <chr>     <int>  <dbl>  <dbl>     <dbl>         <dbl>
1 animal        2 180.    90.0     19.9    0.0000000392
2 site          3   9.13   3.04     0.672  0.571       
3 Residuals   114 516.     4.53    NA     NA           
\end{verbatim}

AbschlieÃend kÃ¶nnen wir uns Ã¼br \(\eta^2\) auch die erklÃ¤rten Anteile
der Varainz wiedergeben lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ eta\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Effect Size for ANOVA (Type I)

Parameter | Eta2 (partial) |       95% CI
-----------------------------------------
animal    |           0.26 | [0.15, 1.00]
site      |           0.02 | [0.00, 1.00]

- One-sided CIs: upper bound fixed at [1.00].
\end{verbatim}

Wir sehen, dass nur ein kleiner Teil der Varianz von dem Faktor
\texttt{animal} erklÃ¤rt wird, nÃ¤mlich 26\%. FÃ¼r den Faktor \texttt{site}
haben wir nur einen Anteil von 2\% der erklÃ¤rten Varianz. Somit hat die
\texttt{site} weder einen signifikanten Einflluss auf die Sprungweite
von FlÃ¶hen noch ist dieser Einfluss als relevant zu betrachten.

AbschlieÃend kÃ¶nnen wir die Werte in der
Tabelle~\ref{tbl-anova-fac2-ohne-inter-example} ergÃ¤nzen. Die Frage ist
inwieweit diese Tabelle in der Form von Interesse ist. Meist wird
geschaut, ob die Faktoren signifikant sind oder nicht. AbschlieÃend
eventuell noch die \(\eta^2\) Werte berichtet. Hier musst du schauen,
was in deinem Kontext der Forschung oder Abschlussarbeit erwartet wird.

\begin{figure*}

\hypertarget{tbl-anova-fac2-ohne-inter-example}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1230}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1475}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1967}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1885}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3443}}@{}}
\caption{\label{tbl-anova-fac2-ohne-inter-example}Zweifaktorielle Anova
ohne Interaktionseffekt mit den ausgefÃ¼llten Werten. Die \(SS_{total}\)
sind die Summe der \(SS_{animal}\) und \(SS_{error}\). Die \(MS\)
berechnen sich dan direkt aus den \(SS\) und den Freiheitsgraden
(\(df\)). AbschlieÃend ergibt sich dann die F Statistik.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(3-1\) & \(SS_{animal} = 180.03\) & \(MS_{animal} = 90.02\) &
\(F_{calc} = \cfrac{90.02}{4.53} = 19.88\) \\
site & \(4-1\) & \(SS_{site} = 9.13\) & \(MS_{site} = 3.04\) &
\(F_{calc} = \cfrac{3.04}{4.53} = 0.67\) \\
error & \(120-(3-1)(4-1)\) & \(SS_{error} = 516.17\) &
\(MS_{error} = 4.53\) & \\
total & \(120-1\) & \(SS_{total} = 705.33\) & & \\
\bottomrule()
\end{longtable}

\end{figure*}

\hypertarget{mit-interaktionssterm}{%
\subsubsection{Mit Interaktionssterm}\label{mit-interaktionssterm}}

Wir wollen nun noch einmal die zweifaktorielle ANOVA mit
Interaktionsterm rechnen, die in Tabelle~\ref{tbl-anova-fac3-inter}
dargestellt ist. Die \(SS\) und \(MS\) fÃ¼r die zweifaktorielle ANOVA
berechnen wir nicht selber sondern nutzen wie immer die Funktion
\texttt{anova()} in R.

\begin{figure*}

\hypertarget{tbl-anova-fac3-inter}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1486}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0946}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1824}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1824}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3919}}@{}}
\caption{\label{tbl-anova-fac3-inter}Zweifaktorielle ANOVA mit
Interaktionseffekt in der theoretischen Darstellung. Die Sum of squares
mÃ¼ssen noch zu den Mean squares gemittelt werden. AbschlieÃend wird die
F Statistik als PrÃ¼fgrÃ¶Ãe berechnet.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(a-1\) & \(SS_{animal}\) & \(MS_{animal}\) &
\(F_{calc} = \cfrac{MS_{animal}}{MS_{error}}\) \\
site & \(b-1\) & \(SS_{site}\) & \(MS_{site}\) &
\(F_{calc} = \cfrac{MS_{site}}{MS_{error}}\) \\
animal \(\times\) site & \((a-1)(b-1)\) & \(SS_{animal \times site}\) &
\(MS_{animal \times site}\) &
\(F_{calc} = \cfrac{MS_{animal \times site}}{MS_{error}}\) \\
error & \(n-ab\) & \(SS_{error}\) & \(MS_{error}\) & \\
total & \(n-1\) & \(SS_{total}\) & & \\
\bottomrule()
\end{longtable}

\end{figure*}

Im Folgenden sehen wir nochmal das Modell mit Interaktionsterm. Wir
nutzen die Schreibweise in R fÃ¼r eine Modellformel. Einen
Interaktionsterm bilden wir durch das \texttt{:} in R ab. Wir kÃ¶nnen
theoretisch auch noch weitere Interaktionsterme bilden, also auch
\texttt{x:y:z}. Ich wÃ¼rde aber davon abraten, da diese Interaktionsterme
schwer zu interpretieren sind.

\[
jump\_length \sim animal + site + animal:site
\]

Wir bauen nun mit der obigen Formel ein lineares Modell mit der Funktion
\texttt{lm()} in R. Es wieder das gleich wie schon zuvor. Danach pipen
wir das Modell in die Funktion \texttt{anova()} wie auch in der
einfaktoriellen Variante der ANOVA. Die Funktion bleibt die Gleiche, was
sich Ã¤ndert ist das Modell in der Funktion \texttt{lm()}. Auch die
Interaktion mÃ¼ssen wir nicht extra in der ANOVA Funktion angeben. Alles
wird im Modell des \texttt{lm()} abgebildet.

Die visuelle Regel zur ÃberprÃ¼fung der Interaktion lautet nun wie folgt.
Abbildung~\ref{fig-anova-inter-example} zeigt die entsprechende
Vislualisierung. Wir haben keine Interaktion vorliegen, wenn die Geraden
parallel zueinander laufen und die AbstÃ¤nde bei bei jedem Faktorlevel
gleich sind. Wir schauen uns im Prinzip die erste Faktorstufe auf der
x-Achse an. Wir sehen den Abstand von der roten zu blauen Linie sowie
das die blaue Gerade Ã¼ber der roten Gerade liegt. Dieses Muster erwarten
wir jetzt auch an dem Faktorlevel B und C. Eine leichte bis mittlere
Interaktion liegt vor, wenn sich die AbstaÃ¤nde von dem zweiten Fakotr
Ã¼ber die Faktorstufen des ersten Faktors Ã¤ndern. Eine starke Interaktion
liegt vor, wenn sich die Geraden schneiden.

\begin{figure*}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-inter-example-1.pdf}

}

}

\subcaption{\label{fig-anova-inter-example-1}Keine Interaktion}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-inter-example-2.pdf}

}

}

\subcaption{\label{fig-anova-inter-example-2}Leichte bis mittlere
Intraktion}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-anova_files/figure-pdf/fig-anova-inter-example-3.pdf}

}

}

\subcaption{\label{fig-anova-inter-example-3}Starke Interaktion}
\end{minipage}%

\caption{\label{fig-anova-inter-example}Darstellung von keiner
Interaktion, leichter bis mittler Interaktion und starker Interaktion in
einer zweifaktoriellen ANOVA mit einem Faktor mit drei Leveln A, B und C
sowie einem Faktor mit zwei Leveln (rot und blau).}

\end{figure*}

In der Abbildung~\ref{fig-interact-anova-1} sehen wir den
Interaktionsplot fÃ¼r unser Beispiel. Auf der y-Achse ist die SprunglÃ¤nge
abgebildet und auf der x-Achse der Faktor \texttt{animal}. Die einzelnen
Farben stellen die Level des Faktor \texttt{site} dar.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(fac2\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ animal, }\AttributeTok{y =}\NormalTok{ jump\_length,}
                     \AttributeTok{color =}\NormalTok{ site, }\AttributeTok{group =}\NormalTok{ site)) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ mean, }\AttributeTok{geom =} \StringTok{"point"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ mean, }\AttributeTok{geom =} \StringTok{"line"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-anova_files/figure-pdf/fig-interact-anova-1-1.pdf}

}

\caption{\label{fig-interact-anova-1}Boxplot der Sprungweiten {[}cm{]}
von Hunden und Katzen.}

\end{figure}

{\marginnote{\begin{footnotesize}Wenn sich die Geraden in einem
Interaktionsplot schneiden, haben wir eine Interaktion zwischen den
beiden Faktoren vorliegen\end{footnotesize}}}

Wir schauen zur visuellen ÃberprÃ¼fung auf den Faktor \texttt{animal} und
das erste level \texttt{cat}. Wir sehen die Ordnung des zweiten Faktors
\texttt{site} mit \texttt{field}, \texttt{village}, \texttt{smalltown}
und \texttt{city}. Diese Ordnung und die AbstÃ¤nde sind bei zweiten
Faktorlevel \texttt{dog} schon nicht mehr gegeben. Die Geraden schneiden
sich. Auch liegt bei dem Level \texttt{fox} eine andere ordnung vor.
Daher sehen wir hier eine starke Interaktion zwischen den beiden
Faktoren \texttt{animal} und \texttt{site}.

{\marginnote{\begin{footnotesize}Du kannst mehr Ã¼ber Geraden sowie
lineare Modelle und deren Eigenschaften im
Kapitel~\ref{sec-modeling-simple-stat} erfahren.\end{footnotesize}}}

Wir nehmen jetzt auf jeden Fall den Interaktionsterm
\texttt{animal:site} mit in unser Modell und schauen uns einmal das
Ergebnis der ANOVA an. Das lineare Modell der ANOVA wird erneut Ã¼ber die
Funktion \texttt{lm()} berechnet und anschlieÃend in die Funktion
\texttt{anova()} gepipt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\OtherTok{\textless{}{-}}  \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ site }\SpecialCharTok{+}\NormalTok{ animal}\SpecialCharTok{:}\NormalTok{site, }\AttributeTok{data =}\NormalTok{ fac2\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  anova}

\NormalTok{fit\_3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: jump_length
             Df  Sum Sq Mean Sq  F value            Pr(>F)    
animal        2 180.033 90.0165 30.28074 0.000000000036302 ***
site          3   9.126  3.0419  1.02327           0.38536    
animal:site   6 195.115 32.5191 10.93914 0.000000001709866 ***
Residuals   108 321.055  2.9727                               
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

{\marginnote{\begin{footnotesize}Wenn wir eine signifikante Interaktion
vorliegen haben, dann mÃ¼ssen wir den Faktor A getrennt fÃ¼r jedes Levels
des Faktors B auswerten.\end{footnotesize}}}

Die Ergebnistabelle der ANOVA wiederholt sich. Wir sehen, dass der
Faktor \texttt{animal} signifkant ist, da der p-Wert mit
\(0.000000000036\) kleiner ist als das Signifikanzniveau \(\alpha\) von
5\%. Wir kÃ¶nnen daher die Nullhypothese ablehnen. Mindestens ein
Mittelwertsvergleich unterschiedet sich zwischen den Levels des Faktors
\texttt{animal}. Im Weiteren sehen wir, dass der Faktor \texttt{site}
nicht signifkant ist, da der p-Wert mit \(0.39\) grÃ¶Ãer ist als das
Signifikanzniveau \(\alpha\) von 5\%. Wir kÃ¶nnen daher die Nullhypothese
nicht ablehnen. AbschlieÃend finden wir die Interaktion zwischen dem
Faktor \texttt{animal}und \texttt{site} las signifkant vor. Wenn wir
eine signifikante Interaktion vorliegen haben, dann mÃ¼ssen wir den
Faktor \texttt{animal} getrennt fÃ¼r jedes Levels des Faktors
\texttt{site} auswerten. Wir kÃ¶nnen keine Aussage Ã¼ber die Sprungweite
von Hunde-, Katzen- und FuchsflÃ¶hen \emph{unabhÃ¤ngig} von der Herkunft
\texttt{site} der FlÃ¶he machen.

{\marginnote{\begin{footnotesize}In Kapitel XX findest du ein Beispiel
fÃ¼r eine signifikante Interaktion und die folgende
Auswertung\end{footnotesize}}}

Wir kÃ¶nnen wie immer die etwas aufgerÃ¤umte Variante der ANOVA Ausgabe
mit der Funktion \texttt{tidy()} uns ausgeben lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 6
  term           df  sumsq meansq statistic   p.value
  <chr>       <int>  <dbl>  <dbl>     <dbl>     <dbl>
1 animal          2 180.    90.0      30.3   3.63e-11
2 site            3   9.13   3.04      1.02  3.85e- 1
3 animal:site     6 195.    32.5      10.9   1.71e- 9
4 Residuals     108 321.     2.97     NA    NA       
\end{verbatim}

Im Folgenden kÃ¶nnen wir noch die \(\eta^2\) fÃ¼r die ANOVA als
EffektschÃ¤tzer berechnen lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ eta\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Effect Size for ANOVA (Type I)

Parameter   | Eta2 (partial) |       95% CI
-------------------------------------------
animal      |           0.36 | [0.24, 1.00]
site        |           0.03 | [0.00, 1.00]
animal:site |           0.38 | [0.24, 1.00]

- One-sided CIs: upper bound fixed at [1.00].
\end{verbatim}

Wir sehen, dass nur ein kleiner Teil der Varianz von dem Faktor
\texttt{animal} erklÃ¤rt wird, nÃ¤mlich 36\%. FÃ¼r den Faktor \texttt{site}
haben wir nur einen Anteil von 3\% der erklÃ¤rten Varianz. Die
Interaktion zwischen \texttt{animal} und \texttt{site} erklÃ¤rt 38\% der
beobachteten Varianz udn ist somit auch vom Effekt her nicht zu
ignorieren. Somit hat die \texttt{site} weder einen signifikanten
Einflluss auf die Sprungweite von FlÃ¶hen noch ist dieser Einfluss als
relevant zu betrachten.

AbschlieÃend kÃ¶nnen wir die Werte in der
Tabelle~\ref{tbl-anova-fac3-inter-example} ergÃ¤nzen. Die Frage ist
inwieweit diese Tabelle in der Form von Interesse ist. Meist wird
geschaut, ob die Faktoren signifikant sind oder nicht. AbschlieÃend
eventuell noch die \(\eta^2\) Werte berichtet. Hier musst du schauen,
was in deinem Kontext der Forschung oder Abschlussarbeit erwartet wird.

\begin{figure*}

\hypertarget{tbl-anova-fac3-inter-example}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1410}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1346}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2308}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2244}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2692}}@{}}
\caption{\label{tbl-anova-fac3-inter-example}Zweifaktorielle Anova mit
Interaktionseffekt mit den ausgefÃ¼llten Werten. Die \(SS_{total}\) sind
die Summe der \(SS_{animal}\) und \(SS_{error}\). Die \(MS\) berechnen
sich dan direkt aus den \(SS\) und den Freiheitsgraden (\(df\)).
AbschlieÃend ergibt sich dann die F Statistik.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Varianzquelle
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
df
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Mean squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F\(_{\boldsymbol{calc}}\)
\end{minipage} \\
\midrule()
\endhead
animal & \(3-1\) & \(SS_{animal} = 180.03\) & \(MS_{animal} = 90.02\) &
\(F_{calc} = \cfrac{90.02}{2.97} = 30.28\) \\
site & \(4-1\) & \(SS_{site} = 9.13\) & \(MS_{site} = 3.04\) &
\(F_{calc} = \cfrac{3.04}{2.97} = 1.02\) \\
animal \(\times\) site & \((3-1)(4-1)\) &
\(SS_{animal \times site} = 195.12\) &
\(MS_{animal \times site} = 32.52\) &
\(F_{calc} = \cfrac{32.52}{2.97} = 10.94\) \\
error & \(120 - (3 \cdot 4)\) & \(SS_{error} = 321.06\) &
\(MS_{error} = 2.97\) & \\
total & \(120-1\) & \(SS_{total} = 705.34\) & & \\
\bottomrule()
\end{longtable}

\end{figure*}

\hypertarget{und-weiter}{%
\section{Und weiter?}\label{und-weiter}}

Nach einer berechnten ANOVA kÃ¶nnen wir zwei FÃ¤lle vorliegen haben.

{\marginnote{\begin{footnotesize}Wenn du in deinem Experiment keine
\emph{signifikanten} Ergebnisse findest, ist das nicht schlimm. Du
kannst deine Daten immer noch mit der explorativen Datenanalyse
auswerten wie in Kapitel~\ref{sec-eda-ggplot}
beschrieben.\end{footnotesize}}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir habe eine nicht signifkante ANOVA berechnet. Wir kÃ¶nnen die
  Nullhypothese \(H_0\) nicht ablehnen und die Mittelwerte Ã¼ber den
  Faktor sind vermutlich alle gleich. Wir enden hier mit unserer
  statistischen Analyse.
\item
  Wir haben eine signifikante ANOVA berechnet. Wir kÃ¶nnen die
  Nullhypothese \(H_0\) ablehnen und mindestens ein Gruppenvergleich
  Ã¼ber mindestens einen Faktor ist vermutlich unterschiedlich. Wir
  kÃ¶nnen dann in Kapitel~\ref{sec-posthoc} eine Posthoc Analyse rechnen.
\end{enumerate}

\hypertarget{sec-ancova}{%
\chapter{Die ANCOVA}\label{sec-ancova}}

{\marginnote{\begin{footnotesize}Eine Kovariate ist eine Variable, die
mit berÃ¼cksichtigt wird, um mÃ¶gliche verzerrende EinflÃ¼sse auf die
Analyseergebnisse (Konfundierung) abzuschÃ¤tzen oder zu
verringern.\end{footnotesize}}}

Eigentlich hat sich die Analysis of Covariance (ANCOVA) etwas Ã¼berlebt.
Wir kÃ¶nnen mit dem statistischen Modellieren \emph{eigentlich} alles was
die ANCOVA kann plus wir erhalten auch noch EffektschÃ¤tzer fÃ¼r die
Kovariaten und die Faktoren. Dennoch hat die ANCOVA ihren Platz in der
Auswertung von Daten. Wenn du ein oder zwei Faktoren hast plus eine
numerische Variable, wie das Startgewicht, fÃ¼r die du die Analyse
adjustieren mÃ¶chtest, dann ist die ANCOVA fÃ¼r dich gemacht.

Also kurz gesprochen adjustiert die Analysis of Covariance (ANCOVA) die
Faktoren einer ANOVA um eine kontinuierliche Covariate. Adjustiert
bedeutet in dem Fall, dass die Effekte des unterschiedlichen
Startgewichts von Pflanzen durch das Einbringen der Kovariate mit in der
statistischen Analyse berÃ¼cksichtigt werden. Wir werden hier auch nur
Ã¼ber die Nutzung in R sprechen und auf die theoretische Herleitung
verzichten.

Wir kÃ¶nnen die \emph{einfaktorielle} ANCOVA in folgender Form schreiben.
Wir haben haben einen Faktor \(x_1\) und eine Kovariate oder aber ein
numerisches \(x_2\). Damit sÃ¤he die ANCOVA wie folgt aus.

\[
y \sim x_1 + x_2
\]

Damit ist die ANCOVA aber sehr abstrakt beschrieben. Der \emph{eine}
Faktor kommt damit gar nicht zur Geltung. Deshalb schreiben wir die
ANCOVA wie folgt mit einem \(f_1\) fÃ¼r den Faktor und einem \(c_1\) fÃ¼r
eine numerische Kovariate. Damit haben wir einen bessere Ãbersicht.

\[
y \sim f_1 + c_1
\]

Somit erklÃ¤rt sich die zweifaktorielle ANCOVA schon fast von alleine.
Wir erweitern einfach das Modell um einen zweiten Faktor \(f_2\) und
haben somit eine zweifaktorielle ANCOVA.

\[
y \sim f_1 + f_2 + c_1
\]

Im Folgenden schauen wir uns einmal die Daten und die Hypothesen zu
einer mÃ¶glichen Fragestellung an.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-8}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-8}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               see, performance)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-1}{%
\section{Daten}\label{daten-1}}

FÃ¼r unser Beispiel nutzen wir die Daten der Sprungweite in {[}cm{]} von
FlÃ¶hen auf Hunde-, Katzen- und FÃ¼chsen. Damit haben wir den ersten
Faktor \texttt{animal} mit drei Leveln. Als Kovariate schauen wir uns
das Gewicht als numerische Variable an. Schlussendlich brauchen wir noch
das Outcome \texttt{jump\_length} als \(y\). FÃ¼r die zweifaktorielle
ANCOVA nehmen wir noch den Faktor \texttt{sex} mit zwei Leveln hinzu.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ancova\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, sex, jump\_length, weight) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-model-1} ist der Datensatz \texttt{ancova\_tbl}
nochmal dargestellt.

\hypertarget{tbl-model-1}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-model-1}Datensatz zu der SprunglÃ¤nge in {[}cm{]} von
FlÃ¶hen auf Hunde-, Katzen- und FÃ¼chsen.}\tabularnewline
\toprule()
animal & sex & jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
animal & sex & jump\_length & weight \\
\midrule()
\endhead
cat & male & 15.79 & 6.02 \\
cat & male & 18.33 & 5.99 \\
cat & male & 17.58 & 8.05 \\
cat & male & 14.09 & 6.71 \\
cat & male & 18.22 & 6.19 \\
cat & male & 13.49 & 8.18 \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} \\
fox & female & 27.81 & 8.04 \\
fox & female & 24.02 & 9.03 \\
fox & female & 24.53 & 7.42 \\
fox & female & 24.35 & 9.26 \\
fox & female & 24.36 & 8.85 \\
fox & female & 22.13 & 7.89 \\
\bottomrule()
\end{longtable}

\hypertarget{hypothesen-fuxfcr-die-ancova}{%
\section{Hypothesen fÃ¼r die ANCOVA}\label{hypothesen-fuxfcr-die-ancova}}

Wir haben fÃ¼r jeden Faktor der ANCOVA ein Hypothesenpaar sowie ein
Hypothesenpaar fÃ¼r die Kovariate. Im Folgenden sehen wir die jeweiligen
Hypothesenpaare.

Einmal fÃ¼r \texttt{animal}, als Haupteffekt. Wir nennen einen Faktor den
Hauptfaktor, weil wir an diesem Faktor am meisten interessiert sind.
Wenn wir spÃ¤ter einen Posthoc Test durchfÃ¼hren wÃ¼rden, dann wÃ¼rden wir
diesen Faktor nehmen. Wir sind primÃ¤r an dem Unterschied der
Sprungweiten in {[}cm{]} in Gruppen Hund, Katze und Fuchs interessiert.

\[
\begin{align*}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{fÃ¼r mindestens ein Paar}
\end{align*}
\]

{\marginnote{\begin{footnotesize}Du kannst mehr Ã¼ber Geraden sowei
lineare Modelle und deren Eigenschaften im
Kapitel~\ref{sec-modeling-simple-stat} erfahren.\end{footnotesize}}}

FÃ¼r die Kovariate testen wir anders. Die Kovariate ist ja eine
numerische Variable. Daher ist die Frage, wann gibt es keinen Effekt von
\texttt{weight} auf die SprunglÃ¤nge? Wenn wir eine parallele Linie
hÃ¤tten. Das heiÃt, wenn sich der Wert von \texttt{weight} Ã¤ndert, Ã¤ndert
sich der Wert von \texttt{jump\_length} nicht. Wir schreiben, dass sich
die Steigung der Geraden nicht Ã¤ndert. Wir bezeichnen die Steigung einer
Graden mit \(\beta\). Wenn kein Effekt vorliegt und die Nullhpyothese
gilt, dann ist die Steigung der Geraden \(\beta_{weight} = 0\).

\[
\begin{align*}
H_0: &\; \beta_{weight} = 0\\
H_A: &\; \beta_{weight} \neq 0
\end{align*}
\]

Du kannst dir Ã¼berlegen, ob due die Interaktion zwischen dem Faktor und
der Kovariate mit ins Modell nehmen willst. Eigentlich schauen wir uns
immer nur die Interaktion zwischen den Faktoren an. Generell schreiben
wir eine Interaktionshypothese immer in Prosa.

\[
\begin{align*}
H_0: &\; \mbox{keine Interaktion}\\
H_A: &\; \mbox{eine Interaktion zwischen animal und site}
\end{align*}
\]

Wir haben also jetzt die verschiedenen Hypothesenpaare definiert und
schauen uns jetzt die ANCOVA in R einmal in der Anwendung an.

\hypertarget{die-einfaktorielle-ancova-in-r}{%
\section{Die einfaktorielle ANCOVA in
R}\label{die-einfaktorielle-ancova-in-r}}

{\marginnote{\begin{footnotesize}Du kannst mehr Ã¼ber Geraden sowie
lineare Modelle und deren Eigenschaften im
Kapitel~\ref{sec-modeling-simple-stat} erfahren.\end{footnotesize}}}

Wir kÃ¶nnen die ANCOVA ganz klassisch mit dem linaren Modell fitten. Wir
nutzen die Funktion \texttt{lm()} um die Koeffizienten des linearen
Modellls zu erhalten. Wir erinnern uns, wir haben haben einen Faktor
\(f_1\) und eine Kovariate bezwiehungsweise ein numerisches \(c_1\). In
unserem Beispiel sieht dann der Fit des Modells wie folgt aus.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ weight }\SpecialCharTok{+}\NormalTok{ animal}\SpecialCharTok{:}\NormalTok{weight, }\AttributeTok{data =}\NormalTok{ ancova\_tbl)}
\end{Highlighting}
\end{Shaded}

Nachdem wir das Modell in dem Objekt \texttt{fit\_1} gespeichert haben
kÃ¶nnen wir dann das Modell in die Funktion \texttt{anova()} pipen. Die
Funktion erkennt, das wir eine ANCOVA rechnen wollen, da wir in unserem
Modell einen Faktor und eine Kovariate mit enthalten haben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: jump_length
               Df  Sum Sq  Mean Sq   F value              Pr(>F)    
animal          2 2693.75 1346.876 204.27636 <0.0000000000000002 ***
weight          1 1917.99 1917.994 290.89611 <0.0000000000000002 ***
animal:weight   2    0.28    0.141   0.02143              0.9788    
Residuals     594 3916.48    6.593                                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

In der ANCOVA erkennne wir nun, dass der Faktor \texttt{animal}
signifikant ist. Der \(p\)-Wert ist mit \(<0.001\) kleiner das das
Signifikanzniveau \(\alpha\) von 5\%. Ebenso ist die Kovariate
\texttt{weight} signifikant. Der \(p\)-Wert ist ebenfalls mit \(<0.001\)
kleiner das das Signifikanzniveau \(\alpha\) von 5\%. Wir kÃ¶nnen also
schlussfolgern, dass sich mindestens eine Gruppenvergleich der Level des
Faktors \texttt{animal} voneinander unterscheidet. Wir wissen auch, dass
mit der Zunahme des Gewichts, die SprunglÃ¤nge sich Ã¤ndert.

{\marginnote{\begin{footnotesize}Die ANCOVA liefert keine Informationen
zu der GrÃ¶Ãe oder der Richtung des Effekts der
Kovariate.\end{footnotesize}}}

Was wir nicht wissen, ist die Richtung. Wir wissen nicht, ob mit
ansteigenden Gewicht sich die SprunglÃ¤nge erhÃ¶ht oder vermindert. Ebenso
wenig wissen wir etwas Ã¼ber den Betrag des Effekts. Wieviel weiter
springen denn nun FlÃ¶he mit 1 mg Gewicht mehr? Wir haben aber die
MÃ¶glichkeit, den Sachverhalt uns einmal in einer Abbildung zu
visualisieren. In Abbildung~\ref{fig-stat-ancova-01} sehen wir die Daten
einmal als Scatterplot dargestellt.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(ancova\_tbl, }\FunctionTok{aes}\NormalTok{(weight, jump\_length, }\AttributeTok{color =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color  =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{shape =} \StringTok{"Geschlecht"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-ancova_files/figure-pdf/fig-stat-ancova-01-1.pdf}

}

\caption{\label{fig-stat-ancova-01}Scatterplot der Daten zur
einfaktoriellen ANCOVA.}

\end{figure}

Der Abbildung~\ref{fig-stat-ancova-01} kÃ¶nnen wir jetzt die positive
Steigung entnehmen sowie die Reihenfolge der Tierarten nach
Sprungweiten. Die ANCOVA sollte immer visualisiert werden, da sich hier
die StÃ¤rke der Methode mit der Visualiserung verbindet.

\hypertarget{die-zweifaktorielle-ancova-in-r}{%
\section{Die zweifaktorielle ANCOVA in
R}\label{die-zweifaktorielle-ancova-in-r}}

Die zweifaktorielle ANCOVA erweitert die einfaktorielle ANCOVA um einen
weiteren Faktor. Das ist manchmal etwas verwirrend, da wir auf einmal
drei oder mehr Terme in einem Modell haben. Klassischerweise haben wir
nun zwei Faktoren \(f_1\) und \(f_2\) in dem Modell. Weiterhin haben wir
nur eine Kovariate \(c_1\). Damit sehe das Modell wie folgt aus.

\[
y \sim f_1 + f_2 + c_1
\]

Wir kÃ¶nnen das Modell dann in R Ã¼bertragen und ergÃ¤nzen noch den
Interaktionsterm fÃ¼r die Faktoren \texttt{animal} und \texttt{sex} in
dem Modell. Das Modell wird klassisch in der Funktion \texttt{lm()}
gefittet.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ weight }\SpecialCharTok{+}\NormalTok{ animal}\SpecialCharTok{:}\NormalTok{sex, }\AttributeTok{data =}\NormalTok{ ancova\_tbl)}
\end{Highlighting}
\end{Shaded}

Nach dem Fit kÃ¶nnen wir das Modell in dem Obkjekt \texttt{fit\_2} in die
Funktion \texttt{anova()} pipen. Die Funktion erkennt die Struktur des
Modells und gibt uns eine ANCOVA Ausgabe wieder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: jump_length
            Df  Sum Sq Mean Sq   F value               Pr(>F)    
animal       2 2693.75 1346.88 359.05679 < 0.0000000000000002 ***
sex          1 3608.07 3608.07 961.85680 < 0.0000000000000002 ***
weight       1    0.02    0.02   0.00526              0.94222    
animal:sex   2    2.24    1.12   0.29806              0.74237    
Residuals  593 2224.43    3.75                                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

In der ANCOVA erkennne wir nun, dass der Faktor \texttt{animal}
signifikant ist. Der \(p\)-Wert ist mit \(<0.001\) kleiner das das
Signifikanzniveau \(\alpha\) von 5\%. Ebenso ist der Faktor \texttt{sex}
signifikant. Der \(p\)-Wert ist mit \(<0.001\) kleiner das das
Signifikanzniveau \(\alpha\) von 5\%. Die Kovariate \texttt{weight} ist
nicht mehr signifikant. Der \(p\)-Wert ist mit \(0.94\) grÃ¶Ãer das das
Signifikanzniveau \(\alpha\) von 5\%. Wir kÃ¶nnen also schlussfolgern,
dass sich mindestens eine Gruppenvergleich der Level des Faktors
\texttt{animal} voneinander unterscheidet. Ebenso wie kÃ¶nnen wir
schlussfolgern, dass sich mindestens eine Gruppenvergleich der Level des
Faktors \texttt{site} voneinander unterscheidet. Da wir nur zwei Level
in dem Faktor \texttt{sex} haben, wissenwir nun, dass sich die beiden
Geschlechter der FlÃ¶he in der Sprungweite unterscheiden. Wir wissen
auch, dass mit der Zunahme des Gewichts, sich die SprunglÃ¤nge nicht
Ã¤ndert.

In Abbildung~\ref{fig-stat-ancova-02} sehen wir nochmal den Zusammenhang
dargestellt. Wenn wir die Daten getrennt fÃ¼r den Faktor \texttt{sex}
anschauen, dann sehen wir, dass das Gewicht keinen Einfluss mehr auf die
Sprungweite hat.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(ancova\_tbl, }\FunctionTok{aes}\NormalTok{(weight, jump\_length, }\AttributeTok{color =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color  =} \StringTok{"Tierart"}\NormalTok{, }\AttributeTok{shape =} \StringTok{"Geschlecht"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex, }\AttributeTok{scales =} \StringTok{"free\_x"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-ancova_files/figure-pdf/fig-stat-ancova-02-1.pdf}

}

\caption{\label{fig-stat-ancova-02}Scatterplot der Daten zur
einfaktoriellen ANCOVA aufgetelt nach dem Geschlecht der FlÃ¶he.}

\end{figure}

\hypertarget{und-weiter-1}{%
\section{Und weiter?}\label{und-weiter-1}}

Nach einer berechnten ANCOVA kÃ¶nnen wir zwei FÃ¤lle vorliegen haben.

{\marginnote{\begin{footnotesize}Wenn du in deinem Experiment keine
\emph{signifikanten} Ergebnisse findest, ist das nicht schlimm. Du
kannst deine Daten immer noch mit der explorativen Datenanalyse
auswerten wie in Kapitel~\ref{sec-eda-ggplot}
beschrieben.\end{footnotesize}}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir habe eine nicht signifkante ANCOVA berechnet. Wir kÃ¶nnen die
  Nullhypothese \(H_0\) nicht ablehnen und die Mittelwerte Ã¼ber den
  Faktor sind vermutlich alle gleich. Wir enden hier mit unserer
  statistischen Analyse.
\item
  Wir haben eine signifikante ANCOVA berechnet. Wir kÃ¶nnen die
  Nullhypothese \(H_0\) ablehnen und mindestens ein Gruppenvergleich
  Ã¼ber mindestens einen Faktor ist vermutlich unterschiedlich. Wir
  kÃ¶nnen dann in Kapitel~\ref{sec-posthoc} eine Posthoc Analyse rechnen.
\end{enumerate}

\hypertarget{sec-utest}{%
\chapter{Der Wilcoxon-Mann-Whitney-Test}\label{sec-utest}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht der Wilcoxon-Mann-Whitney-Test?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Der Wilcoxon-Mann-Whitney-Test vergleicht die Mediane zweier beliebiger
Verteilungen miteinander.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in den Wilcoxon-Mann-Whitney-Test per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube
\href{https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC}{Grundlagen
in R} als Video Reihe. Ich werde zwar alles nochmal hier als Text
aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

\marginnote{\begin{footnotesize}

Die Entscheidung, ob ein \(y\) normal verteilt ist oder nicht kann an
dem Boxplot der Daten abgeschÃ¤tzt werden.

\end{footnotesize}}

Wann nutzen wir den Wilcoxon-Mann-Whitney-Test? Wir nutzen den
Wilcoxon-Mann-Whitney-Test wenn wir zwei Verteilungen miteinander
vergleichen wollen. Das ist jetzt sehr abstrakt. Konrekt, wenn wir zwei
Gruppen haben und ein nicht normalverteiltes \(y\). Haben wir ein
normalverteiltes \(y\) rechnen wir meist einen t-Test. Wir kÃ¶nnten aber
auch einen Wilcoxon-Mann-Whitney-Test rechnen.

Was ist jetzt der Unterschied zwischen einem Wilcoxon-Mann-Whitney-Test
und einem t-Test? Der t-Test vergleicht die Mittelwerte zweier
Normalverteilungen, also zum Beispiel die Verteilung der Sprungweiten
der HundeflÃ¶he gegen die Verteilung der Sprungweiten der KatzenflÃ¶he.
Dazu nutzt der t-Test die Mittelwerte und die Standardabweichung. Beides
sind Parameter einer Verteilung und somit ist der t-Test ein
parametrischer Test.

Der Wilcoxon-Mann-Whitney-Test ist die \emph{nicht-parametrische}
Variante in dem wir die Zahlen in RÃ¤nge umwandeln, also sortieren, und
\emph{mit den RÃ¤ngen} der Zahlen rechnen. Die deskriptiven MaÃzahlen
wÃ¤ren dann Median, Quantile und Quartile. Das heiÃt wir vergleichen mit
dem Wilcoxon-Mann-Whitney-Test die Mediane. Wir wollen also wissen, ob
sich die Mediane zwischen den Sprungweiten von Hunde- und KatzenflÃ¶hen
unterscheiden.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Achte darauf nach welcher Teststatistik in der Klausur gefragt wird! Du
kannst entweder die \(U\) Statistik berechnen oder aber die
transformierte \(z\) Statistik aus der \(U\) Statistik. Je nachdem
welche Statistik du nimmst, Ã¤ndert sich die Richtung der Entscheidung!

Bitte schau dir die Aufgaben in den
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub} an um eine Idee zu haben, welche Fragen zum
Wilcoxon-Mann-Whitney-Test drankommen.

Wenn kein \(U_{\alpha = 5\%}\) in der Klausur gegeben ist, setzen wir
\(U_{\alpha = 5\%} = 12\).

Wenn kein \(z_{\alpha = 5\%}\) in der Klausur gegeben ist, setzen wir
\(z_{\alpha = 5\%} = 1.96\).
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-9}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-9}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, broom, }
\NormalTok{               readxl, coin)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-fuxfcr-den-wilcoxon-mann-whitney-test}{%
\section{Daten fÃ¼r den
Wilcoxon-Mann-Whitney-Test}\label{daten-fuxfcr-den-wilcoxon-mann-whitney-test}}

{\marginnote{\begin{footnotesize}Bindungen (eng. \emph{ties}) in den
Daten sind ein Problem und mÃ¼ssen beachtet werden. Das heiÃt, wenn es
gleiche Zahlen in den Gruppen gibt.\end{footnotesize}}}

FÃ¼r die Veranschaulichung des Wilcoxon-Mann-Whitney-Test nehmen wir ein
simples Beispiel. Wir nehmen ein nicht normalverteiltes \(y\) aus den
Datensatz \texttt{flea\_dog\_cat\_fox.csv} und einen Faktor mit mehr als
zwei Leveln. Wir nehmen hierbei an, dass die SprunglÃ¤nge jetzt mal nicht
normalverteilt ist. SpÃ¤ter sind es Boniturnoten, die definitiv nicht
normalverteilt sind. Aber mit der SprunglÃ¤nge ist das Beispiel einfacher
nachzuvollziehen. DarÃ¼ber hinaus haben wir so keine Bindungen in den
Daten. Bindungen (eng. \emph{ties}) heiÃt, dass wir die numerisch
gleichen Zahlen in beiden Gruppen haben.

Im Folgenden selektieren mit der Funktion \texttt{select()} die beiden
Spalten \texttt{jump\_length} als \(y\) und die Spalte \texttt{animal}
als \(x\). Danach mÃ¼ssen wir noch die Variable \texttt{animal} in einen
Faktor mit der Funktion \texttt{as\_factor()} umwandeln. Wir nehmen in
diesem Beispiel an, dass die Variable \texttt{jump\_length} nicht
normalverteilt ist.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, jump\_length, grade) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{data\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-utest-1} nochmal dargestellt.

\hypertarget{tbl-data-utest-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-utest-1}Selektierter Datensatz fÃ¼r den
Wilcoxon-Mann-Whitney-Test mit einer nicht-normalverteilten Variable
\texttt{jump\_length} und einem Faktor \texttt{animal} mit zwei
Leveln.}\tabularnewline
\toprule()
animal & jump\_length & grade \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & grade \\
\midrule()
\endhead
dog & 5.7 & 8 \\
dog & 8.9 & 8 \\
dog & 11.8 & 6 \\
dog & 8.2 & 8 \\
dog & 5.6 & 7 \\
dog & 9.1 & 7 \\
dog & 7.6 & 9 \\
cat & 3.2 & 7 \\
cat & 2.2 & 5 \\
cat & 5.4 & 7 \\
cat & 4.1 & 6 \\
cat & 4.3 & 6 \\
cat & 7.9 & 6 \\
cat & 6.1 & 5 \\
\bottomrule()
\end{longtable}

Wir bauen daher mit den beiden Variablen mit dem Objekt
\texttt{data\_tbl} folgendes Modell fÃ¼r spÃ¤ter:

\[
jump\_length \sim animal
\]

Bevor wir jetzt das Modell verwenden, mÃ¼ssen wir uns nochmal Ã¼berlegen,
welchen SchluÃ wir eigentlich Ã¼ber die Nullhypothese machen. Wie immer
kÃ¶nnen wir nur die Nullhypothese ablehnen. Daher Ã¼berlegen wir uns im
Folgenden wie die Nullhypothese in dem Wilcoxon-Mann-Whitney-Test
aussieht. Dann bilden wir anhand der Nullhypothese noch die
Alternativehypothese.

\hypertarget{hypothesen-fuxfcr-den-wilcoxon-mann-whitney-test}{%
\section{Hypothesen fÃ¼r den
Wilcoxon-Mann-Whitney-Test}\label{hypothesen-fuxfcr-den-wilcoxon-mann-whitney-test}}

Der Wilcoxon-Mann-Whitney-Test betrachtet die Mediane und RÃ¤nge um einen
Unterschied nachzuweisen. Daher haben wir die Nullhypothese als
Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass
die Mediane der beiden Levels des Faktors \texttt{animal} gleich sind.
Wir vergleichen im Wilcoxon-Mann-Whitney-Test nur zwei Gruppen.

\[
\begin{align*}
H_0: &\; \widetilde{y}_{cat} = \widetilde{y}_{dog}\\
\end{align*}
\]

Die Alternative lautet, dass sich die beiden Gruppen im Median
unterscheiden. Wir kÃ¶nnen uns Ã¼ber die Boxplots oder aber die
berechneten Mediane dann den Unterschied bewerten.

\[
\begin{align*}
H_A: &\; \widetilde{y}_{cat} \ne \widetilde{y}_{dog}\\
\end{align*}
\]

Wir schauen uns jetzt einmal den Wilcoxon-Mann-Whitney-Test theoretisch
an bevor wir uns mit der Anwendung des Wilcoxon-Mann-Whitney-Test in R
beschÃ¤ftigen.

\hypertarget{wilcoxon-mann-whitney-test-theoretisch}{%
\section{Wilcoxon-Mann-Whitney-Test
theoretisch}\label{wilcoxon-mann-whitney-test-theoretisch}}

Der Wilcoxon-Mann-Whitney-Test berechnet die U Teststatistik auf den
RÃ¤ngend der Daten. Es gibt genau soviele RÃ¤nge wie es Beobachtungen im
Datensatz gibt. Wir haben \(n = 14\) Beobachtungen in unseren Daten zu
der Sprungweite in {[}cm{]} von den Hunde- und KatzenflÃ¶hen. Somit
mÃ¼ssen wir auch vierzehn RÃ¤nge vergeben.

Die Tabelle~\ref{tbl-utest-rank} zeigt das Vorgehen der Rangvergabe. Wir
sortieren als erstes das \(y\) aufsteigend. In unserem Fall ist das
\(y\) die SprunglÃ¤nge. Dann vergeben wir die RÃ¤nge jweiles zugehÃ¶rig zu
der Position der SprunglÃ¤nge und der Tierart. AbschlieÃend addieren wir
die Rangsummmen fÃ¼r \texttt{cat} und \texttt{dog} zu den Rangsummen
\(R_{cat}\) und \(R_{dog}\).

\hypertarget{tbl-utest-rank}{}
\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tbl-utest-rank}Datentablle absteigend sortiert nach der
SprunglÃ¤nge in {[}cm{]}. Die Level \texttt{cat} und \texttt{dog} haben
jeweils die entsprechenden RÃ¤nge zugeordnet bekommen und die Rangsummen
wurden berechnet}\tabularnewline
\toprule()
Rank & animal & jump\_length & RÃ¤nge ``cat'' & RÃ¤nge ``dog'' \\
\midrule()
\endfirsthead
\toprule()
Rank & animal & jump\_length & RÃ¤nge ``cat'' & RÃ¤nge ``dog'' \\
\midrule()
\endhead
1 & cat & 2.2 & 1 & \\
2 & cat & 3.2 & 2 & \\
3 & cat & 4.1 & 3 & \\
4 & cat & 4.3 & 4 & \\
5 & cat & 5.4 & 5 & \\
6 & dog & 5.6 & & 6 \\
7 & dog & 5.7 & & 7 \\
8 & cat & 6.1 & 8 & \\
9 & dog & 7.6 & & 9 \\
10 & cat & 7.9 & 10 & \\
11 & dog & 8.2 & & 11 \\
12 & dog & 8.9 & & 12 \\
13 & dog & 9.1 & & 13 \\
14 & dog & 11.8 & & 14 \\
& & Rangsummen & \(R_{cat} = 33\) & \(R_{dog} = 72\) \\
& & GruppengrÃ¶Ãe & 7 & 7 \\
\bottomrule()
\end{longtable}

Die Formel fÃ¼r die U Statistik sieht ein wenig wild aus, aber wir kÃ¶nnen
eigentlich relativ einfach alle Zahlen einsetzen. Dann musst du dich
etwas konzentrieren bei der Rechnung.

\[
U_{calc} = n_1n_2 + \cfrac{n_1(n_1+1)}{2}-R_1
\]

mit

\begin{itemize}
\tightlist
\item
  \(R_1\) der \emph{grÃ¶Ãeren} der beiden Rangsummen,
\item
  \(n_1\) die Fallzahl der \emph{grÃ¶Ãeren} der beiden Rangsummen
\item
  \(n_2\) die Fallzahl der \emph{kleineren} der beiden Rangsummen
\end{itemize}

Wir setzen nun die Zahlen ein. Da wir ein balanciertes Design vorliegen
haben sind die Fallzahlen \(n_1 = n_2 = 7\) gleich. Wir mÃ¼ssen nur
schauen, dass wir mit \(R_1\) die passende Rangsumme wÃ¤hlen. In unserem
Fall ist \(R_1 = R_{dog} = 72\).

\[
U_{calc} = 7 \cdot 7 + \cfrac{7(7+1)}{2}-72 = 5
\]

Der kritische Wert fÃ¼r die U Statistik ist \(U_{\alpha = 5\%} = 8\) fÃ¼r
\(n_1 = 7\) und \(n_2 = 7\). Bei der Entscheidung mit der berechneten
Teststatistik \(U_{calc}\) gilt, wenn \(U_{calc} \leq U_{\alpha = 5\%}\)
wird die Nullhypothese (H\(_0\)) abgelehnt. Da in unserem Fall das
\(U_{calc}\) mit \(5\) kleiner ist als das \(U_{\alpha = 5\%} = 8\)
kÃ¶nnen wir die Nullhypothese ablehnen. Wir haben ein signifkianten
Unterschied in den Medianen zwischen den beiden Tierarten im Bezug auf
die Sprungweite in {[}cm{]} von FlÃ¶hen.

Bei grosser Stichprobe, wenn \(n_1 + n_2 > 30\) ist, kÃ¶nnen wir die U
Statistik auch standariseren und damit in den z-Wert transformieren.

\[
z_{calc} = \cfrac{U_{calc} - \bar{U}}{s_U} = \cfrac{U_{calc} - \cfrac{n_1 \cdot n_2}{2}}{\sqrt{\cfrac{n_1 \cdot n_2 (n_1 + n_2 +1)}{12}}}
\]

mit

\begin{itemize}
\tightlist
\item
  \(\bar{U}\) dem Mittelwert der U-Verteilung ohne Unterschied zwischen
  den Gruppen
\item
  \(s_U\) Standardfehler des U-Wertes
\item
  \(n_1\) StichprobengrÃ¶sse der Gruppe mit der grÃ¶sseren Rangsumme
\item
  \(n_2\) StichprobengrÃ¶sse der Gruppe mit der kleineren Rangsumme
\end{itemize}

Wir setzen dafÃ¼r ebenfalls die berechnete U Statistik ein und mÃ¼ssen
dann wieder konzentriert rechnen.

\[
z_{calc} = \cfrac{5 - \cfrac{7 \cdot 7}{2}}{\sqrt{\cfrac{7 \cdot 7 (7 + 7 +1)}{12}}} = \cfrac{-19.5}{7.83} = |-2.46|
\]

Der kritische Wert fÃ¼r die z-Statistik ist \(z_{\alpha = 5\%} = 1.96\).
Bei der Entscheidung mit der berechneten Teststatistik \(z_{calc}\)
gilt, wenn \(z_{calc} \geq z_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt. Wir haben eine berechnete z Statistik von
\(z_{calc} = 2.46\). Damit ist \(z_{calc}\) grÃ¶Ãer als
\(z_{\alpha = 5\%} = 1.96\) und wir kÃ¶nnen die Nullhypothese ablehnen.
Wir haben einen signifkanten Unterschied zwischen den Medianen der
beiden Floharten im Bezug auf die SprunglÃ¤nge in {[}cm{]}.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit der berechneten Teststatistik \(U_{\boldsymbol{calc}}\)
oder der Teststatistik \(z_{\boldsymbol{calc}}\)}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung mit der berechneten Teststatistik \(U_{calc}\)
gilt, wenn \(U_{calc} \leq U_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt.

Bei der Entscheidung mit der berechneten Teststatistik \(z_{calc}\)
gilt, wenn \(z_{calc} \geq z_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt.

\textbf{Achtung --} Wir nutzen die Entscheidung mit der Teststatistik
\emph{nur und ausschlieÃlich} in der Klausur. In der praktischen
Anwendung hat die Betrachtung der berechneten Teststatistik \emph{keine}
Verwendung mehr.
\end{tcolorbox}

\hypertarget{wilcoxon-mann-whitney-test-in-r}{%
\section{Wilcoxon-Mann-Whitney-Test in
R}\label{wilcoxon-mann-whitney-test-in-r}}

Die Nutzung des Wilcoxon-Mann-Whitney-Test in R ist relativ einfach mit
der Funktion \texttt{wilxoc.test()}. Wir mÃ¼ssen zum einen entscheiden,
ob Bindungen in den Daten vorliegen. Sollte Bindungen vorliegen, warnt
uns R und wir nutzen dann die Funktion \texttt{wilcox\_test()} aus dem R
Paket \texttt{coin}.

\hypertarget{ohne-bindungen}{%
\subsection{Ohne Bindungen}\label{ohne-bindungen}}

Ohne Bindungen kÃ¶nnen wir die Funktion \texttt{wilxoc.test()} nutzen.
Die Funktion benÃ¶tigt das Modell in \texttt{formula} Syntax in der Form
\texttt{jump\_length\ \textasciitilde{}\ animal}. Wir geben noch an,
dass wir die 95\% Konfidenzintervalle wiedergegeben haben wollen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ data\_tbl, }
            \AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Wilcoxon rank sum exact test

data:  jump_length by animal
W = 44, p-value = 0.011072
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 1.0 5.9
sample estimates:
difference in location 
                   3.5 
\end{verbatim}

Wir sehen das der Wilcoxon-Mann-Whitney-Test ein signifikantes Ergebnis
liefert, da der \(p\)-Wert mit 0.011 kleiner ist als das
Signifikanzniveau \(\alpha\) von 5\%. Die Nullhypothese kann daher
abgelehnt werden. Wir haben einen medianen Unterschied in den
Sprungweiten von 3.5 cm {[}1.0; 5.9{]} zwischen Hunde- und KatzenflÃ¶hen.

\hypertarget{mit-bindungen}{%
\subsection{Mit Bindungen}\label{mit-bindungen}}

Mit Bindungen kÃ¶nnen wir die Funktion \texttt{wilxoc\_test()} aus dem R
Paket \texttt{coin} nutzen. Wir nutzen hier als \(y\) die Boniturnoten
\texttt{grade} der Hunde und Katzen. Die Funktion benÃ¶tigt das Modell in
\texttt{formula} Syntax in der Form
\texttt{grade\ \textasciitilde{}\ animal}. Wir geben noch an, dass wir
die 95\% Konfidenzintervalle wiedergegeben haben wollen. Wenn du die
Funktion \texttt{wilcox.test()} nutzen wÃ¼rdest, wÃ¼rde dir R eine Warnung
ausgeben:
\texttt{Warning:\ cannot\ compute\ exact\ p-value\ with\ ties}. Du
wÃ¼sstest dann, dass du die Funktion wechseln musst.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox\_test}\NormalTok{(grade }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ data\_tbl, }
            \AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Asymptotic Wilcoxon-Mann-Whitney Test

data:  grade by animal (dog, cat)
Z = 2.49731, p-value = 0.012514
alternative hypothesis: true mu is not equal to 0
95 percent confidence interval:
 0.99999999 2.99999999
sample estimates:
difference in location 
                     2 
\end{verbatim}

Wir sehen das der Wilcoxon-Mann-Whitney-Test ein signifikantes Ergebnis
liefert, da der \(p\)-Wert mit 0.015 kleiner ist als das
Signifikanzniveau \(\alpha\) von 5\%. Die Nullhypothese kann daher
abgelehnt werden. Wir haben einen medianen Unterschied in den
Boniturnoten von 2 {[}0; 3{]} zwischen Hunde und Katzen.

\hypertarget{minimale-fallzahl-je-gruppe}{%
\section{Minimale Fallzahl je
Gruppe}\label{minimale-fallzahl-je-gruppe}}

HÃ¤ufig wird auch der Wilcoxon-Mann-Whitney-Test eingesetzt, wenn wenig
Beobachtungen vorliegen. Es gibt aber eine untere Grenze der
Signifikanz. Das heiÃt unter einer Fallzahl von \(n_1 = 3\) und
\(n_2 = 3\) wird ein Wilcoxon-Mann-Whitney-Test nicht mehr signifikant.
Egal wie groÃ der Unterschied ist, ein Wilcoxon-Mann-Whitney-Test wird
dann die Nulhypothese nicht ablehnen kÃ¶nnen. Schauen wir das
Datenbeispiel in Tabelle~\ref{tbl-data-utest-2} einmal an.

\hypertarget{tbl-data-utest-2}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-data-utest-2}Kleiner Datensatz mit jeweils nur drei
Beobachtungen pro Gruppe.}\tabularnewline
\toprule()
animal & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length \\
\midrule()
\endhead
dog & 1.2 \\
dog & 5.6 \\
dog & 3.2 \\
cat & 100.3 \\
cat & 111.2 \\
cat & 98.5 \\
\bottomrule()
\end{longtable}

Wir sehen jeweils drei Beobachtunge fÃ¼r Hunde- und Katzensprungweiten.
Der Unterschied ist numerisch riesig. Wir kÃ¶nnen uns den Unterschied
nochmal in Abbildung~\ref{fig-boxplot-utest-min} visualisieren.

\begin{figure}

{\centering \includegraphics{./stat-tests-utest_files/figure-pdf/fig-boxplot-utest-min-1.pdf}

}

\caption{\label{fig-boxplot-utest-min}Boxplot der Sprungweiten {[}cm{]}
von Hunden und Katzen.}

\end{figure}

Wir sehen, der Unterschied ist riesig. Der Wilcoxon-Mann-Whitney-Test
findet jedoch nur einen p-Wert von 0.1 und kann damit die Nullhypothese
nicht ablehnen. Wir haben keinen signifkanten Unterschied.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ small\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Wilcoxon rank sum exact test

data:  jump_length by animal
W = 9, p-value = 0.1
alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

Wir sehen hier ein schÃ¶nes Beispiel fÃ¼r die Begrenztheit von Algorithmen
und mathematischen Formeln. Es gibt einen Unterschied, aber der
Wilcoxon-Mann-Whitney-Test ist technisch nicht in der Lage einen
Unterschied nochzuweisen. Daher solltest du immer versuchen die
Ergebnisse eines Testes mit einer Abbildung zu Ã¼berprÃ¼fen.

\hypertarget{der-kruskal-wallis-test}{%
\chapter{Der Kruskal-Wallis-Test}\label{der-kruskal-wallis-test}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht der Kruskal-Wallis-Test?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Der Kruskal-Wallis-Test vergleicht die Mediane mehrerer beliebiger
Verteilungen miteinander.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in den Kruskal-Wallis-Test per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube
\href{https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC}{Grundlagen
in R} als Video Reihe. Ich werde zwar alles nochmal hier als Text
aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

\marginnote{\begin{footnotesize}

Die Entscheidung, ob ein \(y\) normal verteilt ist oder nicht kann an
dem Boxplot der Daten abgeschÃ¤tzt werden.

\end{footnotesize}}

Wann nutzen wir den Kruskal-Wallis-Test? Wir nutzen den
Kruskal-Wallis-Test wenn wir mehrere Verteilungen miteinander
vergleichen wollen. Das ist jetzt sehr abstrakt. Konrekt, wenn wir
mehrere Gruppen haben und ein nicht normalverteiltes \(y\). Haben wir
ein normalverteiltes \(y\) rechnen wir meist eine einfaktorielle ANOVA.
Das heiÃt, der Kruskal-Wallis-Test ist im Prinzip die einfaktorielle
ANOVA fÃ¼r nicht-normalverteilte Daten.

Was ist jetzt der Unterschied zwischen einem Kruskal-Wallis-Test und
einer einfaktoriellen ANOVA? Die ANOVA vergleicht die Mittelwerte
mehrerer Normalverteilungen, also zum Beispiel die Verteilung der
Sprungweiten der HundeflÃ¶he gegen die Verteilung der Sprungweiten der
KatzenflÃ¶he sowie gegen die Verteilung der Sprungweiten von FuchsflÃ¶hen.
Dazu nutzt die ANOVA die Abweichungsquadrate von den Mittelwerten. Damit
nutze die ANOVAB Parameter einer Verteilung und somit ist der ANOVA ein
parametrischer Test.

Der Kruskal-Wallis-Test ist die \emph{nicht-parametrische} Variante in
dem wir die Zahlen in RÃ¤nge umwandeln, also sortieren, und \emph{mit den
RÃ¤ngen} der Zahlen rechnen. Die deskriptiven MaÃzahlen wÃ¤ren dann
Median, Quantile und Quartile. Das heiÃt wir vergleichen mit dem
Kruskal-Wallis-Test die Mediane mehrer Gruppen miteinander. Wir wollen
also wissen, ob sich die Mediane zwischen den Sprungweiten von Hunde-,
Katzen- und FuchsflÃ¶hen unterscheiden.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Wir rechnen keinen Kruskal-Wallis-Test in der Klausur \emph{per Hand}
sondern interpretieren die Ausgabe der R Funktionen eines
Kruskal-Wallis-Test. Auch hier gilt, Ã¼berprÃ¼fe was du in der Vorlesung
gehÃ¶rt hast!

Bitte schau dir unbedingt die Aufgaben in den
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub} an um eine Idee zu haben, welche Fragen zm
Kruskal-Wallis-Test drankommen.

Wenn kein \(H_{\alpha = 5\%}\) in der Klausur gegeben ist, setzen wir
\(H_{\alpha = 5\%} = 5.99\).
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-10}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-10}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, broom, }
\NormalTok{               readxl, rstatix)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-fuxfcr-den-kruskal-wallis-test}{%
\section{Daten fÃ¼r den
Kruskal-Wallis-Test}\label{daten-fuxfcr-den-kruskal-wallis-test}}

{\marginnote{\begin{footnotesize}Bindungen (eng. \emph{ties}) in den
Daten sind ein Problem und mÃ¼ssen beachtet werden. Das heiÃt, wenn es
gleiche Zahlen in den Gruppen gibt.\end{footnotesize}}}

Wir wollen uns nun erstmal den einfachsten Fall anschauen mit einem
simplen Datensatz. Wir nehmen ein nicht-normalverteiltes \(y\) aus den
Datensatz \texttt{flea\_dog\_cat\_fox.csv} und einen Faktor mit mehr als
zwei Leveln. HÃ¤tten wir nur zwei Level, dann kÃ¶nnen wir auch einen
Wilcoxon-Mann-Whitney-Test rechnen kÃ¶nnen.

Wir nehmen in diesem Abschnitt an, dass die SprunglÃ¤nge jetzt mal nicht
normalverteilt ist. SpÃ¤ter sind es Boniturnoten, die definitiv nicht
normalverteilt sind. Aber mit der SprunglÃ¤nge ist das Beispiel einfacher
nachzuvollziehen. DarÃ¼ber hinaus haben wir so keine Bindungen in den
Daten. Bindungen (eng. \emph{ties}) heiÃt, dass wir die numerisch
gleichen Zahlen in beiden Gruppen haben.

Im Folgenden selektieren mit der Funktion \texttt{select()} die beiden
Spalten \texttt{jump\_length} als \(y\) und die Spalte \texttt{animal}
als \(x\). Danach mÃ¼ssen wir noch die Variable \texttt{animal} in einen
Faktor mit der Funktion \texttt{as\_factor()} umwandeln. Wir nehmen in
diesem Beispiel an, dass die Variable \texttt{jump\_length} nicht
normalverteilt ist.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac1\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, jump\_length, grade) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{fac1\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-kruskal-1} nochmal dargestellt.

\hypertarget{tbl-data-kruskal-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-kruskal-1}Selektierter Datensatz fÃ¼r den
Kruskal-Wallis-Test mit einer nicht-normalverteilten Variable
\texttt{jump\_length} und einem Faktor \texttt{animal} mit drei
Leveln.}\tabularnewline
\toprule()
animal & jump\_length & grade \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & grade \\
\midrule()
\endhead
dog & 5.7 & 8 \\
dog & 8.9 & 8 \\
dog & 11.8 & 6 \\
dog & 8.2 & 8 \\
dog & 5.6 & 7 \\
dog & 9.1 & 7 \\
dog & 7.6 & 9 \\
cat & 3.2 & 7 \\
cat & 2.2 & 5 \\
cat & 5.4 & 7 \\
cat & 4.1 & 6 \\
cat & 4.3 & 6 \\
cat & 7.9 & 6 \\
cat & 6.1 & 5 \\
fox & 7.7 & 5 \\
fox & 8.1 & 4 \\
fox & 9.1 & 4 \\
fox & 9.7 & 5 \\
fox & 10.6 & 4 \\
fox & 8.6 & 4 \\
fox & 10.3 & 3 \\
\bottomrule()
\end{longtable}

Wir bauen daher mit den beiden Variablen mit dem Objekt
\texttt{fac1\_tbl} folgendes Modell fÃ¼r spÃ¤ter:

\[
jump\_length \sim animal
\]

Bevor wir jetzt das Modell verwenden, mÃ¼ssen wir uns nochmal Ã¼berlegen,
welchen SchluÃ wir eigentlich Ã¼ber die Nullhypothese machen. Wie immer
kÃ¶nnen wir nur die Nullhypothese ablehnen. Daher Ã¼berlegen wir uns im
Folgenden wie die Nullhypothese in dem Kruskal-Wallis-Test aussieht.
Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

\hypertarget{hypothesen-fuxfcr-den-kruskal-wallis-test}{%
\section{Hypothesen fÃ¼r den
Kruskal-Wallis-Test}\label{hypothesen-fuxfcr-den-kruskal-wallis-test}}

Der Kruskal-Wallis-Test betrachtet die Mediane und RÃ¤nge um einen
Unterschied nachzuweisen. Daher haben wir in der Nullhypothese als
Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass
die Mediane jedes Levels des Faktors \texttt{animal} gleich sind.

\[
\begin{align*}
H_0: &\; \widetilde{y}_{cat} = \widetilde{y}_{dog} = \widetilde{y}_{fox}\\
\end{align*}
\]

Die Alternative lautet, dass sich mindestens ein paarweiser Vergleich in
den Medianen unterschiedet. Hierbei ist das \emph{mindestens ein
Vergleich} wichtig. Es kÃ¶nnen sich alle Mediane unterschieden oder eben
nur ein Paar. Wenn ein Kruskal-Wallis-Test die \(H_0\) ablehnt, also ein
signifikantes Ergebnis liefert, dann wissen wir nicht, welche Mediane
sich unterscheiden.

\[
\begin{align*}
H_A: &\; \widetilde{y}_{cat} \ne \widetilde{y}_{dog}\\
\phantom{H_A:} &\; \widetilde{y}_{cat} \ne \widetilde{y}_{fox}\\
\phantom{H_A:} &\; \widetilde{y}_{dog} \ne \widetilde{y}_{fox}\\
\phantom{H_A:} &\; \mbox{fÃ¼r mindestens ein Paar}
\end{align*}
\]

Wir schauen uns jetzt einmal den Kruskal-Wallis-Test theoretisch an
bevor wir uns mit der Anwendung des Kruskal-Wallis-Test in R
beschÃ¤ftigen.

\hypertarget{kruskal-wallis-test-theoretisch}{%
\section{Kruskal-Wallis-Test
theoretisch}\label{kruskal-wallis-test-theoretisch}}

Der Kruskal-Wallis-Test berechnet die H Teststatistik auf den RÃ¤ngend
der Daten. Es gibt genau soviele RÃ¤nge wie es Beobachtungen im Datensatz
gibt. Wir haben \(n = 21\) Beobachtungen in unseren Daten zu der
Sprungweite in {[}cm{]} von den Hunde-, Katzen- und FuchsflÃ¶hen. Somit
mÃ¼ssen wir auch einundzwanzig RÃ¤nge vergeben.

Die Tabelle~\ref{tbl-kruskal-rank} zeigt das Vorgehen der Rangvergabe.
Wir sortieren als erstes das \(y\) aufsteigend. In unserem Fall ist das
\(y\) die SprunglÃ¤nge. Dann vergeben wir die RÃ¤nge jweiles zugehÃ¶rig zu
der Position der SprunglÃ¤nge und der Tierart. AbschlieÃend addieren wir
die Rangsummmen fÃ¼r \texttt{cat}, \texttt{dog} und \texttt{fox} zu den
Rangsummen \(R_{cat}\), \(R_{dog}\) und \(R_{fox}\).

\begin{figure*}

\hypertarget{tbl-kruskal-rank}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0779}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1039}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1818}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2078}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2078}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2208}}@{}}
\caption{\label{tbl-kruskal-rank}Datentablle absteigend sortiert nach
der SprunglÃ¤nge in {[}cm{]}. Die Level \texttt{cat}, \texttt{dog} und
\texttt{fox} haben jeweils die entsprechenden RÃ¤nge zugeordnet bekommen
und die Rangsummen wurden berechnet}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Rank
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
animal
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``cat''
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``dog''
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``fox''
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
Rank
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
animal
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``cat''
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``dog''
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
RÃ¤nge ``fox''
\end{minipage} \\
\midrule()
\endhead
1 & cat & 2.2 & 1 & & \\
2 & cat & 3.2 & 2 & & \\
3 & cat & 4.1 & 3 & & \\
4 & cat & 4.3 & 4 & & \\
5 & cat & 5.4 & 5 & & \\
6 & dog & 5.6 & & 6 & \\
7 & dog & 5.7 & & 7 & \\
8 & cat & 6.1 & 8 & & \\
9 & dog & 7.6 & & 9 & \\
10 & fox & 7.7 & & & 10 \\
11 & cat & 7.9 & 11 & & \\
12 & fox & 8.1 & & & 12 \\
13 & dog & 8.2 & & 13 & \\
14 & fox & 8.6 & & & 14 \\
15 & dog & 8.9 & & 15 & \\
16 & dog & 9.1 & & 16 & \\
17 & fox & 9.1 & & & 17 \\
18 & fox & 9.7 & & & 18 \\
19 & fox & 10.3 & & & 19 \\
20 & fox & 10.6 & & & 20 \\
21 & dog & 11.8 & & 21 & \\
& & Rangsummen & \(R_{cat} = 34\) & \(R_{dog} = 87\) &
\(R_{fox} = 110\) \\
& & GruppengrÃ¶Ãe & 7 & 7 & 7 \\
\bottomrule()
\end{longtable}

\end{figure*}

Die Summe aller RÃ¤nge ist \(1+2+3+...+21 = 231\). Wir Ã¼berprÃ¼fen nochmal
die Summe der Rangsummen als Gegenprobe
\(R_{cat} + R_{dog} + R_{fox} = 231\). Das ist identisch, wir haben
keinen Fehler bei der Rangaufteilung und der Summierung gemacht.

Die Formel fÃ¼r die H Statistik sieht wie die U Statistik ein wenig wild
aus, aber wir kÃ¶nnen eigentlich relativ einfach alle Zahlen einsetzen.
Dann musst du dich etwas konzentrieren bei der Rechnung.

\[
H = \cfrac{12}{N(N+1)}\sum_{i=1}^k\cfrac{R_i^2}{n_i}-3(N+1)
\]

mit

\begin{itemize}
\tightlist
\item
  \(R_i\) der Rangsummen fÃ¼r jede Gruppe mit insgesamt \(k\) Gruppen
\item
  \(n_i\) der Fallzahl in jeder Gruppe
\item
  \(N\) der Gesamtzahl an Beobachtungen also die gesamte Fallzahl
\end{itemize}

Wir setzen nun die Zahlen ein. Da wir ein balanciertes Design vorliegen
haben sind die Fallzahlen \(n_1 = n_2 = n_3 = 7\) gleich.

\[
H_{calc} = \cfrac{12}{21(21+1)}\left(\cfrac{34^2}{7}+\cfrac{87^2}{7}+\cfrac{110^2}{7}\right)-3(21+1) = 11.27
\]

Der kritische Wert fÃ¼r die H Statistik ist \(H_{\alpha = 5\%} = 5.99\).
Bei der Entscheidung mit der berechneten Teststatistik \(H_{calc}\)
gilt, wenn \(H_{calc} \geq U_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt. Da in unserem Fall das \(H_{calc}\) mit \(11.27\)
grÃ¶Ãer ist als das \(H_{\alpha = 5\%} = 5.99\) kÃ¶nnen wir die
Nullhypothese ablehnen. Wir haben ein signifkianten Unterschied in den
Medianen zwischen den beiden Tierarten im Bezug auf die Sprungweite in
{[}cm{]} von FlÃ¶hen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung mit der berechneten Teststatistik \(F_{\boldsymbol{calc}}\)}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung mit der berechneten Teststatistik \(H_{calc}\)
gilt, wenn \(H_{calc} \geq H_{\alpha = 5\%}\) wird die Nullhypothese
(H\(_0\)) abgelehnt.

\textbf{Achtung --} Wir nutzen die Entscheidung mit der Teststatistik
\emph{nur und ausschlieÃlich} in der Klausur. In der praktischen
Anwendung hat die Betrachtung der berechneten Teststatistik \emph{keine}
Verwendung mehr.
\end{tcolorbox}

\hypertarget{kruskal-wallis-test-in-r}{%
\subsection{Kruskal-Wallis-Test in R}\label{kruskal-wallis-test-in-r}}

Die Nutzung des Kruskal-Wallis-Test in R ist relativ einfach mit der
Funktion \texttt{kruskal.test()}. Wir nutzen die \texttt{formual} Syntax
um das Modell zu definieren und kÃ¶nnen dann schon die Funktion nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kruskal.test}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Kruskal-Wallis rank sum test

data:  jump_length by animal
Kruskal-Wallis chi-squared = 11.1965, df = 2, p-value = 0.0037043
\end{verbatim}

Mit einem p-Wert von \(0.0037\) kÃ¶nnen wir die Nullhypothese ablehnen,
da der p-Wert kleiner ist als das Signifikanzniveau \(\alpha\) von 5\%.
Wir haben mindestens einen medianen Unterschied zwischen den
Sprungweiten der Hunde-, Katzen- und FuchsflÃ¶hen.

FÃ¼r die Betrachtung der EffektgrÃ¶Ãe in einem Kruskal-Wallis-Test nutzen
wir das R Paket \texttt{rstatix} und die darin enthaltende Funktion
\texttt{kruskal\_effsize()}. Wir berechnene hierbei analog zu
einfaktoriellen ANOVA den \(\eta^2\) Wert.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac1\_tbl }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{kruskal\_effsize}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 5
  .y.             n effsize method  magnitude
* <chr>       <int>   <dbl> <chr>   <ord>    
1 jump_length    21   0.511 eta2[H] large    
\end{verbatim}

Das \(\eta^2\) nimmt Werte von 0 bis 1 an und gibt, multipliziert mit
100, den Prozentsatz der Varianz der durch die \(x\) Variable erklÃ¤rt
wird. In unserem Beispiel wird 51.1\% der Varianz in de Daten durch den
Faktor \texttt{animal} erklÃ¤rt.

\hypertarget{der-mathcalx2-test}{%
\chapter{\texorpdfstring{Der
\(\mathcal{X}^2\)-Test}{Der \textbackslash mathcal\{X\}\^{}2-Test}}\label{der-mathcalx2-test}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht der \(\mathcal{X}^2\)-Test?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Ein \(\mathcal{X}^2\)-Test vergleicht die Anteile zweier Gruppen.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{EinfÃ¼hrung in den \(\mathcal{X}^2\)-Test per Video}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/B6YNtxBsK3c}{Der
Chi-Quadrat-Test erklÃ¤rt} als Video Reihe. Ich werde zwar alles nochmal
hier als Text aufschreiben, aber manchmal ist das Sehen und HÃ¶ren dann
einfacher.
\end{tcolorbox}

Der \(\mathcal{X}^2\)-Test wird hÃ¤ufig verwendet, wenn wir zwei Faktoren
mit jeweils zwei Leveln miteinander vergleichen wollen. Das heiÃt wir
haben zum Beispiel unseren Faktor \texttt{animal} mit den beiden Leveln
\texttt{cat} und \texttt{dog}. Wir schauen uns jetzt den
Infektionsstatus mit FlÃ¶hen auf den Tieren an. Wir erhalten wiederum
einen Faktor \texttt{infected} mit zwei Leveln \texttt{yes} und
\texttt{no}. Wir sind bei dem \(\mathcal{X}^2\)-Test nicht auf nur
Faktoren mit zwei Leveln eingeschrÃ¤nkt. Traditionell wird aber versucht
ein 2x2 Setting zu erreichen.

Im Bereich der Agrarwissenschaften kommt der \(\mathcal{X}^2\)-Test eher
selten vor. Im Bereich der Humanwissenschaften und vor allem der
Epidemiologie ist der \(\mathcal{X}^2\)-Test weit verbreitet.

Das eigentlich besondere an dem \(\mathcal{X}^2\)-Test ist gra nicht mal
der Test selber sondenr die Datenstruktur die der \(\mathcal{X}^2\)-Test
zugrunde liegt: der Vierfeldertafel oder 2x2 Kreuztabelle. Wir werden
diese Form von Tabelle noch spÃ¤ter im maschinellen Lernen und in der
Testdiagnostik wiederfinden.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Wir rechnen den \(\mathcal{X}^2\)-Test per Hand in der Klausur.
Teilweise fÃ¼llen wir die \(2x2\) Tabelle aus, teilweise berechnen wir
nur die Randsummen.

Bitte schau dir die Aufgaben in den
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub} an um eine Idee zu haben, welche Fragen zum
Wilcoxon-Mann-Whitney-Test drankommen.

Wenn kein \(\chi^2_{\alpha=5\%}\) in der Klausur gegeben ist, setzen wir
\(\chi^2_{\alpha=5\%} = 3.84\).
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-11}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-11}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-fuxfcr-den-mathcalx2-test}{%
\section{\texorpdfstring{Daten fÃ¼r den
\(\mathcal{X}^2\)-Test}{Daten fÃ¼r den \textbackslash mathcal\{X\}\^{}2-Test}}\label{daten-fuxfcr-den-mathcalx2-test}}

Wie eben schon benannt schauen wir uns fÃ¼r den \(\mathcal{X}^2\)-Test
eine Vierfeldertafel oder aber 2x2 Kreuztabelle an. In
Tabelle~\ref{tbl-chi-square-obs} sehen wir eine solche 2x2 Kreuztabelle.
Da wir eine Mindestanzahl an Zellbelegung brauchen um Ã¼berhaupt mit dem
\(\mathcal{X}^2\)-Test rechnen zu kÃ¶nnen, mutzen wir hier gleich
aggrigierte Beispieldaten. Wir brauchen mindestens fÃ¼nf Beobachtungen je
Zelle, dass heiÃt mindestens 20 Tiere. Da wir dann aber immer noch sehr
wenig haben, ist die Daumenregel, dass wir etwa 30 bis 40 Beobachtungen
brauchen. In unserem Beispiel schauen wir uns 65 Tiere an.

\hypertarget{tbl-chi-square-obs}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1463}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0854}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2561}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2561}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2561}}@{}}
\caption{\label{tbl-chi-square-obs}Eine 2x2 Tabelle als Beispiel fÃ¼r
unterschiedliche Flohinfektionen bei Hunden und Katzen. Dargestellt sind
die \emph{beobachteten} Werte.}\tabularnewline
\toprule()
\endhead
& & \textbf{Infected} & & \\
& & \emph{Yes (1)} & \emph{No (0)} & \\
\textbf{Animal} & \emph{Dog} & \(23_{\;\Large a}\) & \(10_{\;\Large b}\)
& \(\mathbf{a+b = 33}\) \\
& \emph{Cat} & \(18_{\;\Large c}\) & \(14_{\;\Large d}\) &
\(\mathbf{c+d = 32}\) \\
& & \(\mathbf{a+c = 41}\) & \(\mathbf{b+d = 24}\) & \(n = 65\) \\
\bottomrule()
\end{longtable}

In der Tabelle sehen wir, dass in den zeieln die Level des Faktors
\texttt{animal} angegeben sind und in den Spalten die Level des Faktors
\texttt{infected}. Wir haben somit \(23\) Hunde, die mit FlÃ¶hen
infiziert sind, dann \(10\) Hunde, die nicht mit FlÃ¶hen infirziert sind.
Auf der Seite der Katzen haben wir \(18\) Katzen, die infiziert sind und
\(14\) Katzen, die keine FlÃ¶he haben. An den RÃ¤ndern stehen die
Randsummen. Wir haben \(33\) Hunde und \(32\) Katzen sowie \(41\)
infizierte Tiere und \(24\) nicht infizierte Tiere. Somit haben wir dann
in Summe \(n = 65\) Tiere. Diese Form der Tabelle wird uns immer wieder
begegnen.

Bevor wir jetzt diese 2x2 Kreuztabelle verwenden, mÃ¼ssen wir uns nochmal
Ã¼berlegen, welchen SchluÃ wir eigentlich Ã¼ber die Nullhypothese machen.
Wie immer kÃ¶nnen wir nur die Nullhypothese ablehnen. Daher Ã¼berlegen wir
uns im Folgenden wie die Nullhypothese in dem \(\mathcal{X}^2\)-Test
aussieht. Dann bilden wir anhand der Nullhypothese noch die
Alternativehypothese.

\hypertarget{hypothesen-fuxfcr-den-mathcalx2-test}{%
\section{\texorpdfstring{Hypothesen fÃ¼r den
\(\mathcal{X}^2\)-Test}{Hypothesen fÃ¼r den \textbackslash mathcal\{X\}\^{}2-Test}}\label{hypothesen-fuxfcr-den-mathcalx2-test}}

Der \(\mathcal{X}^2\)-Test betrachtet die Zellbelegung gegeben den
Randsummen um einen Unterschied nachzuweisen. Daher haben wir die
Nullhypothese als Gleichheitshypothese. In unserem Beispiel lautet die
Nullhypothese, dass die Zahlen in den Zellen gegeben der Randsummen
gleich sind. Wir betrachten hier nur die Hypothesen in Prosa und die
mathematischen Hypothesen. Es ist vollkommen ausreichend, wenn du die
Nullhypothese des \(\mathcal{X}^2\)-Test nur in Prosa kennst.

\[
\begin{align*}
H_0: &\; \mbox{Zellbelegung sind gleichverteilt gegeben der Randsummen}\\
\end{align*}
\]

Die Alternative lautet, dass sich die Zahlen in den Zellen gegeben der
Randsummen unterscheiden.

\[
\begin{align*}
H_A: &\; \mbox{Zellbelegung sind nicht gleichverteilt gegeben der Randsummen}\\
\end{align*}
\]

Wir schauen uns jetzt einmal den \(\mathcal{X}^2\)-Test theoretisch an
bevor wir uns mit der Anwendung des \(\mathcal{X}^2\)-Test in R
beschÃ¤ftigen.

\hypertarget{mathcalx2-test-theoretisch}{%
\section{\texorpdfstring{\(\mathcal{X}^2\)-Test
theoretisch}{\textbackslash mathcal\{X\}\^{}2-Test theoretisch}}\label{mathcalx2-test-theoretisch}}

In Tabelle~\ref{tbl-chi-square-obs} von oben hatten wir die
\emph{beobachteten} Werte. Das sind die Zahlen, die wir in unserem
Experiment erhoben und gemessen haben. Der \(\mathcal{X}^2\)-Test
vergleicht nun die \emph{beobachteten} Werte mit den anhand der
Randsummen zu \emph{erwartenden} Werte. Daher ist die Formel fÃ¼r den
\(\mathcal{X}^2\)-Test wie folgt.

\[
\chi^2_{calc} = \cfrac{(O - E)^2}{E}
\]

mit

\begin{itemize}
\tightlist
\item
  \(O\) fÃ¼r die beobachteten Werte
\item
  \(E\) fÃ¼r die nach den Randsummen zu erwartenden Werte
\end{itemize}

In Tabelle~\ref{tbl-chi-square-exp} kannst du sehen wie wir anhand der
Randsummen die erwartenden Zellbelegungen berechnen. Hierbei kÃ¶nnen auch
krumme Zahlen rauskommen. Wir wÃ¼rden keinen Unterschied zwischen Hunde
und Katzen gegeben deren Infektionsstatus erwarten, wenn die
Abweichungen zwischen den beobachteten Werten und den zu erwartenden
Werten klein wÃ¤ren. Wir berechnen nun die zu erwartenden Werte indem wir
die Randsummen der entsprechenden Zelle multiplizieren und durch die
Gesamtanzahl teilen.

\hypertarget{tbl-chi-square-exp}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1154}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0673}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3365}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3365}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1442}}@{}}
\caption{\label{tbl-chi-square-exp}Eine 2x2 Tabelle als Beispiel fÃ¼r
unterschiedliche Flohinfektionen bei Hunden und Katzen. Dargestellt sind
die zu \emph{erwartenden} Werte.}\tabularnewline
\toprule()
\endhead
& & \textbf{Infected} & & \\
& & \emph{Yes (1)} & \emph{No (0)} & \\
\textbf{Animal} & \emph{Dog} & \(\cfrac{41 \cdot 33}{65} = 20.82\) &
\(\cfrac{24 \cdot 33}{65} = 12.18\) & \(\mathbf{33}\) \\
& \emph{Cat} & \(\cfrac{41 \cdot 32}{65} = 20.18\) &
\(\cfrac{24 \cdot 32}{65} = 11.82\) & \(\mathbf{32}\) \\
& & \(\mathbf{41}\) & \(\mathbf{24}\) & \(n = 65\) \\
\bottomrule()
\end{longtable}

Wir kÃ¶nnen dann die Formel fÃ¼r den \(\mathcal{X}^2\)-Test entsprechend
ausfÃ¼llen. Dabei ist wichtig, dass die AbstÃ¤nde quadriert werden. Das
ist ein Kernkonzept der Statistik, AbstÃ¤nde bzw. Abweichungen werden
immer quadriert.

\begin{align*} 
\chi^2_{calc} &= \cfrac{(23 - 20.82)^2}{20.82} + \cfrac{(10 - 12.18)^2}{12.18} + \\
&\phantom{=}\;\; \cfrac{(18 - 20.18)^2}{20.18} + \cfrac{(14 - 11.82)^2}{11.82} = 1.25
\end{align*}

Es ergibt sich ein \(\chi^2_{calc}\) von \(1.25\) mit der Regel, dass
wenn \(\chi^2_{calc} \geq \chi^2_{\alpha=5\%}\) die Nullhypothese
abgelehnt werden kann. Mit einem \(\chi^2_{\alpha=5\%} = 3.84\) kÃ¶nnen
wir die Nullhypothese nicht ablehnen. Es besteht kein Zusammenhang
zwischen den Befall mit FlÃ¶hen und der Tierart. Oder anders herum, Hunde
und Katzen werden gleich stark mit FlÃ¶hen infiziert.

\hypertarget{mathcalx2-test-in-r}{%
\section{\texorpdfstring{\(\mathcal{X}^2\)-Test in
R}{\textbackslash mathcal\{X\}\^{}2-Test in R}}\label{mathcalx2-test-in-r}}

{\marginnote{\begin{footnotesize}Der \(\mathcal{X}^2\)-Test wird meist
in anderen Funktionen in R verwendet und nicht direkt. Wenn du Fragen
dazu hast, schreib mir einfach eine Mail.\end{footnotesize}}}

Wenn wir den \(\mathcal{X}^2\)-Test in R rechnen wollen nutzen wir die
Funktion \texttt{chisq.test()}, die eine Matrix von Zahlen verlangt.
Dies ist etwas umstÃ¤ndlich.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{23}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{14}\NormalTok{), }
              \AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\FunctionTok{chisq.test}\NormalTok{(mat, }\AttributeTok{correct =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  mat
X-squared = 1.26134, df = 1, p-value = 0.2614
\end{verbatim}

Da der \(\mathcal{X}^2\)-Test nicht so hÃ¤ufig im Bereich der
Agrawissenschaften auftritt belasse ich es \emph{fÃ¼r das Erste} hierbei.
Wenn du noch Fragen hast, komme gerne in R Tutorium oder schreibe mir
eine Mail. Dann kÃ¶nnen wir das Problem nochmal diskutieren und sehen, ob
wirklich ein \(\mathcal{X}^2\)-Test notwendig ist.

\hypertarget{sec-test-diag}{%
\chapter{Der diagnostische Test}\label{sec-test-diag}}

\emph{Version vom September 14, 2022 um 08:50:53}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Was macht der diagnostische Test?}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Ein diagnostischer Test gibt die GÃ¼te einer Klassifizierung wieder. Wir
gut wurden Kranke als krank und Gesunde als gesund erkannt? Diese und
Ã¤hnliche Fragen beantwortet das diagnostische Testen.
\end{tcolorbox}

In diesem Kapitel wollen wir uns mit dem diagnostischen Test
beschÃ¤ftigen. Eigentlich wÃ¼rde man meinen, dass Diagnostik nun eher in
die Medizin gehÃ¶rt. HauptsÃ¤chlich wird das diagnostische Testen auch in
der Labordiagnostik oder bei der Herstellung eines neuen medizinischen
Testes verwendet. Deshalb gibt es hier auch erstmal (Stand Ende 2022)
nur einen Ausschnitt aus dem diagnostischen Testen. Wir brauchen aber
die Fachbegriffe, wenn wir uns spÃ¤ter einmal mit dem maschinellen Lernen
oder dem Klasifizieren beschÃ¤ftigen wollen. Dann brauchen wir die hier
verwendeten Fachbegriffe, wie SpezifitÃ¤t, SensifitÃ¤t, AUC und auch die
ROC Abildung.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Bitte schau dir die Aufgaben in den
\href{https://github.com/jkruppa/teaching/tree/main/Klausur}{gesammelten
Klausurfragen auf GitHub} an um eine Idee zu haben, welche Fragen zum
Diagnostischen Testen drankommen.
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-12}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-12}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, }
\NormalTok{               pROC, readxl)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{die-daten-fuxfcr-das-diagnostische-testen}{%
\section{Die Daten fÃ¼r das diagnostische
Testen}\label{die-daten-fuxfcr-das-diagnostische-testen}}

{\marginnote{\begin{footnotesize}Es ist \textbf{unabdingbar}, dass oben
links in der 2x2 Kreuztabelle immer die \(T^+\) und \(K^+\) Werte
stehen. Sonst funktionieren alle Formeln in diesem Kapitel
nicht.\end{footnotesize}}}

Die Datentabelle fÃ¼r das diagnostische Testen basiert wie der
\(\chi^2\)-Test auf der 2x2 Kreuztabelle oder Verfeldertafel. Es ist
dabei \emph{unabdingbar}, dass oben links in der 2x2 Kreuztabelle immer
die \(T^+\) und \(K^+\) Werte stehen. Sonst funktionieren alle Formeln
in diesem Kapitel nicht. Wir schauen usn auch immer \emph{das Schlechte
an}. Daher wollen wir immer wissen, ist der Hund krank? Ist der Hund
tot? Ist der Hund weggelaufen? Beide Voraussetzung sind wichtig, damit
wir mit der 2x2 Kreuztabelle wie in Tabelle~\ref{tbl-2x2-table-general}
gezeigt rechnen kÃ¶nnen.

\hypertarget{tbl-2x2-table-general}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1333}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1467}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2533}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2533}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2133}}@{}}
\caption{\label{tbl-2x2-table-general}Eine 2x2 Tabelle oder
Vierfeldertafel}\tabularnewline
\toprule()
\endhead
& & \textbf{Krank} & & \\
& & \(K^+\) (1) & \(K^-\) (0) & \\
\textbf{Test} & \(T^+\) (1) & \(TP_{\;\Large a}\) & \(FN_{\;\Large b}\)
& \(\mathbf{a+b}\) \\
& \(T^-\) (0) & \(FP_{\;\Large c}\) & \(TN_{\;\Large d}\) &
\(\mathbf{c+d}\) \\
& & \(\mathbf{a+c}\) & \(\mathbf{b+d}\) & \(\mathbf{n}\) \\
\bottomrule()
\end{longtable}

Wir wollen die Tabelle~\ref{tbl-2x2-table-general} mit einem Beispiel
von \emph{Tollwut} an Hauskatzen in \emph{lÃ¤ndlicher} Umgebung. Die
Katzen haben also Auslauf und kÃ¶nnen sich auch mit Tollwut infizieren.
Wir wollen einen neuen, nicht invasiven Labortesten \emph{Tollda} darauf
Ã¼berprÃ¼fen, wie gut der diagnostische Test Tollwut bei Katzen im
FrÃ¼hstadium erkennt.

Wir haben jetzt folgende Informationen erhalten:

\begin{itemize}
\tightlist
\item
  Der diagnostische Test \emph{TollDa} ist positiv \(T^+\), wenn Tollwut
  vorliegt \(K^+\) , in 80\% der FÃ¤lle.
\item
  Der diagnostische Test \emph{TollDa} ist positiv \(T^+\), wenn
  \emph{keine} Tollwut vorliegt \(K^-\), in 9.5\% der FÃ¤lle.
\item
  AbschlieÃend haben noch 2\% der Katzen in lÃ¤ndlicher Umgebung Tollwut.
  Wir haben eine PrÃ¤valenz der Erkrankung in der betrachteten Population
  von 2\%.
\end{itemize}

Die Halterin einer Katze mÃ¶chte nun wissen, wie groÃ ist dei
Wahrscheinlichkeit bei einem positiven Testergebnis, dass meine Katze
Tollwut hat. Also die bedingte Wahrscheinlichkeit \(Pr(K^+|T^+)\) oder
die Wahrscheinlichkeit krank zu sein gegeben eines positiven Tests.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/diag_testen_doppel.png}

}

\caption{\label{fig-stat-diag-01}Visualisierung der Informationen zur
Tollwutdiagnostik in einem Doppelbaum. Gefragt ist nach der
Wahrscheinlichkeit \(Pr(K^+|T^+)\) oder die Wahrscheinlichkeit krank zu
sein gegeben eines positiven Tests.}

\end{figure*}

Abbildung~\ref{fig-stat-diag-01} visualisert unsere Frage in einem
Doppelbaum. Wir haben 10000 Katzen vorliegen. Ja wir waren fleiÃig und
wir kÃ¶nnen damit besser rechnen. Du siehst aber auch, fÃ¼r die Diagnostik
brauchen wir eine Menge Beobachtungen.

Von den 10000 Katzen sind 2\% also 200 wirklich mit Tollwut infiziert,
also haben den Status \(K^+\). Damit sind 9800 Katzen gesund oder nicht
krank und haben den Status \(K^-\). Wir wissen jetzt, dass 80\% der
\(K^+\) Katzen als postitiv vom Test erkannt werden. Damit werden
\(200 \cdot 0.8 = 160\) Katzen \(T^+\). Im Umkehrschluss sind die
anderen 40 Katzen dann \(T^-\). Von den 9800 gesunden Katzen werden
9.5\% fÃ¤lsch als krank erkannt, also \(9800 \cdot 0.095 = 931\) Katzen.
Wiederum im Umkehrschluss sind dann 8869 richtig als gesunde Tiere
erkannt.

Wir kÃ¶nnen nun den Doppelbaum nach unten ergÃ¤nzen. Wir haben damit
\(1091 = 160 + 931\) positiv getestete Katzen \(T^+\) sowie
\(819 = 40 + 8869\) negativ getestete Katzen \(T^-\).

Wie groÃ ist nun die Wahrscheinlichkeit \(Pr(K^+|T^+)\) oder die
Wahrscheinlichkeit krank zu sein gegeben eines positiven Tests? Wir
kÃ¶nnen die Wahrscheinlichkeit \(Pr(K^+|T^+)\) direkt im Baum ablesen.
Wir haben 160 kranke und positive Tier. Insgesamt sind 1091 Tiere
positiv getestet. Daher Wahrscheinlichkeit krank zu sein gegeben eines
positiven Tests \(\tfrac{160}{1091} = 0.147\) oder nur 14\%.

Sammeln wir unsere Informationen um die
Tabelle~\ref{tbl-2x2-table-general} zu fÃ¼llen. Wir haben insgesamt
\(n = 10000\) Katzen untersucht. In Tabelle~\ref{tbl-2x2-table-example}
sehen wir die Ergebnisse unseres Tests auf Tollwut zusammengefasst. Wir
haben \(160\) Katzen die Tollwut haben und vom Test als krank erkannt
wurden. Dann haben wir \(931\) Katzen, die keine Tollwut hatten und vom
Test als positiv erkannt wurden. DarÃ¼ber hinaus haben wir \(40\) Katzen,
die Tollwut haben, aber ein negatives Testergebnis. Sowie \(8869\)
gesunde Katzen mit einem negativen Testergebnis.

\hypertarget{tbl-2x2-table-example}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1124}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1236}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2472}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2584}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2584}}@{}}
\caption{\label{tbl-2x2-table-example}Eine 2x2 Tabelle oder
Vierfeldertafel gefÃ¼llt mit dem Beispiel aus dem
Doppelbaum.}\tabularnewline
\toprule()
\endhead
& & \textbf{Krank} & & \\
& & \(K^+\) (1) & \(K^-\) (0) & \\
\textbf{Test} & \(T^+\) (1) & 160 & 931 & \(\mathbf{a+b} = 1091\) \\
& \(T^-\) (0) & 40 & 8869 & \(\mathbf{c+d} = 8109\) \\
& & \(\mathbf{a+c} = 200\) & \(\mathbf{b+d} = 9800\) &
\(\mathbf{n} = 10000\) \\
\bottomrule()
\end{longtable}

Wie du sehen kannst ist die mittlere Reihe des Doppelbaums nichts
anderes als die ausgefÃ¼llte 2x2 Kreuztabelle. In
Abbildung~\ref{fig-stat-diag-00} sehen wir die letzte Visualisierung des
Zusammenhangs von Testscore auf der x-Achse und der Verteilung der
tollwÃ¼tigen Katzen \(K^+\) und der gesunden Katzen \(K^-\). Links und
rechts von der Testenstscheidung werden Katzen falsch klassifiziert. Das
heiÃt, die Katzen werden als krank oder gesund von dem Test erkannt,
obwohl die Katzen diesen Status nicht haben. Ein idelr Test wÃ¼rde zwei
Verteilungen der kranken und gesunden Tiere hrvorbringen, die sich
perfekt separieren lassen. Es gibt anhand des Testscores keine
Ãberlappung der beiden Verteilungen

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/diag_testen_dist.png}

}

\caption{\label{fig-stat-diag-00}Visualisierung des Zusammenhangs
zwischen Testscore und den Verteilungen der kranken und gesunden Katzen
sowie der Testenstscheidung. Links und rechts von der Testenstscheidung
werden Katzen falsch klassifiziert.}

\end{figure*}

\hypertarget{confusion-matrix-deu.-fehlermatrix}{%
\section{\texorpdfstring{Confusion matrix (deu.
\emph{Fehlermatrix})}{Confusion matrix (deu. Fehlermatrix)}}\label{confusion-matrix-deu.-fehlermatrix}}

\marginnote{\begin{footnotesize}

Die 2x2 Kreuztabelle wird als
\href{https://en.wikipedia.org/wiki/Confusion_matrix}{Confusion matrix}
viel auch in der Klassifikation im machinellen Lernen genutzt. Im
maschinellen Lernen heiÃt es dann meist nur anders\ldots{}

\end{footnotesize}}

In der Statistik beziehungsweise der Epidemiologie gibt es eine Vielzahl
an statistischen MaÃzahlen fÃ¼r die 2x2 Kreuztabelle. In der Fachsprache
wird die 2x2 Kreuztabelle auch
\href{https://en.wikipedia.org/wiki/Confusion_matrix}{Confusion matrix}
genannt. Auf der Confusion Matrix kÃ¶nnen viele MaÃzahlen berechnet
werden wir konzentrieren uns hier erstmal auf die zwei wichtigsten
MaÃzahlen, nÃ¤mlich der SpezifitÃ¤t und der SensitivitÃ¤t.

In der wissenschaftlichen Fachsprache hat ein diagnostischer Test oder
eine Methode, die erkrankte Personen sehr zuverlÃ¤ssig als krank
(\(K^+\)) erkennt, eine hohe SensitivitÃ¤t. Das heiÃt, sie Ã¼bersieht kaum
erkrankte Personen. Ein Test, der gesunde Personen zuverlÃ¤ssig als
gesund (\(K^-\)) einstuft, hat eine hohe SpezifitÃ¤t. Wir kÃ¶nnen die
SpezifitÃ¤t und die SensitivitÃ¤t auf der 2x2 Kreuztabelle wir folgt
berechnen.

\[
\mbox{SensitivitÃ¤t} = \mbox{sens} = \cfrac{TP}{TP + FN} = \cfrac{160}{160 + 931} = 0.147
\]

\[
\mbox{SpezifitÃ¤t} = \mbox{spec} = \cfrac{TN}{TN + FP} = \cfrac{8869}{8869 + 40} = 0.995
\]

Beide statistischen MaÃzahlen benÃ¶tigen wir im Besonderen bei der
Erstellung der Reciever Operator Curve (ROC) im folgenden Abschnitt.

\hypertarget{receiver-operating-characteristic-roc}{%
\section{Receiver Operating Characteristic
(ROC)}\label{receiver-operating-characteristic-roc}}

Die
\href{https://en.wikipedia.org/wiki/Receiver_operating_characteristic}{Reciever
Operator Curve (ROC)} ist \emph{die} Abbildung wenn es darum geht
darzustellen wie gut eine Klassifikation funktioniert hat. Wir werden
die Abbildung spÃ¤ter im maschinellen Lernen und der Klssifikation
wiedertreffen. Da die ROC Kurve aber ursprÃ¼nglich zum diagnostischen
Testen gehÃ¶rt, kommt die ROC Kurve hier auch rein.

\hypertarget{daten-fuxfcr-die-receiver-operating-characteristic-roc}{%
\subsection{Daten fÃ¼r die Receiver Operating Characteristic
(ROC)}\label{daten-fuxfcr-die-receiver-operating-characteristic-roc}}

Schauen wir uns erstmal ein Beispiel fÃ¼r die ROC Kurve an. In
Tabelle~\ref{tbl-data-roc-1} sehen wir Beispieldaten von vierzehn
Hunden. Von den vierzehn Hunden haben sieben eine verdeckte
Flohinfektion im Anfangsstadium und sieben Hunde sind flohfrei und
gesund. Daher haben wir sieben kranke Hunde (\(K^+\) oder
Infektionsstatus ist \(1\)) und sieben gesunde Hunde (\(K^-\) oder
Infektionsstatus ist \(0\)). Wir \emph{testen} jeden der Hunde mit dem
Flohindikatormittel \emph{FleaDa}. Das Flohindikatormittel gibt einen
Farbwert als \texttt{test\_score} zwischen \(0\) und \(1\) wieder. Wir
wollen nun herausfinden, ob wir mit dem \texttt{test\_score} die
vierzehn Hunde korrekt nach ihrem Krankheitszustand klassifizieren
kÃ¶nnen.

\hypertarget{tbl-data-roc-1}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-data-roc-1}Datensatz fÃ¼r vierzehn Hunde mit
Flohinfektion und keiner Flohinfektion sowie dem Testscore des
Flohindikatormittels \emph{fleaDa}.}\tabularnewline
\toprule()
infected & test\_score \\
\midrule()
\endfirsthead
\toprule()
infected & test\_score \\
\midrule()
\endhead
1 & 0.100 \\
1 & 0.150 \\
1 & 0.250 \\
1 & 0.300 \\
1 & 0.400 \\
1 & 0.500 \\
1 & 0.600 \\
0 & 0.350 \\
0 & 0.425 \\
0 & 0.470 \\
0 & 0.550 \\
0 & 0.700 \\
0 & 0.800 \\
0 & 0.820 \\
\bottomrule()
\end{longtable}

Wir sehen die Daten visualisiert in Abbildung~\ref{fig-labels-roc1}. Auf
der \(y\)-Achse ist der binÃ¤re Endpunkt \(infected\) und auf der
\(x\)-Achse der Testscore des Flohindikators \emph{FleaDa}.

\begin{figure}

{\centering \includegraphics{./stat-tests-diagnostic_files/figure-pdf/fig-labels-roc1-1.pdf}

}

\caption{\label{fig-labels-roc1}Aufteilung der kranken und gesunden
Hunde nach Infektionsstatus und dem Testscore.}

\end{figure}

Die Idee der ROC Kurve ist nun fÃ¼r jeden mÃ¶glichen Wert des Testscores
die SpezifitÃ¤t und SensitivitÃ¤t zu berechnen. Wir mÃ¼ssen das aber nicht
fÃ¼r alle Werte des Testscores machen, sondern nur fÃ¼r die Wert bei denen
sich der Status einer Beobachtung anhand des Testscores Ã¤ndern wÃ¼rde.
Klingt ein wenig schrÃ¤g, schauen wir es uns einmal an. Zuerst brauchen
wir jeweils die Grenzen an denen wir fÃ¼r den Testscore eine
Klassifikation machen. In Abbildung~\ref{fig-labels-roc3} sehen wir die
Grenzen als gelbe Linie.

\begin{figure}

{\centering \includegraphics{./stat-tests-diagnostic_files/figure-pdf/fig-labels-roc3-1.pdf}

}

\caption{\label{fig-labels-roc3}Aufteilung der kranken und gesunden
Hunde nach Infektionsstatus und dem Testscore.}

\end{figure}

Wir kÃ¶nnen jetzt fÃ¼r jede gelbe Linie als Threshold des Testscore die
SpezifitÃ¤t und die SensitivitÃ¤t berechen. berechnen
Tabelle~\ref{tbl-data-roc-2} sind die Werte von SpezifitÃ¤t und
SensitivitÃ¤t fÃ¼r jede gelbe Linie ausgegeben. Wenn wir als
Entscheidungsgrenze einen Testscore von 0.12 nehmen wÃ¼rden, dann wÃ¼rden
wir 1 Hund als krank und 13 als gesund klassifizieren. Wir hÃ¤tten 7 TN,
1 TP, 6 FN und 0 FP. Aus diesen Zahlen, die eine 2x2 Kreuztabelle
entsprechen, kÃ¶nnen wir dann die SpezifitÃ¤t und die SensitivitÃ¤t
berechnen. Wir berechnen dann die SpezifitÃ¤t und die SensitivitÃ¤t fÃ¼r
jeden Threshold.

\hypertarget{tbl-data-roc-2}{}
\begin{longtable}[]{@{}lccccccc@{}}
\caption{\label{tbl-data-roc-2}Die SpezifitÃ¤t und die SensitivitÃ¤t
berechnet fÃ¼r jeden Threshold.}\tabularnewline
\toprule()
& threshold & specificity & sensitivity & tn & tp & fn & fp \\
\midrule()
\endfirsthead
\toprule()
& threshold & specificity & sensitivity & tn & tp & fn & fp \\
\midrule()
\endhead
2 & 0.12 & 1.00 & 0.14 & 7 & 1 & 6 & 0 \\
3 & 0.20 & 1.00 & 0.29 & 7 & 2 & 5 & 0 \\
4 & 0.28 & 1.00 & 0.43 & 7 & 3 & 4 & 0 \\
5 & 0.32 & 1.00 & 0.57 & 7 & 4 & 3 & 0 \\
6 & 0.38 & 0.86 & 0.57 & 6 & 4 & 3 & 1 \\
7 & 0.41 & 0.86 & 0.71 & 6 & 5 & 2 & 1 \\
8 & 0.45 & 0.71 & 0.71 & 5 & 5 & 2 & 2 \\
9 & 0.48 & 0.57 & 0.71 & 4 & 5 & 2 & 3 \\
10 & 0.52 & 0.57 & 0.86 & 4 & 6 & 1 & 3 \\
11 & 0.58 & 0.43 & 0.86 & 3 & 6 & 1 & 4 \\
12 & 0.65 & 0.43 & 1.00 & 3 & 7 & 0 & 4 \\
13 & 0.75 & 0.29 & 1.00 & 2 & 7 & 0 & 5 \\
14 & 0.81 & 0.14 & 1.00 & 1 & 7 & 0 & 6 \\
\bottomrule()
\end{longtable}

Wir kÃ¶nnen jetzt fÃ¼r jeden Threshold und damit jedes verbundene
SpezifitÃ¤t und SensitivitÃ¤t Paar einen Punkt in einen Plot einzeichnen.
Wir lassen damit StÃ¼ck fÃ¼r StÃ¼ck die ROC Kurve wachsen.

In der Abbildung~\ref{fig-roc-drawn-1} sehen wir die ROC Kurve mit dem
Threshold von 0.32 vorliegen. Wir haben damit 7 TN, 4 TP, 3 FN und 0 FP
klassifizierte Beobchtungen. Darauf ergibt sich eine SpezifitÃ¤t von 1
und eine SensitivitÃ¤t von 0.57. In der ROC Kurve tragen wir auf die
\(x\)-Achse die 1 - SpezifitÃ¤tswerte auf. Damit haben wir eine schÃ¶n
ansteigende Kurve.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/diag-roc-01.png}

}

\caption{\label{fig-roc-drawn-1}Visualisierung des Anwachsen der ROC
Kurve mit einem Threshold von 0.32 und damit 7 TN, 4 TP, 3 FN und 0 FP.}

\end{figure*}

In der Abbildung~\ref{fig-roc-drawn-2} istr die ROC Kurve schon nach
rechts gewachsen, da wir die ersten falsch positiv (FP) klassifizierten
Beobachtungen bei einem Threshold von 0.48 erhalten.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/diag-roc-02.png}

}

\caption{\label{fig-roc-drawn-2}Visualisierung des Anwachsen der ROC
Kurve mit einem Threshold von 0.48 und damit 4 TN, 5 TP, 2 FN und 3 FP.}

\end{figure*}

In Abbildung~\ref{fig-roc-drawn-3} sind wir mit einem Threshold von 0.65
schon fast am rechten Rand der Verteilung des Testscores angekommen. Wir
haben nur noch 3 richtig negative (TN) Beobachtungen, die jetzt mit
steigenden Threshold alle zu falsch positiven (FP) klassifiziert werden.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/diag-roc-03.png}

}

\caption{\label{fig-roc-drawn-3}Visualisierung des Anwachsen der ROC
Kurve mit einem Threshold von 0.65 und damit 3 TN, 7 TP, 0 FN und 4 FP.}

\end{figure*}

{\marginnote{\begin{footnotesize}Ein AUC von 1 bedeutet eine perfekte
Trennung der beiden Gruppen durch den Testscore. Ein AUC von 0.5
bedeutet keine Trennung der beiden Gruppen durch den
Testscore.\end{footnotesize}}}

Die ROC Kurve endet dann oben rechts in der Abbidlung und startet immer
unten links. Wir kÃ¶nnen noch die FlÃ¤che unter der ROC Kurve berechnen.
Wir nennen diese FlÃ¤che unter der Kurve AUC (eng. \emph{area under the
curce}) und wir brauchen diese MaÃzahl, wenn wir verschiedene Testscores
und die entsprechenden ROC Kurven miteinander vergleichen wollen. Eine
AUC von 0.5 bedeutet, dass unser Testscore nicht in der Lage war die
kranken von den gesunden Hunden zu trennen.

\hypertarget{reciever-operator-curve-roc-in-r}{%
\section{Reciever Operator Curve (ROC) in
R}\label{reciever-operator-curve-roc-in-r}}

Wir berechnen die ROC Kurve nicht per Hand. Das wÃ¤re eine sehr groÃe
FleiÃarbeit fÃ¼r jeden Threshold zwischen den Beobachtungen die jeweilige
SpezifitÃ¤t und SensitivitÃ¤t Paare zu berechnen. Wir nutzen daher das R
Paket \texttt{pROC}. Das Pakt erlaubt es uns spÃ¤ter auch recht einfach
ROC Kurven miteinander zu vergleichen und einen statistischen Test zu
rechnen.

Die Daten von den obigen Beispiel sind in der Datei
\texttt{roc\_data.xlsx} gespeichert und kÃ¶nnen dann einfach verwendet
werden. Die Funktion \texttt{roc()} akzeptiert ein binÃ¤res \(y\) wo bei
die \(1\) das Schlechte bedeutet und die \(0\) die Abwesenheit von dem
Schlechten. Also eben krank oder gesund wie oben beschrieben. Wir wollen
dann noch die AUC und die 95\% Konfidenzintervalle fÃ¼r das AUC
wiedergegeben haben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/roc\_data.xlsx"}\NormalTok{) }

\NormalTok{roc\_obj }\OtherTok{\textless{}{-}} \FunctionTok{roc}\NormalTok{(infected }\SpecialCharTok{\textasciitilde{}}\NormalTok{ test\_score, roc\_tbl, }\AttributeTok{auc =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ci =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{roc\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
roc.formula(formula = infected ~ test_score, data = roc_tbl,     auc = TRUE, ci = TRUE)

Data: test_score in 7 controls (infected 0) > 7 cases (infected 1).
Area under the curve: 0.83673
95% CI: 0.61765-1 (DeLong)
\end{verbatim}

Wir sehen, dass wir eine AUC von 0.837 haben, was auf eine gute
TrennschÃ¤rfe des Tests hindeutet. WÃ¤re die AUC nÃ¤her an 0.5 dann wÃ¼rden
wir sagen, dass der Test die kranken Hunde nicht von den gesunden Hunden
unterscheiden kann.

Im nÃ¤chsten Schritt extrahieren wir noch alle wichtigen Informationen
aus dem Objekt \texttt{roc\_obj} damit wir die ROC Kurve in
\texttt{ggplot} zeichnen kÃ¶nnen. Das Paket pROC hat auch eine eigne
Plotfunktion. Es gibt eine Reihe on
\href{https://web.expasy.org/pROC/screenshots.html}{Screenshots vom pROC
Paket}, wo du noch andere MÃ¶glichkeiten siehst. Einfach mal
ausprobieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc\_res\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ roc\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{coords}\NormalTok{(}\AttributeTok{ret =} \StringTok{"all"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(specificity, sensitivity)}
\end{Highlighting}
\end{Shaded}

Das Objekt \texttt{roc\_obj} nutzen wir jetzt um die ROC Kurve einmal
darzustellen. Achte drauf, dass auf der \(x\)-Achse die 1-SpezifitÃ¤t
Werte stehen. Wir erhalten die ROC Kurve wie in
Abbildung~\ref{fig-labels-roc2} dargestellt. Wie zeichnen noch die
Diagonale ein. Wenn die ROC nahe an der Diagonalen verlÃ¤uft, dann ist
der Testscore nicht in der Lage die Kranken von den Gesunden zu trennen.
Eine perfekte ROC Kurve lÃ¤uft senkrecht nach oben und dann waagerecht
nach rechts und es ergebit sich eine AUC von 1.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(roc\_res\_tbl, }\FunctionTok{aes}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{specificity, sensitivity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_path}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.75}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"1 {-} SpezifitÃ¤t"}\NormalTok{, }\AttributeTok{y =} \StringTok{"SensitivitÃ¤t"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-diagnostic_files/figure-pdf/fig-labels-roc2-1.pdf}

}

\caption{\label{fig-labels-roc2}Abbildung der ROC Kurve.}

\end{figure}

In spÃ¤teren Kapiteln zur Klassifikation werden wir auch verschiedene ROC
Kurven zusammen darstellen und miteinander Vergleichen. Dazu nutzen wir
dann auch die ROC Kurve und die MÃ¶glichkeit auch einen
\texttt{roc.test()} zu rechnen. Mehr dazu gibt es soweit erstmal auf der
Hilfeseite des R Paketes \texttt{pROC} mit vielen
\href{https://web.expasy.org/pROC/screenshots.html}{Screenshots vom pROC
Paket}. FÃ¼r dieses Kapitel soll die Darstellung einer ROC Kurve genÃ¼gen.

\hypertarget{pre-tests-oder-vortest}{%
\chapter{Pre-Tests oder Vortest}\label{pre-tests-oder-vortest}}

\emph{Version vom September 14, 2022 um 08:51:11}

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Probleme mit dem Pre-Tests ist, dass die Fallzahl in unseren Daten \(D\)
oft \textbf{viel zu klein} ist um eine eindeutige Aussage zu treffen.

Der Pre-Test, ein Kapiel was ich nicht mag. Also eher weniger das
Kapitel als den Pre-Test. Auf der einen Seite sind die Pre-Tests
hoffnungslos veraltet. Pre-Tests stammen aus einer Zeit in der man sich
nicht einfach die Daten angucken konnte. Mit angucken meine ich dann in
\texttt{ggplot} visualisieren. Die Idee hinter Pre-Test ist eigentlich
die Angst selber die Entscheidung zu treffen, ob die Daten
varianzhomogen oder normalverteilt sind. Eine bessere LÃ¶sung ist immer
noch das Outcome \(y\) zu transformieren (siehe
Kapitel~\ref{sec-eda-transform}) und dann das untransformierte Modell
mit transformierten Modell zu vergleichen (siehe
Kapitel~\ref{sec-model-basic-compare}). Auf der anderen Seite ist der
Pre-Test eine Art Ã¼bermÃ¤chtiger Entscheider. Dabei sind die Formel sehr
trivial und das Konzept eher simpel.

Neben dieser Angst eine Entscheidung zu treffen, hilft einem der
Pre-Test zur VarianzhomogenitÃ¤t und der Pre-Test zur Normalverteilung
bei kleiner Fallzahl auch nicht wirklich weiter, wie wir gleich sehen
werden. Beide Pre-Tests funktionieren erst bei wirklich hohen Fallzahlen
gut. Mit hohen Fallzahlen meine ich, Fallzahlen von Ã¼ber 20
Beobachtungen \emph{je Gruppe} bzw. Level des Faktors. Bei kleiner
Fallzahl, also der Ã¼blichen Anzahl von weniger als zehn Wiederholungen,
kÃ¶nnen wir auch nur die Boxplots oder Dotplots anschauen. DarÃ¼ber hinaus
kÃ¶nnen wir uns auch schnell ins Abseits testen, so dass wir gar keinen
Test mehr Ã¼brig haben um unsere Daten auszuwerten.

Es ist grundsÃ¤tzlich besser verschiedene Modelle zu fitten und dann sich
in Kapitel~\ref{sec-lin-reg-quality} die GÃ¼te oder QualitÃ¤t der Modelle
anzuschauen. Jedenfalls ist das meiner Meinung nach die bessere LÃ¶sung.
Da aber immer wieder nach den Pre-Tests gefragt wird, habe ich auch
dieses Kapitel erschaffen.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-13}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-13}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted,}
\NormalTok{               broom, car, performance, see)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{pre-test-auf-varianzhomogenituxe4t}{%
\section{Pre-Test auf
VarianzhomogenitÃ¤t}\label{pre-test-auf-varianzhomogenituxe4t}}

Was will also der Pre-Test auf VarianzhomogenitÃ¤t? Eigentlich ist der
Test vollkommen verquer. Zum einen testet der Test auf
VarianzhomogenitÃ¤t gar nicht die \emph{Anwesenheit} von HomogenitÃ¤t. Wir
kÃ¶nnen dank dem Falisifikationsprinzip nur Ablehnen. Deshalb steht in
der Nullhypothese die Gleichheit der Varianzen, also VarianzhomogenitÃ¤t
und in der Alternativen dann die VarianzheterogenitÃ¤t, als der
Unterschied.

Ab wann sollten wir denn die VarianzhomogenitÃ¤t ablehnen? Wenn wir
standardmÃ¤Ãig auf 5\% testen, dann werden wir zu selten die
VarianzhomogenitÃ¤t ablehnen. Daher ist es ratsam in diesem Fall auf ein
Signifikanzniveau von \(\alpha\) gleich 20\% zu testen. Aber auch in
diesem Fall kÃ¶nnen wir natÃ¼rlich eine VarianzhomogenitÃ¤t Ã¼bersehen oder
aber eine VarianzhterogenitÃ¤t fÃ¤lschlicherweise annehmen.

Es ergeben sich folgende Hypothesen fÃ¼r den Pre-Test auf
VarianzhomogenitÃ¤t.

\[
\begin{align*}
H_0: &\; s^2_A = s^2_B\\
H_A: &\; s^2_A \ne s^2_B\\
\end{align*}
\]

Wir sehen, dass in der Nullhypothese die Gleichheit der Varianzen steht
und in der Alternativehypothese der Unterschied, also die
VarianzhterogenitÃ¤t.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung zur VarianzhomogenitÃ¤t}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung zur VarianzhomogenitÃ¤t gilt folgende Regel. Ist der
\(p\)-Wert des Pre-Tests auf VarianzhomogenitÃ¤t kleiner als das
Signifikanzniveau \(\alpha\) von 20\% lehnen wir die Nullhypothese ab.
Wir nehmen VarianzheterogenitÃ¤t an.

\begin{itemize}
\tightlist
\item
  Ist \(p \leq \alpha = 20\%\) so nehmen wir VarianzheterogenitÃ¤t an.
\item
  Ist \(p > \alpha = 20\%\) so nehmen wir VarianzhomogenitÃ¤t an.
\end{itemize}

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf
VarianzhomogenitÃ¤t nochmal visuell bestÃ¤tigen.
\end{tcolorbox}

Wir nutzen zum statistischen Testen den Levene-Test Ã¼ber die Funktion
\texttt{leveneTest()} oder den Bartlett-Test Ã¼ber die Funktion
\texttt{bartlett.test()}. Beide Tests sind in R implementiert und kÃ¶nnen
Ã¼ber das Paket \texttt{car} genutzte werden. Wir werden uns jetzt nicht
die Formel anschauen, wir nutzen wenn die beiden Tests nur in R und
rechnen nicht selber die Werte nach.

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

EinigermaÃen zuverlÃ¤ssig meint, dass wir dann in 1 von 20 FÃ¤llen eine
VarianzhomogenitÃ¤t ablehnen, obwohl eine VarianzhomogenitÃ¤t vorliegt.
Ebenso kÃ¶nnen wir in 1 von 5 FÃ¤llen die Nullhypothese nicht ablehnen,
obwohl die Varianzen heterogen sind (siehe auch
Kapitel~\ref{sec-alpha-beta}).

Wir wollen uns nun zwei FÃ¤lle einmal nÃ¤her anschauen. Zum einen den
Fall, dass wir eine niedrige Fallzahl vorliegen haben und
VarianzhomogenitÃ¤t sowie den Fall, dass wir eine niedriege Fallzahl und
VarianzheterogenitÃ¤t vorliegen haben. Den Fall, dass wir hohe Fallzahl
vorliegen haben, betrachten wir jetzt nicht weiter. In dem Fall
funktionieren die Tests einigigermaÃen zuverlÃ¤ssig.

\hypertarget{varianzen-sind-homogen-fallzahl-niedrig}{%
\section{Varianzen sind homogen, Fallzahl
niedrig}\label{varianzen-sind-homogen-fallzahl-niedrig}}

Wir bauen uns nun einen Datensatz mit zwei Gruppen \(A\) und \(B\) zu je
zehn Beobachtungen. Beide Gruppen kommen aus einer Normalverteilung mit
einem Mittelwert von \(\bar{y}_A = \bar{y}_A = 10\). DarÃ¼ber hinaus
haben wir VarianzhomogenitÃ¤t mit \(s_A = s_B = 5\) vorliegen. Ja, wir
spezifizieren hier in der Funktion \texttt{rnorm()} die
Standardabweichung, aber eine homogene Standardabweichung bedingt eine
homogene Varianz und umgekehrt. AbschlieÃend verwandeln wir das
Wide-Format noch in das Long-Format um.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{202209013}\NormalTok{)}
\NormalTok{small\_homogen\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{5}\NormalTok{),}
                            \AttributeTok{B =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(trt, rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =} \FunctionTok{as\_factor}\NormalTok{(trt))}
\end{Highlighting}
\end{Shaded}

In der Abbildung~\ref{fig-vartest-1} sehen wir die Daten aus dem
\texttt{small\_homogen\_tbl} einmal als Boxplot visualisiert.

\begin{figure}

{\centering \includegraphics{./stat-tests-pretest_files/figure-pdf/fig-vartest-1-1.pdf}

}

\caption{\label{fig-vartest-1}Boxplot der beiden Treatment Level A und
B. Beide Gruppen haben die gleichen Varianzen. Es liegt
VarianzhomogenitÃ¤t vor.}

\end{figure}

Wir wollen nun die Varianz auf HomogenitÃ¤t testen. Wir nutzen dafÃ¼r den
\texttt{levenTest()} sowie den \texttt{bartlett.test()}. Beide Tests
bieten sich an. Die Daumenregel ist, dass der Bartlett-Test etwas
bessere statistische Eigenschaften hat. Dennoch ist der Levene-Test
bekannter und wird hÃ¤ufiger angefragt und genutzt. Wir nutzen die
Funktion \texttt{tidy()} aus dem Paket \texttt{broom} um die Ausgabe
aufzurÃ¤umen und selektieren nur den \(p\)-Wert.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{leveneTest}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_homogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(p.value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 1
  p.value
    <dbl>
1   0.345
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bartlett.test}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_homogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(p.value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 1
  p.value
    <dbl>
1   0.325
\end{verbatim}

Wir sehen, dass der \(p\)-Wert grÃ¶Ãer ist als das Signifikanzniveau
\(\alpha\) von 20\%. Damit kÃ¶nnen wir die Nullhypothese nicht ablehnen.
Wir nehmen VarianzhomogenitÃ¤t an. Ãberdies sehen wir auch, dass sich die
\(p\)-Werte nicht groÃ voneinander unterscheiden.

Wir kÃ¶nnen auch die Funktion \texttt{check\_homogeneity()} aus dem Paket
\texttt{performance} nutzen. Wir erhalten hier auch gleich eine
Entscheidung in englischer Sprache ausgegeben. Die Funktion
\texttt{check\_homogeneity()} nutzt den Bartlett-Test. Wir kÃ¶nnen in
Funktion auch andere Methoden mit
\texttt{method\ =\ c("bartlett",\ "fligner",\ "levene",\ "auto")}
wÃ¤hlen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_homogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{check\_homogeneity}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.325).
\end{verbatim}

Wir nutzen das Paket \texttt{performance} fÃ¼r die ModellgÃ¼te im
Kapitel~\ref{sec-lin-reg-quality}.

\hypertarget{varianzen-sind-heterogen-fallzahl-niedrig}{%
\section{Varianzen sind heterogen, Fallzahl
niedrig}\label{varianzen-sind-heterogen-fallzahl-niedrig}}

Nun stellt sich die Frage, wie sieht es aus, wenn wir ungleiche
Varianzen vorliegen haben. Wir bauen uns nun einen Datensatz mit zwei
Gruppen \(A\) und \(B\) zu je zehn Beobachtungen. Beide Gruppen kommen
aus einer Normalverteilung mit einem Mittelwert von
\(\bar{y}_A = \bar{y}_A = 12\). DarÃ¼ber hinaus haben wir
VarianzheterogenitÃ¤t mit \(s_A = 10 \ne s_B = 5\) vorliegen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{202209013}\NormalTok{)}
\NormalTok{small\_heterogen\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{12}\NormalTok{),}
                              \AttributeTok{B =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(trt, rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =} \FunctionTok{as\_factor}\NormalTok{(trt))}
\end{Highlighting}
\end{Shaded}

In der Abbildung~\ref{fig-vartest-2} sehen wir die Daten aus dem
\texttt{small\_heterogen\_tbl} einmal als Boxplot visualisiert.

\begin{figure}

{\centering \includegraphics{./stat-tests-pretest_files/figure-pdf/fig-vartest-2-1.pdf}

}

\caption{\label{fig-vartest-2}Boxplot der beiden Treatment Level A und
B. Beide Gruppen haben ungleiche Varianzen. Es liegt
VarianzheterogenitÃ¤t vor.}

\end{figure}

Wir wollen nun die Varianz auf HomogenitÃ¤t testen. Wir nutzen dafÃ¼r den
\texttt{levenTest()} sowie den \texttt{bartlett.test()}. Wir kÃ¶nnen nur
die VarianzhomogenitÃ¤t testen, da jeder statistischer Test nur eine
Aussage Ã¼ber die Nullhypothese erlaubt. Damit kÃ¶nnen wir hier nur die
VarianzhomogenitÃ¤t testen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{leveneTest}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_heterogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(p.value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 1
  p.value
    <dbl>
1  0.0661
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bartlett.test}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_heterogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(p.value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 1
  p.value
    <dbl>
1   0.127
\end{verbatim}

Wir sehen, dass der \(p\)-Wert kleiner ist als das Signifikanzniveau
\(\alpha\) von 20\%. Damit kÃ¶nnen wir die Nullhypothese ablehnen. Wir
nehmen VarianzheterogenitÃ¤t an. Ãberdies sehen wir auch, dass sich die
\(p\)-Werte nicht groÃ voneinander unterscheiden. Was wir sehen ist,
dass wir zu einem Signifikanzniveau von 5\% die klare
VarianzheterogenitÃ¤t nicht erkannt hÃ¤tten und immer noch
VarianzhomogenitÃ¤t angenommen hÃ¤tten.

Wir kÃ¶nnen auch die Funktion \texttt{check\_homogeneity()} aus dem Paket
\texttt{performance} nutzen. Wir erhalten hier auch gleich eine
Entscheidung in englischer Sprache ausgegeben. Die Funktion
\texttt{check\_homogeneity()} nutzt den Bartlett-Test. Wir kÃ¶nnen in
Funktion auch andere Methoden mit
\texttt{method\ =\ c("bartlett",\ "fligner",\ "levene",\ "auto")}
wÃ¤hlen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt, }\AttributeTok{data =}\NormalTok{ small\_heterogen\_tbl) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{check\_homogeneity}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.127).
\end{verbatim}

Wir sehen, dass sich die Implementierung des Bartlett-Tests in
\texttt{check\_homogeneity()} nicht von der Funktion
\texttt{bartlett.test()} unterscheidet, aber die Entscheidung gegen die
VarianzhomogenitÃ¤t zu einem Signifikanzniveau von 5\% gefÃ¤llt wird.
Nicht immer hilft einem der Entscheidungtext einer Funktion.

\hypertarget{pre-test-auf-normalverteilung}{%
\section{Pre-Test auf
Normalverteilung}\label{pre-test-auf-normalverteilung}}

Wir treffen bei dem Test auf die Normalverteilung auch auf das gleiche
Problem wie bei dem Pre-Test zur VarianzhomogenitÃ¤t. Wir haben wieder
die Gleichheit, also das unser beobachtetes Outcome gleich einer
Normalverteilung ist, in der Nullhypothese stehen. Den Unterschied, also
das unser beobachtetes Outcome nicht aus einer Normalverteilung kommmt,
in der Alternative.

\[
\begin{align*}
H_0: &\; \mbox{y ist gleich normalverteilt}\\
H_A: &\; \mbox{y ist nicht gleich normalverteilt}\\
\end{align*}
\]

Nun ist es aber so, dass es nicht nur \emph{zwei} Verteilungen gibt. Es
gibt mehr als die Normalverteilung und die
\emph{Nicht}-normalverteilung. Wir haben eine groÃe Auswahl an mÃ¶glichen
Verteilungen und seit den 90zigern des letzten Jahrhunderts auch die
MÃ¶glichkeiten andere Verteilungen des Outcomes \(y\) zu modellieren.
Leider fÃ¤llt dieser Fortschritt hÃ¤ufig unter den Tisch und wir bleiben
gefangen zwischen der Normalverteilung oder eben keiner
Normalverteilung.

\marginnote{\begin{footnotesize}

Der
\href{https://de.wikipedia.org/wiki/Zentraler_Grenzwertsatz}{zentrale
Grenzwertsatz} besagt, dass wenn ein \(y\) von vielen Einflussfaktoren
\(x\) bestimmt wird, man von einem normalverteilten \(y\) ausgehen.

Das Gewicht wird von vielen Einflussfaktoren wie Sport, Kalorienaufnahme
oder aber Veranlagung sowie vielem mehr bestimmt. Wir kÃ¶nnen davon
ausgehen, dass das Gewicht normalverteilt ist.

\end{footnotesize}}

AbschlieÃend sei noch gesagt, dass es fast unmÃ¶glich ist, eine
Verteilung mit weniger als zwanzig Beobachtungen Ã¼berhaupt abzuschÃ¤tzen.
Selbst dann kÃ¶nnen einzelne Beobachtunge an den RÃ¤ndern der Verteilung
zu einer Ablehnung der Normalverteilung fÃ¼hren, obwohl eine
Normalverteilung vorliegt.

Am Ende sei noch auf den \protect\hyperlink{sec-linreg-qq}{QQ-plot}
verwiesen, mit dem wir auch visuell Ã¼berprÃ¼fen kÃ¶nnen, ob eine
Normalverteilung vorliegt.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Entscheidung zur Normalverteilung}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
Bei der Entscheidung zur Normalverteilung gilt folgende Regel. Ist der
\(p\)-Wert des Pre-Tests auf Normalverteilung kleiner als das
Signifikanzniveau \(\alpha\) von 5\% lehnen wir die Nullhypothese ab.
Wir nehmen eine Nicht-Normalverteilung an.

\begin{itemize}
\tightlist
\item
  Ist \(p \leq \alpha = 5\%\) so nehmen wir Nicht-Normalverteilung von
  \(y\) an.
\item
  Ist \(p > \alpha = 5\%\) so nehmen wir Normalverteilung von \(y\) an.
\end{itemize}

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf
Normalverteilung nochmal visuell bestÃ¤tigen.
\end{tcolorbox}

\hypertarget{approximativ-normalverteilt-niedrige-fallzahl}{%
\section{Approximativ normalverteilt, niedrige
Fallzahl}\label{approximativ-normalverteilt-niedrige-fallzahl}}

Auch hier schauen wir uns den Fall mit einer niedrigen Fallzahl an.
DafÃ¼r bauen wir usn erstmal Daten mit der Funktion \texttt{rt()}. Wir
ziehen uns zufÃ¤llig Beobachtungen aus einer t-Verteilung, die
approximativ normalverteilt ist. Je hÃ¶her die Freiheitsgrade \texttt{df}
desto nÃ¤her kommt die t-Verteilung einer Normalverteilung. Mit einem
Freiheitsgrad von \texttt{df\ =\ 30} sind wir sehr nah an einer
Normalverteilung dran.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{202209013}\NormalTok{)}
\NormalTok{low\_normal\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rt}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{df =} \DecValTok{30}\NormalTok{),}
                         \AttributeTok{B =} \FunctionTok{rt}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{df =} \DecValTok{30}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(trt, rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =} \FunctionTok{as\_factor}\NormalTok{(trt))}
\end{Highlighting}
\end{Shaded}

In Abbildung~\ref{fig-normal-1} sehen wir auf der linken Seite den
Dotplot der zehn Beobachtungen aus den beiden Gruppen \(A\) und \(B\).
Wir sehen, dass die Verteilung fÃ¼r das Outcome \texttt{rsp} in etwa
normalverteilt ist.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-pretest_files/figure-pdf/fig-normal-1-1.pdf}

}

}

\subcaption{\label{fig-normal-1-1}Dotplot des Outcomes \texttt{rsp}.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-pretest_files/figure-pdf/fig-normal-1-2.pdf}

}

}

\subcaption{\label{fig-normal-1-2}Densityplot des Outcomes
\texttt{rsp}.}
\end{minipage}%

\caption{\label{fig-normal-1}Verteilung des Outcomes \texttt{rsp} der
zehn Beobachtungen aus den Gruppen \(A\) und \(B\). Beiden Gruppen
kommen aus einer t-Verteilung.}

\end{figure*}

Wir kÃ¶nnen den Shapiro-Wilk-Test nutzen um statistisch zu testen, ob
eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber
nicht, welche \emph{andere} Verteilung vorliegt. Wir testen natÃ¼rlich
fÃ¼r die beiden Gruppen getrennt. Die Funktion
\texttt{shapiro.test()}kann nur mit einem Vektor von Zahlen arbeiten,
daher Ã¼bergeben wir mit \texttt{pull} die entsprechend gefilterten Werte
des Outcomes \texttt{rsp}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{low\_normal\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(trt }\SpecialCharTok{==} \StringTok{"A"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{shapiro.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  .
W = 0.945699, p-value = 0.61797
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{low\_normal\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(trt }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{shapiro.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  .
W = 0.89291, p-value = 0.18282
\end{verbatim}

Wir sehen, dass der \(p\)-Wert grÃ¶Ãer ist als das Signifikanzniveau
\(\alpha\) von 5\% fÃ¼r beide Gruppen. Damit kÃ¶nnen wir die Nullhypothese
nicht ablehnen. Wir nehmen eine Normalverteilung an.

In dem folgendem Beispiel sehen wir dann aber, was ich mit in die Ecke
testen meine bzw. so lange statistisch zu Testen bis nichts mehr geht.

\hypertarget{nicht-normalverteilt-niedrige-fallzahl}{%
\section{Nicht normalverteilt, niedrige
Fallzahl}\label{nicht-normalverteilt-niedrige-fallzahl}}

Schauen wir uns jetzt den anderen Fall an. Wir haben jetzt wieder eine
niedrige Fallzahl mit je 10 Beobachtungen je Gruppe \(A\) und \(B\). In
diesem Fall kommen die Beobachtungen aber aus einer exponentiellen
Verteilung. Wir haben also definitiv keine Normalverteilung vorliegen.
Wir generieren uns die Daten mit der Funktion \texttt{rexp()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{202209013}\NormalTok{)}
\NormalTok{low\_nonnormal\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rexp}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{1500}\NormalTok{),}
                            \AttributeTok{B =} \FunctionTok{rexp}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{1500}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(trt, rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =} \FunctionTok{as\_factor}\NormalTok{(trt))}
\end{Highlighting}
\end{Shaded}

In Abbildung~\ref{fig-normal-2} sehen wir auf der linken Seite den
Dotplot der zehn Beobachtungen aus den beiden Gruppen \(A\) und \(B\).
Wir sehen, dass die Verteilung fÃ¼r das Outcome fÃ¼r die Behandlung \(B\)
in etwa normalverteilt ist sowie das das Outcome fÃ¼r die Behandlung
\(A\) keiner Normalverteilung folgt \emph{oder} zwei AusreiÃer hat. Die
Entscheidung was jetzt stimmt ohne zu wissen wie die Daten generiert
wurden, ist in der Anwendung meist nicht mÃ¶glich.

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-pretest_files/figure-pdf/fig-normal-2-1.pdf}

}

}

\subcaption{\label{fig-normal-2-1}Dotplot des Outcomes \texttt{rsp}.}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-tests-pretest_files/figure-pdf/fig-normal-2-2.pdf}

}

}

\subcaption{\label{fig-normal-2-2}Densityplot des Outcomes
\texttt{rsp}.}
\end{minipage}%

\caption{\label{fig-normal-2}Verteilung des Outcomes \texttt{rsp} der
zehn Beobachtungen aus den Gruppen \(A\) und \(B\). Beiden Gruppen
kommen aus einer Exponentialverteilung.}

\end{figure*}

Wir kÃ¶nnen wieder den Shapiro-Wilk-Test nutzen um statistisch zu testen,
ob eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber
nicht, welche \emph{andere} Verteilung vorliegt. Wir testen natÃ¼rlich
fÃ¼r die beiden Gruppen getrennt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{low\_nonnormal\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(trt }\SpecialCharTok{==} \StringTok{"A"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{shapiro.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  .
W = 0.771138, p-value = 0.0064566
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{low\_nonnormal\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(trt }\SpecialCharTok{==} \StringTok{"B"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(rsp) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{shapiro.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  .
W = 0.933164, p-value = 0.47973
\end{verbatim}

Wir sehen, dass der \(p\)-Wert fÃ¼r die Behandlung \(A\) kleiner ist als
das Signifikanzniveau \(\alpha\) von 5\%. Damit kÃ¶nnen wir die
Nullhypothese ablehnen. Wir nehmen keine Normalverteilung fÃ¼r Gruppe
\(A\) an. Auf der anderen Seite sehen wir, dass der \(p\)-Wert fÃ¼r die
Behandlung \(B\) grÃ¶Ãer ist als das Signifikanzniveau \(\alpha\) von
5\%. Damit kÃ¶nnen wir die Nullhypothese nicht ablehnen. Wir nehmen eine
Normalverteilung fÃ¼r Gruppe \(A\) an.

Super, jetzt haben wir fÃ¼r die eine Gruppe eine Normalverteilung und fÃ¼r
die andere nicht. Wir haben uns in die Ecke getestet. Wir kÃ¶nnen jetzt
verschiedene Szenarien vorliegen haben.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir kÃ¶nnten in der Gruppe \(A\) zwei AusreiÃer vorliegen haben.
\item
  Wir kÃ¶nnten in der Gruppe \(B\) zufÃ¤llig eine Normalverteilung
  beobachtet haben.
\end{enumerate}

{\marginnote{\begin{footnotesize}Und nochmal zum SchluÃ, einem
statistischen Test mit 4 bis 5 Wiederholungen in einer Gruppe zu
glauben, ob eine Normalverteilung vorliegt, kannst du auch
wÃ¼rfeln\ldots{}\end{footnotesize}}}

Leider wissen wir im echten Leben nicht, aus welcher Verteilung unsere
Daten stammen, wir kÃ¶nnen aber \emph{annehmen}, dass die Daten einer
Normalverteilung folgen oder aber die Daten so transformieren, dass die
Daten einer approximativen Normalverteilung folgen. Siehe dazu auch das
Kapitel~\ref{sec-eda-transform} zur Transformation von Daten.

Wenn deine Daten \emph{keiner} Normalverteilung folgen, dann kann es
sein, dass du mit den EffektschÃ¤tzern ein Problem bekommst. Du erfÃ¤hrst
vielleicht, dass du die Nullhypothese ablehnen kannst, aber nicht wie
stark der Effekt in der Einheit des gemessenen Outcomes ist.

\hypertarget{sec-posthoc}{%
\chapter{Multiple Vergleiche oder Post-hoc Tests}\label{sec-posthoc}}

\emph{Version vom September 14, 2022 um 08:51:33}

In diesem Kapitel wollen wir uns mit den multipen Vergleichen
beschÃ¤ftigen. Das heiÃt, wir wollen statistisch Testen, ob sich die
Level eines Faktors voneinander unterscheiden. Eventuell hast du schon
eine einfaktorielle ANOVA gerechnet, wie in Kapitel~\ref{sec-fac1}
beschrieben. Oder aber du hast eine mehrfaktorielle ANOVA gerechnet wie
in Kapitel~\ref{sec-fac2} gezeigt. In beiden FÃ¤llen hast du jetzt einen
signifikanten Faktor, der mehr als zwei Level hat. Du willst nun wissen,
\emph{welche} der Gruppenmittelwerte der Level sich signifikant
unterscheiden. HierfÃ¼r kÃ¶nnen wir verschiedene AnsÃ¤tze wÃ¤hlen.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Wir haben eine einfaktorielle ANOVA gerechnet und nutzen nun paarweise
  Vergleiche um herauszufinden welche Gruppenmittelwerte sich
  unterscheiden (siehe Kapitel~\ref{sec-posthoc-pairwise})
\item
  Wir haben eine mehrfaktorielle ANOVA gerechnet und haben daher mehrere
  Faktoren. Wir nutzen nun entweder das R Paket \texttt{multcomp} (siehe
  Kapitel~\ref{sec-posthoc-multcomp}) oder das R Paket \texttt{emmeans}
  (siehe Kapitel~\ref{sec-posthoc-emmeans}) um herauszufinden welche
  Gruppenmittelwerte sich unterscheiden.
\end{enumerate}

Wenn wir multiple Mittelwertsvergleiche rechnen, dann tritt das Problem
des multipen Testens auf. Im
Kapitel~\ref{sec-statistisches-testen-alpha-adjust} kannst du mehr Ã¼ber
die Problematik erfahren und wie wir mit der \(\alpha\) Inflation
umgehen. Hier in diesem Kapitel gehe ich jetzt davon aus, dass dir die
\(\alpha\) Adjustierung ein Begriff ist.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-14}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-14}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               multcomp, emmeans, ggpubr)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-2}{%
\section{Daten}\label{daten-2}}

Wir nutzen in diesem Kapitel den Datensatz aus dem Beispiel in
Kapitel~\ref{sec-example-3}. Wir haben als Outcome die SprunglÃ¤nge in
{[}cm{]} von FlÃ¶hen. Die SprunglÃ¤nge haben wir an FlÃ¶hen von Hunde,
Katzen und FÃ¼chsen gemessen. Der Datensatz ist also recht Ã¼beerschaubar.
Wir haben ein normalverteiltes \(y\) mit \texttt{jump\_length} sowie
einen multinomialverteiltes \(y\) mit \texttt{grade} und einen Faktor
\texttt{animal} mit drei Leveln.

Du kannst dir komplexere Auswertungen im
Kapitel~\ref{sec-beispiel-auswertung} anschauen. Dort sammelt sich mit
der Zeit Auswertungen vom Fachbereich an. Daher finden sich dort auch
Beispiele fÃ¼r multiple Vergleiche.

Im Folgenden laden wir den Datensatz \texttt{flea\_dog\_cat\_fox.csv}
und selektieren mit der Funktion \texttt{select()} die benÃ¶tigten
Spalten. AbschlieÃend mÃ¼ssen wir die Spalte \texttt{animal}noch in einen
Faktor umwandeln. Damit ist unsere Vorbereitung des Datensatzes
abgeschlossen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac1\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, jump\_length, grade) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal))}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-data-posthoc-1} ist der Datensatz
\texttt{fac1\_tbl} nochmal dargestellt.

\hypertarget{tbl-data-posthoc-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-posthoc-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} sowie der
multinominalverteilten Variable \texttt{grade} und einem Faktor
\texttt{animal} mit drei Leveln.}\tabularnewline
\toprule()
animal & jump\_length & grade \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & grade \\
\midrule()
\endhead
dog & 5.7 & 8 \\
dog & 8.9 & 8 \\
dog & 11.8 & 6 \\
dog & 8.2 & 8 \\
dog & 5.6 & 7 \\
dog & 9.1 & 7 \\
dog & 7.6 & 9 \\
cat & 3.2 & 7 \\
cat & 2.2 & 5 \\
cat & 5.4 & 7 \\
cat & 4.1 & 6 \\
cat & 4.3 & 6 \\
cat & 7.9 & 6 \\
cat & 6.1 & 5 \\
fox & 7.7 & 5 \\
fox & 8.1 & 4 \\
fox & 9.1 & 4 \\
fox & 9.7 & 5 \\
fox & 10.6 & 4 \\
fox & 8.6 & 4 \\
fox & 10.3 & 3 \\
\bottomrule()
\end{longtable}

Wir werden nun den Datensatz \texttt{fac1\_tbl} in den folgenden
Abschnitten immer wieder nutzen.

\hypertarget{hypothesen-fuxfcr-multiple-vergleiche}{%
\subsection{Hypothesen fÃ¼r multiple
Vergleiche}\label{hypothesen-fuxfcr-multiple-vergleiche}}

Als wir eine ANOVA gerechnet hatten, hatten wir nur eine Nullhypothese
und eine Alternativehypothese. Wenn wir Nullhypothese abgelehnt hatten,
wussten wir nur, dass sich mindestens ein paarweiser Vergleich
unterschiedet. Multiple Vergleich lÃ¶sen nun dieses Problem und fÃ¼hren
ein Hypothesen\emph{paar} fÃ¼r jeden paarweisen Vergleich ein. Zum einen
rechnen wir damit \(k\) Tests und haben damit auch \(k\) Hypothesenpaare
(siehe auch Kapitel~\ref{sec-statistisches-testen-alpha-adjust} zur
Problematik des wiederholten Testens).

Wenn wir zum Beispiel alle Level des Faktors \texttt{animal} miteinander
Vergleichen wollen, dann rechnen wir \(k=3\) paarweise Vergleiche. Im
Folgenden sind alle drei Hypothesenpaare dargestellt.

\[
\begin{align*}
H_{01}: &\; \bar{y}_{cat} = \bar{y}_{dog}\\
H_{A1}: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\end{align*}
\]

\[
\begin{align*}
H_{02}: &\; \bar{y}_{cat} = \bar{y}_{fox}\\
H_{A2}: &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\end{align*}
\]

\[
\begin{align*}
H_{03}: &\; \bar{y}_{dog} = \bar{y}_{fox}\\
H_{A3}: &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\end{align*}
\]

Wenn wir drei Vergleiche rechnen, dann haben wir eine \(\alpha\)
Inflation vorliegen. Wir sagen, dass wir fÃ¼r das multiple Testen
adjustieren mÃ¼ssen. In R gibt es eine Reihe von Adjustierungsverfahren.
Wir nehmen meist Bonferroni oder das Verfahren, was in der jeweiligen
Funktion als Standard (eng. \emph{default}) gesetzt ist.

Wir adjustieren grundsÃ¤tzlich die \(p\)-Werte und erhalten adjustierte
\(p\)-Werte aus den jeweiligen Funktionen in R. Die adjustierten p-Werte
kÃ¶nnen wir dann mit dem Signifikanzniveau von \(\alpha\) gleich 5\%
vergleichen.

\hypertarget{sec-posthoc-pairwise}{%
\section{\texorpdfstring{Gruppenvergleiche mit
\texttt{pairwise.*.test()}}{Gruppenvergleiche mit pairwise.*.test()}}\label{sec-posthoc-pairwise}}

{\marginnote{\begin{footnotesize}Die Funktion \texttt{pairwise.*.test()}
ist \emph{veraltet}, wir nutzen das R Paket \texttt{emmeans}oder das R
Paket \texttt{multcomp}.\end{footnotesize}}}

Wenn wir nur einen Faktor mit mehr als zwei Leveln vorliegen haben, dann
kÃ¶nnen wir die Funktion \texttt{pairwise.*.test()} nutzen. Der Stern
\texttt{*} steht entweder als Platzhalter fÃ¼r \texttt{t} fÃ¼r den t-Test
oder aber fÃ¼r \texttt{wilcox} fÃ¼r den Wilcoxon Test. Die Funktion ist
relativ einfach zu nutzen und liefert auch sofort die entsprechenden
p-Werte.

Die Funktion \texttt{pairwise.*.test()} ist in dem Sinne
\emph{veraltet}, da wir keine 95\% Konfidenzintervalle generieren
kÃ¶nnen. Da die Funktion aber immer mal wieder angefragt wird, ist die
Funktion hier nochmal aufgefÃ¼hrt.

\hypertarget{paarweiser-t-test}{%
\subsection{Paarweiser t Test}\label{paarweiser-t-test}}

Wir nutzen den paarweisen t-Test,

\begin{itemize}
\tightlist
\item
  wenn wir ein normalverteiltes \(y\) vorliegen haben, wie
  \texttt{jump\_length}.
\item
  wenn wir \emph{nur} einen Faktor mit mehr als zwei Leveln vorliegen
  haben, wie \texttt{animal}.
\end{itemize}

Die Funktion \texttt{pairwise.t.test} kann nicht mit DatensÃ¤tzen
arbeiten sondern nur mit Vektoren. Daher kÃ¶nnen wir der Funktion auch
keine \texttt{formula} Ã¼bergeben sondern mÃ¼ssen die Vektoren aus dem
Datensatz mit \texttt{fac1\_tbl\$jump\_length} fÃ¼r das Outcome und mit
\texttt{fac1\_tbl\$animal} fÃ¼r die Gruppierende Variable benennen. Das
ist umstÃ¤ndlich und dhaer auch fehleranfÃ¤llig.

\marginnote{\begin{footnotesize}

Mehr zu \texttt{mutate\_if()} erfÃ¤hrst du auf der
\href{https://dplyr.tidyverse.org/reference/mutate_all.html}{Hilfeseite
von mutate()}

\end{footnotesize}}

Als Adjustierungsmethode fÃ¼r den \(\alpha\) Fehler wÃ¤hlen wir die
Bonferroni-Methode mit \texttt{p.adjust.method\ =\ "bonferroni"} aus. Da
wir eine etwas unÃ¼bersichtliche Ausgabe in R erhalten nutzen wir die
Funktion \texttt{tidy()}um die Ausgabe in ein saubers \texttt{tibble} zu
verwandeln. AbschlieÃend runden wir noch alle numerischen Spalten mit
der Funktion \texttt{round} auf drei Stellen hinter dem Komma.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairwise.t.test}\NormalTok{(fac1\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length, fac1\_tbl}\SpecialCharTok{$}\NormalTok{animal,}
                \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  tidy }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, round, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  group1 group2 p.value
  <chr>  <chr>    <dbl>
1 cat    dog      0.007
2 fox    dog      0.876
3 fox    cat      0.001
\end{verbatim}

Wir erhalten in einem Tibble die adujstierten p-Werte nach Bonferroni.
Wir kÃ¶nnen daher die adjustierten p-Werte ganz normal mit dem
Signifikanzniveau \(\alpha\) von 5\% vergleichen. Wir sehen, dass der
Gruppenvergleich \texttt{cat\ -\ dog} signifikant ist, der
Gruppenvergleich \texttt{fox\ -\ dog} nicht signifkant ist und der
Gruppenvergleich \texttt{fox\ -\ cat} wiederum signifkant ist.

Leider kÃ¶nnen wir uns keine Konfidenzintervalle wiedergeben lassen, so
dass die Funktion nicht dem Stand der Wissenschaft und deren AnsprÃ¼chen
genÃ¼gt.

Im Folgenden wollen wir uns nochmal die Visualisierung mit dem R Paket
\texttt{ggpubr} anschauen. Die
\href{https://rpkgs.datanovia.com/ggpubr/index.html}{Hilfeseite des R
Pakets \texttt{ggpubr}} liefert noch eine Menge weitere Beispiele fÃ¼r
den simplen Fall eines Modells \(y ~ x\), also von einem \(y\) und einem
Faktor \(x\).

Um die Abbildung~\ref{fig-ggpubr-1} zu erstellen mÃ¼ssen wir als erstes
die Funktion \texttt{compare\_mean()} nutzen um mit der \texttt{formula}
Syntax einen t-Test zu rechnen. wir adjustieren die p-Werte nach
Bonferroni. AnschlieÃend erstellen wir einen Boxplot mit der Funktion
\texttt{ggboxplot()} und speichern die Ausgabe in dem Objekt \texttt{p}.
Wie in \texttt{ggplot} Ã¼blich kÃ¶nnen wir jetzt auf das Layer \texttt{p}
Ã¼ber das \texttt{+}-Zeichen noch weitere Layer ergÃ¤nzen. Wir nutzen die
Funktion \texttt{stat\_pvalue\_manual()} um die asjustierten p-Werte aus
dem Objekt \texttt{stat\_test\_obj} zu ergÃ¤nzen. AbschlieÃend wollen wir
noch den p-Wert einer einfaktoriellen ANOVA als globalen Test ergÃ¤nzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_test\_obj }\OtherTok{\textless{}{-}} \FunctionTok{compare\_means}\NormalTok{(}
\NormalTok{ jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl,}
 \AttributeTok{method =} \StringTok{"t.test"}\NormalTok{,}
 \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}
\NormalTok{)}

\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ggboxplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ fac1\_tbl, }\AttributeTok{x =} \StringTok{"animal"}\NormalTok{, }\AttributeTok{y =} \StringTok{"jump\_length"}\NormalTok{,}
               \AttributeTok{color =} \StringTok{"animal"}\NormalTok{, }\AttributeTok{palette =}\FunctionTok{c}\NormalTok{(}\StringTok{"\#00AFBB"}\NormalTok{, }\StringTok{"\#E7B800"}\NormalTok{, }\StringTok{"\#FC4E07"}\NormalTok{),}
               \AttributeTok{add =} \StringTok{"jitter"}\NormalTok{, }\AttributeTok{shape =} \StringTok{"animal"}\NormalTok{)}

\NormalTok{p }\SpecialCharTok{+} \FunctionTok{stat\_pvalue\_manual}\NormalTok{(stat\_test\_obj, }\AttributeTok{label =} \StringTok{"p.adj"}\NormalTok{, }\AttributeTok{y.position =} \FunctionTok{c}\NormalTok{(}\DecValTok{13}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{19}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_compare\_means}\NormalTok{(}\AttributeTok{label.y =} \DecValTok{20}\NormalTok{, }\AttributeTok{method =} \StringTok{"anova"}\NormalTok{)    }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-ggpubr-1-1.pdf}

}

\caption{\label{fig-ggpubr-1}Boxplot der Sprungweiten {[}cm{]} von
Hunden und Katzen ergÃ¤nzt um den paarweisen Vergleich mit dem t-Test und
den Bonferroni adjustierten p-Werten.}

\end{figure}

\hypertarget{paarweiser-wilcoxon-test}{%
\subsection{Paarweiser Wilcoxon Test}\label{paarweiser-wilcoxon-test}}

Wir nutzen den paarweisen Wilxocon Test,

\begin{itemize}
\tightlist
\item
  wenn wir ein \emph{nicht}-normalverteiltes \(y\) vorliegen haben, wie
  \texttt{grade}.
\item
  wenn wir \emph{nur} einen Faktor mit mehr als zwei Leveln vorliegen
  haben, wie \texttt{animal}.
\end{itemize}

Die Funktion \texttt{pairwise.wilcox.test} kann nicht mit DatensÃ¤tzen
arbeiten sondern nur mit Vektoren. Daher kÃ¶nnen wir der Funktion auch
keine \texttt{formula} Ã¼bergeben sondern mÃ¼ssen die Vektoren aus dem
Datensatz mit \texttt{fac1\_tbl\$jump\_length} fÃ¼r das Outcome und mit
\texttt{fac1\_tbl\$animal} fÃ¼r die Gruppierende Variable benennen. Das
ist umstÃ¤ndlich und dhaer auch fehleranfÃ¤llig.

\marginnote{\begin{footnotesize}

Mehr zu \texttt{mutate\_if()} erfÃ¤hrst du auf der
\href{https://dplyr.tidyverse.org/reference/mutate_all.html}{Hilfeseite
von mutate()}

\end{footnotesize}}

Als Adjustierungsmethode fÃ¼r den \(\alpha\) Fehler wÃ¤hlen wir die
Bonferroni-Methode mit \texttt{p.adjust.method\ =\ "bonferroni"} aus. Da
wir eine etwas unÃ¼bersichtliche Ausgabe in R erhalten nutzen wir die
Funktion \texttt{tidy()}um die Ausgabe in ein saubers \texttt{tibble} zu
verwandeln. AbschlieÃend runden wir noch alle numerischen Spalten mit
der Funktion \texttt{round} auf drei Stellen hinter dem Komma.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairwise.wilcox.test}\NormalTok{(fac1\_tbl}\SpecialCharTok{$}\NormalTok{grade, fac1\_tbl}\SpecialCharTok{$}\NormalTok{animal,}
                     \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  tidy }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, round, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  group1 group2 p.value
  <chr>  <chr>    <dbl>
1 cat    dog      0.045
2 fox    dog      0.005
3 fox    cat      0.011
\end{verbatim}

Wir erhalten in einem Tibble die adujstierten p-Werte nach Bonferroni.
Wir kÃ¶nnen daher die adjustierten p-Werte ganz normal mit dem
Signifikanzniveau \(\alpha\) von 5\% vergleichen. Wir sehen, dass der
Gruppenvergleich \texttt{cat\ -\ dog} knapp signifikant ist, der
Gruppenvergleich \texttt{fox\ -\ dog} ebenfalls signifkant ist und der
Gruppenvergleich \texttt{fox\ -\ cat} auch signifkant ist.

Leider kÃ¶nnen wir uns keine Konfidenzintervalle wiedergeben lassen, so
dass die Funktion nicht dem Stand der Wissenschaft und deren AnsprÃ¼chen
genÃ¼gt.

Im Folgenden wollen wir uns nochmal die Visualisierung mit dem R Paket
\texttt{ggpubr} anschauen. Die
\href{https://rpkgs.datanovia.com/ggpubr/index.html}{Hilfeseite des R
Pakets \texttt{ggpubr}} liefert noch eine Menge weitere Beispiele fÃ¼r
den simplen Fall eines Modells \(y ~ x\), also von einem \(y\) und einem
Faktor \(x\).

Um die Abbildung~\ref{fig-ggpubr-2} zu erstellen mÃ¼ssen wir als erstes
die Funktion \texttt{compare\_mean()} nutzen um mit der \texttt{formula}
Syntax einen Wilcoxon Test zu rechnen. wir adjustieren die p-Werte nach
Bonferroni. AnschlieÃend erstellen wir einen Boxplot mit der Funktion
\texttt{ggboxplot()} und speichern die Ausgabe in dem Objekt \texttt{p}.
Wie in \texttt{ggplot} Ã¼blich kÃ¶nnen wir jetzt auf das Layer \texttt{p}
Ã¼ber das \texttt{+}-Zeichen noch weitere Layer ergÃ¤nzen. Wir nutzen die
Funktion \texttt{stat\_pvalue\_manual()} um die asjustierten p-Werte aus
dem Objekt \texttt{stat\_test\_obj} zu ergÃ¤nzen. AbschlieÃend wollen wir
noch den p-Wert eines Kruskal Wallis als globalen Test ergÃ¤nzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_test\_obj }\OtherTok{\textless{}{-}} \FunctionTok{compare\_means}\NormalTok{(}
\NormalTok{ grade }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl,}
 \AttributeTok{method =} \StringTok{"wilcox.test"}\NormalTok{,}
 \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}
\NormalTok{)}

\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ggboxplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ fac1\_tbl, }\AttributeTok{x =} \StringTok{"animal"}\NormalTok{, }\AttributeTok{y =} \StringTok{"grade"}\NormalTok{,}
               \AttributeTok{color =} \StringTok{"animal"}\NormalTok{, }\AttributeTok{palette =}\FunctionTok{c}\NormalTok{(}\StringTok{"\#00AFBB"}\NormalTok{, }\StringTok{"\#E7B800"}\NormalTok{, }\StringTok{"\#FC4E07"}\NormalTok{),}
               \AttributeTok{add =} \StringTok{"jitter"}\NormalTok{, }\AttributeTok{shape =} \StringTok{"animal"}\NormalTok{)}

\NormalTok{p }\SpecialCharTok{+} \FunctionTok{stat\_pvalue\_manual}\NormalTok{(stat\_test\_obj, }\AttributeTok{label =} \StringTok{"p.adj"}\NormalTok{, }\AttributeTok{y.position =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{16}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_compare\_means}\NormalTok{(}\AttributeTok{label.y =} \DecValTok{20}\NormalTok{, }\AttributeTok{method =} \StringTok{"kruskal.test"}\NormalTok{)    }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-ggpubr-2-1.pdf}

}

\caption{\label{fig-ggpubr-2}Boxplot der Sprungweiten {[}cm{]} von
Hunden und Katzen ergÃ¤nzt um den paarweisen Vergleich mit dem Wilcoxon
Test und den Bonferroni adjustierten p-Werten.}

\end{figure}

\hypertarget{sec-posthoc-multcomp}{%
\section{\texorpdfstring{Gruppenvergleich mit dem \texttt{multcomp}
Paket}{Gruppenvergleich mit dem multcomp Paket}}\label{sec-posthoc-multcomp}}

Wir drehen hier einmal die ErklÃ¤rung um. Wir machen erst die Anwendung
in R und sollte dich dann noch mehr Ã¼ber die statistischen HintergrÃ¼nde
der Funktionen interessieren, folgt ein Abschnitt noch zur Theorie. Du
wirst die Funktionen aus \texttt{multcomp} vermutlich in deiner
Abschlussarbeit brauchen. HÃ¤ufig werden multiple Gruppenvergleiche in
Abschlussarbeiten gerechnet.

\hypertarget{gruppenvergleiche-mit-multcomp-in-r}{%
\subsection{\texorpdfstring{Gruppenvergleiche mit \texttt{multcomp} in
R}{Gruppenvergleiche mit multcomp in R}}\label{gruppenvergleiche-mit-multcomp-in-r}}

\marginnote{\begin{footnotesize}

Die Ausgabe von \texttt{multcomp} kÃ¶nnen Ã¼ber die Funktion
\texttt{tidy()} aufgerÃ¤umt werden. Mehr dazu unter der
\href{https://broom.tidymodels.org/reference/tidy.glht.html}{Hilfeseite
von \texttt{tidy}() zu multcomp}.

\end{footnotesize}}

Als erstes brauchen wir ein lineares Modell fÃ¼r die Verwendung von
\texttt{multcomp}. Normalerweise verenden wir das gleiche Modell, was
wir schon in der ANOVA verwendet haben. Wir nutzen hier ein simples
lineares Modell mit nur einem Faktor. Im Prinzip kann das Modell auch
grÃ¶Ãer sein. Du findest immer Beispiel im
Kapitel~\ref{sec-beispiel-auswertung}, die dir eventuell dann nochmal
zeigen, wie du deine Daten nutzen musst.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl)}
\end{Highlighting}
\end{Shaded}

Wir haben das Objeckt \texttt{fit\_1} mit der Funktion \texttt{lm()}
erstellt. Im Modell sind jetzt alle Mittelwerte und die entsprechenden
Varianzen geschÃ¤tzt worden. Mit \texttt{summary(fit\_1)} kannst du dir
gerne das Modell auch nochmal anschauen.

\marginnote{\begin{footnotesize}

Wenn wir keinen \emph{all-pair} Vergleich rechnen wollen, dann kÃ¶nnen
wir auch einen \emph{many-to-one} Vergleich mit dem \texttt{Dunnett}
Kontrast rechnen.

\end{footnotesize}}

Im AnschluÃ nutzen wir die Funktion \texttt{glht()} um den multiplen
vergleich zu rechnen. Als erstes musst du wissen, dass wenn wir
\emph{alle} Vergleiche rechnen wollen, wir einen \emph{all-pair}
Vergleich rechnen. In der Statistik heiÃt dieser Typ von Vergleich
\texttt{Tukey}. Wir wollen jetzt als fÃ¼r den Faktor \texttt{animal}
einen multiplen \texttt{Tukey}-Vergleich rechnen. Nichts anders sagt
\texttt{mcp(animal\ =\ "Tukey")} aus, dabei steht \texttt{mcp} fÃ¼r
\emph{multiple comparison procedure}. Mit dem hinteren Teil der Funktion
weiÃ jetzt die Funktion \texttt{glht()} was gerechnet werden soll. Wir
mÃ¼ssen jetzt der Funktion nur noch mitgeben auf was der multiple
vergleich gerehcnet werden soll, mit dem Objekt \texttt{fit\_1}. Wir
speichern die Ausgabe der Funktion in \texttt{comp\_1\_obj}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_1\_obj }\OtherTok{\textless{}{-}} \FunctionTok{glht}\NormalTok{(fit\_1, }\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{animal =} \StringTok{"Tukey"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

Mit dem Objekt \texttt{comp\_1\_fit} kÃ¶nnen wir noch nicht soviel
anfangen. Der Inhalt ist etwas durcheinander und wir wollen noch die
Konfidenzintervalle haben. Daher pipen wir \texttt{comp\_1\_fit} erstmal
in die Funktion \texttt{tidy()} und alssen mit der Option
\texttt{conf.int\ =\ TRUE} die simultanen 95\% Konfidenzintervalle
berechnen. Dann nutzen wir die Funktion \texttt{select()} um die
wichtigen Spalten zu selektieren. AbschlieÃend mutieren wir noch alle
numerischen Spalten in dem wir auf die dritte Kommastelle runden. Wir
speichern alles in das Objekt \texttt{res\_1\_obj}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_1\_obj }\OtherTok{\textless{}{-}}\NormalTok{ comp\_1\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{(}\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, estimate, adj.p.value, }
\NormalTok{         conf.low, conf.high) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, round, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Wir lassen uns dann den Inhalt von dem Objekt \texttt{res\_1\_obj}
ausgeben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_1\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 5
  contrast  estimate adj.p.value conf.low conf.high
  <chr>        <dbl>       <dbl>    <dbl>     <dbl>
1 cat - dog    -3.39       0.006    -5.80     -0.97
2 fox - dog     1.03       0.535    -1.39      3.44
3 fox - cat     4.41       0.001     2.00      6.83
\end{verbatim}

Wir erhalten ein \texttt{tibble()} mit fÃ¼nf Spalten. Zum einen den
\texttt{contrast}, der den Vergleich widerspiegelt. Wir vergleichen im
ersten Kontrast die Katzen- mit den HundeflÃ¶hen, wobei wir
\texttt{cat\ -\ dog} rechnen. Also wirklich der Mittelwert der
Sprungweite der KatzenflÃ¶he \emph{minus} den Mittelwert der Sprungweite
der HundeflÃ¶he rechnen. In der Spalte \texttt{estimate} sehen wir den
Mittelwertsunterschied. Der Mittelwertsunterschied ist in der
\emph{Richtung} nicht ohne den Kontrast zu interpretieren. Danach
erhalten wir die adjustierten \(p\)-Wert sowie die simultanen 95\%
Konfidenzintervalle.

Wir kÃ¶nnen die Nullhypothese ablehnen fÃ¼r den
Vergleiche\texttt{cat\ -\ dog} mit einem p-Wert von \(0.006\) sowie fÃ¼r
den Vergleich \(fox - cat\) mit einem p-Wert von \(0.001\). Beide
p-Werte liegen unter dem Signifikanzniveau von \(\alpha\) gleich 5\%.

In Abbildung~\ref{fig-multcomp-1} sind die simultanen 95\%
Konfidenzintervalle nochmal in einem \texttt{ggplot} visualisiert. Die
Kontraste und die Position hÃ¤ngen von dem Faktorlevel ab. Mit der
Funktion \texttt{factor()} kannst du die Sortierung der Level einem
Faktor Ã¤ndern und somit auch Position auf den Achsen.

\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{ggplot}\NormalTok{(res\_1\_obj, }\FunctionTok{aes}\NormalTok{(contrast, }\AttributeTok{y=}\NormalTok{estimate, }
                        \AttributeTok{ymin=}\NormalTok{conf.low, }\AttributeTok{ymax=}\NormalTok{conf.high)) }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{linetype=}\StringTok{"11"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"grey60"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_errorbar}\NormalTok{(}\AttributeTok{width=}\FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-multcomp-1-1.pdf}

}

\caption{\label{fig-multcomp-1}Simultane 95\% Konfidenzintervalle fÃ¼r
den paarweisen Vergleich der Sprungweiten in {[}cm{]} der Hunde-,
Katzen- und FuchsflÃ¶he.}

\end{figure}

Die Entscheidung gegen die Nullhypothese anhand der simultanen 95\%
Konfidenzintervalle ist inhaltlich gleich, wie die Entscheidung anhand
der p-Werte. Wir entscheiden gegen die Nullhypothese, wenn die 0 nicht
mit im Konfindenzintervall enthalten ist. Wir wÃ¤hlen hier die 0 zur
Entscheidung gegen die Nullhypothese, weil wir einen
Mittelwertsvergleich rechnen.

FÃ¼r den Vergleich \texttt{fox\ -dog} ist die 0 im 95\%
Konfidenzintervall, wir kÃ¶nnen daher die Nullhypothese nicht ablehnen.
Das 95\% Konfidenzintervall ist nicht signifikant. Bei dem Vergleich
\texttt{fox\ -\ cat} sowie dem Vergleich \texttt{cat\ -\ dog} ist
jeweils die 0 nicht im 95\% Konfidenzintervall enthalten. Beide 95\%
Konfidenzintervalle sind signifikant, wir kÃ¶nnen die Nullhypothese
ablehnen.

\hypertarget{sec-posthoc-emmeans}{%
\section{\texorpdfstring{Gruppenvergleich mit der \texttt{emmeans}
Paket}{Gruppenvergleich mit der emmeans Paket}}\label{sec-posthoc-emmeans}}

\marginnote{\begin{footnotesize}

Wir kÃ¶nnen hier nicht alles erklÃ¤ren und im Detail durchgehen. Hier gibt
es noch ein aufwendiges Tutorium zu \texttt{emmeans}:
\href{https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/}{Getting
started with emmeans}.

Daneben gibt es auch noch die
\href{https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html\#contents}{EinfÃ¼hrung
mit Theorie auf der Seite des R Paktes}

\end{footnotesize}}

Im Folgenden wollen wir uns mit einem anderen R Paket beschÃ¤ftigen was
auch multiple Vergleiche rechnen kann. In diesem Kapitel nutzen wir das
R Paket \texttt{emmeans}. Im Prinzip kann \texttt{emmeans} das Gleiche
wir das R Paket \texttt{multcomp}. Beide Pakete rechnen dir einen
multipen Vergleich. Das Paket \texttt{emmeans} kann noch mit
\emph{nested comparisons} umgehen. Deshlb hier nochmal die Vorstellung
von \texttt{emmeans}. Du kannst aber fÃ¼r eine simple Auswertung mit nur
einem Faktor beide Pakete verwenden.

\hypertarget{gruppenvergleiche-mit-emmeans-in-r}{%
\subsection{\texorpdfstring{Gruppenvergleiche mit \texttt{emmeans} in
R}{Gruppenvergleiche mit emmeans in R}}\label{gruppenvergleiche-mit-emmeans-in-r}}

\marginnote{\begin{footnotesize}

Die Ausgabe von \texttt{emmeans} kÃ¶nnen Ã¼ber die Funktion
\texttt{tidy()} aufgerÃ¤umt werden. Mehr dazu unter der
\href{https://broom.tidymodels.org/reference/tidy.emmGrid.html}{Hilfeseite
von \texttt{tidy}() zu emmeans}.

\end{footnotesize}}

Um den multiplen Vergleich in \texttt{emmeans} durchfÃ¼hren zu kÃ¶nnen
brauchen wir zuerst ein lineares Modell, was uns die notwenidgen
Parameter wie Mittelwerte und Standardabweichungen liefert. Wir nutzen
in unserem simplen Beispiel ein lineares Modell mit einer
Einflussvariable \(x\) und nehmen an, dass unser Outcome \(y\)
normalverteilt ist. Achtung, hier muss natÃ¼rlich das \(x\) ein Faktor
sein. Dann kÃ¶nnen wir ganz einfach die Funktion \texttt{lm()} nutzen. Im
Folgenden fitten wir das Modell \texttt{fit\_2} was wir dann auch weiter
nutzen werden.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ fac1\_tbl)}
\end{Highlighting}
\end{Shaded}

Der multiple Vergleich in \texttt{emmeans} ist mehrschrittig. Wir pipen
unser Modell aus \texttt{fit\_2} in die Funktion \texttt{emmeans()}. Wir
geben mit \texttt{\textasciitilde{}\ animal} an, dass wir Ã¼ber die Level
des Faktors \texttt{animal} einen Vergleich rechnen wollen. Wir
adjustieren die \(p\)-Werte nach Bonferroni. Danach pipen wir weiter in
die Funktion \texttt{contrast()} wo der eigentliche Vergleich festgelegt
wird. In unserem Fall wollen wir einen \emph{many-to-one} Vergleich
rechnen. Alle Gruppen zu der Gruppe \texttt{fox}. Du kannst mit
\texttt{ref\ =} auch ein anderes Level deines Faktors wÃ¤hlen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_2\_obj }\OtherTok{\textless{}{-}}\NormalTok{ fit\_2 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{emmeans}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{adjust =} \StringTok{"bonferroni"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{contrast}\NormalTok{(}\AttributeTok{method =} \StringTok{"trt.vs.ctrl"}\NormalTok{, }\AttributeTok{ref =} \StringTok{"fox"}\NormalTok{) }

\NormalTok{comp\_2\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 contrast  estimate    SE df t.ratio p.value
 dog - fox    -1.03 0.947 18  -1.086  0.4682
 cat - fox    -4.41 0.947 18  -4.660  0.0004

P value adjustment: dunnettx method for 2 tests 
\end{verbatim}

Wir kÃ¶nnen auch einen anderen Kontrast wÃ¤hlen. Wir Ã¼berschreiben jetzt
das Objekt \texttt{comp\_2\_obj} mit dem Kontrast \emph{all-pair}, der
alle mÃ¶glichen Vergleiche rechnet. In \texttt{emmeans} heiÃt der
\emph{all-pair} Kontrast \emph{pairwise}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_2\_obj }\OtherTok{\textless{}{-}}\NormalTok{ fit\_2 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{emmeans}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{adjust =} \StringTok{"bonferroni"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{contrast}\NormalTok{(}\AttributeTok{method =} \StringTok{"pairwise"}\NormalTok{) }

\NormalTok{comp\_2\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 contrast  estimate    SE df t.ratio p.value
 dog - cat     3.39 0.947 18   3.574  0.0058
 dog - fox    -1.03 0.947 18  -1.086  0.5347
 cat - fox    -4.41 0.947 18  -4.660  0.0005

P value adjustment: tukey method for comparing a family of 3 estimates 
\end{verbatim}

Wir kÃ¶nnen das Ergebnis auch noch mit der Funktion \texttt{tidy()}
weiter aufrÃ¤umen und dann die Spalten selektieren, die wir brauchen.
HÃ¤ufig benÃ¶tigen wir nicht alle Spalten, die eine Funktion wiedergibt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_2\_obj }\OtherTok{\textless{}{-}}\NormalTok{ comp\_2\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{(}\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, estimate, adj.p.value, conf.low, conf.high) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), round, }\DecValTok{4}\NormalTok{))}

\NormalTok{res\_2\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 5
  contrast  estimate adj.p.value conf.low conf.high
  <chr>        <dbl>       <dbl>    <dbl>     <dbl>
1 dog - cat     3.39      0.0058    0.968      5.80
2 dog - fox    -1.03      0.535    -3.45       1.39
3 cat - fox    -4.41      0.0005   -6.83      -2.00
\end{verbatim}

AbschlieÃend wollen wir noch die 95\% Konfidenzintervalle in
Abbildung~\ref{fig-emmeans-1} abbilden. Hier ist es bei \texttt{emmeans}
genauso wie bei \texttt{multcomp}. Wir kÃ¶nnen das Objekt
\texttt{res\_2\_obj} direkt in \texttt{ggplot()} weiterverwenden und uns
die 95\% Konfidenzintervalle einmal plotten.

\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{ggplot}\NormalTok{(res\_2\_obj, }\FunctionTok{aes}\NormalTok{(contrast, }\AttributeTok{y=}\NormalTok{estimate, }\AttributeTok{ymin=}\NormalTok{conf.low, }\AttributeTok{ymax=}\NormalTok{conf.high)) }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{linetype=}\StringTok{"11"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"grey60"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_errorbar}\NormalTok{(}\AttributeTok{width=}\FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-emmeans-1-1.pdf}

}

\caption{\label{fig-emmeans-1}Die 95\% Konfidenzintervalle fÃ¼r den
\emph{allpair}-Vergleich des simplen Datensatzes.}

\end{figure}

Wir wollen uns noch einen etwas komplizierteren Fall anschauen, indem
sich \texttt{emmeans} von \texttt{multcomp} in der Anwendung
unterscheidet. Wir laden den Datensatz
\texttt{flea\_dog\_cat\_fox\_site.csv} in dem wir \emph{zwei} Faktoren
haben. Damit kÃ¶nnen wir dann ein Modell mit einem Interaktionsterm
bauen. Wir erinnern uns, dass wir in der zweifaktoriellen ANOAV eine
signifikante Interaktion zwischen den beiden Faktoren \texttt{animal}
und \texttt{site} festgestelt hatten.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fac2\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_fox\_site.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(animal, site, jump\_length) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal),}
         \AttributeTok{site =} \FunctionTok{as\_factor}\NormalTok{(site))}
\end{Highlighting}
\end{Shaded}

Wir erhalten das Objekt \texttt{fac2\_tbl} mit dem Datensatz in
Tabelle~\ref{tbl-data-emmeans-1} nochmal dargestellt.

\hypertarget{tbl-data-emmeans-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-data-emmeans-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} und einem Faktor
\texttt{animal} mit drei Leveln sowie dem Faktor \texttt{site} mit vier
Leveln.}\tabularnewline
\toprule()
animal & site & jump\_length \\
\midrule()
\endfirsthead
\toprule()
animal & site & jump\_length \\
\midrule()
\endhead
cat & city & 12.04 \\
cat & city & 11.98 \\
cat & city & 16.1 \\
cat & city & 13.42 \\
cat & city & 12.37 \\
cat & city & 16.36 \\
\ldots{} & \ldots{} & \ldots{} \\
fox & field & 16.38 \\
fox & field & 14.59 \\
fox & field & 14.03 \\
fox & field & 13.63 \\
fox & field & 14.09 \\
fox & field & 15.52 \\
\bottomrule()
\end{longtable}

In Abbildung~\ref{fig-boxplot-emmeans-1} sehen wir nochmal die Daten
visualisiert. Wichtig ist hier, dass wir \emph{zwei} Faktoren vorliegen
haben. Den Faktor \texttt{animal} und den Faktor \texttt{site}. Dabei
ist der Faktor \texttt{animal} in dem Faktor \texttt{site} genested. Wir
messen jedes Level des Faktors \texttt{animal} jeweils in jedem Level
des Faktors \texttt{site}.

\begin{figure}

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-boxplot-emmeans-1-1.pdf}

}

\caption{\label{fig-boxplot-emmeans-1}Boxplot der Sprungweiten {[}cm{]}
von Hunden und Katzen gemessen an verschiedenen Orten.}

\end{figure}

Wir rechnen ein multiples lineares Modell mit einem Interaktionsterm.
Daher packen wir beide Faktoren in das Modell sowie die Intraktion
zwischen den beiden Faktoren. Wir erhalten nach dem fitten des Modells
das Objekt \texttt{fit\_3}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ site }\SpecialCharTok{+}\NormalTok{ animal}\SpecialCharTok{:}\NormalTok{site, }\AttributeTok{data =}\NormalTok{ fac2\_tbl)}
\end{Highlighting}
\end{Shaded}

Der Unterschied zu unserem vorherigen multiplen Vergleich ist nun, dass
wir auch einen multiplen Vergleich fÃ¼r \emph{animal nested in site}
rechnen kÃ¶nnen. DafÃ¼r mÃ¼ssen wir den Vergleich in der Form
\texttt{animal\ \textbar{}\ site} schreiben. Wir erhalten dann die
Vergleiche der Level des faktors \texttt{animal} \emph{getrennt} fÃ¼r die
Level es Faktors \texttt{site}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_3\_obj }\OtherTok{\textless{}{-}}\NormalTok{ fit\_3 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{emmeans}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{|}\NormalTok{ site, }\AttributeTok{adjust =} \StringTok{"bonferroni"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{contrast}\NormalTok{(}\AttributeTok{method =} \StringTok{"pairwise"}\NormalTok{) }

\NormalTok{comp\_3\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
site = city:
 contrast  estimate    SE  df t.ratio p.value
 cat - dog   -3.101 0.771 108  -4.022  0.0003
 cat - fox   -6.538 0.771 108  -8.479  <.0001
 dog - fox   -3.437 0.771 108  -4.457  0.0001

site = smalltown:
 contrast  estimate    SE  df t.ratio p.value
 cat - dog   -4.308 0.771 108  -5.587  <.0001
 cat - fox   -4.064 0.771 108  -5.271  <.0001
 dog - fox    0.244 0.771 108   0.316  0.9463

site = village:
 contrast  estimate    SE  df t.ratio p.value
 cat - dog   -1.316 0.771 108  -1.707  0.2073
 cat - fox   -1.729 0.771 108  -2.242  0.0687
 dog - fox   -0.413 0.771 108  -0.536  0.8540

site = field:
 contrast  estimate    SE  df t.ratio p.value
 cat - dog   -0.982 0.771 108  -1.274  0.4131
 cat - fox    1.366 0.771 108   1.772  0.1840
 dog - fox    2.348 0.771 108   3.045  0.0082

P value adjustment: tukey method for comparing a family of 3 estimates 
\end{verbatim}

Wir kÃ¶nnen uns das Ergebnis auch etwas schÃ¶ner ausgeben lassen. Wir
nutzen hier noch die Funktion \texttt{format.pval()} um die \(p\)-Werte
besser zu formatieren. Die \(p\)-Wert, die kleiner sind als 0.001 werden
als \texttt{\textless{}0.001} ausgegeben und die anderen \(p\)-Werte auf
zwei Nachstellen nach dem Komma gerundet.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_3\_obj }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  summary }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  as\_tibble }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, site, p.value) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p.value =} \FunctionTok{format.pval}\NormalTok{(p.value, }\AttributeTok{eps =} \FloatTok{0.001}\NormalTok{, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 3
   contrast  site      p.value
   <fct>     <fct>     <chr>  
 1 cat - dog city      <0.001 
 2 cat - fox city      <0.001 
 3 dog - fox city      <0.001 
 4 cat - dog smalltown <0.001 
 5 cat - fox smalltown <0.001 
 6 dog - fox smalltown 0.95   
 7 cat - dog village   0.21   
 8 cat - fox village   0.07   
 9 dog - fox village   0.85   
10 cat - dog field     0.41   
11 cat - fox field     0.18   
12 dog - fox field     0.01   
\end{verbatim}

In der Ausgabe kÃ¶nnen wir erkennen, dass die Vergleich in der Stadt alle
signifkant sind. Jedoch erkennen wir keine signifikanten Ergebnisse mehr
in dem Dorf und im Feld ist nur der Vergleich \texttt{dog\ -\ fox}
signifkant. Hier solltest du nochmal beachten, warum wir die Analyse
getrennt machen. In der zweifaktoriellen ANOVA haben wir gesehen, dass
ein signifkanter Interaktionsterm zwischen den beiden Faktoren
\texttt{animal} und \texttt{site} vorliegt.

Wir wollen uns noch Ã¼ber die Funktion \texttt{confint()} die 95\%
Konfidenzintervalle wiedergeben lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_3\_obj }\OtherTok{\textless{}{-}}\NormalTok{ comp\_3\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{confint}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, site, estimate, }\AttributeTok{conf.low =}\NormalTok{ lower.CL, }\AttributeTok{conf.high =}\NormalTok{ upper.CL) }

\NormalTok{res\_3\_obj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 5
   contrast  site      estimate conf.low conf.high
   <fct>     <fct>        <dbl>    <dbl>     <dbl>
 1 cat - dog city        -3.10    -4.93     -1.27 
 2 cat - fox city        -6.54    -8.37     -4.71 
 3 dog - fox city        -3.44    -5.27     -1.60 
 4 cat - dog smalltown   -4.31    -6.14     -2.48 
 5 cat - fox smalltown   -4.06    -5.90     -2.23 
 6 dog - fox smalltown    0.244   -1.59      2.08 
 7 cat - dog village     -1.32    -3.15      0.516
 8 cat - fox village     -1.73    -3.56      0.103
 9 dog - fox village     -0.413   -2.25      1.42 
10 cat - dog field       -0.982   -2.81      0.850
11 cat - fox field        1.37    -0.466     3.20 
12 dog - fox field        2.35     0.516     4.18 
\end{verbatim}

Besonders mit den 95\% Konfiendezintervallen sehen wir nochmal den
Interaktionseffekt zwischen den beiden Faktoren \texttt{animal} und
\texttt{site}. So dreht sich der Effekt von zum Beispiel
\texttt{dog\ -\ fox} von \(-3.44\) in dem Level \texttt{city} zu
\(+2.35\) in dem Level \texttt{field}. Wir haben eine Interaktion
vorliegen und deshalb die Analyse getrennt fÃ¼r jeden Level des Faktors
\texttt{site} durchgefÃ¼hrt.

Abbildung~\ref{fig-emmeans-2} zeigt die entsprechenden 95\%
Konfidenzintervalle. Wir mÃ¼ssen hier etwas mit der \texttt{position}
spielen, so dass die Punkte und der \texttt{geom\_errorbar} richtig
liegen.

\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{ggplot}\NormalTok{(res\_3\_obj, }\FunctionTok{aes}\NormalTok{(contrast, }\AttributeTok{y=}\NormalTok{estimate, }\AttributeTok{ymin=}\NormalTok{conf.low, }\AttributeTok{ymax=}\NormalTok{conf.high,}
                        \AttributeTok{color =}\NormalTok{ site, }\AttributeTok{group =}\NormalTok{ site)) }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{linetype=}\StringTok{"11"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"grey60"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_errorbar}\NormalTok{(}\AttributeTok{width=}\FloatTok{0.1}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-tests-posthoc_files/figure-pdf/fig-emmeans-2-1.pdf}

}

\caption{\label{fig-emmeans-2}Die 95\% Konfidenzintervalle fÃ¼r den
\emph{allpair}-Vergleich des Models mit Interaktionseffekt.}

\end{figure}

\part{Grundlagen der linearen Regression}

\emph{Version vom September 14, 2022 um 08:51:47}

In diesem Kapitel wollen wir uns mit den Grundlagen der simplen linearen
Regression beschÃ¤ftigen. Das heiÃt, wir haben ein Outcome \(y\), was
normalverteilt ist, sowie eine Einflussvariable \(x_1\), die eine
kontinuierliche Variable ist. Wir wollen jetzt herausfinden, welchen
Einfluss oder Effekt das \(x_1\) auf das \(y\) hat. Sehr simple
Gesprochen legen wir eine Gerade durch eine Punktewolke.

\marginnote{\begin{footnotesize}

Ein simples lineares Modell hat ein \(x\):

\[
y \sim x_1
\]

Ein multiples lineares Modell hat mehrere \(x\):

\[
y \sim x_1 + x_2 + ... + x_p
\]

\end{footnotesize}}

Viele der Konzepte hier brauchen wir in dem Kapitel zum statistischen
Modellieren. Wir lernen hier also eher die AufwÃ¤rmÃ¼bungen und Konzepte
um dann multiple lineare Regressionen rechnen zu kÃ¶nnen. In den
seltensten FÃ¤llen reichen simple lineare Modell aus, um die RealitÃ¤t
abzubilden.

Fangen wir also mit den Grundlagen an und bauen dann systematisch die
Konzepte der simplen linearen Regression auf.

\hypertarget{simple-lineare-regression}{%
\section*{Simple lineare Regression}\label{simple-lineare-regression}}
\addcontentsline{toc}{section}{Simple lineare Regression}

Im Kapitel~\ref{sec-modeling-simple-stat} wollen wir einmal die
Grundlagen der linearen Regression an der simplen linearen Regression
erarbeiten. Wir benÃ¶tigen die Formeln und die Worte fÃ¼r das weitere
Modellieren multipler lineare Modelle.

\hypertarget{kausales-modell}{%
\subsection*{Kausales Modell}\label{kausales-modell}}
\addcontentsline{toc}{subsection}{Kausales Modell}

Schon gleich hier vorweg, es gibt einen Unterschied zwischen einem
kausalen und einem prÃ¤diktiven Modell. In diesem kurzen
Kapitel~\ref{sec-simple-kausal} schauen wir uns das kausale Modell
einmal an. MWenn wir eine \emph{klassische} Regression rechnen, rechnen
wir meist ein kausales Modell.

\hypertarget{pruxe4diktives-modell}{%
\subsection*{PrÃ¤diktives Modell}\label{pruxe4diktives-modell}}
\addcontentsline{toc}{subsection}{PrÃ¤diktives Modell}

Die Vorhersage oder PrÃ¤diktion ist ein eigenes Kapitel wert. Im Bereich
des maschinellen Lernens wird die PrÃ¤diktion auch Klassifikation
genannt. Wir schauen uns in diesem Kapitel~\ref{sec-simple-pred} nur die
Grundlage einmal an. SpÃ¤ter nutzen wir auch maschinelle Lernverfahren
fÃ¼r die Klassifikation.

\hypertarget{mauxdfzahlen-der-modelguxfcte}{%
\section*{MaÃzahlen der ModelgÃ¼te}\label{mauxdfzahlen-der-modelguxfcte}}
\addcontentsline{toc}{section}{MaÃzahlen der ModelgÃ¼te}

Nachdem wir ein Modell mathematisch gerechnet haben, mÃ¼ssen wir
herausfinden, ob das Modell auch gut funktioniert hat. In
Kapitel~\ref{sec-lin-reg-quality} schauen wir uns verschiedene MaÃzahlen
an um zu sehen, ob die Wahl des mathematischen Algorithmus auch zu
unseren Daten passt. Rechnen kÃ¶nnen wir alles, aber ob die Rechnung Sinn
ergibt mÃ¼ssen wir erst herausfinden.

\hypertarget{korrelation}{%
\section*{Korrelation}\label{korrelation}}
\addcontentsline{toc}{section}{Korrelation}

Die simple lineare Regression und Korrelation sind eng miteinander
verwandt. In Kapitel~\ref{sec-lin-reg-corr} schauen wir uns einmal die
beiden Korrelationskoeffizienten nach Pearson und Spearman einmal an.

\hypertarget{sec-modeling-simple-stat}{%
\chapter{Simple lineare Regression}\label{sec-modeling-simple-stat}}

\emph{Version vom September 14, 2022 um 08:51:59}

in diesem Kapitel wollen wir uns mit den Grundlagen der linearen
Regression beschÃ¤ftigen. Damit meine ich erstmal die Idee eine Gerade
durch eine Punktewolke zu zeichnen. Das ist erstmal die simpleste
Anwendung. Wir lernen hier einmal die Grundbegriffe und erweitern diese
dann auf komplexere Modelle.

Du kanst duch aber davon gedanklich lÃ¶sen, dass die lineare Regression
\emph{nur} eine Methode ist um eine Gerade durch eine Punktewolke zu
legen. Die lineare Regression und damit auch das statistische
Modellieren kann viel mehr.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-15}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-15}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               readxl)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-3}{%
\section{Daten}\label{daten-3}}

Wir wollen uns erstmal mit einem einfachen Datenbeispiel beschÃ¤ftigen.
Wir kÃ¶nnen die lineare Regression auf sehr groÃen DatensÃ¤tzen anwenden,
wie auch auf sehr kleinen DatensÃ¤tzen. Prinzipiell ist das Vorgehen
gleich. Wir nutzen jetzt aber erstmal einen kleinen Datensatz mit
\(n=7\) Beobachtungen. In der Tabelle~\ref{tbl-model-0} ist der
Datensatz \texttt{simplel\_tbl} dargestellt. Wir wollen den Zusammenhang
zwischen der Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]} fÃ¼r
sieben Beobachtungen modellieren.

\hypertarget{tbl-model-0}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-model-0}Datensatz mit einer normalverteilten
Variable \texttt{jump\_length} und der normalverteilten Variable
\texttt{weight}.}\tabularnewline
\toprule()
jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
jump\_length & weight \\
\midrule()
\endhead
1.2 & 0.8 \\
1.8 & 1.0 \\
1.3 & 1.2 \\
1.7 & 1.9 \\
2.6 & 2.0 \\
1.8 & 2.7 \\
2.7 & 2.8 \\
\bottomrule()
\end{longtable}

In Abbildung~\ref{fig-scatter-lin-01} sehen wir die Visualisierung der
Daten \texttt{simple\_tbl} in einem Scatterplot mit einer geschÃ¤tzen
Gerade.

\begin{figure}

{\centering \includegraphics{./stat-linear-reg-basic_files/figure-pdf/fig-scatter-lin-01-1.pdf}

}

\caption{\label{fig-scatter-lin-01}Scatterplot der Beobachtungen der
Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]}. Die Gerade verlÃ¤uft
mittig durch die Punkte.}

\end{figure}

Wir schauen uns in diesem Kapitel nur eine \emph{simple} lineare
Regression mit einem \(x_1\) an. In unserem Fall ist das \(x_1\) gleich
dem \texttt{weight}. SpÃ¤ter schauen wir dann \emph{multiple} lineare
Regressionen mit mehreren \(x_1,..., x_p\) an.

Bevor wir mit dem Modellieren anfangen kÃ¶nnen, mÃ¼ssen wir verstehen, wie
ein \emph{simples} Modell theoretisch aufgebaut ist. Danach kÃ¶nnen wir
uns das lineare Modell in R anschauen.

\hypertarget{simple-lineare-regression-theoretisch}{%
\section{Simple lineare Regression
theoretisch}\label{simple-lineare-regression-theoretisch}}

Wir haben nun die ersten sieben Beobachtungen in dem Objekt
\texttt{simple\_tbl} vorliegen. Wie sieht nun theoretisch eine lineare
Regression aus? Wir wollen eine Grade durch Punkte legen, wie wie wir es
in Abbildung~\ref{fig-scatter-lin-01} sehen. Die blaue Gerade wir durch
eine Geradengleichung beschreiben. Du kenst vermutlich noch die Form
\(y = mx + b\). In der Statistik beschreiben wir eine solche Gerade aber
wie folgt.

\[
y \sim \beta_0 + \beta_1 x_1 + \epsilon
\]

mit

\begin{itemize}
\tightlist
\item
  \(\beta_0\) als den y-Achsenabschnitt.
\item
  \(\beta_1\) als der Steigung der Geraden.
\item
  \(\epsilon\) als Residuen oder die Abweichungen von den \(y\)-Werten
  auf Geraden zu den einzelnen \(y\)-Werten der Beobachtungen.
\end{itemize}

In Tabelle~\ref{tbl-reg-deu-eng} siehst du nochmal in einer Tabelle den
Vergleich von der Schreibweise der linearen Regression in der Schule und
in der Statistik. DarÃ¼ber hinaus sind die deutschen Begriffe den
englischen Begriffen gegenÃ¼ber gestellt. Warum schreiben wir die
Gleichung in der Form? Damit wir spÃ¤ter noch weitere
\(\beta_px_p\)-Paare ergÃ¤nzen kÃ¶nen und so \emph{multiple} Modelle bauen
kÃ¶nnen.

\hypertarget{tbl-reg-deu-eng}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2281}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4912}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1140}}@{}}
\caption{\label{tbl-reg-deu-eng}Vergleich und Ãbersicht der schulischen
vs.~statistischen Begriffe in den linearen Regression sowie die
deutschen und englischen Begriffe.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{y = mx +b}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{y \sim \beta_0 + \beta_1 x_1 + \epsilon}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Deutsch
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Englisch
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{y = mx +b}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{y \sim \beta_0 + \beta_1 x_1 + \epsilon}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Deutsch
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Englisch
\end{minipage} \\
\midrule()
\endhead
\(m\) & \(\beta_1\) & Steigung & Slope \\
\(x\) & \(x_1\) & Einflussvariable & Risk factor \\
\(b\) & \(\beta_0\) & y-Achsenabschnitt & Intercept \\
& \(\epsilon\) & Residuen & Residual \\
\bottomrule()
\end{longtable}

In Abbildung~\ref{fig-lin-reg-01} sehen wir die Visualisierung der
Gleichung in einer Abbildung. Die Gerade lÃ¤uft durch die Punktewolke und
wird durch die statistischen MaÃzahlen bzw. Parameter \(\beta_0\),
\(\beta_1\) sowie den \(\epsilon\) beschrieben. Wir sehen, dass das
\(\beta_0\) den \emph{Intercept} darstellt und das \(\beta_1\) die
Steigung der Geraden. Wenn wir \(x\) um 1 Einheit erhÃ¶hen \(x+1\), dann
steigt der \(y\) Wert um den Wert von \(\beta_1\). Die einzelnen
Abweichungen der beobachteten \(y\)-Wert zu den \(y\)-Werten auf der
Gerade (\(\hat{y}\)) werden als Residuen oder auch \(\epsilon\)
bezeichnet.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/statistical_modeling_lm.pdf}

}

\caption{\label{fig-lin-reg-01}Visualisierung der linearen Regression.
Wir legen eine Gerade durch eine Punktewolke. Die Gerade wird durch die
statistischen MaÃzahlen bzw. Parameter \(\beta_0\), \(\beta_1\) sowie
den \(\epsilon\) beschrieben.}

\end{figure}

{\marginnote{\begin{footnotesize}In R werden die \(\hat{y}\) auch
\emph{fitted values} genannt. Die \(\epsilon\) Werte werden dann
\emph{residuals} bezeichnet.\end{footnotesize}}}

Schauen wir uns einmal den Zusammenhang von \(y\), den beobachteten
Werten, und \(\hat{y}\), den geschÃ¤tzen Werten auf der Gerade in unserem
Beispiel an. In Tabelle~\ref{tbl-lin-reg-epsilon} sehen wir die
Berechnung der einzelnen Residuen fÃ¼r die Gerade aus der
Abbildung~\ref{fig-scatter-lin-01}. Wir nehmen jedes beobachtete \(y\)
und ziehen den Wert von \(y\) auf der Gerade, bezeichnet als
\(\hat{y}\), ab. Diesen Schritt machen wir fÃ¼r jedes Wertepaar
\((y_i; \hat{y}_i)\).

\begin{figure*}

\hypertarget{tbl-lin-reg-epsilon}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0476}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0476}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2286}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3429}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3333}}@{}}
\caption{\label{tbl-lin-reg-epsilon}Zusammenhang zwischen den \(y\), den
beobachteten Werten, und \(\hat{y}\), den geschÃ¤tzen Werten auf der
Gerade. Wir nennen den Abstand \(y_i - \hat{y}_i\) auch Residuum oder
\emph{Epsilon} \(\epsilon\).}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
x
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
y
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\hat{y}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Residuen (\(\boldsymbol{\epsilon}\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Wert
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
x
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
y
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{\hat{y}}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Residuen (\(\boldsymbol{\epsilon}\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Wert
\end{minipage} \\
\midrule()
\endhead
0.8 & 1.2 & 1.38 & \(\epsilon_1 = y_1 - \hat{y}_1\) &
\(\epsilon_1 = 1.2 - 1.38 = -0.18\) \\
1.0 & 1.8 & 1.48 & \(\epsilon_2 = y_2 - \hat{y}_2\) &
\(\epsilon_2 = 1.8 - 1.48 = +0.32\) \\
1.2 & 1.3 & 1.58 & \(\epsilon_3 = y_3 - \hat{y}_3\) &
\(\epsilon_3 = 1.3 - 1.58 = -0.28\) \\
1.9 & 1.7 & 1.94 & \(\epsilon_4 = y_4 - \hat{y}_4\) &
\(\epsilon_4 = 1.7 - 1.94 = -0.24\) \\
2.0 & 2.6 & 1.99 & \(\epsilon_5 = y_5 - \hat{y}_5\) &
\(\epsilon_5 = 2.6 - 1.99 = +0.61\) \\
2.7 & 1.8 & 2.34 & \(\epsilon_6 = y_6 - \hat{y}_6\) &
\(\epsilon_6 = 1.8 - 2.34 = -0.54\) \\
2.8 & 2.7 & 2.40 & \(\epsilon_7 = y_7 - \hat{y}_7\) &
\(\epsilon_7 = 2.7 - 2.40 = +0.30\) \\
\bottomrule()
\end{longtable}

\end{figure*}

{\marginnote{\begin{footnotesize}In R wird in Modellausgaben die
Standardabweichung der Residuen \(s_{\epsilon}\) als \texttt{sigma}
bezeichnet.\end{footnotesize}}}

Die Abweichungen \(\epsilon\) oder auch Residuen genannt haben einen
Mittelwert von \(\bar{\epsilon} = 0\) und eine Varianz von
\(s^2_{\epsilon} = 0.17\). Wir schreiben, dass die Residuen
normalverteilt sind mit
\(\epsilon \sim \mathcal{N}(0, s^2_{\epsilon})\). Wir zeichnen die
Gerade also so durch die Punktewolke, dass die AbstÃ¤nde zu den Punkten,
die Residuen, im Mittel null sind. Die Optimierung erreichen wir in dem
wir die Varianz der Residuuen minimieren. Folglich modellieren wir die
Varianz.

\hypertarget{simples-lineare-regression-in-r}{%
\section{Simples lineare Regression in
R}\label{simples-lineare-regression-in-r}}

Im Allgemeinen kÃ¶nnen wir ein Modell in R wie folgt schreiben. Wir
brauchen \emph{ein} y auf der linken Seite und in der simplen linearen
Regressione ein \(x\) auf der rechten Seite der Gleichung. Wir brauchen
also zwei Variablen \(y\) und \(x\), die natÃ¼rlich nicht im Datensatz in
R so heiÃen mÃ¼ssen.

\begin{figure}

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{./images/statistical_modeling_0.png}

}

\caption{\label{fig-lin-reg-01}Modellschreibweise \(y\) hÃ¤ngt ab von
\(x\). Das \(y\) reprÃ¤sentiert eine Spalte im Datensatz und das \(x\)
reprÃ¤sentiert ebenso eine Spalte im Datensatz.}

\end{figure}

Konkret wÃ¼rden wir in unserem Beispiel das Modell wie folgt benennen.
Das \(y\) wird zu \texttt{jump\_length} und das \(x\) wird zu
\texttt{weight}. Wir haben dann das Modell in der simplesten Form
definiert.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/statistical_modeling_2.png}

}

\caption{\label{fig-lin-reg-22}Modellschreibweise bzw. \texttt{formula}
Schreibweise in R. Die Variable \(y\) hÃ¤ngt ab von \(x\) am Beispiel des
Datensatzes \texttt{simple\_tbl} mit den beiden Variablen
\texttt{jump\_length} als \(y\) und \texttt{weight} als \(x\).}

\end{figure}

Nachdem wir das Modell definiert haben, setzen wir dieses Modell
\texttt{jump\_length\ \textasciitilde{}\ weight} in die Funktion
\texttt{lm()} ein um das lineare Modell zu rechnen. Wie immer mÃ¼ssen wir
auch festlegen aus welcher Datei die Spalten genommen werden sollen. Das
machen wir mit der Option \texttt{data\ =\ simple\_tbl}. Wir speichern
dann die Ausgabe der Funktion \texttt{lm()} in dem Objekt
\texttt{fit\_1} damit wir die Ausgabe noch in andere Funktionen pipen
kÃ¶nnen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ simple\_tbl)}
\end{Highlighting}
\end{Shaded}

{\marginnote{\begin{footnotesize}An dieser Stelle kannst du schnell in
das Problem der Antwort auf alles kommen: ``42''\end{footnotesize}}}

Wir kÃ¶nnen jetzt mir dem Modell drei Dinge tun. AbhÃ¤ngig von der
Fragestellung liefert uns natÃ¼rlich jedes der drei MÃ¶glichkeiten eine
andere Antwort.

\begin{itemize}
\tightlist
\item
  Wir rechnen mit dem Fit des Modells eine ANOVA (siehe
  Kapitel~\ref{sec-anova})
\item
  Wir rechnen ein kausales Modell, uns interessieren die Effekte (siehe
  Kapitel~\ref{sec-simple-kausal})
\item
  Wir rechnen ein prÃ¤diktives Modell, uns interessiert der Wert
  \emph{neuer} Werte (siehe Kapitel~\ref{sec-simple-pred})
\end{itemize}

\hypertarget{sec-simple-kausal}{%
\subsection{Kausales Modell}\label{sec-simple-kausal}}

Im Folgenden rechnen wir ein kausales Modell, da wir an dem Effekt des
\(x\) interessiert sind. Wenn also das \(x_1\) um eine Einheit ansteigt,
um wie viel verÃ¤ndert sich dann das \(y\)? Der SchÃ¤tzer \(\beta_1\) gibt
uns also den Einfluss oder den kausalen Zusammenhang zwischen \(y\) und
\(x_1\) wieder.

{\marginnote{\begin{footnotesize}Die Funktion \texttt{summary()} gibt
dir das Ergebnis eines kausalen Modells wieder\end{footnotesize}}}

Im ersten Schritt schauen wir uns die Ausgabe der Funktion \texttt{lm()}
in der Funktion \texttt{summary()} an. Daher pipen wir das Objekt
\texttt{fit\_1} in die Funktion \texttt{summary()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ summary}
\end{Highlighting}
\end{Shaded}

Wir erhalten folgende Ausgabe dargestellt in
Abbildung~\ref{fig-lin-reg-3}.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/statistical_modeling_3.png}

}

\caption{\label{fig-lin-reg-3}Die \texttt{summary()} Ausgabe des Modells
\texttt{fit\_1}.}

\end{figure}

Was sehen wir in der Ausgabe der \texttt{summary()} Funktion? Als erstes
werden uns die Residuen wiedergegeben. Wenn wir nur wenige Beobachtungen
haben, dann werden uns die Residuen direkt wiedergegeben, sonst die
Verteilung der Residuen. Mit der Funktion \texttt{augment()} aus dem R
Paket \texttt{broom} kÃ¶nnen wir uns die Residuen wiedergeben lassen. Die
Residuen schauen wir uns aber nochmal im
Kapitel~\ref{sec-lin-reg-quality} genauer an.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ augment}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 7 x 8
  jump_length weight .fitted .resid  .hat .sigma .cooksd .std.resid
        <dbl>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>   <dbl>      <dbl>
1         1.2    0.8    1.38 -0.176 0.388  0.496  0.0778     -0.496
2         1.8    1      1.48  0.322 0.297  0.471  0.151       0.844
3         1.3    1.2    1.58 -0.280 0.228  0.483  0.0725     -0.701
4         1.7    1.9    1.94 -0.237 0.147  0.492  0.0275     -0.564
5         2.6    2      1.99  0.612 0.156  0.384  0.199       1.47 
6         1.8    2.7    2.34 -0.545 0.367  0.376  0.656      -1.51 
7         2.7    2.8    2.40  0.304 0.417  0.467  0.276       0.877
\end{verbatim}

Im zweiten Block erhalten wir die Koeffizienten (eng.
\emph{coefficients}) der linearen Regression. Das heiÃt, wir kriegen
dort \(\beta_0\) als y-Achsenabschnitt sowie die Steigung \(\beta_1\)
fÃ¼r das Gewicht. Dabei ist wichtig zu wissen, dass immer als erstes der
y-Achsenabschnitt \texttt{(Intercept)} auftaucht. Dann die Steigungen
der einzelnen \(x\) in dem Modell. Wir haben nur \emph{ein}
kontinuierliches \(x\), daher ist die Interpretation der Ausgabe
einfach. Wir kÃ¶nnen die Gradengleichung wie folgt formulieren.

\[
jump\_length \sim 0.97 + 0.51 \cdot weight
\]

Was heiÃt die Gleichung nun? Wenn wir das \(x\) um eine Einheit erhÃ¶hen
dann verÃ¤ndert sich das \(y\) um den Wert von \(\beta_1\). Wir haben
hier eine Steigung von \(0.51\) vorliegen. Ohne Einheit keine
Interpretation! Wir wissen, dass das Gewicht in {[}mg{]} gemessen wurde
und die Sprungweite in {[}cm{]}. Damit kÃ¶nnen wir aussagen, dass wenn
ein Floh 1 mg mehr wiegt der Floh 0.51 cm weiter springen wÃ¼rde.

Schauen wir nochmal in die \emph{saubere} Ausgabe der \texttt{tidy()}
Funktion. Wir sehen nÃ¤mlich noch einen \(p\)-Wert fÃ¼r den Intercept und
die Steigung von \texttt{weight}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 5
  term        estimate std.error statistic p.value
  <chr>          <dbl>     <dbl>     <dbl>   <dbl>
1 (Intercept)    0.969     0.445      2.18  0.0813
2 weight         0.510     0.232      2.20  0.0790
\end{verbatim}

Wenn wir einen \(p\)-Wert sehen, dann brauchen wir eine Nullhypothese,
die wir dann eventuell mit der Entscheidung am Signifikanzniveau
\(\alpha\) von 5\% ablehnen kÃ¶nnen. Die Nullhypothese ist die
Gleichheitshypothese. Wenn es also keinen Effekt von dem Gewicht auf die
Sprungweite gebe, wie groÃ wÃ¤re dann \(\beta_1\)? Wir hÃ¤tten dann keine
Steigung und die Grade wÃ¼rde parallel zur x-Achse laufen. Das
\(\beta_1\) wÃ¤re dann gleich null.

\[
\begin{align*} 
H_0: \beta_i &= 0\\  
H_A: \beta_i &\neq 0 \\   
\end{align*}
\]

Wir haben fÃ¼r jedes \(\beta_i\) ein eigenes Hypothesenpaar. Meistens
interessiert uns der Intercept nicht. Ob der Intercept nun durch die
Null geht oder nicht ist eher von geringem Interessen.

Spannder ist aber wie sich der \(p\)-Wert berechnet. Der \(p\)-Wert
basiert auf einer t-Statistik, also auf dem t-Test. Wir rechnen fÃ¼r
jeden Koeffizienten \(\beta_i\) einen t-Test. Das machen wir in dem wir
den Koeffizienten \texttt{estimate} durch den Fehler des Koeffizienten
\texttt{std.error} teilen.

\[
\begin{align*} 
T_{(Intercept)} &= \cfrac{\mbox{estimate}}{\mbox{std.error}}  = \cfrac{0.969}{0.445} = 2.18\\  
T_{weight} &= \cfrac{\mbox{estimate}}{\mbox{std.error}}  = \cfrac{0.510}{0.232} = 2.20\\   
\end{align*}
\]

Wir sehen in diesem Fall, dass weder der Intercept noch die Steigung von
\texttt{weight} signifikant ist, da die \(p\)-Werte mit \(0.081\) und
\(0.079\) leicht Ã¼ber dem Signifikanzniveau von \(\alpha\) gleich 5\%
liegen. Wir haben aber einen starkes Indiz gegen die Nullhypothese, da
die Wahrscheinlichkeit die Daten zu beobachten sehr gering ist unter der
Annahme das die Nullhypothese gilt.

Zun AbschluÃ noch die Funktion \texttt{glance()} ebenfalls aus dem R
Paket \texttt{broom}, die uns erlaubt noch die QualitÃ¤tsmaÃe der
linearen Regression zu erhalten. Wir mÃ¼ssen nÃ¤mlich noch schauen, ob die
Regression auch funktioniert hat. Die ÃberprÃ¼fung geht mit einem \(x\)
sehr einfach. Wir kÃ¶nnen uns die Grade ja anschauen. Das geht dann mit
einem Model mit mehreren \(x\) nicht mehr und wir brauchen andere
statistsiche MaÃzahlen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ glance }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 12
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>
1     0.492         0.391 0.455      4.84  0.0790     1  -3.24  12.5  12.3
# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

\hypertarget{sec-simple-pred}{%
\subsection{PrÃ¤diktives Modell}\label{sec-simple-pred}}

Neben dem kausalen Modell gibt es auch die MÃ¶glichkeit ein prÃ¤diktives
Modell zu rechnen. Im Prinzip ist die Sprache hier etwas ungenau. Wir
verwenden das gefittete Modell nur anders. Anstatt das Modell
\texttt{fit\_1} in die Funktion \texttt{summary()} zu pipen, pipen wir
die das Modell in die Funktion \texttt{predict()}. Die Funktion
\texttt{predict()} kann dann fÃ¼r neue Daten Ã¼ber die Option
\texttt{newdata\ =} das \(y\) vorhersagen.

In unserem Fall mÃ¼ssen wir uns deshalb ein \texttt{tibble} mit einer
Spalte bauen. Wir haben ja oben im Modell auch nur ein \(x_1\) mit
aufgenommen. SpÃ¤ter kÃ¶nnen wir natÃ¼rlich auch fÃ¼r multiple Modelle die
Vorhersage machen. Wichtig ist, dass die Namen gleich sind. Das heiÃt in
dem neuen Datensatz mÃ¼ssen die Spalten \emph{exakt} so heiÃen wir in dem
alten Datensatz in dem das Modell gefittet wurde.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simple\_new\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{weight =} \FunctionTok{c}\NormalTok{(}\FloatTok{1.7}\NormalTok{, }\FloatTok{1.4}\NormalTok{, }\FloatTok{2.1}\NormalTok{, }\FloatTok{3.0}\NormalTok{)) }

\FunctionTok{predict}\NormalTok{(fit\_1, }\AttributeTok{newdata =}\NormalTok{ simple\_new\_tbl) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   1    2    3    4 
1.84 1.68 2.04 2.50 
\end{verbatim}

Wie wir sehen ist die Anwendung recht einfach. Wir haben die vier
\texttt{jump\_length} Werte vorhergesagt bekommen, die sich mit dem Fit
des Modells mit den neuen \texttt{weight} Werten ergeben.

In Abbildung~\ref{fig-scatter-lin-pred} sehen wir die Visualisierung der
vier vorhergesagten Werte. Die Werte mÃ¼ssen auf der Geraden liegen.

\begin{figure}

{\centering \includegraphics{./stat-linear-reg-basic_files/figure-pdf/fig-scatter-lin-pred-1.pdf}

}

\caption{\label{fig-scatter-lin-pred}Scatterplot der \emph{alten}
Beobachtungen der Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]}.
Sowie der \emph{neuen} vorhergesagten Beobachtungen auf der Geraden.}

\end{figure}

Wir werden spÃ¤ter in der Klassiifkation, der Vorhersage von
\(0/1\)-Werten, sowie in der multiplen Regression noch andere
PrÃ¤dktionen und deren MaÃzahlen kennenlernen. Im Rahmen der simplen
Regression soll dies aber erstmal hier genÃ¼gen.

\hypertarget{sec-lin-reg-quality}{%
\chapter{MaÃzahlen der ModelgÃ¼te}\label{sec-lin-reg-quality}}

{\marginnote{\begin{footnotesize}Wir meinen mit GÃ¼tekriterien wie gut
das statistische Modellieren funktioniert hat. Wir haben eine groÃe
Auswahl an Methoden und wir mÃ¼ssen das Ergebnis des Modellierens
Ã¼berprÃ¼fen.\end{footnotesize}}}

Wir interpretieren keine der GÃ¼tekriterien und statistischen MaÃzahlen
alleine sondern in der Gesamtheit. Es gibt eine Reihe von MaÃzahlen fÃ¼r
die GÃ¼te eines Modells, wir schauen uns hier einige an. SpÃ¤ter werden
wir uns noch andere MaÃzahlen anschauen, wenn wir eine multiple lineare
Regression rechnen. Das
\href{https://easystats.github.io/performance/}{R Paket performance}
werden wir spÃ¤ter auch nutzen um die notwendigen GÃ¼tekriterien zu
erhalten.

Wir wollen eine Gerade durch Punkte legen. Deshalb mÃ¼ssen wir folgende
Fragen klÃ¤ren:

\begin{itemize}
\tightlist
\item
  LÃ¤uft die Gerade durch die Mitte der Punkte? Hier hilft ein
  Residualplot fÃ¼r die Bewertung (siehe
  Kapitel~\ref{sec-linreg-residual}).
\item
  Liegen die Punkte alle auf der Geraden? Hier hilft das
  BestimmtheitsmaÃ \(R^2\) weiter (siehe
  Kapitel~\ref{sec-linreg-bestimmt})
\item
  Folgt unser Outcome \(y\) einer Normalverteilung? Hier kann der
  QQ-Plot helfen (siehe Kapitel~\ref{sec-linreg-qq})
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Achte darauf welche Lernstufe du hast und was wir \emph{wirklich} in der
Vorlesung gemacht haben. Hier kann sich das ein oder andere
Ã¼berschneiden.

Was heiÃt Ã¼berscheiden? Wir werden uns nicht in jedem Modul alle
GÃ¼tekriterien anschauen. Deshalb Augen auf deine Mitschrift.
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-16}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-16}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               see, performance)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-4}{%
\section{Daten}\label{daten-4}}

Nachdem wir uns im vorherigen Kapitel mit einem sehr kleinen Satensatz
beschÃ¤ftigt haben, nehmen wir einen groÃen Datensatz. Bleiben aber bei
einem simplen Modell. Wir brauchen dafÃ¼r den Datensatz
\texttt{flea\_dog\_cat\_length\_weight.xlsx}. In einer simplen linearen
Regression schauen wir uns den Zusammenhang zwischen einem \(y\) und
einem \(x_1\) an. Daher wÃ¤hlen wir aus dem Datensatz die beiden Spalten
\texttt{jump\_length} und \texttt{weight}. Wir wollen nun feststellen,
ob es einen Zusammenhang zwischen der Sprungweite in {[}cm{]} und dem
Flohgewicht in {[}mg{]} gibt. In dem Datensatz finden wir 400 FlÃ¶he von
Hunden und Katzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, jump\_length, weight)}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-model-1} ist der Datensatz \texttt{model\_tbl}
nochmal dargestellt.

\hypertarget{tbl-model-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-model-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} und der normalverteilten
Variable \texttt{weight}. Wir betrachten die ersten sieben Zeilen des
Datensatzes.}\tabularnewline
\toprule()
animal & jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & weight \\
\midrule()
\endhead
cat & 15.79 & 6.02 \\
cat & 18.33 & 5.99 \\
cat & 17.58 & 8.05 \\
cat & 14.09 & 6.71 \\
cat & 18.22 & 6.19 \\
cat & 13.49 & 8.18 \\
cat & 16.28 & 7.46 \\
\bottomrule()
\end{longtable}

Im Folgenden \emph{ignorieren} wir, dass die Sprungweiten und die
Gewichte der FlÃ¶he auch noch von den Hunden oder Katzen sowie dem
unterschiedlichen Geschlecht der FlÃ¶he abhÃ¤ngen kÃ¶nnten. Wir schmeiÃen
alles in einen Pott und schauen nur auf den Zusammenhang von Sprungweite
und Gewicht.

\hypertarget{das-simple-lineare-modell}{%
\section{Das simple lineare Modell}\label{das-simple-lineare-modell}}

Wir fitten ein simples lineares Modell mit nur einem Einflussfaktor
\texttt{weight} auf die SprunglÃ¤nge \texttt{jump\_length}. Wir erhalten
dann das Objekt \texttt{fit\_1} was wir dann im Weiteren nutzen werden.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\end{Highlighting}
\end{Shaded}

Wir nutzen jetzt dieses simple lineare Modell fÃ¼r die weiteren
GÃ¼tekritierien.

\hypertarget{sec-linreg-residual}{%
\section{Residualplot}\label{sec-linreg-residual}}

{\marginnote{\begin{footnotesize}In R wird in Modellausgaben die
Standardabweichung der Residuen \(s_{\epsilon}\) als \texttt{sigma}
bezeichnet.\end{footnotesize}}}

Wir wollen mit dem Residualplot die Frage beantworten, ob die Gerade
\emph{mittig} durch die Punktewolke lÃ¤uft. Die Residuen \(\epsilon\)
sollen normalverteilt sein mit einem Mittelwert von Null
\(\epsilon \sim \mathcal{N}(0, s^2_{\epsilon})\).

Wir erhalten die Residuen \texttt{resid} und die angepassten Werte
\texttt{.fitted} auf der Geraden Ã¼ber die Funktion \texttt{augment()}.
Die Funktion \texttt{augment()} gibt noch mehr Informationen wieder,
aber wir wollen uns jetzt erstmal auf die Residuen konzentrieren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{resid\_plot\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ fit\_1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{augment}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(.fitted, .resid)}

\NormalTok{resid\_plot\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 2
  .fitted .resid
    <dbl>  <dbl>
1    17.9 -2.09 
2    17.8  0.489
3    20.6 -3.03 
4    18.8 -4.72 
5    18.1  0.110
\end{verbatim}

Die Daten selber interssieren uns nicht einer Tabelle. Stattdessen
zeichen wir einmal den Residualplot. Bei dem Residualplot tragen wir die
Werte der Residuen \texttt{.resid} auf die y-Achse auf und die
angepassten y-Werte auf der Geraden \texttt{.fitted} auf die x-Achse.
Wir kippen im Prinzip die gefittete Gerade so, dass die Gerade parallel
zu x-Achse lÃ¤uft.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(resid\_plot\_tbl, }\FunctionTok{aes}\NormalTok{(.fitted, .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-linear-reg-quality_files/figure-pdf/fig-scatter-qual-01-1.pdf}

}

\caption{\label{fig-scatter-qual-01}Residualplot der Residuen des Models
\texttt{fit\_1}. Die rote Linie stellt die geschÃ¤tzte Gerade da. Die
Punkte sollen gleichmÃ¤Ãig und ohne eine Struktur um die Gerade verteilt
sein.}

\end{figure}

{\marginnote{\begin{footnotesize}The residual plot should look like the
sky at night, with no pattern of any sort.\end{footnotesize}}}

In Abbildung~\ref{fig-scatter-qual-01} sehen wir den Residualplot von
unseren Beispieldaten. Wir sehen, dass wir keine Struktur in der
Punktewolke erkennen. Auch sind die Punkte gleichmÃ¤Ãig um die Gerade
verteilt. Wir haben zwar einen Punkt, der sehr weit von der Gerade weg
ist, das kÃ¶nnen wir aber ignorieren. SpÃ¤ter kÃ¶nnen wir uns noch
Ã¼berlegen, ob wir einen AusreiÃer (eng. \emph{outlier}) vorliegen haben.

\hypertarget{sec-linreg-bestimmt}{%
\section{\texorpdfstring{BestimmtheitsmaÃ
\(R^2\)}{BestimmtheitsmaÃ R\^{}2}}\label{sec-linreg-bestimmt}}

Nachdem wir nun wissen wie gut die Gerade durch die Punkte lÃ¤uft, wollen
wir noch bestimmen wie genau die Punkte auf der Geraden liegen. Das
heiÃt wir wollen mit dem BestimmtheitsmaÃ \(R^2\) ausdrÃ¼cken wie stark
die Punkte um die Gerade variieren. Wir kÃ¶nnen folgende Aussage Ã¼ber das
BestimmtheitsmaÃ \(R^2\) treffen. Die Abbildung~\ref{fig-rsquare}
visualisiert nochmal den Zusammenhang.

\begin{itemize}
\tightlist
\item
  wenn alle Punkte auf der Geraden liegen, dann ist das BestimmtheitsmaÃ
  \(R^2\) gleich 1.
\item
  wenn alle Punkte sehr stark um die Gerade streuuen, dann lÃ¤uft das
  BestimmtheitsmaÃ \(R^2\) gegen 0.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/statistical_modeling_rsquare.pdf}

}

\caption{\label{fig-rsquare}Visualisierung des BestimmtheitsmaÃes
\(R^2\). Auf der linken Seite sehen wir eine perfekte Ãbereinstimmung
der Punkte und der geschÃ¤tzten Gerade. Wir haben ein \(R^2\) von 1
vorliegen. Sind die Punkte und die geschÃ¤tzte Gerade nicht
deckungsgleich, so lÃ¤uft das \(R^2\) gegen 0.}

\end{figure}

Da die Streuung um die Gerade auch gleichzeitig die Varianz
wiederspiegelt, kÃ¶nnen wir auch sagen, dass wenn alle Punkte auf der
Geraden liegen, die Varianz gleich Null ist. Die Einflussvariable
\(x_1\) erklÃ¤rt die gesamte Varianz, die durch die Beobachtungen
verursacht wurde.

Damit beschreibt das BestimmtheitsmaÃ \(R^2\) auch den Anteil der
Varianz, der durch die lineare Regression, daher der Graden, erklÃ¤rt
wird. Wenn wir ein BestimmtheitsmaÃ \(R^2\) von Eins haben, wird die
gesamte Varianz von unserem Modell erklÃ¤rt. Haben wir ein
BestimmtheitsmaÃ \(R^2\) von Null, wird gar keine Varianz von unserem
Modell erklÃ¤rt. Damit ist ein niedriges BestimmtheitsmaÃ \(R^2\)
schlecht.

Wir kÃ¶nnen die Funktion \texttt{glance()} nutzen um uns das
\texttt{r.squared} und das \texttt{adj.r.squared} wiedergeben zu lassen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{glance}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(r.squared, adj.r.squared)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
  r.squared adj.r.squared
      <dbl>         <dbl>
1     0.251         0.250
\end{verbatim}

{\marginnote{\begin{footnotesize}Wir nutzen grundsÃ¤tzlich das
adjustierte \(R^2\)\texttt{adj.r.squared} in der
Anwendung.\end{footnotesize}}}

Wir haben wir ein \(R^2\) von \(0.31\) vorliegen. Damit erklÃ¤rt unser
Modell bzw. die Gerade 31\% der Varianz. Das ist jetzt nicht viel, aber
wundert uns auch erstmal nicht. Wir haben ja die Faktoren
\texttt{animal} und \texttt{sex} ignoriert. Beide Faktoren kÃ¶nnten ja
auch einen Teil der Varianz erklÃ¤ren. DafÃ¼r mÃ¼ssten wir aber eine
multiple lineare Regression mit mehren \(x\) rechnen.

Wenn wir eine multiple Regression rechnen, dann nutzen wir das
adjustierte \(R^2\)\texttt{adj.r.squared} in der Anwendung. Das hat den
Grund, dass das \(R^2\) automatisch ansteigt je mehr Variablen wir in
das Modell nehmen. Jede neue Variable wird immer \emph{etwas} erklÃ¤ren.
Um dieses Ãberanpassen (eng. \emph{overfitting}) zu vermeiden nutzen wir
das adjustierte \(R^2\). Im Falle des adjustierte \(R^2\) wird ein
Strafterm eingefÃ¼hrt, der das adjustierte \(R^2\) kleiner macht je mehr
Einflussvariablen in das Modell aufgenommen werdenn.

\hypertarget{sec-linreg-qq}{%
\section{QQ-Plot}\label{sec-linreg-qq}}

\begin{marginfigure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/angel_01.png}

}

\end{marginfigure}

Das klingt hier alles etwas wage\ldots{} Ja, das stimmt. Aber wir
brauchen den QQ-Plot nur ganz kurz und wir mÃ¼ssten sehr viel Energei
investieren um den QQ-Plot zu durchdringen. Deshalb hier die wage und
grobe Darstellung.

Mit dem Quantile-Quantile Plot oder kurz QQ-Plot kÃ¶nnen wir Ã¼berprÃ¼fen,
ob unser \(y\) aus einer Normalverteilung stammt. Oder andersherum, ob
unser \(y\) approximativ normalverteilt ist. Der QQ-Plot ist ein
visuelles Tool. Daher musst du immer schauen, ob dir das Ergebnis passt
oder die Abweichungen zu groÃ sind. Es hilft dann manchmal die Daten zum
Beispiel einmal zu \(log\)-Transformieren und dann die beiden QQ-Plots
miteinander zu vergleichen.

Wir brauchen fÃ¼r einen QQ-Plot viele Beobachtungen. Das heiÃt, wir
brauchen auf jeden Fall mehr als 20 Beobachtungen. Dann ist es auch
hÃ¤ufig schwierig den QQ-Plot zu bewerten, wenn es viele
Behandlungsgruppen oder BlÃ¶cke gibt. Am Ende haben wir dann zwar mehr
als 20 Beoabchtungen aber pro Kombination Behandlung und Block nur vier
Wiederholungen. Und vier Wiederholungen sind zu wenig fÃ¼r eine sinnvolle
Interpretation eines QQ-Plots.

Grob gesprochen vergleicht der QQ Plot die Quantile der vorliegenden
Beobachtungen, in unserem Fall der Variablen \texttt{jump\_length}, mir
den Quantilen einer theoretischen Normalverteilung, die sich aus den
Daten mit dem Mittelwert und der Standardabweichung von
\texttt{jump\_length} ergeben wÃ¼rden.

Wir kÃ¶nnen die Annahme der Normalverteilung recht einfach in
\texttt{ggplot} Ã¼berprÃ¼fen. Wir sehen in
Abbildung~\ref{fig-scatter-qual-02} den QQ-Plot fÃ¼r die Variable
\texttt{jump\_length}. Die Punkte sollten alle auf einer Diagonalen
liegen. Hier dargestellt durch die rote Linie. HÃ¤ufig weichen die Punkte
am Anfang und Ende der Spannweite der Beobachtungen etwas ab.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(model\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ jump\_length)) }\SpecialCharTok{+} 
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-linear-reg-quality_files/figure-pdf/fig-scatter-qual-02-1.pdf}

}

\caption{\label{fig-scatter-qual-02}QQ-Plot der Sprungweite in {[}cm{]}.
Die Gerade geht einmal durch die Mitte der Punkte und die Punkte liegen
nicht exakt auf der Geraden. Eine leichte Abweichung von der
Normalverteilung kÃ¶nnte vorliegen.}

\end{figure}

Wir werden uns spÃ¤ter auch noch hÃ¤ufig die Residuen aus den Modellen
anschauen. Die Residuen mÃ¼ssen nach dem Fit des Modells einer
Normalverteilung folgen. Wir kÃ¶nnen diese Annahme an die Residuen mit
einem QQ-Plot Ã¼berprÃ¼fen. In Abbildung~\ref{fig-scatter-qual-resid}
sehen wir die Residuen aus dem Modell \texttt{fit\_1} in einem QQ-Plot.
Wir wÃ¼rden sagen, dass die Residuen approximativ normalvertelt sind. Die
Punkte liegen fast alle auf der roten Diagonalen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(resid\_plot\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ .resid)) }\SpecialCharTok{+} 
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-linear-reg-quality_files/figure-pdf/fig-scatter-qual-resid-1.pdf}

}

\caption{\label{fig-scatter-qual-resid}QQ-Plot der Residuen aus dem
Modell \texttt{fit\_1}. Die Residuen mÃ¼ssen einer approximativen
Normalverteilung folgen, sonst hat der Fit des Modelles nicht
funktioniert.}

\end{figure}

\hypertarget{modellguxfcte-mit-dem-r-paket-performance}{%
\section{\texorpdfstring{ModellgÃ¼te mit dem R Paket
\texttt{performance}}{ModellgÃ¼te mit dem R Paket performance}}\label{modellguxfcte-mit-dem-r-paket-performance}}

AbschlieÃend mÃ¶chte ich hier nochmal das
\href{https://easystats.github.io/performance/}{R Paket performance}
vorstellen. Wir kÃ¶nnen mit dem Paket auch die Normalverteilungsannahme
der Residuen Ã¼berprÃ¼fen. Das geht ganz einfach mit der Funktion
\texttt{check\_normality()} in die wir einfach das Objekt mit dem Fit
des Modells Ã¼bergeben.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{check\_normality}\NormalTok{(fit\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OK: residuals appear as normally distributed (p = 0.555).
\end{verbatim}

Wir haben auch die MÃ¶glichkeit uns einen Plot der ModellgÃ¼te anzeigen zu
lassen. In Abbildung~\ref{fig-scatter-qual-04} sehen wir die Ãbersicht
von bis zu sechs Abbildungen, die uns Informationen zu der ModellgÃ¼te
liefern. Wir mÃ¼ssen nur den Fit unseres Modells an die Funktion
\texttt{check\_model()} Ã¼bergeben.

Das SchÃ¶ne an der Funktion ist, dass jeder Subplot eine Beschreibung in
Englisch hat, wie der Plot auszusehen hat, wenn alles gut mit dem
Modellieren funktioniert hat.

Wir kommen dann in der multiplen linearen Regression nochmal auf das
Paket \texttt{performance} zurÃ¼ck. FÃ¼r dieses Kapitel reicht dieser
kurze Abriss.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{check\_model}\NormalTok{(fit\_1, }\AttributeTok{colors =}\NormalTok{ cbbPalette[}\DecValTok{6}\SpecialCharTok{:}\DecValTok{8}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{figure*}[H]

{\centering \includegraphics{./stat-linear-reg-quality_files/figure-pdf/fig-scatter-qual-04-1.pdf}

}

\caption{\label{fig-scatter-qual-04}Ãbersicht der Plots zu der
ModellgÃ¼te aus der Funktion \texttt{check\_model()}.}

\end{figure*}

\hypertarget{sec-lin-reg-corr}{%
\chapter{Korrelation}\label{sec-lin-reg-corr}}

\emph{Version vom September 14, 2022 um 08:52:37}

Die Korrelation gibt uns die Information welche Steigung die Gerade in
einer simplen linearen Regression hat. Dabei erlaubt es die Korrelation
uns verschiedene Geraden miteinander zu vergleichen. Die Korrelation ist
nÃ¤mlich einheitslos. Wir standardisieren durch die Anwendung der
Korrelation die Steigung der Geraden dafÃ¼r auf -1 bis +1. Damit ist die
Korrelation ein bedeutendes EffektmaÃ fÃ¼r die AbschÃ¤tzung eines
Zusammenhangs zwischen zwei Variablen.

Es gibt aber ein Problem. NÃ¤mlich nur weil etwas miteinander korreliert
muss es keinen kausalen Zusammenhang geben. So ist die Ursache und
Wirkung manchmal nicht klar zu benennen. Nehmen wir als plaktives
Beispiel dicke Kinder, die viel Fernsehen. Wir wÃ¼rden annehmen, dass
zwischen dem Fernsehkonsum und dem Gewicht von Kindern eine hohe
Korrelation vorliegt. Sind jetzt aber die Kinder dick, weil die Kinder
so viel Fernsehen oder schauen einfach dicke Kinder mehr Fernsehen, da
die Kinder dick sind und sich nicht mehr so viel bewegen wollen?

\marginnote{\begin{footnotesize}

Die Internetseite
\href{https://www.tylervigen.com/spurious-correlations}{Spurious
correlations} zeigt verschiedene \emph{zufÃ¤llige} Korrelationen zwischen
zwei \emph{zufÃ¤llig} ausgewÃ¤hlten Variablen aus den USA.

\end{footnotesize}}

Im Weiteren ist das Wort \emph{korrelieren} zum Gattungsbegriff in der
Statistik geworden, wenn es um den Vergleich oder den Zusammenhang von
zwei oder mehreren Variablen geht. Das heiÃt, in der Anwendung wird
gesagt, dass wir A mit B \emph{korrelieren} lassen wollen. Das Wort
\emph{korrelieren} steht jetzt aber nicht fÃ¼r das Konzept statistische
Korrelation sondern ist Platzhalter fÃ¼r eine noch vom Anwender zu
definierende oder zu findene statistische Methode.

In diesem Kapitel wollen wir uns mit der statisischen Korrelation
beschÃ¤ftigen. Die statistische Korrelation ist weniger aufregender, denn
am Ende ist die Korrelation nur eine Zahl zwischen -1 und +1.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Ein Wort zur Klausur}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-caution-color!10!white, colframe=quarto-callout-caution-color-frame]
Wenn wir in der Klausur eine Korrelation berechnen wollen, dann sprechen
wir immer von der Korrelation nach Pearson.
\end{tcolorbox}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-17}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-17}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, readxl,}
\NormalTok{               corrplot)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-5}{%
\section{Daten}\label{daten-5}}

Wir wollen uns erstmal mit einem einfachen Datenbeispiel beschÃ¤ftigen.
Wir kÃ¶nnen die Korrelation auf sehr groÃen DatensÃ¤tzen berechnen, wie
auch auf sehr kleinen DatensÃ¤tzen. Prinzipiell ist das Vorgehen gleich.
Wir nutzen jetzt aber erstmal einen kleinen Datensatz mit \(n=7\)
Beobachtungen. In der Tabelle~\ref{tbl-corr-0} ist der Datensatz
\texttt{simplel\_tbl} dargestellt. Wir wollen den Zusammenhang zwischen
der Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]} fÃ¼r sieben
Beobachtungen modellieren.

\hypertarget{tbl-corr-0}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-corr-0}Datensatz mit einer normalverteilten Variable
\texttt{jump\_length} und der normalverteilten Variable
\texttt{weight}.}\tabularnewline
\toprule()
jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
jump\_length & weight \\
\midrule()
\endhead
1.2 & 0.8 \\
1.8 & 1.0 \\
1.3 & 1.2 \\
1.7 & 1.9 \\
2.6 & 2.0 \\
1.8 & 2.7 \\
2.7 & 2.8 \\
\bottomrule()
\end{longtable}

In Abbildung~\ref{fig-scatter-corr-01} sehen wir die Visualisierung der
Daten \texttt{simple\_tbl} in einem Scatterplot mit einer geschÃ¤tzen
Gerade. Wir wollen jetzt mit der Korrelation die Steigung der Geraden
\emph{unabhÃ¤ngig} von der Einheit beschreiben. Oder wir wollen die
Steigung der Geraden standardisieren auf -1 bis 1.

\begin{figure}

{\centering \includegraphics{./stat-linear-reg-corr_files/figure-pdf/fig-scatter-corr-01-1.pdf}

}

\caption{\label{fig-scatter-corr-01}Scatterplot der Beobachtungen der
Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]}. Die Gerade verlÃ¤uft
mittig durch die Punkte.}

\end{figure}

\hypertarget{korrelation-theoretisch}{%
\section{Korrelation theoretisch}\label{korrelation-theoretisch}}

{\marginnote{\begin{footnotesize}Wenn wir zwei verteilte Variablen
miteinander korrelieren mÃ¶chten, dann nutzen wir die Korrelation nach
Pearson. Wenn wir nicht-normalverteilte Variablen miteinander
korrelieren mÃ¶chten, dann nutzen wir die Korrelation nach
Spearman\end{footnotesize}}}

Wir schauen uns hier die Korrelation nach Pearson an. Die Korrelation
nach Pearson nimmt an, dass beide zu korrelierende Variablen einer
Normalverteilung entstammen. Wenn wir keine Normalverteilung vorliegen
haben, dann nutzen wir die Korrelation nach Spearman. Die Korrelation
nach Spearman basiert auf den RÃ¤ngen der Daten und ist ein
nicht-parametrisches Verfahren. Die Korrelation nach Pearson ist die
parametrische Variante. Wir bezeichnen die Korrelation entweder mit
\(r\) oder dem griechischen Buchstaben \(\rho\) als \emph{rho}
gesprochen.

Was macht nun die Korrelation? Die Korrelation gibt die Richtung der
Geraden an. Oder noch konkreter die Steigung der Geraden normiert auf -1
bis 1. Die Abbildung~\ref{fig-corr1} zeigt die Visualisierung der
Korrelation fÃ¼r drei AusprÃ¤gungen. Eine Korrelation von \(r = -1\)
bedeutet eine maximale negative Korrelation. Die Gerade fÃ¤llt in einem
45Â° Winkel. Eine Korrelation von \(r = +1\) bedeutet eine maximale
positive Korrelation. Die gerade steigt in einem 45Â° Winkel. Eine
Korrelation von \(r = 0\) bedeutet, dass keine Korrelation vorliegt. Die
Grade verlÃ¤uft parallel zur x-Achse.

\begin{figure*}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/statistical_modeling_corr.pdf}

}

\caption{\label{fig-corr1}Visualisierung der Korrelation fÃ¼r drei
AusprÃ¤gungen des Korrelationskoeffizient.}

\end{figure*}

Im Folgenden sehen wir die Formel fÃ¼r den Korrelationskoeffizient nach
Pearson.

\[
\rho = r_{x,y} = \cfrac{s_{x,y}}{s_x \cdot s_y}
\]

Wir berechnen die Korrelation immer zwischen \emph{zwei} Variablen \(x\)
und \(y\). Es gibt keine multiple Korrelation Ã¼ber mehr als zwei
Variablen. Im ZÃ¤hler der Formel zur Korrelation steht die Kovarianz von
\(x\) und \(y\).

Wir kÃ¶nnen mit folgender Formel die Kovarianzen zwischen den beiden
Variablen \(x\) und \(y\) berechnen.

\[
s_{x,y} = \sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})
\]

Die folgende Formel berechnet die quadrierten Abweichung der
Beobachtungen von \(x\) zum Mittelwert \(\bar{x}\).

\[
s_x = \sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}
\]

Die folgende Formel berechnet die quadrierten Abweichung der
Beobachtungen von \(y\) zum Mittelwert \(\bar{y}\).

\[
s_y = \sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}
\]

In Tabelle~\ref{tbl-corr-example} ist der Zusammenhang nochmal Schritt
fÃ¼r Schrit aufgeschlÃ¼sselt. Wir berechnen erst die Abweichungsquadrate
von \(x\) und die Abweichungsquadrate von \(y\). Dann noch die Quadrate
der AbstÃ¤nde von \(x\) zu \(y\). AbschlieÃend summieren wir alles und
zeihen noch die Wurzel fÃ¼r die Abweichungsquadrate von \(x\) und \(y\).

\begin{figure*}

\hypertarget{tbl-corr-example}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1852}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1543}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1975}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1975}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2654}}@{}}
\caption{\label{tbl-corr-example}Tabelle zur Berechnung des
Korrelationskoeffizient}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
jump\_length \(\boldsymbol{y}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
weight \(\boldsymbol{x}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(y_i-\bar{y})^2}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(x_i-\bar{x})^2}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(x_i-\bar{x})(y_i-\bar{y})}\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
jump\_length \(\boldsymbol{y}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
weight \(\boldsymbol{x}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(y_i-\bar{y})^2}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(x_i-\bar{x})^2}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{(x_i-\bar{x})(y_i-\bar{y})}\)
\end{minipage} \\
\midrule()
\endhead
1.2 & 0.8 & 0.45 & 0.94 & 0.65 \\
1.8 & 1.0 & 0.01 & 0.60 & 0.06 \\
1.3 & 1.2 & 0.33 & 0.33 & 0.33 \\
1.7 & 1.9 & 0.03 & 0.02 & -0.02 \\
2.6 & 2.0 & 0.53 & 0.05 & 0.17 \\
1.8 & 2.7 & 0.03 & 0.86 & -0.07 \\
2.7 & 2.8 & 0.69 & 1.06 & 0.85 \\
& \(\sum\) & 2.05 & 3.86 & 1.97 \\
& \(\sqrt{\sum}\) & 1.43 & 1.96 & \\
\bottomrule()
\end{longtable}

\end{figure*}

Wir kÃ¶nnen die Zahlen dann aus der Tabelle in die Formel der Korrelation
nach Pearson einsetzen. Wir erhalten eine Korrelation von 0.70 und haben
damit eine recht starke positve Korrelation vorliegen.

\[
\rho = r_{x,y} = \cfrac{1.97}{1.96 \cdot 1.43} = 0.70
\] Wir kÃ¶nnen mit der Funktion \texttt{cor()} in R die Korrelation
zwischen zwei Spalten in einem Datensatz berechnen. Wir Ã¼berprÃ¼fen kurz
unsere Berechnung und stellen fest, dass wir richtig gerechnet haben.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(simple\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length, simple\_tbl}\SpecialCharTok{$}\NormalTok{weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.70149847
\end{verbatim}

In Abbildung~\ref{fig-corr2} sehen wir nochmal die ZusammenhÃ¤nge der
AbstÃ¤nde farbig hervorgehoben. Dader Nenner nur positive Zahlen annehmen
kann, wird das Vorzeichen der Korrelation durch den ZÃ¤hler bestimmt.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{./images/statistical_modeling_corr_2.pdf}

}

\caption{\label{fig-corr2}Visualisierung der Korrelation nochmal anders.
Um die Korrelation zu berechnen teilen wir die Quadrate mit den roten
und grÃ¼nen RÃ¤ndern durch die Wurzel der Quadrate der roten und grÃ¼nen
Linien. Wenn die Quadrate gleich groÃ sind, dann haben wir eine
Korrelation von \(r = 1.\)}

\end{figure}

\hypertarget{korrelation-in-r}{%
\section{Korrelation in R}\label{korrelation-in-r}}

Wir nutzen die Korrelation in R selten nrur fÃ¼r zwei Variablen. Meistens
schauen wir uns alle \emph{numerischen} Variablen gemeinsam in einer
Abbildung an. Wir nennen diese Abildung auch Korrelationsplot. Faktoren
sind keine numerischen Variablen. Daher kann es sein, dass fÃ¼r dein
Experiment kein Korrelationsplot in Frage kommt.

Wir schauen uns jetzt nochmal einen die Berechnung fÃ¼r den Datensatz
\texttt{simple\_tbl} an. Wir mÃ¼ssen fÃ¼r die Korrelation zwischen zwei
Variablen diese Variablen mit dem \texttt{\$}-Zeichen aus dem Datensatz
extrahieren. Die Funktion \texttt{cor()} kann nur mit Vektoren oder
\emph{ganzen} numerischen DatensÃ¤tzen arbeiten.

Wir kÃ¶nnen den Korrelationskoeffizienten nach Pearson mit der Option
\texttt{method\ =\ "pearson"} auswÃ¤hlen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(simple\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length, simple\_tbl}\SpecialCharTok{$}\NormalTok{weight, }\AttributeTok{method =} \StringTok{"pearson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.70149847
\end{verbatim}

Wenn wir die nicht-parametrische Variante des Korrelationskoeffizienten
nach Spearman berechnen wollen nutzen wir die Option
\texttt{method\ =\ "spearman"}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(simple\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length, simple\_tbl}\SpecialCharTok{$}\NormalTok{weight, }\AttributeTok{method =} \StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.79282497
\end{verbatim}

Wir kÃ¶nnen auch einen statistischen Test fÃ¼r die Korrelation rechnen.
Die Nullhypothese \(H_0\) wÃ¤re hierbei, dass die Korrelation \(r = 0\)
ist. Die Funktion \texttt{cor.test()} liefert den entsprechenden
\(p\)-Wert fÃ¼r die Entscheidung gegen die Nullhypothese.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor.test}\NormalTok{(simple\_tbl}\SpecialCharTok{$}\NormalTok{jump\_length, simple\_tbl}\SpecialCharTok{$}\NormalTok{weight, }\AttributeTok{method =} \StringTok{"pearson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's product-moment correlation

data:  simple_tbl$jump_length and simple_tbl$weight
t = 2.20101, df = 5, p-value = 0.078993
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.10929883  0.95176731
sample estimates:
       cor 
0.70149847 
\end{verbatim}

Aus dem Test erhalten wir den \(p\)-Wert von \(0.079\). Damit liegt der
\(p\)-Wert Ã¼ber den Signifikanzniveau von \(\alpha\) gleich 5\%. Wir
kÃ¶nnen somit die Nullhypothese nicht ablehnen. Wir sehen hier, die
Probelematik der kleinen Falzahl. Obwohl unsere Korrelation mit \(0.7\)
groÃ ist erhalten wir einen \(p\)-Wert, der nicht die Grenze von 5\%
unterschreitet. Wir sehen, dass die starre Grenze von \(\alpha\) auch
Probleme bereitet.

AbschlieÃend wollen wir uns noch die Funktion \texttt{corrplot()} aus
dem gleichnamigen R Paket \texttt{corrplot} anschauen. Die
\href{https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html}{Hilfeseite
zum Paket} ist sehr ausfÃ¼hrlich und bietet noch eine Reihe an anderen
Optionen. Wir benÃ¶tigen dafÃ¼r einen etwas grÃ¶Ãeren Datensatz mit
mehreren numerischen Variablen. Wir nutzen daher den
GummibÃ¤rchendatensatz und selektieren die Spalten \texttt{count\_bears}
bis \texttt{semester} aus.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{corr\_gummi\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/gummibears.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(count\_bears}\SpecialCharTok{:}\NormalTok{semester)}
\end{Highlighting}
\end{Shaded}

Wir brauchen fÃ¼r die Funktion \texttt{corrplot()} eine Matrix mit den
paarweisen Korrelationen. Wir kÃ¶nnen diese Matrix wiederum mit der
Funktion \texttt{cor()} erstellen. Wir mÃ¼ssen dazu aber erstmal alle
numerischen Variablen mit \texttt{select\_if()} selektieren und dann
alle fehlenden Werte Ã¼ber \texttt{na.omit()} entfernen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_mat }\OtherTok{\textless{}{-}}\NormalTok{ corr\_gummi\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select\_if}\NormalTok{(is.numeric) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  na.omit }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{cor}\NormalTok{()}

\NormalTok{cor\_mat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            count_bears count_color    age height semester
count_bears       1.000       0.262  0.013 -0.024   -0.114
count_color       0.262       1.000 -0.078 -0.098   -0.097
age               0.013      -0.078  1.000 -0.058   -0.082
height           -0.024      -0.098 -0.058  1.000    0.157
semester         -0.114      -0.097 -0.082  0.157    1.000
\end{verbatim}

Wir sehen das in der Korrelationsmatrix jeweils Ã¼ber und unterhalb der
Diagonalen die gespiegelten Zahlen stehen. Wir kÃ¶nnen jetzt die Matrix
\texttt{cor\_mat} in die Funktion \texttt{corrplot()} stecken und uns
den Korrelationsplot in Abbildung~\ref{fig-corrplot-01} einmal
anschauen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{corrplot}\NormalTok{(cor\_mat)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-linear-reg-corr_files/figure-pdf/fig-corrplot-01-1.pdf}

}

\caption{\label{fig-corrplot-01}Farbiger paarweiser Korrelationsplot fÃ¼r
die numerischen Variablen aus dem Datensatz zu den GummibÃ¤rchen. Die
Farben spiegeln die Richtung der Korrelation wieder, die GrÃ¶Ãe der
Kreise die StÃ¤rke.}

\end{figure}

Wir sehen in Abbildung~\ref{fig-corrplot-01}, dass wir eine schwache
positive Korrelation zwischen \texttt{count\_color} und
\texttt{count\_bears} haben, angezeigt durch den schwach blauen Kreis.
Der Rest der Korrelation ist nahe Null, tendiert aber eher ins negative.

Nun ist in dem Plot natÃ¼rlich eine der beiden Seiten Ã¼berflÃ¼ssig. Wir
kÃ¶nnen daher die Funktion \texttt{corrplot.mixed()} nutzen um in das
untere Feld die Zahlenwerte der Korrelation darzustellen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{corrplot.mixed}\NormalTok{(cor\_mat)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-linear-reg-corr_files/figure-pdf/fig-corrplot-mixed-01-1.pdf}

}

\caption{\label{fig-corrplot-mixed-01}Farbiger paarweiser
Korrelationsplot fÃ¼r die numerischen Variablen aus dem Datensatz zu den
GummibÃ¤rchen. Die Farben spiegeln die Richtung der Korrelation wieder,
die GrÃ¶Ãe der Kreise die StÃ¤rke. In das untere Feld werden die Werte der
Korrelation angegeben.}

\end{figure}

Es gibt noch eine Vielzahl an weiteren MÃ¶glichkeiten in den Optionen von
der Funktion \texttt{corr.mixed()}. Hier hilft dann die Hilfeseite der
Funktion oder aber die
\href{https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html}{Hilfeseite
zum Paket}.

\part{Statistisches Modellieren}

\emph{Version vom September 14, 2022 um 08:52:50}

{\marginnote{\begin{footnotesize}Beachte auch die komplexeren Beispiel
im Kapitel~\ref{sec-beispiel-auswertung}, wo wir dann alles einmal
anwenden.\end{footnotesize}}}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Modellierung in der Statistik}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
Du findest auf YouTube \href{https://youtu.be/2fXExWzipDI}{Statistik und
Data Science - Teil 15.0 - Modellierung in der Statistik} als Video
Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber
manchmal ist das Sehen und HÃ¶ren dann einfacher.
\end{tcolorbox}

In diesem und den nun folgenden Kapitel wollen wir uns mit den
Grundlagen der \emph{multiplen} linearen Regression beschÃ¤ftigen. Das
heiÃt, wir haben ein Outcome \(y\), was einer Verteilung folgt, sowie
mehrere Einflussvariable \(x_1\) bis \(x_p\). Wir wollen jetzt
herausfinden, welchen Einfluss oder Effekt die \(x_1, ..., x_p\) auf das
\(y\) hat. Sehr simple Gesprochen legen wir eine Gerade durch eine
\emph{mehrdimensionale} Punktewolke.

Wir erinnern und nochmal, das ein \emph{simples} lineares Modell nur ein
\(x_1\) hat:

\[
y \sim x_1
\]

Ein \emph{multiples} lineares Modell hat von \(x_1\) bis \(x_p\)
Einflussvariablen:

\[
y \sim x_1 + x_2 + ... + x_p
\]

Wir brauchen viele der Konzepte aus den vorherigen Kapiteln zur
ModellgÃ¼te sowie Konfidenzintervallen. Vieles fÃ¤llt hier zusammen. Schau
dir ruhig nochmal die vorherigen Kapitel an, wenn dir etwas unklar ist.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-18}{%
\section*{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-18}}
\addcontentsline{toc}{section}{Genutzte R Pakete fÃ¼r das Kapitel}

Neben den R Paketen, die wir in den jeweiligen Kapiteln brauchen, kommen
noch folgende R Pakete immer wieder dran. Deshalb sind die R Pakete hier
schonmal mit den jeweiligen Internetseiten aufgefÃ¼hrt.

\begin{itemize}
\tightlist
\item
  Das Buch \href{https://www.tmwr.org/}{Tidy Modeling with R} gibt
  nochmal einen tieferen Einblick in das Modellieren in R. Wir immer, es
  ist ein Vorschlag aber kein Muss.
\item
  Das \href{https://tidymodels.tidymodels.org/}{R Paket tidymodels}
  nutzen wir als \emph{das} R Paket um mit Modellen umgehen zu kÃ¶nnen.
  Das Paket \texttt{tidymodels} ist wie das Paket \texttt{tidyverse}
  eine Sammlung an anderen R Paketen, die wir brauchen werden.
\item
  Das \href{https://easystats.github.io/parameters/index.html}{R Paket
  parameters} nutzen wir um die Parameter eines Modells aus den Fits der
  Modelle zu extrahieren. Teilweise sind die Standardausgaben der
  Funktionen sehr unÃ¼bersichtich. Hier hilft das R Paket.
\item
  Das \href{https://easystats.github.io/performance/}{R Paket
  performance} hilft uns zu verstehen, ob die Modelle, die wir gefittet
  haben, auch funktioniert haben. In einen mathematischen Algorithmus
  kÃ¶nnen wir alles reinstecken, fast immer kommt eine Zahl wieder raus.
\end{itemize}

\hypertarget{das-regressionskreuz}{%
\section*{Das Regressionskreuz}\label{das-regressionskreuz}}
\addcontentsline{toc}{section}{Das Regressionskreuz}

In diesem Kapitel wollen wir uns mit der Grundlage der multiplen
linearen Regression beschÃ¤ftigen. Das heist wir schauen uns Modelle mit
mehreren \(x\) an. Wir haben also nicht mehr nur eine Einflussvariable
auf der rechten Seite der Gleichung sondern meist mehrere. Je nachdem
wie diese \(x\) beschffen sind, mÃ¼ssen wir die \(x\) auch
interpretieren. Wir unterscheiden in vier Arten von \(x\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Das zu betrachtende \(x\) ist eine Variable mit
  \textbf{kontinuierlichen Zahlen} (siehe
  Kapitel~\ref{sec-interpret-x-cont})
\item
  Das zu betrachtende \(x\) ist eine Variablen mit \textbf{einem Faktor
  mit zwei Leveln} (siehe Kapitel~\ref{sec-interpret-x-cat2}).
\item
  Das zu betrachtende \(x\) ist eine Variablen mit \textbf{einem Faktor
  mit mehr als zwei Leveln} (siehe Kapitel~\ref{sec-interpret-x-cat3}).
\item
  Das zu betrachtende \(x\) ist eine Variable, die einen \textbf{Block
  oder Cluster} beschreibt (siehe Kapitel~\ref{sec-mixed}).
\end{enumerate}

Wir finden die FÃ¤lle 1) bis 3) in der Abbildung~\ref{fig-reg-cross} in
den Spalten wieder.

Neben dem \(x\) mÃ¼ssen wir auch das \(y\) in diesem Kapitel betrachten.
Das \(y\) kann aus verschiedenen Verteilungen kommen. HÃ¤ufig nehmen wir
an, dass das \(y\) normalverteilt ist, das muss das \(y\) aber nicht
sein. Je nachdem wir das \(y\) verteilt ist, rechen wir eine andere
multiple Regression.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Das zu betrachtende \(y\) folgt einer \textbf{Normalverteilung} bzw.
  entstammt einer \textbf{Gaussian} Vertreilungsfamilie. Wir wollen dann
  eine multiple Gaussian Regression rechen.
\item
  Das zu betrachtende \(y\) folgt einer \textbf{Poissonverteilung} bzw.
  entstammt einer Poisson Vertreilungsfamilie. Wir wollen dann eine
  multiple Poisson Regression rechen.
\item
  Das zu betrachtende \(y\) folgt einer \textbf{Ordinalen- oder
  Multinominalenverteilung} bzw. entstammt einer Ordinalen- oder
  Multinominalen Vertreilungsfamilie. Wir wollen dann eine multiple
  ordinale oder multinominale Regression rechen.
\item
  Das zu betrachtende \(y\) folgt einer \textbf{Binomialverteilung} bzw.
  entstammt einer Binomialen Vertreilungsfamilie. Wir wollen dann eine
  multiple logistische Regression rechen.
\end{enumerate}

Wir finden die FÃ¤lle 1) bis 4) in der Abbildung~\ref{fig-reg-cross} in
den Zeilen wieder.

\begin{figure*}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{./images/Regressionskreut_advanced.png}

}

\caption{\label{fig-reg-cross}Das Regressionskreuz als allgemeine
Ãbersicht der MÃ¶glichkeiten einer multiplen linearen Regression.}

\end{figure*}

\hypertarget{sec-mult-reg-basic}{%
\chapter{Multiple lineare Regression}\label{sec-mult-reg-basic}}

\emph{Version vom September 14, 2022 um 08:53:09}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

Ein multiples lineare Modell hat mehrere \(x\). Daher haben wir auf der
linken Seite ein \(y\) und auf der rechten Seite \(p\)-mal ein \(x\).
Wir kÃ¶nnen daher ein multiples lineares Modell daher wie folgt in R
schreiben.

\[
y \sim x_1 + x_2 + ... + x_p 
\]

Oder konkreter kÃ¶nnen wir sagen, dass \texttt{jump\_length} von
\texttt{animal}, \texttt{sex} und \texttt{weight} abhÃ¤ngt und wir diesen
Zusammenhang modellieren wollen.

\[
jump\_length \sim animal + sex + weight 
\]

Das hilft uns jetzt nur bedingt, denn wir wollen ja aus einer
Modellierung in R die Koeffizienten der Regression wiederbekommen. DafÃ¼r
mÃ¼ssen wir uns nochmal klar werden, was die Koeffizienten einer
Regression sind. Das sind zum einen der y-Achsenabschnitt \(\beta_0\)
und die Steigung der einzelnen Variablen mit \(\beta_1\) bis
\(\beta_p\). Wir erhalten auch bei einem multiplen Regressionsmodell nur
einen Vektor mit den Residuen wieder.

\[
y \sim \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon
\]

Dennoch sind die Residuen \(\epsilon\) normalverteilt. Wir haben im
Mittel einen Abstand der \(\epsilon\)'s zur geraden von 0 und eine
Streuung von \(s^2_{\epsilon}\).

\[
\epsilon \sim \mathcal{N}(0, s^2_{\epsilon})
\]

Wir zeichen im Prinzip eine Gerade durch den \(p\)-dimensioneln Raum.

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-19}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-19}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               see, performance, car)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{die-modelmatrix-in-r}{%
\section{Die Modelmatrix in R}\label{die-modelmatrix-in-r}}

Als erstes wollen wir verstehen, wie ein Modell \emph{in} R aussieht.
Dann kÃ¶nnen wir auch besser verstehen, wie die eigentlichen
Koeffizienten aus dem Modell entstehen. Wir bauen uns dafÃ¼r ein sehr
simplen Datensatz.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snake\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{svl =} \FunctionTok{c}\NormalTok{(}\DecValTok{40}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{39}\NormalTok{, }\DecValTok{51}\NormalTok{, }\DecValTok{52}\NormalTok{, }\DecValTok{57}\NormalTok{, }\DecValTok{58}\NormalTok{, }\DecValTok{49}\NormalTok{),}
  \AttributeTok{mass =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{10}\NormalTok{),}
  \AttributeTok{region =} \FunctionTok{as\_factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"west"}\NormalTok{,}\StringTok{"west"}\NormalTok{, }\StringTok{"west"}\NormalTok{, }\StringTok{"nord"}\NormalTok{,}\StringTok{"nord"}\NormalTok{,}\StringTok{"nord"}\NormalTok{,}\StringTok{"nord"}\NormalTok{,}\StringTok{"nord"}\NormalTok{)),}
  \AttributeTok{color =} \FunctionTok{as\_factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"schwarz"}\NormalTok{, }\StringTok{"schwarz"}\NormalTok{, }\StringTok{"rot"}\NormalTok{, }\StringTok{"rot"}\NormalTok{, }\StringTok{"rot"}\NormalTok{, }\StringTok{"blau"}\NormalTok{, }\StringTok{"blau"}\NormalTok{, }\StringTok{"blau"}\NormalTok{))}
\NormalTok{) }
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-snakes} ist der Datensatz \texttt{snake\_tbl}
nochmal dargestellt. Wir haben die SchlangenlÃ¤nge \texttt{svl} als
Outcome \(y\) sowie das Gewicht der Schlangen \texttt{mass}, die
Sammelregion \texttt{region} und die Farbe der Schlangen \texttt{color}.
Dabei ist \texttt{mass} eine kontinuierliche Variable, \texttt{region}
eine kategorielle Variable als Faktor mit zwei Leveln und \texttt{color}
eine kategorielle Variable als Faktor mit drei Leveln.

\hypertarget{tbl-snakes}{}
\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tbl-snakes}Datensatz zu Schlangen ist entlehnt und
modifiiert nach KÃ©ry (2010, p.~77)}\tabularnewline
\toprule()
svl & mass & region & color \\
\midrule()
\endfirsthead
\toprule()
svl & mass & region & color \\
\midrule()
\endhead
40 & 6 & west & schwarz \\
45 & 8 & west & schwarz \\
39 & 5 & west & rot \\
51 & 7 & nord & rot \\
52 & 9 & nord & rot \\
57 & 11 & nord & blau \\
58 & 12 & nord & blau \\
49 & 10 & nord & blau \\
\bottomrule()
\end{longtable}

Wir wollen uns nun einmal anschauen, wie ein Modell in R sich
zusammensetzt.

\hypertarget{kontinuierliches-x}{%
\subsection{\texorpdfstring{Kontinuierliches
\(x\)}{Kontinuierliches x}}\label{kontinuierliches-x}}

Im ersten Schritt wollen wir uns einmal das Modell mit einem
kontenuierlichen \(x\) anschauen. Wir bauen uns ein Modell mit der
Variable \texttt{mass}. Die Funktion \texttt{model.matrix()} gibt uns
die Modelmatrix wieder.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mass, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ as\_tibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 2
  `(Intercept)`  mass
          <dbl> <dbl>
1             1     6
2             1     8
3             1     5
4             1     7
5             1     9
6             1    11
7             1    12
8             1    10
\end{verbatim}

In der ersten Spalte ist der Intercept angegeben, danach folgt dann die
Spalte \texttt{mass} als kontinuierliche Variable.

Wir kÃ¶nnen die Modellmatrix auch mathematisch schreiben und die \(y\)
Spalte fÃ¼r das Outcome \texttt{svl} ergÃ¤nzen. Eben so ergÃ¤nzen wir die
\(\beta\)-Werte als mÃ¶gliche Koeefizienten aus der linearen Regression
sowie die Residuen als Abweichung von der gefitteten Gerade.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 6 \\
  1 & 8 \\
  1 & 5 \\
  1 & 7 \\
  1 & 9 \\
  1 & 11\\
  1 & 12\\
  1 & 10\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} 
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
\]

Jetzt brauche wir die Koeffizienten aus dem linearen Modell, welches wir
wie folgt fitten. Wir nutzen dann die Funktion \texttt{coef()} um uns
die Koeffizienten wiedergeben zu lassen. Die Funktion
\texttt{residuals()} gibt uns die Residuen der Geraden wieder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mass, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ coef }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)        mass 
      26.71        2.61 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{residuals}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    1     2     3     4     5     6     7     8 
-2.36 -2.57 -0.75  6.04  1.82  1.61  0.00 -3.79 
\end{verbatim}

Wir kÃ¶nnen jetzt die Koeffizienten ergÃ¤nzen mit \(\beta_0 = 26.71\) fÃ¼r
den Intercept. Weiter ergÃ¤nzen wir die Koeffizienten fÃ¼r \texttt{mass}
mit \(\beta_{mass}=2.61\). Ebenfalls setzen wir Werte fÃ¼r die Residuen
fÃ¼r jede der Beobachtungen in die Gleichung ein.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  26.71 & \phantom{0}6 \cdot 2.61\\
  26.71 & \phantom{0}8 \cdot 2.61\\
  26.71 & \phantom{0}5 \cdot 2.61\\
  26.71 & \phantom{0}7 \cdot 2.61\\
  26.71 & \phantom{0}9 \cdot 2.61\\
  26.71 & 11\cdot 2.61\\
  26.71 & 12\cdot 2.61\\
  26.71 & 10\cdot 2.61\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} 
 \end{pmatrix} +
  \begin{pmatrix}
  -2.36\\
  -2.57\\
  -0.75 \\
  +6.04\\
  +1.82\\
  +1.61\\
  \phantom{+}0.00\\
  -3.79\\
 \end{pmatrix}
\]

Wir kÃ¶nnen jetzt diese gewaltige Sammlung an Matrixen einmal auflÃ¶sen.
Steht denn nun wirklich rechts das Gleiche wie links von der Gleichung?
Wir bauen uns die Zahlen von der rechten Seite der Gleichung einmal in R
nach und schauen auf das Ergebnis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FloatTok{26.71} \SpecialCharTok{+}  \DecValTok{6}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{{-}} \FloatTok{2.36}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+}  \DecValTok{8}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{{-}} \FloatTok{2.57}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+}  \DecValTok{5}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{{-}} \FloatTok{0.75}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+}  \DecValTok{7}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{+} \FloatTok{6.04}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+}  \DecValTok{9}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{+} \FloatTok{1.82}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+} \DecValTok{11}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{+} \FloatTok{1.61}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+} \DecValTok{12}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{+} \FloatTok{0.00}\NormalTok{,}
  \FloatTok{26.71} \SpecialCharTok{+} \DecValTok{10}\SpecialCharTok{*}\FloatTok{2.61} \SpecialCharTok{{-}} \FloatTok{3.79}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40 45 39 51 52 57 58 49
\end{verbatim}

Die Zahlen, die wir rauskriegen, sind die gleichen Werte die unser
Outcome \(y\) hat.

\hypertarget{kategorielles-x-mit-2-leveln}{%
\subsection{\texorpdfstring{Kategorielles \(x\) mit 2
Leveln}{Kategorielles x mit 2 Leveln}}\label{kategorielles-x-mit-2-leveln}}

Im diesem Schritt wollen wir uns einmal das Modell mit einem
kategoriellen \(x\) mit 2 Leveln anschauen. Wir bauen uns ein Modell mit
der Variable
\texttt{region\textasciigrave{}\textasciigrave{}.\ Die\ Funktion}model.matrix()`
gibt uns die Modelmatrix wieder.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ region, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ as\_tibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 2
  `(Intercept)` regionnord
          <dbl>      <dbl>
1             1          0
2             1          0
3             1          0
4             1          1
5             1          1
6             1          1
7             1          1
8             1          1
\end{verbatim}

In der ersten Spalte ist der Intercept angegeben, danach folgt dann die
Spalte \texttt{regionnord}. In dieser Spalte steht die Dummykodierung
fÃ¼r die Variable \texttt{region}. Die ersten drei Schlangen kommen nicht
aus der Region \texttt{nord} und werden deshalb mit einen Wert von 0
versehen. Die nÃ¤chsten vier Schlangen kommen aus der Region
\texttt{nord} und erhalten daher eine 1 in der Spalte.

Wir kÃ¶nnen die Modellmatrix auch mathematisch schreiben und die \(y\)
Spalte fÃ¼r das Outcome \texttt{svl} ergÃ¤nzen. Eben so ergÃ¤nzen wir die
\(\beta\)-Werte als mÃ¶gliche Koeefizienten aus der linearen Regression
sowie die Residuen als Abweichung von der gefitteten Gerade.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 &  0  \\
  1 &  0 \\
  1 &  0\\
  1 &  1\\
  1 &  1 \\
  1 &  1 \\
  1 &  1 \\
  1 &  1 \\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta^{region}_{nord} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
\]

Jetzt brauche wir die Koeffizienten aus dem linearen Modell, welches wir
wie folgt fitten. Wir nutzen dann die Funktion \texttt{coef()} um uns
die Koeffizienten wiedergeben zu lassen. Die Funktion
\texttt{residuals()} gibt uns die Residuen der Geraden wieder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ region, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }
\NormalTok{fit\_2 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ coef }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)  regionnord 
      41.33       12.07 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{residuals}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    1     2     3     4     5     6     7     8 
-1.33  3.67 -2.33 -2.40 -1.40  3.60  4.60 -4.40 
\end{verbatim}

Wir kÃ¶nnen jetzt die Koeffizienten ergÃ¤nzen mit \(\beta_0 = 41.33\) fÃ¼r
den Intercept. Weiter ergÃ¤nzen wir die Koeffizienten fÃ¼r die Region und
das Level \texttt{nord} mit \(\beta^{region}_{nord} = 12.07\). Ebenfalls
setzen wir Werte fÃ¼r die Residuen fÃ¼r jede der Beobachtungen in die
Gleichung ein.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  41.33 & 0 \cdot 12.07  \\
  41.33 & 0 \cdot 12.07  \\
  41.33 & 0 \cdot 12.07  \\
  41.33 & 1 \cdot 12.07  \\
  41.33 & 1 \cdot 12.07  \\
  41.33 & 1 \cdot 12.07  \\
  41.33 & 1 \cdot 12.07  \\
  41.33 & 1 \cdot 12.07  \\
 \end{pmatrix} +
  \begin{pmatrix}
  -1.33\\
  +3.67 \\
  -2.33 \\
  -2.40 \\
  -1.40 \\
  +3.60 \\
  +4.60 \\
  -4.40 \\
 \end{pmatrix}
\]

Wir kÃ¶nnen jetzt diese gewaltige Sammlung an Matrixen einmal auflÃ¶sen.
Steht denn nun wirklich rechts das Gleiche wie links von der Gleichung?
Wir bauen uns die Zahlen von der rechten Seite der Gleichung einmal in R
nach und schauen auf das Ergebnis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FloatTok{41.33} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{{-}} \FloatTok{1.33}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{+} \FloatTok{3.67}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{{-}} \FloatTok{2.33}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{{-}} \FloatTok{2.40}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{{-}} \FloatTok{1.40}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{+} \FloatTok{3.60}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{+} \FloatTok{4.60}\NormalTok{,}
  \FloatTok{41.33} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{12.07} \SpecialCharTok{{-}} \FloatTok{4.40}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40 45 39 51 52 57 58 49
\end{verbatim}

Die Zahlen, die wir rauskriegen, sind die gleichen Werte die unser
Outcome \(y\) hat.

\hypertarget{kategorielles-x-mit-2-leveln-1}{%
\subsection{\texorpdfstring{Kategorielles \(x\) mit \textgreater2
Leveln}{Kategorielles x mit \textgreater2 Leveln}}\label{kategorielles-x-mit-2-leveln-1}}

Im diesem Schritt wollen wir uns einmal das Modell mit einem
kategoriellen \(x\) mit \textgreater2 Leveln anschauen. Wir bauen uns
ein Modell mit der Variable \texttt{color}. Die Funktion
\texttt{model.matrix()} gibt uns die Modelmatrix wieder.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ color, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ as\_tibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 3
  `(Intercept)` colorrot colorblau
          <dbl>    <dbl>     <dbl>
1             1        0         0
2             1        0         0
3             1        1         0
4             1        1         0
5             1        1         0
6             1        0         1
7             1        0         1
8             1        0         1
\end{verbatim}

In der ersten Spalte ist der Intercept angegeben, danach folgt dann die
Spalten fÃ¼r \texttt{color}. Die Spalten \texttt{colorrot} und
\texttt{colorblau} geben jeweils an, ob die Schlange das Level
\texttt{rot} hat oder \texttt{blau} oder keins von beiden. Wenn die
Schlange weder rot noch blau ist, dann sind beide Spalten mit einer 0
versehen. Dann ist die Schlange schwarz.

Wir kÃ¶nnen die Modellmatrix auch mathematisch schreiben und die \(y\)
Spalte fÃ¼r das Outcome \texttt{svl} ergÃ¤nzen. Eben so ergÃ¤nzen wir die
\(\beta\)-Werte als mÃ¶gliche Koeefizienten aus der linearen Regression
sowie die Residuen als Abweichung von der gefitteten Gerade.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 0 & 0 \\
  1 & 0 & 0\\
  1 & 1 & 0\\
  1 & 1 & 0\\
  1 & 1 & 0\\
  1 & 0 & 1\\
  1 & 0 & 1\\
  1 & 0 & 1\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta^{color}_{rot} \\
  \beta^{color}_{blau} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
\]

Jetzt brauche wir die Koeffizienten aus dem linearen Modell, welches wir
wie folgt fitten. Wir nutzen dann die Funktion \texttt{coef()} um uns
die Koeffizienten wiedergeben zu lassen. Die Funktion
\texttt{residuals()} gibt uns die Residuen der Geraden wieder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ color, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }
\NormalTok{fit\_3 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ coef }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)    colorrot   colorblau 
      42.50        4.83       12.17 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_3 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{residuals}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    1     2     3     4     5     6     7     8 
-2.50  2.50 -8.33  3.67  4.67  2.33  3.33 -5.67 
\end{verbatim}

Wir kÃ¶nnen jetzt die Koeffizienten ergÃ¤nzen mit \(\beta_0 = 25\) fÃ¼r den
Intercept. Weiter ergÃ¤nzen wir die Koeffizienten fÃ¼r die Farbe und das
Level \texttt{rot} mit \(\beta^{color}_{rot} = 4.83\) und fÃ¼r die Farbe
und das Level \texttt{blau} mit \(\beta^{color}_{blau} = 12.17\).
Ebenfalls setzen wir Werte fÃ¼r die Residuen fÃ¼r jede der Beobachtungen
in die Gleichung ein.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  42.50 & 0 \cdot 4.83& 0 \cdot 12.17 \\
  42.50 & 0 \cdot 4.83& 0 \cdot 12.17\\
  42.50 & 1 \cdot 4.83& 0 \cdot 12.17\\
  42.50 & 1 \cdot 4.83& 0 \cdot 12.17\\
  42.50 & 1 \cdot 4.83& 0 \cdot 12.17\\
  42.50 & 0 \cdot 4.83& 1 \cdot 12.17\\
  42.50 & 0 \cdot 4.83& 1 \cdot 12.17\\
  42.50 & 0 \cdot 4.83& 1 \cdot 12.17\\
 \end{pmatrix} +
  \begin{pmatrix}
  -2.50 \\
  +2.50 \\
  -8.33 \\
  +3.67 \\
  +4.67 \\
  +2.33 \\
  +3.33 \\
  -5.67 \\
 \end{pmatrix}
\]

Wir kÃ¶nnen jetzt diese gewaltige Sammlung an Matrixen einmal auflÃ¶sen.
Steht denn nun wirklich rechts das Gleiche wie links von der Gleichung?
Wir bauen uns die Zahlen von der rechten Seite der Gleichung einmal in R
nach und schauen auf das Ergebnis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FloatTok{42.50} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{{-}} \FloatTok{2.50}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{+} \FloatTok{2.50}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{{-}} \FloatTok{8.33}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{+} \FloatTok{3.67}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{+} \FloatTok{4.67}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{+} \FloatTok{2.33}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{+} \FloatTok{3.33}\NormalTok{,}
  \FloatTok{42.50} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{4.83} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{12.17} \SpecialCharTok{{-}} \FloatTok{5.67}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40 45 39 51 52 33 34 25
\end{verbatim}

Die Zahlen, die wir rauskriegen, sind die gleichen Werte die unser
Outcome \(y\) hat.

\hypertarget{das-volle-modell}{%
\subsection{Das volle Modell}\label{das-volle-modell}}

Im letzten Schritt wollen wir uns einmal das volle Modell anschauen. Wir
bauen uns ein Modell mit allen Variablen in dem Datensatz
\texttt{snake\_tbl}. Die Funktion \texttt{model.matrix()} gibt uns die
Modelmatrix wieder.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mass }\SpecialCharTok{+}\NormalTok{ region }\SpecialCharTok{+}\NormalTok{ color, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_tibble}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 5
  `(Intercept)`  mass regionnord colorrot colorblau
          <dbl> <dbl>      <dbl>    <dbl>     <dbl>
1             1     6          0        0         0
2             1     8          0        0         0
3             1     5          0        1         0
4             1     7          1        1         0
5             1     9          1        1         0
6             1    11          1        0         1
7             1    12          1        0         1
8             1    10          1        0         1
\end{verbatim}

In der ersten Spalte ist der Intercept angegeben, danach folgt dann die
Spalte \texttt{mass} als kontenuierliche Variable. In der Spalte
\texttt{regionnord} steht die Dummykodierung fÃ¼r die Variable
\texttt{region}. Die ersten drei Schlangen kommen nicht aus der Region
\texttt{nord} und werden deshalb mit einen Wert von 0 versehen. Die
nÃ¤chsten vier Schlangen kommen aus der Region \texttt{nord} und erhalten
daher eine 1 in der Spalte. Die nÃ¤chsten beiden Spalten sind etwas
komplizierter. Die Spalten \texttt{colorrot} und \texttt{colorblau}
geben jeweils an, ob die Schlange das Level \texttt{rot} hat oder
\texttt{blau} oder keins von beiden. Wenn die Schlange weder rot noch
blau ist, dann sind beide Spalten mit einer 0 versehen. Dann ist die
Schlange schwarz.

Wir kÃ¶nnen die Modellmatrix auch mathematisch schreiben und die \(y\)
Spalte fÃ¼r das Outcome \texttt{svl} ergÃ¤nzen. Eben so ergÃ¤nzen wir die
\(\beta\)-Werte als mÃ¶gliche Koeefizienten aus der linearen Regression
sowie die Residuen als Abweichung von der gefitteten Gerade.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  1 & 6 & 0 & 0 & 0 \\
  1 & 8 & 0 & 0 & 0\\
  1 & 5 & 0 & 1 & 0\\
  1 & 7 & 1 & 1 & 0\\
  1 & 9 & 1 & 1 & 0\\
  1 & 11& 1 & 0 & 1\\
  1 & 12& 1 & 0 & 1\\
  1 & 10& 1 & 0 & 1\\
 \end{pmatrix}
 \times
  \begin{pmatrix}
  \beta_0 \\
  \beta_{mass} \\
  \beta^{region}_{nord} \\
  \beta^{color}_{rot} \\
  \beta^{color}_{blau} \\
 \end{pmatrix} +
  \begin{pmatrix}
  \epsilon_1 \\
  \epsilon_2 \\
  \epsilon_3 \\
  \epsilon_4 \\
  \epsilon_5 \\
  \epsilon_6 \\
  \epsilon_7 \\
  \epsilon_8 \\
 \end{pmatrix}
\]

Jetzt brauche wir die Koeffizienten aus dem linearen Modell, welches wir
wie folgt fitten. Wir nutzen dann die Funktion \texttt{coef()} um uns
die Koeffizienten wiedergeben zu lassen. Die Funktion
\texttt{residuals()} gibt uns die Residuen der Geraden wieder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(svl }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mass }\SpecialCharTok{+}\NormalTok{ region }\SpecialCharTok{+}\NormalTok{ color, }\AttributeTok{data =}\NormalTok{ snake\_tbl) }
\NormalTok{fit\_4 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ coef }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)        mass  regionnord    colorrot   colorblau 
      25.00        2.50        5.00        1.50       -2.83 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_4 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{residuals}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    1     2     3     4     5     6     7     8 
 0.00  0.00  0.00  2.00 -2.00  2.33  0.83 -3.17 
\end{verbatim}

Wir kÃ¶nnen jetzt die Koeffizienten ergÃ¤nzen mit \(\beta_0 = 25\) fÃ¼r den
Intercept. Weiter ergÃ¤nzen wir die Koeffizienten fÃ¼r \texttt{mass} mit
\(\beta_{mass}=2.5\), fÃ¼r Region und das Level \texttt{nord} mit
\(\beta^{region}_{nord} = 5\), fÃ¼r die Farbe und das Level \texttt{rot}
mit \(\beta^{color}_{rot} = 1.5\) und fÃ¼r die Farbe und das Level
\texttt{blau} mit \(\beta^{color}_{blau} = -2.83\). Ebenfalls setzen wir
Werte fÃ¼r die Residuen fÃ¼r jede der Beobachtungen in die Gleichung ein.

\[
 \begin{pmatrix}
  40 \\
  45 \\
  39 \\
  50 \\
  52 \\
  57 \\
  58 \\
  59 \\
 \end{pmatrix}
 =
  \begin{pmatrix}
  25 & \phantom{0}6 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83 \\
  25 & \phantom{0}8 \cdot 2.5 & 0 \cdot 5 & 0 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}5 \cdot 2.5 & 0 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}7 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & \phantom{0}9 \cdot 2.5 & 1 \cdot 5 & 1 \cdot 1.5& 0 \cdot -2.83\\
  25 & 11\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 12\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
  25 & 10\cdot 2.5 & 1 \cdot 5 & 0 \cdot 1.5& 1 \cdot -2.83\\
 \end{pmatrix} +
  \begin{pmatrix}
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  \phantom{+}0.00 \\
  +2.00 \\
  -2.00 \\
  +2.33 \\
  +0.83 \\
  -3.17 \\
 \end{pmatrix}
\]

Wir kÃ¶nnen jetzt diese gewaltige Sammlung an Matrixen einmal auflÃ¶sen.
Steht denn nun wirklich rechts das Gleiche wie links von der Gleichung?
Wir bauen uns die Zahlen von der rechten Seite der Gleichung einmal in R
nach und schauen auf das Ergebnis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\DecValTok{25} \SpecialCharTok{+}  \DecValTok{6}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{0.00}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+}  \DecValTok{8}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{0.00}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+}  \DecValTok{5}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{0.00}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+}  \DecValTok{7}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{2.00}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+}  \DecValTok{9}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{{-}} \FloatTok{2.00}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+} \DecValTok{11}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{2.33}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+} \DecValTok{12}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{+} \FloatTok{0.83}\NormalTok{,}
  \DecValTok{25} \SpecialCharTok{+} \DecValTok{10}\SpecialCharTok{*}\FloatTok{2.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{0}\SpecialCharTok{*}\FloatTok{1.5} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*{-}}\FloatTok{2.83} \SpecialCharTok{{-}} \FloatTok{3.17}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40 45 39 51 52 57 58 49
\end{verbatim}

Die Zahlen, die wir rauskriegen, sind die gleichen Werte die unser
Outcome \(y\) hat. Was haben wir gelernt?

\begin{itemize}
\tightlist
\item
  In einem Modell gibt es immer ein Faktorlevel weniger als ein Faktor
  Level hat. Die Information des \emph{alphanumerisch} ersten Levels
  steckt dann mit in dem Intercept.
\item
  In einem Modell geht eine kontinuierliche Variable als eine Spalte mit
  ein.
\item
  In einem Modell gibt es immer nur eine Spalte fÃ¼r die Residuen und
  damit nur eine Residue fÃ¼r jede Beobachtung, egal wie viele Variablen
  ein Modell hat.
\end{itemize}

\hypertarget{sec-interpret-x}{%
\section{\texorpdfstring{Interpretation von
\(x\)}{Interpretation von x}}\label{sec-interpret-x}}

\hypertarget{sec-interpret-x-cont}{%
\subsection{\texorpdfstring{Kontinuierliches
\(x\)}{Kontinuierliches x}}\label{sec-interpret-x-cont}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20137937}\NormalTok{)}
\NormalTok{cont\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{to =} \DecValTok{7}\NormalTok{, }\AttributeTok{by =} \DecValTok{1}\NormalTok{),}
                   \AttributeTok{y =} \DecValTok{5} \SpecialCharTok{+} \FloatTok{1.5} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\FunctionTok{length}\NormalTok{(x), }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{cont\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 7 x 2
      x     y
  <dbl> <dbl>
1     1  5.93
2     2  8.06
3     3  8.95
4     4 12.1 
5     5 11.9 
6     6 14.9 
7     7 16.3 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cont\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  (Intercept) x
1           1 1
2           1 2
3           1 3
4           1 4
5           1 5
6           1 6
7           1 7
attr(,"assign")
[1] 0 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cont\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(term, estimate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 2
  term        estimate
  <chr>          <dbl>
1 (Intercept)     4.32
2 x               1.71
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(cont\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{fullrange =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{expand =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{), }\AttributeTok{breaks =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{8}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{expand =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{17}\NormalTok{), }\AttributeTok{breaks =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\AttributeTok{x =} \DecValTok{4}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{label =} \StringTok{"y ==  4.32 + 1.71 \%.\% x"}\NormalTok{, }\AttributeTok{parse =} \ConstantTok{TRUE}\NormalTok{,}
           \AttributeTok{hjust =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-basic-00-1.pdf}

}

\caption{\label{fig-stat-modeling-basic-00}foo}

\end{figure}

\hypertarget{sec-interpret-x-cat2}{%
\subsection{\texorpdfstring{Kategorielles \(x\) mit 2
Leveln}{Kategorielles x mit 2 Leveln}}\label{sec-interpret-x-cat2}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20339537}\NormalTok{)}
\NormalTok{cat\_two\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{7}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{),}
                      \AttributeTok{B =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{7}\NormalTok{, }\AttributeTok{mean =} \DecValTok{15}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =}\NormalTok{ x, }\AttributeTok{value =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as\_factor}\NormalTok{(x))}
\NormalTok{cat\_two\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 14 x 2
   x         y
   <fct> <dbl>
 1 A     10.0 
 2 A     10.8 
 3 A     10.7 
 4 A     11.0 
 5 A      9.25
 6 A      8.98
 7 A      9.71
 8 B     15.1 
 9 B     16.0 
10 B     14.5 
11 B     15.1 
12 B     14.2 
13 B     16.8 
14 B     15.6 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cat\_two\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   (Intercept) xB
1            1  0
2            1  0
3            1  0
4            1  0
5            1  0
6            1  0
7            1  0
8            1  1
9            1  1
10           1  1
11           1  1
12           1  1
13           1  1
14           1  1
attr(,"assign")
[1] 0 1
attr(,"contrasts")
attr(,"contrasts")$x
[1] "contr.treatment"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cat\_two\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(term, estimate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 2
  term        estimate
  <chr>          <dbl>
1 (Intercept)    10.1 
2 xB              5.27
\end{verbatim}

\hypertarget{tbl-cat-2}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-cat-2}Datensatz mit mehreren Outcomes zu FlÃ¶hen auf
verschiedenen Tierarten.}\tabularnewline
\toprule()
Factor x & Mean of level & Difference to level A \\
\midrule()
\endfirsthead
\toprule()
Factor x & Mean of level & Difference to level A \\
\midrule()
\endhead
A & 10.07 & 0.00 \\
B & 15.33 & 5.27 \\
\bottomrule()
\end{longtable}

\begin{figure}

{\centering \includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-basic-01-1.pdf}

}

\caption{\label{fig-stat-modeling-basic-01}foo}

\end{figure}

\hypertarget{sec-interpret-x-cat3}{%
\subsection{\texorpdfstring{Kategorielles \(x\) mit \textgreater2
Leveln}{Kategorielles x mit \textgreater2 Leveln}}\label{sec-interpret-x-cat3}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20339537}\NormalTok{)}
\NormalTok{cat\_three\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{7}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{),}
                        \AttributeTok{B =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{7}\NormalTok{, }\AttributeTok{mean =} \DecValTok{15}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{),}
                        \AttributeTok{C =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{7}\NormalTok{, }\AttributeTok{mean =} \DecValTok{3}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =}\NormalTok{ x, }\AttributeTok{value =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as\_factor}\NormalTok{(x))}
\NormalTok{cat\_three\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 21 x 2
   x         y
   <fct> <dbl>
 1 A     10.0 
 2 A     10.8 
 3 A     10.7 
 4 A     11.0 
 5 A      9.25
 6 A      8.98
 7 A      9.71
 8 B     15.1 
 9 B     16.0 
10 B     14.5 
# ... with 11 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model.matrix}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cat\_three\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   (Intercept) xB xC
1            1  0  0
2            1  0  0
3            1  0  0
4            1  0  0
5            1  0  0
6            1  0  0
7            1  0  0
8            1  1  0
9            1  1  0
10           1  1  0
11           1  1  0
12           1  1  0
13           1  1  0
14           1  1  0
15           1  0  1
16           1  0  1
17           1  0  1
18           1  0  1
19           1  0  1
20           1  0  1
21           1  0  1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$x
[1] "contr.treatment"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ cat\_three\_tbl) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(term, estimate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 2
  term        estimate
  <chr>          <dbl>
1 (Intercept)    10.1 
2 xB              5.27
3 xC             -7.41
\end{verbatim}

\hypertarget{tbl-cat-3}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-cat-3}Datensatz mit mehreren Outcomes zu FlÃ¶hen auf
verschiedenen Tierarten.}\tabularnewline
\toprule()
Factor x & Mean of level & Difference to level A \\
\midrule()
\endfirsthead
\toprule()
Factor x & Mean of level & Difference to level A \\
\midrule()
\endhead
A & 10.07 & 0.00 \\
B & 15.33 & 5.27 \\
C & 2.66 & -7.41 \\
\bottomrule()
\end{longtable}

\begin{figure}

{\centering \includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-basic-02-1.pdf}

}

\caption{\label{fig-stat-modeling-basic-02}foo}

\end{figure}

\hypertarget{adjustierung-fuxfcr-confounder}{%
\section{Adjustierung fÃ¼r
Confounder}\label{adjustierung-fuxfcr-confounder}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{animal =} \FunctionTok{as\_factor}\NormalTok{(animal),}
         \AttributeTok{sex =} \FunctionTok{as\_factor}\NormalTok{(sex),}
         \AttributeTok{log\_hatch\_time =} \FunctionTok{round}\NormalTok{(}\FunctionTok{log}\NormalTok{(hatch\_time), }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-model-1} ist der Datensatz \texttt{model\_tbl}
nochmal dargestellt.

\hypertarget{tbl-model-1}{}
\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1039}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1039}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1039}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1688}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1558}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1558}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.2078}}@{}}
\caption{\label{tbl-model-1}Datensatz mit mehreren Outcomes zu FlÃ¶hen
auf verschiedenen Tierarten.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\centering
animal
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
sex
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
weight
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
flea\_count
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
hatch\_time
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
log\_hatch\_time
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\centering
animal
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
sex
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
weight
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
jump\_length
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
flea\_count
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
hatch\_time
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
log\_hatch\_time
\end{minipage} \\
\midrule()
\endhead
cat & male & 6.02 & 15.79 & 5 & 483.6 & 6.18 \\
cat & male & 5.99 & 18.33 & 1 & 82.56 & 4.41 \\
cat & male & 8.05 & 17.58 & 1 & 296.73 & 5.69 \\
cat & male & 6.71 & 14.09 & 3 & 140.9 & 4.95 \\
cat & male & 6.19 & 18.22 & 1 & 162.2 & 5.09 \\
cat & male & 8.18 & 13.49 & 1 & 167.47 & 5.12 \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} &
\ldots{} \\
fox & female & 8.04 & 27.81 & 4 & 424.46 & 6.05 \\
fox & female & 9.03 & 24.02 & 1 & 349.48 & 5.86 \\
fox & female & 7.42 & 24.53 & 3 & 151.43 & 5.02 \\
fox & female & 9.26 & 24.35 & 1 & 182.68 & 5.21 \\
fox & female & 8.85 & 24.36 & 3 & 104.89 & 4.65 \\
fox & female & 7.89 & 22.13 & 2 & 62.99 & 4.14 \\
\bottomrule()
\end{longtable}

Abbildung~\ref{fig-stat-modeling-mult-01-1}

Abbildung~\ref{fig-stat-modeling-mult-01-2}

Abbildung~\ref{fig-stat-modeling-mult-01-3}

\begin{figure*}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-mult-01-1.pdf}

}

}

\subcaption{\label{fig-stat-modeling-mult-01-1}jump\_length
\textasciitilde{} weight}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-mult-01-2.pdf}

}

}

\subcaption{\label{fig-stat-modeling-mult-01-2}jump\_length
\textasciitilde{} weight + animal}
\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-modeling-basic_files/figure-pdf/fig-stat-modeling-mult-01-3.pdf}

}

}

\subcaption{\label{fig-stat-modeling-mult-01-3}jump\_length
\textasciitilde{} weight + animal + sex}
\end{minipage}%

\caption{\label{fig-stat-modeling-mult-01}Darstellung des
\emph{counfounder} Effekts anhand des Zusammenhangs der Sprungweite in
{[}cm{]} und dem Gewicht von FlÃ¶hen {[}mg{]}.}

\end{figure*}

\hypertarget{variance-inflation-factor-vif}{%
\section{Variance inflation factor
(VIF)}\label{variance-inflation-factor-vif}}

VIF kann nicht fÃ¼r kategoriale Daten verwendet werden. Statistisch
gesehen wÃ¼rde es keinen Sinn machen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ disp }\SpecialCharTok{+}\NormalTok{ hp }\SpecialCharTok{+}\NormalTok{ wt }\SpecialCharTok{+}\NormalTok{ drat, }\AttributeTok{data =}\NormalTok{ mtcars)}

\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ model\_tbl)}

\FunctionTok{vif}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      sex    weight 
2.1161355 2.1161355 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{check\_model}\NormalTok{(model, }\AttributeTok{check =} \StringTok{"vif"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-basic_files/figure-pdf/unnamed-chunk-34-1.pdf}

}

\end{figure}

\hypertarget{sec-model-basic-compare}{%
\section{Vergleich von Modellen}\label{sec-model-basic-compare}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\NormalTok{fit\_3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\NormalTok{fit\_4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ sex}\SpecialCharTok{:}\NormalTok{weight }\SpecialCharTok{+}\NormalTok{ animal}\SpecialCharTok{:}\NormalTok{weight, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\NormalTok{fit\_5 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(jump\_length) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\end{Highlighting}
\end{Shaded}

Akaike information criterion (AIC)

Bayesian information criterion (BIC)

\[
\Delta_i = AIC_i - AIC_{min}
\]

\begin{itemize}
\tightlist
\item
  wenn \(\Delta_i < 2\), dann gibt es eine deutliche UnterstÃ¼tzung fÃ¼r
  das \(i\)-te Modell;;
\item
  wenn \(2 < \Delta_i < 4\), dann gibt es eine starke UnterstÃ¼tzung fÃ¼r
  das \(i\)-te Modell;
\item
  wenn \(4 < \Delta_i < 7\), dann gibt es deutlich weniger UnterstÃ¼tzung
  fÃ¼r das \(i\)-te Modell;
\item
  Modelle mit \(\Delta_i > 10\) haben im Wesentlichen keine
  UnterstÃ¼tzung.
\end{itemize}

\(AIC_1 = AIC_{min} = 100\) und \(AIC_2\) ist \(100,7\). Dann ist
\(\Delta_2=0,7<2\), so dass es keinen wesentlichen Unterschied zwischen
den Modellen gibt. \(AIC_1 = AIC_{min} = 100000\) und \(AIC_2\) ist
\(100700\). Dann ist \(\Delta_2 = 700 \gg 10\), also gibt es keine
UnterstÃ¼tzung fÃ¼r das \(2\)-te Modell.

Je kleiner das AIC ist, desto besser ist das AIC.

Je kleiner das BIC ist, desto besser ist das BIC.

\[
p_i = \exp\left(\cfrac{-\Delta_i}{2}\right)
\]

Das \(p_i\) ist die relative (im Vergleich zu \(AIC_{min}\))
Wahrscheinlichkeit, dass das \(i\)-te Modell den AIC minimiert. Zum
Beispiel entspricht \(\Delta_i = 1.5\) einem \(p_i\) von \(0.47\)
(ziemlich hoch) und ein \(\Delta_ = 15\) entspricht einem
\(p_i =0.0005\) (ziemlich niedrig). Im ersten Fall besteht eine
Wahrscheinlichkeit von 47\%, dass das \(i\)-te Modell tatsÃ¤chlich eine
bessere Beschreibung ist als das Modell, das \(AIC_{min}\) ergibt, und
im zweiten Fall betrÃ¤gt diese Wahrscheinlichkeit nur 0,05\%.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model\_performance}\NormalTok{(fit\_1) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(AIC, BIC) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), round, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
    AIC   BIC
  <dbl> <dbl>
1 3076. 3093.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_res }\OtherTok{\textless{}{-}} \FunctionTok{compare\_performance}\NormalTok{(fit\_1, fit\_2, fit\_3, fit\_4, fit\_5, }\AttributeTok{rank =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{comp\_res}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Comparison of Model Performance Indices

Name  | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | BIC weights | Performance-Score
-------------------------------------------------------------------------------------------------
fit_2 |    lm | 0.739 |     0.738 | 1.926 | 1.933 |       0.717 |       0.961 |            79.80%
fit_5 |    lm | 0.731 |     0.729 | 0.099 | 0.099 |    2.88e-09 |    3.85e-09 |            66.01%
fit_3 |    lm | 0.739 |     0.737 | 1.926 | 1.935 |       0.265 |       0.039 |            53.28%
fit_4 |    lm | 0.739 |     0.736 | 1.925 | 1.938 |       0.018 |    3.66e-06 |            46.82%
fit_1 |    lm | 0.316 |     0.314 | 3.118 | 3.126 |   6.04e-126 |   7.29e-125 |             0.00%
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(comp\_res)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-basic_files/figure-pdf/unnamed-chunk-38-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{test\_vuong}\NormalTok{(fit\_1, fit\_2, fit\_3, fit\_4, fit\_5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Name  | Model | Omega2 | p (Omega2) |      LR | p (LR)
------------------------------------------------------
fit_1 |    lm |        |            |         |       
fit_2 |    lm |   0.41 |     < .001 |  -18.46 | < .001
fit_3 |    lm |   0.41 |     < .001 |  -18.45 | < .001
fit_4 |    lm |   0.41 |     < .001 |  -18.46 | < .001
fit_5 |    lm |   0.47 |     < .001 | -123.94 | < .001
Each model is compared to fit_1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#pacman::p\_load(report)}

\CommentTok{\#report(fit\_1)}
\end{Highlighting}
\end{Shaded}

War die Transformation sinnvoll?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(hatch\_time }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(log\_hatch\_time }\SpecialCharTok{\textasciitilde{}}\NormalTok{ animal }\SpecialCharTok{+}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_res }\OtherTok{\textless{}{-}} \FunctionTok{compare\_performance}\NormalTok{(fit\_1, fit\_2, }\AttributeTok{rank =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: When comparing models, please note that probably not all models were fit
  from same data.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp\_res}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Comparison of Model Performance Indices

Name  | Model |    R2 | R2 (adj.) |    RMSE |   Sigma | AIC weights | BIC weights | Performance-Score
-----------------------------------------------------------------------------------------------------
fit_2 |    lm | 0.006 |     0.001 |   0.992 |   0.995 |        1.00 |        1.00 |            66.67%
fit_1 |    lm | 0.008 |     0.003 | 789.441 | 792.086 |    0.00e+00 |    0.00e+00 |            33.33%
\end{verbatim}

\hypertarget{generalisierung-von-lm-zu-glm-und-glmer}{%
\section{\texorpdfstring{Generalisierung von \texttt{lm()} zu
\texttt{glm()} und
\texttt{{[}g{]}lmer()}}{Generalisierung von lm() zu glm() und {[}g{]}lmer()}}\label{generalisierung-von-lm-zu-glm-und-glmer}}

\begin{itemize}
\tightlist
\item
  Die Funktion \texttt{lm()} nutzen wir, wenn das Outcome \(y\) einer
  Normalverteilung folgt.
\item
  Die Funktion \texttt{glm()} nutzen wir, wenn das Outcome \(y\) einer
  \emph{andere} Verteilung folgt.
\item
  Die Funktion \texttt{lmer()} nutzen wir, wenn das Outcome \(y\) einer
  Normalverteilung folgt \emph{und} wir noch einen Block- oder
  Clusterfaktor vorliegen haben.
\item
  Die Funktion \texttt{glmer()} nutzen wir, wenn das Outcome \(y\) einer
  \emph{andere} Verteilung folgt \emph{und} wir noch einen Block- oder
  Clusterfaktor vorliegen haben.
\end{itemize}

\hypertarget{referenzen-6}{%
\section*{Referenzen}\label{referenzen-6}}
\addcontentsline{toc}{section}{Referenzen}

\hypertarget{ausreiuxdfer}{%
\chapter{AusreiÃer}\label{ausreiuxdfer}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-20}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-20}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom,}
\NormalTok{               see, performance)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"mutate"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{cbbPalette }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#000000"}\NormalTok{, }\StringTok{"\#E69F00"}\NormalTok{, }\StringTok{"\#56B4E9"}\NormalTok{, }\StringTok{"\#009E73"}\NormalTok{, }
                \StringTok{"\#F0E442"}\NormalTok{, }\StringTok{"\#0072B2"}\NormalTok{, }\StringTok{"\#D55E00"}\NormalTok{, }\StringTok{"\#CC79A7"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{daten-6}{%
\section{Daten}\label{daten-6}}

Nachdem wir uns im vorherigen Kapitel mit einem sehr kleinen Satensatz
beschÃ¤ftigt haben, nehmen wir einen groÃen Datensatz. Bleiben aber bei
einem simplen Modell. Wir brauchen dafÃ¼r den Datensatz
\texttt{flea\_dog\_cat\_length\_weight.xlsx}. In einer simplen linearen
Regression schauen wir uns den Zusammenhang zwischen einem \(y\) und
einem \(x_1\) an. Daher wÃ¤hlen wir aus dem Datensatz die beiden Spalten
\texttt{jump\_length} und \texttt{weight}. Wir wollen nun feststellen,
ob es einen Zusammenhang zwischen der Sprungweite in {[}cm{]} und dem
Flohgewicht in {[}mg{]} gibt. In dem Datensatz finden wir 400 FlÃ¶he von
Hunden und Katzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(animal, jump\_length, weight)}
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-model-1} ist der Datensatz \texttt{model\_tbl}
nochmal dargestellt.

\hypertarget{tbl-model-1}{}
\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tbl-model-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} und der normalverteilten
Variable \texttt{weight}. Wir betrachten die ersten sieben Zeilen des
Datensatzes.}\tabularnewline
\toprule()
animal & jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
animal & jump\_length & weight \\
\midrule()
\endhead
cat & 15.79 & 6.02 \\
cat & 18.33 & 5.99 \\
cat & 17.58 & 8.05 \\
cat & 14.09 & 6.71 \\
cat & 18.22 & 6.19 \\
cat & 13.49 & 8.18 \\
cat & 16.28 & 7.46 \\
\bottomrule()
\end{longtable}

Im Folgenden \emph{ignorieren} wir, dass die Sprungweiten und die
Gewichte der FlÃ¶he auch noch von den Hunden oder Katzen sowie dem
unterschiedlichen Geschlecht der FlÃ¶he abhÃ¤ngen kÃ¶nnten. Wir schmeiÃen
alles in einen Pott und schauen nur auf den Zusammenhang von Sprungweite
und Gewicht.

\hypertarget{das-simple-lineare-modell-1}{%
\section{Das simple lineare Modell}\label{das-simple-lineare-modell-1}}

Wir fitten ein simples lineares Modell mit nur einem Einflussfaktor
\texttt{weight} auf die SprunglÃ¤nge \texttt{jump\_length}. Wir erhalten
dann das Objekt \texttt{fit\_1} was wir dann im Weiteren nutzen werden.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ model\_tbl)}
\end{Highlighting}
\end{Shaded}

Wir nutzen jetzt dieses simple lineare Modell fÃ¼r die weiteren
GÃ¼tekritierien.

\hypertarget{cooks-abstand}{%
\section{Cook`s Abstand}\label{cooks-abstand}}

Die Cook'sche Distanz hat im Wesentlichen eine Aufgabe. Die Cook'sche
Distanz misst, wie stark sich alle angepassten Werte im Modell Ã¤ndern,
wenn der i-te Datenpunkt gelÃ¶scht wird.

\begin{table}

\caption{\label{tbl-tables}Tables}\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-tables-1}Cars}

{\centering 

\begin{tabular}[t]{cc}
\toprule
weight & jump\_length\\
\midrule
1 & 22\\
2 & 23\\
2 & 24\\
3 & 23\\
4 & 19\\
5 & 34\\
7 & 35\\
3 & 36\\
4 & 23\\
5 & 22\\
\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-tables-2}Pressure}

{\centering 

\begin{tabular}[t]{cc}
\toprule
weight & jump\_length\\
\midrule
1 & 190\\
2 & 23\\
2 & 24\\
3 & 23\\
4 & 19\\
5 & 24\\
7 & 25\\
4 & 26\\
5 & 28\\
8 & 180\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}

\begin{figure*}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-modeling-outlier_files/figure-pdf/fig-cooks-1-1.pdf}

}

}

\subcaption{\label{fig-cooks-1-1}Nicht transformierte, rohe Daten}
\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{./stat-modeling-outlier_files/figure-pdf/fig-cooks-1-2.pdf}

}

}

\subcaption{\label{fig-cooks-1-2}\(log\)-transformierte Daten.}
\end{minipage}%

\caption{\label{fig-cooks-1}Histogramm der nicht transfomierten und
transformierten Daten.}

\end{figure*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(jump\_length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ out\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ fit\_2 }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  augment }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(weight, .cooksd)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cooks\_border }\OtherTok{\textless{}{-}} \DecValTok{4}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(plot\_tbl)}
\NormalTok{cooks\_border}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(plot\_tbl, }\FunctionTok{aes}\NormalTok{(weight, .cooksd)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =}\NormalTok{ cooks\_border, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-outlier_files/figure-pdf/fig-cook-2-1.pdf}

}

\caption{\label{fig-cook-2}.}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{remove\_weight\_id }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(plot\_tbl}\SpecialCharTok{$}\NormalTok{.cooksd }\SpecialCharTok{\textgreater{}}\NormalTok{ cooks\_border)}
\NormalTok{out\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ out\_tbl[}\SpecialCharTok{{-}}\NormalTok{remove\_weight\_id,]}

\NormalTok{out\_tbl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 2
  weight jump_length
   <dbl>       <dbl>
1      2          23
2      2          24
3      3          23
4      4          19
5      5          24
6      7          25
7      4          26
8      5          28
\end{verbatim}

Das \href{https://easystats.github.io/performance/}{R Paket performance}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{check\_normality}\NormalTok{(fit\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OK: residuals appear as normally distributed (p = 0.555).
\end{verbatim}

\hypertarget{imputation-fehlender-werte}{%
\chapter{Imputation fehlender Werte}\label{imputation-fehlender-werte}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\hypertarget{was-sind-fehlende-werte}{%
\section{Was sind fehlende Werte?}\label{was-sind-fehlende-werte}}

\hypertarget{imputation-von-fehlenden-werten}{%
\section{Imputation von fehlenden
Werten}\label{imputation-von-fehlenden-werten}}

\hypertarget{variablenselektion}{%
\chapter{Variablenselektion}\label{variablenselektion}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\hypertarget{gaussian-lineare-regression}{%
\chapter{Gaussian lineare
Regression}\label{gaussian-lineare-regression}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\hypertarget{daten-7}{%
\subsection{Daten}\label{daten-7}}

Wir wollen uns erszmal mit einem einfachen Datenbeispiel beschÃ¤ftigen.
Wir brauchen dafÃ¼r den Datensatz
\texttt{flea\_dog\_cat\_length\_weight.xlsx}. In einer simplen linearen
Regression schauen wir uns den Zusammenhang zwischen einem \(y\) und
einem \(x_1\) an. Daher wÃ¤hlen wir aus dem Datensatz
\texttt{flea\_dog\_cat\_length\_weight.xlsx} die beiden Spalten
\texttt{jump\_length} und \texttt{weight}. Wir wollen nun feststellen,
ob es einen Zusammenhang zwischen der Sprungweite in {[}cm{]} und dem
Flohgewicht in {[}mg{]} gibt. In dem Datensatz finden wir 400 FlÃ¶he, wir
wollen uns aber nur die ersten sieben Zeilen des Datensatzes zuerst
anschauen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simple\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(jump\_length, weight) }
\end{Highlighting}
\end{Shaded}

In der Tabelle~\ref{tbl-model-1} ist der Datensatz \texttt{simplel\_tbl}
nochmal dargestellt. Wir wollen jetzt den Zusammenhang zwischen der
Sprungweite in {[}cm{]} und dem Gewicht in {[}mg{]} fÃ¼r die ersten
sieben Beobachtungen modellieren.

\hypertarget{tbl-model-1}{}
\begin{longtable}[]{@{}cc@{}}
\caption{\label{tbl-model-1}Selektierter Datensatz mit einer
normalverteilten Variable \texttt{jump\_length} und der normalverteilten
Variable \texttt{weight}. Es werden die ersten sieben Zeilen des
Datensatzes benutzt.}\tabularnewline
\toprule()
jump\_length & weight \\
\midrule()
\endfirsthead
\toprule()
jump\_length & weight \\
\midrule()
\endhead
15.79 & 6.02 \\
18.33 & 5.99 \\
17.58 & 8.05 \\
14.09 & 6.71 \\
18.22 & 6.19 \\
13.49 & 8.18 \\
16.28 & 7.46 \\
\bottomrule()
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/flea\_dog\_cat\_length\_weight.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(weight, jump\_length)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
`geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-gaussian_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(weight, jump\_length, }\AttributeTok{color =}\NormalTok{ sex, }\AttributeTok{shape =}\NormalTok{ animal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
`geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-gaussian_files/figure-pdf/unnamed-chunk-5-2.pdf}

}

\end{figure}

\hypertarget{sec-mixed}{%
\chapter{Lineare gemische Modelle}\label{sec-mixed}}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\marginnote{\begin{footnotesize}

Dieses Kapitel basiert auf dem tollen
\href{https://ourcodingclub.github.io/tutorials/mixed-models/}{Tutorium
von Gabriela K Hajduk}. Die Daten wurden von mir angepasst und teilweise
gekÃ¼rzt.

\end{footnotesize}}

\href{https://easystats.github.io/parameters/articles/model_parameters.html}{R
Paket parameters}

https://m-clark.github.io/mixed-models-with-R/introduction.html

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-21}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-21}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, conflicted, broom, see,}
\NormalTok{               multcomp, emmeans, ggpubr, lme4, broom.mixed,}
\NormalTok{               parameters)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lme4)}

\FunctionTok{lmer}\NormalTok{(Sepal.Width }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Petal.Length }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Species), }\AttributeTok{data =}\NormalTok{ iris) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{parameters}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Package 'merDeriv' needs to be installed to compute confidence intervals
  for random effect parameters.
\end{verbatim}

\begin{verbatim}
# Fixed Effects

Parameter    | Coefficient |   SE |       95% CI | t(146) |      p
------------------------------------------------------------------
(Intercept)  |        2.00 | 0.56 | [0.89, 3.11] |   3.56 | < .001
Petal Length |        0.28 | 0.06 | [0.16, 0.40] |   4.75 | < .001

# Random Effects

Parameter               | Coefficient
-------------------------------------
SD (Intercept: Species) |        0.89
SD (Residual)           |        0.32
\end{verbatim}

\begin{verbatim}

Uncertainty intervals (equal-tailed) and p-values (two-tailed) computed
  using a Wald t-distribution approximation.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dragons\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/dragons.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(test\_score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(test\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ body\_length, }\AttributeTok{data =}\NormalTok{ dragons\_tbl)}
\FunctionTok{summary}\NormalTok{(lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = test_score ~ body_length, data = dragons_tbl)

Residuals:
     Min       1Q   Median       3Q      Max 
-56.9622 -16.4087  -0.7789  15.1902  55.1992 

Coefficients:
              Estimate Std. Error t value              Pr(>|t|)    
(Intercept) -61.317343  12.066992 -5.0814          0.0000005383 ***
body_length   0.554866   0.059747  9.2869 < 0.00000000000000022 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 21.2 on 478 degrees of freedom
Multiple R-squared:  0.15285,   Adjusted R-squared:  0.15108 
F-statistic: 86.246 on 1 and 478 DF,  p-value: < 0.000000000000000222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_length, }\AttributeTok{y =}\NormalTok{ test\_score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
`geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-7-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{augment}\NormalTok{(lm\_fit) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ .fitted, }\AttributeTok{y =}\NormalTok{ .resid)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ test\_score)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{stat\_qq\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(mountain\_range, test\_score, }\AttributeTok{fill =}\NormalTok{ mountain\_range)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_length, }\AttributeTok{y =}\NormalTok{ test\_score, }\AttributeTok{colour =}\NormalTok{ mountain\_range)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(body\_length, test\_score, }\AttributeTok{color =}\NormalTok{ mountain\_range)) }\SpecialCharTok{+} 
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ mountain\_range) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_mountain\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(test\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ body\_length }\SpecialCharTok{+}\NormalTok{ mountain\_range, }\AttributeTok{data =}\NormalTok{ dragons\_tbl)}
\FunctionTok{summary}\NormalTok{(lm\_mountain\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = test_score ~ body_length + mountain_range, data = dragons_tbl)

Residuals:
     Min       1Q   Median       3Q      Max 
-52.2637  -9.9260   0.3632   9.9925  44.4853 

Coefficients:
                        Estimate Std. Error t value              Pr(>|t|)    
(Intercept)            20.836993  14.472341  1.4398              0.150594    
body_length             0.012637   0.079737  0.1585              0.874140    
mountain_rangeCentral  36.584313   3.599297 10.1643 < 0.00000000000000022 ***
mountain_rangeEmmental 16.210697   3.696654  4.3852           0.000014304 ***
mountain_rangeJulian   45.116050   4.190138 10.7672 < 0.00000000000000022 ***
mountain_rangeLigurian 17.749292   3.673663  4.8315           0.000001836 ***
mountain_rangeMaritime 49.881892   3.139254 15.8897 < 0.00000000000000022 ***
mountain_rangeSarntal  41.979270   3.197172 13.1301 < 0.00000000000000022 ***
mountain_rangeSouthern  8.519476   2.731277  3.1192              0.001924 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 14.96 on 471 degrees of freedom
Multiple R-squared:  0.58433,   Adjusted R-squared:  0.57727 
F-statistic: 82.763 on 8 and 471 DF,  p-value: < 0.000000000000000222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmer\_1\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lmer}\NormalTok{(test\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ body\_length }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ mountain\_range), }\AttributeTok{data =}\NormalTok{ dragons\_tbl)}
\FunctionTok{summary}\NormalTok{(lmer\_1\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Linear mixed model fit by REML ['lmerMod']
Formula: test_score ~ body_length + (1 | mountain_range)
   Data: dragons_tbl

REML criterion at convergence: 3991.2

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.48160 -0.65140  0.00660  0.66872  2.95807 

Random effects:
 Groups         Name        Variance Std.Dev.
 mountain_range (Intercept) 339.68   18.43   
 Residual                   223.81   14.96   
Number of obs: 480, groups:  mountain_range, 8

Fixed effects:
             Estimate Std. Error t value
(Intercept) 43.716559  17.135092  2.5513
body_length  0.033130   0.078648  0.4213

Correlation of Fixed Effects:
            (Intr)
body_length -0.924
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{augment}\NormalTok{(lmer\_1\_fit) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ .fitted, }\AttributeTok{y =}\NormalTok{ .resid)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-15-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(}\FunctionTok{resid}\NormalTok{(lmer\_1\_fit))}
\FunctionTok{qqline}\NormalTok{(}\FunctionTok{resid}\NormalTok{(lmer\_1\_fit)) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-16-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmer\_2\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lmer}\NormalTok{(test\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ body\_length }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{|}\NormalTok{mountain\_range) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{|}\NormalTok{mountain\_range}\SpecialCharTok{/}\NormalTok{site), }\AttributeTok{data =}\NormalTok{ dragons\_tbl) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
unable to evaluate scaled gradient
\end{verbatim}

\begin{verbatim}
Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
Model failed to converge: degenerate Hessian with 1 negative eigenvalues
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(lmer\_2\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Linear mixed model fit by REML ['lmerMod']
Formula: 
test_score ~ body_length + (1 | mountain_range) + (1 | mountain_range/site)
   Data: dragons_tbl

REML criterion at convergence: 3976

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.24260 -0.67514 -0.01157  0.69753  2.88103 

Random effects:
 Groups              Name        Variance Std.Dev.
 site.mountain_range (Intercept)  23.089   4.8051 
 mountain_range      (Intercept) 119.456  10.9296 
 mountain_range.1    (Intercept) 208.127  14.4266 
 Residual                        208.580  14.4423 
Number of obs: 480, groups:  site:mountain_range, 24; mountain_range, 8

Fixed effects:
             Estimate Std. Error t value
(Intercept) 40.083611  21.863838  1.8333
body_length  0.051176   0.103683  0.4936

Correlation of Fixed Effects:
            (Intr)
body_length -0.955
optimizer (nloptwrap) convergence code: 0 (OK)
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dragons\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_length, }\AttributeTok{y =}\NormalTok{ test\_score, }\AttributeTok{colour =}\NormalTok{ site)) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{mountain\_range, }\AttributeTok{nrow=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =} \FunctionTok{cbind}\NormalTok{(dragons\_tbl, }\AttributeTok{pred =} \FunctionTok{predict}\NormalTok{(lmer\_2\_fit)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ pred)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_okabeito}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./stat-modeling-mixed_files/figure-pdf/unnamed-chunk-18-1.pdf}

}

\end{figure}

\part{Experimentelles Design}

\emph{Version vom September 14, 2022 um 08:54:44}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\hypertarget{grundlagen-der-versuchsplanung}{%
\chapter{Grundlagen der
Versuchsplanung}\label{grundlagen-der-versuchsplanung}}

\emph{Version vom September 14, 2022 um 08:54:54}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\part{Bayesianische Statistik}

\emph{Version vom September 14, 2022 um 08:55:03}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\href{https://mc-stan.org/}{Stan}

\href{https://mc-stan.org/rstanarm/articles/index.html}{R Paket
rstanarm}

\href{https://tidyposterior.tidymodels.org/}{R Paket tidyposterior}

\hypertarget{grundlagen-der-bayesianischen-statistik}{%
\chapter{Grundlagen der Bayesianischen
Statistik}\label{grundlagen-der-bayesianischen-statistik}}

\emph{Version vom September 14, 2022 um 08:55:13}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{./images/caution.png}

}

\end{figure}

\appendix
\addcontentsline{toc}{part}{Anhang}

\hypertarget{sec-beispiel-auswertung}{%
\chapter{Beispielhafte Auswertungen}\label{sec-beispiel-auswertung}}

\emph{Version vom September 14, 2022 um 08:55:27}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-22}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-22}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, readxl, }
\NormalTok{               broom, multcomp, emmeans, }
\NormalTok{               conflicted)}

\DocumentationTok{\#\# resolve some conflicts with same function naming}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"select"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\FunctionTok{conflict\_prefer}\NormalTok{(}\StringTok{"filter"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem
Rutsch zum selber durchfÃ¼hren oder aber kopieren.

\hypertarget{auswertung-von-gewichten}{%
\section{Auswertung von Gewichten}\label{auswertung-von-gewichten}}

\begin{longtable}[]{@{}cccc@{}}
\toprule()
trt & block & rep & rsp \\
\midrule()
\endhead
low & I & 1 & 14.60 \\
low & I & 2 & 14.23 \\
low & I & 3 & 13.57 \\
low & I & 4 & 14.36 \\
low & II & 1 & 17.68 \\
low & II & 2 & 11.00 \\
low & II & 3 & 15.57 \\
low & II & 4 & 13.43 \\
low & III & 1 & 13.02 \\
low & III & 2 & 12.61 \\
low & III & 3 & 12.44 \\
low & III & 4 & 18.43 \\
mid & I & 1 & 16.17 \\
mid & I & 2 & 14.69 \\
mid & I & 3 & 12.61 \\
mid & I & 4 & 14.70 \\
mid & II & 1 & 19.29 \\
mid & II & 2 & 17.52 \\
mid & II & 3 & 16.47 \\
mid & II & 4 & 14.99 \\
mid & III & 1 & 20.39 \\
mid & III & 2 & 17.82 \\
mid & III & 3 & 15.63 \\
mid & III & 4 & 17.56 \\
high & I & 1 & 18.59 \\
high & I & 2 & 19.72 \\
high & I & 3 & 17.68 \\
high & I & 4 & 17.69 \\
high & II & 1 & 23.02 \\
high & II & 2 & 18.93 \\
high & II & 3 & 18.31 \\
high & II & 4 & 22.85 \\
high & III & 1 & 17.94 \\
high & III & 2 & 20.68 \\
high & III & 3 & 19.88 \\
high & III & 4 & 19.93 \\
\bottomrule()
\end{longtable}

\hypertarget{explorative-datenanalyse-eda}{%
\subsection{Explorative Datenanalyse
(EDA)}\label{explorative-datenanalyse-eda}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(trt, rsp, }\AttributeTok{color =}\NormalTok{ block)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-example-analysis_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ data\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(trt, block) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(rsp),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(rsp),}
            \AttributeTok{se =}\NormalTok{ sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()))}

\FunctionTok{ggplot}\NormalTok{(stat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ trt, }\AttributeTok{y =}\NormalTok{ mean, }\AttributeTok{fill =}\NormalTok{ block)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(), }\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean}\SpecialCharTok{{-}}\NormalTok{sd, }\AttributeTok{ymax =}\NormalTok{ mean}\SpecialCharTok{+}\NormalTok{sd),}
                  \AttributeTok{width =} \FloatTok{0.2}\NormalTok{,}
                  \AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(.}\DecValTok{9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-example-analysis_files/figure-pdf/unnamed-chunk-6-1.pdf}

}

\end{figure}

\hypertarget{lineares-modell}{%
\subsection{Lineares Modell}\label{lineares-modell}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(rsp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ trt }\SpecialCharTok{+}\NormalTok{ block, }\AttributeTok{data =}\NormalTok{ data\_tbl)}
\end{Highlighting}
\end{Shaded}

\hypertarget{anova}{%
\subsection{ANOVA}\label{anova}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: rsp
          Df  Sum Sq Mean Sq  F value       Pr(>F)    
trt        2 173.728 86.8639 22.79630 0.0000008151 ***
block      2  20.545 10.2725  2.69589     0.083283 .  
Residuals 31 118.124  3.8104                          
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{gruppenvergleich-mit-dem-multcomp-paket}{%
\subsection{\texorpdfstring{Gruppenvergleich mit dem \texttt{multcomp}
Paket}{Gruppenvergleich mit dem multcomp Paket}}\label{gruppenvergleich-mit-dem-multcomp-paket}}

https://broom.tidymodels.org/reference/tidy.glht.html

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{glht}\NormalTok{(}\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{trt =} \StringTok{"Tukey"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  tidy }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, estimate, adj.p.value) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), round, }\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  contrast   estimate adj.p.value
  <chr>         <dbl>       <dbl>
1 mid - low      2.24      0.0223
2 high - low     5.36      0     
3 high - mid     3.11      0.0014
\end{verbatim}

\hypertarget{gruppenvergleich-mit-der-emmeans-paket}{%
\subsection{\texorpdfstring{Gruppenvergleich mit der \texttt{emmeans}
Paket}{Gruppenvergleich mit der emmeans Paket}}\label{gruppenvergleich-mit-der-emmeans-paket}}

https://broom.tidymodels.org/reference/tidy.emmGrid.html

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{emmeans}\NormalTok{(}\StringTok{"trt"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{contrast}\NormalTok{(}\AttributeTok{method =} \StringTok{"pairwise"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  tidy }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(contrast, estimate, adj.p.value) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), round, }\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  contrast   estimate adj.p.value
  <chr>         <dbl>       <dbl>
1 low - mid     -2.24      0.0223
2 low - high    -5.36      0     
3 mid - high    -3.11      0.0013
\end{verbatim}

\hypertarget{auswertung-von-boniturnoten}{%
\section{Auswertung von
Boniturnoten}\label{auswertung-von-boniturnoten}}

\begin{longtable}[]{@{}ccc@{}}
\toprule()
variety & block & rating \\
\midrule()
\endhead
A & I & 2 \\
A & I & 3 \\
A & I & 3 \\
A & I & 4 \\
A & I & 1 \\
A & II & 3 \\
A & II & 2 \\
A & II & 2 \\
A & II & 4 \\
A & II & 4 \\
A & III & 2 \\
A & III & 2 \\
A & III & 3 \\
A & III & 1 \\
A & III & 2 \\
B & I & 8 \\
B & I & 9 \\
B & I & 8 \\
B & I & 9 \\
B & I & 7 \\
B & II & 7 \\
B & II & 7 \\
B & II & 8 \\
B & II & 8 \\
B & II & 7 \\
B & III & 8 \\
B & III & 9 \\
B & III & 7 \\
B & III & 9 \\
B & III & 8 \\
C & I & 6 \\
C & I & 5 \\
C & I & 5 \\
C & I & 6 \\
C & I & 4 \\
C & II & 4 \\
C & II & 5 \\
C & II & 3 \\
C & II & 6 \\
C & II & 4 \\
C & III & 7 \\
C & III & 6 \\
C & III & 4 \\
C & III & 6 \\
C & III & 4 \\
D & I & 2 \\
D & I & 4 \\
D & I & 1 \\
D & I & 2 \\
D & I & 2 \\
D & II & 2 \\
D & II & 4 \\
D & II & 4 \\
D & II & 1 \\
D & II & 3 \\
D & III & 3 \\
D & III & 4 \\
D & III & 2 \\
D & III & 1 \\
D & III & 3 \\
E & I & 4 \\
E & I & 4 \\
E & I & 2 \\
E & I & 7 \\
E & I & 5 \\
E & II & 4 \\
E & II & 3 \\
E & II & 4 \\
E & II & 7 \\
E & II & 7 \\
E & III & 5 \\
E & III & 5 \\
E & III & 4 \\
E & III & 6 \\
E & III & 6 \\
\bottomrule()
\end{longtable}

\hypertarget{explorative-datenanalyse-eda-1}{%
\subsection{Explorative Datenanalyse
(EDA)}\label{explorative-datenanalyse-eda-1}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(variety, rating, }\AttributeTok{color =}\NormalTok{ block)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_dotplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ block), }\AttributeTok{binaxis =} \StringTok{"y"}\NormalTok{, }\AttributeTok{stackdir=}\StringTok{\textquotesingle{}center\textquotesingle{}}\NormalTok{, }
               \AttributeTok{position=}\FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.8}\NormalTok{))  }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-example-analysis_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(data\_tbl, }\FunctionTok{aes}\NormalTok{(variety, rating, }\AttributeTok{fill =}\NormalTok{ block)) }\SpecialCharTok{+}
  \FunctionTok{geom\_dotplot}\NormalTok{(}\AttributeTok{binaxis =} \StringTok{"y"}\NormalTok{, }\AttributeTok{stackdir=}\StringTok{\textquotesingle{}center\textquotesingle{}}\NormalTok{, }
               \AttributeTok{position=}\FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.8}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ median, }\AttributeTok{fun.min =}\NormalTok{ median, }\AttributeTok{fun.max =}\NormalTok{ median,}
               \AttributeTok{geom =} \StringTok{"crossbar"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.5}\NormalTok{, }
               \AttributeTok{position=}\FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.8}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-example-analysis_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\end{figure}

\hypertarget{friedman-test}{%
\subsection{Friedman Test}\label{friedman-test}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#friedman.test(rating \textasciitilde{} variety | block, data = data\_tbl)}

\NormalTok{data\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{Block =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,}
                   \AttributeTok{Sorte\_1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{),}
                   \AttributeTok{Sorte\_2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{),}
                   \AttributeTok{Sorte\_3 =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{7}\NormalTok{),}
                   \AttributeTok{Sorte\_4 =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}
                   \AttributeTok{Sorte\_5 =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(key, value, Sorte\_1}\SpecialCharTok{:}\NormalTok{Sorte\_5)}

\FunctionTok{friedman.test}\NormalTok{(value }\SpecialCharTok{\textasciitilde{}}\NormalTok{ key }\SpecialCharTok{|}\NormalTok{ Block, }\AttributeTok{data =}\NormalTok{ data\_tbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Friedman rank sum test

data:  value and key and Block
Friedman chi-squared = 13.5263, df = 4, p-value = 0.0089709
\end{verbatim}

\hypertarget{auswertung-von-infektionsstatus}{%
\section{Auswertung von
Infektionsstatus}\label{auswertung-von-infektionsstatus}}

\hypertarget{tutorium-in-r}{%
\chapter{Tutorium in R}\label{tutorium-in-r}}

\emph{Version vom September 14, 2022 um 08:56:00}

In diesem Kapitel gibt es eine etwas \emph{wilde} Sammlung an Fragen und
Antworten, die im Rahmen des R Tutoriums aufkamen. Vielleicht findest du
ja was, was dich inspiriert.

\begin{itemize}
\tightlist
\item
  Wie setze ich um einen farbigen Punkt einen schwarzen Rand? (siehe
  Kapitel~\ref{sec-black-circle-point})
\item
  Wie kann ich die Anordnung der Nutzungen bzw. Behandlungen in einer
  Grafik definieren? (siehe Kapitel~\ref{sec-order-x-names})
\item
  Wie kann ich die Anordnung der Fehlerbalken in einem Barplot
  verÃ¤ndern? (siehe Kapitel~\ref{sec-order-error-bars})
\end{itemize}

\hypertarget{genutzte-r-pakete-fuxfcr-das-kapitel-23}{%
\section{Genutzte R Pakete fÃ¼r das
Kapitel}\label{genutzte-r-pakete-fuxfcr-das-kapitel-23}}

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pacman}\SpecialCharTok{::}\FunctionTok{p\_load}\NormalTok{(tidyverse, magrittr, readxl, broom, broom.mixed, }
\NormalTok{               multcomp, emmeans, performance, lme4, effectsize)}
\end{Highlighting}
\end{Shaded}

Schaue dir bitte erst den R Code zu deiner Frage an und dann kannst du
die Pakete noch nachinstallieren. Es werden sich hier sicherlich eine
Menge ansammeln.

\hypertarget{sec-black-circle-point}{%
\section{Wie setze ich um einen farbigen Punkt einen schwarzen
Rand?}\label{sec-black-circle-point}}

In ggplot kÃ¶nnen wir verschiedene Typen von Punkte auswÃ¤hlen - auch
\texttt{shape} genannt. Der \texttt{shape} mit der Nummer 21 hat die
MÃ¶glichkeit die FÃ¼llung \texttt{fill} anders zu wÃ¤hlen, als die
Randfarbe Ã¼ber \texttt{color}. Daher kÃ¶nnen wir die Punkte nach dem
Faktor \texttt{trt} einfÃ¤rben und setzen dann in dem
\texttt{geom\_point()} die Randfarbe auf \texttt{black}. Wir kÃ¶nnten da
auch jede andere Farbe nehmen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,}
                   \AttributeTok{y =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                   \AttributeTok{trt =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{each =} \DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =}  \FunctionTok{as\_factor}\NormalTok{(trt))}

\FunctionTok{ggplot}\NormalTok{(plot\_tbl, }\FunctionTok{aes}\NormalTok{(x, y, }\AttributeTok{fill =}\NormalTok{ trt)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{shape =} \DecValTok{21}\NormalTok{, }\AttributeTok{size =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/fig-r-tutorium-01-1.pdf}

}

\caption{\label{fig-r-tutorium-01}Farbige Punkte mit einem schwarzen
Rand.}

\end{figure}

\hypertarget{sec-order-x-names}{%
\section{Wie kann ich die Anordnung der Nutzungen bzw. Behandlungen in
einer Grafik definieren?}\label{sec-order-x-names}}

HÃ¤ufig ist es so, dass unser Behandlungs oder Nutzenspalte eine
bestimmte Ordnung hat. Wenn wir die Ordnung beibehalten wollen, wie die
Ordnung auch im Datensatz ist, dann kÃ¶nnen wir nach dem Einlesen der
Daten die Funktion \texttt{as\_factor()} nutzen. Dann bleibt die
\emph{ursprÃ¼ngliche} Ordnung erhalten.

Wenn wir eine andere Ordnung haben wollen, dann kÃ¶nnen wir mit der
Funktion \texttt{factor()} und der Option \texttt{level\ =} eine neue
Ordnung der \emph{existierenden} Level vorgeben.

FÃ¼r die Umbenennung in R empfehle ich die Funktion
\href{https://dplyr.tidyverse.org/reference/recode.html}{\texttt{recode()}}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{y =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                   \AttributeTok{trt =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"GemÃ¼se"}\NormalTok{, }\StringTok{"Obst"}\NormalTok{, }\StringTok{"Strauch"}\NormalTok{, }\StringTok{"Brache"}\NormalTok{), }
                             \AttributeTok{each =} \DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{trt =}  \FunctionTok{factor}\NormalTok{(trt, }\AttributeTok{level =} \FunctionTok{c}\NormalTok{(}\StringTok{"Obst"}\NormalTok{, }\StringTok{"Strauch"}\NormalTok{, }\StringTok{"Brache"}\NormalTok{, }\StringTok{"GemÃ¼se"}\NormalTok{)))}

\FunctionTok{ggplot}\NormalTok{(plot\_tbl, }\FunctionTok{aes}\NormalTok{(trt, y, }\AttributeTok{fill =}\NormalTok{ trt)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/fig-r-tutorium-02-1.pdf}

}

\caption{\label{fig-r-tutorium-02}Neuordnung des Faktors \texttt{trt}
fÃ¼r die Boxplots.}

\end{figure}

\hypertarget{sec-order-error-bars}{%
\section{Wie kann ich die Anordnung der Fehlerbalken in einem Barplot
verÃ¤ndern?}\label{sec-order-error-bars}}

In dem Kapitel~\ref{sec-eda-ggplot} haben wir uns ja nur mit
Balkendiagrammen mit einem Faktor beschÃ¤ftigt. Das heist, wir haben den
Faktor auf die x-Achse gelegt und schon hatten wir den Plot. Wenn wir
zwei Faktoren haben, dann mÃ¼ssen wir Ã¼ber die Option
\texttt{position\ =\ position\_dodge()} etwas spielen. Wir kÃ¶nnen auch
die Position und des Abstand etwas Ã¤ndern. Ich habe hier \texttt{0.9}
fÃ¼r die Fehlerbalken in \texttt{position\ =\ position\_dodge()} probiert
und es sieht ziemlich gut aus.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{expand\_grid}\NormalTok{(}\AttributeTok{site =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }
                        \AttributeTok{trt =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }
                        \AttributeTok{rep =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{site =} \FunctionTok{factor}\NormalTok{(site, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{)),}
         \AttributeTok{trt =} \FunctionTok{factor}\NormalTok{(trt, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"new"}\NormalTok{, }\StringTok{"old"}\NormalTok{)),}
         \AttributeTok{rsp =} \FunctionTok{rnorm}\NormalTok{(}\FunctionTok{n}\NormalTok{(), }\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{))}

\NormalTok{stat\_tbl }\OtherTok{\textless{}{-}}\NormalTok{ plot\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(site, trt) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(rsp),}
            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(rsp))}

\FunctionTok{ggplot}\NormalTok{(stat\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ site, }\AttributeTok{y =}\NormalTok{ mean, }\AttributeTok{group =}\NormalTok{ trt, }\AttributeTok{fill =}\NormalTok{ trt)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean}\SpecialCharTok{{-}}\NormalTok{sd, }\AttributeTok{ymax =}\NormalTok{ mean}\SpecialCharTok{+}\NormalTok{sd),}
                \AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Behandlung"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/fig-r-tutorium-03-1.pdf}

}

\caption{\label{fig-r-tutorium-03}Fehlerbalken fÃ¼r einen Barplot mit
zwei Faktoren.}

\end{figure}

\hypertarget{keimung}{%
\section{Keimung}\label{keimung}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{germ\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/germination\_data.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{schweine}{%
\section{Schweine}\label{schweine}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pig\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/pig\_feed\_data.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{kohlenstoffnitrat}{%
\section{Kohlenstoff/Nitrat}\label{kohlenstoffnitrat}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{carbon\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/carbon\_data.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{c2n =}\NormalTok{ c\_o}\SpecialCharTok{/}\NormalTok{n,}
         \AttributeTok{c\_m2c\_o =}\NormalTok{ c\_m}\SpecialCharTok{/}\NormalTok{c\_o)}
\end{Highlighting}
\end{Shaded}

\hypertarget{lichtintensituxe4t}{%
\section{LichtintensitÃ¤t}\label{lichtintensituxe4t}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{intensity\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"data/light\_intensity\_data.xlsx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{rack =} \FunctionTok{as\_factor}\NormalTok{(rack),}
         \AttributeTok{layer =} \FunctionTok{as\_factor}\NormalTok{(layer),}
         \AttributeTok{light\_intensity =} \FunctionTok{factor}\NormalTok{(light\_intensity, }
                                  \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"low"}\NormalTok{, }\StringTok{"mid"}\NormalTok{, }\StringTok{"high"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(growth }\SpecialCharTok{\textasciitilde{}}\NormalTok{ light\_intensity }\SpecialCharTok{+}\NormalTok{ rack }\SpecialCharTok{+}\NormalTok{ layer, }\AttributeTok{data =}\NormalTok{ intensity\_tbl)}

\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 6
  term               df  sumsq meansq statistic  p.value
  <chr>           <int>  <dbl>  <dbl>     <dbl>    <dbl>
1 light_intensity     2  433.   217.      3.87   0.0278 
2 rack                2  628.   314.      5.61   0.00652
3 layer               2   70.9   35.5     0.633  0.535  
4 Residuals          47 2631.    56.0    NA     NA      
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{glht}\NormalTok{(}\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{light\_intensity =} \StringTok{"Tukey"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 7
  term            contrast   null.value estimate std.error statistic adj.p.value
  <chr>           <chr>           <dbl>    <dbl>     <dbl>     <dbl>       <dbl>
1 light_intensity mid - low           0    -2.88      2.49     -1.15      0.486 
2 light_intensity high - low          0    -6.91      2.49     -2.77      0.0214
3 light_intensity high - mid          0    -4.03      2.49     -1.61      0.249 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marginal }\OtherTok{\textless{}{-}} \FunctionTok{emmeans}\NormalTok{(fit\_1, }\StringTok{"light\_intensity"}\NormalTok{)}
\FunctionTok{tidy}\NormalTok{(marginal) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, round, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 6
  light_intensity estimate std.error    df statistic p.value
  <chr>              <dbl>     <dbl> <dbl>     <dbl>   <dbl>
1 low                 18.2      1.76    47     10.3        0
2 mid                 15.3      1.76    47      8.69       0
3 high                11.3      1.76    47      6.4        0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marginal }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{contrast}\NormalTok{(}\AttributeTok{method =} \StringTok{"pairwise"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ tidy }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, round, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 8
  term        contrast null.value estimate std.error    df statistic adj.p.value
  <chr>       <chr>         <dbl>    <dbl>     <dbl> <dbl>     <dbl>       <dbl>
1 light_inte~ low - m~          0     2.88      2.49    47      1.15        0.49
2 light_inte~ low - h~          0     6.91      2.49    47      2.77        0.02
3 light_inte~ mid - h~          0     4.03      2.49    47      1.61        0.25
\end{verbatim}

\hypertarget{komplexes-weizenbeispiel}{%
\section{Komplexes Weizenbeispiel}\label{komplexes-weizenbeispiel}}

Wir wollen uns nun ein kpmplexeres Datenbeispiel anschauen. In diesem
Beispiel liegen zum einen die Daten in einem ungÃ¼nstigen Wide-Format vor
und mÃ¼ssen Ã¼ber \texttt{gather()} erst in das Long-Format gebracht
werden. Zum anderen entstehen dadurch ungÃ¼nstige EintrÃ¤ge in der
\texttt{key}-Spalte, so dass wir hier nochmal einen regulÃ¤ren Ausdruck
benÃ¶tigen um den \texttt{character} Vektor umwandeln zu kÃ¶nnen.

Als wÃ¤re dies nicht schon kompliziert genug, schauen wir uns nicht nur
ein Outcome an, sondern in der Summe die Outcomes WeizenhÃ¶he,
Chlorophyllgehalt sowie Frisch- und Trockengewichte. Der Weizen wurde in
vier BlÃ¶cken angezogen und zu verschiedenen Zeitpunkten gemessen.
Hierdurch entsteht ein komplexer Versuchsaufbau.

\hypertarget{weizenhuxf6he}{%
\subsection{WeizenhÃ¶he}\label{weizenhuxf6he}}

Die HÃ¶he der Weizenpflanzen {[}cm{]} wurde in vier BlÃ¶cken an insgesamt
neun Tagen gemessen. Die Datei \texttt{corn\_plant\_height.csv}
beinhaltet die Daten des Versuchs. FÃ¼r die folgende Auswertung nehmen
wir an, das die WeizenhÃ¶he normalverteilt ist. Wie beginnen mit einer
exploratven Datenanalyse udn schauen uns die Daten einmal an.

\hypertarget{exlorative-datenanalyse}{%
\subsubsection{Exlorative Datenanalyse}\label{exlorative-datenanalyse}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plant\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/corn\_plant\_height.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"day"}\NormalTok{, }\AttributeTok{value =} \StringTok{"height"}\NormalTok{, }\StringTok{"1...3"}\SpecialCharTok{:}\StringTok{"9...47"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{day =} \FunctionTok{str\_replace}\NormalTok{(day, }\StringTok{"...}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{, }\StringTok{""}\NormalTok{),}
         \AttributeTok{day =} \FunctionTok{as\_factor}\NormalTok{(day),}
         \AttributeTok{treatment =} \FunctionTok{as\_factor}\NormalTok{(treatment),}
         \AttributeTok{block =} \FunctionTok{factor}\NormalTok{(block, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"I"}\NormalTok{, }\StringTok{"II"}\NormalTok{, }\StringTok{"III"}\NormalTok{, }\StringTok{"IV"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

In der \texttt{csv}-Datei sind die die Tage jeweils fÃ¼nfmal mit einer 1
bis 9 in den Spalten abgebildet. Wir nutzen die Funktion
\texttt{read\_csv2} um mit dem deutschen Format der \texttt{csv}-Datei
umgehen zu kÃ¶nnen. Die Funktion \texttt{read\_csv2} erkennt das
\texttt{;} als Separator. Da R nicht mit gleichen Benennungen in den
Spalten umgehen kann, setzt R hinter jeden Spaltennamen, der gleich ist
drei Punkte und eine fortlaufende Zahl. Mit der Funktion
\texttt{gather()} kÃ¶nnen wir die Spalten \texttt{1...3} bis
\texttt{9...47} untereinanderkleben. AbschlieÃend mÃ¼ssen wir noch den
\texttt{...{[}Zahl{]}}-Teil loswerden. Das machen wir Ã¼ber den regulÃ¤ren
Ausdruck in der Funktion \texttt{str\_replace()}. RegulÃ¤re AusdrÃ¼cke
musst du nicht verstehen, sind aber sehr mÃ¤chtige Werkzeuge im Umgang
mit groÃen DatensÃ¤tzen.

Schauen wir uns nun einmal die Daten an. Unser Outcome (Y) ist
\texttt{height} und auf X wollen wir das \texttt{treatment}. Das wollen
wir die Boxplots noch nach dem Tag einfÃ¤rben und jeweils ein Subplot fÃ¼r
die vier BlÃ¶cke bauen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(plant\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ treatment, }\AttributeTok{y =}\NormalTok{ height, }\AttributeTok{fill =}\NormalTok{ day)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ block) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{y =} \StringTok{"WeizenhÃ¶he [cm]"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Messtag"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure*}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/fig-crop-boxplot-1-1.pdf}

}

\caption{\label{fig-crop-boxplot-1}An 39 Hunden wurde die Anzahl an
FlÃ¶hen gezÃ¤hlt.}

\end{figure*}

Abbildung~\ref{fig-crop-boxplot-1} zeigt den entsprechenden Boxplot. Du
siehst, dass du auf den ersten Blick nichts siehst. Bei einer so groÃen
Datenmenge ist es selbst mit einem guten \texttt{ggplot()} schwer etwas
zu erkennen. Hier mÃ¼ssen wir uns mehrere Fragen stellen\ldots{}

\begin{itemize}
\tightlist
\item
  \ldots{} wollen wir wirklich alle BlÃ¶cke getrennt auswerten?
\item
  \ldots{} wollen wir uns wirklich alle Tage anschauen? Oder geht es
  nicht eher um die PflanzenhÃ¶he \textbf{am Ende} des Versuches?
\item
  \ldots{} wollen wir wirklich alle \texttt{treatment} Stufen
  vergleichen?
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plant\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(block }\SpecialCharTok{==} \StringTok{"I"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(day }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ treatment, }\AttributeTok{y =}\NormalTok{ height, }\AttributeTok{fill =}\NormalTok{ day)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ block) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{y =} \StringTok{"WeizenhÃ¶he [cm]"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Messtag"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/fig-crop-boxplot-2-1.pdf}

}

\caption{\label{fig-crop-boxplot-2}An 39 Hunden wurde die Anzahl an
FlÃ¶hen gezÃ¤hlt.}

\end{figure}

Abbildung~\ref{fig-crop-boxplot-2} zeigt einen Auschnitt in dem wir nur
nach Block I und den Tagen 6 bis 9 gefiltert haben. In diesem Fall
kÃ¶nnten wir auf den vollen Datensatz weitermachen \emph{oder} vorab Ã¼ber
\texttt{filter()} einen kleinern Datensatz bauen, der unsere
Fragestellung bgut beantworten kann. Wir gehen jetzt den steinigeren Weg
und analysieren den ganzen Datensatz - das muss nicht der bessere Weg
sein!

\hypertarget{lineares-modell-mit-lm}{%
\subsubsection{\texorpdfstring{Lineares Modell mit
\texttt{lm()}}{Lineares Modell mit lm()}}\label{lineares-modell-mit-lm}}

Wir beginnen mit einer ANOVA und mÃ¼ssen dafÃ¼r ein lineare Modell
schÃ¤tzen. DafÃ¼r nutzen wir erst die Funktion \texttt{lm()} und
anschlieÃend mit dem Ergebnis des linearen Modells die Funktion
\texttt{anova()} um eine Varianzanalyse durchzufÃ¼hren.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_height }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ treatment }\SpecialCharTok{+}\NormalTok{ day }\SpecialCharTok{+}\NormalTok{ block }\SpecialCharTok{+} 
\NormalTok{                   treatment}\SpecialCharTok{:}\NormalTok{day }\SpecialCharTok{+}\NormalTok{ treatment}\SpecialCharTok{:}\NormalTok{block, }
                 \AttributeTok{data =}\NormalTok{ plant\_tbl)}

\NormalTok{fit\_height }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: height
                  Df  Sum Sq Mean Sq    F value                 Pr(>F)    
treatment          7  2402.5  343.22  211.20218 < 0.000000000000000222 ***
day                8 41280.2 5160.03 3175.28495 < 0.000000000000000222 ***
block              3    63.4   21.14   13.01124     0.0000000222375065 ***
treatment:day     56  1076.3   19.22   11.82650 < 0.000000000000000222 ***
treatment:block   21   162.2    7.72    4.75297     0.0000000000099287 ***
Residuals       1344  2184.1    1.63                                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Wir konzentrieren uns auf die Spalte \texttt{Pr(\textgreater{}F)} welche
den p-Wert beinhaltet. Wir schauen welcher p-Wert kleiner ist als
\(\alpha = 5\% = 0.05\). Alle p-Werte sind signifikant. Mindestens zwei
\texttt{treatment} Level unterscheiden sich, mindestens zwei
\texttt{day} Level unterschieden sich und mindestens zwei \texttt{block}
Level unterscheiden sich. AbschlieÃend ist auch der Interaktionsterm
zwischen den Behandlungen und den Tagen sowie den Behandlungen und den
BlÃ¶cken signifikant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_height }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ anova }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{eta\_squared}\NormalTok{(}\AttributeTok{partial =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Effect Size for ANOVA (Type I)

Parameter       |     Eta2 |       95% CI
-----------------------------------------
treatment       |     0.05 | [0.03, 1.00]
day             |     0.88 | [0.87, 1.00]
block           | 1.34e-03 | [0.00, 1.00]
treatment:day   |     0.02 | [0.00, 1.00]
treatment:block | 3.44e-03 | [0.00, 1.00]

- One-sided CIs: upper bound fixed at [1.00].
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_height\_lme }\OtherTok{\textless{}{-}} \FunctionTok{lmer}\NormalTok{(height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ treatment }\SpecialCharTok{+}\NormalTok{ block }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{|}\NormalTok{day), }
                       \AttributeTok{data =}\NormalTok{ plant\_tbl)}

\NormalTok{fit\_height\_lme }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Linear mixed model fit by REML ['lmerMod']
Formula: height ~ treatment + block + (1 | day)
   Data: plant_tbl

REML criterion at convergence: 5430.6

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.09029 -0.62046 -0.00151  0.57885  4.37546 

Random effects:
 Groups   Name        Variance Std.Dev.
 day      (Intercept) 32.2351  5.6776  
 Residual              2.4085  1.5519  
Number of obs: 1440, groups:  day, 9

Fixed effects:
                  Estimate Std. Error  t value
(Intercept)       13.51875    1.89739   7.1249
treatmentlow_Fe   -0.15778    0.16359  -0.9645
treatmentmid_P     1.30278    0.16359   7.9637
treatmentmid_Fe    1.38111    0.16359   8.4425
treatmenthigh_P    1.16167    0.16359   7.1011
treatmenthigh_Fe   1.63722    0.16359  10.0081
treatmentlow_N    -1.87333    0.16359 -11.4514
treatmentlow_P_Fe -1.61278    0.16359  -9.8587
blockII            0.58861    0.11568   5.0885
blockIII           0.24611    0.11568   2.1276
blockIV            0.23472    0.11568   2.0291

Correlation of Fixed Effects:
            (Intr) trtmntl_F trtmntm_P trtmntm_F trtmnth_P trtmnth_F trtm_N
tretmntlw_F -0.043                                                         
tretmntmd_P -0.043  0.500                                                  
tretmntmd_F -0.043  0.500     0.500                                        
trtmnthgh_P -0.043  0.500     0.500     0.500                              
trtmnthgh_F -0.043  0.500     0.500     0.500     0.500                    
tretmntlw_N -0.043  0.500     0.500     0.500     0.500     0.500          
trtmntl_P_F -0.043  0.500     0.500     0.500     0.500     0.500     0.500
blockII     -0.030  0.000     0.000     0.000     0.000     0.000     0.000
blockIII    -0.030  0.000     0.000     0.000     0.000     0.000     0.000
blockIV     -0.030  0.000     0.000     0.000     0.000     0.000     0.000
            tr_P_F blckII blcIII
tretmntlw_F                     
tretmntmd_P                     
tretmntmd_F                     
trtmnthgh_P                     
trtmnthgh_F                     
tretmntlw_N                     
trtmntl_P_F                     
blockII      0.000              
blockIII     0.000  0.500       
blockIV      0.000  0.500  0.500
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_height\_lme }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{(}\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{effects =} \StringTok{"fixed"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 11 x 7
   effect term              estimate std.error statistic conf.low conf.high
   <chr>  <chr>                <dbl>     <dbl>     <dbl>    <dbl>     <dbl>
 1 fixed  (Intercept)         13.5       1.90      7.12   9.80       17.2  
 2 fixed  treatmentlow_Fe     -0.158     0.164    -0.964 -0.478       0.163
 3 fixed  treatmentmid_P       1.30      0.164     7.96   0.982       1.62 
 4 fixed  treatmentmid_Fe      1.38      0.164     8.44   1.06        1.70 
 5 fixed  treatmenthigh_P      1.16      0.164     7.10   0.841       1.48 
 6 fixed  treatmenthigh_Fe     1.64      0.164    10.0    1.32        1.96 
 7 fixed  treatmentlow_N      -1.87      0.164   -11.5   -2.19       -1.55 
 8 fixed  treatmentlow_P_Fe   -1.61      0.164    -9.86  -1.93       -1.29 
 9 fixed  blockII              0.589     0.116     5.09   0.362       0.815
10 fixed  blockIII             0.246     0.116     2.13   0.0194      0.473
11 fixed  blockIV              0.235     0.116     2.03   0.00800     0.461
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{model\_performance}\NormalTok{(fit\_height\_lme) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Indices of model performance

AIC      |     AICc |      BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma
--------------------------------------------------------------------------------
5456.619 | 5456.875 | 5525.161 |      0.934 |      0.047 | 0.930 | 1.542 | 1.552
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{r2}\NormalTok{(fit\_height\_lme)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# R2 for Mixed Models

  Conditional R2: 0.934
     Marginal R2: 0.047
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{glht}\NormalTok{(fit\_height\_lme, }\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{treatment =} \StringTok{"Tukey"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tidy}\NormalTok{(}\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(estimate) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{contrast =} \FunctionTok{as\_factor}\NormalTok{(contrast))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Joining, by = c("term", "contrast", "estimate")
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(conf\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ contrast, }\AttributeTok{y =}\NormalTok{ estimate, }
                     \AttributeTok{ymin =}\NormalTok{ conf.low, }\AttributeTok{ymax =}\NormalTok{ conf.high)) }\SpecialCharTok{+}
  \FunctionTok{geom\_pointrange}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{""}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mittelwertsdifferenz der WeizenhÃ¶he [cm]"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/unnamed-chunk-20-1.pdf}

}

\end{figure}

\hypertarget{chlorophyllgehalt}{%
\subsection{Chlorophyllgehalt}\label{chlorophyllgehalt}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chlorophyl\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/corn\_chlorophyl.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"day"}\NormalTok{, }\AttributeTok{value =} \StringTok{"chlorophyl"}\NormalTok{, }\StringTok{"1...3"}\SpecialCharTok{:}\StringTok{"3...62"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{day =} \FunctionTok{str\_replace}\NormalTok{(day, }\StringTok{"...}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{, }\StringTok{""}\NormalTok{),}
         \AttributeTok{day =} \FunctionTok{as\_factor}\NormalTok{(day),}
         \AttributeTok{treatment =} \FunctionTok{as\_factor}\NormalTok{(treatment),}
         \AttributeTok{block =} \FunctionTok{factor}\NormalTok{(block, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"I"}\NormalTok{, }\StringTok{"II"}\NormalTok{, }\StringTok{"III"}\NormalTok{, }\StringTok{"IV"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(chlorophyl }\SpecialCharTok{\textgreater{}=} \DecValTok{20} \SpecialCharTok{\&}\NormalTok{ chlorophyl }\SpecialCharTok{\textless{}=} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(chlorophyl\_tbl, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ treatment, }\AttributeTok{y =}\NormalTok{ chlorophyl, }\AttributeTok{fill =}\NormalTok{ day)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ block) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Chlorophyllgehalt"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Messtag"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure*}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/unnamed-chunk-22-1.pdf}

}

\end{figure*}

\hypertarget{frisch--und-trockenmasse}{%
\subsection{Frisch- und Trockenmasse}\label{frisch--und-trockenmasse}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{burn\_tbl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv2}\NormalTok{(}\StringTok{"data/corn\_burning.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"day\_outcome"}\NormalTok{, }\AttributeTok{value =} \StringTok{"drymatter"}\NormalTok{, }\StringTok{"1\_FM"}\SpecialCharTok{:}\StringTok{"3\_TMperc"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{separate}\NormalTok{(day\_outcome, }\FunctionTok{c}\NormalTok{(}\StringTok{"day"}\NormalTok{, }\StringTok{"outcome"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{day =} \FunctionTok{as\_factor}\NormalTok{(day),}
         \AttributeTok{treatment =} \FunctionTok{as\_factor}\NormalTok{(treatment),}
         \AttributeTok{block =} \FunctionTok{factor}\NormalTok{(block, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"I"}\NormalTok{, }\StringTok{"II"}\NormalTok{, }\StringTok{"III"}\NormalTok{, }\StringTok{"IV"}\NormalTok{)),}
         \AttributeTok{outcome =} \FunctionTok{as\_factor}\NormalTok{(outcome)) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{burn\_tbl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(outcome }\SpecialCharTok{==} \StringTok{"FM"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ treatment, }\AttributeTok{y =}\NormalTok{ drymatter, }\AttributeTok{color =}\NormalTok{ day)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \DocumentationTok{\#\#facet\_wrap(\textasciitilde{} block, scales = "free\_y") +}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Behandlung"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Gewicht"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Messtag"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{./app-r-tutorial_files/figure-pdf/unnamed-chunk-24-1.pdf}

}

\end{figure}

\hypertarget{writing-principles}{%
\chapter{Writing principles}\label{writing-principles}}

\emph{Version vom September 14, 2022 um 08:56:23}

\hypertarget{wie-schreibe-ich-eine-gute-abschlussarbeit}{%
\section{Wie schreibe ich eine gute
Abschlussarbeit}\label{wie-schreibe-ich-eine-gute-abschlussarbeit}}

Schreiben ist nicht einfach. \emph{Aber es folgt einem Schema.}
Schreiben ist anstrengend und dauert seine Zeit. Ein guter Text wird
mehrfach revidiert, umgeschrieben und gelÃ¶scht, bis er zu einem guten
Text geworden ist. HÃ¤ufig vergehen mehrere Tage bis man eine Idee so auf
das Blatt Papier gebracht hat, dass auch ein Dritter den Text lesen und
verstehen kann.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zentraler Gedanke}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Der erste Entwurf ist fÃ¼r einen selber, ab dem zweiten geht es um den
Leser.
\end{tcolorbox}

Es geht also am Anfang erstmal darum, Text auf das weiÃe Blatt zu
kriegen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Otto Kruse -- Keine Angst vor dem leeren Blatt}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Viele wissenschaftliche Themen kann man erst dann lÃ¶sen, wenn man alle
Aspekte explizit formuliert hat. Das Denken ist dafÃ¼r insofern nicht
genÃ¼gend vorbereitet, als es immer nur kleine Ausschnitte fokussieren
kann. Systematisch denken kann man nur, wenn man schreibt, also die
Ergebnisse seines Denkens festhÃ¤lt und mit weiteren Aspekten in
Beziehung setzt.
\end{tcolorbox}

Das ist die Idee vom Schreiben. Andere merken, wie weit du mit deinen
Gedanken gekommen bist. Wir bringen komplexe GedankengÃ¤nge in die
lineare Form des Textes.

\hypertarget{der-schreibprozess}{%
\section{Der Schreibprozess}\label{der-schreibprozess}}

Der Schreibprozess lÃ¤uft nach Beginn in den nÃ¤chsten Wochen und Monaten
in mehreren Phasen ab. In jeder Phase ist es wichtig, sich ein gutes
Umfeld fÃ¼r konzentriertes Arbeiten zu schaffen, gleichzeitig aber die
Kommunikation mit den Betreuenden und anderen Mitschaffenden nicht
abreiÃen zu lassen.

\hypertarget{zeitplan}{%
\section{Zeitplan}\label{zeitplan}}

Hier ist es wichtig was geschrieben werden soll. Eine Bachelor- und
Masterarbeit hat einen klaren Zeitplan, der vorab feststehen muss. Bis
wann mÃ¼ssen wie viele WÃ¶rter geschrieben sein, damit die Arbeit fertig
werden kann. Beide Abschlussformen haben ja unterschiedliche Zeitrahmen.
Und das ist wirklich wichtig! Wann sollte man fertig sein mit
Programmieren, wie lange soll man sich Zeit fÃ¼r Vortragsvorbereitung
nehmen, etc. Auch eine wissenschaftliche VerÃ¶ffentlichung hat einen
Zeitplan! Leider -- das ist der Primat der Forschung -- kann sich der
Zeitplan immer wieder Ã¤ndern, wenn Methoden nicht klappen oder neue
Erkenntnisse gewonnen werden. Dennoch muss klar sein, dass in endlicher
Zeit -- meist ein Jahr -- ein Paper eingereicht werden kann. Auf dieses
Ziel sollten sich alle EinschwÃ¶ren. Sonst ist eine Promotion in
endlicher Zeit nicht machbar.

\hypertarget{ideen-entwickeln}{%
\section{Ideen entwickeln}\label{ideen-entwickeln}}

Man sammelt Ideen zunÃ¤chst in der Breite und fokussiert dann, was davon
man aufschreiben will. Man liest andere wissenschaftliche Paper, lernt
vielleicht noch Grundlagen und Methoden, und macht sich Notizen, was
interessant sein kÃ¶nnte, und wo es steht. NatÃ¼rlich kann man sich bei
den Betreuern und Mitschaffenden Hilfe und Anregungen holen, wo man
Input herbekommt. Holen heiÃt aber nicht, dass man gebracht bekommt.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{OCAR Prinzip}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Frage dich, was ist das \textbf{O}pening (der Hintergrund der Arbeit),
die \textbf{C}hallenge (was ist das Problem, was gelÃ¶st werden soll?),
die \textbf{A}ction (was wirst du tun um dieses Problem zu lÃ¶sen?) und
die \textbf{R}esults (Was kam dabei raus oder soll rauskommen?)
\end{tcolorbox}

\hypertarget{strukturieren}{%
\section{Strukturieren}\label{strukturieren}}

Das grobe GerÃ¼st ist ja vorgegeben. Eine wissenschaftliche Arbeit folgt
dem \textbf{IMRaD} Schema. Erst die Einleitung (\textbf{I}ntroduction),
dann die Methoden (\textbf{M}ethods), gefolgt von den Ergebnissen
(\textbf{R}esults) und der Diskussion (\textbf{D}iscussion). Am Ende der
Einleitung wird nochmal die Fragestellung benannt. Welche Frage soll in
der Arbeit beantwortet werden? Dann fehlt noch die Zusammenfassung am
Anfang (abstract) und der Schluss bzw. das Fazit (conclusion). So ist
das vorgegebene Schema fÃ¼r die Arbeit, das soll mit Inhalt gefÃ¼llt
werden. Klingt erstmal einfach und ist es auch. Mit
ZwischenÃ¼berschriften in den einzelnen Abschnitten kann man sich eine
grobe Ordnung vorgeben, was in welcher Reihenfolge aufgeschrieben werden
soll. Die Struktur innerhalb von Methodenteilen ist zum Beispiel oft
gleich, Beschreibung der Studie, Beschreibung der interessierenden
Variablen und ihrer Erhebung, Beschreibung der Auswertungsmethodik. Das
kommt aber aufs Thema an. Und unterhalb dieser kann man sich wieder
Unter-zwischen-unterÃ¼berschriften machen. Es wird sowieso noch alles
Ã¼berarbeitet.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Grobe Strukturierung nach IMRaD}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]

\begin{itemize}
\tightlist
\item
  Zusammenfassung
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Einleitung

  \begin{itemize}
  \tightlist
  \item
    Forschungsfrage
  \end{itemize}
\item
  Material und Methoden
\item
  Ergebnisse
\item
  Diskussion
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Literatur
\end{itemize}

\end{tcolorbox}

Wenn es einen Flowchart gibt, so gibt dieser auch die Struktur vor. Ein
Flowchart ist nicht final und Ã¤ndert sich mit der Zeit! Mach den
Flowchart am besten auf einem Blatt Papier. Da kannst du schneller was
ergÃ¤nzen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hinweis}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Zeichne einen Flowchart, der aufzeigt was in der Arbeit passiert!
\end{tcolorbox}

\hypertarget{rohtexten}{%
\section{Rohtexten}\label{rohtexten}}

Das kann wirklich sloppy sein, in Stichpunkten oder hingerotzt, aber
hier soll man sich auch nicht an Details aufhalten, sondern dem Arbeits-
und Denkfluss folgen. Gerne auch Denglisch. Lieber erst Text schreiben
und dann korrigieren. Wenn das Englische Wort nicht einfÃ¤llt, das
deutsche Hinschreiben. Den Schreibprozess nicht durch im Internet suchen
und dann mal was Anderes gucken unterbrechen. Gerade wenn die Arbeit
selbst noch im Entstehen ist, schreibt man erst einmal auf, was man tut,
was man gemacht, gelernt, oder gelesen hat. Diese Frage stellt sich
meist nach den ersten paar SÃ¤tzen in einer wissenschaftlichen Arbeit.
Worum geht es hier eigentlich? Es kÃ¶nnte alles so einfach sein. Das ist
normal. Durch das Aufschreiben werden einem meist die Dinge klarer und
uns wird bewusst, wo wir nochmal genauer einhaken mÃ¼ssen.

\hypertarget{reflektieren}{%
\section{Reflektieren}\label{reflektieren}}

Die Grundideen sind jetzt schon mal auf dem Papier, jetzt muss man sich
Ã¼berlegen, wie daraus ein Text wird. Gut ist es, sich schon an dieser
Stelle Feedback von Betreuern oder Kommilitonen zu holen. Das hilft
auch, die eigene Perspektive auf den Text zu Ã¤ndern und ihn aus mehreren
Richtungen zu betrachten -- was ist wichtig, was soll viel Platz
einnehmen, was fehlt vielleicht noch?

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Hinweis}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]
Was kÃ¶nnte die zentrale Abbildung in den Ergebnissen sein?
\end{tcolorbox}

Ein guter Ansatz um einen Fokus zu haben!

\hypertarget{jetzt-schreiben-wir-wie-geht-es-am-besten}{%
\section{Jetzt schreiben wir! Wie geht es am
besten?}\label{jetzt-schreiben-wir-wie-geht-es-am-besten}}

DafÃ¼r geht gut die HÃ¤lfte der Schreibzeit drauf. Am wichtigsten sind
Inhalt und Struktur, Korrektheit und VerstÃ¤ndlichkeit dÃ¼rfen aber auch
nicht unterschÃ¤tzt werden: Wir nutzen einfache englische Sprache. Das
geschriebene Wort muss nicht schlau klingen, sondern der Inhalt muss
schlau sein. Keine umstÃ¤ndlichen, gekÃ¼nstelten Verben verwenden, wenn es
ein einfaches Verb auch tut. Wir machen es dem Leser einfach. SpÃ¤ter
wirst du in einem wissenschaftlichen Paper âwe'' schreiben, da man
selten ein Paper alleine schreibt. Um das jetzt hier gleich am Anfang zu
Ã¼ben, schreibst du keine verschachtelten Passivkonstruktionen, sondern
âI do/did something''. Das fÃ¼hlt sich erst seltsam an, aber wir als
Leser danken dir!

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Schlecht}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
After the raw methylation data has been preprocessed, a student t test
was used for the differential analysis.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Gut}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
I used the student t test for the differential analysis after the
preprocessing of the raw methylation data.
\end{tcolorbox}

Wir nutzen auch keine Pronomen, wo man nicht weiÃ, was diese Pronomen
aussagen sollen. Was ist âit'' oder âthey''?

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Schlecht}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
The dog and the cat walk into a house. It eats all the cookies.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Gut}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
The dog and the cat walk into a house. The cat eats all the cookies.
\end{tcolorbox}

Wir fÃ¼hren alle Begriffe vorher ein, daher erklÃ¤ren wir diese Begriffe,
bevor wir die Begriffe verwenden. Ja, mache Begriffe sind klar, aber
welche das sind, ergibt sich manchmal erst auf Nachfrage bei uns und ist
fÃ¼r einen Neuling in einem Fachbereich gar nicht zu wissen.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Schlecht}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
I analyzed the NGS data with an ANOVA after checking the residuals with
a QQ-plot.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Gut}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
I analyzed the next generation sequencing data (NGS) with an analysis of
variance (ANOVA) after plotting the residuals of the model in a
quantile-quantile plot (QQ-plot).
\end{tcolorbox}

Ist dir der Begriff nicht klar, erklÃ¤re ihn. SpÃ¤ter kÃ¶nnen wir immer
noch kÃ¼rzen. Erkenntnisgewinn durch schreiben ist das Ziel.

\hypertarget{wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz}{%
\section{Wer macht was? Die Frage des Lesers an jeden einzelnen
Satz!}\label{wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz}}

Komme in den \textbf{ersten sieben WÃ¶rtern} zum Punkt, wer was macht.
Subjekt und PrÃ¤dikat sollen nah beieinander sein und mÃ¶glichst frÃ¼h im
Satz kommen. Wir schreiben kurze SÃ¤tze und vermeiden komplizierte
SchachtelsÃ¤tze.

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Schlecht}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, colframe=quarto-callout-important-color-frame]
The differential analysis of whole genome genetic data - like
methylation pattern or expression analysis - has a long history of
different invented methods and I used different analysis methods to find
the best method for the analysis of methylation data with repeated
measurements.
\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Gut}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, colframe=quarto-callout-tip-color-frame]
{[}1{]} A long history of different analysis methods like methylation
pattern or expression analysis exists. {[}2{]} Hence, many scientist
have invented different analysis methods of whole genome.
\end{tcolorbox}

\hypertarget{luxf6schen-von-text}{%
\section{LÃ¶schen von Text}\label{luxf6schen-von-text}}

Text lÃ¶schen macht keine Freude. Es ist immer nervig Teile des Textes,
den man so mÃ¼hsam in die Maschine getippt hat, zu lÃ¶schen. Lege dir eine
neue Datei an, in der du alles was du lÃ¶schen willst reinkopierst. Bei
mir heiÃt die Datei dump.docx oder dump.R oder auch anders. Auf jeden
Fall lÃ¶schst du so keinen Text, sondern bewahrst ihn erstmal auf. Denk
immer daran, es geht nicht darum nur viel Text zu produzieren!

\hypertarget{zum-schluss-kommen}{%
\section{Zum Schluss kommen}\label{zum-schluss-kommen}}

Wie Anne und Jochen\sidenote{\footnotesize Die beide zusammen die erste Version von
  diesem Text mal 2019 geschrieben haben. Tja, wie so die Zeit vergeht.}
jetzt in diesem Augenblick musst du zum Schluss kommen. Kein Text ist
perfekt, kein Gedankengang so klar niedergeschrieben, wie er sein
kÃ¶nnte. Aber irgendwann muss gut sein. Lass das Perfekte nicht der Feind
des Guten sein. Dieser Leitfaden ist \emph{good enough} und somit muss
es reichen. Viel Erfolg!

\begin{tcolorbox}[enhanced jigsaw, coltitle=black, titlerule=0mm, bottomrule=.15mm, opacityback=0, opacitybacktitle=0.6, leftrule=.75mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Erfahrungsbericht von ehemaligen Bachelorstudierenden}, toprule=.15mm, bottomtitle=1mm, toptitle=1mm, left=2mm, breakable, arc=.35mm, colback=white, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, colframe=quarto-callout-note-color-frame]

\begin{itemize}
\tightlist
\item
  keine neuen (wichtigen) Begriffe verwenden, wenn sie nicht vorher
  eingefÃ¼hrt wurden
\item
  wenn man einen Begriff nicht richtig versteht oder nicht richtig
  erklÃ¤ren kann, sollte man ihn nicht verwenden. Daher ist es sehr
  hilfreich sich grÃ¼ndlich in den Hintergrund des Themas einzulesen.
\item
  man sollte mehr wissen Ã¼ber das Thema, als man eigentlich im Text
  erklÃ¤rt (um auf Fragen vorbereitet zu sein)
\item
  Achtgeben auf die Zeitformen
\item
  ``it'', ``they'' und weitere Pronomen vermeiden, d.h. immer klar
  machen worauf man sich bezieht
\item
  wenn etwas komplizierter scheint, sollte man Beispiele benutzen oder
  es eventuell graphisch darstellen. \textbf{Aber:} ein Bild nicht
  verwenden, wenn es keinen inhaltlichen Wert hat! Bringt dieses Bild
  etwas zum VerstÃ¤ndnis des Lesers bei?
\item
  in der Diskussion kein neues ``Fass aufmachen''
\item
  die Limitationen in der Diskussion im FlieÃtext ``verstecken''
\item
  die eigene Arbeit nicht schlecht reden; ``schlechte'' Resultate sind
  auch Resultate
\item
  keine zu langen SÃ¤tze
\item
  es sollte ein roter Faden in jedem Kapitel zu erkennen sein: Was ist
  das Ziel? Wie erreiche ich das? Was bringt mir diese Methode? Was
  sagen mir die Resultate (in Bezug auf mein Ziel)?
\item
  und fÃ¼r die eigene Motivation: Es werden oft Schreibblockaden kommen,
  es wird oft frustrierend sein, weil vielleicht etwas umgeschmissen
  wird und man von vorne anfangen muss, etc., aber davon soll man sich
  nicht entmutigen lassen
\item
  Der Text muss nicht gleich beim ersten Hinschreiben perfekt sein,
  sondern es hilft erstmal etwas drauflos zu schreiben um die Gedanken
  besser ordnen zu kÃ¶nnen
\item
  Ã¤hnlich beim Programmieren: hier hat es mir auch geholfen einfach
  erstmal anzufangen und Ideen aufzuschreiben, aus welchen sich kann das
  Programm aufbauen kann
\item
  Man sollte nicht zÃ¶gern so etwas wie deepl
  (\href{www.deepl.com}{deepl.com}) zu benutzen, wenn man mal mit einer
  englischen Formulierung nicht weiterkommt
\item
  Man kann vor Beginn eines Tages ein realistisches Tagesziel (oder
  alternativ ein Wochenziel) festlegen, dann hat man ein Zwischenziel
  vor Augen und ist zufrieden mit sich, wenn dieses erreicht ist
\end{itemize}

\end{tcolorbox}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-bruce2020practical}{}}%
Bruce, Peter, Andrew Bruce, und Peter Gedeck. 2020. \emph{Practical
statistics for data scientists: 50+ essential concepts using R and
Python}. O'Reilly Media.

\leavevmode\vadjust pre{\hypertarget{ref-dormann2013parametrische}{}}%
Dormann, Carsten F. 2013. \emph{Parametrische Statistik}. Springer.

\leavevmode\vadjust pre{\hypertarget{ref-george2020s}{}}%
George, Andrew, Thor S Stead, und Latha Ganti. 2020. {âWhat's the risk:
differentiating risk ratios, odds ratios, and hazard ratios?``}
\emph{Cureus} 12 (8).

\leavevmode\vadjust pre{\hypertarget{ref-gigerenzer2004null}{}}%
Gigerenzer, Gerd, Stefan Krauss, und Oliver Vitouch. 2004. {âThe null
ritual``}. \emph{The Sage handbook of quantitative methodology for the
social sciences}, 391--408.

\leavevmode\vadjust pre{\hypertarget{ref-kery2010introduction}{}}%
KÃ©ry, Marc. 2010. \emph{Introduction to WinBUGS for ecologists: Bayesian
approach to regression, ANOVA, mixed models and related analyses}.
Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-kruppa2021spielerisch}{}}%
Kruppa, Jochen, und Miriam Sieg. 2021. {âSpielerisch Daten reinigen``}.
In \emph{Zeig mir Health Data Science!}, 93--103. Springer.

\leavevmode\vadjust pre{\hypertarget{ref-salsburg2001lady}{}}%
Salsburg, David. 2001. \emph{The lady tasting tea: How statistics
revolutionized science in the twentieth century}. Macmillan.

\leavevmode\vadjust pre{\hypertarget{ref-wasserstein2019moving}{}}%
Wasserstein, Ronald L, Allen L Schirm, und Nicole A Lazar. 2019.
{âMoving to a world beyond {âp\textless{} 0.05`}``}. \emph{The American
Statistician}. Taylor \& Francis.

\leavevmode\vadjust pre{\hypertarget{ref-wickham2016r}{}}%
Wickham, Hadley, und Garrett Grolemund. 2016. \emph{R for data science:
import, tidy, transform, visualize, and model data}. O'Reilly Media,
Inc.

\end{CSLReferences}


\backmatter

\end{document}
