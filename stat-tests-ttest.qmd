```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc,
               patchwork, see, tinytable, infer)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
fac1_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  mutate(animal = as_factor(animal)) |> 
  select(animal, jump_length)
```

# Der t-Test {#sec-ttest}

*Letzte Änderung am `r format(fs::file_info("stat-tests-ttest.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"You cannot be a powerful and life-changing presence to some people without being a joke or an embarrassment to others." --- Mark Manson*

{{< video https://youtu.be/iECcenEDzOM >}}

Beginnen wir unsere Reise durch die statistischen Tests mit dem t-Test. Damit beginnen wir auch historisch korrekt, da der t-Test auch der erste statistische Test war, der entwickelt wurde. Wir sehen die Nutzung des t-Tests in vielen wissenschaftlichen Publikationen, wie zum Beispiel der Veröffentlichung von @erb2012anthropogenic zu dem Auftreten von Säugetieren entlang des [Appalachian Trail](https://de.wikipedia.org/wiki/Appalachian_Trail) in den USA. Gibt es einen Unterschied im Auftreten von Schwarzbären und Rotfüchsen in Abhängigkeit von der Trailnutzung? Wie du erkennst, handelt es sich hier um Säulendiagramme als Mittelwerte und Standardfehler. Der t-Test versteckt sich hinter den Sternen, die du als eine mögliche Darstellung der p-Werte aus dem statistischen Testen kennst.

![*Vorrausichtliches Auftreten von Schwarzbären und Rotfüchsen im Appalachian Trail Korridor nach der Häufigkeit der Nutzung. Die Sterne stellen das Signifikanzniveau auf der Grundlage eines t-Tests mit zwei Stichproben unter der Annahme ungleicher Varianz dar (\*\*\* p \< 0.001).* Quelle: @erb2012anthropogenic](images/preface_t_test.png){#fig-utest-intro fig-align="center" width="100%"}

Woher kommen nun die Sterne über die Säulen und was soll ungleiche Varianzen bedeuten? Hier wollen wir dann mal einsteigen und verstehen was der t-Test macht und warum der t-Test für den zwei Gruppenvergleich immer noch der Goldstandard ist.

## Allgemeiner Hintergrund

Der t-Test ist *der* bedeutende Test, wenn es um das Verständnis der Algorithmen und Konzepte in der Statistik geht. Wir haben den t-Test schon genutzt um die Idee des statistischen Testens zu verstehen und wir werdend den t-Test auch im statistischen Modellieren wiedertreffen. Dort finden wir aber die Teststatistik des t-Tests. Wir werden dort nicht direkt den t-Test rechnen sondern das Konzept des t-Tests wieder nutzen. Natürlich hat der t-Test auch wieder verschiedene Namen, je nachdem welche Software du nutzen möchtest. Deshalb nochmal eine kurze Übersicht in der nachfolgenden Tabelle für R und Excel.

| Name | R | Excel |
|:--:|:--:|:--:|
| Student t-Test | Two Sample t-test | t-Test: Two-Sample Assuming Equal Variances |
| Welch t-Test | Welch Two Sample t-test | t-Test: Two-Sample Assuming Unequal Variances |

: Verschiedene Bezeichnungen für den t-Test je nach verwendeter Software. Es gibt natürlich noch weitere statistsiche Software mit noch anderen Namen. {#tbl-t-test-name}

Was macht also der t-Test? Der t-Test vergleicht die Mittelwerte zweier Gruppen miteinander. Das heißt wir haben zwei Gruppen, wie Hunde und Katzen, und wollen nun wissen wie sich die Sprungweiten der Hundeflöhe im Mittel von den Katzenflöhen unterscheiden. In R hätten wir damit einen Faktor mit zwei Leveln vorliegen. Darüber hinaus nimmt der t-Test implizit an, das unser Outcome $y$ normalverteilt ist. Die Varianzen können in beiden Gruppen gleich sein, dann sprechen wir von homogenen Varianzen oder Varianzhomogenität. Wir können den t-Test aber auch mit ungleichen Varianzen in beiden Gruppen rechnen, dann sprechen wir von heterogenen Varianzen oder eben Varianzheterogenität. Wir nutzen dann den Welch t-Test.

Nutze den Welch t-Test, wenn du unsicher über die Varianzen bist

:   Ich kann als Empfehlung nur aussprechen eigentlich immer den Welch t-Test zu nutzen. Sollten die Varianzen dennoch homogen sein, macht der Welch t-Test faktisch nichts schlechter als der Student t-Test. Dafür hat der Student t-Test wirklich Probleme mit ungleichen Varianzen.

Nun ist es so, das wir häufig einen t-Test verwenden müssen, wenn unsere Fallzahl $n$ sehr klein wird, da nicht-parametrische Methoden dann algorithmisch nicht mehr funktionieren. Hier hilft dann als wissenschaftliche Quelle die Arbeit von @rasch2007robust, die auch unter dem Titel [The Robustness of Parametric Statistical Methods](https://www.researchgate.net/profile/Dieter-Rasch/publication/279377987_The_Influence_of_Different_Shapes_of_Distributions_with_the_Same_First_four_Moments_on_Robustness/links/586b823108aebf17d3a58cbb/The-Influence-of-Different-Shapes-of-Distributions-with-the-Same-First-four-Moments-on-Robustness.pdf) frei verfügbar ist. Wichtig ist eigentlich nur das folgende Zitat aus dem Abstrakt der wissenschaftlichen Arbeit.

> *"All the results are that in most practical cases the two-sample t-test is so robust that it can be recommended in nearly all applications." --- @rasch2007robust*

Unter den meisten Bedingungen ist der t-Test robust gegen die Verletzung der Normalverteilungsannahme. Wenn wir Varianzheterogenität vorliegen haben, dann können wir ja den Welch t-Test rechnen. Aber auch hier ist es dann wichtig auf den konkreten Datenfall zu schauen. Mehr zu der Thematik gibt es auch von @rasch2011two in der Veröffentlichugn [The two-sample t test: pre-testing its assumptions does not pay off](https://link.springer.com/article/10.1007/s00362-009-0224-x) mit dem zentralen Zitat.

> *"As a result, we propose that it is preferable to apply no pre-tests for the t test and no t test at all, but instead to use the Welch-test as a standard test: its power comes close to that of the t test when the variances are homogeneous \[...\]."* --- @rasch2011two

Auch findet @de2010five in der Veröffentlichung [Five-point Likert items: t test versus Mann-Whitney-Wilcoxon](https://research.tudelft.nl/en/publications/five-point-likert-items-t-test-versus-mann-whitney-wilcoxon), dass wir uns nicht so richtig um die Normalverteilung sorgen müssen. Auch für Boniturnoten auf der Likertskala kann gut ein t-Test gerechnet werden.

> "*In conclusion, for five-point Likert items, the t test and wilcoxon mann whitney test generally have similar power, and researchers do not have to worry about finding a difference whilst there is none in the population."* --- @de2010five

## Theoretischer Hintergrund

Wenn du direkt aus dem statistischen Testen hierher kommst, dann ist die Berechnung des Student t-Tests für dich kein Problem. Das machen wir im statistischen Testen ja schon als Beispiel für die Teststatistik und den p-Wert. Hier kommen dann gleich fertige Funktionen in R, die dir alles in einem berechnen. Da ist es dann immer etwas schwerer nachzuvollziehen, was die einzelnen Schritte im statistischen Testen eigentlich sind.

Hier hilft dann das R Paket `{infer}` mit einer Schritt für Schritt Prozedur bei Durchführung des statistischen Testen. Dann machen wir es also einmal genau so, wie wir es schon kennen. Erst die Teststatistik $T_D$ der Daten berechenen. Dann die Verteilung der Nullhypothese der Grundgesamtheit bestimmen und dann beides zusammenbringen. Ein weiterer Vorteil von `{infer}` ist, dass wir die Funktionen sehr gut mit dem `|>` Operator nutzen können.

Als erstes berechnen wir die Teststatistik für den t-Test $T_D$ aus den beobachteten Daten. Dafür nutzen wir unsere Sprungweiten der Hunde- und Katzenflöhe. Mehr zu den Daten auch gleich weiter unten im Abschnitt zu den genutzen Daten im Kapitel.

```{r}
t_d <- fac1_tbl |> 
  specify(jump_length ~ animal) |> 
  calculate(stat = "t", order = c("dog", "cat"))
t_d
```

Mit der Teststatistik der Daten $T_D$ können wir so erstmal nichts anfangen. Wir brauchen noch einen vergleich zu der Verteilung der Nullhypothese. Daher bestimmen wir im Folgednen die Verteilung der Nullhypothese zu der wir unsere berechnete Teststatistik $T_D$ aus den Daten vergleichen wollen.

```{r}
set.seed(202506)
null_dist_data <- fac1_tbl |> 
  specify(jump_length ~ animal) |> 
  hypothesize(null = "independence") |> 
  generate(reps = 1000, type = "permute") |> 
  calculate(stat = "t", order = c("dog", "cat"))
```

Dann schauen wir uns einmal die Verteilung der Nullhypothese an. Wie wir sehen können, liegen die meisten Teststatistiken bei der Null. Macht ja auch Sinn, in der Nullhypothese haben wir ja auch Gleichheit zwischend Hunde- und Katzenflöhen angenommen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-theo-infer-01
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Verteilung der Nullhypothese in unseren Daten der Sprungweiten von Hunde- und Katzenflöhen. *[Zum Vergrößern anklicken]*"

visualize(null_dist_data) +
  theme_minimal() +
  labs(x = "Statistik", y = "Absolute Häufigkeit") 
```

Dann wollen wir noch die Fläche neben unsere berechnete Teststatistik $T_D$ um damit den $p$-Wert zu bestimmen.

```{r}
null_dist_data %>%
  get_p_value(obs_stat = t_d, direction = "two-sided")
```

Wie du dich noch erinnerst, ist der p-Wert die Fläche neben der berechneten Teststatistik $T_D$ zu den Verteilungsenden hin. Das wollen wir uns dann in der folgenden Abbildung nochmal anschauen, damit wir den Zusammenhang nochmal besser verstehen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-theo-infer-02
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Verteilung der Nullhypothese in unseren Daten der Sprungweiten von Hunde- und Katzenflöhen. Die rote Linie stellt die berechnete Teststatistik $T_D$ der Daten dar. Die Eingefärbte Fläche ist der p-Wert. *[Zum Vergrößern anklicken]*"

visualize(null_dist_data) +
  theme_minimal() +
  shade_p_value(obs_stat = t_d, direction = "two-sided",
                color = "#CC79A7") +
  labs(x = "Statistik", y = "Absolute Häufigkeit") 
```

Die Abfolge der Schritte erfolgt so nicht in der generischen Funktion `t.test()`, die wir dann in der Anwendung viel nutzen. Daher ist das R Paket `{infer}` nochmal gut um die Schritte der Berechnung sich klar werden zu lassen. Später nutzen wir dann nur eine Funktion, aber der Prozess ist im Hintergrund immer sehr ähnlich.

Eine detailliertere Einführung mit mehr Beispielen für die Nutzung vom [R Paket `{infer}`](https://infer.netlify.app/) findest du im Kapitel [Testen in R](#sec-test-R). Hier soll es dann bei der kurzen Gegenüberstellung bleiben.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, readxl,
               infer, see, tidyplots, rstatix, ggpubr,
               ggrepel, conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(rstatix::t_test)
set.seed(20221206)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

In den folgendne Abschnitten brauchen wir dann zwei Datensätze. Der erste Datensatz beschreibt Hunde- und Katzenflöhe, die springen und deren Sprungweite dann gemessen wurde. Wir haben hier verschiedene Flöhe vorliegen, die nur einmal springen. Wir können aber auch den Fall haben, dass wir uns wiederholt einen Floh anschauen. Der zweite Datensatz betrachtet Hundeflöhe, die vor der Fütterung und nach der Fütterung gesprungen sind.

#### Unabhängige Messungen {.unnumbered .unlisted}

Beginnen wir mit einem Datenbeispiel zu den Hunde- und Katzenflöhen. Was brauchen wir damit wir den t-Test rechnen können? Wir brauchen für den t-Test eine Spalte $y$ mit kontinuierlichen Zahlen und einer Spalte $x$ in dem wir einen Faktor mit zwei Leveln finden oder eben zwei Gruppen. Jedes Level steht dann für eine der beiden Gruppen. Das war es schon. Schauen wir uns nochmal den Datensatz `flea_dog_cat.xlsx` in @tbl-data-ttest an und überlegen, was wir dort auswählen können.

```{r}
fac1_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  mutate(animal = as_factor(animal)) |> 
  select(animal, jump_length)
```

Wir benötigen für den t-Test ein normalverteiltes $y$ womit wir uns hier erstmal für die kontinuierliche Sprungweite entscheiden. Dann brauchen wir einen Faktor mit zwei Leveln als $x$ und da bietet sich natürlich die beiden Gruppen Hunde- und Katzenflöhe an. Wir wählen daher mit `select()` die Spalte `jump_length` und `animal` aus dem Datensatz `flea_dog_cat.xlsx` aus. Wichtig ist, dass wir die Spalte `animal` mit der Funktion `as_factor()` in einen Faktor umwandeln. Anschließend speichern wir die Auswahl in dem Objekt `fac1_tbl`. Hier dann nochmal die Datentabelle.

```{r}
#| echo: false
#| message: false
#| tbl-cap: "Tabelle von sieben Hunde- und Katzenflöhen mit der Sprunglänge [cm]."
#| label: tbl-data-ttest

fac1_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  mutate(animal = as_factor(animal)) |> 
  select(animal, jump_length)

fac1_tbl |> kable(align = "c", "pipe")
```

Wir haben jetzt die Daten richtig vorbereiten und können uns nun mit dem t-Test beschäftigen. Bevor wir den t-Test jedoch rechnen können, müssen wir uns nochmal überlegen, was der t-Test eigentlich testet und uns die Daten einmal visualisieren. Klassischerweise wollen wir einen t-Test rechnen, da wir zwei Säulen in einem Barplot miteinander vergleichen wollen. Dafür schauen wir uns in @fig-barplot-ttest einmal den Barplot und den Boxplot für die Sprungweiten getrennt nach Hund und Katze an.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-barplot-ttest
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Visualisierung der Sprungweiten der Hunde- und Katzenflöhe. **(A)** Säulendiagramm oder Barplot mit den Mittelwerten und der Standardabweichung. **(B)** Boxplot mit den Median und dem IQR. *[Zum Vergrößern anklicken]*"

stat_tbl <- fac1_tbl |> 
  group_by(animal) |> 
  summarise(mean = mean(jump_length),
            sd = sd(jump_length),
            se = sd/sqrt(n()))

p1 <- ggplot(stat_tbl, aes(x = animal, y = mean, fill = animal)) + 
  theme_minimal() +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),
                width = 0.2) +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Hund", "Katze")) +
  scale_fill_okabeito()

p2 <- ggplot(fac1_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Hund", "Katze")) +
  scale_fill_okabeito()

p1 + p2 + 
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

Zum einen sind die Mittelwerte der Barplots nicht auf einer Höhe. Dies spricht schon mal dafür, dass wir hier einen Unterschied in den Sprungweiten vorliegen haben könnten. Schauen wir auch einmal auf die Boxplots. Wir sehen, dass sich die Boxen nicht überschneiden, ein Indiz für einen signifikanten Unterschied zwischen den beiden Gruppen. Im Weiteren liegt der Median in etwa in der Mitte der beiden Boxen. Die Whisker sind ungefähr gleich bei Hunden und Katzen. Ebenso sehen wir bei beiden Gruppen keine Ausreißer. Wir schließen daher nach der Betrachtung der beiden Abbildungen auf Folgendes:

1)  Die Sprungweite ist für beide Gruppen ist annähernd bzw. approximativ normalverteilt.
2)  Die Standardabweichungen und damit die Varianzen $s^2_{dog} = s^2_{cat}$ der beiden Gruppen sind gleich. Es liegt somit Varianzhomogenität vor.

Manchmal ist es etwas verwirrend, dass wir uns in einem Boxplot mit Median und IQR die Daten für einen t-Test anschauen. Immerhin rechnet ja ein t-Test mit den Mittelwerten und der Standardabweichung. Hier vergleichen wir etwas Äpfel mit Birnen. Deshalb in der @fig-dotplot-ttest der Dotplot mit dem Mittelwert und den entsprechender Standardabweichung als Fehlerbalken.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Dotplot der Sprungweiten [cm] von Hunden und Katzen zusammen mit dem Mittelwert und der Standardabweichung als Fehlerbalken."
#| label: fig-dotplot-ttest


ggplot(fac1_tbl, aes(x = animal, y = jump_length, 
                             fill = animal)) + 
  theme_minimal() +  
  geom_dotplot(binaxis = 'y', stackdir = 'center') + 
  stat_summary(fun.data = mean_sdl, fun.args = list(mult=1), 
               geom = "errorbar", color = "gray50", width = 0.1) +
  stat_summary(fun = "mean", geom="point", color="gray50", size = 5,
               shape = 23) +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Hund", "Katze")) +
  scale_fill_okabeito()


```

Wir nutzen aber später häufig den Boxplot zur Visualisierung der einzelnen Gruppen. Über den Boxplot können wir auch gut abschätzen, ob wir eine annähernde bzw. approximative Normalverteilung vorliegen haben. Häufig werden aber auch Barplots verlangt, so dass du hier relativ frei bist, was du verwendest. Am Ende ist es aber nicht so wichtig, ob wir eine Normalverteilung vorliegen haben oder nicht. Der t-Test ist recht robust gegen eine Abweichung. Viel wichtiger ist, das du eben Mittelwerte vergleichst. Also dann zum Beispiel mittlere Boniturnoten oder mittlere Anzahlen.

#### Abhängige Messungen {.unnumbered .unlisted}

Der t-Test erlaubt auch abhängige Daten zu analysieren. Das heißt wir haben die gleichen sieben Hundeflöhe wiederholt gemessen. Einmal haben wir einen Hundefloh gemessen bevor er was gegessen hat, also hungrig ist, und einmal nachdem der gleiche Floh sich satt gegessen hat. Daher haben wir hier abhängige oder verbundene Bebachtungen. Im folgenden einmal der Datensatz eingelesen im Wide-Format.

```{r}
#| message: false
paired_tbl <- read_excel("data/flea_dog_cat_repeated.xlsx") 
```

Wie du sehen kannst haben wir die sieben Flöhe wiederholt gemessen. Die Daten sind nicht im `tidy`-Format, da nicht jede Zeile nur eine Messunfg für eine Beobachtung beinhaltet. Das ändern wir dann einmal gleich in Long-Format.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Tabelle  der Sprunglängen [cm] von fünf Hundeflöhen zu zwei Zeitpunkten. Einmal wurde die Sprungweite mit den hungrigen Flöhen und einmal mit den gleichen satten Flöhen bestimmt."
#| label: tbl-data-ttest-paired-01

paired_tbl |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

Dann hier nochmal die Long-Formatvariante mit der Funktion `pivot_longer()`. Wir brauchen das Long-Format für die Auswertung in den unteren Abschnitten für das R Paket `{rstatix}`.

```{r}
paired_long_tbl <- paired_tbl |> 
  pivot_longer(cols = hungrig:satt,
               values_to = "jump_length",
               names_to = "trt") 
```

Manchmal ist es schwer zu verstehen, was jetzt wiederholt oder gepaart heißen soll. Deshalb hier nochmal die Visualiserung der Daten für die beiden Sprünge vor und nach der Fütterung. Ich habe die Messungen, die zusammengehören mit einer Linie verbunden. Dazu dann auch noch die jeweiligen IDs der Flöhe ergänzt.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Dotplot der Sprungweiten [cm] für Hundeflöhe in zwei verschiedenen Ernährungszuständen gemessen an zwei Zeitpunkten. Die Linien verbinden die Messung an dem gleichen Floh."
#| label: fig-example-paired

paired_tbl |> 
  pivot_longer(cols = hungrig:satt,
               values_to = "jump_length",
               names_to = "trt") |> 
ggplot(aes(trt, jump_length, fill = trt)) +
  theme_minimal() +
  geom_line(aes(group = id), color = "gray50") +
  geom_point(shape = 21, size = 4) +
  scale_fill_okabeito() +
  geom_text(aes(label = id), position = position_nudge(x = 0.05, y = -0.05)) +
  theme(legend.position = "none") +
  labs(x = "Ernährungszustand",
       y = "Sprungweite in [cm]")
```

## Hypothesen

Ohne eine Hypothese ist das Ergebnis eines statistischen Tests wie auch der t-Test nicht zu interpretieren. Wir berechnen eine Teststatistik und einen p-Wert. Beide statistischen Maßzahlen machen eine Aussage über die beobachteten Daten $D$ unter der Annahme, das die Nullhypothese $H_0$ gilt.

Wie lautet nun das Hypothesenpaar des t-Tests? Der t-Test vergleicht die Mittelwerte von zwei Gruppen. Die Nullhypothese ist auch die Gleichheitshypothese. Die Alternativehypothese haben wir auch als Unterschiedshypothese bezeichnet.

Daher ergibt sich für unser Beispiel mit den Sprungweiten für Hunde- und Katzenflöhen folgende Hypothesen. Die Nullhypothese sagt, dass die mittleren Sprungweite für die Hundeflöhe gleich der mittleren Sprungweite der Katzenflöhe ist. Die Alternativehypothese sagt aus, dass sich die mittlere Sprungweite von Hunde- und Katzenflöhen unterscheidet.

$$
\begin{aligned} 
H_0: \bar{y}_{dog} &= \bar{y}_{cat} \\  
H_A: \bar{y}_{dog} &\neq \bar{y}_{cat} \\   
\end{aligned}
$$

Wir testen grundsätzlich auf ein zweiseitiges $\alpha$-Niveau von 5%.

## Der t-Test

Dann wollen wir mal den t-Test berechnen. Den t-Test gibt es in drei Varianten, je nachdem, was wir für Fallzahlen oder aber Varianzen vorliegen haben. Wir können den t-Test wie immer mit der Hand berechnen oder aber in R sowie in Excel. Wir konzentrieren uns hier einmal auf die händsiche Berechnung für die Klausur und die Anwendung in R. Ich habe aber nochmal ein Video aufgenommen für die Anwendung des t-Tests in Excel. Manchmal gibt es ja den Notfall, dass nur Excel geht. Du müsstest die Formel des t-Test in der einfachen Form des Student t-Test gleich wiedererkennen, denn an dem t-Test erkläre ich die statistische Testtheorie und die Testentscheidung.

### Student t-Test für Varianzhomogenität

Fangen wir mit den einfacheren der beiden t-Tests an, dem Student t-Test. Der Student t-Test heißt so komisch, weil der Erfinder [William Sealy Gosset](https://de.wikipedia.org/wiki/William_Sealy_Gosset) zum Zeitpunkt der Entwicklung der Formel bei Guinness-Brauerei gearbeitet hat. Die Firma wollte aber nicht, dass seine Entdeckungen veröffentlicht werden. Also entschied sich Gosset unter einem Pseudonym seine Ideen zu präsentieren. Warum Gosset nun unbedingt Student als Pseudonym wählen musste, wird wohl sein Geheimnis bleiben. Deshalb der etwas wirre Name des t-Tests für Varianzhomogenität.

:::: panel-tabset
## Theoretisch

Die Formel des Student t-Test für Varianzhomogenität müsste dir noch aus dem Kapitel zur Testentscheidung bekannt vorkommen. Die Formel ist recht einfach, deshalb nutze ich den Student t-Test in dem Kapitel für die Einführung zur Teststatistik und dem p-Wert. Was brauchen wir nun für einen Student t-Test? Liegt ein normalverteiltes $y$ vor und sind die Varianzen für die beiden zu vergleichenden Gruppen homogen $s^2_{1} = s^2_{2}$, können wir einen Student t-Test rechnen. Wir nutzen dazu die folgende Formel des Student t-Tests.

$$
T_{D} = \cfrac{\bar{y}_{1}-\bar{y}_{2}}{s_{p} \cdot \sqrt{\cfrac{2}{n_{g}}}}
$$

mit

-   $T_D$, der berechneten Teststatistik der Daten $D$.
-   $\bar{y}_{1}$, dem Mittelwert der ersten Gruppe. Gerne nehme ich hier den numerisch *größeren* Mittelwert.
-   $\bar{y}_{2}$, dem Mittelwert der zweiten Gruppe. Gerne nehme ich hier den numerisch *kleineren* Mittelwert.
-   $s_{p}$, die gepoolte Standardabweichung aus den Standardabweichungen der $s_1$ und $s_2$ der beiden Gruppen.
-   $n_{g}$, die Gruppengröße der beiden Gruppen, die hier gleich sein muss. Daher ist $n_1 = n_2 = n_g$.

Dann nutzen wir die vereinfachte Formel für die gepoolte Standardabweichung $s_p$. Das hat den einfachen Grund, dass wir eben den t-Test nur in der Klausur händisch rechnen. Und hier machen wir uns es dann etwas einfacher.

$$
s_{p} = \cfrac{s_{1} + s_{2}}{2}
$$

mit

-   $s_1$, der Standardabweichung der ersten Gruppe.
-   $s_2$, der Standardabweichung der zweiten Gruppe.

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01_small.png){fig-align="center" width="100%"}

> Eigentlich wäre hier folgende Formel mit $s_{p} = \sqrt{\frac{1}{2} (s^2_{dog} + s^2_{cat})}$ richtig, da wir eigentlich die Varianzen mitteln müssten und dann die Wurzel ziehen. Aber auch hier erwischen wir einen Statistikengel um es etwas einfacher zu machen.
:::

Dann kannst du in den folgenden Tab auch dir einmal anschauen, wie die Berechnung des Student t-Tests für das Beispiel mit den Sprungweiten der Hunde- und Katzenflöhe ablaufen würde.

## Händisch

Wenn wir einen Student t-Test per Hand berechnen wollen, dann brauchen wir ja einiges an statistischen Maßzahlen. Hier erstmal nochmal die Formel, damit wir dann für Wissen, welche der statistischen Maßzahlen wir benötigen.

$$
T_{D} = \cfrac{\bar{y}_{dog}-\bar{y}_{cat}}{s_{p} \cdot \sqrt{\cfrac{2}{n_{g}}}}
$$

Wir wollen nun die Werte für $\bar{y}_{dog}$, $\bar{y}_{cat}$ und $s_{p}$ berechnen. Der Wert von $n_g$ ist ja mit sieben schon bekannt. Wir nutzen hierfür die folgenden Formeln aus dem Kapitel zur deskriptiven Statistik. Wichtig ist nochmal, dass wir annehmen, dass die Varianz der Hundeflöhe ungefähr gleich ist zu der Varianz der Katzenflöhe mit $s^2_{cat} = s^2_{dog}$.

Fangen wir einmal an mit den Mittelwerten der Sprungweiten der Hunde- und Katzenflöhe.

$$
\bar{y}_{dog} = \cfrac{5.7 + 8.9 + 11.8 + 5.6 + 9.1 + 8.2 + 7.6}{7} = 8.13
$$

$$
\bar{y}_{cat} = \cfrac{3.2 + 2.2 + 5.4 + 4.1 + 4.3 + 7.9 + 6.1}{7} = 4.74
$$

Dann berechnen wir jeweils die Varianz der Sprungweite der Hunde- und Katzenflöhe. Dafür brauchen wir jetzt den Mittelwert der Sprungweiten.

$$
s^2_{dog} = \cfrac{(5.7 - 8.13)^2 + (8.9 - 8.13)^2 + \cdots + (7.6 - 8.13)^2}{7-1} = 4.60
$$

$$
s^2_{cat} = \cfrac{(3.2 - 4.74)^2 + (2.2 - 4.74)^2 + \cdots + (6.1 - 4.74)^2}{7-1} = 3.62
$$

Wenn wir die Varianz haben, können wir auch gleich die Standardabweichungen der Sprungweite der Hunde- und Katzenflöhe berechnen. Wir brauchen die einzelnen Standardabweichungen, um diese dann im Anschluss zusammenzufassen (eng. *pool*).

$$
s_{dog} = \sqrt{4.60} = 2.14
$$

$$
s_{car} = \sqrt{3.62} = 1.90
$$

Jetzt können wir die gepoolte Standardabweichung aus den einzelnen Standardabweichungen der Sprungweiten der Hunde- und Katzenflöhe berechnen.

$$
s_{p} = \cfrac{2.14 + 1.90}{2} = 2.02 
$$

Abschließend setzen wir alle berechneten Werte in den Formel des Student t-Test ein. Wir können jetzt $s_p$ und die Mittelwerte sowie die Gruppengröße $n_g = 7$ in die Formel für den Student t-Test einfach einsetzen und die Teststatistik $T_{D}$ berechnen.

$$
T_{D} = \cfrac{8.13 - 4.74}{2.02 \cdot \sqrt{\cfrac{2}{7}}} = 3.14
$$

Wir erhalten eine Teststatistik $T_{D} = 3.14$ die wir mit dem kritischen Wert $T_{\alpha = 5\%} = 2.17$ vergleichen können. Da $T_{D} > T_{\alpha = 5\%}$ ist, können wir die Nullhypothese ablehnen. Wir haben ein signifikanten Unterschied zwischen den mittleren Sprungweiten von Hunde- und Katzenflöhen nachgewiesen.

## `{stats}`

Soweit für den Weg zu Fuß. Wir rechnen in der Anwendung keinen Student t-Test per Hand. Wir nutzen die Formel `t.test()`. Da wir den Student t-Test unter der Annahme der Varianzhomogenität nutzen wollen, müssen wir noch die Option `var.equal = TRUE` wählen. Die Funktion `t.test()` benötigt erst die das $y$ und $x$ in der Modellschreibweise mit den Namen, wie die beiden Variablen auch im Datensatz `fac1_tbl` stehen. In unserem Fall ist die Modellschreibweise dann `jump_length ~ animal`. Im Weiteren müssen wir noch den Datensatz angeben den wir verwenden wollen durch die Option `data = fac1_tbl`. Dann können wir die Funktion `t.test()` ausführen.

```{r}
t.test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = TRUE)
```

Wir erhalten eine sehr lange Ausgabe, die auch etwas verwirrend aussieht. Gehen wir die Ausgabe einmal durch. Ich gehe nicht auf alle Punkte ein, sondern konzentriere mich hier auf die wichtigsten Aspekte.

-   `t = 3.12528` ist die berechnete Teststatistik $T_{D}$. Der Wert unterscheidet sich leicht von unserem berechneten Wert. Der Unterschied war zu erwarten, wir haben ja auch die t-Test Formel vereinfacht.
-   `p-value = 0.0087684` ist der berechnete p-Wert $Pr(T_{D}|H_0)$ aus der obigen Teststatistik. Daher die Fläche rechts von der Teststatistik.
-   `95 percent confidence interval: 1.0253394 5.7460892` ist das 95% Konfidenzintervall. Die erste Zahl ist die untere Grenze, die zweite Zahl ist die obere Grenze.

Wir erhalten hier dreimal die Möglichkeit eine Aussage über die $H_0$ zu treffen. In dem obigen Output von R fehlt der kritische Wert $T_{\alpha = 5\%}$. Daher ist die berechnete Teststatistik für die Testentscheidung nicht verwendbar. Wir nutzen daher den p-Wert und vergleichen den p-Wert mit dem $\alpha$-Niveau von 5%. Da der p-Wert kleiner ist als das $\alpha$-Niveau können wir wie Nullhypothese ablehnen. Wir haben einen signifikanten Unterschied. Die Entscheidung mit dem Konfidenzintervall benötigt die Signifikanzschwelle. Da wir hier einen Mittelwertsvergleich vorliegen haben ist die Signifikanzschwelle gleich 0. Wenn die 0 im Konfidenzintervall liegt können wir die Nullhypothese nicht ablehnen. In unserem Fall ist das nicht der Fall. Das Konfidenzintervall läuft von 1.025 bis 5.75. Damit ist die 0 nicht im Konfidenzintervall enthalten und wir können die Nullhypothese ablehnen. Wir haben ein signifikantes Konfidenzintervall vorliegen.

Wie wir sehen fehlt der Mittelwertsunterschied als Effekt $\Delta$ in der Standardausgabe des t-Tests in R. Wir können den Mittelwertsunterschied selber berechnen oder aber die Funktion `tidy()` aus dem R Paket `{broom}` nutzen. Da der Funktion `tidy()` kriegen wir die Informationen besser sortiert und einheitlich wiedergegeben. Da `tidy` eine Funktion ist, die mit vielen statistischen Tests funktioniert müssen wir wissen was die einzelnen `estimate` sind. Es hilft in diesem Fall sich die Visualisierung der Daten anzuschauen und die Abbildung mit den berechneten Werten abzugleichen.

```{r}
t.test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = TRUE) |> 
  tidy() 
```

Wir erkennen als erstes den Mittelwertsunterschied zwischen den beiden Gruppen von $3.39cm$. Danach folgen die einzelnen Mittelwerte der Sprungweiten der Hunde und Katzenflöhe mit jeweils $8.13cm$ und $4.74cm$. Darauf folgt noch der p-Wert als `p.value` mit 0.00891 und die beiden Grenzen des Konfidenzintervalls \[1.03; 5.75\].

## `{rstatix}`

Ich würde eher die Implementierung in `{rstatix}` der Standardimplementierung in `{stats}` vorziehen, da wir hier die Daten über die Pipe in die Funktion weiterleiten können. Das macht es dann doch etwas einfacher. Am Ende kommt aber das gleiche raus, so dass ich die Funktion hier als Alternative stehen lasse. Das wir noch eine Datentabelle als Ausgabe kriegen, ist natürlich auch super schön.

```{r}
t_test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = TRUE) |> 
  select(group1, group2, p)
```

## Excel

Ich habe einmal ein Video eingesprochen indem ich nochmal zeige, wie du in Excel einen t-Test rechnen kannst. Ich empfehle grundsätzlich, wenn es schon Excel sein muss, immer den Welch t-Test zu rechnen. In Excel heißt dann der Welch t-Test `t-Test: Two-Sample Assuming Unequal Variances`. Ich kann es nicht so richtig empfehlen, alles in Excel zu rechnen. Die Möglichkeiten sind doch arg begrenz. Aber ich kann verstehen, dass es manchmal sein muss.

{{< video https://youtu.be/fA_7X_Rz83M >}}
::::

### Welch t-Test mit Varianzheterogenität

Jetzt stellt sich natürlich sofort die Frage, was ist, wenn ich nicht die gleichen Varianzen in den beiden Gruppen vorliegen habe oder aber eben mir nicht sicher bin, ob die Varianzen *wirklich* gleich sind? Dann kannst du auch den Welch t-Test nutzen. Der Welch t-Test verlangt keine Varianzhomogenität zwischen den beiden Gruppen. Es kann also die Varianz jeweils unterschiedliche sein. Auch kann die Fallzahl in den beiden Gruppen variieren, was manchmal auch sehr praktisch sein kann. Im Allgemeinen empfehle ich eigentlich immer als Standard, wie es auch in R ist, den Welch t-Test zu nutzen. Wenn die Varianzen homogen sind, dann verlierst du nicht viel. Auf der anderen Seite gewinnst du aber mehr, wenn die Varianzen heterogen sind.

::: panel-tabset
## Theoretisch

Der Welch t-Test ist auch in der Lage mit Varianzheterogenität umzugehen. Das heißt, wenn die Varianzen der beiden Gruppen nicht gleich sind. Eigentlich haben wir damit die generalisierte Formel für den t-Test vorliegen. Neben der unterschiedlichen Varianz erlaubt der Welch t-Test nämlich auch unterschiedliche Gruppengrößen zu verwenden. Wir haben dann folgende Formel vorliegen. Wir können nun wirklich jeden der drei statistischen Parameter, Mittelwert, Varianz und Fallzahl der Gruppe, entsprechend anpassen.

$$
T_{D} = \cfrac{\bar{y}_1 - \bar{y}_2}{\sqrt{\cfrac{s^2_1}{n_1} + \cfrac{s^2_2}{n_2}}}
$$

mit

-   $T_D$, der berechneten Teststatistik der Daten $D$.
-   $\bar{y}_{1}$, dem Mittelwert der ersten Gruppe. Gerne nehme ich hier den numerisch *größeren* Mittelwert.
-   $\bar{y}_{2}$, dem Mittelwert der zweiten Gruppe. Gerne nehme ich hier den numerisch *kleineren* Mittelwert.
-   $s^2_1$, der Varianz der ersten Gruppe.
-   $s^2_2$, der Varianz der zweiten Gruppe.
-   $n_{1}$, der Fallzahl der ersten Gruppe.
-   $n_{2}$, der Fallzahl der zweiten Gruppe.

Wir sehen, dass sich die Formel dadurch etwas ändert. Da wir nicht mehr annehmen, dass die Varianzen homogen und daher gleich sind, können wir auch keinen gepoolten Varianzschätzer $s_p$ berechnen. Die Varianzen gehen einzeln in die Formel des Welch t-Tests ein. Ebenso müssen die beiden Gruppen nicht mehr gleich groß sein. Statt einen Wert $n_g$ für die Gruppengröße können wir auch die beiden Gruppengrößen mit $n_1$ und $n_2$ separat angeben.

Wir könne auch kurz die Formel des Student t-Test aus der Formel des Welch t-Test herleiten. Wir müssen dazu annehmen, dass wir gleiche Fallzahlen $n_1 = n_2$ sowie die gleiche Varianz $s^2_1 = s^2_2$ in den beiden Gruppen vorliegen haben. Dann sehen wir, dass die Formel des Welch t-Test im Nenner in sich zusammenfällt und wir die einfache Formel des Student t-Test erhalten.

$$ 
\begin{align}
T_{D} &= \cfrac{\bar{y}_1 - \bar{y}_2}{\sqrt{\cfrac{s^2_1}{n_1} + \cfrac{s^2_1}{n_1}}}\\
&= \cfrac{\bar{y}_1 - \bar{y}_2}{\sqrt{\cfrac{s^2_1 + s^2_1}{n_1}}}\\
&= \cfrac{\bar{y}_1 - \bar{y}_2}{\sqrt{\cfrac{2 \cdot s^2_1}{n_1}}}\\
&= \cfrac{\bar{y}_1 - \bar{y}_2}{s_1 \cdot \sqrt{\cfrac{2}{n_1}}}
\end{align}
$$

Eine Sache muss ich noch erwähnen, wenn du den Welch t-Test nutzt, dann ändern sich auch die Freiheitsgrade für die t-Verteilung, wenn die Nullhypothese gilt, nach einer etwas schrägen Formel. Daher muss man noch bedenken, dass die Freiheitsgrade anders berechnet werden. Die Freiheitsgrade werden wie folgt mit einer etwas komplexeren Formel berechnet.

$$ 
df = \cfrac{\left(\cfrac{s^2_1}{n_1} + \cfrac{s^2_2}{n_2}\right)^2}{\cfrac{\left(\cfrac{s^2_1}{n_1}\right)^2}{n_1-1} + \cfrac{\left(\cfrac{s^2_2}{n_2}\right)^2}{n_2-1}}
$$

Was aber in der eigentlichen Anwendung nichts zur Sache tut. Deshalb gehen wir hier auch nicht tiefer darauf ein. In der Anwendung wird intern schon mit den angepassten Freiheitsgraden gerechnet und händisch nutzten wir diese Formel nicht, wenn wir den Welch t-Test ausrechnen.

## Händisch

Wenn wir einen Welch t-Test per Hand berechnen wollen, dann brauchen wir ja einiges an statistischen Maßzahlen. Hier erstmal nochmal die Formel, damit wir dann für Wissen, welche der statistischen Maßzahlen wir benötigen.

$$
T_{D} = \cfrac{\bar{y}_{dog} - \bar{y}_{cat}}{\sqrt{\cfrac{s^2_{dog}}{n_{dog}} + \cfrac{s^2_{cat}}{n_{cat}}}}
$$

Wir wollen nun die Werte für $\bar{y}_{dog}$, $\bar{y}_{cat}$ und die beiden Varianzen $s^2_{dog}$ sowie $s^2_{cat}$ berechnen. Die Fallzahlen für die beiden Gruppen sind ja mit jeweils sieben Flöhen schon bekannt. Wir nutzen hierfür die folgenden Formeln aus dem Kapitel zur deskriptiven Statistik. Wichtig ist nochmal, dass wir annehmen, dass die Varianz der Hundeflöhe **nicht** gleich der Varianz der Katzenflöhe mit $s^2_{cat} \neq s^2_{dog}$ ist.

Fangen wir einmal an mit den Mittelwerten der Sprungweiten der Hunde- und Katzenflöhe.

$$
\bar{y}_{dog} = \cfrac{5.7 + 8.9 + 11.8 + 5.6 + 9.1 + 8.2 + 7.6}{7} = 8.13
$$

$$
\bar{y}_{cat} = \cfrac{3.2 + 2.2 + 5.4 + 4.1 + 4.3 + 7.9 + 6.1}{7} = 4.74
$$

Dann berechnen wir jeweils die Varianz der Sprungweite der Hunde- und Katzenflöhe. Dafür brauchen wir jetzt den Mittelwert der Sprungweiten.

$$
s^2_{dog} = \cfrac{(5.7 - 8.13)^2 + (8.9 - 8.13)^2 + \cdots + (7.6 - 8.13)^2}{7-1} = 4.60
$$

$$
s^2_{cat} = \cfrac{(3.2 - 4.74)^2 + (2.2 - 4.74)^2 + \cdots + (6.1 - 4.74)^2}{7-1} = 3.62
$$

Abschließend setzen wir alle berechneten Werte in den Formel des Welch t-Test ein. Wir können jetzt die Varianzen der beiden Gruppen, die Mittelwerte sowie die Gruppengröße $n_{dog} = n_{cat} = 7$ in die Formel für den Student t-Test einfach einsetzen und die Teststatistik $T_{D}$ berechnen.

$$
T_{D} = \cfrac{8.13 - 4.74}{\sqrt{\cfrac{4.60}{7} + \cfrac{3.62}{7}}} = 3.13
$$

Wir erhalten eine Teststatistik $T_{D} = 3.13$ die wir mit dem kritischen Wert $T_{\alpha = 5\%} = 2.17$ vergleichen können. Da $T_{D} > T_{\alpha = 5\%}$ ist, können wir die Nullhypothese ablehnen. Wir haben ein signifikanten Unterschied zwischen den mittleren Sprungweiten von Hunde- und Katzenflöhen nachgewiesen.

## `{stats}`

Wir schauen uns gleich die Umsetzung in R an. Wir nutzen erneut die Funktion `t.test()` und zwar diesmal mit der Option `var.equal = FALSE`. Damit geben wir an, dass die Varianzen heterogen zwischen den beiden Gruppen sind. Wir nutzen in unserem Beispiel die gleichen Zahlen und Daten wie schon im obigen Student t-Test Beispiel.

```{r}
t.test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = FALSE)
```

Wir erhalten eine sehr lange Ausgabe, die auch etwas verwirrend aussieht. Gehen wir die Ausgabe einmal durch. Ich gehe nicht auf alle Punkte ein, sondern konzentriere mich hier auf die wichtigsten Aspekte.

-   `t = 3.1253` ist die berechnete Teststatistik $T_{D}$. Der Wert unterscheidet sich leicht von unserem berechneten Wert. Der Unterschied war zu erwarten, wir haben ja auch die t-Test Formel vereinfacht.
-   `p-value = 0.008906` ist der berechnete p-Wert $Pr(T_{D}|H_0)$ aus der obigen Teststatistik. Daher die Fläche rechts von der Teststatistik.
-   `95 percent confidence interval: 1.021587 5.749842` ist das 95% Konfidenzintervall. Die erste Zahl ist die untere Grenze, die zweite Zahl ist die obere Grenze.

Wir nutzen auch hier den p-Wert für unsere Testentscheidung. Daher vergleichen wir den p-Wert mit dem $\alpha$-Niveau von 5%. Da der p-Wert kleiner ist als das $\alpha$-Niveau können wir wie Nullhypothese ablehnen. Wir haben einen signifikanten Unterschied. Die Entscheidung mit dem Konfidenzintervall benötigt die Signifikanzschwelle. Wenn die 0 im Konfidenzintervall liegt können wir die Nullhypothese nicht ablehnen. Das Konfidenzintervall läuft von 1.022 bis 5.75. Damit ist die 0 nicht im Konfidenzintervall enthalten und wir können die Nullhypothese ablehnen. Wir haben ein signifikantes Konfidenzintervall vorliegen.

Wir sehen das viele Zahlen nahezu gleich zum Student t-Test sind. Das liegt auch daran, dass wir in unserem Daten keine große Abweichung von der Varianzhomogenität haben. Wir erhalten die gleichen Aussagen wie auch schon im Student t-Test. Schauen wir uns nochmal die Ausgabe der Funktion `tidy()` zum Abschluss an.

```{r}
t.test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = FALSE) |> 
  tidy() 
```

## `{rstatix}`

Ich würde eher die Implementierung in `{rstatix}` der Standardimplementierung in `{stats}` vorziehen, da wir hier die Daten über die Pipe in die Funktion weiterleiten können. Das macht es dann doch etwas einfacher. Am Ende kommt aber das gleiche raus, so dass ich die Funktion hier als Alternative stehen lasse. Das wir noch eine Datentabelle als Ausgabe kriegen, ist natürlich auch super schön.

```{r}
t_test(jump_length ~ animal, 
       data = fac1_tbl, var.equal = FALSE) |> 
  select(group1, group2, p)
```

## Excel

Ich habe einmal ein Video eingesprochen indem ich nochmal zeige, wie du in Excel einen t-Test rechnen kannst. Ich empfehle grundsätzlich, wenn es schon Excel sein muss, immer den Welch t-Test zu rechnen. In Excel heißt dann der Welch t-Test `t-Test: Two-Sample Assuming Unequal Variances`. Ich kann es nicht so richtig empfehlen, alles in Excel zu rechnen. Die Möglichkeiten sind doch arg begrenz. Aber ich kann verstehen, dass es manchmal sein muss.

{{< video https://youtu.be/fA_7X_Rz83M >}}
:::

Wir sehen hier etwas besser, dass es kaum Abweichungen gibt. Alles egal? Nicht unbedingt. Das Problem ist eher *das Erkennen* von Varianzheterogenität in sehr kleinen Datensätzen. Kleine Datensätze meint Datensätze unter 30 Beobachtungen je Gruppe. Erst aber dieser Anzahl lassen sich unverzerrte Histogramme zeichnen und so aussagekräftige Abschätzungen der Varianzhomogenität oder Varianzheterogenität treffen.

Für das Erkennen von Normalverteilung und Varianzheterogenität werden häufig so genannte Vortest empfohlen. Aber auch hier gilt, bei kleiner Fallzahl liefern die Vortests keine verlässlichen Ergebnisse. In diesem Fall ist weiterhin die Beurteilung über einen Boxplot sinnvoller. Du findest hier mehr Informationen im Kapitel zum [Pre-Test oder Vortest](#sec-pretest).

### Verbundener t-Test mit abhängigen Beobachtungen

Es kommt häufiger mal vor, dass wir an dem *gleichen* Tier oder der *gleichen* Pflanze Messungen durchführen. Dann haben wir es mit abhängigen oder verbundenen Beobachtungen zu tun. Hier müssen wir dann zu einem anderen t-Test greifen, nämlich den t-Test für abhängige Beobachtungen. Wir nennen den t-Test auch gerne gepaarten t-Test (eng. *paired t test*).

::: panel-tabset
## Theoretisch

Was ist nun der theoretische Hintergrund des gepaarten t-Test? Wir brauchen dafür zwei Spalten, die jeweils zwei Messungen am gleichen Tier oder an der gleichen Pflanze darstellen. Dann bilden wir die Differenz der Messwerte für die erste Messung sowie der zweiten Messung und nennen diesen Wert dann $\Delta$ (deu. *Delta*). Wir rechnen den Test also auf der deskriptiven Statistik der Differenzen. Es ergeben sich dann die folgenden Hypothesenpaare für den gepaarten t-Test.

Nullhypothese

:   Wir testen, ob der Mittelwert der Differenzen gleich Null ist. $$\bar{\Delta} = 0$$

Alternativhypothese

:   Als Alternative ist der Mittelwert der Differenzen ungleich Null. $$\bar{\Delta} \neq 0$$

Dann brauchen wir natürlich auch eine Datentabelle mit der ID der Beobachtung, damit auch klar wird, dass wir eine Beobachtung zweimal messen. Dann kommen die beiden Messungen und anschließend die berechnete Differenz der beiden Messungen. Zwischen den Messungen kann natürlich beliebig viel Zeit vergehen. Je länger der Zeitraum, desto eher könntest du von unabhängigen Beobachtungen ausgehen.

| ID Beobachtung | Messung 1 | Messung 2 | Differenz $\boldsymbol{\Delta}$ |
|----------------|:---------:|:---------:|:-------------------------------:|
| 1              | $y_{11}$  | $y_{21}$  |  $\Delta_1 = y_{11} - y_{21}$   |
| 2              | $y_{12}$  | $y_{22}$  |  $\Delta_2 = y_{12} - y_{22}$   |
| 3              | $y_{13}$  | $y_{23}$  |  $\Delta_3 = y_{13} - y_{23}$   |
| $\vdots$       | $\vdots$  | $\vdots$  |            $\vdots$             |
| n              | $y_{1n}$  | $y_{2n}$  |  $\Delta_n = y_{1n} - y_{2n}$   |
|                |           |           |         $\bar{\Delta}$          |

: Beispielhafter Datensatz für einen gepaarten t-Test mit bis zu $n$ Beobachtungen. Jede Beobachtung wird zweimal gemessen und anschließend wird die Differenz als deskriptive Statistik für den Test berechnet. {#tbl-t-test-verbunden}

Wir nutzen folgende Formel für den gepaarten t-Test für verbundene Stichproben. Wir teilen als deen Mittelwert der Differenzen durch die Standardabweichung der Differenzen. Dann multiplizieren wir mit der Anzahl der Beobachtungen.

$$
T_{D} = \sqrt{n}\cdot\cfrac{\bar{\Delta}}{s_{\Delta}}
$$

mit

-   $T_D$, der berechneten Teststatistik der Daten $D$.
-   $\bar{\Delta}$, dem Mittelwert der Differenzen $\Delta$.
-   $s_{\Delta}$, der Standardabweichung der Differenzen $\Delta$.

Den Wert der Teststatistik aus den Daten $T_{D}$ können wir dann wie immer mit einem kritischen Wert mit $T_{\alpha = 5\%}$ vergleichen. Diesen Wert $T_{\alpha = 5\%}$ erhälst du dann in der Klausur oder aber ist den Anwendungsprogrammen bekannt. Da musst du dir in der Anwendung keine Gedanken zu machen.

## Händisch

Im folgenden Datenbeispiel in @tbl-data-ttest-paired haben wir eine verbundene Stichprobe. Das heißt wir haben nicht zehn Flöhe gemessen sondern fünf Flöhe jewiels zweimal. Einmal haben wir die Sprungweite der Flöhe im ungefütterten Zustand `hungrig` und einmal im gefütterten Zustand `satt` gemessen. Wir wollen nun wissen, ob der Fütterungszustand Auswirkungen auf die Sprungweite in \[cm\] hat. Hier dann nochmal die Tabelle als Erinnerung.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Tabelle  der Sprunglängen [cm] von fünf Flöhen zu zwei Zeitpunkten. Einmal wurde die Sprungweite ungefüttert und einmal gefüttert bestimmt."
#| label: tbl-data-ttest-paired

paired_raw_tbl <- tibble(hungrig = c(5.2, 4.1, 3.5, 3.2, 4.6),
                         satt = c(6.1, 5.2, 3.9, 4.1, 5.3),
                         diff = satt - hungrig) 

paired_mean <- mean(paired_raw_tbl$diff)
paired_sd <- round(sd(paired_raw_tbl$diff), 2)
paired_t <- round(sqrt(5) * paired_mean/paired_sd, 2)

paired_raw_tbl |> 
  kable(align = "c", "pipe")

```

Als erstes brauchen wir den Mittelwert der Differenzen. Daher berechnen wir einmal den Mittelwert der Differenzen $\Delta$ wie folgt aus.

$$
\bar{\Delta} = \cfrac{0.9 + 1.1 + 0.4 + 0.9 + 0.7}{5} = 0.8
$$

Und dann brauchen wir auch einmal die Standardabweichung der einzelnen Differenzen zu dem Mittelwert der Differenzen $\bar{\Delta}$. Wir rechnen natürlich die Standardabweichung als Wurzel der Varianz aus. Deshalb die Wurzel hier in der Formel.

$$
s_{\Delta} = \sqrt{\cfrac{(0.9 - 0.8)^2 + (1.1 - 0.8)^2 + \cdots + (0.7 - 0.8)^2}{n-1}}
$$

Wir können jetzt $\bar{\Delta}$ als Mittelwert der Differenzen die Standardabweichung der Differenzen $s_{\Delta}$ in die Formel für den t-Test für verbundene Beobachtungen einsetzen.

$$
T_{D} = \sqrt{5}\cfrac{`r paired_mean`}{`r paired_sd`} = `r paired_t`
$$

Jetzt brauchen wir natürlich noch einen kritischen Wert $T_{\alpha = 5\%}$ und der wäre in diesem Fall gleich $`r round(qt(0.95, (5 + 5 - 2), lower.tail = TRUE), 2)`$. Damit können wir dann die Nullhypothese ablehnen, dass wir keinen Effekt der Behandlung vorliegen haben. Es macht einen Unterschied, wie wir die Flöhe gefüttert haben. Da das $\Delta$ positiv ist, können wir auch sagen, dass gefütterte Flöhe weiter springen als nicht gefütterte Flöhe.

## `{stats}`

Dann haben wir hier einmal unseren kleinen Datensatz, den wir für unseren gepaarten t-Test nutzen wollen. Wir brauchen die `id` um später nochmal die Daten besser darstellen zu können. Ich möchte nämlich in den Ergebnisabbildungen weiter unten die Beobachtungen miteinander verbinden.

Um den die Funktion `t.test()`in R mit der Option `paired = TRUE` für den paired t-Test zu nutzen, müssen wir die Daten jeweils als Vektor in die Funktion übergeben. Daher als erstes die Spalte mit den Informationen zu den ungefütterten Flöhen und dann die Spalte mit der Information zu den gefütterten Flöhen. Wir wollen nun wissen, ob der Fütterungszustand nun eine Auswirkungen auf die Sprungweite in \[cm\] hat.

```{r}
t.test(paired_tbl$satt, paired_tbl$hungrig, 
       paired = TRUE)
```

Die Ausgabe des paired t-Test ähnelt stark der Aussage des Student t-Test. Wir erhalten ebenfalls den wichtigen p-Wert mit 0.0025 sowie das 95% Konfidenzintervall mit \[0.47; 1.13\]. Zum einen ist $0.0025 < \alpha$ und somit können wir die Nullhypothese ablehnen, zum anderen ist auch die 0 nicht mit in dem Konfidenzintervall, womit wir auch hier die Nullhypothese ablehnen können.

## `{rstatix}`

Ich würde eher die Implementierung in `{rstatix}` der Standardimplementierung in `{stats}` vorziehen, da wir hier die Daten über die Pipe in die Funktion weiterleiten können. Das macht es dann doch etwas einfacher. Am Ende kommt aber das gleiche raus, so dass ich die Funktion hier als Alternative stehen lasse. Das wir noch eine Datentabelle als Ausgabe kriegen, ist natürlich auch super schön.

```{r}
t_test(jump_length ~ trt, data = paired_long_tbl, 
       paired = TRUE) |> 
  select(group1, group2, p)
```
:::

## Ergebnisse mit `{tidyplots}`

Häufig wollen wir nicht nur den p-Wert aus einem t-Test berichten sondern natürlich auch gleich die richtige Abbildung dazu haben. Hier gibt es mit dem R Paket `{tidyplots}` eine gute Möglichkeit. Das R Paket verbindet dabei die Funktionalität von `{ggplot}` und `{ggpubr}`. Dabei bleibt es aber dann sehr einfahc zu bedienen. Insbesondere in dem Fall, dass du nur zwei Gruppen in einem t-Test miteinander vergleichen willst.

::: callout-tip
## Alternativen zu `{tidyplots}`

Das R Paket `{ggpubr}` bietet auch noch andere Alternativen für die Darstellung von statistischen Vergleichen in deinen Daten unter [ggpubr: ‘ggplot2’ Based Publication Ready Plots](https://rpkgs.datanovia.com/ggpubr/). Vielleicht findest du da auch noch eine bessere Abbildung als hier. Da wir hier sehr viel ähnliches haben, bleibe ich bei `{tidyplots}`.
:::

Neben den p-Werten, die ich hier mit der Funktion `add_test_pvalue()` ergänze kannst du auch Sterne mit der Funktion `add_test_asterisks()` nutzen. Das liegt dann ganz bei dir. Es gibt auch die Möglichkeit nicht signifikante Ergebnisse auszublenden. Mehr dazu findest du dann auf der [Hilfeseite zu den statistischen Vergleichen in `{tidyplots}`](https://jbengler.github.io/tidyplots/articles/Visualizing-data.html#statistical-comparison). Ich zeige hier dir nur die Standardanwendung. Wichtig ist auch zu wissen, dass wir immer einen Welch t-Test rechnen, also immer für die Varianzheterogenität adjustieren. Das ist auch eigentlich die bessere Variante als der Student t-Test. Häufig ist es sehr schwer in kleinen Fallzahlen abzuschätzen wie die Varianzen in den Gruppen sind. Dann lieber gleich richtig adjsutieren und auf der sicheren Seite sein.

::: panel-tabset
## Barplot

Die Standardabbildung ist sicherlich der Barplot zusammen mit der Standardabweichung als Fehlerbalken. Dann habe ich noch die einzelnen Beobachtungen ergänzt. Die Klammer über den beiden Säulen gibt den Vergleich an und die Zahl ist der p-Wert aus einem Welch t-Test. Wir sehen hier, dass sich die beiden Floharten in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-barplot-ttest
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Einfaktorieller Barplot für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem Welch t-Test."

tidyplot(data = fac1_tbl, 
         x = animal, y = jump_length, color = animal) |> 
  add_data_points() |>
  add_mean_bar(alpha = 0.4, width = 0.4) |> 
  add_sd_errorbar(width = 0.2) |> 
  add_test_pvalue(method = "t_test", hide_info = TRUE) |>
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Flohart") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  rename_x_axis_labels(new_names = c("dog" = "Hund", "cat" = "Katze")) |> 
  adjust_size(width = NA, height = NA) 
```

## Boxplot

Es gibt auch gute Gründe ienmal den Boxplot zu wählen, wenn wir etwas besser die Verteilung der Sprungweiten darstellen wollen. Ich habe dann noch die einzelnen Beobachtungen ergänzt. Die Klammer über den beiden Säulen gibt den Vergleich an und die Zahl ist der p-Wert aus einem Welch t-Test. Wir sehen hier, dass sich die beiden Floharten in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-boxplot-ttest
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Einfaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem Welch t-Test."

tidyplot(data = fac1_tbl, 
         x = animal, y = jump_length, color = animal) |> 
  add_data_points() |>
  add_boxplot(alpha = 0.4, box_width = 0.3) |> 
  add_test_pvalue(method = "t_test", hide_info = TRUE) |> 
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Flohart") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  rename_x_axis_labels(new_names = c("dog" = "Hund", "cat" = "Katze")) |> 
  adjust_size(width = NA, height = NA) 
```

## Gepaarter Dotplot

Am Ende wollen wir uns dann nochmal den gepaarten t-Test anschauen. Hier ist dann die Abbildung realtiv einfach. Wir können da die Daten `paired_tbl` aus dem gepaarten t-Test nutzen nachdem wir die Daten in das Long-Format überführt haben. Etwas schwieriger ist dann der p-Wert, den p-Wert müssen wir dann erst selber errechnen und dann ergänzen. Hier nutzen wir dann den gepaarten Datensatz in dem Long-Format.

Jetzt können wir den gepaarten t-Test rechnen und zwar aus dem R Paket `{rstatix}`. Dann müssen wir noch alles so umbauen, dass wir die Informationen dann in `{tidyplots}` auch nutzen können.

```{r}
stats_tbl <- paired_long_tbl |> 
  arrange(id) |> 
  t_test(jump_length ~ trt, paired = TRUE) |> 
  add_significance() |> 
  add_xy_position()
```

Wir nutzen hier die Funktion `stat_pvalue_manual()` um händisch die p-Werte zu den Dotplot mit den Mittelwert und Standardabweichung zu ergänzen. Die Verbindungen zwischen den Beobachtungen haben wir dann durch `add_line()` erzeugt. Ich gebe zu, dass ist etwas komplizierter. Wenn du dann die Sterne haben willst, dann musst due das Label auf `"p.signif"` setzen. Dann werden statt der p-Werte `"p"` dir die Sterne `*` angezeigt. Wir sehen hier, dass sich die beiden Fütterungslevel in den Sprungweiten signifikant unterscheiden. Der p-Wert ist kleiner als das Signifikanzniveau $\alpha$ gleich 5%.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-tidyplot-barplot-ttest-paired
#| fig-align: center
#| fig-height: 3
#| fig-width: 3.5
#| fig-cap: "Dotplot mit Mittelwert und Standardabweichung für die Sprungweiten in [cm] gruppiert nach den Floharten mit mehr Optionen und angepassten Beschriftungen sowie den p-Wert aus einem paired t-Test. Gleiche Messungen an gleichen Flöhen sind mit einer Linie verbunden."

paired_long_tbl |> 
  tidyplot(x = trt, y = jump_length, color = trt, fill = NA) |> 
  add_line(group = id, color = "grey") |> 
  add_data_points() |>
  add_mean_dash(width = 0.2) |> 
  add_sd_errorbar(width = 0.2) |> 
  add(stat_pvalue_manual(stats_tbl, size = 7/.pt, label = "p",
                         bracket.nudge.y = 0.1)) |> 
  remove_legend() |> 
  adjust_font(fontsize = 9) |>
  adjust_x_axis_title("Fütterung") |>
  adjust_y_axis_title("Sprungweite in [cm]") |> 
  reorder_x_axis_labels("unfed", "fed") |>  
  rename_x_axis_labels(new_names = c("fed" = "gefüttert", "unfed" = "ungefüttert")) |>
  adjust_size(width = NA, height = NA) 
```
:::

## Freiheitsgrade

Der t-Verteilung der Teststatistiken des t-Tests verhält sich nicht wie eine [klassische Normalverteilung](#sec-distribution), die durch den Mittelwert und die Standardabweichung definiert ist. Die t-Verteilung ist nur durch die Freiheitsgrade definiert. Der Freiheitsgrad (eng. *degree of freedom*, abk. *df*) in einem t-Test mit zwei Gruppen mit den Fallzahlen $n_1$ und $n_2$ ist gegeben durch $df = n_1 + n_2 -2$. Damit beschreiben die Freiheitsgrade grob die gesamte Fallzahl in einen Datensatz mit nur zwei Gruppen. Je mehr Fallzahl in den beiden Gruppen desto großer der Freiheitsgrad eines t-Tests.

Die @fig-ttest-06 visualisiert diesen Zusammenhang von Freiheitsgraden und der Form der t-Verteilung. Je kleiner die Freiheitsgrade und damit die Fallzahl in unseren beiden Gruppen, desto weiter sind die Verteilungsschwänze. Wie du sehen kannst, reicht die rote Verteilung mit einem Freiheitsgrad von $df = 10$ viel weiter nach links und rechts als die anderen Verteilungen mit niedrigeren Freiheitsgraden. Daher benötigen wir auch größere $T_{D}$ Werte um ein signifikantes Ergebnis zu erhalten. Denn die Fläche unter der t-Verteilung ist immer gleich 1 und somit wandert dann der kritische Wert $T_{\alpha = 5\%}$ immer weiter nach außen. Das macht ja auch Sinn, wenn wir wenige Beobachtungen vorliegen haben, dann brauchen wir größere Werte der Teststatistik um an einen signifikanten Effekt glauben zu können.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-ttest-06
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Die t-Verteilung für drei beispielhafte Freiheitsgrade. Je größer die Freiheitsgrade und damit die Fallzahl, desto näher kommt die t-Verteilung einer Normalverteilung nahe. Bei einer geringeren Fallzahl, müssen damit größere $T_{D}$ Werte erreicht werden um eine signifikantes Ergebnis zu erhalten, da mehr Fläche nach außen wandert. *[Zum Vergrößern anklicken]*"


ggplot(data.frame(x = c(-3.25, 3.25)), aes(x)) +
  theme_minimal() +
  geom_vline(xintercept = c(0)) + 
  geom_hline(yintercept = c(0)) + 
  stat_function(fun = dnorm, linewidth = 1, args = list(mean = 0, sd = 1.5), 
                xlim = c(-8.25, 8.25), color = "#E89F00") +
  stat_function(fun = dnorm, xlim = c(-8.25, 8.25), args = list(mean = 0, sd = 1.5), 
                geom = "area", fill = "#E89F00", alpha = 0.25) +
  annotate("text", x = -2.8, y = 0.25, label = "df = 30", size = 8,
           color = "#E89F00") +
  geom_curve(x = -2.8, y = 0.24, xend = -0.6, yend = 0.21,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = 0.3, color = "black", alpha = 0.3) +
  stat_function(fun = dnorm, linewidth = 1, args = list(mean = 0, sd = 2), 
                xlim = c(-8.25, 8.25), color = "#58B4E9") +
  stat_function(fun = dnorm, xlim = c(-8.25, 8.25), args = list(mean = 0, sd = 2), 
                geom = "area", fill = "#58B4E9", alpha = 0.25) +
  annotate("text", x = 3, y = 0.175, label = "df = 20", size = 8,
           color = "#58B4E9") +
  geom_curve(x = 3, y = 0.165, xend = 1.2, yend = 0.14,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = -0.3, color = "black", alpha = 0.3) +
  stat_function(fun = dnorm, linewidth = 1, args = list(mean = 0, sd = 3), 
                xlim = c(-8.25, 8.25), color = "#CC89A8") +
  stat_function(fun = dnorm, xlim = c(-8.25, 8.25), args = list(mean = 0, sd = 3), 
                geom = "area", fill = "#CC89A8", alpha = 0.25) +
  annotate("text", x = 5, y = 0.1, label = "df = 10", size = 8,
           color = "#CC89A8") +
  geom_curve(x = 5, y = 0.09, xend = 4.1, yend = 0.035,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = -0.3, color = "black", alpha = 0.3) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = "", y = "") 
```

## Referenzen {.unnumbered}
