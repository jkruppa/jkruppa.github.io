```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

# Der t-Test {#sec-ttest}

*Letzte Änderung am `r format(fs::file_info("stat-tests-ttest.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

::: callout-note
## Was macht der t-Test?

Der t-Test vergleicht zwei Mittelwerte, gewichtet nach der Standardabweichung und der Fallzahl, miteinander. Etwas statistisch genauer vergleicht der t-Test die Parameter zweier Normalverteilungen miteinander.
:::

::: callout-tip
## Einführung in den t-Test per Video

Du findest auf YouTube [Der Two Sample t-Test erklärt](https://youtu.be/iECcenEDzOM) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Der t-Test ist *der* bedeutende Test, wenn es um das Verständnis der Algorithmen und Konzepte in der Statistik geht. Wir haben den t-Test schon genutzt um die Idee des statistischen Testens zu verstehen und wir werdend den t-Test auch im statistischen Modellieren wiedertreffen. Dort finden wir aber die Teststatistik des t-Tests. Wir werden dort nicht direkt den t-Test rechnen sondern das Konzept des t-Tests wieder nutzen.

Was macht also der t-Test? Der t-Test vergleicht die Mittelwerte zweier Gruppen miteinander. Das heißt wir haben zwei Gruppen, wie Hunde und Katzen, und wollen nun wissen wie sich die Sprungweiten der Hundeflöhe im Mittel von den Katzenflöhen unterscheiden. In R hätten wir damit einen Faktor mit zwei Leveln vorliegen. Darüber hinaus nimmt der t-Test implizit an, das unser Outcome $y$ normalverteilt ist. Die Varianzen können in beiden Gruppen gleich sein, dann sprechen wir von homogenen Varianzen oder Varianzhomogenität. Wir können den t-Test aber auch mit ungleichen Varianzen in beiden Gruppen rechnen, dann sprechen wir von heterogenen Varianzen oder eben Varianzheterogenität.

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Wir nutzen folgende Formel in der Klausur wenn ein Zweistichproben t-Test verlangt wird:

$$
T_{calc} = \cfrac{\bar{y}_1-\bar{y}_2}{s_{p} \cdot \sqrt{\cfrac{2}{n_{group}}}}
$$

Wir nutzen folgende Formel in der Klausur für einen gepaarten t-Test:

$$
T_{calc} = \sqrt{n}\cfrac{\bar{d}}{s_d}
$$

Wenn nicht anders in der Klausuraufgabe angegeben dann ist $T_{\alpha = 5\%} = 1.96$ oder $\alpha = 5\%$.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
pacman::p_load(tidyverse, magrittr, broom, readxl)
##
set.seed(20221206)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten und Modell für den t-Test

Wichtig ist, dass wir schon jetzt die Modellschreibweise lernen um die Daten später richtig in R nutzen zu können. Wir werden die Modellschreibweise immer wieder sehen. Die Modellschreibweise ist die Art und Weise wie wir in R eine Abhängigkeit beschreiben. Wir brauchen dieses Konzept in den folgenden Kapiteln. In R heißt `y ~ x` auch `formula`, also eine Formelschreibweise.

![Modellschreibweise $y$ hängt ab von $x$. Das $y$ repräsentiert eine Spalte im Datensatz und das $x$ repräsentiert ebenso eine Spalte im Datensatz. Wir brauchen also zwei Variablen $y$ und $x$, die natürlich nicht so heißen müssen.](images/statistical_modeling_0.png){#fig-ttest-0 fig-align="center" width="20%"}

[Etwas unbefriedigend, dass der t-Test nur **zwei** Gruppen miteinander Vergleichen kann. Mehr Gruppen gehen in der ANOVA im @sec-anova]{.aside}

Was brauchen wir damit wir den t-Test in R rechnen können? Später in der Anwendung nutzt du ja nur die Implementierung des t-Tests in R. Wir rechnen ja unsere Auswertung nicht per Hand. In R brauchen wir für den t-Test eine Spalte $y$ mit kontinuierlichen Zahlen und einer Spalte $x$ in dem wir einen Faktor mit zwei Leveln finden. Jedes Level steht dann für eine der beiden Gruppen. Das war es schon. Schauen wir uns nochmal den Datensatz `flea_dog_cat.xlsx` in @tbl-data-ttest an und überlegen, wie wir das realisieren können.

```{r}
#| echo: false
#| message: false
#| tbl-cap: Tabelle  der Sprunglängen [cm], Anzahl an Flöhen, Boniturnote sowie der Infektionsstatus von Hunden und Katzen.
#| label: tbl-data-ttest

data_tbl <- read_excel("data/flea_dog_cat.xlsx") %>% 
  mutate(animal = as_factor(animal))

data_tbl %>% kable(align = "c", "pipe")
```

In @fig-ttest-1 sehen wir einmal den Zusammenhang zwischen den Schreibweise $y \sim x$ und den beiden Variablen `jump_length` als $y$ und `animal` als $x$ aus dem Datensatz `flea_dog_cat.xlsx`. Wir haben also die `formula` Schreibweise in R als `jump_length ~ animal`.

![Modellschreibweise bzw. `formula`-Schreibweise in R. Die Variable $y$ hängt ab von $x$ am Beispiel des Datensatzes flea_dog_cat.xlsx mit den beiden Variablen jump_length als $y$ und animal als $x$.](images/statistical_modeling_1.png){#fig-ttest-1 fig-align="center" width="70%"}

Wir benötigen für den t-Test ein normalverteiltes $y$ und einen Faktor mit zwei Leveln als $x$. Wir nehmen daher mit `select()`die Spalte `jump_length` und `animal` aus dem Datensatz `flea_dog_cat.xlsx`. Wichtig ist, dass wir die Spalte `animal` mit der Funktion `as_factor()` in einen Faktor umwandeln. Anschließend speichern wir die Auswahl in dem Objekt `data_tbl`.

```{r}
data_tbl <- read_excel("data/flea_dog_cat.xlsx") %>% 
  mutate(animal = as_factor(animal)) %>% 
  select(animal, jump_length)

data_tbl
```

Wir haben jetzt die Daten richtig vorbereiten und können uns nun mit dem t-Test beschäftigen. Bevor wir den t-Test jedoch rechnen können, müssen wir uns nochmal überlegen, was der t-Test eigentlich testet und uns die Daten einmal visualisieren.

## Visualiserung der Daten

Bevor wir einen statistischen Test rechnen, wollen wir uns erstmal die Daten, die dem Test zugrunde liegen, visualisieren. Wir schauen uns in @fig-boxplot-ttest einmal den Boxplot für die Sprungweiten getrennt nach Hund und Katze an.

Wir sehen, dass sich die Boxen nicht überschneiden, ein Indiz für einen signifikanten Unterschied zwischen den beiden Gruppen. Im Weiteren liegt der Median in etwa in der Mitte der beiden Boxen. Die Whisker sind ungefähr gleich bei Hunden und Katzen. Ebenso sehen wir bei beiden Gruppen keine Ausreißer.

Wir schließen daher nach der Betrachtung der Boxplots auf Folgendes:

1)  Die Sprungweite ist für beide Gruppen ist annähernd bzw. approximativ normalverteilt.
2)  Die Standardabweichungen und damit die Varianzen $s^2_{dog} = s^2_{cat}$ der beiden Gruppen sind gleich. Es liegt somit Varianzhomogenität vor.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-boxplot-ttest

ggplot(data_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() +
  theme(legend.position = "none") 

```

Manchmal ist es etwas verwirrend, dass wir uns in einem Boxplot mit Median und IQR die Daten für einen t-Test anschauen. Immerhin rechnet ja ein t-Test mit den Mittelwerten und der Standardabweichung. Hier vergleichen wir etwas Äpfel mit Birnen. Deshalb in der @fig-dotplot-ttest der Dotplot mit dem Mittelwert und den entsprechender Standardabweichung als Fehlerbalken.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Dotplot der Sprungweiten [cm] von Hunden und Katzen zusammen mit dem Mittelwert und der Stanardabweichung als Fehlerbalken.
#| label: fig-dotplot-ttest


ggplot(data_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) + 
  geom_dotplot(binaxis = 'y', stackdir = 'center') + 
  stat_summary(fun.data = mean_sdl, fun.args = list(mult=1), 
               geom = "errorbar", color = "black", width = 0.1) +
  stat_summary(fun = "mean", geom="point", color="black", size = 5) +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("Hund", "Katze")) 


```

Wir nutzen aber später häufig den Boxplot zur Visualisierung der einzelnen Gruppen. Über den Boxplot können wir auch gut abschätzen, ob wir eine annährende bzw. approximative Normalverteilung vorliegen haben.

## Hypothesen für den t-Test

Ohne eine Hypothese ist das Ergebnis eines statistischen Tests wie auch der t-Test nicht zu interpretieren. Wir berechenen eine Teststatistik und einen p-Wert. Beide statistischen Maßzahlen machen eine Aussage über die beobachteten Daten $D$ unter der Annahme, das die Nullhypothese $H_0$ gilt.

Wie lautet nun das Hypothesenpaar des t-Tests? Der t-Test vergleicht die Mittelwerte von zwei Gruppen. Die Nullhypothese ist auch die Gleichheitshypothese. Die Alternativehypothese haben wir auch als Unterschiedshypothese bezeichnet.

Daher ergibt sich für unser Beispiel mit den Sprungweiten für Hunde- und Katzenflöhen folgende Hypothesen. Die Nullhypothese sagt, dass die mittleren Sprungweite für die Hundeflöhe gleich der mittleren Sprungweite der Katzenflöhe ist. Die Alternativehypothese sagt aus, dass sich die mittlere Sprungweite von Hunde- und Katzenflöhen unterscheidet.

$$
\begin{aligned} 
H_0: \bar{y}_{dog} &= \bar{y}_{cat} \\  
H_A: \bar{y}_{dog} &\neq \bar{y}_{cat} \\   
\end{aligned}
$$

Wir testen grundsätzlich auf ein zweiseitiges $\alpha$-Niveau von 5%.

## Der Student t-Test

Liegt ein normalverteiltes $y$ vor und sind die Varianzen für die beiden zu vergleichenden Gruppen homogen $s^2_{cat} = s^2_{dog}$, können wir einen Student t-Test rechnen. Wir nutzen dazu die folgendeFormel des Student t-Tests.

$$
T_{calc} = \cfrac{\bar{y}_{dog}-\bar{y}_{cat}}{s_{p} \cdot \sqrt{\cfrac{2}{n_{group}}}}
$$

mit der vereinfachten Formel für die gepoolte Standardabweichung $s_p$.

$$
s_{p} = \cfrac{s_{dog} + s_{cat}}{2}
$$

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Eigentlich wäre hier folgende Formel mit $s_{p} = \sqrt{\frac{1}{2} (s^2_{dog} + s^2_{cat})}$ richtig, aber auch hier erwischen wir einen Statistikengel um es etwas einfacher zu machen.
:::

Wir wollen nun die Werte für $\bar{y}_{dog}$, $\bar{y}_{cat}$ und $s_{p}$ berechnen. Wir nutzen hierfür R auf die etwas komplizierte Art und Weise. Es gibt in R auch die Funktion `t.test()`, die für uns alles auf einmal macht, aber hier nochaml zu Fuß.

```{r}
sum_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean = round(mean(jump_length), 2), 
            sd = round(sd(jump_length), 2)) 

sum_tbl
```

```{r}
#| echo: false
sd_pool <- (sum_tbl$sd[1] + sum_tbl$sd[2])/2
t_student <- round((sum_tbl$mean[1] - sum_tbl$mean[2])/(sd_pool * sqrt(2/7)), 2)
```

Wir erhalten durch die Funktion `group_by()` den Mittelwert und die Standardabweichung für die Sprungweite getrennt für die Hunde- und Katzenflöhe. Wir können damit die beiden obigen Formeln füllen.

Wir berechnen $s_p$ wie folgt.

$$
s_{pooled} = \cfrac{`r sum_tbl$sd[1]` + `r sum_tbl$sd[2]`}{2} = `r sd_pool`
$$

Anschließend können wir jetzt $s_p$ und die Mittelwerte sowie die Gruppengröße $n_g = 7$ in die Formel für den Student t-Test einsetzen und die Teststatistik $T_{calc}$ berechnen.

$$
T_{calc} = \cfrac{`r sum_tbl$mean[1]`- `r sum_tbl$mean[2]`}{`r sd_pool` \cdot \sqrt{\cfrac{2}{7}}} = `r t_student`
$$

Wir erhalten eine Teststatistik $T_{calc} = `r t_student`$ die wir mit dem kritischen Wert $T_{\alpha = 5\%} = 2.17$ vergleichen können. Da $T_{calc} > T_{\alpha = 5\%}$ ist, können wir die Nullhypothese ablehnen. Wir haben ein signifikanten Unterschied zwischen den mittleren Sprungweiten von Hunde- und Katzenflöhen nachgewiesen.

Soweit für den Weg zu Fuß. Wir rechnen in der Anwendung keinen Student t-Test per Hand. Wir nutzen die Formel `t.test()`. Da wir den Student t-Test unter der Annahme der Varianzhomogenität nutzen wollen, müssen wir noch die Option `var.equal = TRUE` wählen.

Die Funktion `t.test()` benötigt erst die das $y$ und $x$ in Modellschreibweise mit den Namen, wie die beiden Variablen auch im Datensatz `data_tbl` stehen. In unserem Fall ist die Modellschreibweise dann `jump_length ~ animal`. Im Weiteren müssen wir noch den Datensatz angeben den wir verwenden wollen durch die Option `data = data_tbl`. Dann können wir die Funktion `t.test()` ausführen.

```{r}
t.test(jump_length ~ animal, 
       data = data_tbl, var.equal = TRUE)
```

Wir erhalten eine sehr lange Ausgabe, die aucb etwas verwirrend aussieht. Gehen wir die Ausgabe einmal durch. Ich gehe nicht auf alle Punkte ein, sondern konzentriere mich hier auf die wichtigsten Aspekte.

-   `t = 3.12528` ist die berechnete Teststatistik $T_{calc}$. Der Wert unterscheidet sich leicht von unserem berechneten Wert. Der Unterschied war zu erwarten, wir haben ja auch die t-Test Formel vereinfacht.
-   `p-value = 0.0087684` ist der berechnete p-Wert $Pr(T_{calc}|H_0)$ aus der obigen Teststatistik. Daher die Fläche rechts von der Teststatistik.
-   `95 percent confidence interval: 1.0253394 5.7460892` ist das 95% Konfidenzintervall. Die erste Zahl ist die untere Grenze, die zweite Zahl ist die obere Grenze.

Wir erhalten hier dreimal die Möglichkeit eine Aussage über die $H_0$ zu treffen. In dem obigen Output von R fehlt der kritische Wert $T_{\alpha = 5\%}$. Daher ist die berechnete Teststatistik für die Testentscheidung nicht verwendbar. Wir nutzen daher den p-Wert und vergleichen den p-Wert mit dem $\alpha$-Niveau von 5%. Da der p-Wert kleiner ist als das $\alpha$-Niveau können wir wie Nullhypothese ablehnen. Wir haben einen signifikanten Unterschied. Die Entscheidung mit dem Konfidenzintervall benötigt die Signifikanzschwelle. Da wir hier einen Mittelwertsvergleich vorliegen haben ist die Signifikanzschwelle gleich 0. Wenn die 0 im Konfidenzintervall liegt können wir die Nullhypothese nicht ablehnen. In unserem Fall ist das nicht der Fall. Das Konfidenzintervall läfut von 1.025 bis 5.75. Damit ist die 0 nicht im Konfidenzintervall enthalten und wir können die Nullhypothese ablehnen. Wir haben ein signifikantes Konfidenzintervall vorliegen.

Wie wir sehen fehlt der Mittelwertsuntschied als Effekt $\Delta$ in der Standardausgabe des t-Tests in R. Wir können den Mittelwertsunterschied selber berechnen oder aber die Funktion `tidy()` aus dem R Paket `broom` nutzen. Da der Funktion `tidy()` kriegen wir die Informationen besser sortiert und einheitlich wiedergegeben. Da `tidy` eine Funktion ist, die mit vielen statistischen Tests funktioniert müssen wir wissen was die einzelnen `estimate` sind. Es hilft in diesme Fall sich die Visualisierung der Daten anzuschauen und die Abbildung mit den berechneten Werten abzugleichen.

```{r}
t.test(jump_length ~ animal, 
       data = data_tbl, var.equal = TRUE) %>% 
  tidy() 
```

Wir erkennen als erstes den Mittelwertsunterschied zwischen den beiden Gruppen von 3.39 cm. Danach folgen die einzelnen Mittelwerte der Sprungweiten der Hunde und Katzenflöhe mit jeweils 8.13 cm und 4.74 cm. Darauf folgt noch der p-Wert als `p.value` mit 0.00891 und die beiden Grenzen des Konfidenzintervalls \[1.03; 5.75\].

## Der Welch t-Test

Der t-Test ist auch in der Lage mit Varianzhetrogenität umzugehen. Das heißt, wenn die Varianzen der beiden Gruppen nicht gleich sind. Dadurch ändert sich die Formel für den t-Test wie folgt. Dann nennen wir den statistischen Test Welch t-Test.

$$
T_{calc} = \cfrac{\bar{y_1} - \bar{y_2}}{\sqrt{\cfrac{s^2_{y_1}}{n_1} + \cfrac{s^2_{y_2}}{n_2}}}
$$

Wir sehen, dass sich die Formel etwas andert. Da wir nicht mehr annehmen, dass die Varianzen homogen und daher gleich sind, können wir auch keinen gepoolten Varianzschätzer $s_p$ berechnen. Die Varianzen gehen einzeln in die Formel des Welch t-Tests ein. Ebenso müssen die beiden Gruppen nicht mehr gleich groß sein. Statt einen Wert $n_g$ für die Gruppengröße können wir auch die beiden Gruppengrößen separat angeben.

::: column-margin
Hier muss man noch bedenken, dass die Freiheitsgrade anders berechnet werden Die Freiheitsgrade werden wie folgt berechnet.

$$
df = \cfrac{\left(\cfrac{s^2_{y_1}}{n} +
    \cfrac{s^2_{y_2}}{m}\right)^2}{\cfrac{\left(\cfrac{s^2_{y_1}}{n}\right)^2}{n-1} + \cfrac{\left(\cfrac{s^2_{y_2}}{m}\right)^2}{m-1}}
$$
:::

Es ergibt keinen tieferen Sinn die obige Formel nochmal händisch auszurechnen. Die Zahlen ändern sich leicht, aber konzeptionell erhalten wir hier keinen Mehrwert. Deshalb schauen wir uns gleich die Umsetzung in R an. Wir nutzen erneut die Funktion `t.test()` und zwar diesmal mit der Option `var.equal = FALSE`. Damit geben wir an, dass die Varianzen heterogen zwischen den beiden Gruppen sind. Wir nutzen in unserem Beispiel die gleichen Zahlen und Daten wie schon im obigen Student t-Test Beispiel.

```{r}
t.test(jump_length ~ animal, 
       data = data_tbl, var.equal = FALSE)
```

Wir sehen das viele Zahlen nahezu gleich sind. Das liegt auch daran, dass wir in unserem Daten keine große Abweichung von der Varianzhomogenität haben. Wir erhalten die gleichen Aussagen wie auch schon im Student t-Test.

Schauen wir uns nochmal die Ausgabe der Funkton `tidy()` an.

```{r}
t.test(jump_length ~ animal, 
       data = data_tbl, var.equal = FALSE) %>% 
  tidy() 
```

[Für das Erkennen von Normalverteilung und Varianzheterogenität werden häufig sogenannte Vortest empfohlen. Aber auch hier gilt, bei kleiner Fallzahl liefern die Vortests keine verlässlichen Ergebnisse. In diesem Fall ist weiterhin die Beurteilung über einen Boxplot sinnvoller.]{.aside}

Wir sehen hier etwas besser, dass es kaum Abweichungen gibt. Alles egal? Nicht unbedingt. Das Problem ist eher *das Erkennen* von Varianzheterogenität in sehr kleinen Datensätzen. Kleine Datensätze meint Datensätze unter 30 Beobachtungen je Gruppe. Erst aber dieser Anzahl lassen sich unverzerrte Histogramme zeichnen und so aussagekräftige Abschätzungen der Varianzhomogenität oder Varianzheterogenität treffen.

## Der verbundene t-Test (Paired t-Test)

Im folgenden Datenbeispiel in @tbl-data-ttest-paired haben wir eine verbundene Stichprobe. Das heißt wir haben nicht zehn Flöhe gemessen sondern fünf Flöhe. Einmal im ungefütterten Zustand `unfed` und einmal im gefütterten Zustand `fed`. Wir wollen nun wissen, ob der Fütterungszustand Auswirkungen auf die Sprungweite in \[cm\] hat.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Tabelle  der Sprunglängen [cm] von fünf Flöhen zu zwei Zeitpunkten. Einmal wurde die Sprungweite ungefüttert und einmal gefüttert bestimmt. Die Daten liegen im Wide Format vor.
#| label: tbl-data-ttest-paired

paired_raw_tbl <- tibble(unfed = c(5.2, 4.1, 3.5, 3.2, 4.6),
                         fed = c(6.1, 5.2, 3.9, 4.1, 5.3),
                         diff = fed - unfed) 

paired_mean <- mean(paired_raw_tbl$diff)
paired_sd <- round(sd(paired_raw_tbl$diff), 2)
paired_t <- round(sqrt(5) * paired_mean/paired_sd, 2)

paired_tbl <- paired_raw_tbl %>%
  select(unfed, fed) %>% 
  gather(food_status, jump_length)

paired_raw_tbl %>% 
  kable(align = "c", "pipe")

```

Wir nutzen folgende Formel für den paired t-Test für verbundene Stichproben.

$$
T_{calc} = \sqrt{n}\cfrac{\bar{d}}{s_d}
$$

Wir können $\bar{d}$ als Mittelwert der Differenzen der Variablen `diff` berechnen. Ebenso verfahren wir mit der Standardabweichung der Differenzen $s_d$.

$$
T_{calc} = \sqrt{10}\cfrac{`r paired_mean`}{`r paired_sd`} = `r paired_t`
$$

Um den die Funktion `t.test()`in R mit der Option `paired = TRUE` für den paired t-Test zu nutzen, müssen wir die Daten nochmal über die Funktion `gather()` in das Long Format umwandeln. Wir wollen nun wissen, ob der Fütterungszustand `food_status` Auswirkungen auf die Sprungweite in \[cm\] hat.

```{r}
t.test(jump_length ~ food_status, 
       data = paired_tbl, paired = TRUE)
```

Die Ausgabe des paired t-Test ähnelt stark der Ausage des Student t-Test. Wir erhalten ebenfalls den wichtigen p-Wert mit 0.0025 sowie das 95% Konfidenzintervall mit \[0.47; 1.13\]. Zum einen ist $0.0025 < \alpha$ und somit können wir die Nullhypothese ablehnen, zum anderen ist auch die 0 nicht mit in dem Konfidenzintervall, womit wir auch hier die Nullhypothese ablehnen können.

```{r}
t.test(jump_length ~ food_status, 
       data = paired_tbl, paired = TRUE) %>% 
  tidy() 
```

Die Funktion `tidy()` gibt uns in diesem Fall keine neuen zusätzlichen Informationen.

## Freiheitsgrade im t-Test

Der t-Verteilung der Teststatistiken des t-Tests verhält sich nicht wie eine klassische Normalverteilung, die durch den Mittelwert und die Standardabweichung definiert ist. Die t-Verteilung ist nur durch die Freiheistgrade definiert. Der Freiheitsgrade in einem t-Test mit zwei Stichproben ist gegeben durch $df = n_1 + n_2 -2$. Damit beschreiben die Freiheitsgrade grob die Fallzahl. Je mehr Fallzahl desto großer der Freiheitsgrad eines t-Tests.

@fig-ttest-06 visualisiert diesen Zusammenhang von Freiheitsgraden und der Form der t-Verteilung. Je kleiner die Freiheitgrade und damit die Fallzahl, desto weiter sind die Verteilungsschwänze. Daher benötigen wir auch größere $T_{calc}$ Werte um ein signifikantes Ergebnis zu erhalten. Die Fläche unter der t-Verteilung ist immer gleich.

![Die t-Verteilung für drei beispielhafte Freiheitsgrade. Je größer die Freiheitsgrade und damit die Fallzahl, desto näher kommt die t-Verteilung einer Normalverteilung nahe. Bei einer geringeren Fallzahl, müssen damit größere $T_{calc}$ Werte erreicht werden um eine signifikantes Ergebnis zu erhalten, da mehr Fläche nach rechts wandert.](images/t-verteilung_06.png){#fig-ttest-06 fig-align="center"}

In diesem Exkurs wollen wir einmal überlegen, warum wir verschiedene Freiheitsgrade für die Testverteilungen brauchen. Wir wollen die Verteilung der Teststatistik unter der Nullhypothese für den Freiheitsgrad $df_1 = n_1 + n_2 -2 = 6$ und somit $n_1 = n_2 = 4$ sowie den Freiheitsgrad $df_2 = n_1 + n_2 -2 = 18$ und somit $n_1 = n_2 = 10$ einmal herleiten.

Zuerst gehen wir davon aus, dass die Mittelwerte der Sprungweite der Hunde- und Katzenflöhe gleich sind $\bar{y}_{cat} = \bar{y}_{dog} = (8.13 + 4.74)/2 = 6.43$. Daher nehmen wir an, dass die Mittelwerte aus der gleichen Normalverteilung kommen. Wir ziehen also vier Sprungweiten jeweils für die Hunde- und Katzenflöhe aus einer Normalverteilung mit $\mathcal{N}(6.43, 2.0)$. Das ganze wiederholen wir dann für jeweils zehn Hunde- und Katzenflöhe. Wir nutzen dafür die Funktion `rnorm()`. Anschließend berechnen wir die Teststatistik. Diesen Schritt wiederholen wir eintausend Mal.

Im Folgenden berechnen wir eintausend Mal die Teststatistik, wenn die Nullhypothese gilt, für jeweils vier Hunde- und Katzenflöhe. Wir haben damit einen Freiheitsgrad von $df_1 = 6$.

```{r}
T_n4_vec <- map_dbl(1:1000, function(...){
  dog_vec <- rnorm(n = 4, mean = 6.43, sd = 2.0)
  cat_vec <- rnorm(n = 4, mean = 6.43, sd = 2.0)
  s_p <- (sd(cat_vec) + sd(dog_vec))/2 
  T_calc <- (mean(cat_vec) - mean(dog_vec))/(s_p * sqrt(2/4)) 
  return(T_calc)  
}) %>% round(2)
```

Und das ganze nochmal für jeweils zehn Hunde- und Katzenflöhe. Wir haben damit einen Freiheitsgrad von $df_2 = 18$.

```{r}
T_n10_vec <- map_dbl(1:1000, function(...){
  dog_vec <- rnorm(n = 10, mean = 6.43, sd = 2.0)
  cat_vec <- rnorm(n = 10, mean = 6.43, sd = 2.0)
  s_p <- (sd(cat_vec) + sd(dog_vec))/2 
  T_calc <- (mean(cat_vec) - mean(dog_vec))/(s_p * sqrt(2/10)) 
  return(T_calc)  
}) %>% round(2)
```

Schauen wir uns einmal die Spannweite der Teststatistiken mit einer niedrigen Fallzahl an. Darüber hinaus wollen wir wissen, wie viele Teststatistiken gibt es, die unsere Teststatistik $T_{calc} = 3.14$ vom obigen Beispiel übersteigen.

```{r}
T_n4_vec %>% range()
sum(T_n4_vec > 3.14)
```

Im Gegensatz dazu dann die Spannweite der Teststatistiken mit einer höheren Fallzahl an. Auch hier wollen wir wissen, wie viele Teststatistiken es gibt, die unsere Teststatistik $T_{calc} = 3.14$ vom obigen Beispiel übersteigen.

```{r}
T_n10_vec %>% range()
sum(T_n10_vec > 3.14)
```

In @fig-test-df-1 sehen wir die Verteilung der berechneten eintausend Verteilungen nochmal als ein Histogramm dargestellt. Wiederum sehen wir, dass unsere berechnete Teststatistik $T_{calc} = 3.14$,dargestellt als gestrichelte Linie, sehr weit rechts am Rand der Verteilung liegt.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-test-df-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Histogramm der 1000 gerechneten Teststaistiken $T_{calc} = 3.14$, wenn die $H_0$ war wäre und somit kein Unterschied zwischen den Mittelwerten der Sprungweiten der Hunde- und Katzenflöhe vorliegen würde."

n_compare_tbl <- tibble(n4 = T_n4_vec,
                        n10 = T_n10_vec) %>% 
  gather()

ggplot(n_compare_tbl, aes(x = value, fill = key)) +
  theme_bw() +
  labs(x = "Teststatistik", y = "Anzahl") +
  geom_density(alpha = 0.4) +
  geom_vline(xintercept = 3.47, color = "black", size = 1, linetype = 2) +
  geom_vline(xintercept = qt(c(0.025, 0.975), df = 4 + 4 - 2, lower.tail = FALSE), 
             color = cbbPalette[3], linewidth = 1) +
  geom_vline(xintercept = qt(c(0.025, 0.975), df = 10 + 10 - 2, lower.tail = FALSE), 
             color = cbbPalette[2], linewidth = 1) +
  scale_fill_manual(values = cbbPalette[2:3])
```
