```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Multinomiale / Ordinale logistische Regression {#sec-multinom-ordinal}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

::: callout-tip
## Einführung in die Multinomiale / Ordinale logistische Regression per Video

Du findest auf YouTube [Multinomiale / Ordinale logistische Regression](https://youtu.be/CQQEXiYASUk) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Was machen wir wenn wir ein Outcome haben mit mehr als zwei Kategorien. Wenn wir nur zwei Kategorien hätten, dann würden wir eine logistische Regression rechnen. Wenn wir mehr als zwei Kategorien haben, dann sind wir in dem Fall der multinomialen / ordinalen logistischen Regression. Wir rechnen eine multinomialen Regression, wenn wir keine Ordnung in den Kategorien in dem Outcome haben. Wenn wir eine Ordnung vorliegen haben, dann nutzen wir die ordinale Regression. Wir werden uns erstmal eine ordinale Regression anschauen mit nur drei geordenten Stufen. Dann schauen wir uns einmal wie wir eine ordinale Regression auf Boniturnoten in der Likert-Skala rechnen. Wir machen das getrennt, denn wir sind bei wenigen geordneten Kategorien meistens noch am Effekt zwischen den Kategorien interessiert. Im Gegensatz wollen wir bei einem Outcome mit Boniturnoten einen Gruppenvergleich rechnen. Dann interessiert uns der Unterschied und die Effekte zwischen den Boniturnoten nicht. Deshalb trennen wir das hier etwas auf.

Im zweiten Teil wollen wir uns dann noch eine multinominale Regression auf ungeordneten Kategorien eines Outcomes anschauen. Korrelterweise tuen wir nur so, als wäre unser vorher geordnetes Outcome dann eben ungeordnet. Das macht dann aber bei deiner Anwendung dann keinen großen Unterschied. Als eine Alternative zur multinationalen Regression stelle ich dann noch die logistsiche Regression vor. Wir können nämlich einfach unsere Daten nach dem Outcome jeweils in kleinere Datensätze mit nur jeweils zwei der Kategorien aufspalten. Das ist zwar nicht schön, aber auch eine Möglichkeit mit einem Problem umzugehen.

Ich gehe hier nicht auf die Theorie hinter der multinomialen / ordinalen logistischen Regression ein. Wenn dich dazu mehr interessiert findest du in den jeweiligen Abschnitten dann noch eine passende Referenz. Da kannst du dann schauen, welche Informationen du noch zusätzlich findest.

## Annahmen an die Daten

[Unser gemessenes Outcome $y$ folgt einer Multinomialverteilung.]{.aside}

Im folgenden Kapitel zu der multinomialen / ordinalen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Daher sieht unser Modell wie folgt aus. Wir haben ein $y$ und $p$-mal $x$. Wobei $p$ für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser $y$ einer Multinomialverteilung. Damit finden wir im Outcome im Falle der multinomialen logistischen linearen Regression *ungeordnete* Kategorien und im Falle der ordinalen logistischen linearen Regression *geordnete* Kategorien.

$$
y \sim x_1 + x_2 + ... + x_p 
$$

Wir können in dem Modell auch Faktoren $f$ haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in @sec-posthoc nochmal nachlesen.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               parameters, performance, gtsummary,
               ordinal, janitor, MASS, nnet, flextable,
               emmeans, multcomp, ordinal, see, scales,
               janitor)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Im Folgenden wollen wir uns die Daten von den infizierten Ferkeln noch einmal anschauen. Wir nehmen als Outcome die Spalte `frailty` und damit die Gebrechlichkeit der Ferkel. Die Spalte ordnen wir einmal nach *robust*, *pre-frail* und *frail*. Wobei *robust* ein gesundes Ferkel beschreibt und *frail* ein gebrechliches Ferkel. Damit wir später die Richtung des Effekts richtig interpretieren können, müssen wir von *gut* nach *schlecht* sortieren. Das brauchen wir nicht, wenn wir Boniturnoten haben, dazu mehr in einem eigenen Abschnitt. Wir bauen uns dann noch einen Faktor mit ebenfalls der Spalte `frailty` in der wir so tun, als gebe es diese Ordnung nicht. Wir werden dann die ordinale Regression mit dem Outcome `frailty_ord` rechnen und die multinominale Regression dann mit dem Outcome `frailty_fac` durchführen.

```{r}
pig_tbl <- read_excel("data/infected_pigs.xlsx") %>%
  mutate(frailty_ord = ordered(frailty, levels = c("robust", "pre-frail", "frail")),
         frailty_fac = as_factor(frailty)) %>% 
  select(-infected)

```

Schauen wir uns nochmal einen Ausschnitt der Daten in der @tbl-multinom-pigs an.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-multinom-pigs
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.
#| column: page

raw_pig_tbl <- pig_tbl %>% 
  mutate(frailty_ord = as.character(frailty_ord),
         frailty_fac = as.character(frailty_fac))

rbind(head(raw_pig_tbl),
      rep("...", times = ncol(raw_pig_tbl)),
      tail(raw_pig_tbl)) %>% 
  kable(align = "c", "pipe")
```

Das wären dann die Daten, die wir für unsere Modelle dann brauchen. Schauen wir mal was wir jetzt bei der ordinalen Regression herausbekommen.

## Ordinale logistische Regression {#sec-ordinal}

Es gibt sicherlich einiges an Paketen in R um eine ordinale Regression durchzuführen. Ich nutze gerne die Funktion `polr` aus dem R Paket `MASS`. Daneben gibt es auch noch das R Paket `ordinal` mit der Funktion `clm()`, die wir dann noch im Anschluss besprechen werden. Ich nutze jetzt erstmal die Funktion `polr`, da wir hier noch eine externe Referenz haben, die uns noch detailliertere Informationen liefern kann.

::: column-margin
Ich verweise gerne hier auf das tolle Tutorium [Ordinal Logistic Regression \| R Data Analysis Examples](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/). Hier erfährst du noch mehr über die Analyse der ordinalen logistischen Regression.
:::

Wir schon erwähnt sparen wir usn die mathematischen Details und utzen gleich die Funktion `polr` auf unserem Outcome `frailty`. Wir müssen keine Verteilungsfamilie extra angeben, dass haben wir schon mit der Auswahl der Funktion getan. Die Funktion `polr` kann nur eine ordinale Regression rechnen und wird einen Fehler ausgeben, wenn das Outcome $y$ nicht passt.

```{r}
#| message: false
#| warning: false
ologit_fit <- polr(frailty_ord ~ age + sex + location + activity + crp + 
                     bloodpressure + weight + creatinin, 
                   data = pig_tbl)
```

Schauen wir uns einmal die Ausgabe des Modellfits der ordinalen Regression mit der Funktion `summary()` an. Wir sehen eine Menge Zahlen und das wichtigste für uns ist ja, dass wir zum einen Wissen, dass wir auch die ordinale Regression auf der $link$-Funktion rechnen. Wir erhalten also wieder eine Transformation des Zusammenhangs zurück, wie wir es schon bei der Poisson Regression sowie bei der logistischen Regression hatten.

[Hier gibt es nur die Kurzfassung der *link*-Funktion. @dormann2013parametrische liefert hierzu in Kapitel 7.1.3 nochmal ein Einführung in das Thema.]{.aside}

```{r}
#| message: false
#| warning: false
ologit_fit %>% summary()
```

Unsere Ausgabe teilt sich in zwei Teile auf. In dem oberen Teil sehen wir die Koeffizienten des Modells zusammen mit dem Fehler und der Teststatistik. Was wir nicht sehen, ist ein $p$-Wert. Die Funktion rechnet uns keinen Signifikanztest aus. Das können wir aber gleich selber machen. In dem Abschnitt `Intercepts` finden wir die Werte für die Gruppeneinteilung auf der *link*-Funktion wieder. Wir transformieren ja unsere drei Outcomekategorien in einen kontinuierliche Zahlenzusammenhang. Trotzdem müssen ja die drei Gruppen auch wieder auftauchen. In dem Abschnitt `Intercepts` finden wir die Grenzen für die drei Gruppen auf der *link*-Funktion.

::: column-margin
Wir gibt auch ein Tutorial für [How do I interpret the coefficients in an ordinal logistic regression in R?](https://stats.oarc.ucla.edu/r/faq/ologit-coefficients/)
:::

Berechnen wir jetzt einmal die $p$-Werte per Hand. Dafür brauchen wir die absoluten Werte aus der `t value` Spalte aus der `summary` des Modellobjekts. Leider ist die Spalte nicht schön formatiert und so müssen wir uns etwas strecken um die Koeffizienten sauber aufzuarbeiten. Wir erhalten dann das Objekt `coef_tbl` wieder.

```{r}
#| message: false
#| warning: false

coef_tbl <- summary(ologit_fit) %>% 
  coef %>% 
  as_tibble(rownames = "term") %>% 
  clean_names() %>% 
  mutate(t_value = abs(t_value))

coef_tbl
```

Um die Fläche rechts von dem $t$-Wert zu berechnen, können wir zwei Funktionen nutzen. Die Funktion `pnorm()` nimmt eine Standradnormalverteilung an und die Funktion `pt()` vergleicht zu einer $t$-Verteilung. Wenn wir *rechts* von der Verteilung schauen wollen, dann müssen wir die Option `lower.tail = FALSE` wählen. Da wir auch zweiseitig statistisch Testen, müssen wir den ausgerechneten $p$-Wert mal zwei nehmen. Hier einmal als Beispiel für den $t$-Wert von $1.96$. Mit `pnorm(1.96, lower.tail = FALSE) * 2` erhalten wir $0.05$ als Ausgabe. Das ist unser $p$-Wert. Was uns ja nicht weiter überrascht. Denn rechts neben dem Wert von $1.96$ in einer Standardnormalverteilung ist ja $0.05$. Wenn wir einen $t$-Test rechnen würden, dann müssten wir noch die Freiheitsgrade `df` mit angeben. Mit steigendem $n$ nähert sich die $t$-Verteilung der Standardnormalverteilung an. Wir haben mehr als $n = 400$ Beobachtungen, daher können wir auch `df = 400` setzen. Da kommt es auf eine Zahl nicht an. Wir erhalten mit `pt(1.96, lower.tail = FALSE, df = 400) * 2` dann eine Ausgabe von $0.0507$. Also *fast* den gleichen $p$-Wert.

Im Folgenden setzte ich die Freiheitsgrade `df = 3` dammit wir was sehen. Bei so hohen Fallzahlen wir in unserem beispiel würden wir sonst keine Unterschiede sehen.

```{r}
#| message: false
#| warning: false

coef_tbl %>% 
  mutate(p_n = pnorm(t_value, lower.tail = FALSE) * 2,
         p_t = pt(t_value, lower.tail = FALSE, df = 3) * 2) %>% 
  mutate(across(where(is.numeric), round, 3))
```

Damit haben wir einmal händisch uns die $p$-Werte ausgerechnet. Jetzt könnte man sagen, dass ist ja etwas mühselig. Gibt es da nicht auch einen einfacheren Weg? Ja wir können zum einen die Funktion `tidy()` nutzen um die 95% Konfidenzintervalle und die exponierten Effektschätzer aus der ordinalen Regresssion zu erhalten. Wir erhalten aber wieder keine $p$-Werte sondern müssten uns diese $p$- Werte dann wieder selber berechnen.

```{r}
#| message: false
#| warning: false
ologit_fit %>% 
  tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
  select(-coef.type)
```

Um all dieses Berechnen zu umgehen, können wir dann auch die Funktion `model_parameters()` nutzen. Hier berechnen wir dann die $p$-Wert mit $df = 400$ aus einer $t$-Verteilung. Damit umgehen wir das Problem, dass unser Modellfit keine $p$-Werte liefert.

```{r}
#| message: false
#| warning: false

ologit_fit %>% 
  model_parameters() 
```

In @tbl-regression-ordinal sehen wir nochmal die Ergebnisse der ordinalen Regression einmal anders aufgearbeitet. Wir aber schon bei der Funktion `tidy()` fehlen in der Tabelle die $p$-Werte. Wir können aber natürlich auch eine Entscheidung über die 95% Konfidenzintervalle treffen. Wenn die 1 mit im 95% Konfidenzintervall ist, dann können wir die Nullhypothese nicht ablehnen.

```{r}
#| message: false
#| warning: false
#| label: tbl-regression-ordinal
#| tbl-cap: "Tabelle der Ergebnisse der ordinalen Regression."

ologit_fit %>% 
  tbl_regression(exponentiate = TRUE) %>% 
  as_flex_table()
```

Wi es im gazen Kapitel schon durchscheint, die Interpreation der $OR$ aus einer ordinalen Regression ist nicht einfach, geschweige den intuitiv. Was wir haben ist der Trend. Wir haben unser Outcome von *robust* zu *frail* sortiert und damit von *gut* nach *schlecht*. Wir können so die Richtung der Variablen in unserem Modell interpretieren. Das heißt, dass männliche Ferkel eher von einer Gebrechlichkeit betroffen sind als weibliche Ferkel. Oder wir sagen, dass ein ansteigender CRP Wert führt zu weniger Gebrechlichkeit. Auf diesem Niveau lassen sich die $OR$ einer ordinalen Regression gut interpretieren.

## Cumulative Link Models (CLM) für ordinale Daten

Jetzt kommen wir nochmal zu dem Fall, dass wir Boniturdaten vorliegen habe. Das heißt, wir bauen uns flux wieder einen Datensatz mit drei Blöcken mit jeweils drei Wiederholungen. Wir haben Weizen angepflanzt und bonitieren die Weizenpflanzen nach der Likert Skala. Dabei bedeutet dann eine 1 ein schlechte Note und eine 9 die best mögliche Note. Wir hätten natürlich hier auch einen Kurskal-Wallis-Test rechnen können und dann im Anschluss einen paarweisen Wilcoxon Test. Nun modellieren wir hier aber die Boniturnoten mal mit einer ordinalen Regression und rechnen den anschließenden Gruppenvergleich dann mit dem R Paket `emmeans`.

::: column-margin
Wir finden auch ein Tutorial zu [Introduction to Cumulative Link Models (CLM) for Ordinal Data](https://rcompanion.org/handbook/G_01.html).
:::

Unser Datensatz `grade_tbl` enthält den Faktor `block` mit drei Levels sowie den Faktor `variety` mit fünf Leveln. Jedes Level repränsentiert dabei eine Weizensorte.

```{r}
#| message: false
#| warning: false
grade_tbl <- tibble(block = rep(c("I", "II", "III"), each = 3),
                    A = c(2,3,4,3,3,2,4,2,1),
                    B = c(7,9,8,9,7,8,9,6,7),
                    C = c(6,5,5,7,5,6,4,7,6),
                    D = c(2,3,1,2,1,1,2,2,1),
                    E = c(4,3,7,5,6,4,5,7,5)) %>%
  gather(key = variety, value = grade, A:E) %>% 
  mutate(grade_ord = ordered(grade))

```

Wir schauen uns nochmal den Datensatz an und sehen, dass wir einmal die Spalte `grade` als numerische Spalte vorliegen haben udn einmal als geordneten Faktor. Wir brauchen die numerische Spalte um die Daten besser in `ggplot()` darstellen zu können.

```{r}
grade_tbl
```

In @fig-clm-dot sehen wir einmal die Daten als Dotplot dargestellt. Auf der x-Achse sind die Weizensorten und auf der y-Achse die Boniturnoten. Ich habe noch die zusätzlichen Linien für jede einzelne Note mit eingezeichnet.

```{r}
#| echo: true
#| message: false
#| label: fig-clm-dot
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Dotplot des Datenbeispiels für die Bonitur von fünf Weizensorten."

ggplot(grade_tbl, aes(variety, grade, fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir='center', 
               position=position_dodge(0.6), dotsize = 0.75) +
  scale_y_continuous(breaks = 1:9, limits = c(1,9)) +
  scale_fill_okabeito() 

```

Jetzt können wir schon die Funktion `clm()` aus dem R Paket `ordinal` verwenden um die ordinale Regression zu rechnen. Wir haben in dem Paket `ordinal` noch weitere Modelle zu Verfügung mit denen wir auch komplexere Designs bis hin zu linearen gemischten Modellen für eine ordinale Regresssion rechnen können. Da wir mit Boniturnoten als Outcome arbeiten setzen wir auch die Option `threshold = "symmetric"`. Damit teilen wir der Funktion `clm()` mit, dass wir es mit einer symmetrischen Notenskala zu tun haben. Wenn du das nicht hast, dass kannst du die Option auch of `"flexible"` stellen. Dann wird eine nicht symmetrische Verteilung des Outcomes angenommen.

```{r}
#| message: false
#| warning: false
clm_fit <- clm(grade_ord ~ variety + block, data = grade_tbl,
               threshold = "symmetric")
```

Wir können uns dann den Fit des Modells wieder in der Funktion `model_parameters()` einmal anschauen. Wir *brauchen* aber die Ausgabe nicht weiter. Wir werden Koeffizienten des Modells jetzt verwenden um die Gruppenvergleiche zu rechnen. Ich habe hier einmal die $OR$ über die Option `exponentiate = TRUE` mir ausgeben lassen. Leider sind die $OR$ so alleine nicht zu interpretieren.

```{r}
#| message: false
#| warning: false
clm_fit %>% 
  model_parameters(exponentiate = TRUE)
```

Es ist auch möglich auf dem Modellfit eine ANOVA zu rechnen. Wir machen das hier einmal, aber wir erwaten natürlich einen signifikanten Effekt von der Sorte. Die Signifikanz konnten wir ja schon oben im Dortplot sehen.

```{r}
#| message: false
#| warning: false
anova(clm_fit)
```

Ich hatte ja eben geschrieben, dass wir die Effektschätzer nicht nutzen. Wir können mit den $OR$ aus dem Modell nichts anfangen. Stattdessen nutzen wir die Schätzer der *link*-Funktion, also die Log Odds, um den paarweisen Gruppenvergleich zu rechnen. Wir nutzen dafür die Funktion `emmeans()` und lassen uns das *compact letter display* über die Funktion `cld()` wiedergeben. Ich habe dann noch die Ausgabe einmal nach den Sorten sortiert und nicht nach dem *compact letter display*. Dadurch lassen sich die Buchstaben besser zum Dotplot vergleichen.

```{r}
#| message: false
#| warning: false
clm_fit %>% 
  emmeans(~ variety) %>% 
  cld(Letters = letters) %>% 
  arrange(variety)
```

Wir erinnern uns, gleiche Buchstaben heißen *kein* Unterschied zwischen den Weizensorten. Damit ist die Weizensorte A gleich der Weizensorte D. Die Weizensorte C ist gleich der Weizensorte E. Am Ende unterscheidet sich die Weizensorte B von allen anderen Sorten. Wir können aber die Werte in der Spalte `emmean` nicht als Notenunterschied interpretieren. Dafür müssen wir dann den Median für die Gruppen berechnen. Wir können dann das *compact letter display* händisch ergänzen.

```{r}
grade_tbl %>% 
  group_by(variety) %>% 
  summarise(median(grade)) %>% 
  mutate(cld = c("a", "  c", " b ", "a  ", " b "))
```

Du könntest dir auch die Buchstaben des *compact letter display* aus einem Objekt ziehen und nicht händisch übertragen. Ich habe mir hier aber einen Schritt gespart.

## Multinomiale logistische Regression {#sec-multinom}

::: column-margin
Ich verweise gerne hier auf das tolle Tutorium [Multinomial Logistic Regression \| R Data Analysis Examples](https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/). Hier erfährst du noch mehr über die Analyse der multinominale logistischen Regression.
:::

```{r}
#| message: false
#| warning: false
pig_tbl <- pig_tbl %>% 
  mutate(frailty_fac = relevel(frailty_fac, ref = "robust"))
```

```{r}
#| message: false
#| warning: false
multinom_fit <- multinom(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, 
                         data = pig_tbl)
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% summary
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% confint %>%  exp
```

```{r}
#| message: false
#| warning: false
z_mat <- summary(multinom_fit)$coefficients/summary(multinom_fit)$standard.errors
p_n <- (1 - pnorm(abs(z_mat), 0, 1)) * 2
p_n
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)
```

```{r}
#| message: false
#| warning: false
multinom_fit %>% model_parameters()
```

@tbl-tbl-regression-multinom

```{r}
#| message: false
#| warning: false
#| label: tbl-tbl-regression-multinom
#| tbl-cap: "."

multinom_fit %>% 
  tbl_regression(exponentiate = TRUE) %>% 
  as_flex_table()
```

## Logistische Regression

```{r}
#| message: false
#| warning: false
pig_tbl$frailty %>% tabyl
```

```{r}
#| message: false
#| warning: false
pig_lst <- list(robust_prefrail = filter(pig_tbl, frailty_fac %in% c("robust", "pre-frail")),
                robust_frail = filter(pig_tbl, frailty_fac %in% c("robust", "frail")),
                prefrail_frail = filter(pig_tbl, frailty_fac %in% c("pre-frail", "frail")))

```

```{r}
#| message: false
#| warning: false
pig_lst %>% 
  map(~mutate(.x, frailty_fac = fct_drop(frailty_fac))) %>% 
  map(~glm(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, 
           data = .x, family = binomial)) %>% 
  map(model_parameters, exponentiate = TRUE) %>% 
  map(extract, -1, )
```

## Referenzen {.unnumbered}
