In diesem Zerforschenbeispiel schauen wir uns eine nicht-lineare Regression einmal genauer an. Ganz am Ende geht es dann auch nochmal ganz kurz um die Modellierung. Jetzt wollen wir uns aber erstmal die @fig-ur-regression vornehmen und diese in `ggplot` nachbauen. Das wird eine echte Freude, denn die Abbildung ist wunderbar komplex. Wir haben zum einen die nicht-linearen Regressionsgeraden sowie deren Funktionen im Plot. Darüber hinaus dann noch ein Zielbereich mit einem Pfeil und einer Beschriftung. Am Ende müssen wir dann auch noch die Achsen mit den mathematischen Formeln beschriften. Wir haben also einiges zu tun.

![Ursprüngliche Abbildung, die nachgebaut werden soll. Zwei nicht-lineare Regession laufen durch Mittelwert plus/minus Standardabweichung. Im Weiteren sind die Regressionsgleichungen noch ergänzt sowie ein Zielbereich farblich hervorgehoben. Am Ende müssen dann die Achsen noch sauber beschriftet werden.](images/eda/zerforschen_regression_01.jpeg){#fig-ur-regression fig-align="center" width="80%"}

Zuerst habe ich mir einmal einen leeren Plot erstellt in dem ich nur die Regressionsgleichungen abbilden werde. Aus den Gleichungen kann ich mir dann die Mittelwerte von dem `content` für die entsprechenden `iodine`-Werte berechnen. Also erstmal ein paar passende $x$-Werte und die entsprechenden $y$-Werte. Hierbei sind die $y$-Werte nicht so wichtig, die werden wir uns ja mit den Regressionsgleichungen berechnen, aber wir brauchen ja die $y$-Werte für unser Canvas. Die Funktion `ggplot()` muss ja wissen was auf $x$ und $y$ soll.

```{r}
func_tbl <- tibble(iodine = c(0, 0.25, 0.5, 0.75, 1, 2),
                   content = c(0, 100, 150, 200, 300, 400))
```

Dann schreibe ich mir noch über das `\(x){}` die Funktionen für die Regressionsgleichungen in R auf. Dabei ist `\(x){}` die Kurzschreibweise für `function(x){}`. Ich mache es mir hier nur etwas leichter.

```{r}
ki_func <- \(x) {-104 * x^2 + 445 * x}
kio3_func <- \(x) {-117 * x^2 + 374 * x}
```

Dann schauen wir uns einmal die beiden Funktion mit dem `geom_function()` einmal in der @fig-ggplot-zerforschen-regression-1 einmal an. Das `geom_function()` nimmt dabei eine definierte Funktion und berechnet dann die entsprechenden $y$-Werte aus den $x$-Werten.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-zerforschen-regression-1
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Darstellung der beiden Regressionsgleichungen für $KI$ und $KIO_3$."


ggplot(data = func_tbl, aes(x = iodine, y = content)) +
  theme_bw() +
  geom_function(fun = ki_func, color = cbbPalette[2], linetype = 'dashed') +
  geom_function(fun = kio3_func, color = cbbPalette[3], linetype = 'dashed') 
```

Anhand der beiden Funktionen kann ich mir jetzt auch die Mittelwerte berechnen. Die Mittelwerte sind ja die Werte, die sich für einen `iodine`-Wert auf der entsprechenden Regressionsgeraden ergeben. Hier also einmal alle meine Werte des `content` auf den beiden Geraden für die entsprechenden `iodine`-Werte.

```{r}
tibble(iodine = c(0, 0.25, 0.5, 0.75, 1, 2),
       ki = ki_func(iodine),
       kio3 = kio3_func(iodine))
```

Ich habe mir dann die Mittelwerte genommen und für jede `iodine`/`ki`-Kombination noch zwei Werte ergänzt um dann noch etwas Streuung zu bekommen. So habe ich dann nur drei Beobachtungen pro Kombination, aber die Anzahl soll hier erstmal reichen. Du findest die Werte in der Datei `zerforschen_regression.xlsx`. Hier ist die Datei in einem Auszug dann einmal geladen und dargestellt.

```{r}
regression_tbl <- read_excel("data/zerforschen_regression.xlsx") %>% 
  mutate(type = as_factor(type))
regression_tbl 
```

Wir berechnen wie gewohnt die Mittelwerte und die Standardabweichungen um diese dann als Punkte und Fehlerbalken in der Abbildung darstellen zu können.

```{r}
#| message: false
#| warning: false
stat_tbl <- regression_tbl %>% 
  group_by(type, iodine) %>% 
  summarise(mean = mean(content),
            sd = sd(content))
stat_tbl
```

So und nun geht es los. Ich habe dir den folgenden Code einmal annotiert. Klicke dafür dann einfach auf die Nummern um mehr Informationen zu erhalten. Der Code ist sehr umfangreich, aber die Abbildung ist ja auch recht komplex. Beachte im Besonderen den Abschnitt von weiter oben zu den [mathematischen Ausdrücken in den Achsenbeschriftungen](#sec-eda-tex). Ich mache hier ja auch sehr viel um dann die mathematischen Ausdrücke richtig hinzukriegen.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-zerforschen-regression-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Einmal die komplexe Abbildung der nicht-linearen Regression in `ggplot` nachgebaut. Am Ende wurde es dann doch noch eine Legende und keien Beschriftung."

ggplot(data = stat_tbl, aes(x = iodine, y = mean,
                            color = type)) +
  theme_bw() +
  geom_function(fun = ki_func, color = cbbPalette[2], linetype = 'dashed') + # <1>
  geom_function(fun = kio3_func, color = cbbPalette[3], linetype = 'dashed') + # <1>
  geom_point() +
  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd), # <2>
                width = 0.03) + # <2>
  scale_y_continuous(breaks = c(0, 150, 300, 450, 600), limits = c(0, 600)) +
  scale_color_okabeito(labels = c(TeX(r"($KI$)"), TeX(r"($KIO_3$)"))) + # <3>
  labs(color = "Iodine",
       x = TeX(r"(Iodine supply $[kg\, l\, ha^{-1}]$)"),
       y = TeX(r"(Iodine content $[\mu g\, l \, 100 g^{-1}\, f.m.]$)")) +
  annotate("text", x = 0.8, y = 500, hjust = "left", # <4>
           label = TeX(r"($y = -98.41 \cdot x^2 + 432.09 \cdot x;\; R^2 = 0.957$)"), # <4>
           color = cbbPalette[2]) + # <4>
  annotate("text", x = 0.8, y = 200, hjust = "left", # <4>
           label = TeX(r"($y = -117.08 \cdot x^2 + 372.34 \cdot x;\; R^2 = 0.955$)"), # <4>
           color = cbbPalette[3]) + # <4>
  annotate("rect", xmin = 0, xmax = 2, ymin = 50, ymax = 100, # <5>
           alpha = 0.2, fill = cbbPalette[6]) +  # <5>
  annotate("text", x = 1.525, y = 150, label = "Target range", hjust = "left",  # <5>
           size = 5) +   # <5>
  geom_curve(aes(x = 1.5, y = 150, xend = 1.25, yend = 105),   # <5>
             colour = "#555555",   # <5>
             size = 0.5,   # <5>
             curvature = 0.2,  # <5>
             arrow = arrow(length = unit(0.03, "npc"))) +  # <5>
  theme(legend.position = c(0.11, 0.8),
        legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(t = 1, l = 1),
        legend.text.align = 0) 
```

1.  Hier werden die beiden nicht-linearen Kurven gezeichnet.
2.  Hier werden die Fehlerbalken erstellt.
3.  Hier passen wir die Labels in der Legende entsprechend an.
4.  Hier schreiben wir die Regressionsgleichung für die jeweiligen Kurven hin.
5.  Hier produzieren wir den blauen Bereich plus den Pfeil sowie die Beschreibung.

Und dann zum Abschluss nochmal die [nicht-lineare Regression](#sec-non-linear) um zu schauen welche Koeffizienten der nicht-linearen Regression wir erhalten würden, wenn wir unsere selbst ausgedachten Daten nehmen würden. Wir nutzen hier einmal die Funktion `nls()` um die nicht-lineare Regression anzupassen und dann die Funktion `r2()` aus dem R Paket `performance` für unser Bestimmtheitsmaß $R^2$. Das Ganze machen wir dann natürlich für beide Geraden, also einmal für $KI$ und einmal für $KIO_3$.

::: panel-tabset
## Nicht-lineare Regression für $KI$

```{r}
#| message: false
#| echo: true
#| warning: false

fit <- nls(content ~ b1 * iodine^2 + b2 * iodine, data = filter(regression_tbl, type == "KI"), 
           start = c(b1 = 1, b2 = 1)) 

fit %>% 
  parameters::model_parameters() %>% 
  select(Parameter, Coefficient)

performance::r2(fit)
```

## Nicht-lineare Regression für $KIO_3$

```{r}
#| message: false
#| echo: true
#| warning: false

fit <- nls(content ~ b1 * iodine^2 + b2 * iodine, data = filter(regression_tbl, type == "KIO3"), 
    start = c(b1 = 1, b2 = 1)) 

fit %>% 
  parameters::model_parameters() %>% 
  select(Parameter, Coefficient)

performance::r2(fit)
```
:::
