```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Neural networks {#sec-neural}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

So, das war ein ganz schönes Brett, TensorFlow bzw. Keras auf dem Rechner zu installieren. Es gibt zwar einen [Quick start um Tensorflow zu installieren](https://tensorflow.rstudio.com/install/) aber dann hatte ich das schöne Problem der GPU auf dem macOS mit M1 Chip. Die Lösung für die [Local GPU](https://tensorflow.rstudio.com/install/local_gpu) hat mich auf dem macOS einen Tag Nerven gekostet. Das mag dann auf einem Windows Rechner anders sein bzw. andere Probleme verursachen. Schlussendlich ist die Nutzung von *neural networks* auf keinen Laptops vielleicht auch nicht so die beste Idee. Wir würden die Algorithmen eher auf Hochleistungsrechner durchführen und dann vermutlich eine Linuxdistribution verwenden. Dennoch werde ich hier einmal Tensorflow in R vorstellen. Die Pakete für die Integration von dem eigenständigen Algorithmus Tensorflow gibt es und wenn es dann mal installiert ist, funktioniert auch alles super. Da Tensorflow in Phyton programmiert ist, muss auch Phyton auf dem Rechner installiert sein. Du siehst also, es ist einiges einzurichten, damit wir Deep learning betreiben können. Hier möchte ich dann auch gerne auf @mueller2019deep verweisen, der zu dem Thema Deep learning einen guten Einstieg liefert. Denn wir machen hier eigentlich kein Deep learning, denn unsere neuronalen Netzwerke werden nicht viele Schichten haben, dass würde hier mein kleiner Rechner auch gar nicht schaffen.

Neben TensorFlow / Keras zeige ich auch nochmal die Anwendung der etwas veralteten R Pakete `neuralnet` und `nnet`. Wie immer musst du selber entscheiden, was du brauchst. Der Vorteil des Paketes `nnet` ist, dass wir das Paket zum einen mit Rezepten und Tuning gut nutzen können. Zum anderen brauchen wir aber nicht diesen Installationsmarathon wie bei TensorFlow / Keras. Ich präsnetiere hier einfach die Auswahl und du schaust dann was passt.

::: column-margin
Wir immer basiert dieser Text zum Teilen auch auf guten Tutorien im Netz. Zum einen ist es das Tutorium [Understanding the Magic of Neural Networks](https://blog.ephorie.de/understanding-the-magic-of-neural-networks) und das Tutorium [A Beginner's Guide to Neural Networks and Deep Learning](https://wiki.pathmind.com/neural-network). Beide Tutorien sind in Englisch und Teile beider Tutorien hat auch diesen Text hier inspiriert. Nicht zu vergessen das Tutorium [A Quick Introduction to Neural Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/).
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, tidymodels, magrittr, 
               janitor, keras, tensorflow, see,
               neuralnet, NeuralNetTools,
               OneR,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
##
set.seed(2025429)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Neuronale Netzwerke theoretisch

| **Neural network**  | **Logistic regression (eng.)** | Logistische Regression (deu.) |
|:--------------------|:-------------------------------|-------------------------------|
| Activation function | Link function                  | Link Funktion                 |
| Weights             | Coefficients / Slope           | Koeffizienten / Steigung      |
| Bias                | Intercept                      | Intercept                     |
| Variance            | Residuals                      | Fehler / Residuen             |
| Learning            | Fitting                        | Modellieren                   |

: test

::: clumn-margin
[What is the role of the bias in neural networks?](https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks)
:::

```{r}
little_red_tbl <- tibble(grosse_ohren = c(1, 0, 1), 
                         grosse_augen = c(1, 1, 0),
                         grosse_zaehne = c(1, 0, 0) , 
                         freundlich = c(0, 1, 1), 
                         faltig = c(0, 1, 0), 
                         gutaussehend = c(0, 0, 1),
                         renn_weg = c(1, 0, 0), 
                         schrei = c(1, 0, 0), 
                         ruf_holzfaeller = c(1, 0, 0), 
                         plaudere = c(0, 1, 1), 
                         geh_hin = c(0, 1, 0), 
                         biete_essen = c(0, 1, 1), 
                         rettung = c(0, 0, 1))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-little_red_data
#| tbl-cap: "Die beiden Datensätze für das neuronale Netzwerk. Wie lässt sich der Input sinnvoll mit dem Output verbinden? Wir geben dafür drei Hidden Layers vor, die dann die Charaktere Wolf, Goßmutter und den Holzfäller repräsentieren.."
#| tbl-subcap: 
#|   - "Daten des Input Layers."
#|   - "Daten des Output Layers."
#| layout-ncol: 2

little_red_tbl %>% 
  select(grosse_ohren:gutaussehend) %>% 
  t() %>% 
  kable(align = "c", "pipe")

little_red_tbl %>% 
  select(renn_weg:rettung) %>% 
  t() %>% 
  kable(align = "c", "pipe")
```

```{r}
neuralnetwork <- neuralnet(renn_weg + schrei + ruf_holzfaeller + plaudere + 
                             geh_hin + biete_essen + rettung ~ 
                             grosse_ohren + grosse_augen + grosse_zaehne + 
                             freundlich + faltig + gutaussehend,
                           data = little_red_tbl, hidden = 3, 
                           exclude = c(1, 8, 15, 22, 26, 30, 34, 38, 42, 46), 
                           lifesign = "none", linear.output = FALSE)
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-nn-01
#| fig-align: center
#| fig-height: 6
#| fig-width: 7
#| fig-cap: "Visualisierung des neuronalen Netzwerkes mit drei vorgebenen Hidden Layers. Die Hidden Layers repräsentieren in diesem Beispiel die Characktere Wolf, Großmutter und den Holzfäller."

plotnet(neuralnetwork, bias = FALSE, pad_x = 0.74)
```

Das folgende etwas mathematische Beispiel ist von @kubat2017introduction, pp. 65-73, entnommen. Ich habe das Beispiel dann für R adaptiert, so dass wir hier auch R Code zum ausprobieren haben.

::: column-margin
Das Buch [An Introduction to Machine Learning](https://link.springer.com/book/10.1007/978-3-319-63913-0) kannst du dir an der HS Osnabrück als PDF über die Hochschule runterladen.
:::

Wir haben ein simples Datenbeispiel von vier Beobachtungen mit jeweils einem $x_1$ und einem $x_2$ Wert als Prädiktor. Der Wert den $x_1$ oder $x_2$ annehmen können sind binär. Wir haben also für unsere beiden Prädiktoren nur $0/1$ Werte vorliegen. Unser Label $y$ ist ebenfalls binär. Entweder ist die betreffende Beobachtung erkrankt oder eben nicht. In unserem Beispiel sind die ersten beiden Beobachtungen nicht erkrankt und die letzten beiden Beobachtungen sind erkrankt. Schauen wir uns den Datensatz einmal an.

```{r}
data_tbl <- tibble(y = c(0, 0, 1, 1),
                   x_1 = c(0, 1, 0, 1),
                   x_2 = c(0, 0, 1, 1))
data_tbl
```

Faktisch wollen wir jetzt eine Grae durch die Punkte legen, so dass wir die gesunden von den kranken Beobachtungen trennen können. Praktisch machen wir das mit einer linearen Funktion $h(x)$, die uns anhand von $x_1$ und $x_2$ eine Aussagen über den Status von $y$ ermöglicht. Wir erhalten zuerst einen *numerischen* Wert, den wir dann noch mit einer Regel in eine $0/1$ Entscheidung umwandeln müssen.

$$
h(x) \sim w_0 + w_1 \cdot x_1 + w_2 \cdot x_2
$$

Nun können wir die Formel nochmal kompakter schreiben.

$$
h(x) \sim \sum_{i = 0}^{n=2} w_i x_i
$$

Wir drücken im Folgenden damit aus, das wir auch die Gewichte $w_i$ mit den einzelnen $x_i$ multiplizieren und anschließend aufsummieren. Anhand der aufsummierten Zahl aus $h(x)$ können wir dann eine Entscheidung für $0/1$ treffen. In unserem Beispiel entscheiden wir uns dazu, das wir $y=0$ annehmen wenn $h(x) < 0$ ist oder aber $y=1$ annehmen, wenn $h(x) \geq 0$ ist. Wir können das einmal formal aufschreiben.

$$
h(x)= 
\begin{cases}
    1,& \text{wenn } h(x)\geq 0\\
    0,              & \text{ansonsten}
\end{cases}
$$

Nichts anders ist dann auch unser Neuron, was die Entscheidungen trifft. Wir haben vier verschiedene $x_1$ und $x_2$ Kombinationen und gewichten diese beiden $x$ dann noch einem Gewichtsvektor. Wenn wir dann als aufsummiertes Ergebnis eine Zahl größer als $0$ erhalten, dann gibt unser Neuron als Klassifikationsergebnis ein $1$ wieder.

```{r}
neuron <- function(input, weights) {if_else(input %*% weights > 0, 1, 0)}
```

Wir brauchen alos zum einen nochmal die Inputmatrxi. Die bauen wir uns einmal mit der Funktion `model.matrix()`. Dann haben wir drei Spalten für jedes Gewicht $w$. Dann brauchen wir noch die drei Gewichte $w_0$, $w_1$ und $w_2$. Nichts anders als der Intercept und die Steigung in einem linearen Modell.

```{r}
input <- data_tbl %$%
  model.matrix(~ x_1 + x_2)
input
```

```{r}
weights <- c(0.1, 0.3, 0.4)
```

```{r}
eta <- 0.2
```

```{r}
for(i in 1:4){
  weights <- weights + eta * (data_tbl$y[i] - neuron(weights, input[i,])) * input[i,]
  print(weights)
}
```

```{r}
input %*% c(-0.3, 0.1, 0.4)
```

```{r}
neuron(input, weights = c(-0.3, 0.1, 0.4))
```

## Daten

In diesem Kapitel wolle wir uns aber mal auf einen echten Datensatz anschauen. Wir nutzen daher einmal den Gummibärchendatensatz. Als unser Label und daher als unser Outcome nehmen wir das Geschlecht `gender`. Dabei wollen wir dann die weiblichen Studierenden vorhersagen. Im Weiteren nehmen wir nur die Spalte Geschlecht sowie als Prädiktoren die Spalten `most_liked`, `age`, `semester`, und `height`.

```{r}
gummi_tbl <- read_excel("data/gummibears.xlsx") %>% 
  mutate(gender = as_factor(gender),
         most_liked = as_factor(most_liked)) %>% 
  select(gender, most_liked, age, semester, height) %>% 
  drop_na(gender)

```

Wir dürfen keine fehlenden Werte in den Daten haben. Wir können für die Prädiktoren später die fehlenden Werte imputieren. Aber wir können keine Labels imputieren. Daher entfernen wir alle Beobachtungen, die ein `NA` in der Variable `gender` haben. Wir haben dann insgesamt $n = `r nrow(gummi_tbl)`$ Beobachtungen vorliegen. In @tbl-gummi-prepro sehen wir nochmal die Auswahl des Datensatzes in gekürzter Form.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-gummi-model-compare
#| tbl-cap: Auszug aus dem Daten zu den Gummibärchendaten.

gummi_raw_tbl <- gummi_tbl %>% 
  mutate(gender = as.character(gender),
         most_liked = as.character(most_liked))

rbind(head(gummi_raw_tbl),
      rep("...", times = ncol(gummi_raw_tbl)),
      tail(gummi_raw_tbl)) %>% 
  kable(align = "c", "pipe")
```

Unsere Fragestellung ist damit, können wir anhand unserer Prädiktoren männliche von weiblichen Studierenden unterscheiden und damit auch klassifizieren? Um die Klassifikation mit Entscheidungsbäumen rechnen zu können brauchen wir wie bei allen anderen Algorithmen auch einen Trainings- und Testdatensatz. Wir splitten dafür unsere Daten in einer 3 zu 4 Verhältnis in einen Traingsdatensatz sowie einen Testdatensatz auf. Der Traingsdatensatz ist dabei immer der größere Datensatz. Da wir aktuell nicht so viele Beobachtungen in dem Gummibärchendatensatz haben, möchte ich mindestens 100 Beobachtungen in den Testdaten. Deshalb kommt mir der 3:4 Split sehr entgegen.

```{r}
gummi_data_split <- initial_split(gummi_tbl, prop = 3/4)
```

Wir speichern uns jetzt den Trainings- und Testdatensatz jeweils separat ab. Die weiteren Modellschritte laufen alle auf dem Traingsdatensatz, wie nutzen dann erst ganz zum Schluss einmal den Testdatensatz um zu schauen, wie gut unsere trainiertes Modell auf den neuen Testdaten funktioniert.

```{r}
gummi_train_data <- training(gummi_data_split)
gummi_test_data  <- testing(gummi_data_split)
```

Nachdem wir die Daten vorbereitet haben, müssen wir noch das Rezept mit den Vorverabreitungsschritten definieren. Wir schreiben, dass wir das Geschlecht `gender` als unser Label haben wollen. Daneben nehmen wir alle anderen Spalten als Prädiktoren mit in unser Modell, das machen wir dann mit dem `.` Symbol. Da wir noch fehlende Werte in unseren Prädiktoren haben, imputieren wir noch die numerischen Variablen mit der Mittelwertsimputation und die nominalen fehlenden Werte mit Entscheidungsbäumen. Dann müssen wir noch alle numerischen Variablen normalisieren und alle nominalen Variablen dummykodieren. Am Ende werde ich nochmal alle Variablen entfernen, sollte die Varianz in einer Variable nahe der Null sein.

```{r}
gummi_rec <- recipe(gender ~ ., data = gummi_train_data) %>% 
  step_impute_mean(all_numeric_predictors()) %>% 
  step_impute_bag(all_nominal_predictors()) %>% 
  step_range(all_numeric_predictors(), min = 0, max = 1) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_nzv(all_predictors())

gummi_rec %>% summary()

```

Alles in allem haben wir ein sehr kleines Modell. Wir haben ja nur ein Outcome und vier Prädiktoren. Trotzdem sollte dieser Datensatz reichen um zu erklären wie Keras oder Tensorflow funktionieren. Am Ende muss man sich aber auch ehrlich machen und sagen, dass ein Datensatz mit unter tausend Beobachtungen eigentlich keinen großen Sinn für ein neuronales Netz macht. Deshalb ist das hier eher eine Demonstration des Algorithmus.

## Neuronale Netze mit `neuralnet`

Neuronale Netze mit den R Paketen `neuralnet` und dem R Paket `nnet` sind mehr oder minder veraltet (eng. *outdated*). Wir können das Paket `neuralnet` nicht über die `parsnip` Umgebung nutzen. Deshalb hier einmal zu Fuß mit all den Komplikationen, die das so mit sich bringt. Auf der anderen Seite liefert das Paket `neuralnet` auch gute Ergebnisse mit wenig rechenlaufzeit. Da musst du dann einmal abwägen, was du in deiner Arbei so brauchst.

Das die Funktion `neuralnet()` nicht mit den Workflow kann, müssen wir uns erstmal wieder den Traingsdatendatz und den Testdatensatz aus unserem Rezept extrahieren. Den Traingsdatensatz können wir uns über die Funktion `juice()` einmal aus dem Rezept ziehen.

```{r}
gummi_train_tbl <- gummi_rec %>% 
  prep %>% 
  juice()
```

Den Testdatensatz müssen wir mit dem Rezept einmal backen. Dann müssen wir noch die Spalte `gender` in eine numerische Spalte umwandeln. Sonst klappt das später nicht mit der Prädiktion und der Konfusionsmatrix.

```{r}
gummi_test_tbl <- gummi_rec %>% 
  prep %>% 
  bake(gummi_test_data) %>% 
  mutate(gender = as_factor(ifelse(gender == "m", 0, 1)))
```

Dann können wir auch schon die Funktion `neuralnet` auf unsere Daten anwenden. Wir wollen fünfmal über die Traingsdaten iterieren (`rep = 5`). Später heißt dieses Iterieren dann auch `epoch`. Dann müssen wir noch den Threshold für den Fehler festlegen, der gerade noch so akzeptabel ist und wo das Wachstum endet. Je kleiner, desto länger dauer der Prozess. Mit einem `threshold = 0.2` sind wir aber schon sehr weit oben, sonst ist der Wert bei $0.01$. Hier musst ein wenig selber mit den Parametern spielen. Eine Tuningmöglichkeit oder eine Kreuzvalidierung musst du dir dann selber programmieren. Wir nehmen dann fünf Hiddenlayers mit jeweils fünf Knoten pro Hiddenlayer.

```{r}
neuralnet_fit <- neuralnet(gender ~., data = gummi_train_tbl, rep = 5, threshold = 0.2,
                           hidden = c(5, 5), lifesign = "minimal")
```

Wenn wir das Modell haben, dann können wir uns hier ganz einfach mal das beste neuronale Netzwerk anschauen. Also die Wiederholung mit dem kleinsten Fehler. In Abbildung @fig-class-nn-02 sehen wir das Netzwerk einmal dargestellt. Die blauen Knoten stellen die Biasknoten dar. Die Zahlen an den Kanten stellen dann die Gewichte dar, die von dem jeweiligen Knoten weitergegeben werden. Die Interpretation des Netzwerks ist so schwer, es ist eben nur eine visuelle Darstellung. Da so eine Abbildung etwas schwer zu interpretieren ist, erlaubt ein neurales Interpretationsdiagramm mehr Einblicke. Die schwarzen Kanten haben einen höheren Einfluss als die grauen Kanten. Die exakte Interpretation der Knoten und der Kanten ist aber dennoch schwierig.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-nn-02
#| fig-align: center
#| fig-height: 7
#| fig-width: 8
#| fig-cap: "Abbildung des neuronalen Netzwerks mit dem kleinsten Fehler."
#| fig-subcap: 
#|   - "Neuronales Netzwerk mit den Gewichten und dem Bias als numerische Representation."
#|   - "Neurales Interpretationsdiagramm für ein neurales Netzwerk."
#| layout-nrow: 1
#| column: page

plot(neuralnet_fit, rep = "best")

plotnet(neuralnet_fit, rep = "best", bias = FALSE, pad_x = 0.59)
```

Am Ende machen wir das Ganze ja nicht um etwas *interpretieren* zu können, sondern um eine Vorhersage zu treffen. Das machen wir mit der Funktion `predict()`. Jetzt wird es wieder nervig. Wir müssen usn merken, dass unser Faktor zwei Level hat mit `0` und `1` wobei die `m = 0` und `w = 1` ist. Als wäre das nicht schon nervig genug, haben wir dann in der Ausgabe von `predict()` nur eine MAtrix mit zwei Spalten. Wir brauchen die zweite Spalte, da wir das Geschlecht `w` vorhersagen wollen.

```{r}
neuralnet_pred <- predict(neuralnet_fit, gummi_test_tbl) %>% 
  round(2)
```

Kurzer Check, ob wir auch alles richtig gemacht haben.

```{r}
range(neuralnet_pred[,1])
range(neuralnet_pred[,2])
```

Und wir stellen fest, dass hier irgendwas mit unserer Wahrscheinlichkeit für die Klassenzugehörigkeit nicht stimmt. Wir haben negative Werte und Werte über Eins. Das macht für eine Wahrscheinlichkeit keinen Sinn. **STOPP**, heißt es jetzt hier!

Ich zeige aber noch wie du dir die Konfusionsmatrix berechnest. Da musst du dich wieder strecken um alles in die Funktion `conf_mat()` richtig rein zu kriegen. Aber Vorsicht, erst wenn du die Wahrscheinlichkeiten hingekriegt hast, dann kannst du mit der Konfusionsmatrix weitermachen.

```{r}
neuralnet_cm <- conf_mat(data = data.frame(.pred_class = as.factor(round(neuralnet_pred[,2])),
                                           gender = as.factor(pull(gummi_test_tbl, gender))), 
                         gender, .pred_class)
```

Dann können wir uns die Konfusionsmatrix auch einmal wiedergeben lassen. Ich wäre hier sehr vorsichtig, was die Werte angeht. Wir haben gerade komische Wahrscheinlichkeiten wiedergegeben bekommen. Daher würde ich der Sache hier nicht trauen und nochmal an der Funktion `neuralnet()` mit anderen Parametern herumprobieren. Man sieht, es hat auch einen Grund warum manche Funktionen nicht in der `parsnip` Umgebung implementiert sind.

```{r}
neuralnet_cm %>% 
  summary %>% 
  mutate_if(is.numeric, round, 2)
```

Hier ist also wirklich Vorsicht geboten, wenn wir uns die Ergebnisse anschauen. Die Ergebnisse sind zwar nicht so schlecht, aber wir vertrauen da nicht dem Algorithmus, wenn wir ungültige Wahrscheinlichkeiten erhalten.

## Neuronale Netze mit `nnet`

Wir können aber das R Paket `nnet` mit unserer bekannten Rezeptumgebung nutzen und uns damit das Leben einfacher machen. Das macht auch in diesem Fall sehr viel mehr Sinn, da wir ja nur komische Wahrscheinlichkeiten der Klassenzugehörigkeit aus der Funktion `neuralnet()` wiederbekommen. Also das ganze einmal ohne wildes Installieren von Tensorflow / Keras. Ein simples neurales Netzwerk in R mit der Engine aus `nnet`.

In unserem Beispiel lassen wir einhundert Replikationen laufen (`epoch = 100`) und wählen auch hier mal fünf Hidden Layers (`hidden_units = 5`). Dann wollen wir natürlich eine Klassifikation rechnen.

```{r}
nnet_mod <- mlp(epochs = 100, hidden_units = 5) %>% 
  set_engine("nnet") %>% 
  set_mode("classification")
```

Wir bringen wieder unser Modell mit dem Rezept des Gummibärchendatensatzes zusammen und können dann den Workflow abspeicherb.

```{r}
nnet_wflow <- workflow() %>% 
  add_model(nnet_mod) %>% 
  add_recipe(gummi_rec)
```

Wie immer starten wir dann den Workflow mit der Funktion `fit()` und erhalten das `nnet` Modell zurück.

```{r}
#| message: false
#| warning: false

nnet_fit <- nnet_wflow %>% 
  parsnip::fit(gummi_train_data)

```

Jetzt müssen wir nur noch mit der Funktion `augment` uns die Vorhersagen mit dem Testdatensatz wiedergeben lassen.

```{r}
nnet_aug <- augment(nnet_fit, gummi_test_data ) 
```

Da wir hier etwas vorsichtig geworden sind, nochmal schnell schauen, ob unsere Wahrscheinlichkeiten der Klassenzugehörigkeit auch wirklich eine Wahrscheinlichkeit ist.

```{r}
pluck(nnet_aug, ".pred_w") %>% range()
```

Ja, das passt soweit und wir können uns dann die Konfusionsmatrix berechnen lassen. Die Ergebnisse sind jetzt nicht so berauschend, aber auf der anderen Seite richtiger als in der Funktion `neuralnet()`.

```{r}
nnet_cm <- nnet_aug %>% 
  conf_mat(gender, .pred_class)

nnet_cm
```

Dann schauen wir uns nochmal die ganzen anderen Gütekriterien aus der Konfusionsmatrix einmal an.

```{r}
nnet_cm %>% summary()
```

Die Ergebnisse sind höchstens okay. Die Accuracy ist nicht sehr hoch und auch der Rest der Werte ist eher mittelmäßig. Das Ganze sehen wir dann in @fig-class-nnet-01 auch nochmal entsprechend in der ROC Kurve visualisiert. Die ROC Kurve sieht nur mittelmäßig aus. Wir müssten hier auf jeden Fall nochmal über Kreuzvalidierung und Tuning nachdenken. Ohne Kreuzvalidierung und Tuning würde ich das Modell nicht anwenden.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-nnet-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "ROC Kurve für den `nnet` Algorithmus."

nnet_aug %>% 
  roc_curve(gender, .pred_w, event_level = "second") %>% 
  autoplot()
```

## Neuronale Netze mit Keras / Tensorflow

Deeplearning in R

Nochmal genauer anschauen:

https://colorado.rstudio.com/rsc/churn/modeling/tensorflow-w-r.nb.html

https://parsnip.tidymodels.org/reference/details_linear_reg_keras.html

https://camrongodbout.medium.com/tensorflow-in-a-nutshell-part-one-basics-3f4403709c9d

https://medium.com/analytics-vidhya/neural-networks-in-a-nutshell-bb013f40197d

```{r}
keras_mod <- mlp() %>% 
  set_engine("keras") %>% 
  set_mode("classification")
```

```{r}
keras_wflow <- workflow() %>% 
  add_model(keras_mod) %>% 
  add_recipe(gummi_rec)
```

```{r}
#| message: false
#| warning: false

keras_fit <- keras_wflow %>% 
  parsnip::fit(gummi_train_data)

```

```{r}
keras_aug <- augment(keras_fit, gummi_test_data ) 
```

```{r}
keras_cm <- keras_aug %>% 
  conf_mat(gender, .pred_class)

keras_cm
```

```{r}
keras_cm %>% summary()
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-keras-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "ROC Kurve für den `keras` Algorithmus."

keras_aug %>% 
  roc_curve(gender, .pred_w, event_level = "second") %>% 
  autoplot()
```

::: callout-note
## Kann ich auch eine Kreuzvalidierung für Keras / Tensorflow durchführen?

Ja, kannst du. Wenn du *nur* eine Kreuzvalidierung durchführen willst, findest du alles im @sec-knn für den $k$-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf Keras / Tensorflow Algorithmus anwenden.
:::

## Tuning

Was heißt Tuning? Wie bei einem Auto können wir an verschiedenen Stellschrauben bei einem mathematischen Algorithmus schrauben. Welche Schrauben und Teile das sind, hängt dann wieder vom Algorithmus ab. Im Falle des xgboost Algorithmus können wir an folgenden Parametern drehen und jeweils schauen, was dann mit unserer Vorhersage passiert. Insgesamt hat der [keras Algorithmus fünf Tuningparameter](https://parsnip.tidymodels.org/reference/details_mlp_keras.html), wir wählen jetzt für uns hier drei aus. Ich nehme hier auch nur drei Parameter, da sich dann drei Parameter noch sehr gut visuell darstellen lassen. In der Anwendung wäre dann natürlich besser alle Parameter zu tunen, aber das dauert dann auch lange.

-   `hidden_units`, Anzahl der Ebenen (eng. *layer*) in dem neuronalen Netzwerk. Wie viele Ebenen soll unser Netzwerk haben? Oder auch wie *deep* soll das Netzwerk gebaut werden?
-   `penalty`, ein Wert für die Regulierung des neuronalen Netzwerk.
-   `epochs`, bezieht sich auf einen Zyklus durch die Layer für den gesamten Trainingsdatensatz. Wie oft rechnen wir den Trainingsdatensatz und trainieren unser Netzwerk?

Nun ist es so, dass wir natürlich nicht händisch alle möglichen Kombinationen von der Anzahl der ausgewählten Variablen pro Baum, der kleinsten Knotengröße und der Anzahl der Bäume berechnen wollen. Das sind ziemlich viele Kombinationen und wir kommen dann vermutlich schnell durcheinander. Deshalb gibt es die Funktion `tune()` aus dem R Paket `tune`, die uns einen Prozess anbietet, das Tuning automatisiert durchzuführen.

Da ich nicht ewig warten wollte, habe ich noch das parallele Rechnern aktiviert, in dem ich mir die Anzahl an Rechenkernen minus eins wiedergeben habe lassen.

```{r}
cores <- parallel::detectCores() - 1
```

Als erstes müssen wir uns ein Objekt bauen, das aussieht wie ein ganz normales Modell in der Klassifikation. Aber wir ergänzen jetzt noch hinter jeder zu tunenden Option noch die Funktion `tune()`. Das sind die Parameter des Algorithmus, die wir später tunen wollen.

```{r}
tune_spec <- mlp(hidden_units = tune(),
                 penalty = tune(), 
                 epochs = tune()) %>% 
  set_engine("keras", num.threads = cores) %>% 
  set_mode("classification") 

tune_spec
```

Jetzt bauen wir uns den Workflow indem wir statt unserem Modell, die Tuninganweisung in den Workflow reinnehmen. Echt simpel und straightforward. Das Rezept bleibt ja das Gleiche.

```{r}
gummi_tune_wflow <- workflow() %>% 
  add_model(tune_spec) %>% 
  add_recipe(gummi_rec)
```

Jetzt müssen wir noch alle Kombinationen aus den drei Parametern `hidden_units`, `penalty` und `epochs` ermitteln. Das macht die Funktion `grid_regular()`. Es gibt da noch andere Funktionen in dem R Paket `tune`, aber ich konzentriere mich hier auf die einfachste. Jetzt müssen wir noch die Anzahl an Kombinationen festlegen. Ich möchte für jeden Parameter fünf Werte tunen. Daher nutze ich hier die Option `levels = 5` auch damit hier die Ausführung nicht so lange läuft. Fange am besten mit `levels = 5` an und schaue, wie lange das zusammen mit der Kreuzvalidierung dann dauert. Dann kannst du die Levels noch hochschrauben. Beachte aber, dass mehr Level nur mehr *Zwischenschritte* bedeutet. Jede Option hat eine Spannweite `range`, die du dann anpassen musst, wenn du *höhere* Werte haben willst. Mehr Level würden nur mehr Zwischenschritte bedeuten.

```{r}
gummi_grid <- grid_regular(hidden_units(range = c(1, 100)),
                           penalty(),
                           epochs(range = c(10, 200)),
                           levels = 5)
```

Das Tuning nur auf dem Trainingsdatensatz durchzuführen ist nicht so eine gute Idee. Deshalb nutzen wir hier auch die Kreuzvalidierung. Eigentlich ist eine 10-fache Kreuzvalidierung mit $v=10$ besser. Das dauert mir dann aber hier im Skript viel zu lange. Deshalb habe ich hier nur $v=5$ gewählt. Wenn du das Tuning rechnest, nimmst du natürlich eine 10-fach Kreuzvalidierung.

```{r}
gummi_folds <- vfold_cv(gummi_train_data, v = 5)
```

Nun bringen wir den Workflow zusammen mit dem Tuninggrid und unseren Sets der Kreuzvaidierung. Daher pipen wir den Workflow in die Funktion `tune_grid()`. Als Optionen brauchen wir die Kreuzvaldierungsdatensätze und das Tuninggrid. Wenn du `control_grid(verbose = TRUE)` wählst, dann erhälst du eine Ausgabe wie weit das Tuning gerade ist. **Achtung!**, das Tuning dauert seine Zeit. Im Falle des keras Algorithmus dauert das Tuning **extrem lange**, aber immer noch nur ein paar Stunden. Wenn du dann alle fünf Parameter des keras Algorithmustunen wollen würdest, dann würde die Berechnung Tage dauern. Deshalb ist ein Großerechner mit mehreren Kernen unabdingbar für die Nutzung von *deep learning* Du kannst das Ergebnis des simpleren Tunings auch in der Datei `gummi_xgboost_tune_res.rds` finden.

```{r}
#| eval: false
gummi_tune_res <- gummi_tune_wflow %>% 
   tune_grid(resamples = gummi_folds,
             grid = gummi_grid,
             control = control_grid(verbose = FALSE))
```

```{r}
#| eval: false
#| echo: false

## write_rds(gummi_tune_res, "data/gummi_keras_tune_res.rds")
```

Damit du nicht das Tuning durchlaufen lassen musst, habe ich das Tuning in die Datei `gummi_xgboost_tune_res.rds` abgespeichert und du kannst dann über die Funktion `read_rds()` wieder einlesen. Dann kannst du den R Code hier wieder weiter ausführen.

```{r}
#| echo: false

gummi_tune_res <- read_rds("data/gummi_keras_tune_res.rds")
```

Nachdem das Tuning durchgelaufen ist, können wir uns über die Funktion `collect_metrics()`, die Ergebnisse des Tunings für jede Kombination der drei Parameter `hidden_units`, `penalty` und `epochs` wiedergeben lassen. Diese Ausgabe ist super unübersichtlich. Ich habe mich ja am Anfange des Abschnitts auch für drei Tuningparameter entschieden, da sich dann diese drei Parameter noch gut visualisieren lassen. Deshalb einmal die Abbildung der mittleren Accuarcy und der mittleren AUC-Werte über alle Kreuzvalidierungen.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-keras-02
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Tuning Kurven für den `keras` Algorithmus."

gummi_tune_res %>%
  collect_metrics() %>%
  mutate(hidden_units = as_factor(hidden_units),
         penalty = as_factor(penalty)) %>%
  ggplot(aes(epochs, mean, color = hidden_units, linetype = penalty)) +
  theme_minimal() +
  geom_line(alpha = 0.6) +
  geom_point() +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_okabeito()
```

Damit wir nicht händisch uns die beste Kombination raussuchen müssen, können wir die Funktion `show_best()` nutzen. Wir wählen hier die beste Accuarcy und erhalten dann die sortierten Ergebnisse nach der Accuarcy des Tunings.

```{r}
gummi_tune_res %>%
  show_best("accuracy")
```

Das war die Funktion `show_best()` aber wir können uns auch die gleich die besten Parameter nach der Accuracy raus ziehen. Das Rausziehen der besten Parameter macht für uns die Funktion `select_best()`.

```{r}
best_keras <- gummi_tune_res %>%
  select_best("accuracy")

best_keras
```

Wir sehen, dass wir `hidden_units = 75` wählen sollten. Dann müssen wir als Penalty `penalty = 0.0000000001` nutzen. Die Anzahl an Durchläufen pro Training ist dann `epochs = 200`. Müssen wir jetzt die Zahlen wieder in ein Modell eingeben? Nein, müssen wir nicht. Mit der Funktion `finalize_workflow()` können wir dann die besten Parameter aus unserem Tuning gleich mit dem Workflow kombinieren. Dann haben wir unseren finalen, getunten Workflow. Du siehst dann auch in der Ausgabe, dass die neuen Parameter in dem keras Algorithmus übernommen wurden

```{r}
final_gummi_wf <- gummi_tune_wflow %>% 
  finalize_workflow(best_keras)

final_gummi_wf 
```

Jetzt bleibt uns nur noch der letzte Fit übrig. Wir wollen unseren finalen, getunten Workflow auf die Testdaten anwenden. Dafür gibt es dann auch die passende Funktion. Das macht für uns die Funktion `last_fit()`, die sich dann die Informationen für die Trainings- und Testdaten aus unserem Datensplit von ganz am Anfang extrahiert.

```{r}
#| cache: false
#| message: false
#| warning: false

final_fit <- final_gummi_wf %>%
  last_fit(gummi_data_split) 
```

Da wir immer noch eine Kreuzvaldierung rechnen, müssen wir dann natürlich wieder alle Informationen über alle Kreuzvaldierungsdatensätze einsammeln. Dann erhalten wir unsere beiden Gütekriterien für die Klassifikation des Geschlechts unser Studierenden nach dem keras Algorithmus. Die Zahlen sind schon gut für echte Daten. Eine Accuracy von 81% bedeutet das wir über acht von zehn Studierenden richtig klassifizieren. Die AUC ist auch schon fast hervorragend, wir bringen kaum Label durcheinander.

```{r}
final_fit %>%
  collect_metrics()
```

Dann bleibt uns nur noch die ROC Kurve zu visualisieren. Da wir wieder etwas faul sind, nutzen wir die Funktion `autoplot()`. Als Alternative geht natürlich auch das [R Paket `pROC`](https://web.expasy.org/pROC/screenshots.html), was eine Menge mehr Funktionen und Möglichkeiten bietet.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-class-keras-03
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "ROC Kurve für den `keras` Algorithmus nach der Kreuvalidierung und dem Tuning."

final_fit %>%
  collect_predictions() %>% 
  roc_curve(gender, .pred_w, event_level = "second") %>% 
  autoplot()
```

Da wir eine ROC Kurve hier vorliegen haben, die sehr weit weg von der Diagonalen ist, haben wir sehr viele richtig vorhergesagte Studierende in unseren Testdaten. Unser Modell funktioniert um das Geschlecht von Studierenden anhand unserer Gummibärchendaten vorherzusagen. Besonders bei den neuronalen Netzwerken sieht man, wenn du die ROC Kurven vor und nach dem Tuning vergleichst, wie wichtig das Tuning ist. Dabei haben wir hier nur die abgespeckte Variante genutzt, da mein Rechner nicht länger laufen sollte.

## Referenzen {.unnumbered}
