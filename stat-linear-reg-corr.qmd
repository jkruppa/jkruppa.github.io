```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Korrelation {#sec-lin-reg-corr}

Die Korrelation gibt uns die Information welche Steigung die Gerade in einer simplen linearen Regression hat. Dabei erlaubt es die Korrelation uns verschiedene Geraden miteinander zu vergleichen. Die Korrelation ist nämlich einheitslos. Wir standardisieren durch die Anwendung der Korrelation die Steigung der Geraden dafür auf -1 bis +1. Damit ist die Korrelation ein bedeutendes Effektmaß für die Abschätzung eines Zusammenhangs zwischen zwei Variablen.

Es gibt aber ein Problem. Nämlich nur weil etwas miteinander korreliert muss es keinen kausalen Zusammenhang geben. So ist die Ursache und Wirkung manchmal nicht klar zu benennen. Nehmen wir als plaktives Beispiel dicke Kinder, die viel Fernsehen. Wir würden annehmen, dass zwischen dem Fernsehkonsum und dem Gewicht von Kindern eine hohe Korrelation vorliegt. Sind jetzt aber die Kinder dick, weil die Kinder so viel Fernsehen oder schauen einfach dicke Kinder mehr Fernsehen, da die Kinder dick sind und sich nicht mehr so viel bewegen wollen?

::: column-margin
Die Internetseite [Spurious correlations](https://www.tylervigen.com/spurious-correlations) zeigt verschiedene *zufällige* Korrelationen zwischen zwei *zufällig* ausgewählten Variablen aus den USA.
:::

Im Weiteren ist das Wort *korrelieren* zum Gattungsbegriff in der Statistik geworden, wenn es um den Vergleich oder den Zusammenhang von zwei oder mehreren Variablen geht. Das heißt, in der Anwendung wird gesagt, dass wir A mit B *korrelieren* lassen wollen. Das Wort *korrelieren* steht jetzt aber nicht für das Konzept statistische Korrelation sondern ist Platzhalter für eine noch vom Anwender zu definierende oder zu findene statistische Methode.

In diesem Kapitel wollen wir uns mit der statisischen Korrelation beschäftigen. Die statistische Korrelation ist weniger aufregender, denn am Ende ist die Korrelation nur eine Zahl zwischen -1 und +1.

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Wenn wir in der Klausur eine Korrelation berechnen wollen, dann sprechen wir immer von der Korrelation nach Pearson.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, readxl,
               corrplot)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Wir wollen uns erstmal mit einem einfachen Datenbeispiel beschäftigen. Wir können die Korrelation auf sehr großen Datensätzen berechene , wie auch auf sehr kleinen Datensätzen. Prinzipiell ist das Vorgehen gleich. Wir nutzen jetzt aber erstmal einen kleinen Datensatz mit $n=7$ Beobachtungen. In der @tbl-corr-0 ist der Datensatz `simplel_tbl` dargestellt. Wir wollen den Zusammenhang zwischen der Sprungweite in \[cm\] und dem Gewicht in \[mg\] für sieben Beobachtungen modellieren.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Datensatz mit einer normalverteilten Variable `jump_length` und der normalverteilten Variable `weight`. 
#| label: tbl-corr-0

simple_tbl <- tibble(jump_length = c(1.2, 1.8, 1.3, 1.7, 2.6, 1.8, 2.7),
                     weight = c(0.8, 1, 1.2, 1.9, 2, 2.7, 2.8))

simple_tbl %>% kable(align = "c", "pipe")
```

In @fig-scatter-corr-01 sehen wir die Visualisierung der Daten `simple_tbl` in einem Scatterplot mit einer geschätzen Gerade. Wir wollen jetzt mit der Korrelation die Steigung der Geraden *unabhängig* von der Einheit beschreiben. Oder wir wollen die Steigung der Geraden standardisieren auf -1 bis 1.

```{r}
#| echo: false
#| message: false
#| label: fig-scatter-corr-01
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "Scatterplot der Beobachtungen der Sprungweite in \\[cm\\] und dem Gewicht in \\[mg\\]. Die Gerade verläuft mittig durch die Punkte."

ggplot(simple_tbl, aes(weight, jump_length)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  theme_bw() +
  xlim(0, 3.5) + ylim(0, 3.5)
```

## Korrelation theoretisch

[Wenn wir zwei verteilte Variablen miteinander korrelieren möchten, dann nutzen wir die Korrelation nach Pearson. Wenn wir nicht-normalverteilte Variablen miteinander korrelieren möchten, dann nutzen wir die Korrelation nach Spearman]{.aside}

Wir schauen uns hier die Korrelation nach Pearson an. Die Korrelation nach Pearson nimmt an, dass beide zu korrelierende Variablen einer Normalverteilung entstammen. Wenn wir keine Normalverteilung vorliegen haben, dann nutzen wir die Korrelation nach Spearman. Die Korrelation nach Spearman basiert auf den Rängen der Daten und ist ein nicht-parametrisches Verfahren. Die Korrelation nach Pearson ist die parametrische Variante. Wir bezeichnen die Korrelation entweder mit $r$ oder dem griechischen Buchstaben $\rho$ als *rho* gesprochen.

Was macht nun die Korrelation? Die Korrelation gibt die Richtung der Geraden an. Oder noch konkreter die Steigung der Geraden normiert auf -1 bis 1. Die @fig-corr1 zeigt die Visualisierung der Korrelation für drei Ausprägungen. Eine Korrelation von $r = -1$ bedeutet eine maximale negative Korrelation. Die Gerade fällt in einem 45° Winkel. Eine Korrelation von $r = +1$ bedeutet eine maximale positive Korrelation. Die gerade steigt in einem 45° Winkel. Eine Korrelation von $r = 0$ bedeutet, dass keine Korrelation vorliegt. Die Grade verläuft parallel zur x-Achse.

::: column-page
![Visualisierung der Korrelation für drei Ausprägungen des Korrelationskoeffizient.](images/statistical_modeling_corr){#fig-corr1 fig-align="center" width="80%"}
:::

Im Folgenden sehen wir die Formel für den Korrelationskoeffizient nach Pearson.

$$
\rho = r_{x,y} = \cfrac{s_{x,y}}{s_x \cdot s_y}
$$

Wir berechnen die Korrelation immer zwischen *zwei* Variablen $x$ und $y$. Es gibt keine multiple Korrelation über mehr als zwei Variablen. Im Zähler der Formel zur Korrelation steht die Kovarianz von $x$ und $y$.

Wir können mit folgender Formel die Kovarianzen zwischen den beiden Variablen $x$ und $y$ berechnen.

$$
s_{x,y} = \sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})
$$

Die folgende Formel berechnet die quadrierten Abweichung der Beobachtungen von $x$ zum Mittelwert $\bar{x}$.

$$
s_x = \sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}
$$

Die folgende Formel berechnet die quadrierten Abweichung der Beobachtungen von $y$ zum Mittelwert $\bar{y}$.

$$
s_y = \sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}
$$

In @tbl-corr-example ist der Zusammenhang nochmal Schritt für Schrit aufgeschlüsselt. Wir berechnen erst die Abweichungsquadrate von $x$ und die Abweichungsquadrate von $y$. Dann noch die Quadrate der Abstände von $x$ zu $y$. Abschließend summieren wir alles und zeihen noch die Wurzel für die Abweichungsquadrate von $x$ und $y$.

::: column-page
| jump_length $\boldsymbol{y}$ | weight $\boldsymbol{x}$ | $\boldsymbol{(y_i-\bar{y})^2}$ | $\boldsymbol{(x_i-\bar{x})^2}$ | $\boldsymbol{(x_i-\bar{x})(y_i-\bar{y})}$ |
|:----------------------------:|:-----------------------:|:------------------------------:|:------------------------------:|:-----------------------------------------:|
|             1.2              |           0.8           |              0.45              |              0.94              |                   0.65                    |
|             1.8              |           1.0           |              0.01              |              0.60              |                   0.06                    |
|             1.3              |           1.2           |              0.33              |              0.33              |                   0.33                    |
|             1.7              |           1.9           |              0.03              |              0.02              |                   -0.02                   |
|             2.6              |           2.0           |              0.53              |              0.05              |                   0.17                    |
|             1.8              |           2.7           |              0.03              |              0.86              |                   -0.07                   |
|             2.7              |           2.8           |              0.69              |              1.06              |                   0.85                    |
|                              |         $\sum$          |              2.05              |              3.86              |                   1.97                    |
|                              |      $\sqrt{\sum}$      |              1.43              |              1.96              |                                           |

: Tabelle zur Berechnung des Korrelationskoeffizient {#tbl-corr-example}
:::

Wir können die Zahlen dann aus der Tabelle in die Formel der Korrelation nach Pearson einsetzen. Wir erhalten eine Korrelation von 0.70 und haben damit eine recht starke positve Korrelation vorliegen.

$$
\rho = r_{x,y} = \cfrac{1.97}{1.96 \cdot 1.43} = 0.70
$$ Wir können mit der Funktion `cor()` in R die Korrelation zwischen zwei Spalten in einem Datensatz berechnen. Wir überprüfen kurz unsere Berechnung und stellen fest, dass wir richtig gerechnet haben.

```{r}
cor(simple_tbl$jump_length, simple_tbl$weight)
```

In @fig-corr2 sehen wir nochmal die Zusammenhänge der Abstände farbig hervorgehoben. Dader Nenner nur positive Zahlen annehmen kann, wird das Vorzeichen der Korrelation durch den Zähler bestimmt.

![Visualisierung der Korrelation nochmal anders. Um die Korrelation zu berechnen teilen wir die Quadrate mit den roten und grünen Rändern durch die Wurzel der Quadrate der roten und grünen Linien. Wenn die Quadrate gleich groß sind, dann haben wir eine Korrelation von $r = 1.$](images/statistical_modeling_corr_2){#fig-corr2 fig-align="center" width="80%"}

## Korrelation in R

Wir nutzen die Korrelation in R selten nrur für zwei Variablen. Meistens schauen wir uns alle *numerischen* Variablen gemeinsam in einer Abbildung an. Wir nennen diese Abildung auch Korrelationsplot. Faktoren sind keine numerischen Variablen. Daher kann es sein, dass für dein Experiment kein Korrelationsplot in Frage kommt.

Wir schauen uns jetzt nochmal einen die Berechnung für den Datensatz `simple_tbl` an. Wir müssen für die Korrelation zwischen zwei Variablen diese Variablen mit dem `$`-Zeichen aus dem Datensatz extrahieren. Die Funktion `cor()` kann nur mit Vektoren oder *ganzen* numerischen Datensätzen arbeiten.

Wir können den Korrelationskoeffizienten nach Pearson mit der Option `method = "pearson"` auswählen.

```{r}
cor(simple_tbl$jump_length, simple_tbl$weight, method = "pearson")
```

Wenn wir die nicht-parametrische Variante des Korrelationskoeffizienten nach Spearman berechnen wollen nutzen wir die Option `method = "spearman"`.

```{r}
cor(simple_tbl$jump_length, simple_tbl$weight, method = "spearman")
```

Wir können auch einen statistischen Test für die Korrelation rechnen. Die Nullhypothese $H_0$ wäre hierbei, dass die Korrelation $r = 0$ ist. Die Funktion `cor.test()` liefert den entsprechenden $p$-Wert für die Entscheidung gegen die Nullhypothese.

```{r}
cor.test(simple_tbl$jump_length, simple_tbl$weight, method = "pearson")
```

Aus dem Test erhalten wir den $p$-Wert von $0.079$. Damit liegt der $p$-Wert über den Signifikanzniveau von $\alpha$ gleich 5%. Wir können somit die Nullhypothese nicht ablehnen. Wir sehen hier, die Probelematik der kleinen Falzahl. Obwohl unsere Korrelation mit $0.7$ groß ist erhalten wir einen $p$-Wert, der nicht die Grenze von 5% unterschreitet. Wir sehen, dass die starre Grenze von $\alpha$ auch Probleme bereitet.

Abschließend wollen wir uns noch die Funktion `corrplot()` aus dem gleichnamigen R Paket `corrplot` anschauen. Die [Hilfeseite zum Paket](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) ist sehr ausführlich und bietet noch eine Reihe an anderen Optionen. Wir benötigen dafür einen etwas größeren Datensatz mit mehreren numerischen Variablen. Wir nutzen daher den Gummibärchendatensatz und selektieren die Spalten `count_bears` bis `semester` aus.

```{r}
#| message: false
corr_gummi_tbl <- read_excel("data/gummibears.xlsx") %>% 
  select(count_bears:semester)
```

Wir brauchen für die Funktion `corrplot()` eine Matrix mit den paarweisen Korrelationen. Wir können diese Matrix wiederum mit der Funktion `cor()` erstellen. Wir müssen dazu aber erstmal alle numerischen Variablen mit `select_if()` selektieren und dann alle fehlenden Werte über `na.omit()` entfernen.

```{r}
cor_mat <- corr_gummi_tbl %>% 
  select_if(is.numeric) %>% 
  na.omit %>% 
  cor()

cor_mat %>% round(3)
```

Wir sehen das in der Korrelationsmatrix jeweils über und unterhalb der Diagonalen die gespiegelten Zahlen stehen. Wir können jetzt die Matrix `cor_mat` in die Funktion `corrplot()` stecken und uns den Korrelationsplot in @fig-corrplot-01 einmal anschauen.

```{r}
#| echo: true
#| message: false
#| label: fig-corrplot-01
#| fig-align: center
#| fig-height: 6
#| fig-width: 6
#| fig-cap: "Farbiger paarweiser Korrelationsplot für die numerischen Variablen aus dem Datensatz zu den Gummibärchen. Die Farben spiegeln die Richtung der Korrelation wieder, die Größe der Kreise die Stärke."

corrplot(cor_mat)
```

Wir sehen in @fig-corrplot-01, dass wir eine schwache positive Korrelation zwischen `count_color` und `count_bears` haben, angezeigt durch den schwach blauen Kreis. Der Rest der Korrelation ist nahe Null, tendiert aber eher ins negative.

Nun ist in dem Plot natürlich eine der beiden Seiten überflüssig. Wir können daher die Funktion `corrplot.mixed()` nutzen um in das untere Feld die Zahlenwerte der Korrelation darzustellen.

```{r}
#| echo: true
#| message: false
#| label: fig-corrplot-mixed-01
#| fig-align: center
#| fig-height: 6
#| fig-width: 6
#| fig-cap: "Farbiger paarweiser Korrelationsplot für die numerischen Variablen aus dem Datensatz zu den Gummibärchen. Die Farben spiegeln die Richtung der Korrelation wieder, die Größe der Kreise die Stärke. In das untere Feld werden die Werte der Korrelation angegeben."

corrplot.mixed(cor_mat)
```

Es gibt noch eine Vielzahl an weiteren Möglichkeiten in den Optionen von der Funktion `corr.mixed()`. Hier hilft dann die Hilfeseite der Funktion oder aber die [Hilfeseite zum Paket](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html).
