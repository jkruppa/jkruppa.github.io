```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Maßzahlen der Modelgüte {#sec-lin-reg-quality}

![](images/caution.png){fig-align="center" width="50%"}

[Wir meinen mit Gütekriterien wie gut das statistische Modellieren funktioniert hat. Wir haben eine große Auswahl an Methoden und wir müssen das Ergebnis des Modellierens überprüfen.]{.aside}

Wir interpretieren keine der Gütekriterien und statistischen Maßzahlen alleine sondern in der Gesamtheit. Es gibt eine Reihe von Maßzahlen für die Güte eines Modells, wir schauen uns hier einige an. Später werden wir uns noch andere Maßzahlen anschauen, wenn wir eine multiple lineare Regression rechnen. Das [R Paket performance](https://easystats.github.io/performance/) werden wir später auch nutzen um die notwendigen Gütekriterien zu erhalten.

Wir wollen eine Gerade durch Punkte legen. Deshalb müssen wir folgende Fragen klären:

-   Läuft die Gerade durch die Mitte der Punkte? Hier hilft ein Residualplot für die Bewertung (siehe @sec-linreg-residual).
-   Liegen die Punkte alle auf der Geraden? Hier hilft das Bestimmtheitsmaß $R^2$ weiter (siehe @sec-linreg-bestimmt)
-   Folgt unser Outcome $y$ einer Normalverteilung? Hier kann der QQ-Plot helfen (siehe @sec-linreg-qq)

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Achte darauf welche Lernstufe du hast und was wir *wirklich* in der Vorlesung gemacht haben. Hier kann sich das ein oder andere überschneiden.

Was heißt überscheiden? Wir werden uns nicht in jedem Modul alle Gütekriterien anschauen. Deshalb Augen auf deine Mitschrift.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               see, performance, patchwork)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Nachdem wir uns im vorherigen Kapitel mit einem sehr kleinen Satensatz beschäftigt haben, nehmen wir einen großen Datensatz. Bleiben aber bei einem simplen Modell. Wir brauchen dafür den Datensatz `flea_dog_cat_length_weight.xlsx`. In einer simplen linearen Regression schauen wir uns den Zusammenhang zwischen einem $y$ und einem $x_1$ an. Daher wählen wir aus dem Datensatz die beiden Spalten `jump_length` und `weight`. Wir wollen nun feststellen, ob es einen Zusammenhang zwischen der Sprungweite in \[cm\] und dem Flohgewicht in \[mg\] gibt. In dem Datensatz finden wir 400 Flöhe von Hunden und Katzen.

```{r}
#| message: false

model_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") %>%
  select(animal, jump_length, weight)
```

In der @tbl-model-1 ist der Datensatz `model_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz mit einer normalverteilten Variable `jump_length` und der normalverteilten Variable `weight`. Wir betrachten die ersten sieben Zeilen des Datensatzes.
#| label: tbl-model-1

model_tbl %>% head(7) %>% kable(align = "c", "pipe")
```

Im Folgenden *ignorieren* wir, dass die Sprungweiten und die Gewichte der Flöhe auch noch von den Hunden oder Katzen sowie dem unterschiedlichen Geschlecht der Flöhe abhängen könnten. Wir schmeißen alles in einen Pott und schauen nur auf den Zusammenhang von Sprungweite und Gewicht.

## Das simple lineare Modell

Wir fitten ein simples lineares Modell mit nur einem Einflussfaktor `weight` auf die Sprunglänge `jump_length`. Wir erhalten dann das Objekt `fit_1` was wir dann im Weiteren nutzen werden.

```{r}
fit_1 <- lm(jump_length ~ weight, data = model_tbl)
```

Wir nutzen jetzt dieses simple lineare Modell für die weiteren Gütekritierien.

## Residualplot {#sec-linreg-residual}

[In R wird in Modellausgaben die Standardabweichung der Residuen $s_{\epsilon}$ als `sigma` bezeichnet.]{.aside}

Wir wollen mit dem Residualplot die Frage beantworten, ob die Gerade *mittig* durch die Punktewolke läuft. Die Residuen $\epsilon$ sollen normalverteilt sein mit einem Mittelwert von Null $\epsilon \sim \mathcal{N}(0, s^2_{\epsilon})$.

Wir erhalten die Residuen `resid` und die angepassten Werte `.fitted` auf der Geraden über die Funktion `augment()`. Die Funktion `augment()` gibt noch mehr Informationen wieder, aber wir wollen uns jetzt erstmal auf die Residuen konzentrieren.

```{r}
resid_plot_tbl <- fit_1 %>% 
  augment() %>% 
  select(.fitted, .resid)

resid_plot_tbl %>% 
  head(5)
```

Die Daten selber interssieren uns nicht einer Tabelle. Stattdessen zeichen wir einmal den Residualplot. Bei dem Residualplot tragen wir die Werte der Residuen `.resid` auf die y-Achse auf und die angepassten y-Werte auf der Geraden `.fitted` auf die x-Achse. Wir kippen im Prinzip die gefittete Gerade so, dass die Gerade parallel zu x-Achse läuft.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-01
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "Residualplot der Residuen des Models `fit_1`. Die rote Linie stellt die geschätzte Gerade da. Die Punkte sollen gleichmäßig und ohne eine Struktur um die Gerade verteilt sein."

ggplot(resid_plot_tbl, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw()
```

[The residual plot should look like the sky at night, with no pattern of any sort.]{.aside}

In @fig-scatter-qual-01 sehen wir den Residualplot von unseren Beispieldaten. Wir sehen, dass wir keine Struktur in der Punktewolke erkennen. Auch sind die Punkte gleichmäßig um die Gerade verteilt. Wir haben zwar einen Punkt, der sehr weit von der Gerade weg ist, das können wir aber ignorieren. Später können wir uns noch überlegen, ob wir einen Ausreißer (eng. *outlier*) vorliegen haben.

## Bestimmtheitsmaß $R^2$ {#sec-linreg-bestimmt}

Nachdem wir nun wissen wie gut die Gerade durch die Punkte läuft, wollen wir noch bestimmen wie genau die Punkte auf der Geraden liegen. Das heißt wir wollen mit dem Bestimmtheitsmaß $R^2$ ausdrücken wie stark die Punkte um die Gerade variieren. Wir können folgende Aussage über das Bestimmtheitsmaß $R^2$ treffen. Die @fig-rsquare visualisiert nochmal den Zusammenhang.

-   wenn alle Punkte auf der Geraden liegen, dann ist das Bestimmtheitsmaß $R^2$ gleich 1.
-   wenn alle Punkte sehr stark um die Gerade streuuen, dann läuft das Bestimmtheitsmaß $R^2$ gegen 0.

![Visualisierung des Bestimmtheitsmaßes $R^2$. Auf der linken Seite sehen wir eine perfekte Übereinstimmung der Punkte und der geschätzten Gerade. Wir haben ein $R^2$ von 1 vorliegen. Sind die Punkte und die geschätzte Gerade nicht deckungsgleich, so läuft das $R^2$ gegen 0.](images/statistical_modeling_rsquare){#fig-rsquare fig-align="center" width="100%"}

Da die Streuung um die Gerade auch gleichzeitig die Varianz wiederspiegelt, können wir auch sagen, dass wenn alle Punkte auf der Geraden liegen, die Varianz gleich Null ist. Die Einflussvariable $x_1$ erklärt die gesamte Varianz, die durch die Beobachtungen verursacht wurde.

Damit beschreibt das Bestimmtheitsmaß $R^2$ auch den Anteil der Varianz, der durch die lineare Regression, daher der Graden, erklärt wird. Wenn wir ein Bestimmtheitsmaß $R^2$ von Eins haben, wird die gesamte Varianz von unserem Modell erklärt. Haben wir ein Bestimmtheitsmaß $R^2$ von Null, wird gar keine Varianz von unserem Modell erklärt. Damit ist ein niedriges Bestimmtheitsmaß $R^2$ schlecht.

Wir können die Funktion `glance()` nutzen um uns das `r.squared` und das `adj.r.squared` wiedergeben zu lassen.

```{r}
#| message: false

fit_1 %>% 
  glance() %>% 
  select(r.squared, adj.r.squared)
```

[Wir nutzen grundsätzlich das adjustierte $R^2$`adj.r.squared` in der Anwendung.]{.aside}

Wir haben wir ein $R^2$ von $0.31$ vorliegen. Damit erklärt unser Modell bzw. die Gerade 31% der Varianz. Das ist jetzt nicht viel, aber wundert uns auch erstmal nicht. Wir haben ja die Faktoren `animal` und `sex` ignoriert. Beide Faktoren könnten ja auch einen Teil der Varianz erklären. Dafür müssten wir aber eine multiple lineare Regression mit mehren $x$ rechnen.

Wenn wir eine multiple Regression rechnen, dann nutzen wir das adjustierte $R^2$`adj.r.squared` in der Anwendung. Das hat den Grund, dass das $R^2$ automatisch ansteigt je mehr Variablen wir in das Modell nehmen. Jede neue Variable wird immer *etwas* erklären. Um dieses Überanpassen (eng. *overfitting*) zu vermeiden nutzen wir das adjustierte $R^2$. Im Falle des adjustierte $R^2$ wird ein Strafterm eingeführt, der das adjustierte $R^2$ kleiner macht je mehr Einflussvariablen in das Modell aufgenommen werdenn.

## QQ-Plot {#sec-linreg-qq}

Mit dem Quantile-Quantile Plot oder kurz QQ-Plot können wir überprüfen, ob unser $y$ aus einer Normalverteilung stammt. Oder andersherum, ob unser $y$ approximativ normalverteilt ist.

Wir brauchen für einen QQ-Plot viele Beobachtungen. Das heißt, wir brauchen auf jeden Fall mehr als 20 Beobachtungen. Dann ist es auch häufig schwierig den QQ-Plot zu bewerten, wenn es viele Behandlungsgruppen oder Blöcke gibt. Am Ende haben wir dann zwar mehr als 20 Beoabchtungen aber pro Kombination Behandlung und Block nur vier Wiederholungen. Und vier Wiederholungen sind zu wenig für eine sinnvolle Interpretation eines QQ-Plots.

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-02
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "QQ-Plot der Sprungweite in \\[cm\\]. Die Gerade geht einmal durch die Mitte der Punkte und die Punkte liegen nicht exakt auf der Geraden. Eine leichte Abweichung von der Normalverteilung könnte vorliegen."

ggplot(model_tbl, aes(sample = jump_length)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw()
```

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-03
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "QQ-Plot der Sprungweite in \\[cm\\] aufgeteilt nach dem Faktor `animal`. Die Geraden geht einmal durch die Mitte der Punkte und die Punkte liegen nicht exakt auf der Geraden. Eine leichte Abweichung von der Normalverteilung könnte vorliegen. Wichtig ist hier, dass die Verteilungen für beide Level des Faktors gleich aussehen."

ggplot(model_tbl, aes(sample = jump_length, color = animal)) + 
  stat_qq() + 
  stat_qq_line() +
  scale_color_okabeito() +
  theme_bw()
```

## Cook\`s Abstand

Die Cook'sche Distanz hat im Wesentlichen eine Aufgabe. Die Cook'sche Distanz misst, wie stark sich alle angepassten Werte im Modell ändern, wenn der i-te Datenpunkt gelöscht wird.

```{r}
#| message: false
#| echo: false
#| label: tbl-tables
#| tbl-cap: "Tables"
#| tbl-subcap:
#|   - "Cars"
#|   - "Pressure"
#| layout-ncol: 2

no_out_tbl <- tibble(weight = c(1, 2, 2, 3, 4, 5, 7, 3, 4, 5),
                     jump_length = c(22, 23, 24, 23, 19, 34, 35, 36, 23, 22))

out_tbl <- tibble(weight = c(1, 2, 2, 3, 4, 5, 7, 4, 5, 8),
                  jump_length = c(190, 23, 24, 23, 19, 24, 25, 26, 28, 180))

no_out_tbl %>% kable(align = "c", "pipe")
out_tbl %>% kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| label: fig-cooks-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Histogramm der nicht transfomierten und transformierten Daten."
#| fig-subcap: 
#|   - "Nicht transformierte, rohe Daten"
#|   - "$log$-transformierte Daten."
#| layout-nrow: 1
#| column: page

#create scatterplot for data frame with no outliers
ggplot(data = no_out_tbl, aes(x = weight, y = jump_length)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(0, 200) +
  theme_bw()

#create scatterplot for data frame with outliers
ggplot(data = out_tbl, aes(x = weight, y = jump_length)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  ylim(0, 200) +
  theme_bw()

```

```{r}
fit_2 <- lm(jump_length ~ weight, data = out_tbl)
```

```{r}
plot_tbl <- fit_2 %>% 
  augment %>% 
  select(weight, .cooksd)
```

```{r}
cooks_border <- 4/nrow(plot_tbl)
cooks_border
```

```{r}
#| echo: true
#| message: false
#| label: fig-cook-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "."

ggplot(plot_tbl, aes(weight, .cooksd)) +
  geom_point() +
  geom_hline(yintercept = cooks_border, color = "red") +
  theme_bw()
```

```{r}
#| message: false
remove_weight_id <- which(plot_tbl$.cooksd > cooks_border)
out_tbl <- out_tbl[-remove_weight_id,]

out_tbl
```

## Modellgüte mit dem R Paket `performance`

```{r}
#| echo: true
#| message: false
#| label: fig-scatter-qual-04
#| fig-align: center
#| fig-height: 15
#| fig-width: 10
#| fig-cap: "."
#| column: page

check_normality(fit_1)

check_model(fit_1)

library(ggplot2)
library(patchwork)

#p1 <- ggplot(mtcars) + geom_point(aes(mpg, disp))
#p2 <- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear))

#p1 + p2

```
