```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, performance, parameters,
               latex2exp, see, patchwork, mfp, multcomp, emmeans, janitor, effectsize,
               broom, ggmosaic, tinytable, ggrepel, tidyplots,
               conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- cb_pal
source("stat-tests-anova_plot/repeated_plots.R")
```

# Der Friedman Test {#sec-friedman}

*Letzte Änderung am `r format(fs::file_info("stat-tests-friedman.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"It's easy to lie with statistics. It's hard to tell the truth without statistics." --- Andrejs Dunkels*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Baustelle (seit 06.2025)

Dieses Kapitel wird überarbeitet. Ziel ist es die Nichtparametrik zum Start des Wintersemesters 2025/26 überarbeitet zu haben. Da ich hier direkt im Kapitel arbeite, kann es sein, dass mal die ein oder andere Funktion nicht funktioniert oder aber Teile im Nichts enden. Wird dann repariert.
:::

Willkommen in der Gruft. Der Friedman Test ist schlecht und sollte nicht angewendet werden. Das Kapitel existiert eigentlich nur, damit du es finden kannst und gleich lesen kannst, dass du den Friedman Test sein lassen sollst. Weder tut der Friedman Test, dass was du von ihm verlangst, noch macht er das was er tut besonders im statistischen Sinne gut. Am besten rechnest du nach @zimmerman1993relative auf den rangtransformierten Messwerten eine repeated ANOVA, wie ich dir weiter unten zeige.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Sollte man statistische Test schlecht machen? Vermutlich ja. Einige Tests haben einfach Ihren Zenit erreicht und sind einfach nicht mehr der Stand der Wissenschaft im 21. Jahrhundert. Deshalb bitte einfach zurücklassen und sich nicht mehr drum kümmern." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

## Allgemeiner Hintergrund

Der Friedman Test ist der Kruskal Wallis Test für abhängige Daten. Oder doch nicht? Wenn man sich mit den Friedman Test beschäftigt, dann wird einem nach einer etwas längeren Internetscuhe dann doch klar, dass hier irgendwas nicht so richtig stimmt. Es gibt nämlich [zwei Arten des Friedman Tests](https://math.montana.edu/jobo/thainp/ksampa.pdf). Also eigentlich auch nein, es gibt nur einen Friedman Test aber zwei Arten den Test anzuwenden. Wir können den Friedman Test einmal in den Agrarwissenschaften nutzen um ein randomisiertes vollständiges Blockdesign (eng. *Randomized Complete Block Design*) auszuwerten. In den Geisteswissenschaften wird der Friedman Test gerne für ein einfaches Design mit wiederholten Messungen (eng. *Simple Repeated Measures Design*) genutzt. Damit fängt es schon an, denn die beiden Designs haben was gemeinsam aber dann auch wieder nicht. Also wir merken uns, je nachdem aus welcher Fachrichtung du kommst, mag der Firedman Test für dich was anderes bedeuten. In beiden Fällen heißt es aber ["Beware the Friedman test!"](https://seriousstats.wordpress.com/2012/02/14/friedman/)

Hilft ja alles nichts, fangen wir also einmal an uns anzuschauen, was der Friedman Test macht. Du findest noch ein gutes [Tutorium zum Friedman Test](https://rcompanion.org/handbook/F_10.html) sowie die Alternative einer repeated ANOVA auf den rangtransformierten Messwerten nach @zimmerman1993relative. Wir schauen uns diese Lösung dann auch einmal an. Wichtig ist noch zu wissen, dass die asymptotische Effizienz des Friedman-Tests bei $0.955 \cdot J/(J+1)$, also bei $0.64$ für $J=2$ und $0.87$ für $J=10$ liegt. Wir beschrieben mit $J$ die Anzahl der Gruppen oder Versuchsbedingungen also den Spalten ist. Bei einer Effizienz von $0.64$ braucht der Friedman Test somit eine um $(100-64)/64$ gleich $0.56$ also eine ca. 50% größere Stichprobe um die selbe Signifikanz zu erreichen. Oder etwas anders, dass der Friedman Test $50\%$ mehr Fallzahl benötigt um die gleiche Effizienz zu haben wie eine einfaktorielle ANOVA, deren Annahmen an die Normalverteilung und Varianzhomogenität erfüllt werden. Der Begriff der Effizienz ist hier natürlich etwas wage, aber du kannst den Begriff für dich auch vereinfacht als gleiche statistische Eigenschaften was die Signifikanz angeht lesen. Der Friedman Test braucht also sehr viele Gruppen in den Spalten.

#### Datenformat {.unnumbered .unlisted}

Sprechen wir nochmal über das Datenformat. In der Datentabelle für den Friedman Test haben wir keine Wiederholungen für die Faktorkombinationen vorliegen, wie du in der folgenden Tabelle siehst. Solltest du wiederholt Faktorkombinationen gemessen haben, dann müsstest du die Daten erst Aggregieren. Was wiederum wirr ist, denn damit verlierst du Informationen. Heutzutage kannst du auch auf den vollen Datensätzen rechnen. Wir haben also in den Spalten den Faktor $A$ mit den Leveln $A.1$ bis $A.4$ vorliegen. Der Faktor $A$ beschreibt die Versuchsbedingungen, wie Behandlung oder Sorte. Du kannst natürlich auch mehr als vier Behandlungen vorliegen haben. In den Zeilen findest du dann den Faktor $B$ für die Messwiederholungen oder Blöcke. Wir haben hier fünf Level im Faktor $B$ vorliegen. Damit sieht die Tabelle eher wie eine Kreuztabelle einer deskriptiven Statistik aus als ein Datensatz.

| Faktor B | A.1  | A.2  | A.3  | A.4  |
|----------|------|------|------|------|
| **B.1**  | 9.1  | 10.2 | 12.2 | 14.1 |
| **B.2**  | 4.2  | 5.2  | 6.2  | 7.3  |
| **B.3**  | 12.1 | 14.5 | 12.5 | 13.7 |
| **B.4**  | 1.2  | 3.6  | 3.5  | 7.1  |
| **B.5**  | 4.1  | 4.5  | 4.7  | 8.1  |

: Beispielhafte, aggregierte Datentabelle für einen Friedman Test mit vier Behandlungen in den Spalten und fünf Wiederholungen in den Zeilen. In den Spalten ist der Behandlungsfaktor A mit den entsprechenden Leveln A.1 bis A.4 eingetragen. In den Zeilen finden sich der Faktor für Wiederholungen wie Blöcke oder individuelle IDs mit den entsprechenden Leveln B.1 bis B.5 eingetragen. Es liegen keine Messwiederholungen für die Faktorkombinationen vor. {#tbl-test}

Dann wollen wir gleich einmal den Friedman Test anwenden. Dafür habe ich dann auch wieder die passenden R Paket sowie zwei Datensätze mitgebracht. Am Ende musst du schauen, ob du deine Daten mit dem Friedman Test auswerten möchtest. Der Friedman Test hat Probleme bei wenigen Behandlungen und Blöcken einen Effekt signifikant zu finden. Solltest du nur eine aggregierte Datentabelle haben, dann mag der Friedman Test eine Lösung für dein Problem sein.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, pgirmess,
               readxl, rstatix, coin, nparcomp,
               effectsize, PMCMRplus, rcompanion,
               conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

Eigentlich sind die Datensätze hier zweimal das Gleiche, aber es gibt eben diese [zwei Arten des Friedman Tests](https://math.montana.edu/jobo/thainp/ksampa.pdf), die im Orbit rumgeistern. Deshalb hier im Folgenden einmal der agrawissenschaftliche Datensatz mit einem, Block in den Zeilen sowie einen Datensatz zu Messwiederholungen an Individuen mit unseren Flöhen. Damit haben wir beide Fälle abgefrühstückt und können uns dann die Auswertung einmal näher anschauen.

::: panel-tabset
## Randomisiertes vollständiges Blockdesign

Beginnen wir einmal mit dem randomisierten vollständigen Blockdesign (eng. *Randomized Complete Block Design*). Wir haben die Daten in der folgenden Datei in dem Reiter `block` abliegen. Die Besonderheit ist hier, dass wir dennoch Messwiederholungen in den Blöcken vorliegen haben. Sehe einfahc die Blöcke als verschiedene Käfige. Ich habe die Daten mal etwas realistischer gebaut. Wir haben hier pro Block jeweils die Sprungweite von drei Hundeflöhen gemessen. Dabei sind die Flöhe dann unter verschiedenen Ernährungsformen gesprungen. Wir haben aber nicht den gleichen Floh in jeder Behandlung gemessen. Jeder Zahlenwert entspricht der Sprungweite eines individuellen Hundeflohs. Der Weg hier vom Wide-Format zum Long-Format über die Aggregation ist etwas lang, aber geht so nicht anders.

```{r}
#| message: false
block_raw_tbl <- read_excel("data/friedman_data.xlsx",
                            sheet = "block") 
```

In der folgenden Datentabelle siehst du einmal den Datensatz mit den Sprungweiten unter den verschiedenen Ernährungsformen. Wir haben eine Wiederholung in den Blöcken vorliegen, diese Wiederholung müssen wir dann noch aggregieren, so dass wir dann nur eine Zeile pro Block haben.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table-block
#| tbl-cap: "Auszug aus der Datentabelle eines randomisierten vollständigen Blockdesign mit drei Messweiderholungen pro Block. Ein Block kann als ein Käfig angesehen werden. Für die einzelnen Hundeflöhe wurden unter verschiedenen Ernährungsformen die Sprungweiten gemessen. Jeder Wert entspricht einem individuellen Floh. Die Daten müssen noch aggregiert werden damit wir den Friedman Test anwenden können."

block_raw_tbl <- read_excel("data/friedman_data.xlsx",
                        sheet = "block") 

rbind(head(block_raw_tbl, n = 4),
      rep("...", times = ncol(block_raw_tbl)),
      tail(block_raw_tbl, n = 4)) |> 
  tt(width = 1, align = "c", theme = "striped")
```

Dann bilden wir einmal den Mittelwert über jede Zeile für jeden Block. Somit haben wir dann die Blockmittel für jede Ernährungsform und nur noch einen Wert für die Sprungweite für jede Faktorkombination. In jeden Zahlenwert gehen jetzt die individuellen Sprungweiten der drei Hundeflöhe auf.

```{r}
block_tbl <- block_raw_tbl |>
  group_by(block) |> 
  summarise(across(ctrl:ketchup, mean))  
```

In der folgenden Tabelle siehst du dann das Ergebnis der Aggregation. Wir haben dann nur noch eine Sprungweite der Hundeflöhe für jede Faktorkombination der Ernährungsform und des Blocks vorliegen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table-block-aggr
#| tbl-cap: "Aggregierte Datentabelle eines randomisierten vollständigen Blockdesign mit den mittleren Sprungweiten pro Block.  Jeder Wert entspricht dem Mittel der Sprungweiten der drei Flöhe. Jede Faktorkombination ist nur einmal vertreten."

block_tbl |> 
  mutate_if(is.numeric, round, 2) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

Das reicht dann aber natürlich wieder nicht, den wir haben damit die Daten im Wide-Format in der vorherigen Tabelle vorliegen. Die Analysen in R verlangen aber da Long-Format, so dass ich hier nochmal mit der Funktion `pivot_longer()` einen entsprechenden Datensatz baue. Dann kann ich auch gleich die entsprechenden Faktoren umwandeln.

```{r}
block_long_tbl <- block_tbl |> 
  pivot_longer(cols = ctrl:ketchup,
               names_to = "feeding",
               values_to = "jump_length") |> 
  mutate(block = as_factor(block),
         feeding = as_factor(feeding))
```

Der Weg war jetzt etwas länger, aber so ist es manchmal, wenn wir mit etwas veralteten Algorithmen rechnen wollen. In der folgenden Abbildung siehst du dann nochmal die Daten in einem Dotplot dargestellt. Wir sehen, dass die Kontrolle eine etwas weitere Sprungweite hat als das Blut und auch die Ernährung mit Ketchup.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-fried-ggplot-block
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Dotplot des Datenbeispiels für die fünf Blöcke und die drei Ernährungsformen."

ggplot(block_long_tbl, aes(feeding, jump_length, fill = block)) +
  theme_minimal() +
  geom_dotplot(binaxis = "y", stackdir='center', 
               position=position_dodge(0.3)) +
  labs(x = "Ernährungsform", y = "Sprungweite in [cm]", color = "Block") +
  scale_fill_okabeito() 
```

## Design mit wiederholten Messungen

Den zweiten Datensatz, den wir uns anschauen wollen, zeigt ein einfaches Design mit wiederholten Messungen (eng. *Simple Repeated Measures Design*). Wir haben hier also fünf Hundeflöhe vorliegen, die wir dann viermal springen lassen. Wir messen dann nach jedem Sprung einmal die Sprungweite. Damit haben wir dann über die Zeilen eine Messwiederholung in unseren Daten vorliegen.

```{r}
#| message: false
repeated_tbl <- read_excel("data/friedman_data.xlsx",
                           sheet = "repeated") 
```

Wir haben damit folgenden Datensatz vorliegen. In den Zeilen sind die fünf Hundeflöhe, die jeweils zu vier Zeitpunkten einmal gesprungen sind. Wir haben dann zu jedem Zeitpunkt einmal die Sprungweite erfasst und aufgeschrieben. Die Messwerte sind damit abhängig. Damit ist der Datensatz sehr klassisch für einen Friedman Test.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table-repeated
#| tbl-cap: "Datentabelle eines einfachen Design mit wiederholten Messungen für die Sprungweite zu vier Zeitpunkten. Fünf Hundeflöhe sind jeweils viermal gesprungen und die Sprungweiten wurden erfasst. Die Messwiederholungen laufen über die Zeilen."

repeated_tbl |> 
  tt(width = 1, align = "c", theme = "striped")
```

Das reicht dann aber natürlich noch nicht, den wir haben die Daten noch im Wide-Format in der vorherigen Tabelle vorliegen. Die Analysen in R verlangen aber da Long-Format, so dass ich hier nochmal mit der Funktion `pivot_longer()` einen entsprechenden Datensatz baue. Dann kann ich auch gleich die entsprechenden Faktoren umwandeln.

```{r}
repeated_long_tbl <- repeated_tbl |> 
  pivot_longer(cols = t1:t4,
               names_to = "time",
               values_to = "jump_length") |> 
  mutate(flea_id = as_factor(flea_id),
         time_fct = as_factor(time))
```

In der folgenden Abbildung siehst du dann nochmal die Daten in einem Dotplot dargestellt. Die Linien verbinden die einzelnen Flöhe und die Sprungweiten über die Zeiten miteinander. Wie wir sehen, haben wir die höchsten Sprungweiten zu dem Zeitpunkt `t2` und weniger zu dem Zeitpunkt `t3`. Hier scheint es einen Effekt der Zeit zu geben.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-fried-ggplot-repeated
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Dotplot des Datenbeispiels für die Bonitur von fünf Weizensorten."

ggplot(repeated_long_tbl, aes(time_fct, jump_length, fill = flea_id)) +
  theme_minimal() +
geom_line(aes(group = flea_id), color = "gray",
            position=position_dodge(0.3)) +
  geom_dotplot(binaxis = "y", stackdir='center', 
               position=position_dodge(0.3)) +
  labs(x = "Zeitpunkt", y = "Sprungweite in [cm]", color = "Floh ID") +
  scale_fill_okabeito() 
```
:::

Ich habe hier nochmal beide Datenformate dargestellt. Wir können in den Agrarwissenschaften nicht in den verschiedenen Blöcken wiederholt messen. Was wir in den einen Block Pflanzen wächst in dem einen Block und kann nicht nochmal woanders gemessen werden. Zwar ist ein Block eine Versuchseinheit, aber die Pflanzen oder Tiere, die in dem ersten Block stehen, stehen dann eben nicht in dem zweiten Block. Das ist technisch ja gar nicht möglich. Das hier zwei so unterschiedliche Fragestellungen angeblich mit dem gleichen Test beantwortet werden können, sollte einen schon stutzig machen.

## Hypothesen

Der Friedman Test betrachtet die Gruppen und Ränge um einen Unterschied nachzuweisen. Daher haben wir in der Nullhypothese als Gleichheitshypothese folgende Prosahypothese. Mehr zu den Hintergründen der Hypothesen in einem nichtparametrischen Test findest du im [Kapitel zum U-Test](#sec-utest).

$H_0:$ *Die Gruppen werden aus Populationen mit identischen Verteilungen entnommen. Typisch ist, dass die Stichprobenpopulationen stochastische Gleichheit aufweisen. Daher sind häufig die Mediane gleich.*

Die Alternative lautet, dass sich mindestens ein paarweiser Vergleich unterschiedet. Hierbei ist das mindestens ein Vergleich wichtig. Es können sich alle Gruppen unterschieden oder eben nur ein Paar. Wenn ein Friedman Test die $H_0$ ablehnt, also ein signifikantes Ergebnis liefert, dann wissen wir nicht, welche Gruppen sich unterscheiden und einen entsprechenden Post-hoc Test rechnen.

$H_A:$ *Die Gruppen werden aus Populationen mit unterschiedlichen Verteilungen entnommen. Typischerweise weist eine der untersuchten Populationen eine stochastische Dominanz auf. Die Mediane sind häufig verschieden.*

Wir schauen uns jetzt einmal den Friedman Test theoretisch an bevor wir uns mit der Anwendung des Friedman Test in R beschäftigen.

## Der Friedman Test

Beginnen wir nun mit der Umsetzung des Friedman Tests. Ich zeige dir hier beide Anwendungsfelder. Nur der erste Fall für ein randomisiertes vollständiges Blockdesign macht überhaupt Sinn. Andere Fall für ein einfaches Design mit Messwiederholungen ist nur hier um dich zu warnen. Der Friedman Test leidet unter Mängeln und sollte nicht verwendet werden.

### ... für ein randomisiertes vollständiges Blockdesign

Der Friedman Test ist in R in verschiedenen Paketen implementiert. Alle Funktionen liefern mehr oder minder das gleiche Ergebnis. Wichtig ist wie wir in der Funktion das Modell definieren. Wir nutzen das Symbol `|` um die Behandlung von dem Block zu trennen. Vor dem `|` Symbol steht die Behandlung, hinter dem `|` steht der Block. Damit sieht das Modell etwas anders aus, aber im Prinzip ist die Definition des Modells einfach. Diese Schreibweise ist in allen drei vorgestellten Paketen und Funktionen gleich.

::: panel-tabset
## Theoretisch

| Block  |      Kontrolle       |         Blut         |       Ketchup        |
|:------:|:--------------------:|:--------------------:|:--------------------:|
|   1    | $7.07 \rightarrow 1$ | $5.57 \rightarrow 2$ | $1.43 \rightarrow 3$ |
|   2    | $7.33 \rightarrow 2$ | $8.17 \rightarrow 1$ | $2.50 \rightarrow 3$ |
|   3    | $9.43 \rightarrow 1$ | $4.50 \rightarrow 2$ | $4.30 \rightarrow 3$ |
|   4    | $6.33 \rightarrow 2$ | $5.43 \rightarrow 3$ | $7.20 \rightarrow 1$ |
|   5    | $2.67 \rightarrow 3$ | $8.43 \rightarrow 1$ | $3.50 \rightarrow 2$ |
| $\sum$ |         $9$          |         $9$          |         $12$         |

: text {tbl-friedman-theo-block}

$$
E(R) = \cfrac{N(k+1)}{2} = \cfrac{5(3+1)}{2} = 10
$$

$$
\mathcal{X_D}^2 = \cfrac{12}{N \cdot k \cdot (k+1)} \cdot \sum R^2 - 3 \cdot N \cdot (k+1)
$$ mit

-   $R$ der Rangsummen für jede Gruppe mit insgesamt $k$ Gruppen.
-   $k$ ist die Anzahl an Gruppen. Hier also die Spalten der Daten.
-   $N$ der Gesamtzahl an Beobachtungen also die gesamte Fallzahl. Hier also die Zeilen der Daten.

$$
\begin{aligned}
\mathcal{X_D}^2 &= \cfrac{12}{5 \cdot 3 \cdot (3+1)} \cdot (9^2 + 9^2 + 12^2) - 3 \cdot 5 \cdot (3+1) \\
&= 0.2 \cdot 306 - 60 \\
&= 1.6
\end{aligned}
$$

$\mathcal{X}^2_{\alpha = 5\%}$ ist in unserem Fall mit $5.99$ gegeben.

## `{stats}`

```{r}
#| message: false
#| warning: false
friedman.test(jump_length ~ feeding | block, data = block_long_tbl)
```

Nachdem wir die Funktion aufgerufen haben, erhalten wir auch gleich den $p$-Wert von $0.005$ wieder. Da der $p$-Wert kleienr ist als das Signifikanzniveau $\alpha$ von 5% können wir die Nullhypothese ablehnen. Es gibt mindestens einen paarweisen Unterschied. Das war auch anhand des Doplots zu erwarten.

## `{coin}`

`friedman_test()`

```{r}
#| message: false
#| warning: false
coin::friedman_test(jump_length ~ feeding | block, data = block_long_tbl)
```

## `{rstatix}`

[Friedman Test in R](https://www.datanovia.com/en/lessons/friedman-test-in-r/)

```{r}
#| message: false
#| warning: false
rstatix::friedman_test(jump_length ~ feeding | block, data = block_long_tbl)
```
:::

#### Effektschätzer {.unnumbered .unlisted}

```{r}
#| message: false
#| warning: false
friedman_effsize(jump_length ~ feeding | block, data = block_long_tbl)
```

Wir haben also herausgefunden, dass wir einen starken Effekt haben und sich die Mediane der Gruppen unterscheiden.

#### Parametrische Lösung: Die ANOVA {.unnumbered .unlisted}

```{r}
signed_rank <- function(x) sign(x) * rank(abs(x))
```

`{rstatix}`

```{r}
block_long_tbl |> 
  mutate(ranked_jump_length = signed_rank(jump_length)) |> 
  anova_test(ranked_jump_length ~ feeding + block) 
```

### ... für ein Design mit wiederholten Messungen

::: callout-warning
## Achtung, bitte beachten!

[Beware the Friedman test!](https://seriousstats.wordpress.com/2012/02/14/friedman/) Das ist der wichtigste Punkt. Wenn du den Friedman Test rechnen willst, weil in deinen Zeilen Messwiederholungen sind, dann bitte lassen. Du also bei jedem Floh wiederholt die Sprungweite gemessen und möchtest jetzt wissen, ob es einen Unterschied in den Zeitpunkten gibt. Die Alternativen hat @zimmerman1993relative einmal diskutiert und ich zeige dir dann auch die besseren Lösungen.
:::

Die Frage ist, warum sollte man auf Messwiederholungen einen Friedman Test rechnen? Weil die Normalverteilung für den Messwert in einer ANOVA nicht gegeben ist. Dafür brauchen wir aber nicht den Friedman Test wir können da auch einen anderen Weg gehen.

> *"\[In cases\] where one-way repeated measures ANOVA is not appropriate, rank transformation followed by ANOVA will provide a more robust test with greater statistical power than the Friedman test." --- [Beware the Friedman test!](https://seriousstats.wordpress.com/2012/02/14/friedman/) und @zimmerman1993relative*

::: panel-tabset
## Theoretisch

| Floh | Zeitpunkt 1 | Zeitpunkt 2 | Zeitpunkt 3 | Zeitpunkt 4 |
|:--:|:--:|:--:|:--:|:--:|
| 1 | $10.2 \rightarrow 4$ | $12.4 \rightarrow 2$ | $11.1 \rightarrow 3$ | $13.4 \rightarrow 1$ |
| 2 | $8.3 \rightarrow 2$ | $9.1 \rightarrow 1$ | $6.8 \rightarrow 4$ | $7.1 \rightarrow 3$ |
| 3 | $12.1 \rightarrow 3$ | $15.1 \rightarrow 1$ | $11.3 \rightarrow 4$ | $12.5 \rightarrow 2$ |
| 4 | $7.8 \rightarrow 3$ | $8.1 \rightarrow 2$ | $5.6 \rightarrow 4$ | $8.2 \rightarrow 1$ |
| 5 | $8.6 \rightarrow 3$ | $10.3 \rightarrow 2$ | $8.1 \rightarrow 4$ | $11.3 \rightarrow 1$ |
| $\sum$ | $15$ | $8$ | $19$ | $8$ |

: text {tbl-friedman-theo-block}

$$
E(R) = \cfrac{N(k+1)}{2} = \cfrac{5(4+1)}{2} = 12.5
$$

$$
\mathcal{X_D}^2 = \cfrac{12}{N \cdot k \cdot (k+1)} \cdot \sum R^2 - 3 \cdot N \cdot (k+1)
$$

-   $R$ der Rangsummen für jede Gruppe mit insgesamt $k$ Gruppen.
-   $k$ ist die Anzahl an Gruppen. Hier also die Spalten der Daten.
-   $N$ der Gesamtzahl an Beobachtungen also die gesamte Fallzahl. Hier also die Zeilen der Daten.

$$
\begin{aligned}
\mathcal{X_D}^2 &= \cfrac{12}{5 \cdot 4 \cdot (4+1)} \cdot (15^2 + 8^2 + 19^2 + 8^2) - 3 \cdot 5 \cdot (4+1) \\
&= 0.12 \cdot 714 - 75 \\
&= 10.68
\end{aligned}
$$

$\mathcal{X}^2_{\alpha = 5\%}$ ist in unserem Fall mit $7.82$ gegeben.

## `{stats}`

```{r}
#| message: false
#| warning: false
friedman.test(jump_length ~ time_fct | flea_id, data = repeated_long_tbl)
```

## `{nparcomp}`

`mctp.rm()`

```{r}
mctp.rm_obj <- mctp.rm(jump_length ~ time_fct, data = repeated_long_tbl,
                       info = FALSE)
mctp.rm_obj$Analysis
```
:::

#### Parametrische Lösung: Die repeated ANOVA {.unnumbered .unlisted}

```{r}
signed_rank <- function(x) sign(x) * rank(abs(x))
```

`{rstatix}`

```{r}
repeated_aov <- repeated_long_tbl |> 
  mutate(ranked_jump_length = signed_rank(jump_length)) |> 
  anova_test(dv = ranked_jump_length, wid = flea_id, within = time_fct)
get_anova_table(repeated_aov)
```

## Post-hoc Test

::: panel-tabset
## `{pgirmess}`

`friedmanmc()`

```{r}
#| message: false
#| warning: false
friedmanmc_res <-  friedmanmc(y = block_long_tbl$jump_length,
                               groups = block_long_tbl$feeding,
                               blocks = block_long_tbl$block)
```

```{r}
friedmanmc_tbl <- friedmanmc_res$dif.com |> 
  rownames_to_column("comparison") |> 
  as_tibble()
```

```{r}
cldList(p.value ~ comparison, data = friedmanmc_tbl)
```

## `{PMCMRplus}`

Nachdem wir jetzt festgestellt haben, dass sich mindestens ein Gruppenunterschied zwischen den Weizensorten finden lassen muss, wollen wir noch feststellen wo dieser Unterschied liegt. Wir nutzen dafür den Siegel- und Castellan-Vergleichstests für alle Paare durch. Der Test ist mit der Funktion `frdAllPairsSiegelTest()` in dem R Paket `{PMCMRplus}` implementiert und einfach nutzbar. In dem Paket sind noch eine weitere Reihe an statistischen Test für paarweise nicht-parametrische Test enthalten. Leider sind das Paket und die Funktion schon älter, so dass wir nicht einmal die Formelschreibweise zu Verfügung haben. Wir müssen alle Spalten aus unserem Datensatz mit dem `$` einzeln selektieren und den Optionen zuordnen.

```{r}
#| message: false
#| warning: false
siegel_test_res <-  frdAllPairsSiegelTest(y = block_long_tbl$jump_length,
                                          groups = block_long_tbl$feeding,
                                          blocks = block_long_tbl$block,
                                          p.adjust.method = "none")
siegel_test_res
```

Ich empfehle ja immer eine Adjustierung für multiple Vergleiche, aber du kannst das selber entscheiden. Wenn du für die multiplen Vergleiche adjustieren willst, dann nutze gerne die Option `p.adjust.method = "bonferroni"` oder eben statt `bonferroni` die Adjustierungsmethode `fdr`.

Damit wir auch das *compact letter display* aus unseren $p$-Werte berechnen können, müssen wir unser Ergebnisobjekt nochmal in eine Tabelle umwandeln. Dafür gibt es dann auch eine passende Funktion mit `PMCMRTable`. Wir sehen, es ist alles etwas altbacken.

```{r}
siegel_test_tab <- PMCMRTable(siegel_test_res)

siegel_test_tab
```

Nachdem wir die Tabellenschreibweise der $p$-Werte vorliegen haben, können wir dann das *compact letter display* uns über die Funktion `cldList()` anzeigen lassen. Leider gibt es keine Möglichkeit die 95% Konfidenzintervalle zu erhalten. Wir auch beim Kruskal-Wallis-Test erhalten wir bei dem Friedman Test keine 95% Konfidenzintervalle und müssen im Zweifel mit dieser Einschränkung leben.

```{r}
cldList(p.value ~ Comparison, data = siegel_test_tab)
```

Am *compact letter display* sehen wir im Prinzip das gleiche Muster wie in den $p$-Werten. Nur nochmal etwas anders dargestellt und mit dem Fokus auf die *nicht* Unterschiede.
:::

## Referenzen {.unnumbered}
