# Formeln

## Verzerrung oder Bias

Wenn ein statistischer Test ein falsches Ergebnis liefert, weil die Daten nicht die Voraussetzungen des statistischen Tests erfüllt haben.

## Robust

Wir sagen, dass ein statistischer Test *robust* ist, wenn wir meinen, dass Annahmen an die Daten falsch sein können und der statistsiche Test dennoch unverzerrte Ergebnisse liefert.

## Homogenität und Heterogenität der Varianzen

Eine Varianzhomogenität liegt vor, wenn die Varianzen der Gruppen gleich sind.

$$
s^2_{dog} = s^2_{cat} = s^2_{fox}
$$

Eine Varianzheterogenität liegt vor, wenn die Varianzen der Gruppen ungleich sind.

$$
s^2_{dog} \neq s^2_{cat} \neq s^2_{fox}
$$

## Balancierte Daten

Wir haben balancierte Daten vorliegen, wenn in jeder Gruppe gleich viele Beobachtungen sind.

$$
n_{dog} = n_{cat} = n_{fox}
$$

Ein unbalanziertes Design heißt, dass wir nicht in jeder Gruppe die gleiche Anzahl an Beobachtungen vorliegen haben.

$$
n_{dog} \neq n_{cat} \neq n_{fox}
$$

Wir reden von balanziertem Design und meinen dmit die Behandlungsgruppe oder den Faktor mit den zu vergleichenden Leveln. Natürlich kann es über den gesamten Datensatz Faktoren mit unterschiedlichen Belegungen an Beobachtungen geben.

## Äquivalenztest -- Test auf Abwesenheit eines Effekts

http://www.regorz-statistik.de/inhalte/aequivalenztest.html

https://cran.rstudio.com/web/packages/TOSTER/vignettes/IntroductionToTOSTER.html

https://easystats.github.io/parameters/reference/equivalence_test.lm.html

## `ggpubr`

$\mathcal{N}(0, 1)$

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-4
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Zusammenhang von Histogramm und Densityplot an der Anzahl der Flöhe auf 39 Hunden."

ggplot(fac1_tbl, aes(x = animal, y = jump_length, color = animal)) + 
  geom_boxplot() +
  ##scale_colour_manual(values = par$cbbPalette) +
  theme(legend.position="none") +
  theme_bw() +
  theme(legend.position="none") +
  ylab("") + xlab("") 
```

## Die Wichtigkeit des t-Tests

$$
\text{Teststatistik} = \cfrac{\text{Signal}}{\text{Noise}}
$$

Als Ausblick sei hier einmal die lineare Regression auf den Daten gerechnet.

```{r}
lm(jump_length ~ animal, 
       data = data_tbl) %>% 
  summary() 
```

Zum einen finden wir hier unseren Effekt von $8.13 - 4.74 = 3.39$ bei `animalcat` und `Estimate` sowie unsere gepoolte Varianz $s_p = `r sd_pool`$ als `Residual standard error` wieder.

## Palmer Penguins

[Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/index.html)

**Diese Seite ist eine Sammelseite für Formeln und Ideen**

## Gummibärchen

Die beiden Datensätze aus @sec-example-1 und @sec-example-2 sind klein. Wir schauen uns nur wenige Beobachtungen an. Du könntest sagen, dass eigentlich Statistik nicht so notwendig ist, da du ja Unterschiede oder Gleichheit schon an den Daten siehst. In dem Gummibärchendatensatz aus XX schauen wir uns sehr viel mehr Beoachtungen an. Mehrere hundert Studierende haben an dem Datensatz schon mitgewirkt, so dass der Datensatz ziemlich groß ist. So einfach lassen sich nun keine Schlüsse mehr ziehen.

$$
Pr\left(\left.\cfrac{\Delta_{y_1,\, y_2}}{s_{y_1,\,y_2} \cdot \sqrt{2/n_g}}\right| \Delta_{y_1,\,y_2}=0\right)
$$

$$
\left[
(\bar{y}_1-\bar{y}_2) - 
T_{\left( 1-\tfrac{\alpha}{2} \right)} \cdot \frac {s_p}{\sqrt{n}}; \;
(\bar{y}_1-\bar{y}_2) + 
T_{\left( 1-\tfrac{\alpha}{2} \right)} \cdot \frac {s_p}{\sqrt{n}};
\right]
$$

## Fischer vs. Neyman-Pearson

**Wahrscheinlichkeit - Tea drinking Lady ergänzen**

$$
Pr(T|H_0)
$$

$$
Pr(T_{calc}|H_0)
$$

$$
Pr\left(\left.T_{calc}=\cfrac{\bar{y}_1-\bar{y}_2}{s_{y_1,\,y_2} \cdot \sqrt{2/n_g}}\right| H_0{:}\; \bar{y}_1-\bar{y}_2=0\right)
$$

$$
Pr\left(\left.T_{calc}\right| \Delta_{y_1,\,y_2}=0\right)
$$

$$
\text{Pr}(D | H_0)
$$

::: callout-tip
## Prinzip des statistischen Testens III - Das 95% Konfidenzintervall

Du findest auf YouTube [Prinzip des statistischen Testens III - Das 95% Konfidenzintervall]() als Video. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

```{r }
#| echo: false
#| message: false
#| label: fig-hist-flea-2
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "An 39 Hunden wurde die Anzahl an Flöhen gezählt."

ggplot(data = dog_fleas_tbl, aes(x = flea_weight)) +
  geom_histogram(binwidth = 1, fill = "gray", color = "black") +
  scale_x_continuous(breaks = 0:28) +
  scale_y_continuous(breaks = 0:9) +
  geom_vline(xintercept = 0:28, color = cbbPalette[6], alpha = 0.5,
             linetype = "dashed") +
  geom_hline(yintercept = 0:9, color = cbbPalette[6], alpha = 0.5,
             linetype = "dashed") +
  theme_bw() +
  labs(x = "Gewicht [mg]", y = "Anzahl") 

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "An 39 Hunden wurde die Anzahl an Flöhen gezählt."

ggplot(data = small_tbl, aes(x = flea_weight)) +
  geom_histogram(binwidth = 2, fill = "gray", color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = 11:19) +
  scale_y_continuous(breaks = 0:5) +
  geom_vline(xintercept = seq(11, 19, 2), color = cbbPalette[6], alpha = 0.5,
             linetype = "dashed") +
  geom_vline(xintercept = small_tbl$flea_weight, color = cbbPalette[7], size = 1.5) +
  geom_hline(yintercept = 0:5, color = cbbPalette[6], alpha = 0.5,
             linetype = "dashed") +
  theme_bw() +
  labs(x = "Gewicht [mg]", y = "Anzahl") 
```

## Der Effektschätzer {#sec-effect}

[Doing Meta-Analysis with R: A Hands-On Guide](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html)

[Der Effektschätzer wird auch gerne Theta $\boldsymbol{\theta}$ genannt. Da wir dann aber später noch mit anderen Konzepten in die Quere kommen, nutze ich das etwas intuitivere Delta $\boldsymbol{\Delta}$.]{.aside}

### Unterschied zweier Mittelwerte

Wir berechnen zwei Mittelwerte $\bar{y}_1$ und $\bar{y}_2$. Wenn wir wissen wollen wie groß der Effekt zwischen den beiden Mittelwerten ist, dann bilden wir die Differenz. Wir berechnen das $\Delta$ von $y_1$ und $y_2$ indem wir die Diffenz bilden.

$$
\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2
$$

Wenn es keinen Unterschied zwischen den beiden Mittelwerten $\bar{y}_1$ und $\bar{y}_2$ gibt, dann ist die Differenz $\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2$ gleich 0.

$$
H_0: \Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2 = 0
$$

In @tbl-dog-cat-small-delta ist eine Datenbeispiel gegeben.

```{r}
#| echo: false
#| label: tbl-dog-cat-small-delta
#| tbl-cap: Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.
data_tbl <- tibble(animal = gl(2, 4, labels = c("cat", "dog")),
                   jump_length = c(8.0, 7.9, 8.3, 9.1, 8.0, 7.8, 9.2, 7.7)) 

data_tbl %>% 
  kable(align = "c", "pipe")

mean_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean_animal = round(mean(jump_length), 1))

mean_cat <- mean_tbl$mean_animal[1]
mean_dog <- mean_tbl$mean_animal[2]

```

Nehmen wir an, wir berechnen für die Sprungweite \[cm\] der Hundeflöhe einen Mittelwert von $\bar{y}_{dog} = `r mean_dog`$ und für die Sprungweite \[cm\] der Katzenflöhe einen Mittelwert von $\bar{y}_{cat} =`r mean_cat`$. Wie große ist nun der Effekt? Oder anders gesprochen, welchen Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu sein? Was ist also der Effekt von `animal`? Wir rechnen $\bar{y}_{dog} - \bar{y}_{cat} = 8.2 - 8.3 = -0.1$. Zum einen wissen wir jetzt "die Richtung". Da wir ein Minus vor dem Mittelwertsunterschied haben, müssen die Katzenflöhe weiter springen als die Hundeflöhe, nämlich 0,1cm. Dennoch ist der Effekt sehr klein.

### Unterschied zweier Anteile

Neben den Unterschied zweier Mittelwerte ist auch häufig das Interesse an dem Unterschied zwischen zwei Wahrscheinlichkeiten oder auch Anteilen. Ebenso kann die Chance berechnet werden. Hier tritt häufig Verwirrung auf, daher hier zuerst ein Beispiel.

|            |       |                   |                   |
|:----------:|:-----:|:-----------------:|:-----------------:|
|            |       |   **Infected**    |                   |
|            |       |     *Yes (1)*     |     *No (0)*      |
| **Animal** | *Dog* | $23_{\;\Large a}$ | $10_{\;\Large b}$ |
|            | *Cat* | $18_{\;\Large c}$ | $14_{\;\Large d}$ |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils. {#tbl-2x2-ratio-delta}

Aus der @tbl-2x2-ratio-delta können wir entnehmen, dass 23 Hunde mit Flöhen infiziert sind und 10 Hunde keine Infektion aufweisen. Bei den Katzen haben wir 18 infizierte und 14 gesunde Tiere beobachtet. Wir können nun zwei Arten von Anteilen berechnen. Das bekanntere ist die Frequenz oder Wahrscheinlichkeit oder Risk Ratio (RR). Das andere ist das Chancenverhältnis oder Odds Ratio (OR). Beide kommen in der Statistik vor und sind unterschiedlich zu interpretieren.

#### Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)

$$
Pr(\mbox{dog}|\mbox{infected}) = \cfrac{a}{a+c} = \cfrac{23}{23+10} \approx 0.67
$$

$$
Pr(\mbox{cat}|\mbox{infected}) = \cfrac{b}{b+d} = \cfrac{18}{18+14} \approx 0.56
$$

$$
\Delta_{y_1/y_2} = RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} =  \cfrac{0.67}{0.56} \approx 1.2 
$$

#### Chancenverhältnis oder Odds Ratio (OR)

$$
Odds(\mbox{dog}|\mbox{infected}) = a:b = 23:10 = \cfrac{23}{10} = 2.3
$$

$$
Odds(\mbox{cat}|\mbox{infected}) = c:d = 18:14 = \cfrac{18}{14} \approx 1.29 
$$

$$
\Delta_{y_1/y_2} = OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = \cfrac{a \cdot d}{b \cdot c} = \cfrac{2.30}{1.29} \approx 1.78
$$

Wann liegt nun kein Effekt bei einem Anteil wie dem RR oder OR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe. Dies gilt sowohl fürdas RR als auch das OR.

$$
H_0: RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} = 1
$$

$$
H_0: OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = 1
$$

::: callout-important
## Stärke eines Effektes

Du musst immer den Effekt, hier den Mittelwertsunterschied, im Kontext der Fragestellung bzw. des Outcomes $y$ bewerten. Der numerische Unterschied von 0,1cm kann in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein Unterschied von 0,1cm sehr viel sein. Oder aber sehr wenig, wenn wir uns das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage, ob ein Unterschied von 6% viel oder wenig ist...
:::

::: callout-tip
## Effektschätzer

Wenn wir uns einen Unterschied eines **Mittelwerts** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn das $\Delta$ zwischen Gruppe $A$ und Gruppe $B$ gleich 0 ist. Die Nullhypothese gilt.

$$
\Delta_{A-B} = A - B = 0
$$

Wenn wir uns einen Unterschied eines **Anteils** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn das $\Delta$ zwischen Gruppe $A$ und Gruppe $B$ gleich 1 ist. Die Nullhypothese gilt.

$$
\Delta_{A/B} = \cfrac{A}{B} = 1
$$

Dieses Wissen brauchen wir um die Signifikanzschwelle bei einem 95% Konfidenzintervall richtig zu setzen und interpretieren zu können.
:::
