```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Grundlagen der Klassifikation {#sec-class-basic}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

Dieses Kapitel dient als Einführung in die *Klassifikation* mit maschinellen Lernmethoden. Leider müssen wir wieder einiges an Worten lernen, damit wir überhaupt mit den Methoden anfangen können. Vieles dreht sich um die Aufbereitung der Daten, damit wir dann auch mit den Modellen anfangen können zu *arbeiten*. Ja ich meine wirklich Arbeiten, denn wir werden eher einen Prozess durchführen. Selten rechnet man einmal ein Modell und ist zufrieden. Meistens müssen wir noch die Modelle *tunen* um mehr aus den Modellen rauszuholen. Wir wollen bessere Vorhersagen mit einem kleineren Fehler erreichen. Das ganze können wir dann aber nicht in einem Schritt machen, sondern brauchen viele Schritte nacheinander. Damit müssen wir auch mir R umgehen können sonst ist der Prozess nicht mehr abzubilden.

[Mit *Tuning* bezeichnen wir den Prozess, ein Modell wiederholt zu verändern und dabei zu verbessern. Was wir verändern können, hängt vom gewählten Algorithums ab.]{.aside}

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, tidymodels, magrittr, conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

In dieser Einführung nehmen wir die infizierten Ferkel als Beispiel um einmal die verschiedenen Verfahren zu demonstrieren. Ich füge hier noch die ID mit ein, die nichts anderes ist, als die Zeilennummer. Dann habe ich noch die ID an den Anfang gestellt. Wir wählen auch nur ein kleines Subset aus den Daten aus, da wir in diesem Kapitel nur Funktion demonstrieren und nicht die Ergebnisse interpretieren.

```{r}
pig_tbl <- read_excel("data/infected_pigs.xlsx") %>% 
  mutate(pig_id = 1:n()) %>% 
  select(pig_id, infected, age:crp) %>% 
  select(pig_id, infected, everything())  
```

In @tbl-ml-basic-pig siehst du nochmal einen Auschnitt aus den Daten. Wir haben noch die ID mit eingefügt, damit wir einzelne Beobachtungen nachvollziehen können.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-ml-basic-pig
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.

rbind(head(pig_tbl),
      rep("...", times = ncol(pig_tbl)),
      tail(pig_tbl)) %>% 
  kable(align = "c", "pipe")
```

Gehen wir jetzt mal die Wörter und Begrifflichkeiten, die wir für das maschinelle Lernen später brauchen einmal durch.

## What he say's?

In diesem Teil des Skriptes werden wir wieder mit einer Menge neuer Begriffe konfrontiert. Deshalb steht hier auch eine Menge an neuen Worten drin. Leider ist es aber auch so, dass wir *bekanntes* neu bezeichnen. Wir tauchen jetzt ab in die Community der Klassifizierer und die haben dann eben die ein oder andere Sache neu benannt.

::: column-margin
Kurze Referenz zu [What he says?](https://youtu.be/RAidDYQLIK4)
:::

Die gute nachticht zuerst, wir haben ein relativ festes Vokabular. Das heißt, wir springen nicht so sehr zwischen den Begrifflichkeiten wie wir es in den anderen Teilen des Skriptes gemacht haben. Du kennst die Modellbezeichnungen wie folgt.

$$
y \sim x
$$

mit

-   $y$, als Outcome oder Endpunkt.
-   $x$, als Covariate oder Einflussvariable.

Das bauen wir jetzt um. Wir nennen in dem Bereich des maschinellen Lernen jetzt das $y$ und das $x$ wie folgt.

-   $y$ ist unser *label*, dafür gibt es kein deutsches Wort.
-   $x$ sind unsere *features* und mehrere Features bilden den *feature space*, dafür gibt es jeweils auch kein deutsches Wort.

Im folgenden Text werde ich also immer vom Label schreiben und dann damit das $y$ links von dem `~` in der Modellgleichung meinen. Wenn ich dann von den Features schreibe, meine ich alle $x$-Variablen rechts von dem `~` in der Modellgleichung. Ja, daran muss du dich dann gewöhnen. Es ist wieder ein anderer sprachlicher Akzent in einem anderen Gebiet der Statistik.

[*Label* meint also das $y$ oder Outcome. *Feature* beschreibt das $x$ oder die Einflussvariablen.]{.aside}

## Klassifikation vs. Regression

Wenn mich etwas aus der Bahn geworfen hat, dann waren es die Terme *classification* und *regression* im Kontext des maschinellen Lernens. Wenn ich von *classification* schreibe, dann wollen wir ein kategoriales Label vorhersagen. Das bedeutet wir haben ein $y$ vorliegen, was nur aus Klassen bzw. Kategorien besteht. Im Zweifel haben wir dann ein Label mit $0/1$ einträgen. Wenn mehr Klassen vorliegen, wird auch gerne von *multiclass* Klassifikation gesprochen.

Dazu steht im Kontrast der Term *regression*. In dem Kontext vom maschinellen Lernen meint *regression* die Vorhersage eines numerischen Labels. Das heißt, wir wollen die Körpergröße der Studierenden vorhersagen und nutzen dazu einen *regression* Klassifikator. Das ist am Anfang immer etwas verwirrend. Wir unterschieden hier nur die Typen der Label, sonst nichts. Wir fassen also wie folgt zusammen.

-   *classification*, wir haben ein Label bzw. $y$ mit Kategorien. Nehmen wir einmal unser Ferkelbeispiel. In unserer Spalte `infected` sind die Ferkel infiziert $(1)$ oder nicht-infiziert daher gesund $(0)$.
-   *regression*, wir haben ein Label bzw. $y$ mit kontinuierlichen Werten. Unsere Ferkel haben ein Gewicht in $kg$ und daher nehmen wir die Spalte `weight`.

Wir brauchen die Begriffe, da wir später in den Algorithmen spezifizieren müssen, welcher Typ die Klassifikation sein soll.

## Supervised vs. unsupervised

Der Unterschied zwischen einer *suprvised* Lernmethode oder Algorithmus ist, dass das Label bekannt ist. Das heißt, dass wir in unseren Daten eine $y$ Spalte haben an der wir unser Modell dann trainieren können. Das Modell weiß also an was es sich optimieren soll. In @tbl-class-supervised sehen wir einen kleinen Datensatz in einem *supervised* Setting. Wir haben ein $y$ in den Daten und können an diesem Label unser Modell optimieren.

| $y$ | $x_1$ | $x_2$ | $x_3$ |
|-----|-------|-------|-------|
| 1   | 0.2   | 1.3   | 1.2   |
| 0   | 0.1   | 0.8   | 0.6   |
| 1   | 0.3   | 2.3   | 0.9   |
| 1   | 0.2   | 9.1   | 1.1   |

: Beispieldatensatz für *supervised learning*. Unsere Daten haben eine Spalte $y$, die wir als Label in unserem Modell nutzen können. {#tbl-class-supervised}

In der @tbl-class-unsupervised sehen wir als Beispiel einen Datensatz ohne eine Spalte, die wir als Label nutzen können. Nazürlich haben wir in echt dann keine freie Spalte. Ich habe das einmal so gebaut, damit du den Unterschied besser erkennen kannst. Beim *unsuoervised* Lernen muss der Algorithmus sich das Label selber bauen. Wir müssen meist vorgeben, wie viele Gruppen wir im Label erwarten würden. Dann können wir den Algorithmus starten.

|               | $x_1$ | $x_2$ | $x_3$ |
|---------------|-------|-------|-------|
| $\phantom{0}$ | 0.2   | 1.3   | 1.2   |
|               | 0.1   | 0.8   | 0.6   |
|               | 0.3   | 2.3   | 0.9   |
|               | 0.2   | 9.1   | 1.1   |

: Beispieldatensatz für *unsupervised learning*. Unsere Daten haben keine Spalte $y$, die wir als Label in unserem Modell nutzen können. {#tbl-class-unsupervised}

Wir haben sehr oft eine *superised* Setting vorliegen. Aber wie immer, du wirst vielleicht auch Cluster bilden wollen und dann ist das *unsupervised* Lernen eine Methode, die du gut nutzen kannst.

## Bias vs. Varianz

-   **Bias**: Der Bias (deu. *Verzerrung*) unseres Modells hat mit den Annahmen zu tun, die wir über die Daten machen. Im Weiteren wie gut das Modell zu den Daten passt, wenn das Modell trainiert wird. Ein Modell mit einem hohen Bias passt nicht gut zu den Trainingsdaten, hat eine begrenzte Flexibilität oder ist extrem einfach für die vorliegenden Daten. Wenn ein Modell zu simpel ist führt es häufig zu einem hohen Trainingsfehler. Das Label der Traingsdaten wird daher nicht gut wiedergegeben.
-   **Varianz**: Die Varianz unseres Modells hat damit zu tun, wie es seine Ergebnisse in Abhängigkeit von den Traingsdaten variiert. Ein Modell mit hoher Varianz kann sich gut an die Trainingsdaten anpassen und hat daher Probleme bei der Verallgemeinerung auf die ungesehene Testdaten, was zu einem hohen Testfehler führt.

![Der Bias ist eine menschliche Komponente des Modells. Wir wählen das Modell aus und bringen damit eine *mögliche* Verzerrung in die Auswertung. Die Varianz wird vom Modell selber verursacht und beschreibt den Zusammenhang zwischen dem Traings- und Testdaten.](images/class-bias-overview.png){#fig-class-bias-overview fig-align="center" width="90%"}

[Der Bias zeigt uns, wie gut unser Modell der Realität entspricht. Die Varianz sagt uns, wie gut unser Modell auf die Trainingsdaten abgestimmt ist.]{.aside}

$$
error = variance + bias + \epsilon
$$

![Abstrakte Darstellung des Bias vs. Varianz Trade-off.](images/class-bias-variance-overview.png){#fig-class-bias-var-overview fig-align="center" width="90%"}

![Unser erstes Modell hat ein hohes Bias. Daher klassifiziert mich das Modell 1 als ein Meerschweinchen, obwohl ich ein Krokodil bin.](images/class-bias-03.jpg){#fig-class-bias-03 fig-align="center" width="60%"}

::: {#fig-class-bias-0102 layout-ncol="2" layout-valign="center"}
![In unserem Trainingsdatensatz hat unser Modell 2 eine hohe Varianz. Das Modell 2 findet zwar das Meerschweinchen im Bild, aber hat Probleme auf dem folgenden Testdaten.](images/class-bias-01.png){#fig-class-bias-01 fig-align="center" width="80%"}

![In unseren Testdaten zu dem trainierten Modell 2 kann das Meerschweinchen im Bild nicht erkannt werden. Das Modell 2 hat eine zu hohe Varianz.](images/class-bias-02.jpg){#fig-class-bias-02 fig-align="center" width="100%"}

Unser zweites Modell hat eine hohe Varianz. Es erkennt zwar *perfekt* eine Meerschweinchenart, muss aber bei einer anderen Art passen.
:::

![Unser letztes Modell 3 hat eine niedrige Varianz und ist in der Lage die Schafe auch als Schafe zu entdecken. Ein Schaf senkt den Kopf und schon kann unser Modell 3 das Schaf nicht mehr finden.](images/class-bias-04.png){#fig-class-bias-04 fig-align="center" width="70%"}

https://towardsdatascience.com/quick-bias-variance-trade-off-d4895b126b08

## Bagging

Das Wort *Bagging* steht für *bootstrap aggregating* und ist eine Methode, um Vorhersagen aus verschiedenen Modellen zu kombinieren. Dabei müssen alle Modelle mit dem gleichen Algorithmus laufen, können aber auf verschiedenen Datensätzen oder aber Variablensätzen zugreifen. Häufig haben die Modelle eine hohee Varianz in der Vorhersage und wir nutzen dann Bagging um die Modelle miteinader zu kombinieren und dadurch die Varianz zu verringern. Die Ergebnisse der Modelle werden dann im einfachsten Fall gemittelt. Das Ergebnis jeder Modellvorhersage geht mit gleichem Gewicht in die Vorhersage ein. Wir haben auch noch andere Möglichkeiten, aber du kannst dir Vorstellen wir rechnen verschiedene Modelle $k$-mal und bilden dann ein finales Modell in dem wir alle $k$-Modelle zusammenfassen. Wie wir die Zusammenfassung rechnen, ist dann immer wieder von Fall zu Fall unterschiedlich. Wir erhalten am Ende einen *Ensemble* Klassifizierer, da ja ein Ensemble von Modellen zusammengefasst wird.

## Boosting

![](images/caution.png){fig-align="center" width="50%"}

https://medium.com/greyatom/a-quick-guide-to-boosting-in-ml-acf7c1585cb5

https://towardsdatascience.com/boosting-algorithms-explained-d38f56ef3f30

https://howtolearnmachinelearning.com/articles/boosting-in-machine-learning/

## Recipes

::: column-margin
Du findest hier die [Introduction to recipes](https://recipes.tidymodels.org/) und dann eine Idee wie `recipes` funktionieren mit [Preprocess your data with recipes](https://www.tidymodels.org/start/recipes/).
:::

1)  Erstellen des Modells (lr_mod),
2)  ein Vorverarbeitungsrezept (eng. *preprocessing*) erstellt (flights_rec),
3)  das Modell und das Rezept gebündelt (flights_wflow), und
4)  unseren Workflow mit einem einzigen Aufruf von fit() trainiert.

## Problem der fehlenden Werte

::: callout-note
## Mehr zu fehlenden Werten

Im @sec-pre-processing erfährst du, wie du mit den fehlenden Werten im maschinellen Lernen umgehst. Im @sec-missing mehr über die Hintergründe und die Verfahren.
:::

Ein wichtiger Punkt ist bei der Nutzung von maschinellen Lernen, dass wir *keine* fehlenden Beobachtungen in den Daten haben dürfen. Es darf kein einzelner Wert fehlen. Dann funktionieren die Algorithmen nicht und wir erhalten eine Fehlermeldung. Deshalb ist es die erste Statistikerpflicht darauf zu achten, dass wir nicht so viele fehlenden Werte in den Daten haben. Das ist natürlich nur begrenzt möglich. Wenn wir auf die Gummibärchendaten schauen, dann wurden die Daten ja von mir mit Erhoben. Dennoch haben wir viele fehlende Daten mit drin, da natürlich Studierende immer was eingetragen haben. Wenn du wissen willst, wie du mit fehlenden Werten umgehst, dann schaue einmal dazu das @sec-missing an. Wir gehen hier nicht nochmal auf alle Verfahren ein, werden aber die Verfahren zur Imputation von fehlenden Werten dann am Beispiel der Gummibärchendaten anwenden. Müssen wir ja auch, sonst könnten wir auch die Daten nicht für maschinelle Lernverfahren nutzen.

## Normalisierung

::: callout-note
## Mehr zur Normalisierung

Im @sec-pre-processing erfährst du, wie du die Normalisierung von Daten im maschinellen Lernen anwendest. Im @sec-eda-transform mehr über die Hintergründe und die Verfahren.
:::

Unter Normalisierung der Daten fassen wir eigentlich ein *preprocessing* der Daten zusammen. Wir haben ja unsere Daten in einer ursprünglichen Form vorliegen. Häufig ist diese Form nicht geeignet um einen maschinellen Lernalgorithmus auf diese ursprüngliche Form der Daten anzuwenden. Deshalb müssen wir die Daten vorher einmal anpassen und in eine geleiche Form über alle Variablen bringen. Was meine ich so kryptisch damit? Schauen wir uns einmal in der @tbl-class-normal ein Beispiel für zu normalisierende Daten an.

| $y$ | $x_1$ | $x_2$ | $x_3$ |
|-----|-------|-------|-------|
| 1   | 0.2   | 1430  | 23.54 |
| 0   | 0.1   | 1096  | 18.78 |
| 1   | 0.4   | 2903  | 16.89 |
| 1   | 0.2   | 7861  | 12.98 |

: Beispieldatensatz für einen Datensatz der nomiert werden muss. Die einzelenen Spalten haben sehr unterschiedliche Wertebereiche eingetragen. {#tbl-class-normal}

Warum müssen diese Daten normalisiert werden? Wir haben mit $x_1$ eine Variable vorliegen, die im Iterval $[0;1]$ liegt. Die Variable $x_2$ liegt in einem zehntausendfach größeren Wertebereich. Die Werte der Variable $x_3$ ist auch im Vergleich immer noch hundertfach im Wertebereich unterschiedlich. Dieser großen Unterschiede im Wertebereich führen zu fehlern bei Modellieren. Wir können hierzu das @sec-eda-transform betrachten. Dort werden gängige Transformationen einmal erklärt. Wir gehen hier nicht nochmal auf alle Verfahren ein, sondern konzentrieren uns auf die häufigsten Anwendungen.
