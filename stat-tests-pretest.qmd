```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Der Pre-Test oder Vortest {#sec-pretest}

*Letzte Änderung am `r format(fs::file_info("stat-tests-pretest.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"I struggle with some demons; They were middle class and tame." --- Leonard Cohen, You Want It Darker*

Der Pre-Test, ein Kapitel was ich nicht mag. Also eher weniger das Kapitel als den Pre-Test. Auf der einen Seite sind die Pre-Tests hoffnungslos veraltet. Pre-Tests stammen aus einer Zeit in der man sich nicht einfach die Daten angucken konnte. Mit angucken meine ich dann in `ggplot` visualisieren. Die Idee hinter Pre-Test ist eigentlich die Angst selber die Entscheidung zu treffen, ob die Daten varianzhomogen oder normalverteilt sind. Eine bessere Lösung ist immer noch das Outcome $y$ zu transformieren (siehe @sec-eda-transform) und dann das untransformierte Modell mit transformierten Modell zu vergleichen (siehe @sec-model-basic-compare). Auf der anderen Seite ist der Pre-Test eine Art übermächtiger Entscheider. Dabei sind die Formel sehr trivial und das Konzept eher simpel. Wir können uns aber folgende Faustregel merken:

1)  Wir testen die Varianzhomogenität auf dem *ganzen* Datensatz.
2)  Wir testen die Abweichung von der Normalverteilung für jede Behandlungsgruppe *getrennt*.

Neben dieser Angst eine Entscheidung zu treffen, hilft einem der Pre-Test zur Varianzhomogenität und der Pre-Test zur Normalverteilung bei kleiner Fallzahl auch nicht wirklich weiter, wie wir gleich sehen werden. Beide Pre-Tests funktionieren erst bei wirklich hohen Fallzahlen gut. Mit hohen Fallzahlen meine ich, Fallzahlen von über 20 Beobachtungen *je Gruppe* bzw. Level des Faktors. Bei kleiner Fallzahl, also der üblichen Anzahl von weniger als zehn Wiederholungen, können wir auch nur die Boxplots oder Dotplots anschauen. Darüber hinaus können wir uns auch schnell ins Abseits testen, so dass wir gar keinen Test mehr übrig haben um unsere Daten auszuwerten.

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Probleme mit dem Pre-Tests ist, dass die Fallzahl in unseren Daten $D$ oft **viel zu klein** ist um eine eindeutige Aussage zu treffen.
:::

::: callout-tip
## Visuelle Überprüfung der Normalverteilung und Varianzheterogenität

Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/intro.html) erlaubt eine weitreichende Diagnostik auf einem normalverteilten Outcome $y$. Es ist besser sich die Diagnostikplots anzuschauen, als die statistischen Pre-Tests zu rechnen. Besonders bei kleiner Fallzahl. Wenn du dazu dann noch Literatur für deine Abschlussarbeit brauchst, dann nutze doch die Arbeit von @zuur2010protocol mit dem Artikel [A protocol for data exploration to avoid common statistical problems](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210X.2009.00001.x) oder aber die Arbeit von @kozak2018s mit dem Artikel [What's normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions](https://onlinelibrary.wiley.com/doi/pdf/10.1111/jac.12220?casa_token=22Jm83-kW-MAAAAA:yh0EVuGiGHWDsuPiVP8ZLj51OCasdpIiVWUcYv3Q8dGaIo0yMeNZNwkHIk1ibTCsLhkxbLKZrwZSByo).

Es ist grundsätzlich besser verschiedene Modelle zu fitten und dann sich in @sec-lin-reg-quality die Güte oder Qualität der Modelle anzuschauen. Jedenfalls ist das meiner Meinung nach die bessere Lösung. Da aber immer wieder nach den Pre-Tests gefragt wird, habe ich auch dieses Kapitel erschaffen.

Ich habe dir am Ende des Kapitels nochmal den einfachen Weg dein Modell zu überprüfen an einem etwas komplexeren Datensatz aufgezeigt. Schau dir dazu dann die @fig-pretest-check-model einmal an. Diese Abbildung kannst du dann auch nachbauen und in deinen Anhang packen sowie dich mit der Referenz drauf beziehen.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, olsrr,
               broom, car, performance, 
               see, scales, readxl, nlme,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

## Die Flowchart, die jeder möchte...

Dann hier mal gleich zu Beginn die Flowchart, die jeder gerne möchte. In der @fig-mermaid-pretest-01 sehen wir einmal dargestellt, welches statistische Modell wir rechnen können um dann eine ANOVA und ein Posthoc-Test anzuschließen. Wie du auf den ersten Blick siehst, ist es immer besser auf der linken Seite der Flowchart zu sein. Viele Merkmale in den Agrarwissenschaften folgen per se einer Normalverteilung, so dass sich nur die Frage nach der Varianzhomogenität stellt.

```{mermaid}
%%| label: fig-mermaid-pretest-01
%%| fig-width: 6
%%| fig-cap: "Flowchart für die Entscheidung welches statistische Modell gerechnet werden kann: `lm()`, lineare Regression, `gls()`, generalized least squares Regression, `rq()`, Quantilesregression. Die Funktionen finden sich teilweise in eigenen R Paketen. Bei einem nicht-normalverteilten Outcome mit Varianzheterogenität über die Gruppen müssen wir nochmal gemeinsam in die Daten schauen."
flowchart TD
    A("Normalverteiltes Outcome
       in jeder Versuchsgruppe"):::factor --- B(((ja))) --> B1 %% C(Varianzhomogenität):::factor 
    A("Normalverteiltes Outcome
       in jeder Versuchsgruppe"):::factor --- F(((nein))) --> B2 %%G(Varianzhomogenität):::factor 
    subgraph B1["Mittelwertsvergleiche"]
    C("Varianzhomogenität
       über alle Gruppen"):::factor --- D((("ja"))) --> E("lm()"):::factor
    C("Varianzhomogenität
       über alle Gruppen"):::factor --- J(((nein))) --> K("gls()"):::factor 
    end
    subgraph B2["Medianvergleiche, OR oder RR"]
    G("Varianzhomogenität
       über alle Gruppen"):::factor --- H(((ja))) --> I("rq()"):::factor  
    G("Varianzhomogenität
       über alle Gruppen"):::factor --- L(((nein))) 
    end
    classDef factor fill:#56B4E9,stroke:#333,stroke-width:0.75px
```

Du findest die vorgeschlagenen Funktionen dann in den entsprechenden Kapiteln zur ANOVA und den Posthoc-Tests. Du kannst dir dann dort den Code zusammensuchen. Je nach deiner Datenlage musst du dann nochmal etwas an dem R Code programmieren. Beachte, dass die Funktionen sich teilweise in eigenen R Paketen finden lassen. So ist die Funktion `gls()` im R Paket `nlme` und die Funktion `rq()` im R Paket `quantreg` zu finden. Aber hier ist nicht der richtige Ort um ins Detail zu gehen.

Bei einem nicht-normalverteilten Outcome mit Varianzheterogenität über die Gruppen müssen wir nochmal gemeinsam in die Daten schauen. Da meldest du dich bitte nochmal bei mir in der statistischen Beratung. Hier öffnet sich nämlich eine Tür in eine ganz eigene Modellwelt und je nach wissenschaftlicher Fragestellung können wir dann eine Lösung finden.

::: {.callout-tip collapse="true"}
## Exkurs: Robuste Schätzung von Standardfehlern, Konfidenzintervallen und p-Werten

Wenn du noch etwas weiter gehen möchtest, dann kannst du dir noch die Hilfeseite von dem R Paket `performance` [Robust Estimation of Standard Errors, Confidence Intervals, and p-values](https://easystats.github.io/parameters/articles/model_parameters_robust.html?q=Heteroskedasticity#robust-covariance-matrix-estimation-from-model-parameters) anschauen. Die Idee ist hier, dass wir die Varianz/Kovarianz robuster daher mit der Berücksichtigung von Varianzheterogenität (eng. *heteroskedasticity*) schätzen.
:::

## Pre-Test auf Varianzhomogenität

Was will also der Pre-Test auf Varianzhomogenität? Eigentlich ist der Test vollkommen verquer. Zum einen testet der Test auf Varianzhomogenität gar nicht die *Anwesenheit* von Homogenität. Wir können dank dem Falisifikationsprinzip nur Ablehnen. Deshalb steht in der Nullhypothese die Gleichheit der Varianzen, also Varianzhomogenität und in der Alternativen dann die Varianzheterogenität, als der Unterschied.

Ab wann sollten wir denn die Varianzhomogenität ablehnen? Wenn wir standardmäßig auf 5% testen, dann werden wir zu selten die Varianzhomogenität ablehnen. Daher ist es ratsam in diesem Fall auf ein Signifikanzniveau von $\alpha$ gleich 20% zu testen. Aber auch in diesem Fall können wir natürlich eine Varianzhomogenität übersehen oder aber eine Varianzheterogenität fälschlicherweise annehmen.

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Einigermaßen zuverlässig meint, dass wir dann in 1 von 20 Fällen eine Varianzhomogenität ablehnen, obwohl eine Varianzhomogenität vorliegt. Ebenso können wir in 1 von 5 Fällen die Nullhypothese nicht ablehnen, obwohl die Varianzen heterogen sind (siehe auch @sec-alpha-beta).
:::

Es ergeben sich folgende Hypothesen für den Pre-Test auf Varianzhomogenität.

$$
\begin{aligned}
H_0: &\; s^2_A = s^2_B\\
H_A: &\; s^2_A \ne s^2_B\\
\end{aligned}
$$

Wir sehen, dass in der Nullhypothese die Gleichheit der Varianzen steht und in der Alternativehypothese der Unterschied, also die Varianzhterogenität.

::: callout-important
## Entscheidung zur Varianzhomogenität

Bei der Entscheidung zur Varianzhomogenität gilt folgende Regel. Ist der $p$-Wert des Pre-Tests auf Varianzhomogenität kleiner als das Signifikanzniveau $\alpha$ von 20% lehnen wir die Nullhypothese ab. Wir nehmen Varianzheterogenität an.

-   Ist $p \leq \alpha = 20\%$ so nehmen wir Varianzheterogenität an.
-   Ist $p > \alpha = 20\%$ so nehmen wir Varianzhomogenität an.

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf Varianzhomogenität nochmal visuell bestätigen.
:::

Wir nutzen zum statistischen Testen den Levene-Test über die Funktion `leveneTest()` oder den Bartlett-Test über die Funktion `bartlett.test()`. Beide Tests sind in R implementiert und können über das Paket `car` genutzte werden. Wir werden uns jetzt nicht die Formel anschauen, wir nutzen wenn die beiden Tests nur in R und rechnen nicht selber die Werte nach.

Einfach ausgedrückt, überprüft der Bartlett-Test die Homogenität der Varianzen auf der Grundlage des Mittelwerts. Dementsprechend ist der Bartlett-Test empfindlicher gegen eine Abweichung von der Normalverteilung der Daten, die er überprüfen soll. Der Levene-Test überprüft die Homogenität der Varianzen auch auf der Grundlage des Mittelwerts. Wir haben aber auch die Wahl, den Median zu nutzen dann ist der Levene-Test robuster gegenüber Ausreißern.

Im Folgenden wollen wir uns einmal in der Theorie den Levene-Test anschauen. Der Levene-Test ist eigentlich nichts anderes als eine etwas versteckte einfaktorielle ANOVA, aber dazu dann am Ende mehr. Dafür nutzen wir als erstes die folgende Formel um die Teststatistik zu berechnen. Dabei ist $W$ die Teststatistik, die wir zu einer $F$-Verteilung, die wir schon aus der ANOVA kennen, vergleichen können.

$$
W = \frac{(N-k)}{(k-1)} \cdot \frac{\sum_{i=1}^k N_i (\bar{Z}_{i\cdot}-\bar{Z}_{\cdot\cdot})^2} {\sum_{i=1}^k \sum_{j=1}^{N_i} (Z_{ij}-\bar{Z}_{i\cdot})^2}
$$

Zur Veranschaulichung bauen wir uns einen simplen Datensatz mit $N = 14$ Beobachtungen für $k = 2$ Tierarten mit Hunden und Katzen. Damit hat jede Tierart $7$ Beobachtungen der Sprunglängen der jeweiligen Hunde- und Katzenflöhe.

```{r}
#| message: false

animal_tbl <- tibble(dog = c(5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6),
                     cat = c(3.2, 2.2, 5.4, 4.1, 1.1, 7.9, 8.6))
animal_tbl
```

Dann berechnen wir uns auch gleich die absoluten Abstände $Z_{ij}$ von jeder Beobachtung zu den jeweiligen Mittelwerten der Gruppe. Wir könnten auch die Abstände zu den jeweiligen Medianen der Gruppe berechnen. Beides ist möglich. Hier sehen wir auch den Unterschied zu der ANOVA, wir berechnen hier nicht die *quadratischen* Abstände sondern die absoluten Abstände.

```{r}
#| message: false

z_tbl <- animal_tbl %>% 
  mutate(dog_abs = abs(dog - mean(dog)),
         cat_abs = abs(cat - mean(cat)))
z_tbl
```

Im Folgenden nochmal in formelschreibweise der Unterschied zwischen den beiden Abstandsberechnungen $Z_{ij}$ für jeden Wert. Wir haben die Wahl zwischen den Abständen von jeder Beobachtung zu dem Mittelwert oder dem Median.

$$
Z_{ij} = 
\begin{cases}
|Y_{ij} - \bar{Y}_{i\cdot}|, & \bar{Y}_{i\cdot} \text{ ist der Mittelwert der } i\text{-ten Gruppe}, \\
|Y_{ij} - \tilde{Y}_{i\cdot}|, & \tilde{Y}_{i\cdot} \text{ ist der Median der } i\text{-ten Gruppe}. 
\end{cases} 
$$

Berechnen wir nun die Gruppenmittelwerte $\bar{Z}_{i\cdot}$ für die Hunde und die Katzen jeweils einmal separat.

```{r}
mean(z_tbl$dog_abs)
```

```{r}
mean(z_tbl$cat_abs)
```

Dann brauchen wir noch den Mittelwert über alle Beobachtungen hinweg $\bar{Z}_{\cdot\cdot}$. Den können wir aus allen Beoachtungen berechnen oder aber einfach den Mittelwert der beiden Gruppenmittelwerte nehmen.

```{r}
(1.57 + 2.28)/2
```

Am Ende fehlt uns dann noch der Nenner mit der Summe der einzelnen quadratischen Abstände $Z_{ij}$ zu den Abstandsmitteln der einzelnen Gruppen $\bar{Z}_{i\cdot}$ mit $\sum_{i=1}^k \sum_{j=1}^{N_i} (Z_{ij}-\bar{Z}_{i\cdot})^2$. Den Wert können wir dann in R direkt einmal berechnen. Wir nehmen also die Vektoren der Einzelwerte und ziehen dort immer den Mittelwert der Abstände der Gruppe ab. Abschließend summieren wir dann einmal auf.

```{r}
sum((z_tbl$dog_abs - 1.57)^2)
sum((z_tbl$cat_abs - 2.28)^2)
```

Wir können dann alle Zahlen einmal zusammenbringen und in die Formel des Levene-Test einsetzen. Nun rechen wir dann wieder die quadratischen Abstände auf den absoluten Abständen. Ja, das ist etwas wirr, wenn man es zum ersten Mal liest.

$$
W = 
\cfrac{14-2}{2-1}\cdot
\cfrac{7 \cdot (1.57 - 1.93)^2 + 7 \cdot (2.28 - 1.93)^2}
{10.39 + 11.43} =
\cfrac{12}{1} \cdot \cfrac{1.76}{21.82} =
\cfrac{21.12}{21.82} \approx 0.968
$$

Wir erhalten ein $W = 0.968$, was wir direkt als eine F-Statistik interpretieren können. Schauen wir uns das Ergebnis einmal in der R Funktion `leveneTest()` aus dem R Paket `car` an. Wir brauchen dafür einmal die Werte für die Sprungweiten und müssen dann die Daten in das long-Format umbauen und dann rechnen wir den Levene-Test. Wir erhalten fast die numerisch gleichen Werte. Bei uns haben wir etwas gerundet und dann kommt die Abweichung zustande.

```{r}
#| message: false
#| warning: false
z_tbl %>% 
  select(dog, cat) %>% 
  gather(key = animal, value = jump_length) %$% 
  leveneTest(jump_length ~ animal, center = "mean")

```

Der Levene-Test ist eigentlich nichts anderes als eine einfaktorielle ANOVA auf den absoluten Abständen von den einzelnen Werten zu dem Mittelwert oder dem Median. Das können wir hier einmal nachvollziehen indem wir auf den absoluten Werten einmal eine einfaktorielle ANOVA in R rechnen. Wir erhalten den gleichen F-Wert in beiden Fällen. Eigentlich ist die ANOVA sogar etwas genauer, da wir hier auch die *Sum of squares* wie auch *Mean squares* erhalten.

```{r}
z_tbl %>% 
  select(dog_abs, cat_abs) %>% 
  gather(key = animal, value = jump_length) %$% 
  lm(jump_length ~ animal) %>% 
  anova()
```

Wir wollen uns nun im Folgenden nun zwei Fälle einmal näher anschauen. Zum einen den Fall, dass wir eine niedrige Fallzahl vorliegen haben und Varianzhomogenität sowie den Fall, dass wir eine niedrige Fallzahl und Varianzheterogenität vorliegen haben. Den Fall, dass wir hohe Fallzahl vorliegen haben, betrachten wir jetzt nicht weiter. In dem Fall funktionieren die Tests einigermaßen zuverlässig.

### Varianzen sind homogen, Fallzahl niedrig

Wir bauen uns nun einen Datensatz mit zwei Gruppen $A$ und $B$ zu je zehn Beobachtungen. Beide Gruppen kommen aus einer Normalverteilung mit einem Mittelwert von $\bar{y}_A = \bar{y}_A = 10$. Darüber hinaus haben wir Varianzhomogenität mit $s_A = s_B = 5$ vorliegen. Ja, wir spezifizieren hier in der Funktion `rnorm()` die Standardabweichung, aber eine homogene Standardabweichung bedingt eine homogene Varianz und umgekehrt. Abschließend verwandeln wir das Wide-Format noch in das Long-Format um.

```{r}
set.seed(202209013)
small_homogen_tbl <- tibble(A = rnorm(n = 10, mean = 10, sd = 5),
                            B = rnorm(n = 10, mean = 10, sd = 5)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In der @fig-vartest-1 sehen wir die Daten aus dem `small_homogen_tbl` einmal als Boxplot visualisiert.

```{r}
#| message: false
#| echo: false
#| label: fig-vartest-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Boxplot der beiden Treatment Level A und B. Beide Gruppen haben die gleichen Varianzen. Es liegt Varianzhomogenität vor."

ggplot(small_homogen_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_boxplot() +
  scale_fill_okabeito() +
  theme(legend.position = "none")
```

Wir wollen nun die Varianz auf Homogenität testen. Wir nutzen dafür den `leveneTest()` sowie den `bartlett.test()`. Beide Tests bieten sich an. Die Daumenregel ist, dass der Bartlett-Test etwas bessere statistische Eigenschaften hat. Dennoch ist der Levene-Test bekannter und wird häufiger angefragt und genutzt. Wir nutzen die Funktion `tidy()` aus dem Paket `broom` um die Ausgabe aufzuräumen und selektieren nur den $p$-Wert.

```{r}
leveneTest(rsp ~ trt, data = small_homogen_tbl) %>% 
  tidy %>% 
  select(p.value)

bartlett.test(rsp ~ trt, data = small_homogen_tbl) %>% 
  tidy %>% 
  select(p.value)
```

Wir sehen, dass der $p$-Wert größer ist als das Signifikanzniveau $\alpha$ von 20%. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen Varianzhomogenität an. Überdies sehen wir auch, dass sich die $p$-Werte nicht groß voneinander unterscheiden.

Wir können auch die Funktion `check_homogeneity()` aus dem Paket `performance` nutzen. Wir erhalten hier auch gleich eine Entscheidung in englischer Sprache ausgegeben. Die Funktion `check_homogeneity()` nutzt den Bartlett-Test. Wir können in Funktion auch andere Methoden mit `method = c("bartlett", "fligner", "levene", "auto")` wählen.

```{r}
lm(rsp ~ trt, data = small_homogen_tbl) %>% 
  check_homogeneity()
```

Wir nutzen das Paket `performance` für die Modellgüte im @sec-lin-reg-quality.

### Varianzen sind heterogen, Fallzahl niedrig

Nun stellt sich die Frage, wie sieht es aus, wenn wir ungleiche Varianzen vorliegen haben. Wir bauen uns nun einen Datensatz mit zwei Gruppen $A$ und $B$ zu je zehn Beobachtungen. Beide Gruppen kommen aus einer Normalverteilung mit einem Mittelwert von $\bar{y}_A = \bar{y}_A = 12$. Darüber hinaus haben wir Varianzheterogenität mit $s_A = 10 \ne s_B = 5$ vorliegen.

```{r}
set.seed(202209013)
small_heterogen_tbl <- tibble(A = rnorm(10, 10, 12),
                              B = rnorm(10, 10, 5)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In der @fig-vartest-2 sehen wir die Daten aus dem `small_heterogen_tbl` einmal als Boxplot visualisiert.

```{r}
#| message: false
#| echo: false
#| label: fig-vartest-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Boxplot der beiden Treatment Level A und B. Beide Gruppen haben ungleiche Varianzen. Es liegt Varianzheterogenität vor."

ggplot(small_heterogen_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_boxplot() +
  scale_fill_okabeito() +
  theme(legend.position = "none")
```

Wir wollen nun die Varianz auf Homogenität testen. Wir nutzen dafür den `levenTest()` sowie den `bartlett.test()`. Wir können nur die Varianzhomogenität testen, da jeder statistischer Test nur eine Aussage über die Nullhypothese erlaubt. Damit können wir hier nur die Varianzhomogenität testen.

```{r}
leveneTest(rsp ~ trt, data = small_heterogen_tbl) %>% 
  tidy %>% 
  select(p.value)

bartlett.test(rsp ~ trt, data = small_heterogen_tbl) %>% 
  tidy %>% 
  select(p.value)
```

Wir sehen, dass der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$ von 20%. Damit können wir die Nullhypothese ablehnen. Wir nehmen Varianzheterogenität an. Überdies sehen wir auch, dass sich die $p$-Werte nicht groß voneinander unterscheiden. Was wir sehen ist, dass wir zu einem Signifikanzniveau von 5% die klare Varianzheterogenität nicht erkannt hätten und immer noch Varianzhomogenität angenommen hätten.

Wir können auch die Funktion `check_homogeneity()` aus dem Paket `performance` nutzen. Wir erhalten hier auch gleich eine Entscheidung in englischer Sprache ausgegeben. Die Funktion `check_homogeneity()` nutzt den Bartlett-Test. Wir können in Funktion auch andere Methoden mit `method = c("bartlett", "fligner", "levene", "auto")` wählen.

```{r}
lm(rsp ~ trt, data = small_heterogen_tbl) %>% 
  check_homogeneity()
```

Wir sehen, dass sich die Implementierung des Bartlett-Tests in `check_homogeneity()` nicht von der Funktion `bartlett.test()` unterscheidet, aber die Entscheidung gegen die Varianzhomogenität zu einem Signifikanzniveau von 5% gefällt wird. Nicht immer hilft einem der Entscheidungtext einer Funktion.

## Pre-Test auf Normalverteilung

Wir treffen bei dem Test auf die Normalverteilung auch auf das gleiche Problem wie bei dem Pre-Test zur Varianzhomogenität. Wir haben wieder die Gleichheit, also das unser beobachtetes Outcome gleich einer Normalverteilung ist, in der Nullhypothese stehen. Den Unterschied, also das unser beobachtetes Outcome nicht aus einer Normalverteilung kommmt, in der Alternative.

$$
\begin{aligned}
H_0: &\; \mbox{y ist gleich normalverteilt}\\
H_A: &\; \mbox{y ist nicht gleich normalverteilt}\\
\end{aligned}
$$

Nun ist es aber so, dass es nicht nur *zwei* Verteilungen gibt. Es gibt mehr als die Normalverteilung und die *Nicht*-normalverteilung. Wir haben eine große Auswahl an möglichen Verteilungen und seit den 90zigern des letzten Jahrhunderts auch die Möglichkeiten andere Verteilungen des Outcomes $y$ zu modellieren. Leider fällt dieser Fortschritt häufig unter den Tisch und wir bleiben gefangen zwischen der Normalverteilung oder eben keiner Normalverteilung.

::: column-margin
Der [zentrale Grenzwertsatz](https://de.wikipedia.org/wiki/Zentraler_Grenzwertsatz) besagt, dass wenn ein $y$ von vielen Einflussfaktoren $x$ bestimmt wird, man von einem normalverteilten $y$ ausgehen.

Das Gewicht wird von vielen Einflussfaktoren wie Sport, Kalorienaufnahme oder aber Veranlagung sowie vielem mehr bestimmt. Wir können davon ausgehen, dass das Gewicht normalverteilt ist.
:::

Abschließend sei noch gesagt, dass es fast unmöglich ist, eine Verteilung mit weniger als zwanzig Beobachtungen überhaupt abzuschätzen. Selbst dann können einzelne Beobachtunge an den Rändern der Verteilung zu einer Ablehnung der Normalverteilung führen, obwohl eine Normalverteilung vorliegt.

Das R Paket `oslrr` bietet hier noch eine Funktion `ols_test_normality()`, die es erlaubt mit allen bekannten statistischen Tests auf Normalverteilung zu testen. Wenn der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$, dann können wir die Nullhypothese, dass unsere Daten gleich einer Normalverteilung wären, ablehnen. Die Anwendung kannst du dir in @sec-gaussian anschauen. Um jetzt kurz einen statistischen Engel anzufahren, wir nutzen *wenn überhaupt* den Shapiro-Wilk-Test oder den Kolmogorov-Smirnov-Test. Für die anderen beiden steigen wir jetzt hier nicht in die Therorie ab.

Am Ende sei noch auf den [QQ-plot](#sec-linreg-qq) verwiesen, mit dem wir auch visuell überprüfen können, ob eine Normalverteilung vorliegt.

::: callout-important
## Entscheidung zur Normalverteilung

Bei der Entscheidung zur Normalverteilung gilt folgende Regel. Ist der $p$-Wert des Pre-Tests auf Normalverteilung kleiner als das Signifikanzniveau $\alpha$ von 5% lehnen wir die Nullhypothese ab. Wir nehmen eine Nicht-Normalverteilung an.

-   Ist $p \leq \alpha = 5\%$ so nehmen wir Nicht-Normalverteilung von $y$ an.
-   Ist $p > \alpha = 5\%$ so nehmen wir Normalverteilung von $y$ an.

Auf jeden Fall sollten wir das Ergebnis unseres Pre-Tests auf Normalverteilung nochmal visuell bestätigen.
:::

### Approximativ normalverteilt, niedrige Fallzahl

Auch hier schauen wir uns den Fall mit einer niedrigen Fallzahl an. Dafür bauen wir usn erstmal Daten mit der Funktion `rt()`. Wir ziehen uns zufällig Beobachtungen aus einer t-Verteilung, die approximativ normalverteilt ist. Je höher die Freiheitsgrade `df` desto näher kommt die t-Verteilung einer Normalverteilung. Mit einem Freiheitsgrad von `df = 30` sind wir sehr nah an einer Normalverteilung dran.

```{r}
set.seed(202209013)
low_normal_tbl <- tibble(A = rt(10, df = 30),
                         B = rt(10, df = 30)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In @fig-normal-1 sehen wir auf der linken Seite den Dotplot der zehn Beobachtungen aus den beiden Gruppen $A$ und $B$. Wir sehen, dass die Verteilung für das Outcome `rsp` in etwa normalverteilt ist.

```{r}
#| message: false
#| echo: false
#| label: fig-normal-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Verteilung des Outcomes `rsp` der zehn Beobachtungen aus den Gruppen $A$ und $B$. Beiden Gruppen kommen aus einer t-Verteilung."
#| fig-subcap: 
#|   - "Dotplot des Outcomes `rsp`."
#|   - "Densityplot des Outcomes `rsp`."
#| layout-nrow: 1
#| column: page

ggplot(low_normal_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  scale_fill_okabeito() +
  theme(legend.position = "none")

ggplot(low_normal_tbl, aes(rsp, fill = trt)) +
  theme_bw() +
  geom_density(alpha = 0.5) +
  scale_fill_okabeito() +
  xlim(-5, 5) +
  theme(legend.position = "none")

```

Wir können den Shapiro-Wilk-Test nutzen um statistisch zu testen, ob eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber nicht, welche *andere* Verteilung vorliegt. Wir testen natürlich für die beiden Gruppen getrennt. Die Funktion `shapiro.test()`kann nur mit einem Vektor von Zahlen arbeiten, daher übergeben wir mit `pull` die entsprechend gefilterten Werte des Outcomes `rsp`.

```{r}
low_normal_tbl %>% 
  filter(trt == "A") %>% 
  pull(rsp) %>% 
  shapiro.test()
  
low_normal_tbl %>% 
  filter(trt == "B") %>% 
  pull(rsp) %>% 
  shapiro.test()
```

Wir sehen, dass der $p$-Wert größer ist als das Signifikanzniveau $\alpha$ von 5% für beide Gruppen. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen eine Normalverteilung an.

In dem folgendem Beispiel sehen wir dann aber, was ich mit in die Ecke testen meine bzw. so lange statistisch zu Testen bis nichts mehr geht.

### Nicht normalverteilt, niedrige Fallzahl

Schauen wir uns jetzt den anderen Fall an. Wir haben jetzt wieder eine niedrige Fallzahl mit je 10 Beobachtungen je Gruppe $A$ und $B$. In diesem Fall kommen die Beobachtungen aber aus einer exponentiellen Verteilung. Wir haben also definitiv keine Normalverteilung vorliegen. Wir generieren uns die Daten mit der Funktion `rexp()`.

```{r}
set.seed(202209013)
low_nonnormal_tbl <- tibble(A = rexp(10, 1/1500),
                            B = rexp(10, 1/1500)) %>% 
  gather(trt, rsp) %>% 
  mutate(trt = as_factor(trt))
```

In @fig-normal-2 sehen wir auf der linken Seite den Dotplot der zehn Beobachtungen aus den beiden Gruppen $A$ und $B$. Wir sehen, dass die Verteilung für das Outcome für die Behandlung $B$ in etwa normalverteilt ist sowie das das Outcome für die Behandlung $A$ keiner Normalverteilung folgt *oder* zwei Ausreißer hat. Die Entscheidung was jetzt stimmt ohne zu wissen wie die Daten generiert wurden, ist in der Anwendung meist nicht möglich.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-normal-2
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Verteilung des Outcomes `rsp` der zehn Beobachtungen aus den Gruppen $A$ und $B$. Beiden Gruppen kommen aus einer Exponentialverteilung."
#| fig-subcap: 
#|   - "Dotplot des Outcomes `rsp`."
#|   - "Densityplot des Outcomes `rsp`."
#| layout-nrow: 1
#| column: page


ggplot(low_nonnormal_tbl, aes(trt, rsp, fill = trt)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  scale_fill_okabeito() +
  theme(legend.position = "none")

ggplot(low_nonnormal_tbl, aes(rsp, fill = trt)) +
  theme_bw() +
  geom_density(alpha = 0.5) +
  scale_fill_okabeito() +
  xlim(-1500, 4400) +
  theme(legend.position = "none")

```

Wir können wieder den Shapiro-Wilk-Test nutzen um statistisch zu testen, ob eine Abweichung von der Normalverteilung vorliegt. Wir erfahren aber nicht, welche *andere* Verteilung vorliegt. Wir testen natürlich für die beiden Gruppen getrennt.

```{r}

low_nonnormal_tbl %>% 
  filter(trt == "A") %>% 
  pull(rsp) %>% 
  shapiro.test()
  
low_nonnormal_tbl %>% 
  filter(trt == "B") %>% 
  pull(rsp) %>% 
  shapiro.test()

```

Wir sehen, dass der $p$-Wert für die Behandlung $A$ kleiner ist als das Signifikanzniveau $\alpha$ von 5%. Damit können wir die Nullhypothese ablehnen. Wir nehmen keine Normalverteilung für Gruppe $A$ an. Auf der anderen Seite sehen wir, dass der $p$-Wert für die Behandlung $B$ größer ist als das Signifikanzniveau $\alpha$ von 5%. Damit können wir die Nullhypothese nicht ablehnen. Wir nehmen eine Normalverteilung für Gruppe $A$ an.

Super, jetzt haben wir für die eine Gruppe eine Normalverteilung und für die andere nicht. Wir haben uns in die Ecke getestet. Wir können jetzt verschiedene Szenarien vorliegen haben.

1)  Wir könnten in der Gruppe $A$ zwei Ausreißer vorliegen haben.
2)  Wir könnten in der Gruppe $B$ zufällig eine Normalverteilung beobachtet haben.

[Und nochmal zum Schluß, einem statistischen Test mit 4 bis 5 Wiederholungen in einer Gruppe zu glauben, ob eine Normalverteilung vorliegt, kannst du auch würfeln...]{.aside}

Leider wissen wir im echten Leben nicht, aus welcher Verteilung unsere Daten stammen, wir können aber *annehmen*, dass die Daten einer Normalverteilung folgen oder aber die Daten so transformieren, dass die Daten einer approximativen Normalverteilung folgen. Siehe dazu auch das @sec-eda-transform zur Transformation von Daten.

Wenn deine Daten *keiner* Normalverteilung folgen, dann kann es sein, dass du mit den Effektschätzern ein Problem bekommst. Du erfährst vielleicht, dass du die Nullhypothese ablehnen kannst, aber nicht wie stark der Effekt in der Einheit des gemessenen Outcomes ist.

### Testen der Normalverteilungsannahme in mehreren Gruppen

Im folgenden Beispiel zu den Keimungsraten von verschiedenen Nelkensorten wollen wir einmal testen, ob jede Sorte einer Normalverteilung folgt. Da wir hier insgesamt 20 Sorten vorliegen haben, nutzen wir die Funktion `map()` aus dem R Paket `purrr` um hier schneller voranzukommen. Wie immer laden wir erst die Daten und mutieren die Spalten in dem Sinne wie wir die Spalten brauchen.

```{r}
clove_tbl <- read_excel("data/clove_germ_rate.xlsx") %>% 
  mutate(clove_strain = as_factor(clove_strain),
         germ_rate = as.numeric(germ_rate))
```

Jetzt können wir die Daten nach der Sorte der Nelken in eine Liste mit der Funktion `split()` aufspalten und dann auf jedem Listeneintrag einen Shapiro-Wilk-Test rechnen. Dann machen wir uns noch die Ausgabe schöner und erschaffen uns eine `decision`-Spalte in der wir gleich das Ergebnis für oder gegen die Normalverteilung ablesen können.

```{r}
clove_tbl %>% 
  split(.$clove_strain) %>% 
  map(~shapiro.test(.x$germ_rate)) %>% 
  map(tidy) %>% 
  bind_rows(.id = "test") %>%
  select(test, p.value) %>% 
  mutate(decision = ifelse(p.value <= 0.05, "reject normal", "normal"),
         p.value = pvalue(p.value, accuracy = 0.001))

```

## Visuelle Überprüfung

Abschließend möchte ich hier nochmal das [R Paket performance](https://easystats.github.io/performance/) vorstellen. Wir können mit dem Paket auch die Normalverteilungsannahme der Residuen überprüfen sowie die Annahme der Homogenität der Varianzen. Das geht ganz einfach mit der Funktion `check_model()` in die wir einfach das Objekt mit dem Fit des Modells übergeben.

```{r}
lm_fit <- lm(germ_rate ~ clove_strain, clove_tbl)
```

Tja und schon haben wir in der @fig-pretest-check-model mehr als wir eigentlich wollen. Aber du siehst hier ganz gut, dass wir in diesen Daten Probleme mit der Varianzhomogenität haben. Die Linie in dem Subplot "Homogeneity of Variance" ist nicht flach und horizontal. Deshalb könnten wir die Daten einmal Transformieren oder aber mit der Varianzheterogenität modellieren. Das Modellieren machen wir gleich mal im Anschluss.

```{r}
#| echo: true
#| message: false
#| label: fig-pretest-check-model
#| fig-align: center
#| fig-height: 8
#| fig-width: 8
#| fig-cap: "Übersicht der Plots zu der Modellgüte aus der Funktion `check_model()` nach der Modellierung mit der Funktion `lm()` und der Annahme der Varianzhomogenität."
lm_fit %>% check_model(check = c("normality", "linearity", "homogeneity", "qq"))

```

Jetzt modellieren wir einmal die Effekte der `clove_strain` unter der Annahme der Varianzheterogenität. Die Funktion `gls()` aus dem R Paket `nlme` passt ein lineares Modell unter Verwendung der verallgemeinerten kleinsten Quadrate an. Die Fehler dürfen dabei aber korreliert oder aber ungleiche Varianzen haben. Damit haben wir ein Modell, was wir nutzen können, wenn wir Varianzheterogenität vorliegen haben.

```{r}
gls_fit <- gls(germ_rate ~ clove_strain, 
               weights = varIdent(form =  ~ 1 | clove_strain), 
               data = clove_tbl)
```

Wir gehen hier nicht tiefer auf die Funktion ein. Wir müssen nur die `weights` so angeben, dass die `weights` die verschiedenen Gruppen in dem Faktor `clove_strain` berücksichtigen können. Dann haben wir schon das Modell für die Varianzheterogenität. Mehr musst du dann auch nicht machen, dass ist dann manchmal das schöne in R, dass wir dann auch immer wieder auf gewohnte Templates zurückgreifen können.

In der @fig-pretest-check-model-gls sehen wir das Ergebnis der Modellanpassung. Sieht gut aus, jedenfalls besser als mit dem `lm()`. Besonders schön sehen wir, dass wir dann auch wieder normalverteilte Residuen vorliegen haben. Damit ist eine wichtige Annahme an das Modell erfüllt. Das wäre jetzt ein gutes Modell um im Anschluss `emmeans()` zu nutzen. Da gehst du dann aber bitte in das [Kapitel zu den Posthoc Tests](#sec-posthoc).

```{r}
#| echo: true
#| message: false
#| label: fig-pretest-check-model-gls
#| fig-align: center
#| fig-height: 8
#| fig-width: 8
#| fig-cap: "Übersicht der Plots zu der Modellgüte aus der Funktion `check_model()` nach der Modellierung mit der Funktion `gls()` und der Annahme der Varianzheterogenität über die Gruppen von `clove_strain`."
gls_fit %>% check_model(check = c("normality", "linearity", "qq"))

```

## Referenzen {.unnumbered}
