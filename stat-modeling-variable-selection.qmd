```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Variablenselektion {#sec-variable-selection}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

## Theoretischer Hintergrund

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

In diesem Kapitel prügeln wir aber einen statistischen Engel. Wir werden hier mal schauen müssen, was alles geht und was nicht. Variablen Selektion ist faktisch nicht *ein* Kapitel sondern ein Regal(kilo)meter voll mit Büchern.
:::

@sec-class-rf

::: column-margin
Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/variable_selection.html) erlaubt eine weitreichende Variablen Selektion, wenn ein normalverteiltes Outcome $y$ vorliegt.
:::

Im Folgenden will ich *kurz* die fünf Mythen der Variablenselektion von @heinze2017five zusammenfassen. Wie immer ersetzt meine deutsche Zusammenfassung nicht das eigenständige Lesen der *englischen* Orgnialquelle, wenn du die Informationen in deiner Bachelorarbeit zitieren willst.

1)  Die Anzahl der Variablen in einem Modell sollte reduziert werden, bis es 10 Ereignisse pro Variable gibt.
2)  Nur Variablen mit nachgewiesener Signifikanz des univariaten Modells sollten in ein Modell aufgenommen werden.
3)  Nicht signifikante Effekte sollten aus einem Modell entfernt werden.
4)  Der berichtete P-Wert quantifiziert den Typ-I-Fehler einer fälschlich ausgewählten Variablen.
5)  Variablenauswahl vereinfacht die Analyse.

"Variable selection should always be accompanied by sensitivity analyses to avoid wrong conclusions."

@heinze2018variable

@talbot2019descriptive

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, 
               MASS, ranger, Boruta, broom,
               scales, olsrr)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-chickpea-var
#| tbl-cap: Auszug aus dem Daten zu den Kichererbsen in Brandenburg.
#| column: page


chickpea_tbl <- read_excel("data/chickpeas.xlsx") 

rbind(head(chickpea_tbl, 3),
      rep("...", times = ncol(chickpea_tbl)),
      tail(chickpea_tbl, 3)) %>% 
  kable(align = "c", "pipe")

```

$$
3 * sand + 2 * temp + 1.5 * rained - 1.2 * forest + 1.1 * no3  
$$

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-pigs-var
#| tbl-cap: Auszug aus dem Daten zu den kranken Ferkeln.
#| column: page

pig_tbl <- read_excel("data/infected_pigs.xlsx") 

rbind(head(pig_tbl, 3),
      rep("...", times = ncol(pig_tbl)),
      tail(pig_tbl, 3)) %>% 
  kable(align = "c", "pipe")
```

$$
2 * crp + 0.5 * sex + 0.5 * frailty + 0.2 * bloodpressure + 0.05 * creatinin +  0.01 * weight
$$

## Methoden der Variablenselektion

### Per Hand

"Oft gibt es keinen wissenschaftlichen Grund, eine Variablenauswahl durchzuführen. Insbesondere erfordern Methoden der Variablenselektion einen viel größeren Stichprobenumfang als die Schätzung eines multiplen Modells mit einem festen Satz von Prädiktoren auf der Grundlage klinischer Erfahrung."

### Univariate Vorselektion

```{r}

chickpea_tbl %>%
  select(-dryweight) %>%                   
  map(~glm(dryweight ~ .x, data = chickpea_tbl, family = gaussian)) %>%    
  map(tidy) %>%                          
  map(filter, term != "(Intercept)") %>%       
  map(select, -term, -std.error, -statistic) %>%                        
  bind_rows(.id="term") %>% 
  arrange(p.value) %>% 
  mutate(p.value = pvalue(p.value),
         estimate = round(estimate, 2))

```

```{r}

pig_tbl %>%
  select(-infected) %>%                   
  map(~glm(infected ~ .x, data = pig_tbl, family = binomial)) %>%    
  map(tidy) %>%                          
  map(filter, term != "(Intercept)") %>%       
  map(select, -term, -std.error, -statistic) %>%                        
  bind_rows(.id="term") %>% 
  arrange(p.value) %>% 
  mutate(p.value = pvalue(p.value),
         estimate = round(estimate, 2))

```

### Sonderfall Gaussian linear Regression

[Variable Selection Methods](https://olsrr.rsquaredacademy.com/articles/variable_selection.html)

```{r}
chickenpea_fit <- lm(dryweight ~ temp + rained + location + no3 + fe + sand + forest, 
                   data = chickpea_tbl)
```

```{r}
ols_step_all_possible(chickenpea_fit) %>%
  as_tibble %>%
  arrange(desc(adjr)) %>%
  filter(n <= 4) %>% 
  select(predictors, adjr, aic) 

```

### `step` und `setpAIC`

```{r}
#| echo: true
#| message: false
#| eval: true
#| warning: false

fit <- glm(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin, 
           data = pig_tbl, family = binomial)

fit_step <- stepAIC(fit, direction = "both")
```

Test

```{r}
fit_step 
```

Test

### `ranger`

```{r}
#| echo: true
#| message: false
#| warning: false

fit <- ranger(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin, 
              data = pig_tbl, importance = "permutation")

pluck(fit, "variable.importance") %>% sort(decreasing = TRUE)
```

### `boruta`

```{r}
boruta_output <- Boruta(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin,  
                        data = pig_tbl)  

boruta_output
```

```{r}
#| echo: true
#| message: false
#| label: fig-log-pred
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Visualisierung der logistischen Gerade in einer simplen logistischen Regression mit der Variable `crp`."

plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  

```

```{r}
tent_boruta <- TentativeRoughFix(boruta_output)

tent_boruta
```

## Skalieren der Daten?

## Referenzen {.unnumbered}
