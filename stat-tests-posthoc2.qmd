```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, see, latex2exp,
               multcomp, emmeans, ggpubr, multcompView, nlme, quantreg, janitor,
               parameters, effectsize, patchwork, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
## ggplot template
gg_template <- ggplot() +
  theme_minimal() +
  theme(#axis.text.x = element_blank(),
        #axis.ticks.x = element_blank(),
        # axis.text.y = element_text(color = "#CC79A7", face = "bold", size = 14),
        axis.text.y = element_text(),
        axis.ticks.y = element_blank(),
        axis.text = element_text(size = 12),
        #axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 12, face = "italic"),
        plot.caption = element_text(face = "italic"),
        legend.position = "none") +
  scale_color_okabeito() +
  scale_fill_okabeito() 

```

# Der Post-hoc-Test {#sec-posthoc}

*Letzte Änderung am `r format(fs::file_info("stat-tests-posthoc.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Comparison is the thief of joy." --- Theodore Roosevelt*

|                         | Tukey HSD Test | `{emmeans}`  | Games |
|:------------------------|:--------------:|:------------:|:-----:|
| **Verteilung von y**    | normalverteilt |   beliebig   |       |
| **Varianzen von x**     |    homogen     |   beliebig   |       |
| **Fallzahl per Gruppe** |   balanciert   |   beliebig   |       |
| **Adjustierte p-Werte** |     immer      |   beliebig   |       |
| **Mögliche Vergleiche** |   *all-pair*   | enge Auswahl |       |

: test. Achtung, teilweise müssen die Optionen *aktiv* von dir aktiviert werden. {#tbl-übersicht}

Auf der Seite DSFAIR gibt es noch einen Artikel zu `emmeans` und der Frage [Why are the StdErr all the same?](https://schmidtpaul.github.io/dsfair_quarto/ch/summaryarticles/whyseequal.html) und dazu dann auch passend die Publikation [Analyzing designed experiments: Should we report standard deviations or standard errors of the mean or standard errors of the difference or what?](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/92DB0AF151C157B9C6E2FA40F9C9B635/S0014479719000401a.pdf/analyzing-designed-experiments-should-we-report-standard-deviations-or-standard-errors-of-the-mean-or-standard-errors-of-the-difference-or-what.pdf)

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-posthoc-temp
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Visueller Zusammenhang eines gemittelten Outcomes ($y$) aus einer Normalverteilung im Verhältnis zu der Einflussvariable ($x$) mit zwei oder mehr Kategorien anhand von Barplots. Hauptsächlich unterscheiden sich die Barplots durch die unterschiedlichen Einheiten auf der $y$-Achse. Die Fehlerbalken stellen den Standardfehler (*SE*) dar. *[Zum Vergrößern anklicken]*"

gg_template %+%
  tibble(x_fct = c("A", "B", "C"),  
         mean_normal = c(1.5, 2.5, 5),
         sd_normal = c(0.5, 0.5, 0.5)) +
  aes(x_fct, mean_normal, fill = x_fct) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean_normal-(sd_normal), 
                    ymax = mean_normal+(sd_normal)),
                width = 0.2) +
  labs(x = "Kategoriell (>2 Level)", y = "Mittlerer Ertrag [t/ha]",
       title = "Paarweiser Vergleich",
       subtitle = "Mit signifikanter ANOVA und Compact letter display") +
  annotate("text", x = 1.1, y = 6, hjust = "right", color = "black", size = 4, 
           label = "ANOVA < 0.05", fontface = 2) +
  annotate("text", x = c(1, 2, 3), y = c(2.3, 3.3, 5.8),
           label = c("a", "ab", "b"), size = 5, fontface = 2) 
```

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, see, latex2exp,
               multcomp, emmeans, ggpubr, multcompView, nlme, quantreg, janitor,
               parameters, effectsize, patchwork, agricolae, broom, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

```{r}
#| message: false

fac1_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length) |> 
  mutate(animal = as_factor(animal))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table
#| tbl-cap: "foo"

fac1_raw_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length)

rbind(head(fac1_raw_tbl, n = 3),
      rep("...", times = ncol(fac1_raw_tbl)),
      tail(fac1_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

Die Funktion `standard_error()` aus dem R Paket `{parameters}`

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-mean
#| tbl-cap: "foo"
fac1_tbl |> 
  group_by(animal) |> 
  summarise(Mittelwert = mean(jump_length),
            Standardabweichung = sd(jump_length),
            SE = standard_error(jump_length)) |> 
  mutate_if(is.numeric, round, 2) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Boxplot der Sprungweiten [cm] von Hunden und Katzen gemessen an verschiedenen Orten."
#| label: fig-boxplot-emmeans-fac1

ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) +
  geom_boxplot() +
  scale_fill_okabeito() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_minimal() +
  theme(legend.position = "none")
```

Wir machen den Datensatz mal kleiner

```{r}
#| message: false

fac2_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
  filter(site %in% c("city", "village")) |> 
  mutate(animal = as_factor(animal),
         site = as_factor(site))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-table
#| tbl-cap: "foo"

fac2_raw_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
    filter(site != "smalltown") 

rbind(head(fac2_raw_tbl, n = 3),
      rep("...", times = ncol(fac2_raw_tbl)),
      tail(fac2_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-mean
#| tbl-cap: "foo"
fac2_tbl |> 
  group_by(animal, site) |> 
  summarise(Mittelwert = mean(jump_length),
            Standardabweichung = sd(jump_length),
            SE = standard_error(jump_length)) |> 
  mutate_if(is.numeric, round, 2) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Boxplot der Sprungweiten [cm] von Hunden und Katzen gemessen an verschiedenen Orten."
#| label: fig-boxplot-emmeans-fac2

ggplot(fac2_tbl, aes(x = animal, y = jump_length, 
                     fill = site)) +
  geom_boxplot() +
  scale_fill_okabeito() +
  labs(x = "Tierart", y = "Sprungweite [cm]", fill = "Messort") +
  theme_minimal() 
```

## Modell

Einfaktorielles Modell

$$
y \sim f_1
$$

Zweifaktorielles Modell

$$
y \sim f_1 + f_2
$$

### Varianzhomogenität und Varianzheterogenität

Varianz in den Fakoren

::: panel-tabset
## Theoretisch

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-posthoc-var-homo-bar
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Visueller  *[Zum Vergrößern anklicken]*"

p1 <- gg_template %+%
  tibble(x_fct = c("A", "B", "C"),  
         mean_normal = c(1.5, 2.5, 5),
         sd_normal = c(0.5, 0.5, 0.5)) +
  aes(x_fct, mean_normal, fill = x_fct) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean_normal-(sd_normal), 
                    ymax = mean_normal+(sd_normal)),
                width = 0.2, linewidth = 1) +
  labs(x = "Behandlungsgruppen (X)", y = "Mittler Messwert (Y)",
       title = "Varianzhomogenität", subtitle = "Varianzen sind gleich")  +
  ylim(0, 8)

p2 <- gg_template %+%
  tibble(x_fct = c("A", "B", "C"),  
         mean_normal = c(1.5, 2.5, 5),
         sd_normal = c(0.25, 1.25, 2.5)) +
  aes(x_fct, mean_normal, fill = x_fct) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean_normal-(sd_normal), 
                    ymax = mean_normal+(sd_normal)),
                width = 0.2, linewidth = 1) +
  labs(x = "Behandlungsgruppen (X)", y = "Mittler Messwert (Y)",
       title = "Varianzheterogenität", subtitle = "Varianzen sind unterschiedlich")  +
  ylim(0, 8)

p1 + p2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-posthoc-var-homo-box
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Visueller  *[Zum Vergrößern anklicken]*"

p1 <- gg_template %+%
  tibble(x_fct = gl(3, 5, labels = c("A", "B", "C")),  
         y_val = c(0.25, 1, 1.5, 2, 2.75,
                   1.25, 2, 2.5, 3, 3.75,
                   3.75, 4.5, 5, 5.5, 6.25)) +
  aes(x_fct, y_val, fill = x_fct) +
  geom_boxplot(linewidth = 1) +
  labs(x = "Behandlungsgruppen (X)", y = "Mittler Messwert (Y)",
       title = "Varianzhomogenität", subtitle = "Varianzen sind gleich") +
  ylim(0, 8)

p2 <- gg_template %+%
  tibble(x_fct = gl(3, 5, labels = c("A", "B", "C")),  
         y_val = c(0.5, 1, 1.5, 2, 2.5,
                   0, 1, 2.5, 4, 6.5,
                   2, 3, 5, 6, 8)) +
  aes(x_fct, y_val, fill = x_fct) +
  geom_boxplot(linewidth = 1) +
  labs(x = "Behandlungsgruppen (X)", y = "Mittler Messwert (Y)",
       title = "Varianzheterogenität", subtitle = "Varianzen sind unterschiedlich")  +
  ylim(0, 8)

p1 + p2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

## `{ggplot}`
:::

## Der ANOVA Pfad mit Tukey HSD

Der Tukey HSD Test (abk. *HSD Test*) hat viele Namen. Im Englischen kennen wir den Tukey HSD Test auch als *Tukey's range test* oder aber als *Tukey's test*, *Tukey method*, *Tukey's honest significance test* oder eben *Tukey's HSD (honestly significant difference)* Test. Dabei steht die Abkürzung HDS für *honestly significant difference* (deu. *ehrlich signifikanter Unterschied*). Für mich etwas weit aus dem Fenster gelehnt, aber der Name sagt hier mal was auch wirklich gemacht wird. Im Prinzip stellen wir nur die Formel von den Student t-Test einmal um und benennen alles neu. Dann sieht man auch nicht gleich, was Sache ist und jeder denkt, es wäre was Neues. Wir werden hier aber mal den Tukey HSD Test zerforschen. Wir nutzen aber die ANOVA um einmal die Streuung und die Effekte zu berechnen. Daher nenne ich das ganze hier auch den ANOVA Pfad. Der Tukey HSD Test basiert eben mehr oder minder auf der Ausgabe einer ANOVA. Mehr Informationen gibt es auch im Tutorial [Post-Hoc Analysis with Tukey’s Test](https://rpubs.com/aaronsc32/post-hoc-analysis-tukey). Ach, der Tukey HSD Test ist schon etwas älter und kann nicht so viel wie neuere Implementierungen wie das R Paket `{emmeans}` und `{multcomp}`.

Varianzhomogenität

:   Es ist wichtig zu wissen, dass der Tukey HSD Test auf der ANOVA basiert und die ANOVA nimmt Varianzhomogenität an. Damit meine ich, dass alle Gruppen in der Behandlung die gleiche Varianz haben. Du kannst leider den Tukey HSD Test nur unter der Annahme von varianzhomogenität nutzen. Wenn das dir eine zu starke Annahme ist, dann nutze einfach das R Paket `{emmeans}`, wie ich es dir weiter unten im Kapitel vorstelle.

Adjustierung für multiple Vergleiche

:   Der Tukey HSD Test adjustiert für die $\alpha$-Inflation bei multiplen Vergleichen. Wir müssen da auch nichts weiter machen um die Adjustierung durchzuführe. Das macht die Funktion `TukeyHSD()` für uns automatisch. Auf der anderen Seite können wir die Adjustierung für multiple Vergleiche aber auch nicht ausschalten. Du erhälst *immer* adjustierte p-Werte aus einem Tukey HSD Test. Wenn du das nicht möchtest, dann nutze einfach das R Paket `{emmeans}`, welches du weiter unten findest.

Mögliche multiple Vergleiche

:   Wir können immer nur alle Gruppen mit allen anderen Gruppen vergleichen. Wir rechnen also einen *all pair* Vergleich. Wenn du zum Beispiel nur die Behandlungsgruppen zur Kontrolle vergleichen willst, aber nciht untereinander, dann ist das nicht mit dem Tukey HDS Test möglich. Dafür musst du dann das R Paket `{ememans}` oder für noch komplexere Gruppenvergleiche das R Paket `{multcomp}` nutzen.

Fallzahl in den einzelnen Behandlungsgruppen

:   Der Tukey HSD Test geht von einem balancierten Design aus. Daher brauchen wir in allen Behandlungsgruppen die gleiche Anzahl an Beobachtungen. Wenn wir kein balanciertes Design vorliegen haben, dann wird die Fallzahl mehr oder minder über die Gruppen gemittelt. Teilweise funktioniert dann auch der Tukey HSD Test nicht mehr richtig. Daher ist von der Nutzung es Tukey HSD Tests bei ungleich großen Gruppen abzuraten. Auch hier ist dann der Ausweg das R Paket `{emmeans}`, welches genau für den unblancierten Fall ursprünglich entworfen wurde.

Schauen wir uns nun einmal an, wie der Tukey HSD Test theoretisch funktioniert und wie die Implmentierugn in R dargestellt ist. Wir haben die Wahl zwischen der Funktion `TukeyHSD()` und der Funktion `HSD.test()` aus dem R Paket `{agricolae}`. Die Funktion `HSD.test()` liefert auch gleich das *Compact letter display* in der Ausgabe mit. Sonst sind die beiden Funktionen sehr ähnlich. Oft wird eben der Tukey HSD Test noch verwendet, weil er eben sehr alt ist und somit schon sehr lange verwendet wurde.

::::: panel-tabset
## Theoretisch

Zuerst einmal die Formel des Tukey HSD Test. Wir berechnen dabei asl statistische Maßzahl den HSD-Wert, der nichts anderes aussagt als der minimal Mittelwertsunterschied, den wir gegeben der Streuung und der Fallzahl in den Daten als signifikant nachweisen können. Sozusagen der minimalste mögliche signifikante Mittelwertsunterschied.

$$
HSD = q_{\alpha=5\%, k, n-k} \cdot \sqrt{\tfrac{MSE}{n}}
$$

mit

-   $HSD$, den zu berechnenden minimalst möglichen signifikanten Mittelwertsunterschied.
-   $q_{\alpha=5\%, k, n-k}$, den kritsichen Wert gegeben aus dem Signifikanzniveau $\alpha$ gleich 5% der Anzahl an zu vergleichenden Gruppen $k$ und einem Freiheitsgrad $n-k$.
-   $\sqrt{\tfrac{MSE}{n}}$, der Streuung in den Daten gewichtet für die Fallzahl $n$. Hier wird die Streuung über alle Gruppen hinweg berechnet.

Wir können uns das Ganze auch nochmal in der folgenden Tabelle als Vergleich zu dem Student t-Test anschauen. Hier dann erstmal noch die beiden Formeln.

$$
\begin{array}{c|c}
  HSD = q_{\alpha=5\%, k, n-k} \cdot \sqrt{\tfrac{MSE}{n}} & \bar{y}_1 - \bar{y}_2 =  T_{\alpha=5\%} \cdot s_p\sqrt{\tfrac{2}{n_g}}
\end{array}
$$

Ich habe dort einmal die statistischen Maßzahlen aus einem Tukey HDS Test den statistischen Maßzahlen eines Student t-Test in der folgenden Tabelle gegenüber gestellt. Du siehst, dass wir hier eigentlich nur eine Umstellung der t-Test Formel haben.

|                 | Tukey HSD Test           | Student t-Test             |
|-----------------|--------------------------|----------------------------|
| Effekt          | $HSD$                    | $\bar{y}_1 - \bar{y}_2$    |
| Streuung        | $\tfrac{MSE}{n}$         | $s_p\sqrt{\tfrac{2}{n_g}}$ |
| Kritischer Wert | $q_{\alpha=5\%, k, n-k}$ | $T_{\alpha=5\%}$           |

: Etwas wilder Vergleich vom Tukey HSD Test zum Student t-Test. Im Prinzip ist der Tukey HSD Test nur eine Umsstellung der Formel des Student t-Test. {#tbl-hds-ttest}

Um die Idee des Tukey HDS Test zusammenzufassen, setzen wir für $q_{\alpha=5\%, k, n-k}$ den Wert ein, den wir mindestens erreichen müssen um einen signifikanten Unterschied nachweisen zu können. Bei dem Student t-Test war es meist $T_{\alpha=5\%}$ gleich $1.96$, hier ist der Wert für $q_{\alpha=5\%, k, n-k}$ natürlich anders. Dann können wir den minimalen Mittelwertsunterschied mit $\bar{y}_1 - \bar{y}_2$ oder eben $HSD$ berechnen, denn wir mindestens erreichen müssen um einen signifikanten Unetrschied nachweisen zu können. Alle Mittelwertsdifferenzen größer als der $HDS$ Wert werden dann signifikant sein und alle Mittelwertsdifferenzen kleiner als der $HDS$ Wert nicht signifikant sein.

::: callout-note
## Entscheidung mit dem HDS Wert

Wenn eine Mittelwertsdifferenz $\bar{y}_i - \bar{y}_j$ eines Gruppenvergleiches *größer* ist als der HDS Wert dann wird die Nullhypothese (H$_0$) abgelehnt. Ist die Mittelwertsdifferenz $\bar{y}_i - \bar{y}_j$ eines Gruppenvergleiches ist als der HDS Wert dann wird die Nullhypothese (H$_0$) beibehalten.
:::

## Händisch

Im Folgenden wollen wir einmal den Tuley HSD Test nachvollziehen. Dafür hier nochmal die Formel, die wir dann mit den entsprechenden Werten ausfüllen müssen. Wir beginnen mit dem q-Wert und erhalten den MSE Wert aus einer ANOVA.

$$
HSD = q_{\alpha=5\%, k, n-k} \cdot \sqrt{\tfrac{MSE}{n}}
$$

Für die semi händische Berechnung des Tukey HSD Test brauchen wir erstmal die Werte für die gesamte Fallzahl in dem Datensatz $N$, dann noch die Anzahl an Behandlungsgruppen $k$ und abschließend die Fallzahl pro Gruppe $n$. Ich nutze hier dann den Datensatz `fac1_tbl` mit der Sprungweite von 21 Flöhen von drei Tierrassen mit jeweils sieben Beobachtungen pro Gruppe. Dann geben wir das Ganze einmal bei R ein.

```{r}
N <- 21
k <- 3
n <- 21 / 3
```

Die Funktion `qtukey()` gibt uns den q-Wert anhand des Signifikanzniveaus $1 - \alpha$ sowie der Anzahl an Gruppen $k$ und der dem Freiheitsgrad $N-k$ wieder.

```{r}
qtukey(p = 0.95, nmeans = k, df = N - k)
```

Dann brauchen wir noch den Wert für die Streuung $MSE$. Den MSE Wert könnten wir auch händisch berechnen, aber normalerweise nutzen wir auch die ANOVA um an den Wert zu gelangen. Daher hier einmal die ANOVA und wir lesen den Wert für MSE in der Ergebnistabelle ab.

```{r}
fac1_av <- aov(jump_length ~ animal, data = fac1_tbl)
summary(fac1_av)
```

Nun wissen wir den Wert für $MSE$ mit $3.14$ aus der Tabelle der einfaktoriellen ANOVA. Dann können wir auch schon den HSD Wert anhand der Formel berechnen in dem wir die Werte einsetzen.

```{r}
hsd <- 3.61 * sqrt(3.14 / 7)
hsd
```

Am Ende müssen wir dann die Mittelwertsdifferenzen unserer Tierarten mit dem HDS Wert vergleichen. Dafür ahbe ich einmal die folgende Tabelle aufgebaut. Wichtig ist hier, dass wir mit den Beträgen der Mittelwertsdifferenz rechnen, sonst macht der Vergleich zum HDS Wert keinen Sinn. Wir erhalten also zwei signifikante Vergleiche. Die Sprungweiten der Katzenflöhe unterscheiden sich von den Sprungweiten der Fuchs- und Hundeflöhe.

| Vergleich | Mittelwertsdifferenz | HDS Testentscheidung |
|----|----|----|
| cat-dog | $4.74 - 8.13 = -3.39$ | $\mid-3.39\mid\; \geq 2.42 \rightarrow \mbox{signifikant}$ |
| fox-dog | $9.16 - 8.13 = \phantom{-}1.03$ | $\mid1.03\mid\; \geq 2.42 \rightarrow \mbox{nicht signifikant}$ |
| fox-cat | $9.16 - 4.74 = \phantom{-}4.42$ | $\mid4.42\mid\; \geq 2.42 \rightarrow \mbox{signifikant}$ |

: Händische Testentscheidung anhand des berechneten HDS Wert und den Mittelwertsdifferenzen der drei Tierarten. Wenn eine Mittelwertsdifferenz größer ist als der HDS Wert, dann liegt ein signifikanter Unterschied vor. {#tbl-hds-ttest-händisch}

Am Ende willst du das natürlich nicht händische machen sondern wir nutzen die Funktionen in R um uns die Testentscheidung auch mit einem p-Wert berechnen zu lassen. Ganz wichtig hier nochmal, wir glauben daran, dass die Varianz in allen drei Tierarten gleich ist. Wir haben Varianzhomogenität vorliegen.

## `TukeyHSD()`

Die Standardfunktion für den Tukey HDS Test ist `TukeyHSD()`. Wir können den Tukey HSD Test mit nur einem Faktor oder zwei Faktoren rechnen. Ich stelle hier die einfaktorielle sowie zweifaktorielle Analyse einmal vor. Am Ende zeige ich dann nochmal, wie du das *Compact letter display* erhälst. Hier müssen wir noch ein zusätzliches Paket nutzen. Die Funktion `HSD.test()` aus dem Paket `{agricolae}`, die du im nächsten Tab findest, gibt dir sofort das *Compact letter display* wieder. Der Ablauf ist aber in beiden Fällen der gleiche. Wir rechnen erst eine ANOVA mit der Funktion `aov()` um dann den Tukey HSD Test zu rechnen.

### Einfaktorielle Analyse

Am Anfang rechnen wir erst eine einfaktorielle ANOVA mit der Funktion `aov()`. Wir erhalten dann alle notwendigen Informationen in dem Ausgabeobjekt für die Berechnung des Tukey HSD Test. Darüber hinaus können wir auch auch gleich schauen, ob unsere Bahendlung überhaupt einen signifkanten Einfluss auf unser Outcome der Sprunglänge hat.

```{r}
fac1_av <- aov(jump_length ~ animal, data = fac1_tbl)
summary(fac1_av)
```

An dem p-Wert sehen wir, dass wir einen signifikanten Effekt der Tierart `animal` auf die Sprunglänge der Flöhe vorliegen haben. Wir können jetzt einen Tukey HSD Test rechnen um rauszufinden welche der drei Tierarten sich unterscheiden. Wir erhalten dann als Ausgabe die Mittlwertsdifferenzen zusammen mit den 95% Konfidenzintervallen und den adjustierten p-Werten.

```{r}
tukey_fac1_obj <- TukeyHSD(fac1_av)
tukey_fac1_obj
```

Du erhälst immer adjustierte p-Werte aus einem Tukey HSD Test. Das muss dir klar sein. Die p-Werte kannst du dann mit dem Signifikanzniveau $\alpha$ von 5% vergleichen. Wir sehen dass sich die Sprungweiten der Katzenflöhe von den Sprungweiten der Fuchs- und Hundeflöhe signifikant unterscheiden.

Dann kannst du noch die Funktion `mulcompLetters()` aus dem R Paket `{mulcompView}` nutzen um dir das *Compact letter display* wiedergeben zu lassen. Das *Compact letter display* kannst du dann entsprechend zu deinen Barplots ergänzen.

```{r}
multcompLetters(extract_p(tukey_fac1_obj$animal))
```

Auch hier sei angemerkt, dass du dan schauen muss, ob das *Compact letter display* zu deinen Daten passt. Sind die Mittelwerte wirklich unterschiedlich? Kannst du die Unetrschiede in den Barplots erkennen? Wenn das der Fall ist, dann spricht nichts gegen die Verwendung des Tukey HSD Test.

### Zweifaktorielle Analyse

Jetzt können wir die Sache etwas kürzer machen, da wir auch in einem zweifaktoriellen Fall den gleichen Weg wie im einfaktoriellen Fall durchgehen. Wir rechnen erst eine ANOVA mit den beiden Faktoren und dem Interaktinsterm, dargestellt durch den Doppelpunkt zwischen den beiden Faktoren.

```{r}
fac2_av <- aov(jump_length ~ animal + site + animal:site, data = fac2_tbl)
summary(fac2_av)
```

In diesem Fall finden wir eine signifikante Interaktion. Daher verhalten sich die Tierarten `animal` in den beiden Messorten in dem Faktor `site` nicht gleich. Die Interaktion kanst du auch in der Visualisierung der Daten in der @fig-boxplot-emmeans-fac2 sehen. Für die Füchse ändert sich die Sprungweite von `city` zu `village`. Bei Hunden- und Katzenflöhen springen in der Tendenz Dorfflöhe weiter als Stadtflöhe. Wir nutzen jetzt das Modell einmal in der Funktion `TukeyHSD()` um uns einmal einen Tukey HSD TEst berechnen zu lassen.

```{r}
tukey_fac2_obj <- TukeyHSD(fac2_av)
tukey_fac2_obj
```

Wie du an der sehr langen Ausgabe sehen kannst, erhalten wir erstmal die Informationen zu der Tierart, dort sehen wir dann, dass sich alle drei Sprungweiten der Tierarten voneinander unterscheiden. Dann erhalten wir die Information über den Ort oder eben den zweiten Faktor. Am Ende nochmal sehr detailiert alle Interaktionen aufgeschlüsselt. Leider ist die Tabelle dann sehr schlecht zu lesen, aber hier siehst du dann welche Faktorkombination dann signifikant ist. Wenn du eine signifikante Interaktion vorliegen hast, dann kannst du keine *pauschale* Aussage über die Sprungweiten der Tierarten machen. Es kommt eben immer drauf an, welches Level du im zweiten Faktor betarchtest.

Am Ende wollen wir dann doch noch das *Compact letter display* haben. Ich wähle hier einmal die Gruppe der Tierarten aus. Du kannst das auch für die anderen Faktoren machen, aber hier einmal zur Demonstration. Wir sehen, dass sich alle Tierarten in der Sprungweiet unterscheiden, keine Tierart hat den gleichen Buchstaben.

```{r}
multcompLetters(extract_p(tukey_fac2_obj$animal))
```

Hier nochmal Achtung, die Interaktion wird natürlich nicht berücksichtigt. Im Zweifel dann doch lieber `{emmeans}` nutzen und nochmal bei mir nachfragen. Allgemeine Aussagen zur Interaktion kann ich immer schwer treffen, es hängt sehr von der wissenschaftlichen Fragestellung und den Daten ab.

## `HSD.test()`

::: callout-warning
## Achtung, bitte beachten!

Die Funktion `HSD.test()` kann nur ein einfaktorielles Modell rechnen und *ignoriert* weitere Faktoren oder Interaktionsterme im `aov()` Modell. Du erhälst zwar immer eine Ausgabe, aber nur als einfaktorielle Analyse. Unabhängig von dem Modell was du in die Funktion `HSD.test()` reinsteckst! Und ohne weitere Warnung.
:::

Eine zweite Variante den Tukey HSD Test in R durchzuführen ist die Funktion `HSD.test()` aus dem R Paket `{agricolae}`. Persönlich entwickle ich so langsam eine Aversion gegen das Paket, da ich selten eine so rundimentäre und lustlose Hilfe für die Funktion gesehen habe wie in `{agricolae}`. Prinzipiell haben wir die gleichen Möglichkeiten wie auch mit dem Tukey HSD Test für ein einfaktorielles Versuchsdesign. Wir nutzen auch erste eine ANOVA um uns alle wichtigen statistischen Maßzahlen berechnen zu lassen und dann können wir mit denen den Tukey HSD Test durchführen. Leider erhalten wir *keine* p-Werte. Was auch irgendwie irre ist. Dafür dann aber das *Compact letter display* ohne einen weiteren Schritt.

### Einfaktorielle Analyse

Am Anfang rechnen wir auch hier eine einfaktorielle ANOVA mit der Funktion `aov()`. Wir erhalten dann alle notwendigen Informationen in dem Ausgabeobjekt für die Berechnung des Tukey HSD Test. Darüber hinaus können wir auch auch gleich schauen, ob unsere Bahendlung überhaupt einen signifkanten Einfluss auf unser Outcome der Sprunglänge hat.

```{r}
fac1_av <- aov(jump_length ~ animal, data = fac1_tbl)
summary(fac1_av)
```

An dem p-Wert sehen wir, dass wir einen signifikanten Effekt der Tierart `animal` auf die Sprunglänge der Flöhe vorliegen haben. Wir können jetzt einen Tukey HSD Test rechnen um rauszufinden welche der drei Tierarten sich unterscheiden. Wir erhalten dann als Ausgabe die Mittlwerte ohne p-Werte und müssten uns sogar die Mittelwertsdifferenzen selber berechnen. Keine Ahnung was das soll. Dafür dann aber das *Compact letter display*, was ja auch irgendwie reicht.

```{r}
tukey_fac1_obj <- HSD.test(fac1_av, trt = 'animal')
tukey_fac1_obj
```

Wenn du keinen p-Werte haben möchtest sondern nur das *Compact letter display*, dann macht es dir die Funktion `HSD.test()` etwas leichter. Dann brauchst du dir nicht nochmal eine Funktion zusätzlich laden. Wenn du p-Werte brauchst, dann stehst du hier im Regen. Dann nutze bitte die Funktion `TukesHSD()` im vorherigen Tab.

### Zweifaktorielle Analyse

Eine zweifaktorielle Analyse ist in der Funktion `HSD.test()` nicht möglich. Ein zweifaktorielles Modell wird wie ein einfaktorielles Modell behandelt und damit der zweite Faktor sowie der Interaktionsterm von der Funktion `HSD.test()` ignoriert. Du erhälst keine Warnung sondern eben das Ergebnis einer einfaktoriellen Analyse wiedergeben. Ich bin immer noch sprachlos was das soll.
:::::

## Der effektive Pfad mit `{emmeans}`

Text

Varianzhomogenität oder Varianzheterogenität

:   Wir können in `{emmeans}` eine mögliche Varianzheterogenität modellieren, wenn wir das nicht tun, dann rechnet `{emmeans}` immer unter der Annahme von Varianzhomogenität. Wenn du nicht für die Varianzheterogenität adjustieren möchtest, dann rechnest du faktisch einen Tukey HSD Test. Der Tukey HSD Test rechnet *immer* mit Varianzhomogenität. In allen Beispielen hier, werde ich aber für Varianzheterogenität adjustieren. Dazu nutze ich dann die Option `vcov. = sandwich::vcovHAC` im `emmeans()` Funktionsaufruf. In dem R Paket `{sandwich}` gibt es eine riesige Anzahl an möglichen Funktionen um für Varianzheterogenität zu adjustieren. Wir nutzen hier die Option `vcovHAC`, die in vielen Fällen vollkommen ausrichend ist.

Adjustierung für multiple Vergleiche

:   Das Paket `{emmeans}` kann sehr einfach für die Adjustierung von multiplen Vergleichen angepasst werden um adjustierte p-Werte zu erhalten. In der Standardeinstellung nutzt `{emmeans}` die Quartile aus einem Tukey HSD Test und somit ist `{emmeans}` gar nicht so weit weg von dem Tukey HSD Test. Ich stelle aber meistens die Adjustierung auf Bonferroniadjustierung mit der Option `adjust = "bonferroni"`, da diese Adjustierung etwas eingängiger ist. Das bleibt aber dir überlassen, ob du überhaupt eine Adustierung wählen willst. Mit der Option `adjust = "none"` stellst du die Adjustierung für multiple Vergleiche aus. Du erhälst die rohen p-Werte.

Mögliche multiple Vergleiche

:   Wir können auch eine andere Kontrolle wählen `contrast(method = "trt.vs.ctrl", ref = "fox")`

Fallzahl in den einzelnen Behandlungsgruppen

:   text

### Einfaktorielle Analyse

```{r}
fac1_fit <- lm(jump_length ~ animal, data = fac1_tbl)
```

```{r}
emm_fac1_obj <- fac1_fit |>  
  emmeans(~ animal, vcov. = sandwich::vcovHAC) 

emm_fac1_obj
```

::: panel-tabset
## p-Werte

```{r}
comp_fac1_obj <- emm_fac1_obj |> 
  contrast(method = "pairwise", adjust = "bonferroni") 

comp_fac1_obj
```

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: "Visualisierung der Ergebnisse im Pairwise P-value plot."
#| label: fig-emmeans-3

emm_fac1_obj |> 
  pwpp(adjust = "bonferroni") +
  theme_minimal()
```

```{r}
emm_fac1_obj |> 
  pwpm(adjust = "bonferroni")
```

## *Compact Letter Display*

```{r}
emm_fac1_obj |> 
  contrast(method = "pairwise") |>  
  cld(Letters = letters, adjust = "bonferroni")
```

## 95% Konfidenzintervall

```{r}
#| message: false
#| warning: false
res_fac1_ci_obj <- emm_fac1_obj |> 
  contrast(method = "pairwise") |> 
  tidy(conf.int = TRUE) |> 
  select(contrast, estimate, adj.p.value, conf.low, conf.high) |> 
  mutate(across(where(is.numeric), round, 4))

res_fac1_ci_obj
```

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: Die 95% Konfidenzintervalle für den *allpair*-Vergleich des simplen Datensatzes.
#| label: fig-emmeans-1

  ggplot(res_fac1_ci_obj, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +
    geom_hline(yintercept=0, linetype="11", colour="grey60") +
    geom_errorbar(width=0.1) + 
    geom_point() +
    coord_flip() +
    theme_classic()
```
:::

### Zweifaktorielle Analyse

Modell

$$
y \sim f_1 + f_2 + f_1 \times f_2
$$

```{r}
fac2_fit <- lm(jump_length ~ animal + site + animal:site, data = fac2_tbl)
```

Wir müssen uns jetzt entscheiden wie wir die beiden Faktoren $f_1$ mit `animal` und $f_2$ mit `site` auswerten wollen. Wir können den Faktor `animal` getrennt für jedes Level des Faktors `site` vergleichen oder wir vergleichen alle Faktorkombinationen gemeinsam.

::: panel-tabset
## Getrennt für $f_1$ und $f_2$ mit $\boxed{\sim f_1 | f_2}$

```{r}
emm_fac2_separate_obj <- fac2_fit |> 
  emmeans(~ animal | site, vcov. = sandwich::vcovHAC) 

emm_fac2_separate_obj
```

## Gemeinsam für $f_1$ und $f_2$ mit $\boxed{\sim f_1 * f_2}$

```{r}
emm_fac2_combinded_obj <- fac2_fit |> 
  emmeans(~ animal * site, vcov. = sandwich::vcovHAC) 

emm_fac2_combinded_obj
```
:::

::: panel-tabset
## p-Werte

```{r}
comp_fac2_separate_obj <- emm_fac2_separate_obj |> 
  contrast(method = "pairwise", adjust = "bonferroni")

comp_fac2_separate_obj
```

```{r}
comp_fac2_separate_obj |> 
  summary() |> 
  as_tibble() |> 
  select(contrast, site, p.value) |> 
  mutate(p.value = format.pval(p.value, eps = 0.001, digits = 2))
```

Hier müssen wir dann nochmal emmeans aufrufen! Wir machen das hier nochmal für getrennt.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 8
#| fig-cap: "Visualisierung der Ergebnisse im Pairwise P-value plot."
#| label: fig-emmeans-foo-2


emm_fac2_separate_obj |> 
  pwpp(adjust = "bonferroni") +
  theme_minimal()

```

```{r}
emm_fac2_separate_obj |>   
  pwpm(adjust = "bonferroni")
```

## *Compact Letter Display*

```{r}
emm_fac2_separate_obj |> 
  contrast(method = "pairwise") |>  
  cld(Letters = letters, adjust = "bonferroni")
```

## 95% Konfidenzintervall

```{r}
comp_fac2_ci_obj <- emm_fac2_separate_obj |> 
  contrast(method = "pairwise") |> 
  confint(adjust = "bonferroni") |> 
  as_tibble() |> 
  select(contrast, site, estimate, conf.low = lower.CL, conf.high = upper.CL) 

comp_fac2_ci_obj 
```

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: Die 95% Konfidenzintervalle für den *allpair*-Vergleich des Models mit Interaktionseffekt.
#| label: fig-emmeans-2

ggplot(comp_fac2_ci_obj, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high,
                             color = site, group = site)) +
  geom_hline(yintercept=0, linetype="11", colour="grey60") +
  geom_errorbar(width=0.1, position = position_dodge(0.5)) + 
  geom_point(position = position_dodge(0.5)) +
  scale_color_okabeito() +
  coord_flip() +
  theme_classic()
```
:::

## Weitere Pfade

### Paarweise Tests

```{r}
#| warning: false
pairwise.t.test(fac1_tbl$jump_length, fac1_tbl$animal,
                p.adjust.method = "bonferroni",
                pool.sd = FALSE) 
```

```{r}
#| warning: false

pairwise.wilcox.test(fac1_tbl$jump_length, fac1_tbl$animal,
                     p.adjust.method = "bonferroni")
```

### `{multcomp}`

::: panel-tabset
## p-Werte

## *Compact letter display*

## 95% Konfidenzintervall
:::

### `{nparcomp}`

::: panel-tabset
## p-Werte

## *Compact letter display*

## 95% Konfidenzintervall
:::

### Games Howell Test

::: panel-tabset
## p-Werte

## *Compact letter display*

## 95% Konfidenzintervall
:::

## Weitere Dinge von Interesse

## Re-engineering *Compact letter display*

In dem kurzen Kapitel zu [Re-engineering CLDs](https://cran.r-project.org/web/packages/emmeans/vignettes/re-engineering-clds.html) in der Vingette des R Pakets `{emmeans}` geht es darum, wie das *compact letter display* auch anders gebaut werden könnte. Nämlich einmal als wirkliches Anzeigen von Gleichheit über die Option `delta` oder aber über das Anzeigen von Signifikanz über die Option `signif`. Damit haben dann auch wirklich die Information, die wir dann wollen. Also eigentlich was Schönes. Wie machen wir das nun?

::: panel-tabset
## Delta Methode

Wenn wir das *compact letter display* in dem Sinne der Gleichheit der Behandlungen interpretieren wollen, also das der gleiche Buchstabe bedeutet, dass sich die Behandlungen nicht unterscheiden, dann müssen wir ein `delta` setzen in deren Bandbreite oder Intervall die Behandlungen gleich sind. Ich habe hier mal ein `delta` von 4cm gewählt und wir adjustieren bei einem Test auf Gleichheit nicht.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |>
  emmeans(~ animal) |>
  cld(Letters = letters, adjust = "none", delta = 4)
```

Wie wir jetzt sehen, bedeuten gleiche Buchstaben, dass die Behandlungen gleich sind. In dem Sinne gleich sind, dass die Behandlungen im Mittel nicht weiter als der Wert in `delta` auseinanderliegen. Wie du jetzt das `delta` bestimmst ist eine biologische und keine statistische Frage.

## Unterschied anzeigen

Können wir uns auch signifikante Unterschiede anzeigen lassen? Ja, können wir auch, aber das ist meiner Meinung nach die schlechtere der beiden Anpassungen. Wir haben ja im Kopf, dass das *compact letter display* eben mit gleichen Buchstaben das Gleiche anzeigt. Jetzt würden wir diese Eigenschaften zu Unterschied ändern. Schauen wir uns das einmal an einem kleineren Datensatz einmal an.

Dann können wir uns hier einmal das Problem mit den Buchstaben anschauen. Wir kriegen jetzt mit der Option `signif = TRUE` wiedergeben `Estimates sharing the same symbol are significantly different` und das ist irgendwie auch wirr, dass *gleiche* Buchstaben einen Unterschied darstellen. Das *compact letter display* wird eben als Gleichheit gelesen, so dass wir hier mehr verwirrt werden als es hilft.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  emmeans(~ animal) |>
  cld(Letters = letters, adjust = "bonferroni", signif = TRUE)
```

Deshalb würde ich auf die Buchstaben verzichten und die Zahlen angeben, damit hier nicht noch mehr Verwirrung aufkommt. Wir nehmen also die Option für die Buchstaben einmal aus dem `cld()` Aufruf raus. Dann haben wir Zahlen als Gruppenzuweisung, was schon mal was anderes ist als die Buchstaben aus dem *compact letter display*.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  emmeans(~ animal) |>
  cld(adjust = "bonferroni", signif = TRUE)
```

Innerhalb des selben Konzepts dann zwei Arten von Interpretation des *compact letter display* zu haben, ist dann auch nicht zielführend. Den auch die *gleichen* Zahlen bedeuten jetzt einen Unterschied. Irgendwie mag ich persönlich nicht diese sehr verdrehte Interpretation nicht. Deshalb lieber ein `delta` einführen und auf echte Gleichheit testen.
:::

### Modellierung von Varianzheterogenität {#sec-posthoc-var-heterogen}

:::: panel-tabset
## Generalized Least Squares

Neben dem Games-Howell-Test gibt es auch die Möglichkeit *Generalized Least Squares* zu nutzen. Hier haben wir dann auch die Möglichkeit mehrfaktorielle Modelle zu schätzen und dann auch wieder `emmeans` zu nutzen. Das ist natürlich super, weil wir dann wieder in dem `emmeans` Framework sind und alle Funktionen von oben nutzen können. Deshalb hier auch nur die Modellanpassung, den Rest kopierst du dir dann von oben dazu.

Die Funktion `gls()` aus dem R Paket `{nlme}` passt ein lineares Modell unter Verwendung der verallgemeinerten kleinsten Quadrate an. Die Fehler dürfen dabei aber korreliert oder aber ungleiche Varianzen haben. Damit haben wir ein Modell, was wir nutzen können, wenn wir Varianzheterogenität vorliegen haben. Hier einmal das simple Beispiel für die Tierarten. Wir nehmen wieder die ganz normale Formelschreiweise. Wir können jetzt aber über die Option `weights =` angeben, wie wir die Varianz modellieren wollen. Die Schreibweise mag etwas ungewohnt sein, aber es gibt wirklich viele Arten die Varainz zu modellieren. Hier machen wir uns es einfach und nutzen die Helferfunktion `varIdent` und modellieren dann für jedes Tier eine eigene Gruppenvarianz.

```{r}
gls_fac1_fit <- gls(jump_length ~ animal, 
                    weights = varIdent(form =  ~ 1 | animal), 
                    data = fac1_tbl)
```

Dann können wir die Modellanpasssung auch schon in `emmeans()` weiterleiten und schauen uns mal das Ergebnis gleich an. Wir achten jetzt auf die Spalte `SE`, die uns ja den Fehler der Mittelwerte für jede Gruppe wiedergibt.

```{r}
gls_fac1_fit |> 
  emmeans(~ animal)
```

Wir sehen, dass wir für jedes Tier eine eigene Varianz über den Standardfehler `SE` geschätzt haben. Das war es ja auch was wir wollten. Bis hierhin wäre es auch mit dem Games-Howell-Test gegangen. Was ist aber, wenn wir ein zweifaktorielles design mit Interaktion schätzen wollen? Das können wir analog wie eben machen. Wir erweitern einfach das Modell um die Terme `site` für den zweiten Faktor und den Interaktionsterm `animal:site`.

```{r}
gls_fac2_fit <- gls(jump_length ~ animal + site + animal:site, 
                    weights = varIdent(form =  ~ 1 | animal), 
                    data = fac2_tbl)
```

Dann können wir uns wieder die multiplen Vergleiche getrennt für die Interaktionsterme wiedergeben lassen. Blöderweise haben jetzt alle Messorte `site` die gleiche Varianz für jede Tierart, aber auch da können wir noch ran.

```{r}
gls_fac2_fit |> 
  emmeans(~ animal | site)
```

Die eigentliche Stärke von `gls()` kommt eigentlich erst zu tragen, wenn wir auch noch erlauben, dass wir die Varianz *über alle* Tierarten, Messsorte und Interaktionen variieren kann. Das machen wir, in dem wir einfach `animal*site` zu der `varIdent()` Funktion ergänzen.

```{r}
gls_fac2_fit <- gls(jump_length ~ animal + site + animal:site, 
                    weights = varIdent(form =  ~ 1 | animal*site), 
                    data = fac2_tbl)
```

Dann noch schnell in `emmeans()` gesteckt und sich das Ergebnis angeschaut.

```{r}
gls_fac2_fit |> 
  emmeans(~ animal | site)
```

Wie du jetzt siehst schätzen wir die Varianz für jede Tierart und jeden Messort separat. Wir haben also wirklich jede Varianz einzeln zugeordnet. Die Frage ist immer, ob das notwendig ist, denn wir brauchen auch eine gewisse Fallzahl, damit die Modelle funktionieren. Aber das kommt jetzt sehr auf deine Fragestellung an und müssten wir nochmal konkret besprechen.

## Robuste Schätzung von Standardfehlern

Wir immer gibt es noch eine Möglichkeit die Varianzheterogenität zu behandeln. Wir nutzen jetzt hier einmal die Funktionen aus dem R Paket `{sandwich}`, die es uns ermöglichen Varianzheterogenität (eng. *heteroskedasticity*) zu modellieren. Es ist eigentlich super einfach, wir müssen als erstes wieder unser Modell anpassen. Hier einmal mit einer simplen linearen Regression.

```{r}
lm_fac1_fit <- lm(jump_length ~ animal, data = fac1_tbl)
```

Dann können wir auch schon für einen Gruppenvergleich direkt in der Funktion `emmeans()` für die Varianzheterogenität adjustieren. Es gibt verschiedene mögliche Sandwich-Schätzer, aber wir nehmen jetzt mal einen der häufigsten mit `vcovHC`. Wie immer gilt, es gibt ja nach Datenlage bessere und schlechtere Schätzer. Wir laden jetzt nicht das ganze Paket, sondern nur die Funktion mit `sandwich::vcovHAC`. Achtung, hinter der Option `vcov.` ist ein *Punkt*. Ohne den Aufruf `vcov. =` funktioniert die Funktion dann nicht.

```{r}
em_obj <- lm_fac1_fit |> 
  emmeans(~ animal, method = "pairwise", vcov. = sandwich::vcovHAC)
em_obj
```

Wir du siehst, die Standardfehler sind jetzt nicht mehr über alle Gruppen gleich. Dann können wir uns auch die paarweisen Vergleiche ausgeben lassen.

```{r}
contr_obj <- em_obj |> 
  contrast(method = "pairwise", adjust = "none")
```

Oder aber wir lassen uns das *compact letter display* wiedergeben.

```{r}
cld_obj <- em_obj |>
  cld(Letters = letters, adjust = "none")
```

::: {.callout-tip collapse="true"}
## Exkurs: Robuste Schätzung von Standardfehlern, Konfidenzintervallen und p-Werten

Wenn du noch etwas weiter gehen möchtest, dann kannst du dir noch die Hilfeseite von dem R Paket `{performance}` [Robust Estimation of Standard Errors, Confidence Intervals, and p-values](https://easystats.github.io/parameters/articles/model_parameters_robust.html?q=Heteroskedasticity#robust-covariance-matrix-estimation-from-model-parameters) anschauen. Die Idee ist hier, dass wir die Varianz/Kovarianz robuster daher mit der Berücksichtigung von Varianzheterogenität (eng. *heteroskedasticity*) schätzen.
:::
::::

## Referenzen {.unnumbered}
