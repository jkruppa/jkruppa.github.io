# Einführung {#sec-intro}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

[**Spoiler** Das wichtigste Lernziel ist, das du deine Bachelorarbeit selsbtständig in R auswerten und die Ergebnisse interpretieren kannst.]{.aside}

In diesem Kapitel nenne ich die wichtigsten Lernziele, die nach dem Lesen des Skriptes im Rahmen deiner Lehrveranstaltung von dir erreicht worden sein sollten. Je nach besuchten Kurs kann natürlich nicht *alles* geschafft worden sein. Viele Kapitel haben noch eine Abschnitt in dem du mehr über die Klausur erfährst. So sehe diese Übersicht als Einführung für das was später an Lehrinhalten kommt. Wenn du die Lernziele hier verstehst, dann hast du eine gute und solide Grundlage in Statistik und Bio Data Science. Damit solltest du dann auch gut durch deine Bachelorarbeit kommen.

```{r}
#| warning: false
#| echo: false

pacman::p_load(tidyverse, readxl, knitr, kableExtra, ggfortify)
data_tbl <- read_excel("data/flea_dog_cat.xlsx")

```

## Ein Wort der Warnung... {.unnumbered}

Wenn du dieses Bild eines niedergeschlagenen *Engels der Statistik* siehst...

![](images/angel_01.png){fig-align="center" width="30%"}

... dann bedeutet der niedergeschlagene Engel der Statistik:

1)  Wir opfern Genauigkeit für Anwendbarkeit. Ja, manchmal ist es eben statstisch nicht richtig was hier steht, aber aus Gründen der Anwendung fahren wir mal über den Engel drüber. *Schade*.
2)  Wir sind hier Anfänger und Anwender. Später kannst du noch tiefer ins Detail gehen. Hier wollen wir die Grundlagen lernen. Das hat dann einen Preis an *Richtigkeit*.
3)  Wir wollen fertig werden. Durch geschicktes Manövrieren können wir an einen Punkt kommen, wo kein statistischer Test mehr passt. Das wollen wir nicht. Deshalb zahlen wir hier auch einen Preis. Passt aber.

Deshalb konzentrieren wir uns auf einige wichtige Lernziele, die wir jetzt einmal nacheinander durchgehen.

## Lernziel 1: Eine explorative Datananalyse durchführen

Gleich zu Beginn R Code zu zeigen und eine entsprechende Abbildung ist vielleicht ungewöhnlich, aber wir wollen zu dieser @fig-boxplot-preface hin. In @fig-boxplot-preface siehst du einen Boxplot. Und wie wir aus den Daten `flea_dog_cat.xlsx` einen Boxplot erstellen, das soll uns in den nächsten Kapitel beschäftigen. Dafür müssen wir nämlich eine Menge in dem Codeblock verstehen und dann auch Anwenden können. Und natürlich lernen was eigentlich ein Boxplot ist und was in einem Boxplot eigentlich dargestellt ist.

```{r}
#| echo: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-boxplot-preface


## Einlesen von Daten aus Excel
data_tbl <- read_excel("data/flea_dog_cat.xlsx")

## Umformen der <chr> Spalte in einen Factor <fct>
data_tbl <- data_tbl %>% 
  mutate(animal = as_factor(animal))

## Auswählen der wichtigen Spalten für den anschließenden Boxplot
data_tbl <- data_tbl %>% 
  select(animal, jump_length) 

## Generieren des Boxplots in ggplot()
ggplot(data_tbl, aes(x = animal, y = jump_length, fill = animal)) +
  geom_boxplot() +
  geom_jitter() +
  labs(x = "Tierart", y = "Sprungweite in [cm]", fill = "Tierart") +
  scale_x_discrete(labels = c("Hund", "Katze")) +
  theme_bw()

```

Hier ist der Codeblock der in R die @fig-boxplot-preface erstellt.

```{r}
#| echo: true 
#| eval: false  

## Einlesen von Daten aus Excel
data_tbl <- read_excel("data/flea_dog_cat.xlsx")

## Umformen der <chr> Spalte in einen Factor <fct>
data_tbl <- data_tbl %>% 
  mutate(animal = as_factor(animal))

## Auswählen der wichtigen Spalten für den Boxplot
data_tbl <- data_tbl %>% 
  select(animal, jump_length) 

## Generieren des Boxplots in ggplot()
ggplot(data_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) +
  geom_boxplot() +
  geom_jitter() +
  labs(x = "Tierart", y = "Sprungweite in [cm]", 
       fill = "Tierart") +
  scale_x_discrete(labels = c("Hund", "Katze")) +
  theme_bw()

```

Wir müssen nun folgende Dinge lernen um den Codeblock zu verstehen:

-   Wir müssen das Datenbeispiel verstehen. Was sind das eigentlich für Daten, die wir da abbilden? Was sind überhaupt Daten im Sinne der Statistik bzw. für R.
-   Wir müssen den R Code verstehen. Von einzelnen wichtigen Operatoren wie `->` und `%\>%` zu dem den Unterschieden von Worten und Objekten.
-   Wie kriegen wir Daten aus Excel in R hinein? Wir können die Daten ja nicht einfach in R eintragen sondern haben die Daten ja meist in einer (Excel) Datei wie `flea_dog_cat.xlsx`.
-   Was ist eigentlich ein Boxplot und welche statistischen Maßzahlen werden hier eigentlich abgebildet?
-   Wie funktioniert eigentlich die Funktionalen `ggplot()` mit der wir den Boxplot erstellt haben?

All diese Fragen und weitere Fragen, die sich diesen Fragen anschließen, wollen wir uns in den nächsten Kapitel anschauen. Leider kann ich hier nur *linear* schreiben. Deshalb musst du eventuell mal ein Kapitel wiederholen oder etwas quer lesen. Du kannst dir ja auch nicht immer alles auf einmal merken.

## Lernziel 2: RStudio und R

::: callout-tip
## Was ist eigentlich RStudio und woher kriege ich das?

Du findest auf YouTube [Einführung in R - Teil 01 - Installation von RStudio und R](https://youtu.be/krF7TJVb-UA) als Video. Ich gehe in dem Video einmal alle wichtigen Schritte durch und so kannst du dir Rstudio und R installieren.
:::

Um Data Science durchführen zu können musst du etwas Programmieren können. Wir programmieren in R und nutzen die Software um Abbildungen zu erstellen und Analysen zu rechnen.

Wir arbeiten in R und nutzen dafür das RStudio. Führe einfach folgende Schritte aus um erst R zu installieren und dann das RStudio.

1.  R installieren unter <https://cran.rstudio.com/>
2.  RStudio installieren unter <https://www.rstudio.com/products/rstudio/download/#download>

Bitte die Reihenfolge beachten. Beide Schritte kannst du dir auch nochmals im Video anschauen oder aber du kommst in das R Tutorium was regelmäßig an der Hochschule Osnabrück von mir angeboten wird. Die Termine findest du im @sec-r-tutorium.

## Lernziel 3: Falsifikationsprinzip

::: callout-tip
## Grundlagen der Wissenschaft und Falsifikationsprinzip

Du findest auf YouTube [Grundlagen der Wissenschaft und Falsifikationsprinzip](https://youtu.be/h45ftLNsspM) als Video Reihe.
:::

Wie funktioniert ein *statistischer* Versuch? Ich könnte auch wissenschaftliches Experiment schreiben, aber ein wissenschaftliches Experiment ist sehr abstrakt. Wir wollen ja einen Versuch durchführen und danach - ja was eigentlich? Was wollen wir nach dem Versuch haben? Meistens eine neue Erkenntnis. Um diese Erkenntnis zu validieren oder aber abzusichern nutzen wir Statistik. Dazu musst du noch wissen, dass wir eine spezielle Form der Statistik nutzen: die *frequentistische Statistik*.

[Eine **biologische Wiederholung** beinhaltet ein neues Tier, Pflanze oder Mensch. Eine **technische** Wiederholung ist die gleiche Messung an dem gleichen Tier, Pflanze oder Mensch.]{.aside}

[Wir nennen das **Outcome** auch **Endpunkt**, **Response** oder kurz $y$.]{.aside}

Die *frequentistische Statistik* basiert - wie der Name andeutet - auf Wiederholungen in einem Versuch. Daher der Name frequentistisch. Also eine Frequenz von Beobachtungen. Ist ein wenig gewollt, aber daran gewöhnen wir uns schon mal. Konkret, ein Experiment welches wir frequentistisch Auswerten wollen besteht immer aus biologischen Wiederholungen. Wir müssen also ein Experiment planen in dem wir wiederholt ein Outcome an vielen Tieren, Pflanzen oder Menschen messen. Auf das Outcome gehen wir noch später ein. Im Weiteren konzentrieren wir uns hier auf die *parametrische* Statistik. Die parametrische Statistik beschäftigt sich mit Parametern von Verteilungen.

::: callout-note
## Wie gehen wir nun vor, wenn wir ein Experiment durchführen wollen?

1)  Wir müssen auf jeden Fall wiederholt ein Outcome an verschiedenen Tieren, Pflanzen oder Menschen messen.
2)  Wir überlegen uns aus welcher Verteilungsfamilie unser Outcome stammt, damit wir dann die entsprechende Verfahren zur Analyse nehmen können.
:::

Wenn wir nun ein Experiment durchführen dann erheben wir einmalig Daten $D_1$. Wir könnten das Experiment wiederholen und erneut Daten $D_2$ erheben. Wir können das Experiment $j$-mal wiederholen und haben dann Daten von $D_1,..., D_j$. Dennoch werden wir nie *alle* Daten erheben können, die mit einem Experiment verbunden sind.

[**Strukturgleichkeit** erreichen wir durch **Randomisierung**.]{.aside}

Nehmen wir das Beispiel, dass wir die Sprungweite von Hunde- und Katzenflöhen vergleichen wollen. Wir können nicht *alle* Hunde- und Katzenflöhe messen. Wir können nur eine Stichprobe an Daten $D_1$ erheben. Über diese Daten $D_1$ können wir dann später durch statistische Algorithmen eine Aussage treffen. Wichtig ist hier sich zu merken, dass wir eine Grundgesamtheit haben aus der wir eine Stichprobe ziehen. Wir müssen darauf achten, dass die Stichprobe *repräsentativ* ist und damit *strukturgleich* zur Grundgesamtheit ist. Die Strukturgleichkeit erreichen wir durch Randomisierung. Wir veranschaulichen diesen Zusammenhang in @fig-grundgesamtheit-schema. Ein Rückschluß von der Stichprobe ist nur möglich, wenn die Stichprobe die Grundgesamtheit repräsentiert. Auch eine Randomisierung mag dieses Ziel nicht immer erreichen. Im Beispiel der Hundeflöhe könnte wir eine Art an Flöhen übersehen und diese Flohart nicht mit in die Stichprobe aufnehmen. Ein Rückschluß auf diese Flohart wäre dann mit unserem Experiment nicht möglich.

![Abbildung über die Grundgesamtheit und die Stichprobe(n) $D_1$ bis $D_j$. Durch Randomisierung wird Sturkturgleichheit erreicht, die dann einen Rückschluß von der Stichprobe auf die Grundgesamtheit erlaubt. Jede Stichprobe ist anders und nicht jede Randomisierung ist erfolgreich was die Strukturgleicheit betrifft.](images/preface-grundgesamtheit.png){#fig-grundgesamtheit-schema fig-align="center" width="80%"}

@tbl-grundgesamtheit-stichprobe zeigt nochmal die Zusammenfassung von der Grundgesamtheit un der Stichprobe im Vergleich. Wichtig ist zu merken, dass wir mit unserem kleinen Experiment Daten $D$ generieren mit denen wir einen Rückschluß und somit eine Verallgemeinerung erreichen wollen.

| Grundgesamtheit                                           | Stichprobe                                           |
|-----------------------------------------------------------|------------------------------------------------------|
| ... $n$ ist riesig bis unfassbar.                         | ... $n$ von $D$ ist klein.                           |
| ... der Mittelwert wird mit $\mu_y$ beschrieben.          | ... der Mittelwert wird mit $\bar{y}$ beschrieben.   |
| ... die Varianz wird mit $\sigma^2$ beschrieben.          | ... die Varianz wird mit $s^2$ beschrieben.          |
| ... die Standardabweichung wird mit $\sigma$ beschrieben. | ... die Standardabweichung wird mit $s$ beschrieben. |

: Vergleich von Grundgesamtheit und Stichprobe. {#tbl-grundgesamtheit-stichprobe}

In @tbl-experimental-hurlbert

|     | Quelle der Verwirrung                                                     | Merkmal des experimentellen Designs um die Verwirrung zu reduziert oder aufzulösen                                                                |
|-----|---------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|
| 1\. | Zeitliche Veränderung                                                     | Kontrollgruppe                                                                                                                                    |
| 2\. | Artefakte in der Behandlung                                               | Kontrollgruppe                                                                                                                                    |
| 3\. | Voreingenommenheit des Forschenden (Bias)                                 | Randomisierte Zuordnung der Versuchseinheiten zu den Behandlungen; generelle Randomisierung bei allen möglichen Prozessen; Verblindete Prozeduren |
| 4\. | Vom Forschenden induzierte Variabilität (zufälliger Fehler)               | Wiederholungen der Behandlungen (und Kontrolle)                                                                                                   |
| 5\. | Anfängliche oder beinhaltende Variabilität zwischen den Versuchseinheiten | Wiederholungen der Behandlungen (und Kontrolle); Durchmischen der Behandlungen; Begleitbeobachtungen (Positive Kontrolle)                         |
| 6\. | Nicht-dämonische Einflüsse                                                | Wiederholung und Durchmischung der Behandlungen (und Kontrolle)                                                                                   |
| 7\. | Dämonische Eingriffe                                                      | Ewige Wachsamkeit; Geisteraustreibung; Menschenopfer                                                                                              |

: @dormann2013parametrische und @hurlbert1984pseudoreplication und @feynman1998cargo {#tbl-experimental-hurlbert}

## Referenzen {.unnumbered}
