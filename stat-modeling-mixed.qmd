```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, simstudy, writexl)
```

# Lineare gemischte Modelle {#sec-mixed}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-mixed.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Wer die Arbeit kennt und sich nicht drückt, der ist verrückt." --- Tick, Trick und Track*

::: callout-tip
## Einführung in die linearen gemischten Modelle per Video

Du findest auf YouTube [Lineare gemischte Modelle](https://youtu.be/54ba9cn3MeY) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

In diesem Kapitel vollen wir die Grundzüge der lineare gemischten Modell (eng. *linear mixed models*, abk. *lmm*) zu versuchen zu verstehen. Wir immer, es gibt dazu auch hervorragende Literatur wie das sehr ausführliche Buch von @zuur2009mixed. Fangen wir also einmal an zu verstehen, wie eigentlich ein Experiment aussehen muss, damit wir ein lineares gemischtes Modell rechnen wollen. Wir haben häufig in den Agarwissenschaften Faktoren als unser $x$ vorliegen. Für das $y$ können aber jeden Messwert abbilden. Dafür gibt es dann die Funktion `glmer()`, die das Äquivalent zu der Funktion `glm()` ist. Wir haben also folgendes, mehrfaktorielles Modell vorliegen.

$$
y \sim f_1 + f_2 + f_3 + f_4
$$

Und eigentlich haben wir ja gar nicht vier *gleichwertige* Faktoren vorliegen, sondern meistens unsere Behandlungsfaktor $f_1$ und $f_2$ an dem wir interessiert sind und dann noch bis zu zwei weitere Faktoren $f_3$ und $f_4$, die eine weitere Gruppierung repräsentieren. Wir können auch noch mehr Faktoren vorliegen haben, aber ich empfehle ein Design immer auf maximal vier Faktoren zu begrenzen. Unsere beiden Faktoren $f_3$ und $f_4$ beschreiben jetzt aber nicht noch mehr Behandlungen sondern stellen ein Feld, einen Block oder aber einen Stall dar. Wir haben es also mit Faktoren für eine "Position" zu tun. Die Position kann auch eine zeitliche Komponente sein. Deshalb schreiben wir etwas allgemeiner für die Faktoren $f_3$ und $f_4$ dann als Blockfaktor $b_1$ und $b_2$. Wie schon erwähnt es handelt sich nicht ausschließlich um Blöcke, es können auch andere Positionen in Raum und Zeit sein. Es geht immer mehr und manchmal braucht man auch mehr Faktoren, aber in unserem Kontext hier würde ich anraten sich auf eher auf drei Faktoren zu begrenzen. Also entweder zwei Behandlungsfaktoren und ein Positionsfaktor oder aber ein Behandlungsfaktor und zwei Positionsfaktoren. Damit können wir wie folgt unser Modell schreiben.

$$
y \sim f_1 + f_2 + b_1 + b_2
$$

Als wäre das nicht kompliziert genug, haben wir meistens auch noch verschachtelte (eng. *nested*) Daten vorliegen. Damit meine ich, dass wir den Faktor $b_1$ in jedem Level des Faktors $b_2$ vorliegen haben. Wir können eben verschiedene Standorte als Faktor $b_2$ betrachten und an jedem der Standorte haben wir Blöcke $b_1$ vorliegen. Mehr dazu findest du dann auch in dem Kapitel [Versuchsplanung in R](#sec-experimental-design-r) und gleich nochmal weiter unten im Text.

Was ist nun das Besondere an einem linearen gemischten Modell? Wie der Name schon sagt, haben wir irgendwas gemischt. Glücklicherweise mischen wir nur zwei Dinge miteinander. Wir mischen hier feste Effekte (eng. *fixed effect*) und zufällige Effekte (eng. *random effect*) miteinander. Bis jetzt kennst du eigentlich nur feste Effekte. Immer wenn wir ein Modell gebaut haben, dann haben wir das Modell mit festen Effekten gebaut. Wir haben dabei Fakotoren als feste Effekte modelliert. Was ist also nun der Unterschied zwischen der Wahl einen Faktor als festen Effekt oder zufälligen Effekt anzusehen? Zuerst ist dies eine Modellierungsentscheidung. Wir müssen uns also zwischen Arten von Modellen unterscheiden. Daher können wir auch verschiedene Modelle mit unterschiedlichen Anzahlen an Faktoren bauen und dann diese Modelle vergleichen. Welcher Faktor jetzt als fester Effekt und welcher als zufälliher Effekt gilt, liegt dabei an uns.

Die Idee hinter dem Modell mit **festen Effekten** ist, dass die beobachteten Effektgrößen von Block zu Block variieren können, was aber nur auf den Varianz der Blöcke zurückzuführen ist. In Wirklichkeit sind die wahren Effektgrößen alle gleich: Sie sind fix. Alle Blöcke haben den gleichen Mittelwert und variieren nur in der Varianz. Wir sehen aber diesen wahren Mittelwert nicht, da sich alle Blöcke eben immer leicht unterscheiden. Mehr dazu auch in [The Fixed-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#fem))

Das Modell der **zufälligen Effekte** geht davon aus, dass es nicht nur eine wahre Effektgröße gibt, sondern eine Verteilung der wahren Effektgrößen. Jeder unserer Blöcke kann also einen anderen wahren Mittelwert haben. Das Ziel des Modells mit zufälligen Effekten ist es daher nicht, die eine wahre Effektgröße aller Blöcke zu schätzen, sondern den Mittelwert der Verteilung der wahren Effekte. Mehr dazu auch in [The Random-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem))

Dabei verbinden die gemischten Modelle die Vorteile eines Modells mit festen Effekt sowie eines Modells mit zufälligen Effekten. Lineare gemischte Modelle schätzen nun die subjektspezifischen Auswirkungen (eng. *subject-specific*) auf die Varianz eines Versuches. Dabei kommt es häufig darauf an unter welchen Umständen eine Beobachtung gemessen wurde. Stehen die Pflanze zusammen auf einem Feld? Sind die Ferkel alle Nachkommen einer Sau? Daher erweitern wir unser lineare Modell um einen zufälligen Effekt $z$ und schreiben wie folgt.

$$
y \sim f_1 + 1|z_1
$$

Wir schreiben in R den Term für da zufällige Modell in der Form $z_0|z_1$. Meist setzen wir den Intercept $z_0$ für den zufälligen Effekt auf `1`. Wenn wir darstellen wollen, das ein zufälliger Faktor in einem anderen zufälligen Fakotr genestet ist, dann schreiben wir `1|z_1/z_2`.

$$
y \sim f_1 + 1|z_1/z_2
$$

Das heißt, dass der zufällige Blockfaktor $z_1$ in den zufälligen Blockfaktor $z_2$ genestet ist. Das klingt jetzt etwas schräg, also einmal ein Beispiel. Wir haben eine Schule, dann sind die Schulklassen dieser Schule in der Schule genestet. Es gibt diese spezifischen Klassen mit den Schülern schlichtweg nicht in anderen Schulen. Wir sagen genestet (eng. *nested*), wenn wir sagen wollen, dass ein Faktor in einen anderen Faktor verschränkt ist. Die Klassen einer Schule sind in der Schule genestet.

In der @fig-mermaid-r-mixed-01 siehst du einmal exemplarisch die Darstellung eines experimentellen Designs mit drei Faktoren. Die Behandlung ist dabei ein fester Effekt und die beiden Faktoren für die Tische und die Gewächshäuser sind zufällige Effekte. Damit wir in der Folge nicht immer so sehr durcheinanderkommen, habe ich die festen Effekt als blau Kästen und die zufälligen Effekte als orange Kästen gesetzt.

```{mermaid}
%%| label: fig-mermaid-r-mixed-01
%%| fig-width: 6
%%| fig-cap: "Beispiel für drei Faktoren und deren Abhänigigkeitsstruktur untereinander. Die Behandlungen sind in den Tischen genested und die Tische in den Gewächshäusern. Die festen Effekte sind als blaue Kästen und die zufälligen als orange Kästen eingefärbt."
flowchart LR
    C(Behandlungen):::fixed --- D(((nested))) --> E(Tische):::random --- F(((nested))) --> G(Gewächshäuser):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

Okay, das ist jetzt bis hierher sehr abstrakt. Machen wir das mal konkret mit einem Beispiel mit drei Behandlungen gegen Blattläuse auf jeweils vier Tischen in drei Gewächshäusern. Pro Behandlung nehmen wir fünf Pflanzen. Damit ergibt sich folgendes Schema der Abhängigkeiten mit den jeweiligen Anzahlen.

$$
\overbrace{\mbox{Gewächshauser}}^{n_g = 3} \xrightarrow[alle]{beinhaltet} \underbrace{\mbox{Tische}}_{n_t = 4} \xrightarrow[alle]{beinhaltet} \overbrace{\mbox{Behandlungen}}^{n_b = 3} \xrightarrow[alle]{beinhaltet} \underbrace{\mbox{Beobachtungen}}_{n_w = 5}
$$

Wie du an dem obigen Beispiel sehen kannst, kommen wir bei linearen gemischten Modellen sehr schnell auf sehr große Fallzahlen. Wir haben im obigen, kleinen Beispiel alleine schon eine Fallzahl von $n_{gesamt} = 3 \times 4 \times 3 \times 5 = 180$ Pflanzen. Und damit ist eigentlich unser Beispiel sehr klein gewählt. Eigentlich brauchen wir für einen zufälligen Effekt als Daumenregel immer mehr als fünf Level für eine gute Modellschätzung.

::: callout-tip
## Weitere Tutorien zu gemischten Modellen

Wie immer und natürlich im Besonderen bei linearen gemischten Modellen, gibt es eine Reihe von tollen Hilfen. Daher hier einmal eine lose Sammlung an Ideen und Tutorien, die mir geholfen haben dieses Kapitel hier zu schreiben. Fast jede Quelle hat dann nochmal Referezen zu weiteren Informationen und Hilfen.

-   [GLMM FAQ -- Ben Bolker and others](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random) ist meine Anlaufstelle, wenn ich mal was nachlesen muss. Eine sehr hilfreiche und umfangreiche Sammlung.
-   [Mixed Models with R -- Getting started with random effects](https://m-clark.github.io/mixed-models-with-R/) ist ein freies Buch, was ich auch immer mal wieder anschaue, wenn ich Fragen rund um das gemischte Modell habe. Dies ist hier nur ein Kapitel mit einer Zusammenfassung und eben kein ganzes Buch.
-   Teile dieses Kapitel auf dem tollen [Tutorium von Gabriela K Hajduk](https://ourcodingclub.github.io/tutorials/mixed-models/). Die Daten und Inhalte wurden von mir teilweise gekürzt sowie inhaltlich angepasst. Auch hier findest du sehr viel mehr Informationen und dann auch Links zu weiteren Quellen.
-   Ideen und weitere Erklärungen sind auch beim [Tutorium von Sara Stoudt](https://rlbarter.github.io/Practical-Statistics/2017/03/03/fixed-mixed-and-random-effects/) zu finden. Hier musst du dich aber mehr Einarbeiten, da der Artikel etwas mehr mathematisch aufgebaut ist.
-   Als weiteres Tutorium für die Auswertung von linearen gemischten Modellen und allgemein dem Modellieren von agarwissenschaftlichen Daten kann ich die Seite [Data Science for Agriculture in R](https://schmidtpaul.github.io/dsfair_quarto/) sehr empfehlen. Dort findest du dann auch die Anwebdung der R Pakete aus diesem Kapitel.
-   [Introduction to `{broom.mixed}`](https://cran.r-project.org/web/packages/broom.mixed/vignettes/broom_mixed_intro.html) hilft dabei die Ausgaben der verschiedenen R Pakte, die es zu gemischten Modellen gibt zu vereinheitlichen. Wir erhalten dann immer die gleiche `tidy()`-Ausgabe und nicht immer was anderes von den Funktionen wiedergegeben.
-   [Linear Models and Mixed Models with R](https://bodo-winter.net/tutorials.html) sind zwei PDF Dateien von @winter2013linear in denen er nochmal sehr schön erklärt wie lineare gemischte Modelle in R funktionieren.
:::

## Dump of ideas (remove me)

<https://multilevelmod.tidymodels.org/articles/multilevelmod.html>

## Annahmen an die Daten

Im folgenden Kapitel zu den linearen gemischten Modellen gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffällige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Das Thema Modellvergleich und Variablenselektion ist im Falle des linearen gemischten Modells nochmal etwas spezieller. Wir gehen hier auch nochmal in einem Abschnitt drauf ein, wie wir das hier in dem Fall von linearen gemischten Modellen machen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom, see, simstudy,
               multcomp, emmeans, lme4, broom.mixed, readxl,
               parameters, ggridges, scales, performance, 
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

### Von Drachen auf Bergen

In diesem fiktiven Datenbeispiel wollen wir uns die Testscores eines Intelligentest bei $N = 480$ Drachen anschauen. Wir sind dafür an acht Berge gefahren und haben die dortigen Drachen an den drei Flanken des Berges getestet. Daher hat der Faktor `mountain` acht Level mit Bavarian, Ligurian, Emmental, Central, Maritime, Southern, Julian, und Sarntal. Die drei Flanken des Berges bilden wir im Faktor `site` mit den Leveln north, east und south ab. In @fig-mountain-site sehen wir eine Skizze für drei Berge mit den jeweiligen Flanken, wo gemessen wurde.

![Beispiel für drei der acht Berge mit *Bavarian*, *Central* und *Julian*. Auf jeden der acht Berge wurden an drei Seiten *north*, *east* und *south* die Testscores der dort lebenden Drachen erhoben. Die dort lebenden Drachen wurden dann in fünf Gruppen nach der Körperlänge eingeteilt.](images/mountain.png){#fig-mountain-site fig-align="center" width="90%"}

Damit haben wir dann folgende Struktur der Faktoren vorliegen.

```{mermaid}
%%| label: fig-mermaid-r-mixed-dragon
%%| fig-width: 6
%%| fig-cap: "In unseren Drachendaten leben die einzelnen Drachen auf einer der drei Seiten `site` eines Berges `mountain`. Daher sind die Drachen mit ihrem Faktor `body_length_cat` in dem Faktor `site` genestet. Der Faktor `site` ist dann wiederum in jedem Faktor `mountain` genestet."
flowchart LR
    C(dragons):::fixed --- D(((nested))) --> E(site):::random --- F(((nested))) --> G(mountain):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

Die Daten liegen in dem Datensatz `dragons.xlsx` ab.

```{r}
dragons_tbl <- read_excel("data/dragons.xlsx") %>% 
  mutate(body_length_cat = as_factor(body_length_cat),
         mountain = as_factor(mountain),
         site = factor(site, labels = c("north", "east", "south"))) 
```

Es ergibt sich dann der Datensatz wie in @tbl-dragon gezeigt. Wir belassen die Körperlänge der Drachen in der kontinuierlichen Form nochmal mit in den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-dragon
#| tbl-cap: Datensatz der Testscores für die Drachen auf verschiedenen Bergen und dort an verschiedenen Flanken der Berge.

dragons_raw_tbl <- dragons_tbl %>% 
  mutate(body_length_cat = as.character(body_length_cat),
         mountain = as.character(mountain),
         site = as.character(site))

rbind(head(dragons_raw_tbl, n = 4),
      rep("...", times = ncol(dragons_raw_tbl)),
      tail(dragons_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

### Von Schülern in Schulen

Beispiel mit den Simpsons

Erstklässler

Flipped Classroom HyperFlex

```{mermaid}
%%| label: fig-mermaid-r-mixed-dragon
%%| fig-width: 6
%%| fig-cap: "In unseren Schuldaten haben wir verschiedene Schulen `school` und Klassen `class` mit zwei innovativen Lehrmethoden unterrichtet. Eine Kontrollgruppe soll die Ergebnisse eines Leistungstests absichern. Daher sind die Lehrmethoden `trt` in dem Faktor `class` genestet. Der Faktor `class` ist dann wiederum in jedem Faktor `school` genestet."
flowchart LR
    C(trt):::fixed --- D(((nested))) --> E(class):::random --- F(((nested))) --> G(school):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

::: {.callout-caution collapse="true"}
## Generierung von Schuldaten (3-faktoriell)

Aus Gründen der Einfachheit haben wir immer ein balanciertes Design vorliegen. Wir haben also immer in allen Faktorkombinationen die gleiche Anzahl an Beobachtungen `n_reps` vorliegen. In der Anwendung mag es Unterschiede geben, so hat eine Sau sicherlich nicht immer exakt zwölf Ferkel, aber in unseren Beispielen macht es keinen Unterschied. Balanciert oder unbalanciert ist bei gemischten Modellen eher nachrangig wichtig.

```{r}
#| eval: false

# set seed
set.seed(20231210)
# sample sizes
n_school <- 9
n_class_per_school <- 3
n_class <- n_school * n_class_per_school
n_trt <- 3
n_reps <- 20
# effects and variance
var_school <- 10
var_class <- 5
eff_trt <- c(frontal = 10,
             flipped = -10,
             hyflex = 30)

# generate data
school_tbl <- tibble(s_id = 1:n_s,
       s_0 = rnorm(n_s, 0, var_school)) %>% 
  add_column(trt = rep(1:n_trt, n_trt),
             t_eff = rep(eff_trt, n_trt)) %>% 
  expand_grid(c_per_s = 1:n_class_per_school) %>%
  mutate(c_id = 1:n_class,
         c_0 = rnorm(n_class, 0, var_class)) %>% 
  expand_grid(reps = 1:n_reps) %>% 
  mutate(test = round(50 + s_0 + c_0 + t_eff + rnorm(n(), 0, 2), 2),
         s_id = factor(s_id, labels = c("Springfield School", "Jacksonville High", "Franklin Country", 
                                        "Clinton Christian", "Arlington Academy", "Georgetown High", 
                                        "Greenville School", "Bristol Country", "Dover Tech Center")),
         c_id = as_factor(c_id),
         c_per_s = factor(c_per_s, labels = c("1a", "1b", "1c")),
         trt = factor(trt, labels = c("Frontal", "Flipped classroom", "HyFlex"))) %>% 
  select(school_id = s_id, class_in_school_id = c_per_s, class_id = c_id, trt, test)

write_xlsx(school_tbl, "data/school_testing.xlsx")
```
:::

Die Daten liegen in dem Datensatz `school_testing.xlsx` ab.

```{r}
school_tbl <- read_excel("data/school_testing.xlsx") %>% 
  mutate(school_id = as_factor(school_id),
         class_in_school_id = as_factor(class_in_school_id),
         class_id = as_factor(class_id),
         trt = as_factor(trt)) 
```

Es ergibt sich dann der Datensatz wie in @tbl-dragon gezeigt. Wir belassen die Körperlänge der Drachen in der kontinuierlichen Form nochmal mit in den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-school
#| tbl-cap: Datensatz der Testscores für die Drachen auf verschiedenen Bergen und dort an verschiedenen Flanken der Berge.

school_raw_tbl <- read_excel("data/school_testing.xlsx") 

rbind(head(school_raw_tbl, n = 4),
      rep("...", times = ncol(school_raw_tbl)),
      tail(school_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

@tbl-mixed-simple-2fac

| school | $\boldsymbol{eff_{school}}$ | class | $\boldsymbol{eff_{class}}$ | trt | $\boldsymbol{eff_{trt}}$ | reps |
|:------:|:---------------------------:|:-----:|:--------------------------:|:---:|:------------------------:|:----:|
|   1    |           $0.23$            |   1   |          $-0.14$           |  1  |           $10$           |  1   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  1  |           $10$           |  2   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  2  |           $5$            |  1   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  2  |           $5$            |  2   |
|   1    |           $0.23$            |   2   |           $0.21$           |  1  |           $10$           |  1   |
|   1    |           $0.23$            |   2   |           $0.21$           |  1  |           $10$           |  2   |
|   1    |           $0.23$            |   2   |           $0.21$           |  2  |           $5$            |  1   |
|   1    |           $0.23$            |   2   |           $0.21$           |  2  |           $5$            |  2   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  1  |           $10$           |  1   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  1  |           $10$           |  2   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  2  |           $5$            |  1   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  2  |           $5$            |  2   |
|   2    |           $0.71$            |   4   |           $0.59$           |  1  |           $10$           |  1   |
|   2    |           $0.71$            |   4   |           $0.59$           |  1  |           $10$           |  2   |
|   2    |           $0.71$            |   4   |           $0.59$           |  2  |           $5$            |  1   |
|   2    |           $0.71$            |   4   |           $0.59$           |  2  |           $5$            |  2   |

: Kurzform eines dreifaktoriellen Datensatzes mit zwei zufälligen Effekten für `school` und `class` sowie einem Bahandlungsfaktor `trt`. Die zufälligen Effekte sind normalverteilt mit $\mathcal{N}(0, s^2)$. Pro Behandlung haben wir dann nur zwei Wiederholungen. Dennoch erreichen wir eine Fallzahl von sechzehn Beobachtungen. {#tbl-mixed-simple-2fac}

## Visualisierung

Bevor wir mit dem Modellieren beginnen, wollen wir erstmal visuell überprüfen, ob unser Outcome $y$ mit dem Testscore auch normalverteilt ist. Wir benötigen für das *klassische* lineare gemischte Modell ein normalverteiltes Outcome $y$. In @fig-mixed-1 sehen wir das Histogramm der Verteilung des Testscores für alle $N = 480$ Drachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-1

ggplot(dragons_tbl, aes(test_score)) +
  geom_histogram() +
  theme_bw() 
```

Wir können in der @fig-mixed-2 auch nochmal schauen, ob die Annahme der annährenden Normalverteilung für unseren Testscore auch für jedes Level unseres Faktors der Körperlängen gegeben ist. Wir sehen auch hier, dass der Testscore einer Normalverteilung über alle Kategorien der Körperlänge folgt.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores aufgeteilt nach Kategorie der Körpergröße zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores für alle Kategorien der Körpergröße.
#| label: fig-mixed-2

ggplot(dragons_tbl, aes(y = body_length_cat, x = test_score, fill = body_length_cat)) +
  theme_bw() +
  stat_density_ridges() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Natürlich können wir uns hier noch weitere Abbildungen erstellen, aber hier soll es erstmal reichen. Wir sehen, dass der Testscore einer Normalverteilung folgt und dass die Varianzen vermutlich homogen sind, da die Histogramme ungefähr gleich breit sind. Ja, ein wenig unterscheiden sich die Verteilungen, aber so gravierend ist es erstmal nicht.

## Mitteln über die einzelnen Beobachtungen

Wir mitteln über den Block oder der Klasse

## Modellierung

Bevor wir jetzt mit dem Modellieren beginnen, müssen wir noch kurz in einem QQ-Plot schauen, ob unser Ourcome `testscore` auch ungefähr normalverteilt ist. @fig-mixed-6 zeigt den QQ-Plot des Testscores. Wir sehen, dass der Hauptteil der Beobachtungen auf der Geraden liegt und wir nehmen daher an, dass der Testscore zumindest approximativ normalverteilt ist. Wir können also mit einem gaussian linearen gemischten Modell weitermachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: QQ-Plot zu Überprüfung, ob der Testscore einer Normalverteilung folgt. Die Punkte liegen ungefähr auf der Geraden als Winkelhalbierende, so dass wi eine Normalverteilung des Testscores annehmen können.
#| label: fig-mixed-6

ggplot(dragons_tbl, aes(sample = test_score)) +
  stat_qq() + stat_qq_line(color = "red") +
  theme_bw() +
  scale_color_okabeito()
```

Schauen wir uns nun als erstes das Modell `lm_simple_fit` einmal an. Wir bauen das Modell nur mit der Faktorvariable `body_length_cat`. Wir erhalten dann gleich die Ausgabe des Modells über die Funktion `model_parameters()` in einer aufgearbeiteten Form.

```{r}
#| message: false
#| warning: false

lm_simple_fit <- lm(test_score ~ body_length_cat, data = dragons_tbl)

lm_simple_fit %>% model_parameters()

```

Der Intercept beinhaltet den Mittelwert für die Drachen des Levels `[tiny]`. Die jeweiligen Koeffizienten dann die Abweichung von den Drachen des Levels `[tiny]`. Daher sind Drachen des Levels `[small]` ungefähr um $2.63$ Einheiten intelligenter. Wir sehen dann an dem $p$-Wert, ob sich die Koeffizienten signifikant von 0 unterscheiden. In @fig-mixed-3 sehen wir nochmal die Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße. Wir erkennen, dass die kleineren Drachen tendenziell dümmer sind als die großen Drachen. Wir sehen zwei Plateaus.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße.
#| label: fig-mixed-3

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = body_length_cat)) +
  theme_bw() +
  geom_boxplot() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Nun haben wir aber nicht nur die Körpergrößen gemessen sondern auch auf welchem Berg wir die jeweiligen Drachen gefunden haben. Nun könnte es sein, dass der Berg einen viel größeren Einfluss auf die Inteliegenz hat als die Drachenkörpergröße. Wir könnten einen Confoundereffekt durch die Berge vorliegen haben. Ergänzen wir also das Modell um den Faktor `mountain` und erhalten das Modell `lm_mountain_fit`.

```{r}
#| message: false
#| warning: false

lm_mountain_fit <- lm(test_score ~ body_length_cat + mountain, data = dragons_tbl)
lm_mountain_fit %>% model_parameters()
```

Wie wir sehen, werden nun die Körpergrößen der Drachen nicht mehr als signifikant ausgegeben. Die Effekte der Körpergröße auf den Testscore sind auch viel kleiner geworden, wenn wir die `mountain` mit in das Modell nehmen. Anscheinend hat der Berg auf dem wir den Drachen getroffen haben einen viel größeren Einfluss auf die Intelligenz als die Körpergröße. Wir können uns den Zusammenhang zwischen dem Testscore und dem Berg auch in der @fig-mixed-4 einmal anschauen.

Eigentlich würden wir erwarten, dass es keinen Effekt der Berge auf den Testscore der Drachen gibt. Es müsste eigentlich egal sein, wo wir einen Drachen befragen, wenn wir nur an der Körpergröße und dem Testscore interessiert sind. Wir sehen jedoch in der @fig-mixed-4 einen klaren Unterschied zwischen den Bergen im Bezug auf den Testscore.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung.
#| label: fig-mixed-4

ggplot(dragons_tbl, aes(mountain, test_score, fill = mountain)) +
  geom_boxplot() +
  theme_bw() +
  theme(legend.position = "none") +
  scale_fill_okabeito()
```

In der @fig-mixed-5 sehen wir den Zusammenhang von Testscore und der Körpergröße sowie den Bergen auf denen das Interview stattgefunden hat. so langsam dämmert uns warum wir hier einen Effekt der Körperlänge zu dem Testscore sehen. Die kleineren Drache sind alle nur auf bestimmten Bergen zu finden! Betrachten wir die Berge mit in dem Modell, dann hat die Körpergröße keinen Einfluß mehr.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße.
#| label: fig-mixed-5

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain")
```

Der Zusammenhang wird vielleicht in @fig-mixed-7 nochmal klarer. Hier schauen wir uns den Zusamenhang wieder für die Körperlänge getrennt für die Berge an. Nur zeichnen wir jetzt jeden einzelnen Berg in ein Subplot. Wir sehen, dass es hier fast keinen Unterschied macht, wie lang die Drachen sind. Der Testscore ist immer gleich. Was einen Unterschied macht, sind die Berge.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße in getrennten Subplots.
#| label: fig-mixed-7

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain") +
  theme(legend.position = "none") +
  facet_wrap(~ mountain) 
```

Schauen wir uns nun einmal ein lineares gemischtes Modell an. Wir nutzen daszu das R Paket `{lme4}`. Wir haben auch noch andere Pakete zur Aswahl, aber wir nutzen hier erstmal das gängiste Paket. Um ein lineares gemischtes Modell in R zu schätzen nutzen wir die Funktion `lmer()`. Die Funktion `lmer()` nimmt an, dass das Outcome `test_score` normalverteilt ist. Wir haben diese Annahme ja weiter oben in dem QQ-Plot überprüft.

In einem lineare gemischten Modell müssen wir die *festen* Effekte sowie die *zufälligen* Effekte definieren. Die festen Effekte werden ganz normal wie wir es gewohnt sind in das Modell eingegeben. Die zufälligen Effkete schreiben wir in eine Klammer in der Form `(1|)`.

Wir schreiben `(1|moutain_range)` und definieren damit die Variable `mountain` als zufälligen Effekt im Modell. Wir schreiben `1|` vor `mountain`, da wir für jeden Berg die gleiche Steigung von Körperlänge und Testscore annehmen. Wir können dann später noch das Model komplizierter aufbauen und jedem Berg eine eigene Steigung erlauben. Bauen wir uns jetzt erstmal ein lineares gemischtes Modell mit einem festen Effekt `body_length_cat` und einem zufälligen Effekt `(1|mountain)`.

```{r}
#| message: false
#| warning: false

lmer_1_fit <- lmer(test_score ~ body_length_cat + (1 | mountain), data = dragons_tbl)
lmer_1_fit %>% model_parameters()
```

Unser Model sieht etwas aufgeräumter aus. Als feste Effekte haben wir nur noch die Körperlänge `body_length_cat` und die dazugehörigen Koeffizienten des Modells. Unsere Variable `mountain` verschwindet dann in den zufälligen Effekten. Die Funktion `summary` liefert uns den gesamten Ausdruck, der etwas überwältigend ist. Vieles brauchen wir auch nicht davon.

```{r}
#| message: false
#| warning: false
#| eval: false

lmer_1_fit %>% summary()
```

![](images/lmer_summary.png){fig-align="center" width="90%"}

Was wir extrahieren wollen ist die Information von den zufälligen Effekten. Wir wollen wissen, wieviel Varianz durch die zufälligen Effekte erklärt wird. Wir nutzen dazu die Funktion `VarCorr()`, die uns erlaubt die Information zu en zufälligen Effekten zu extrahieren und auszugeben.

```{r}
print(VarCorr(lmer_1_fit), comp = "Variance")
```

Wieviel Varianz erklären nun die Berge? Wir können die erklärte Varianz der zufälligen Effekte einfach berechnen. Wir vergleichen die erklärte Varianz von `mountain` mit der gesamten Varianz. Die gesamte Varianz ist die Varianz aller zufälligen Effekte plus der residualen Varianz. Wir erhalten dann $R^2_{random} = 339.7/(339.7 + 223.8) \approx 0.60$. Wir sehen, dass ca. 60% der Varianz in unseren Daten von der Variable `mountain` verursacht wird.

Wir können die Funktion `model_performance()` nutzen um mehr über den Fit des Modells zu erfahren. Das `R2 (cond.)` ist faktisch das gleiche wie wir gerade oben berechnet haben. Wir benötigen also nicht immer den Ausdruck der zufälligen Effekte. Wir können auch die Informationen aus der Funktion `model_performance()` nehmen.

```{r}
lmer_1_fit %>% model_performance()
```

In der Abbildung @fig-mixed-8 schauen wir uns nochmal an, ob wir das Modell auch gut gefittet haben. Der Residualplot sieht gut aus, wir erkennen kein Muster. Ebenso sieht der QQ-Plot gut aus, die Beobachtungen liegen alle auf der Geraden. Wir sind mit dem Modell soweit erstmal ganz zufrieden.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-mixed-8
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Visuelle Überprüfung des Modells mit dem Residual und QQ-Plot."
#| fig-subcap: 
#|   - "Residualplot"
#|   - "QQ-Plot"
#| layout-nrow: 1

augment(lmer_1_fit) %>% 
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  scale_color_okabeito()

ggplot(tibble(.resid = resid(lmer_1_fit)), aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw()
```

Wir haben noch eine Variable in unseren Daten ignoriert. Wir haben uns bis jetzt nicht die Variabl `site` angeschaut. Auf jedem Berg haben wir die Drachen noch auf verschiedenen Flanken des Berges `site` befragt. Das heißt, wir haben die Variable `site`, die in der Variable `mountain_site` genestet ist. Wir schreiben daher ein neues Modell und nutzen die Schreibweise `(1|mountain/site)` um zu beschreiben, dass `site` immer zusamen in einem Berg vorkommt. Schaue dir dazu nochmal die Abbidlung ganz zu Beginn dieses Kapitels an um die Zusammenhänge nochmal visualisiert zu bekommen.

```{r}
#| message: false
#| warning: false

lmer_2_fit <- lmer(test_score ~ body_length_cat + (1|mountain/site), data = dragons_tbl) 
lmer_2_fit %>% model_parameters()
```

Das Modell hat nun einen weiteren zufälligen Effekt. Es werden jetzt auch nochmal für jeden Berg die Flankeneffekte mit berücksichtigt. Hat das überhaupt einen Einfluss auf das Modell? Schauen wir uns einmal die Modellgüte mit der Funktion `model_performance()` an.

```{r}
#| message: false
#| warning: false

lmer_2_fit %>% model_performance()
```

Wir sehen, dass sich die erklärte varianz leicht erhöht hat. Die $R^2_{random}$ liegt jetzt bei $0.623$ also fast 62%. Etwas besser als vorher, aber auch nicht unbedingt sehr viel mehr.

Wie können wir nun unsere vier Modelle miteinander vergleichen? Wir haben ja folgende Modelle vorliegen:

-   Das simple lineare Modell `lm_simple_fit` mit `test_score ~ body_length_cat`.
-   Das multiple lineare Modell `lm_mountain_fit` mit `test_score ~ body_length_cat + mountain`.
-   Das gemischte lineare Modell `lmer_1_fit` mit `test_score ~ body_length_cat + (1|mountin_range)`.
-   Das genestete gemischte lineare Modell `lmer_2_fit` mit `test_score ~ body_length_cat + (1|mountain/site)`.

Um die Modelle miteinander zu vergleichen können wir die Funktion `compare_performance()` nutzen. Wir erhalten mit der Option `rank = TRUE` auch eine Sortierung der Modelle wieder. Das beste Modell steht dann ganz oben.

```{r}
#| message: false
#| warning: false

compare_performance(lm_simple_fit, lm_mountain_fit, lmer_1_fit, lmer_2_fit, rank = TRUE)
```

In diesem Beispiel wäre sogar eine multiple lineare Regression das beste Modell. Wir würden also auch mit zwei festen Effekten die Variabilität der Berge richtig modellieren. Der Effekt der Flanken auf den Testscore scheint ziemlich klein zu sein, so dass wir auch auf die Variable `site` verzichten können.

## Gruppenvergleich {#sec-mult-comp-lmer-reg}

![](images/caution.png){fig-align="center" width="50%"}

text

`{simstudy}`

```{r}
gen_school <- defData(varname = "n_classes", dist = "nonrandom", formula = 3,
    id = "id_school")
gen_school <- defData(gen_school, varname = "s0", dist = "normal", formula = 0, variance = 3)
```

```{r}
set.seed(282721)

dt_school <- genData(9, gen_school)
dt_school <- trtAssign(dt_school, n = 3, grpName = "trt")

dt_school
```

text

```{r}
gen_class <- defDataAdd(varname = "n_students", dist = "nonrandom", formula = 5)
gen_class <- defDataAdd(gen_class, varname = "c0", dist = "normal", formula = 0, variance = 2)
```

```{r}
dt_class <- genCluster(dt_school, "id_school", numIndsVar = "n_classes", level1ID = "id_class")
dt_class <- addColumns(gen_class, dt_class)

dt_class %<>% 
  add_column(trt_new = rep(1:3, 9))

head(dt_class)
```

text

```{r}
gen_student <- defDataAdd(varname = "test", dist = "normal",
                          formula = "50 + s0 + c0 + 8 * trt", variance = 2)
dt_student <- genCluster(dt_class, cLevelVar = "id_class", numIndsVar = "n_students",
    level1ID = "id_child")

dt_student <- addColumns(gen_student, dt_student) %>% 
  mutate(id_class = as_factor(id_class),
         id_school = as_factor(id_school),
         trt = as_factor(trt),
         trt_new = as_factor(trt_new))
```

```{r}
#| eval: false
n_s <- 9
s_tbl <- tibble(s_id = 1:n_s,
                s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3)) %>% 
  expand_grid(c_per_s = 1:3)

foo <- tibble(s_id = 1:n_s,
       s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3),
             t_eff = rep(c(10, -10, 30), 3)) %>% 
  expand_grid(c_per_s = 1:3) %>% 
  mutate(c_id = 1:27,
         c_0 = rnorm(27, 0, 5)) %>% 
  expand_grid(reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + t_eff + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

foo %>% 
  ggplot(aes(trt, test, fill = s_id, group = c_id)) +
  theme_bw() +
  geom_boxplot() 

lmer_fit <- lmer(test ~ trt + (1|s_id) + (1|c_id), data = foo) 

lmer_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

```

```{r}
#| eval: false
expand_grid(tibble(s_id = 1:n_s,
                   s_0 = rnorm(n_s, 0, 2)),
            tibble(trt = 1:3,
                   trt_eff = c(10, -5, 20))) 



final_data <- s_tbl %>% 
  mutate(c_id = 1:27,
         c_0 = rnorm(27, 0, 5)) %>% 
  expand_grid(reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + 10 * trt + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

final_data %>% 
  ggplot(aes(trt, test, fill = s_id, group = c_id)) +
  theme_bw() +
  geom_boxplot() 
```

```{r}
#| eval: false
n_s <- 9
s_tbl <- tibble(s_id = 1:n_s,
                s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3)) 

c_tbl <- tibble(c_id = 1:3,
                c_0 = rnorm(3, 0, 5))


final_data <- s_tbl %>% 
  expand_grid(c_tbl,
              reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + 8 * trt + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

final_data %>% 
  ggplot(aes(trt, test, fill = c_id)) +
  theme_bw() +
  geom_boxplot() +
  facet_wrap(~s_id)

```

```{r}
dt_student %>% 
  ggplot(aes(id_class, test, fill = id_school, linetype = trt, color = trt)) +
  theme_bw() +
  geom_boxplot()


dt_student %>% 
  ggplot(aes(trt, test, fill = id_school, group = id_class)) +
  theme_bw() +
  geom_boxplot()
```

::: panel-tabset
## `lmer`

```{r}
lmer_fit <- lmer(test ~ trt + (1|id_school) + (1|id_class), data = dt_student) 

lmer_fit2 <- lmer(test ~ trt + (1|id_class/id_school), data = dt_student) 

compare_performance(lmer_fit, lmer_fit2, rank = TRUE)


lmer_fit %>% 
  model_performance()

lmer_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

lmer_fit %>% anova

```

## `lm`

```{r}
lm_fit <- lm(test ~ trt + id_school + id_class, data = dt_student) 

lm_fit %>% 
  model_performance()

lm_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

lm_fit %>% anova
```
:::

::: callout-tip
## Anwendungsbeispiel: Dreifaktorieller Gruppenvergleich für das Gewicht

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit Brokkoli an. Wir haben uns in diesem Experiment verschiedene Dosen `fert_amount` von einem Dünger aufgebracht sowie verschiedene Zeitpunkte der Düngung `fert_time` berücksichtigt. Auch hier haben wir einige Besonderheiten in den Daten, da nicht jede Faktorkombination vorliegt. Wir ignorieren aber diese Probleme und rechnen einfach stumpf unseren Gruppenvergleich.

```{r}
broc_tbl <- read_excel("data/broccoli_weight.xlsx") %>% 
  mutate(fert_time = factor(fert_time, levels = c("none", "early", "late")),
         fert_amount = as_factor(fert_amount),
         block = as_factor(block)) %>%
  select(-stem_hollowness) 
```

Dann können wir auch schon die Gaussian Regression mit `lm()` rechnen.

```{r}
lm_fit <- lm(weight ~ fert_time + fert_amount + fert_time:fert_amount + block, 
             data = broc_tbl) 
```

Jetzt rechnen wir in den beiden folgenden Tabs einmal die ANOVA und dann auch den multiplen Gruppenvergleich mit `{emmeans}`. Da wir hier normalveteilte Daten haben, können wir dann einfach die Standardverfahren nehmen. Eventuell müssten wir bei dem Gruppenvergleich mit `emmeans()` nochmal für Varianzheterogenität adjustieren, aber da erfährst du dann mehr in dem Kapitel zu den [Multiple Vergleichen oder Post-hoc Tests](#sec-posthoc).

::: panel-tabset
## ANOVA mit `anova()`

Wir rechnen hier einmal die ANOVA und nutzen den $\mathcal{X}^2$-Test für die Ermittelung der p-Werte. Wir müssen hier einen Test auswählen, da per Standardeinstellung kein Test gerechnet wird. Wir machen dann die Ausgabe nochmal schöner und fertig sind wir.

```{r}
lm_fit %>% 
  anova() %>% 
  model_parameters()
```

Wir sehen, dass der Effekt der Düngerzeit und die Menge des Düngers signifikant ist, jedoch wir keinen signifikanten Einfluss durch die Interaktion haben. Wir haben aber also keine Interaktion vorliegen. Leider ist auch der Block signifikant, so dass wir eigentlich nicht über den Block mitteln sollten. Wir rechnen trotzdem die Analyse gemittelt über die Blöcke. Wenn du hier mehr erfahren möchtest, dann schaue dir das Beispiel hier nochmal im Kapitel zu dem [linearen gemischten Modellen](#sec-mixed) an.

## Gruppenvergleich mit `emmeans()`

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `fert_time` und `fert_amount` einen Gruppenvergleich. Dafür nutzen wir die Option `fert_time * fert_amount`. Wenn du die Analyse *getrennt* für die Menge und den Zeitpunkt durchführen willst, dann nutze die Option `fert_time | fert_amount`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- lm_fit %>% 
  emmeans(~ fert_time * fert_amount) %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `emmean` stellt den mittleren Gewicht des Brokkoli je Faktorkombination dar gemittelt über alle Blöcke. Das Mitteln über die Blöcke ist eher fragwürdig, da wir ja einen Effekt der Blöcke in der ANOVA gefunden hatten. Hier schauen wir dann nochmal auf das Beispiel im Kapitel zu den [linearen gemischten Modellen](#sec-mixed). Dann können wir zum Abschluss auch das *compact letter display* anhand der Abbildung interpretieren.
:::

In der @fig-log-mod-gaussian-broc siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Wir sehen einen klaren Effekt der Düngezeitpunkte sowie der Düngermenge auf das Gewicht von Brokkoli. Wenn wir ein mittleres Gewicht von $500g$ für den Handel erreichen wollen, dann erhalten wir das Zielgewicht nur bei einer Düngemenge von $300mg/l$. Hier stellt sich dann die Frage, ob wir bei $225mg/l$ und einem frühen Zeitpunkt der Düngung nicht auch genug Brokkoli erhalten. Das Ziel ist es ja eigentlich in einen Zielbereich zu kommen. Die Köpfe sollen ja nicht zu schwer und auch nicht zu leicht sein. Aber diese Frage und andere Fragen der biologischen Anwendung lassen wir dann hier einmal offen, denn das Beispiel soll ja nur ein Beispiel sein.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-gaussian-broc
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mittleren Brokkoligewichte aus einer Gaussian Regression. Das `lm()`-Modell berechnet das mittler Gewicht des Brokkoli in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert. Wir nutzen hier den Standardfehler, da die Standardabweichung mit der großen Fallzahl rießig wäre. Wir haben noch ein Mindestgewicht von 500g ergänzt."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = fert_time, y = emmean, fill = fert_amount)) +
  theme_bw() + 
  labs(y = "Mittleres Gewicht [g] des Brokkoli", x = "Düngezeitpunkt",
       fill = "Düngemenge [mg/l]") +
  scale_y_continuous(breaks = seq(0, 500, by = 100)) +
  geom_hline(yintercept = 500, size = 0.75, linetype = 2) +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = .group, y = emmean + SE + 0.01),  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = emmean-SE, ymax = emmean+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

::: callout-tip
## Anwendungsbeispiel: Dreifaktorieller Gruppenvergleich für Thripsenbefall

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit jungen Apfelbäumen an. Wir haben uns in diesem Experiment verschiedene Dosen `trt` von einem Insektizid aufgebracht sowie verschiedene Startanzahlen von Raubmilben als biologische Alternative untersucht. Dann haben wir noch fünf Zeitpunkte bestimmt, an denen wir die Anzahl an Thripsen auf den Blättern gezählt haben. Wir haben nicht die Blätter per se gezählt sondern Fallen waagerecht aufgestellt. Dann haben wir geschaut, wie viele Thripsen wir über `above` und unter `below` von den Fallen gefunden haben. In unserem Fall beschränken wir uns auf die obere Anzahl an Thripsen und schauen uns auch nur die Behandlung mit dem Insektizid an.

```{r}
insects_tbl <- read_excel("data/insects_count.xlsx") %>% 
  mutate(timepoint = factor(timepoint, labels = c("1 Tag", "4 Tag", "7 Tag", "11 Tag", "14 Tag")),
         rep = as_factor(rep),
         trt = as_factor(trt)) %>%
  select(timepoint, trt, rep, thripse = thripse_above, mite = mite_above) %>% 
  filter(trt %in% c("10ml", "30ml", "60ml"))
```

Dann können wir auch schon die Poisson Regression mit `glm()` rechnen. Auch hier wieder darauf achten, dass wir dann als Option `family = poisson` oder `family = quasipoisson` wählen. Es hängt jetzt davon ab, ob du in deinen Daten Overdispersion vorliegen hast oder nicht. In den beiden folgenden Tabs, rechne ich dann mal beide Modelle.

::: panel-tabset
## `family = poisson`

Als Erstes rechnen wir eine normale Poisson Regression und schauen einmal, ob wir Overdispersion vorliegen haben. Wenn wir Overdispersion vorliegen haben, dann können wir keine Poisson Regression rechnen, sondern müssen auf eine Quasipoisson Regression ausweichen. Das ist aber sehr einfach, wie du im anderen Tab sehen wirst.

```{r}
insects_poisson_fit <- glm(thripse ~ trt + timepoint + trt:timepoint, 
                           data = insects_tbl, 
                           family = poisson) 
```

Bevor wir uns das Modell mit `summary()` überhaupt anschauen, wollen wir erstmal überprüfen, ob wir überhaupt Overdispersion vorliegen haben. Wenn ja, dann können wir uns die `summary()` hier gleich sparen. Also einmal geguckt, was die Overdispersion macht.

```{r}
insects_poisson_fit %>% check_overdispersion()
```

Wir haben sehr starke Overdispersion vorliegen und gehen daher rüber in den anderen Tab und rechnen eine Quasipoisson Regression. Nur wenn du keine Overdispersion vorliegen hast, dann kannst du eine eine Poisson Regression rechnen.

## `family = quasipoisson`

Entweder hast du in deinen Daten eine Overdispersion gefunden oder aber du meinst, es wäre besser gleich eine Quasipoisson zu rechnen. Beides ist vollkommen in Ordnung. Ich rechne meistens immer eine Quasipoisson und schaue dann nur, ob die Overdispersion sehr groß war. In den seltensten Fällen hast du eine Overdispersion vorliegen, die eher klein ist. Daher mache ich erst die Lösung und schaue, ob das Problem dann da war.

```{r}
insects_quasipoisson_fit <- glm(thripse ~ trt + timepoint + trt:timepoint, 
                                data = insects_tbl, 
                                family = quasipoisson) 
```

Du kannst in der `summary()` Ausgabe direkt sehen, ob du Overdispersion vorliegen hast. Du musst nur relativ weit unten schauen, was zu dem `Dispersion parameter` in den Klammern geschrieben ist. Wenn da eine Zahl größer als 1 drin steht, dann hast du Overdispersion.

```{r}
insects_quasipoisson_fit %>% 
  summary()
```

Wir haben hier auf jeden Fall Overdispersion vorliegen. Daher nutze ich dann auch das Modell hier mit der Annahme an eine Quasipoissonverteilung. Dann stimmt es auch mit unseren Varianzen und wir produzieren nicht zufällig zu viele signifikante Ergebnisse, die es dann gar nicht gibt.
:::

Ich habe mich gerade in den obigen Tabs für eine Quasipoisson Regression entschieden, da wir Overdispersion vorliegen haben. Damit mache ich dann mit dem `insects_quasipoisson_fit` Modell weiter. In den beiden folgenden Tabs findest du dann einmal das Ergebnis für die ANOVA und einmal für den Gruppenvergleich mit dem R Paket `{emmeans}`. Bitte beachte, dass die ANOVA für ein `glm()`-Objekt nicht ganz gleich wie für ein `lm()`-Objekt ist. Du kannst aber die ANOVA erstmal ganz normal interpretieren, nur haben wir hier nicht die Möglichkeit ein $\eta^2$ zu bestimmen. Dann nutzen wir `{emmeans}` für den Gruppenvergleich. Nochmal, weil wir Overdispersion festgestellt haben, nutzen wir das Objekt `insects_quasipoisson_fit` mit der Berücksichtigung der Overdispersion.

::: panel-tabset
## ANOVA mit `anova()`

Wir rechnen hier einmal die ANOVA und nutzen den $\mathcal{X}^2$-Test für die Ermittelung der p-Werte. Wir müssen hier einen Test auswählen, da per Standardeinstellung kein Test gerechnet wird. Wir machen dann die Ausageb nochmal schöner und fertig sind wir.

```{r}
insects_quasipoisson_fit %>% 
  anova(test = "Chisq") %>% 
  model_parameters(drop = "NULL")
```

Wir sehen, dass der Effekt für die Behandlung signifikant ist, jedoch die Zeit und die Interaktion keinen signifikanten Einfluss haben. Wir haben aber also keine Interaktion vorliegen. Daher können wir dann die Analyse gemeinsam über alle Zeitpunkte rechnen.

## Gruppenvergleich mit `emmeans()`

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `trt` und `timepoint` einen Gruppenvergleich. Dafür nutzen wir die Opition `trt * timepoint`. Wenn du die Analyse *getrennt* für die Zeitpunkte durchführen willst, dann nutze die Option `trt | timepoint`. Wir wollen die Wahrscheinlichkeiten für das Auftreten einer Beschädigung von wiedergegeben bekommen, deshalb die Option `regrid = "response`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- insects_quasipoisson_fit %>% 
  emmeans(~ trt * timepoint, regrid = "response") %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `rate` stellt die mittlere Anzahl an Thripsen je Faktorkombination dar. Dann können wir auch das *compact letter display* anhand der Abbildung interpretieren.
:::

In der @fig-log-mod-pois-insect siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Hier unbedingt `SE` als den Standardfehler für die Fehlerbalken nutzen, da wir sonst Fehlerbalken größer und kleiner als $0$ erhalten, wenn wir die Standardabweichung nutzen würden. Das ist in unserem Fall nicht so das Problem, aber wenn du eher kleine Anzahlen zählst, kann das schnell zu Werten kleiner Null führen. Wir sehen einen klaren Effekt der Behandlung `60ml`. Die Zeit hat keinen Effekt, was ja schon aus der ANOVA klar war, die Säulen sehen für jeden Zeitpunkt vollkommen gleich aus. Gut etwas Unterschied ist ja immer.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-pois-insect
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mitleren Zahl der Thripsen aus einer Poisson Regression. Das `glm()`-Modell berechnet die mittlere Anzahl in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = timepoint, y = rate, fill = trt)) +
  theme_bw() + 
  labs(y = "Mittlere Anzahl an Thripsen", x = "Messzeitpunkte der Zählungen",
       fill = "Dosis") +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = .group, y = rate + SE + 0.01),  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = rate-SE, ymax = rate+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

## Referenzen {.unnumbered}
