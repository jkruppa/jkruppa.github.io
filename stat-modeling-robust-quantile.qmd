```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Robust und Quantile Regression {#sec-reg-quantile}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"All models are approximations. Essentially, all models are wrong, but some are useful. However, the approximate nature of the model must always be borne in mind." --- George E. P. Box*

In diesem Kapitel geht es um zwei Arten der Regression, die immer wieder genannt werden, aber dennoch eine Art Nischendasein fristen. Zum einen möchte ich hier die robuste Regression (eng. *robust regression*) und zum anderen die Quantilsregression (eng. *quantile regression*) vorstellen. Die robuste Regression ist faktisch statistisch tot. Das heißt, die Implementierungen werden kaum weiterentwickelt und auch findet methodische Forschung nur in der theoretischen Nische statt. Zwar wird die robuste Regression in ihrer ursprünglichen Form als Regression angewendet, aber das reicht meistens nicht. Selten wollen wir nur durch ein paar Punkte eine Gerade ziehen und uns über das gute Modell erfreuen. Wir haben mit dem Modell meist mehr vor. Wir wollen eine ANOVA rechnen und dann auch einen wie auch immer gearteten Mittelwertsvergleich. Wenn dies zwar theoretisch möglich ist, praktisch aber nicht implementiert, dann wollen und können wir die Methoden nur eingeschränkt verwenden. Bei der Quantilsregression sieht es etwas anders aus, hier können wir dann schon den ein oder anderen Mittelwertsvergleich rechnen. Was bei der Quantilsregression eher problematisch ist, ist das das Modell nicht immer konvergiert oder aber nicht algorithmisch eine Lösung für einen spezifischen Datensatz findet. In diesem Datensatz dann den einen Grund zu finden, ist dann meist so aufwendig, dass wir es auch gleich mit der Quantilsregression lassen können.

Der Charme der Quantilesregression ist ja am Ende, dass wir auch den Median als Quantile auswählen können. So haben wir dann die Möglichkeit eine Regression auf den Medianen zu rechnen. Wir vergleichen damit dann auch die Mediane und sind so nicht mehr auf die Normalverteilung unseres Outcomes wie in der gewöhnlichen Regression angewiesen. Also eigentlich eine tolle Sache, wenn wir nur an den Mittelwertsvergleichen interessiert sind. Eine klassische ANOVA geht leider nicht auf einer Medianregression. Eine klassische ANOVA wäre aber mit nicht parametrischen Methoden sowieso nicht möglich gewesen. Wir verlieren also nicht so viel, gewinnen aber etwas, wenn das Modell konvergiert und ein Ergebnis liefert.

In diesem Kapitel brechen wir etwas die bisherige Struktur der Regressionskapitel auf. Wir schauen uns hier zuerst die beiden Modelle an und entscheiden dann, ob wir die Modelle für die ANOVA oder den Gruppenvergleich *überhaupt* nutzen können. Am Ende vergleichen wir dann einmal alle Modell mit dem fantastische Paket `modelsummary` mit der gleichnamigen Funktion. Hier hilft dann wie immer die tolle [Hilfsseite von modelsummary](https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html) zu besuchen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom, quantreg,
               see, performance, emmeans, multcomp, janitor,
               parameters, effectsize, MASS, modelsummary)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Für unser erstes Beispiel nutzen wir die Daten aus einem Wachstumsversuch mit Basilikum mit vier Bodenbehandlungen und vier Blöcken, die Blöcke sind eigentlich Gewächshaustische. Wir wollen also einen klassischen Gruppenvergleich mit Berücksichtigung der Blockstruktur rechnen.

```{r}
basi_tbl <- read_excel("data/keimversuch_basilikum_block.xlsx") %>%
  clean_names() %>% 
  mutate(versuchsgruppe = as_factor(versuchsgruppe)) %>% 
  select(versuchsgruppe, block_1:block_4)
```

In @tbl-model-1 sehen wir einmal die Daten im Wide-Format. Wir haben also das Frischgewicht der Basilikumpflanzen gemessen und wollen wissen, ob die verschiedenen Bodenarten einen Einfluss auf das Wachstum haben.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz des Frischegewichts von Basilikumpflanzen auf vier Tischen bzw. Blöcken in vier Versuchsgruppen."
#| label: tbl-model-1

basi_raw_tbl <- basi_tbl %>% 
  mutate(versuchsgruppe = as.character(versuchsgruppe))
rbind(head(basi_raw_tbl),
      rep("...", times = ncol(basi_raw_tbl)),
      tail(basi_raw_tbl)) %>% 
  kable(align = "c", "pipe")

```

Da wir die Daten im Wide-Format vorliegen haben, müssen wir die Daten nochmal in Long-Format umwandeln. Wie immer nutzen wir dafür die Funktion `pivot_longer()`.

```{r}
#| message: false
#| warning: false
basi_block_tbl <- basi_tbl %>% 
  pivot_longer(cols = block_1:block_4,
               values_to = "weight",
               names_to = "block") %>% 
  mutate(block = as_factor(block))
```

In der @fig-robust-basi-00 siehst du einmal die Daten als Dotplots mit Mittelwert und Standardabweichung. Wir machen hier mal einen etwas komplizierteren Plot, aber immer nur Barplot ist ja auch langweilig.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-robust-basi-00
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Dotplot des Frischegewichts von Basilikumpflanzen auf vier Tischen bzw. Blöcken in vier Versuchsgruppen mit Mittelwert und Standardabweichung."

ggplot(basi_block_tbl, aes(block, weight, color = versuchsgruppe)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_point(position = position_dodge(0.5), shape = 4, size = 2.5) +
  stat_summary(fun.data="mean_sdl", fun.args = list(mult = 1), 
               geom="pointrange", position = position_dodge(0.5))  +
  stat_summary(fun = "mean", fun.min = "min", fun.max = "max", geom = "line",
               position = position_dodge(0.5)) 
```

Unser zweiter Datensatz ist ein Anwendungsdatensatz aus dem Gemüsebau. Wir schauen uns das Wachstum von drei Gurkensorten über siebzehn Wochen an. Die Gurkensorten sind hier unsere Versuchsgruppen. Da wir es hier mit echten Daten zu tun haben, müssen wir uns etwas strecken damit die Daten dann auch passen. Wir wollen das Wachstum der drei Gurkensorten *über* die Zeit betrachten - also faktisch den Verlauf des Wachstums. Wir ignorieren hier einmal die abhängige Datenstruktur über die Zeitpunkte.

::: column-margin
Mit einer abhängigen Datenstruktur müssten wir eigentlich ein lineares gemischtes Modell rechnen. Aber wir nutzen hier die Daten einmal anders.
:::

Im Weiteren haben wir zwei Typen von Daten für das Gurkenwachstum. Einmal messen wir den Durchmesser für jede Sorte (`D` im Namen der Versuchsgruppe) oder aber die Länge (`L` im Namen der Versuchsgruppe). Wir betrachten hier nur das Längenwachstum und deshalb filtern wir erstmal nach allen Versuchsgruppen mit einem `L` im Namen. Am Ende schmeißen wir noch Spalten raus, die wir nicht weiter brauchen.

```{r}
#| message: false
#| warning: false

gurke_raw_tbl <- read_excel("data/wachstum_gurke.xlsx") %>% 
  clean_names() %>% 
  filter(str_detect(versuchsgruppe, "L$")) %>% 
  select(-pfl, -erntegewicht) %>% 
  mutate(versuchsgruppe = factor(versuchsgruppe, 
                                 labels = c("Katrina", "Proloog", "Quarto"))) 
```

In der @tbl-model-2 sehen wir einmal die rohen Daten dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz zu dem Längen- und Dickenwachstum von Gurken."
#| label: tbl-model-2

gurke_raw_2_tbl <- gurke_raw_tbl %>% 
  mutate(versuchsgruppe = as.character(versuchsgruppe))
rbind(head(gurke_raw_2_tbl),
      rep("...", times = ncol(gurke_raw_2_tbl)),
      tail(gurke_raw_2_tbl)) %>% 
  kable(align = "c", "pipe")

```

Dann müssen wir die Daten noch in Long-Format bringen. Da wir dann auch noch auf zwei Arten die Daten über die Zeit darstellen wollen, brauchen wir einmal die Zeit als Faktor `time_fct` und einmal als numerisch `time_num`. Leider haben wir auch Gurken mit einer Länge von 0 cm, diese Gruken lassen wir jetzt mal drin, da wir ja eine robuste Regression noch rechnen wollen. Auch haben wir ab Woche 14 keine Messungen mehr in der Versuchsgruppe `Prolong`, also nehmen wir auch nur die Daten bis zur vierzehnten Woche.

```{r}
gurke_time_len_tbl <- gurke_raw_tbl %>% 
  pivot_longer(cols = t1:t17,
               values_to = "length",
               names_to = "time") %>% 
  mutate(time_fct = as_factor(time),
         time_num = as.numeric(time_fct)) %>% 
  filter(time_num <= 14)
```

In der @fig-robust-gurke-00 sehen wir dann nochmal den Scatterplot für das Gurkenwachstum. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-robust-gurke-00
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Scatterplot des Längenwachstums der drei Gurkensorten über vierzehn Wochen. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar."

ggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +
  theme_bw() +
  geom_point() +
  stat_summary(fun = "mean", geom = "line") +
  stat_summary(fun = "median", geom = "line", linetype = 2) +
  scale_color_okabeito()
```

## Gewöhnliche lineare Regression

(eng. *ordinary linear regression*)

```{r}
#| message: false
#| warning: false
basi_lm_fit <- lm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
```

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Scatterplot der Daten zur einfaktoriellen ANCOVA aufgetelt nach dem Geschlecht der Flöhe.
#| label: fig-stat-robust
emmip(basi_lm_fit, versuchsgruppe ~ block, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()
```

### ANOVA

```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  anova() %>% 
  model_parameters()
```

```{r}
pf(1.14, 9, 64, lower.tail = FALSE)
```

```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  eta_squared()
```

### Gruppenvergleich

```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  emmeans(specs = ~ versuchsgruppe | block) %>%
  cld(Letters = letters, adjust = "none") 
```

## Robuste Regression {#sec-robust-reg}

Bei einer robusten Regression werden jeder Beobachtung auf der Grundlage ihres Residuums unterschiedliche Gewichte (eng. *robustness weights*) von 0 bis 1 zugewiesen. Wir kennen ein Residuum als die Differenz zwischen den beobachteten und den vorhergesagten Werten der Daten. Die vorhergesagten Daten sind ja die Punkte auf der Geraden. Je kleiner also das Residuum ist, desto größer ist die Gewichtung und desto näher liegt eine Beobachtung an der geschätzten Geraden.

```{r}
#| message: false
#| warning: false
reg_tbl <- tibble(x = c(0, 1, 2, 3, 4, 5, 6, 7),
                  y = c(1, 1.5, 2.3, 2.8, 4.1, 5.3, 0, 6.8))
```

```{r}
#| message: false
#| warning: false
reg_lm_fit <- lm(y ~ x, reg_tbl)
reg_rlm_fit <- rlm(y ~ x, reg_tbl)
```

@fig-stat-robust-demo

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "Scatterplot für den Unterschied zwischen einer robusten und gewöhnlichen Regression. Die gewöhnliche Regression ist blau, die robuste Regression rot."
#| label: fig-stat-robust-demo
ggplot(reg_tbl, aes(x, y, label = x)) +
  theme_bw() +
  geom_label() +
  geom_line(aes(y = predict(reg_lm_fit)), color = cbbPalette[3]) +
  geom_line(aes(y = predict(reg_rlm_fit)), color = cbbPalette[7]) 

```

In unserem Beispiel ist die Beobachtung 6 der Ausreißer. In einer normalen Regression erhält diese Beobachtung sehr viel Gewicht. Die Gerade wird dadurch nach unten gezogen. In einer robusten Regression erhält eine Beobachtung mit einem großen Residuum sehr wenig Gewicht, in diesem konstruierten Beispiel fast 0. Daher können wir sagen, das unser Modell *robust* gegen Ausreißer ist.

Unbeliebt?

[History and unpopularity of robust regression](https://en.wikipedia.org/wiki/Robust_regression#History_and_unpopularity_of_robust_regression)

@stromberg2004write

Gibt es in biologischen Daten eigentlich überhaupt Ausreißer? Oder müssten wir nicht Ausreißer besonders betrachten, weil die Ausreßer dann doch mehr über die Daten verraten?

::: column-margin
Ein englisches Tutorium gibt es dann nochmal ausführlicher unter [R demo \| Robust Regression (don't depend on influential data!)](https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression/)

Ebenso liefert auch das Tutorium [Robust regression \| R data analysis example](https://stats.oarc.ucla.edu/r/dae/robust-regression/) einen Überblick.
:::

Es gibt noch das R Paket `robustbase` aber hier sind die Funktionen von `emmeans` nicht zugänglich.

$$
y \sim f_1 + f_2 + c_1
$$

$$
length \sim \overbrace{versuchsgruppe}^{f_1} + \underbrace{(time\_num)^3}_{c_1} + \overbrace{versuchsgruppe:(time\_num)^3}^{f_1:c_1}
$$

```{r}
#| message: false
#| warning: false
basi_rob_fit <- rlm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)

```

### ANOVA

Leider hilft hier die ANOVA nicht weiter. Aber wir können händisch rechnen.

```{r}
#| message: false
#| warning: false
basi_rob_fit %>% 
  anova() %>% 
  tidy()
```

```{r}
pf(3.4, 3, 12, lower.tail = FALSE)
```

```{r}
#| message: false
#| warning: false
basi_rob_fit %>% 
  eta_squared()
```

### Gruppenvergleich

```{r}
#| message: false
#| warning: false
basi_rob_fit %>% 
  emmeans(specs = ~ versuchsgruppe | block) %>%
  cld(Letters = letters, adjust = "none") 
```

## Quantilsregression {#sec-quantile-reg}

::: column-margin
Ein englisches Tutorium gibt es dann nochmal ausführlicher unter [Quantile Regression as an useful Alternative for Ordinary Linear Regression](https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression/)
:::

```{r}
#| message: false
#| warning: false
time_rq_fit <- rq(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, tau = 0.5,
                  gurke_time_len_tbl)
```

### ANOVA

Geht nicht

### Gruppenvergleich

Und eigentlich den Spezialfall der Median-Regression schauen wir uns an.

Dafür nutzen wir das R Paket `quantreg` und die Funktion `rq()`

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Scatterplot der Daten zur einfaktoriellen ANCOVA aufgetelt nach dem Geschlecht der Flöhe.
#| label: fig-stat-ancova-07
emmip(time_rq_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()
```

```{r}
#| message: false
#| warning: false

time_rq_fit %>% 
  emmeans(pairwise ~ versuchsgruppe | time_num, infer  = TRUE,
          adjust = "none", at = list(time_num = c(1, 7, 14))) %>%
  cld(Letters = letters, adjust = "none") 

```

## Modellvergleich

### Basilikumdaten

Für den Modellvergleich der gewöhnlichen, robusten und medianen Regression nutzen wir nochmal den Datensatz für das Basilikumwachstum. In einem ersten Schritt fitten wir wieder alle Modelle und achten darauf, dass wir bei der Quantilesregression angeben welches Quantile wir wollen. Wir wählen mit `tau = 0.5` dann den Median und rechnen so eine Medianregression.

```{r}
#| message: false
#| warning: false
basi_lm_fit <- lm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
basi_rlm_fit <- rlm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
basi_rq_fit <- rq(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl,
                  tau = 0.5)
```

Im Folgenden nutzen wir dann das fantastische Paket `modelsummary` mit der gleichnamigen Funktion um uns einmal die Modelle im Vergleich anzuschauen. Hier hilft dann wie immer die tolle [Hilfsseite von modelsummary](https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html) zu besuchen. Ich möchte nur nicht den Intercept und die Schätzer für die Blöcke haben, deshalb fliegen die hier einmal raus.

```{r}
modelsummary(lst("Ordinary" = basi_lm_fit,
                 "Robust" = basi_rlm_fit,
                 "Quantile" = basi_rq_fit),
             estimate  = "{estimate}",
             statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"),
             coef_omit = "Intercept|block")
```

Wie wir sehen sehen haben nicht alle Modelle die gleichen Informationen zurüch gegeben. Insbesondere das fehlen des Bestimmtheitsmaßes $R^2$ bei der robusten Regression ist schmerzlich, da wir hier dann nicht die Möglichkeit haben eine Aussage über die erklärte Varianz der robusten Regression zu treffen. Auch fehlt bei der Medianregression das adjustierte $R^2$, was die Nutzung bei Modellen mit mehr als einer Einflussvariable $x$ im Modell erschwert bis nutzlos macht. Daher bleibt uns am Ende nur das AIC oder BIC, wobei wir dort den kleinsten Wert als besser erachten. Die AIC und BIC Werte sind somit am besten für die Quantilesregression. Dafür ist dann aber der Fehler RMSE bei der gewöhnlichen Regression am niedrigsten. Und so stehe ich wieder davor und weiß nicht was das beste Modell ist. Hier müsste ich dann nochmal überlegen, ob ich lieber über Mittelwerte oder Mediane berichten möchte und das ist ohne die Forschungsfrage nicht hier zu lösen.

### Gurkendaten

```{r}
#| message: false
#| warning: false
time_lm_fit <- lm(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, gurke_time_len_tbl)
time_rlm_fit <- rlm(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, gurke_time_len_tbl)
time_rq_fit <- rq(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, tau = 0.5,
                  gurke_time_len_tbl)
```

Auch hier nutzen wir dann das fantastische Paket `modelsummary` mit der gleichnamigen Funktion um uns einmal die Modelle im Vergleich anzuschauen.

```{r}
modelsummary(lst("Ordinary" = time_lm_fit,
                 "Robust" = time_rlm_fit,
                 "Quantile" = time_rq_fit),
             estimate  = "{estimate}",
             statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"),
             coef_omit = "Intercept|time_num")
```

Hier sieht es ähnlich aus wie bei den Modellvergleichen von den Basilikumdaten. Nur hier wissen wir, dass wir Ausreißer in der Form von Gurken mit einer Länge von 0 cm in den Daten haben. Daher sehen wir auch, dass die robuste Regression und die Medianregression ein niedrigeres AIC und BIC haben. Für mich interessant ist, dass der Fehler RMSE wieder am kleinsten bei der gewöhnlichen Regression ist, das mag aber auch an der Berechnung liegen. Da wir Ausreißer haben, sind natürlich dann auch die robuste Regression und die Medianregression vorzuziehen. Da die Medianregression den kleineren AIC Wert hat, nehmen wir dann die Medianregression als die beste Regression an.

Vermutlich wäre es aber schlauer zuerst die Daten zu bereinigen und die Gurken mit einem Wachstum von 0 cm zu entfernen. Auch die anderen Wachstumskurven von anderen Gurken sind etwas wirr. Da müsste man auch nochmal ran und schauen, ob nicht die Gurken lieber aus der Analyse raus müssen. Am Ende ist dann natürlich die Frage, ob man die Daten dann nicht doch lieber über ein gemischtes Modell auswertet, da natürlich die Zeitpunkte voneinander abhängig sind. Aber wie immer im Leben, alles geht nicht.

## Referenzen {.unnumbered}
