```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, simstudy)
```

# Lineare gemischte Modelle {#sec-mixed}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-mixed.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Wer die Arbeit kennt und sich nicht drückt, der ist verrückt." --- Tick, Trick und Track*

::: callout-tip
## Einführung in die linearen gemischten Modelle per Video

Du findest auf YouTube [Lineare gemischte Modelle](https://youtu.be/54ba9cn3MeY) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Dieses Kapitel basiert auf dem tollen [Tutorium von Gabriela K Hajduk](https://ourcodingclub.github.io/tutorials/mixed-models/). Die Daten und Inhalte wurden von mir teilweise gekürzt sowie inhaltlich angepasst. Ideen und weitere Erklärungen sind auch beim [Tutorium von Sara Stoudt](https://rlbarter.github.io/Practical-Statistics/2017/03/03/fixed-mixed-and-random-effects/) zu finden. Als Literatur ist vor allem dann das sehr ausführliche Buch von @zuur2009mixed zu empfehlen.

## Annahmen an die Daten

Im folgenden Kapitel zu den linearen gemischten Modellen gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffällige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Das Thema Modellvergleich und Variablenselektion ist im Falle des linearen gemischten Modells nochmal etwas spezieller. Wir gehen hier auch nochmal in einem Abschnitt drauf ein, wie wir das hier in dem Fall von linearen gemischten Modellen machen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom, see, simstudy,
               multcomp, emmeans, lme4, broom.mixed, readxl,
               parameters, ggridges, scales, performance, 
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

In diesem fiktiven Datenbeispiel wollen wir uns die Testscores eines Intelligentest bei $N = 480$ Drachen anschauen. Wir sind dafür an acht Berge gefahren und haben die dortigen Drachen an den drei Flanken des Berges getestet. Daher hat der Faktor `mountain_range` acht Level mit Bavarian, Ligurian, Emmental, Central, Maritime, Southern, Julian, und Sarntal. Die drei Flanken des Berges bilden wir im Faktor `site` mit den Leveln north, east und south ab. In @fig-mountain-site sehen wir eine Skizze für drei Berge mit den jeweiligen Flanken, wo gemessen wurde.

![Beispiel für drei der acht Berge mit *Bavarian*, *Central* und *Julian*. Auf jeden der acht Berge wurden an drei Seiten *north*, *east* und *south* die Testscores der dort lebenden Drachen erhoben.](images/mountain.png){#fig-mountain-site fig-align="center" width="90%"}

Die Daten liegen in dem Datensatz `dragons.csv` ab. Wir müssen aber noch einen Faktor `body_length_cat` bilden in dem wir die `body_length` der einzelnen Drachen in Kategorien umwandeln. Wir wollen später noch Gruppenvergleiche rechnen und brauchen daher einen Faktor mit Leveln. Daher nutzen wir die Funktion `case_when()` um einen Faktor mit fünf Größenkategorien zu bilden. Danach müssen wir wie immer noch die `character` Spalten in die entsprechenden Faktoren umwandeln.

```{r}

dragons_tbl <- read.csv2("data/dragons.csv") %>% 
  as_tibble() %>% 
  mutate(body_length_cat = 
           case_when(body_length < 170 ~ "tiny",
                     body_length >= 170 & body_length < 180 ~ "small",
                     body_length >= 180 & body_length < 200 ~ "medium",
                     body_length >= 200 & body_length < 220 ~ "large",
                     body_length >= 220 ~ "gigantic"),
         body_length_cat = as_factor(body_length_cat),
         mountain_range = as_factor(mountain_range),
         site = factor(site, labels = c("north", "east", "south"))) %>% 
  select(test_score, body_length, body_length_cat, everything())

```

Es ergibt sich dann der Datensatz wie in @tbl-dragon gezeigt. Wir belassen die Körperlänge der Drachen in der kontinuierlichen Form nochmal mit in den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-dragon
#| tbl-cap: Datensatz der Testscores für die Drachen auf verschiedenen Bergen und dort an verschiedenen Flanken der Berge.

dragons_raw_tbl <- dragons_tbl %>% 
  mutate(body_length_cat = as.character(body_length_cat),
         mountain_range = as.character(mountain_range),
         site = as.character(site))

rbind(head(dragons_raw_tbl, n = 4),
      rep("...", times = ncol(dragons_raw_tbl)),
      tail(dragons_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Bevor wir mit dem Modellieren beginnen, wollen wir erstmal visuell überprüfen, ob unser Outcome $y$ mit dem Testscore auch normalverteilt ist. Wir benötigen für das *klaissche* lineare gemischte Modell ein normalverteiltes Outcome $y$. In @fig-mixed-1 sehen wir das Histogramm der Verteilung des Testscores für alle $N = 480$ Drachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-1

ggplot(dragons_tbl, aes(test_score)) +
  geom_histogram() +
  theme_bw() 
```

Wir können in der @fig-mixed-2 auch nochmal schauen, ob die Annahme der annährenden Normalverteilung für unseren Testscore auch für jedes Level unseres Faktors der Körperlängen gegeben ist. Wir sehen auch hier, dass der Testscore einer Normalverteilung über alle Kategorien der Körperlänge folgt.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores aufgeteilt nach Kategorie der Körpergröße zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores für alle Kategorien der Körpergröße.
#| label: fig-mixed-2

ggplot(dragons_tbl, aes(y = body_length_cat, x = test_score, fill = body_length_cat)) +
  theme_bw() +
  stat_density_ridges() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Natürlich können wir uns hier noch weitere Abbildungen erstellen, aber hier soll es erstmal reichen. Wir sehen, dass der Testscore einer Normalverteilung folgt und dass die Varianzen vermutlich homogen sind, da die Histogramme ungefähr gleich breit sind. Ja, ein wenig unterscheiden sich die Verteilungen, aber so gravierend ist es erstmal nicht.

## Modellierung

Im Folgenden wollen wir uns verschiedene statistische Modelle anschauen um uns dem linearen gemischten Modell einmal anzunähern. Dabei beginnen wir mit einem simplen Gaussian lineare Modell mit einem Faktor $f_1$:

$$
y \sim f_1
$$

Wir haben also nur einen Faktor in unserem Modell vorliegen und ignorieren die restlichen in den Daten vorhandenen Variablen.

Als zweites Modell betrachten wir eine multiples Gaussian lineares Modell mit einem Faktor $f_1$ und einem Blockfaktor $b_1$:

$$
y \sim f_1 + b_1
$$

Jetzt erweitern wir das Modell nochmal um einen Block oder auch Clustereffekt. Das heißt, wir haben alle Beobachtungen nicht auf einem Feld oder in einem Stall durchgeführt, sondern an mehreren Orten.

Der eigentliche Bruch kommt jetzt. Wie wollen wir den Effekt des Blocks betrachten? Hier entscheidet sich, ob wir den Block als festen Effekt (eng. *fixed effect*) oder als zufälligen Effekt (eng. *random effect*) ausweisen wollen. Zuerst ist dies eine Modellierungsentscheidung. Wir müssen uns also zwischen zwei Modellen entscheiden. Daher können wir auch beide Arten bauen und dann Modelle vergleichen. Machen wir dann auch am Ende des Kapitels.

Die Idee hinter dem Modell mit **festen Effekten** ist, dass die beobachteten Effektgrößen von Block zu Block variieren können, was aber nur auf den Stichprobenfehler $\epsilon$ zurückzuführen ist. In Wirklichkeit sind die wahren Effektgrößen alle gleich: Sie sind fix. (siehe auch [The Fixed-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#fem))

Das Modell der **zufälligen Effekte** geht davon aus, dass es nicht nur eine wahre Effektgröße gibt, sondern eine Verteilung der wahren Effektgrößen. Das Ziel des Modells mit zufälligen Effekten ist es daher nicht, die eine wahre Effektgröße aller Studien zu schätzen, sondern den Mittelwert der Verteilung der wahren Effekte. (siehe auch [The Random-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem))

Lineare gemischte Modelle schätzen die subjektspezifischen Auswirkungen (eng. *subject-specific*). Betrachten wir dabei die folgenden zwei Szenarien nach @allison2009fixed:

-   *Szenario 1:* Du bist ein Arzt. Du möchtest wissen, um wie viel ein Cholesterinmedikament die Wahrscheinlichkeit eines Herzinfarkts bei deinem Patienten senkt.
-   *Szenario 2:* Du bist ein staatlicher Gesundheitsbeamter. Du möchtest wissen, wie sich die Zahl der Menschen, die an einem Herzinfarkt sterben, verändern würde, wenn alle Menschen in der Risikogruppe das Cholesterinmedikament einnehmen würden.

Im ersten Szenario wollen wir die subjektspezifischen (eng. *subject-specific*) Chancen wissen. Im zweiten Fall sind wir an der Vorhersage für die gesamte Bevölkerung interessiert. Lineare gemischte Modelle können uns Schätzungen für das erste, aber nicht für das zweite Szenario liefern.

Daher kommt jetzt als drittes Model ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor $f_1$ und einem zufälligen Blockfaktor $z_1$:

$$
y \sim f_1 + 1|z_1
$$

Wir schreiben in R den Term für da zufällige Modell in der Form $z_0|z_1$. Meist setzen wir den Intercept $z_0$ für den zufälligen Effekt auf `1`.

Abschießend schauen wir uns noch ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor $f_1$ und einem zufälligen Blockfaktor $z_2$ genested in einem einem zufälligen Blockfaktor $z_1$:

$$
y \sim f_1 + 1|z_1/z_2
$$

Das heißt, dass der zufällige Blockfaktor $z_2$ in den zufälligen Blockfaktor $z_1$ genested ist. Das heist, die Faktorlevel des Blockfaktors $z_2$ finden sich jeweils nur in jeweils einem der Faktorlevel des Blocks $z_1$. Das klingt jetzt etwas schräg, also einmal ein Beispiel. Wir haben eine Schule, dann sind die Schulklassen dieser Schule in der Schule genested. Es gibt diese spezifischen Klassen mit den Schülern schlichtweg nicht in anderen Schulen. Wir sagen *nested*, wenn wir meinen, dass ein Faktor in einen anderen Faktor verschränkt ist. Die Klassen einer Schule sind in der Schule genested.

Bevor wir jetzt mit dem Modellieren beginnen, müssen wir noch kurz in einem QQ-Plot schauen, ob unser Ourcome `testscore` auch ungefähr normalverteilt ist. @fig-mixed-6 zeigt den QQ-Plot des Testscores. Wir sehen, dass der Hauptteil der Beobachtungen auf der Geraden liegt und wir nehmen daher an, dass der Testscore zumindest approximativ normalverteilt ist. Wir können also mit einem gaussian linearen gemischten Modell weitermachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: QQ-Plot zu Überprüfung, ob der Testscore einer Normalverteilung folgt. Die Punkte liegen ungefähr auf der Geraden als Winkelhalbierende, so dass wi eine Normalverteilung des Testscores annehmen können.
#| label: fig-mixed-6

ggplot(dragons_tbl, aes(sample = test_score)) +
  stat_qq() + stat_qq_line(color = "red") +
  theme_bw() +
  scale_color_okabeito()
```

Schauen wir uns nun als erstes das Modell `lm_simple_fit` einmal an. Wir bauen das Modell nur mit der Faktorvariable `body_length_cat`. Wir erhalten dann gleich die Ausgabe des Modells über die Funktion `model_parameters()` in einer aufgearbeiteten Form.

```{r}
#| message: false
#| warning: false

lm_simple_fit <- lm(test_score ~ body_length_cat, data = dragons_tbl)

lm_simple_fit %>% model_parameters()

```

Der Intercept beinhaltet den Mittelwert für die Drachen des Levels `[tiny]`. Die jeweiligen Koeffizienten dann die Abweichung von den Drachen des Levels `[tiny]`. Daher sind Drachen des Levels `[small]` ungefähr um $2.63$ Einheiten intelligenter. Wir sehen dann an dem $p$-Wert, ob sich die Koeffizienten signifikant von 0 unterscheiden. In @fig-mixed-3 sehen wir nochmal die Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße. Wir erkennen, dass die kleineren Drachen tendenziell dümmer sind als die großen Drachen. Wir sehen zwei Plateaus.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße.
#| label: fig-mixed-3

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = body_length_cat)) +
  theme_bw() +
  geom_boxplot() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Nun haben wir aber nicht nur die Körpergrößen gemessen sondern auch auf welchem Berg wir die jeweiligen Drachen gefunden haben. Nun könnte es sein, dass der Berg einen viel größeren Einfluss auf die Inteliegenz hat als die Drachenkörpergröße. Wir könnten einen Confoundereffekt durch die Berge vorliegen haben. Ergänzen wir also das Modell um den Faktor `mountain_range` und erhalten das Modell `lm_mountain_fit`.

```{r}
#| message: false
#| warning: false

lm_mountain_fit <- lm(test_score ~ body_length_cat + mountain_range, data = dragons_tbl)
lm_mountain_fit %>% model_parameters()
```

Wie wir sehen, werden nun die Körpergrößen der Drachen nicht mehr als signifikant ausgegeben. Die Effekte der Körpergröße auf den Testscore sind auch viel kleiner geworden, wenn wir die `mountain_range` mit in das Modell nehmen. Anscheinend hat der Berg auf dem wir den Drachen getroffen haben einen viel größeren Einfluss auf die Intelligenz als die Körpergröße. Wir können uns den Zusammenhang zwischen dem Testscore und dem Berg auch in der @fig-mixed-4 einmal anschauen.

Eigentlich würden wir erwarten, dass es keinen Effekt der Berge auf den Testscore der Drachen gibt. Es müsste eigentlich egal sein, wo wir einen Drachen befragen, wenn wir nur an der Körpergröße und dem Testscore interessiert sind. Wir sehen jedoch in der @fig-mixed-4 einen klaren Unterschied zwischen den Bergen im Bezug auf den Testscore.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung.
#| label: fig-mixed-4

ggplot(dragons_tbl, aes(mountain_range, test_score, fill = mountain_range)) +
  geom_boxplot() +
  theme_bw() +
  theme(legend.position = "none") +
  scale_fill_okabeito()
```

In der @fig-mixed-5 sehen wir den Zusammenhang von Testscore und der Körpergröße sowie den Bergen auf denen das Interview stattgefunden hat. so langsam dämmert uns warum wir hier einen Effekt der Körperlänge zu dem Testscore sehen. Die kleineren Drache sind alle nur auf bestimmten Bergen zu finden! Betrachten wir die Berge mit in dem Modell, dann hat die Körpergröße keinen Einfluß mehr.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße.
#| label: fig-mixed-5

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain")
```

Der Zusammenhang wird vielleicht in @fig-mixed-7 nochmal klarer. Hier schauen wir uns den Zusamenhang wieder für die Körperlänge getrennt für die Berge an. Nur zeichnen wir jetzt jeden einzelnen Berg in ein Subplot. Wir sehen, dass es hier fast keinen Unterschied macht, wie lang die Drachen sind. Der Testscore ist immer gleich. Was einen Unterschied macht, sind die Berge.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße in getrennten Subplots.
#| label: fig-mixed-7

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain") +
  theme(legend.position = "none") +
  facet_wrap(~ mountain_range) 
```

Schauen wir uns nun einmal ein lineares gemischtes Modell an. Wir nutzen daszu das R Paket `{lme4}`. Wir haben auch noch andere Pakete zur Aswahl, aber wir nutzen hier erstmal das gängiste Paket. Um ein lineares gemischtes Modell in R zu schätzen nutzen wir die Funktion `lmer()`. Die Funktion `lmer()` nimmt an, dass das Outcome `test_score` normalverteilt ist. Wir haben diese Annahme ja weiter oben in dem QQ-Plot überprüft.

In einem lineare gemischten Modell müssen wir die *festen* Effekte sowie die *zufälligen* Effekte definieren. Die festen Effekte werden ganz normal wie wir es gewohnt sind in das Modell eingegeben. Die zufälligen Effkete schreiben wir in eine Klammer in der Form `(1|)`.

Wir schreiben `(1|moutain_range)` und definieren damit die Variable `mountain_range` als zufälligen Effekt im Modell. Wir schreiben `1|` vor `mountain_range`, da wir für jeden Berg die gleiche Steigung von Körperlänge und Testscore annehmen. Wir können dann später noch das Model komplizierter aufbauen und jedem Berg eine eigene Steigung erlauben. Bauen wir uns jetzt erstmal ein lineares gemischtes Modell mit einem festen Effekt `body_length_cat` und einem zufälligen Effekt `(1|mountain_range)`.

```{r}
#| message: false
#| warning: false

lmer_1_fit <- lmer(test_score ~ body_length_cat + (1 | mountain_range), data = dragons_tbl)
lmer_1_fit %>% model_parameters()
```

Unser Model sieht etwas aufgeräumter aus. Als feste Effekte haben wir nur noch die Körperlänge `body_length_cat` und die dazugehörigen Koeffizienten des Modells. Unsere Variable `mountain_range` verschwindet dann in den zufälligen Effekten. Die Funktion `summary` liefert uns den gesamten Ausdruck, der etwas überwältigend ist. Vieles brauchen wir auch nicht davon.

```{r}
#| message: false
#| warning: false
#| eval: false

lmer_1_fit %>% summary()
```

![](images/lmer_summary.png){fig-align="center" width="90%"}

Was wir extrahieren wollen ist die Information von den zufälligen Effekten. Wir wollen wissen, wieviel Varianz durch die zufälligen Effekte erklärt wird. Wir nutzen dazu die Funktion `VarCorr()`, die uns erlaubt die Information zu en zufälligen Effekten zu extrahieren und auszugeben.

```{r}
print(VarCorr(lmer_1_fit), comp = "Variance")
```

Wieviel Varianz erklären nun die Berge? Wir können die erklärte Varianz der zufälligen Effekte einfach berechnen. Wir vergleichen die erklärte Varianz von `mountain_range` mit der gesamten Varianz. Die gesamte Varianz ist die Varianz aller zufälligen Effekte plus der residualen Vamrianz. Wir erhalten dann $R^2_{random} = 339.7/(339.7 + 223.8) \approx 0.60$. Wir sehen, dass ca. 60% der Varianz in unseren Daten von der Variable `mountain_range` verursacht wird.

Wir können die Funktion `model_performance()` nutzen um mehr über den Fit des Modells zu erfahren. Das `R2 (cond.)` ist faktisch das gleiche wie wir gerade oben berechnet haben. Wir benötigen also nicht immer den Ausdruck der zufälligen Effekte. Wir können auch die Informationen aus der Funktion `model_performance()` nehmen.

```{r}
lmer_1_fit %>% model_performance()
```

In der Abbildung @fig-mixed-8 schauen wir uns nochmal an, ob wir das Modell auch gut gefittet haben. Der Residualplot sieht gut aus, wir erkennen kein Muster. Ebenso sieht der QQ-Plot gut aus, die Beobachtungen liegen alle auf der Geraden. Wir sind mit dem Modell soweit erstmal ganz zufrieden.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-mixed-8
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Visuelle Überprüfung des Modells mit dem Residual und QQ-Plot."
#| fig-subcap: 
#|   - "Residualplot"
#|   - "QQ-Plot"
#| layout-nrow: 1
#| column: page

augment(lmer_1_fit) %>% 
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  scale_color_okabeito()

ggplot(tibble(.resid = resid(lmer_1_fit)), aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw()
```

Wir haben noch eine Variable in unseren Daten ignoriert. Wir haben uns bis jetzt nicht die Variabl `site` angeschaut. Auf jedem Berg haben wir die Drachen noch auf verschiedenen Flanken des Berges `site` befragt. Das heißt, wir haben die Variable `site`, die in der Variable `mountain_site` genestet ist. Wir schreiben daher ein neues Modell und nutzen die Schreibweise `(1|mountain_range/site)` um zu beschreiben, dass `site` immer zusamen in einem Berg vorkommt. Schaue dir dazu nochmal die Abbidlung ganz zu Beginn dieses Kapitels an um die Zusammenhänge nochmal visualisiert zu bekommen.

```{r}
#| message: false
#| warning: false

lmer_2_fit <- lmer(test_score ~ body_length_cat + (1|mountain_range/site), data = dragons_tbl) 
lmer_2_fit %>% model_parameters()
```

Das Modell hat nun einen weiteren zufälligen Effekt. Es werden jetzt auch nochmal für jeden Berg die Flankeneffekte mit berücksichtigt. Hat das überhaupt einen Einfluss auf das Modell? Schauen wir uns einmal die Modellgüte mit der Funktion `model_performance()` an.

```{r}
#| message: false
#| warning: false

lmer_2_fit %>% model_performance()
```

Wir sehen, dass sich die erklärte varianz leicht erhöht hat. Die $R^2_{random}$ liegt jetzt bei $0.623$ also fast 62%. Etwas besser als vorher, aber auch nicht unbedingt sehr viel mehr.

Wie können wir nun unsere vier Modelle miteinander vergleichen? Wir haben ja folgende Modelle vorliegen:

-   Das simple lineare Modell `lm_simple_fit` mit `test_score ~ body_length_cat`.
-   Das multiple lineare Modell `lm_mountain_fit` mit `test_score ~ body_length_cat + mountain_range`.
-   Das gemischte lineare Modell `lmer_1_fit` mit `test_score ~ body_length_cat + (1|mountin_range)`.
-   Das genestete gemischte lineare Modell `lmer_2_fit` mit `test_score ~ body_length_cat + (1|mountain_range/site)`.

Um die Modelle miteinander zu vergleichen können wir die Funktion `compare_performance()` nutzen. Wir erhalten mit der Option `rank = TRUE` auch eine Sortierung der Modelle wieder. Das beste Modell steht dann ganz oben.

```{r}
#| message: false
#| warning: false

compare_performance(lm_simple_fit, lm_mountain_fit, lmer_1_fit, lmer_2_fit, rank = TRUE)
```

In diesem Beispiel wäre sogar eine multiple lineare Regression das beste Modell. Wir würden also auch mit zwei festen Effekten die Variabilität der Berge richtig modellieren. Der Effekt der Flanken auf den Testscore scheint ziemlich klein zu sein, so dass wir auch auf die Variable `site` verzichten können.

## Gruppenvergleich {#sec-mult-comp-lmer-reg}

![](images/caution.png){fig-align="center" width="50%"}

text

`{simstudy}`

```{r}

gen.school <- defData(varname = "nClasses", dist = "nonrandom", formula = 3,
    id = "idSchool")
gen.school <- defData(gen.school, varname = "s0", dist = "normal", formula = 0, variance = 3)
```

```{r}
set.seed(282721)

dtSchool <- genData(9, gen.school)
dtSchool <- trtAssign(dtSchool, n = 3)

dtSchool
```

text

```{r}
gen.class <- defDataAdd(varname = "nStudents", dist = "noZeroPoisson", formula = 20)
gen.class <- defDataAdd(gen.class, varname = "c0", dist = "normal", formula = 0, variance = 2)
```

```{r}
dtClass <- genCluster(dtSchool, "idSchool", numIndsVar = "nClasses", level1ID = "idClass")
dtClass <- addColumns(gen.class, dtClass)

head(dtClass, 10)
```

text

```{r}
gen.student <- defDataAdd(varname = "Male", dist = "binary",
    formula = 0.5)
gen.student <- defDataAdd(gen.student, varname = "age", dist = "uniform",
    formula = "9.5; 10.5")
gen.student <- defDataAdd(gen.student, varname = "test", dist = "normal",
    formula = "50 - 5*Male + s0 + c0 + 8 * trtGrp", variance = 2)
dtStudent <- genCluster(dtClass, cLevelVar = "idClass", numIndsVar = "nStudents",
    level1ID = "idChild")

dtStudent <- addColumns(gen.student, dtStudent) %>% 
  mutate(idClass = as_factor(idClass),
         idSchool = as_factor(idSchool),
         trtGrp = as_factor(trtGrp)) 
```

```{r}
dtStudent %>% 
  mutate(idClass = as_factor(idClass),
         idSchool = as_factor(idSchool),
         trtGrp = as_factor(trtGrp)) %>% 
  ggplot(aes(idClass, test, fill = idSchool, linetype = trtGrp, color = trtGrp)) +
  theme_bw() +
  geom_boxplot()


dtStudent %>% 
  mutate(idClass = as_factor(idClass),
         idSchool = as_factor(idSchool),
         trtGrp = as_factor(trtGrp)) %>% 
  ggplot(aes(trtGrp, test, fill = idSchool, group = idClass)) +
  theme_bw() +
  geom_boxplot()
```

::: panel-tabset
## `lmer`

```{r}
lmer_fit <- lmer(test ~ trtGrp + (1|idSchool) + (1|idClass), data = dtStudent) 

lmer_fit2 <- lmer(test ~ trtGrp + (1|idClass/idSchool), data = dtStudent) 

compare_performance(lmer_fit, lmer_fit2, rank = TRUE)


lmer_fit %>% 
  model_performance()

lmer_fit %>% 
  emmeans(~ trtGrp) %>% 
  pairs()

lmer_fit %>% anova

```

## `lm`

```{r}
lm_fit <- lm(test ~ trtGrp + idSchool + idClass, data = dtStudent) 

lm_fit %>% 
  model_performance()

lm_fit %>% 
  emmeans(~ trtGrp) %>% 
  pairs()

lm_fit %>% anova
```
:::

::: callout-tip
## Anwendungsbeispiel: Dreifaktorieller Gruppenvergleich für das Gewicht

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit Brokkoli an. Wir haben uns in diesem Experiment verschiedene Dosen `fert_amount` von einem Dünger aufgebracht sowie verschiedene Zeitpunkte der Düngung `fert_time` berücksichtigt. Auch hier haben wir einige Besonderheiten in den Daten, da nicht jede Faktorkombination vorliegt. Wir ignorieren aber diese Probleme und rechnen einfach stumpf unseren Gruppenvergleich.

```{r}
broc_tbl <- read_excel("data/broccoli_weight.xlsx") %>% 
  mutate(fert_time = factor(fert_time, levels = c("none", "early", "late")),
         fert_amount = as_factor(fert_amount),
         block = as_factor(block)) %>%
  select(-stem_hollowness) 
```

Dann können wir auch schon die Gaussian Regression mit `lm()` rechnen.

```{r}
lm_fit <- lm(weight ~ fert_time + fert_amount + fert_time:fert_amount + block, 
             data = broc_tbl) 
```

Jetzt rechnen wir in den beiden folgenden Tabs einmal die ANOVA und dann auch den multiplen Gruppenvergleich mit `{emmeans}`. Da wir hier normalveteilte Daten haben, können wir dann einfach die Standardverfahren nehmen. Eventuell müssten wir bei dem Gruppenvergleich mit `emmeans()` nochmal für Varianzheterogenität adjustieren, aber da erfährst du dann mehr in dem Kapitel zu den [Multiple Vergleichen oder Post-hoc Tests](#sec-posthoc).

::: panel-tabset
## ANOVA mit `anova()`

Wir rechnen hier einmal die ANOVA und nutzen den $\mathcal{X}^2$-Test für die Ermittelung der p-Werte. Wir müssen hier einen Test auswählen, da per Standardeinstellung kein Test gerechnet wird. Wir machen dann die Ausgabe nochmal schöner und fertig sind wir.

```{r}
lm_fit %>% 
  anova() %>% 
  model_parameters()
```

Wir sehen, dass der Effekt der Düngerzeit und die Menge des Düngers signifikant ist, jedoch wir keinen signifikanten Einfluss durch die Interaktion haben. Wir haben aber also keine Interaktion vorliegen. Leider ist auch der Block signifikant, so dass wir eigentlich nicht über den Block mitteln sollten. Wir rechnen trotzdem die Analyse gemittelt über die Blöcke. Wenn du hier mehr erfahren möchtest, dann schaue dir das Beispiel hier nochmal im Kapitel zu dem [linearen gemischten Modellen](#sec-mixed) an.

## Gruppenvergleich mit `emmeans()`

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `fert_time` und `fert_amount` einen Gruppenvergleich. Dafür nutzen wir die Option `fert_time * fert_amount`. Wenn du die Analyse *getrennt* für die Menge und den Zeitpunkt durchführen willst, dann nutze die Option `fert_time | fert_amount`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- lm_fit %>% 
  emmeans(~ fert_time * fert_amount) %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `emmean` stellt den mittleren Gewicht des Brokkoli je Faktorkombination dar gemittelt über alle Blöcke. Das Mitteln über die Blöcke ist eher fragwürdig, da wir ja einen Effekt der Blöcke in der ANOVA gefunden hatten. Hier schauen wir dann nochmal auf das Beispiel im Kapitel zu den [linearen gemischten Modellen](#sec-mixed). Dann können wir zum Abschluss auch das *compact letter display* anhand der Abbildung interpretieren.
:::

In der @fig-log-mod-gaussian-broc siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Wir sehen einen klaren Effekt der Düngezeitpunkte sowie der Düngermenge auf das Gewicht von Brokkoli. Wenn wir ein mittleres Gewicht von $500g$ für den Handel erreichen wollen, dann erhalten wir das Zielgewicht nur bei einer Düngemenge von $300mg/l$. Hier stellt sich dann die Frage, ob wir bei $225mg/l$ und einem frühen Zeitpunkt der Düngung nicht auch genug Brokkoli erhalten. Das Ziel ist es ja eigentlich in einen Zielbereich zu kommen. Die Köpfe sollen ja nicht zu schwer und auch nicht zu leicht sein. Aber diese Frage und andere Fragen der biologischen Anwendung lassen wir dann hier einmal offen, denn das Beispiel soll ja nur ein Beispiel sein.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-gaussian-broc
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mittleren Brokkoligewichte aus einer Gaussian Regression. Das `lm()`-Modell berechnet das mittler Gewicht des Brokkoli in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert. Wir nutzen hier den Standardfehler, da die Standardabweichung mit der großen Fallzahl rießig wäre. Wir haben noch ein Mindestgewicht von 500g ergänzt."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = fert_time, y = emmean, fill = fert_amount)) +
  theme_bw() + 
  labs(y = "Mittleres Gewicht [g] des Brokkoli", x = "Düngezeitpunkt",
       fill = "Düngemenge [mg/l]") +
  scale_y_continuous(breaks = seq(0, 500, by = 100)) +
  geom_hline(yintercept = 500, size = 0.75, linetype = 2) +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = .group, y = emmean + SE + 0.01),  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = emmean-SE, ymax = emmean+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

::: callout-tip
## Anwendungsbeispiel: Dreifaktorieller Gruppenvergleich für Thripsenbefall

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit jungen Apfelbäumen an. Wir haben uns in diesem Experiment verschiedene Dosen `trt` von einem Insektizid aufgebracht sowie verschiedene Startanzahlen von Raubmilben als biologische Alternative untersucht. Dann haben wir noch fünf Zeitpunkte bestimmt, an denen wir die Anzahl an Thripsen auf den Blättern gezählt haben. Wir haben nicht die Blätter per se gezählt sondern Fallen waagerecht aufgestellt. Dann haben wir geschaut, wie viele Thripsen wir über `above` und unter `below` von den Fallen gefunden haben. In unserem Fall beschränken wir uns auf die obere Anzahl an Thripsen und schauen uns auch nur die Behandlung mit dem Insektizid an.

```{r}
insects_tbl <- read_excel("data/insects_count.xlsx") %>% 
  mutate(timepoint = factor(timepoint, labels = c("1 Tag", "4 Tag", "7 Tag", "11 Tag", "14 Tag")),
         rep = as_factor(rep),
         trt = as_factor(trt)) %>%
  select(timepoint, trt, rep, thripse = thripse_above, mite = mite_above) %>% 
  filter(trt %in% c("10ml", "30ml", "60ml"))
```

Dann können wir auch schon die Poisson Regression mit `glm()` rechnen. Auch hier wieder darauf achten, dass wir dann als Option `family = poisson` oder `family = quasipoisson` wählen. Es hängt jetzt davon ab, ob du in deinen Daten Overdispersion vorliegen hast oder nicht. In den beiden folgenden Tabs, rechne ich dann mal beide Modelle.

::: panel-tabset
## `family = poisson`

Als Erstes rechnen wir eine normale Poisson Regression und schauen einmal, ob wir Overdispersion vorliegen haben. Wenn wir Overdispersion vorliegen haben, dann können wir keine Poisson Regression rechnen, sondern müssen auf eine Quasipoisson Regression ausweichen. Das ist aber sehr einfach, wie du im anderen Tab sehen wirst.

```{r}
insects_poisson_fit <- glm(thripse ~ trt + timepoint + trt:timepoint, 
                           data = insects_tbl, 
                           family = poisson) 
```

Bevor wir uns das Modell mit `summary()` überhaupt anschauen, wollen wir erstmal überprüfen, ob wir überhaupt Overdispersion vorliegen haben. Wenn ja, dann können wir uns die `summary()` hier gleich sparen. Also einmal geguckt, was die Overdispersion macht.

```{r}
insects_poisson_fit %>% check_overdispersion()
```

Wir haben sehr starke Overdispersion vorliegen und gehen daher rüber in den anderen Tab und rechnen eine Quasipoisson Regression. Nur wenn du keine Overdispersion vorliegen hast, dann kannst du eine eine Poisson Regression rechnen.

## `family = quasipoisson`

Entweder hast du in deinen Daten eine Overdispersion gefunden oder aber du meinst, es wäre besser gleich eine Quasipoisson zu rechnen. Beides ist vollkommen in Ordnung. Ich rechne meistens immer eine Quasipoisson und schaue dann nur, ob die Overdispersion sehr groß war. In den seltensten Fällen hast du eine Overdispersion vorliegen, die eher klein ist. Daher mache ich erst die Lösung und schaue, ob das Problem dann da war.

```{r}
insects_quasipoisson_fit <- glm(thripse ~ trt + timepoint + trt:timepoint, 
                                data = insects_tbl, 
                                family = quasipoisson) 
```

Du kannst in der `summary()` Ausgabe direkt sehen, ob du Overdispersion vorliegen hast. Du musst nur relativ weit unten schauen, was zu dem `Dispersion parameter` in den Klammern geschrieben ist. Wenn da eine Zahl größer als 1 drin steht, dann hast du Overdispersion.

```{r}
insects_quasipoisson_fit %>% 
  summary()
```

Wir haben hier auf jeden Fall Overdispersion vorliegen. Daher nutze ich dann auch das Modell hier mit der Annahme an eine Quasipoissonverteilung. Dann stimmt es auch mit unseren Varianzen und wir produzieren nicht zufällig zu viele signifikante Ergebnisse, die es dann gar nicht gibt.
:::

Ich habe mich gerade in den obigen Tabs für eine Quasipoisson Regression entschieden, da wir Overdispersion vorliegen haben. Damit mache ich dann mit dem `insects_quasipoisson_fit` Modell weiter. In den beiden folgenden Tabs findest du dann einmal das Ergebnis für die ANOVA und einmal für den Gruppenvergleich mit dem R Paket `{emmeans}`. Bitte beachte, dass die ANOVA für ein `glm()`-Objekt nicht ganz gleich wie für ein `lm()`-Objekt ist. Du kannst aber die ANOVA erstmal ganz normal interpretieren, nur haben wir hier nicht die Möglichkeit ein $\eta^2$ zu bestimmen. Dann nutzen wir `{emmeans}` für den Gruppenvergleich. Nochmal, weil wir Overdispersion festgestellt haben, nutzen wir das Objekt `insects_quasipoisson_fit` mit der Berücksichtigung der Overdispersion.

::: panel-tabset
## ANOVA mit `anova()`

Wir rechnen hier einmal die ANOVA und nutzen den $\mathcal{X}^2$-Test für die Ermittelung der p-Werte. Wir müssen hier einen Test auswählen, da per Standardeinstellung kein Test gerechnet wird. Wir machen dann die Ausageb nochmal schöner und fertig sind wir.

```{r}
insects_quasipoisson_fit %>% 
  anova(test = "Chisq") %>% 
  model_parameters(drop = "NULL")
```

Wir sehen, dass der Effekt für die Behandlung signifikant ist, jedoch die Zeit und die Interaktion keinen signifikanten Einfluss haben. Wir haben aber also keine Interaktion vorliegen. Daher können wir dann die Analyse gemeinsam über alle Zeitpunkte rechnen.

## Gruppenvergleich mit `emmeans()`

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `trt` und `timepoint` einen Gruppenvergleich. Dafür nutzen wir die Opition `trt * timepoint`. Wenn du die Analyse *getrennt* für die Zeitpunkte durchführen willst, dann nutze die Option `trt | timepoint`. Wir wollen die Wahrscheinlichkeiten für das Auftreten einer Beschädigung von wiedergegeben bekommen, deshalb die Option `regrid = "response`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- insects_quasipoisson_fit %>% 
  emmeans(~ trt * timepoint, regrid = "response") %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `rate` stellt die mittlere Anzahl an Thripsen je Faktorkombination dar. Dann können wir auch das *compact letter display* anhand der Abbildung interpretieren.
:::

In der @fig-log-mod-pois-insect siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Hier unbedingt `SE` als den Standardfehler für die Fehlerbalken nutzen, da wir sonst Fehlerbalken größer und kleiner als $0$ erhalten, wenn wir die Standardabweichung nutzen würden. Das ist in unserem Fall nicht so das Problem, aber wenn du eher kleine Anzahlen zählst, kann das schnell zu Werten kleiner Null führen. Wir sehen einen klaren Effekt der Behandlung `60ml`. Die Zeit hat keinen Effekt, was ja schon aus der ANOVA klar war, die Säulen sehen für jeden Zeitpunkt vollkommen gleich aus. Gut etwas Unterschied ist ja immer.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-pois-insect
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mitleren Zahl der Thripsen aus einer Poisson Regression. Das `glm()`-Modell berechnet die mittlere Anzahl in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = timepoint, y = rate, fill = trt)) +
  theme_bw() + 
  labs(y = "Mittlere Anzahl an Thripsen", x = "Messzeitpunkte der Zählungen",
       fill = "Dosis") +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = .group, y = rate + SE + 0.01),  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = rate-SE, ymax = rate+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

## Referenzen {.unnumbered}
