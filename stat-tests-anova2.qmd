```{r echo = FALSE}
#| message: false
#| echo: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, plyr,
               patchwork, ggforce, see, sjPlot, tinytable, conflicted)
set.seed(202434)
conflicts_prefer(dplyr::summarise)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(magrittr::set_names)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| cache: false
#| label: source-anova-plots
source("stat-tests-anova_plot/anova_plots.R")
```

# Die ANOVA {#sec-anova}

*Letzte Änderung am `r format(fs::file_info("stat-tests-anova2.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Yeah, I might seem so strong; Yeah, I might speak so long; I've never been so wrong." --- London Grammar, Strong*

Die ANOVA (eng. *analysis of variance*) ist wichtig. Was für ein schöner Satz um anzufangen. Historisch betrachtet ist die ANOVA, *das* statistische Verfahren was gut per Hand ohne Computer berechnet werden kann. Daher war die ANOVA von den 20zigern bis in die frühen 90ziger des letzten Jahrhunderts *das* statistische Verfahren der Wahl. Wir brauchen daher die ANOVA aus mehreren Gründen. Die Hochzeiten der ANOVA sind eigentlich vorbei, wir haben in der Statistik für viele Fälle mittlerweile besser Werkzeuge, aber als Allrounder ist die ANOVA immer noch nutzbar. Insbesondere wenn wir uns mit einem faktoriellen Design beschäftigen, dann komt die Stärke der ANOVA voll zu tragen. Da wir in den agrarwissenschaften eben dann doch sehr viele Feldexperimente in einem faktoriellen Design vorliegen haben, hat auch die ANOVA ihren Platz in der praktischen Auswertung. Wir werden immer wieder in diesem Buch auf die ANOVA inhaltlich zurück kommen und in vielen Abschlussarbeiten wird die ANOVA immer noch als integraler Bestandteil genutzt.

Was findest du in diesem Übersichtskapitel zur ANOVA?

:   Wir werden uns in diesem Kapitel auf die einfaktorielle ANOVA (eng. *one-way ANOVA*) sowie die zweifaktorielle ANOVA (eng. *two-way ANOVA*) konzentrieren. Ich gehe dann auch noch auf ein mehrfaktorielles Modell ein. Am Ende kommt dann noch die multivariate ANOVA, wenn du simultan mehr als einen Messwert $y$ in dein Modell nehmen willst. In dem [Kapitel zur ANCOVA](#sec-ancova) findest du dann alle Informationen, wenn du zusärtzlich zu deinen Faktoren noch eine numerische Kovariate mit in dein Modell nehmen willst. Häufig wird die ANOVA auch verwendet, wenn du Messwiederholungen in deinen Daten vorliegen hast. Hierfür habe ich dann das [Kapitel zur repeated & mixed ANOVA](#sec-anova-mixed) geschrieben, wo du dann einmal schauen musst.

## Allgemeiner Hintergrund

Fangen wir also mit der zentralen Idee der ANOVA an und arbeiten uns dann vor. Du kannst gerne den allgemeinen wie auch den theoretischen Teil überspringen und dir gleich das passende Datenbeispiel für deine Fragestellung raussuchen. Der Teil hier vorab dient nur dem tieferen Verständnis und du brauchst es eigentlich nicht um einfach nur eine ANOVA anzuwenden und ein Ergebnis zu erhalten. Da ist die ANOVA ziemlich gut zu interpretieren und anzuwenden. Wir fangen hier jetzt aber einmal an uns eine grundsätzliche Frage über unser experimentellen Versuch zu stellen.

Ist eine hohe Varianz in dem Messwert $\boldsymbol{y}$ zu vermeiden?

:   Es gibt eigentlich zwei Fehlannahmen (eng. *misconception*) an die ANOVA. Zum einen, dass die ANOVA die Varianzen vergleichen würde. Das stimmt nur bedingt. Die Nullhypothese der ANOVA ist die Gleichheit der Mittelwerte in den Gruppen. Zum anderen, dass wenig Varianz in den Messwerten $y$ per se gut wäre und ein angestrebtes Ziel in einem geplanten Feldexperiment.

In der folgenden Abbildung siehst du einmal vier Maisspflanzen mit jeweils einer Behandlung für ein gesteigertes Wachstum. In der linken Abbildung haben wir eine geringe Varianz udn damit auch gleiche Mittelwerte. Die Behandlungen haben überhaupt keinen Einfluß auf den Wuchs. In der rechten Abbdlung siehst du eine hohe Varianz, weil eben die Behandlungen einen Effekt auf das Wachstum haben. Wenn du also ein geplantes Experiment mit Kontrolle und Behandlungen durchführst, dann erwartest du eine hohe Varianz in dem Messwert $y$. Ansonsten würde deine Behandlung überhaupt nicht wirken.

![Feldexperiment mit vier Behandlungen zur Steigerung der Wuchshöhe von Maispflanzen. Jede Pflanze stellt vereinfacht eine Behandlung dar. **(A)** Die gepoolte Varianz $s^2_p$ über die Gruppen ist klein ($s^2_p=0$), die Behandlungen haben keinen Effekt auf das Wachstum. **(B)** Die gepoolte Varianz $s^2_p$ über die Gruppen ist groß ($s^2_p>0$), die Behandlungen haben einen Effekt auf das Wachstum der Maisspflanzen.](images/anova/anova_intro.png){#fig-anova-intro fig-align="center" width="100%"}

Arbeiten wir uns nun einmal durch die Themen der Hypothesen sowie der Idee des faktoriellen Modells. Wir brauchen eine Idee des faktoriellen Modells um die verschiednen Typen der ANOVA unterscheiden zu können. Teilweise sind es eben dann nur Erweiterungen des immer gleichen Grundgerüst. Dann schauen wir nochmal auf die Voraussetzungen der ANOVA an deine Daten. Zum einen mit dem Fokus auf die Normalverteilung deines Messwert $y$ und zum anderen die Varianzhomogenität in deinen Faktoren. Bevor wir dann nochmal als Einschub die Theorie behandlen, stelle ich dir R Pakete vor, die dir die ANOVA rechnen können.

#### Das Modell {.unnumbered .unlisted}

Beginnen wir also mit der Festlegung welche Art der Analyse wir rechnen wollen. Wichtig ist hier, dass du einen normmalverteiten Messwert $y$ vorliegen hast und ein oder mehrere Faktoren $f$. Was sind im Kontext von R Faktoren? Ein Faktor ist eine Behandlung oder eben eine Spalte in deinem Datensatz, der verschiedene Gruppen oder Kategorien beinhaltet. Wir nennen diese Kategorien Level. In den folgenden Datenbeispielen ist die Spalte `animal` ein Faktor mit drei Leveln. Wir haben dort nämlich die Sprungweiten von drei Floharten gemessen. Jetzt kann es aber auch sein, dass du neben einem Faktor noch eine numeriche Kovariate $c$ gemessen hast. Oder aber du hast zwei Messwerte, die du dann gemeinsam mit einem Faktor vergleichen willst. Diese drei Analysetypen wollen wir uns in den folgenden Tabs mal näher anschauen.

::: panel-tabset
## ANOVA (faktoriell)

Das faktorielle Modell der klassischen ANOVA beinhaltet einen Messwert $y$, der normalverteilt ist. Darüber hinaus haben wir noch ein bis mehrere Faktoren $f$. Wir bezeichnen hier die Faktoren mit den Indizes $A$, $B$ und $C$ und die jeweiligen Level des Faktors $A$ als $A.1, A.2,..., A.k$. Häufig haben wir aber zwei Faktoren in einem Modell mit zwei bis fünf Leveln. Aber hier gibt es sicherlich auch noch Fragestellungen mit mehr Gruppen und damit Leveln in einem Faktor. Wir schreiben ein faktorielles Modell wie folgt.

$$
y \sim f_A + f_B + ... + f_P + f_A \times f_B + ... + f_A \times f_B \times f_C
$$

mit

-   $y$ gleich dem Messwert oder Outcome
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung
-   $f_A \times f_B \times f_C$ gleich einem beispielhaften Interaktionsterm zweiter Ordnung

Zusätzlich können noch Interaktionsterme höherer Ordnungen entstehen, aber hier wird es extrem schwierig diese Interaktionsterme dann auch zu interpretieren. Ich würde grundsätzlich vermeiden Interaktionen zweiter und höherer Ordnungen mit ins Modell zu nehmen. Was genau eine Interaktion ist, besprechen wir in einem folgenden Abschnit. Um eine Interaktion beobachten zu können, brauchst du aber mindestens zwei Faktoren in deiner Analyse.

## ANCOVA (faktoriell und numerisch)

Wenn wir neben einem bis mehreren Faktoren $f$ noch eine numerische Kovariate $c$ mit modellieren wollen, dann nutzen wir die ANCOVA (eng. *Analysis of Covariance*). Hier kommt dann immer als erstes die Frage, was heißt den Kovariate $c$? Hier kannst du dir eine numerische Variable vorstellen, die ebenfalls im Experiment gemessen wird. Es kann das Startgewicht oder aber die kummulierte Wassergabe sein. Wir haben eben hier keinen Faktor als Kategorie vorliegen, sondern eben etwas numerisch gemessen. Daher ist unsere Modellierung etwas anders.

$$
y \sim f_A + f_B + ... + f_P + f_A \times f_B + c_1 + ... + c_p
$$

mit

-   $y$ gleich dem Messwert oder Outcome
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung
-   $c_1 + ... + c_p$ gleich einer oder mehrer numerischer Kovariaten

Hier muss ich gleich die Einschränkung machen, dass wir *normalerweise* maximal ein zweifaktorielles Modell mit einem Faktor $A$ und einem Faktor $B$ sowie einer Kovariate $c$ betrachten. Sehr selten haben wir mehr Faktoren oder gar Kovariaten in dem Modell. Wenn das der Fall sein sollte, dann könnte eine andere Modellierung wie eine multiple Regression eine bessere Lösung sein. Mehr Informationen zur der Berechnung findest du in dem [Kapitel zur ANCOVA](#sec-ancova)

## MANOVA (multivariat)

Am Ende des Kapitels schauen wir uns noch einen weiteren Spezialfall an. Nämlich den Fall, dass wir nicht nur einen Messwert $y$ vorliegen haben sondern eben mehrere die wir simultan auswerten wollen. Das klingt jetzt erstmal etwas schräg, aber es wird dann klarer, wenn wir uns die Sachlage einmal an einem Beispiel anschauen.

$$
(y_1, y_2, ..., y_j) \sim f_A + f_B + ... + f_P + f_A \times f_B 
$$

mit

-   $(y_1, y_2)$ gleich der Messwerte oder Outcomes
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung

Die ganze multivariate Analyse ist dann etwas seltener, da wir hier dann doch schon einiges an Fallzahl brauchen, damit es dann auch einen Sinn macht. Einiges an Fallzahl heißt dann hier, dass wir dann schon mehr als sechs Beobachtungen in einer Gruppe haben sollten. Wenn du weniger hast, kann es sein, dass du keine signifikanten Unterschiede findest.
:::

Daneben gibt es natürlich noch Spezialfälle wie die gemischte ANOVA (eng. *mixed ANOVA*), wenn wir Beobachtungen wiederholt messen. Dieses Modell schauen wir uns dann auch nochmal an. Der Unterschied in der Modellierung ist ein Fehlerterm (eng. *Error*), den wir dann nochmal mit angeben müssen. Dazu dann aber mehr in dem [Kapitel zur repeated & mixed ANOVA](#sec-anova-mixed).

#### Hypothesen {.unnumbered .unlisted}

Wenn wir von der ANOVA sprechen, dann kommen wir natürlich nicht an den Hypothesen vorbei. Die ANOVA ist ja auch ein klassischer statistischer Test. Hier müssen wir unterscheiden, ob wir eine Behandlung mit zwei Gruppen, also einem Faktor $A$ mit $2$ Leveln vorliegen haben. Oder aber eine Behandlung mit drei oder mehr Gruppen vorliegen haben, also einem Faktor $A$ mit $\geq 3$ Leveln in den Daten haben. Da wir schnell in einer ANOVA mehrere Faktoren haben, haben wir auch schnell viele Hypothesen zu beachten. Jeweils ein Hypothesenpaar pro Faktor muss dann betrachtet werden. Das ist immer ganz wichtig, die Hypothesenpaare sind unter den Faktoren mehr oder minder unabhängig.

::: panel-tabset
## Faktor mit $2$ Leveln

Bei einem Faktor $A$ mit nur zwei Leveln $A.1$ und $A.2$ haben wir eine Nullhypothese, die du schon aus den Gruppenvergleichen wie dem t-Test kennst. Wir wollen zwei Mittelwerte vergleichen und in unserer Nullhypothese steht somit die Gleichheit. Da wir nur zwei Gruppen haben, sieht die Nullhypothese einfach aus.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2}
$$

In der Alternativehypothese haben wir dann den Unterschied zwischen den beiden Mittelwerten. Wenn wir die Nullhypothese ablehnen können, dann wissen wir auch welche Mittelwertsunterschied signifikant ist. Wir haben ja auch nur einen Unterschied getestet.

$$
H_A: \; \bar{y}_{A.1} \neq \bar{y}_{A.2}
$$ Das Ganze wird dann etwas komplexer im Bezug auf die Alternativehypothese wenn wir mehr als zwei Gruppen haben. Hier kommt dann natürlich auch die Stärke der ANOVA zu tragen. Eben mehr als zwei Mittelwerte vergleichen zu können.

## Faktor mit $\geq 3$ Leveln

Die klassische Nullhypothese der ANOVA hat natürlich mehr als zwei Level. Hier einmal beispielhaft die Nullhypothese für den Vergleich von drei Gruppen des Faktors $A$. Wir wollen als Nullhypothese testen, ob alle Mittelwerte der drei Gruppen gleich sind.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

Wenn wir die Nullhypothese betrachten dann sehen wir auch gleich das Problem der Alternativehypothese. Wir haben eine Menge an paarweisen Vergleichen. Wenn wir jetzt die Nullhypothese ablehnen, dann wissen wir nicht welcher der drei paarweisen Mittelwertsvergleiche denn nun unterschiedlich ist. Praktisch können es auch alle drei oder eben zwei Vergleiche sein.

$$
\begin{aligned}
H_A: &\; \bar{y}_{A.1} \ne \bar{y}_{A.2}\\
\phantom{H_A:} &\; \bar{y}_{A.1} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \bar{y}_{A.2} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \mbox{für mindestens einen Vergleich}
\end{aligned}
$$

Wenn wir die Nullhypothese abgelhent haben, dann müssen wir noch einen sogenannten Post-hoc Test anschließen um die paarweisen Unterschiede zu finden, die dann signifikant sind. Das ganze machen wir dann aber in einem eigenen Kapitel zum Post-hoc Test.
:::

#### Normalverteilung und Varianzhomogenität {.unnumbered .unlisted}

> *"Soll ich's wirklich machen oder lass ich's lieber sein? Jein..." --- Fettes Brot, Jein*

Wenn wir die ANOVA nutzen wollen, dann kommen wir um die Voraussetzungen der Normalverteilung an den Messwert $y$ sowie die Varianzhomogenität in den Faktorleveln oder Behandlungsgruppen $f$ nicht herum. In dem [Kapitel zum Pre-Test oder Vortest](#sec-pretest) gehe ich nochmal detailierter auf mögliche Tests auf die Normalverteilung und die Varianzhomogenität ein. In diesem Kapitel findest du in dem Abschnitt [Test auf Normalverteilung und Varianzhomogenität](#sec-anova-test-pre) einmal ein Vorgehen für das Testen der Annahmen. Ich würde davon allgemein abraten, aber es wird immer wieder verlangt, also stelle ich es hier auch vor. Kurzfassung, die ANOVA ist realtiv robust gegen eine Abweichung von der Normalverteilung der Messwerte. Ebenso kann die ANOVA mit leichter Varianzheterogenität umgehen.

Häufig kommt jetzt die Frage, ob mein Messwert $y$ wirklich normalverteilt ist und ich nicht den Messwert auf Normalverteilung testen sollte. Die kurze Antwort lautet nein, da du meistens zu wenig Beobachtungen pro Gruppe vorliegen hast. Die etwas längere liefert @kozak2018s mit dem Artikel [What's normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions](https://onlinelibrary.wiley.com/doi/pdf/10.1111/jac.12220?casa_token=22Jm83-kW-MAAAAA:yh0EVuGiGHWDsuPiVP8ZLj51OCasdpIiVWUcYv3Q8dGaIo0yMeNZNwkHIk1ibTCsLhkxbLKZrwZSByo).

Kommen wir nun zur Varianzhomogenität oder Varianzhterogenität in den Gruppen des Behandlunsgfaktors. Wir betrachten also meistens nur den wichtigen Faktor $f_A$ und ignorieren ein wenig den zwieten Faktor. Prinzipiell kannst du natürlich auch den zweiten Fakto anschauen, aber dann werden es immer mehr Gruppen und Fakotrkombinationen. Am Ende kommt dann sowieso heraus, dass über alle Gruppen hinweg keine homogenen Varianzen vorliegen. Wenn du mehr lesen willst so gibt es auf der Seite DSFAIR noch einen Artikel zu `{emmeans}` und der Frage [Why are the StdErr all the same?](https://schmidtpaul.github.io/dsfair_quarto/ch/summaryarticles/whyseequal.html)

Wann liegt vermutlich Varianzheterogenität in deinen experimentellen Faktoren $f$ vor?

:   Es gibt so ein paar Daumenregeln, die dir helfen abzuschätzen, ob in deinen Gruppen Varianzheterogenität vorliegt. Um es kurz zu machen, vermutlich hast du mindestens leichte Varianzhterogenität in den Daten vorliegen.

1)  Du hat viele Behandlungsgruppen. Je mehr Gruppen du hast oder eben dann auch Faktorkombinationen, die du testen möchtest, desto wahrscheinlicher wird es, dass mindestens eine Gruppe eine unterschiedliche Varianz hat. Du hast Varianzheterogenität vorliegen.
2)  Du misst deine Gruppen über die Zeit. Je größer, schwerer oder allgemein höher ein Messwert wird, desto größer wird auch die Varianz. Schaust du dir deine Messwerte über die Zeit an hast du meistens Varianzheterogenität vorliegen.
3)  Deine Kontrolle ohne Behandlung verhält sich meistens nicht so, wie die Gruppen, die eine Behandlung erhalten haben. Wenn du nichts machst in deiner negativen Kontrolle, dann hast du meistens eine andere Streuung der Messwerte als unter einer Behandlung.
4)  Diene Behandlungen sind stark unterschiedlich. Wenn deine Behandlungen sich biologisch oder chemisch in der Wirkung unterscheiden, denn werden vermutlich deine Messwerte auch anders streuen. Hier spielt auch die Anwendung der Behandlung und deren Bereitstellung eine Rolle. Wenn was nicht gleich ist, dann wird es vermutlich nicht gleiche Messwerte erzeugen.
5)  Du hast wenig Fallzahl pro Gruppe oder Faktorkombination. Wenn du wenig Fallzahl in einer Gruppe hast, dann reicht schon eine (zufällige) Messabweichung und schon sind deine Varianzen heterogen.

Gut, jetzt wissen wir, dass du *vermutlich* Varianzheterogenität in deinen Daten vorliegen hast. Erstmal ist das kein so großes Problem.

Tut Varianzhterogenität anstatt Varianzhomogenität weh?

:   Nein. Meistens ist die Varianzheterogenität nicht so ausgeprägt, dass du nicht auch eine ANOVA rechnen kannst. Über alle Gruppen hinweg wird dann zwar in einer ANOVA die Varianz gemmittelt und es kann dann zu weniger signifkanten Ergebnissen führen, aber so schlimm ist es nicht. Im Post-hoc Test solltest du aber die Varianzhterogenität berücksichtigen, da du ja immer nur zwei Gruppen gleichzeitig betrachtest.

#### Welche Pakete gibt es eigentlich? {.unnumbered .unlisted}

Wenn um die Anwendung der ANOVA in R geht, dann haben wir eine Menge Pakete zur Auswahl. Wie immer macht die Fragestellung und das gewählte Modell den Großteil der Entscheidungsindung aus. Ich zeige dir später in der Anwendung dann auch alle Pakete einmal, gebe dir dann aber auch immer eine Empfehlung mit. In der folgenden Tabelle gebe ich dir einmal eine kurze Übersicht über die beiden Annahmen an die ANOVA. Normalerweise brauchen wir einen normalverteilten Messwert $y$ und Varianzhomogenität in den Faktoren. In den letzten Jahren wurden aber noch weitere Implementierungen der ANOVA entwickelt, so dass hier auch Alternativen vorliegen.

|                            | `{base}` | `{car}`  | `{afex}` | `{WRS2}` | Excel |
|:---------------------------|:--------:|:--------:|:--------:|:--------:|:-----:|
| **Normalverteilt** $y$     |    ja    |    ja    |    ja    |   nein   |  ja   |
| **Varianzhomogenität** $f$ |    ja    | optional |    ja    |   nein   |  ja   |
| **Messwiederholungen**     |   nein   |   nein   |    ja    |    ja    | nein  |

: Übersicht über Funktion der ANOVA in ausgewählten Paketen und Excel. Die Aussagen sind nicht als absolut zu verstehen sondern eher als Empfehlung und Leitplanken zur Orientierung. {#tbl-anova-übersicht}

Gehen wir jetzt mal die Pakete durch. Wir immer gibt es einiges an Möglichkeiten und ich zeige dir hier eben die Auswahl. Es gibt hier das ein oder andere noch zu beachten, aber da gehe ich dann bei den jeweiligen Methoden drauf ein. Es macht eben dann doch einen Unterschied ob ich eine einfaktorielle oder komplexere ANOVA rechnen will. Nicht alles geht in allen R Pakten oder gar Excel.

Der Standard mit der Funktion `aov()` aus `{base}`

:   Die Standardfunktion `aov()` erlaubt es eine einfaktorielle oder zweifaktorielle ANOVA direkt auf einem Datensatz zu rechnen. Hier brauchen wir nur ein Modell in der in R üblichen Formelschreibweise `y ~ f`. Du kannst diesen Ansatz als schnelle ANOVA begreifen. Dein Messwert $y$ muss hier normalverteilt sein.

Der erweiterte Standard mit der Funktion `anova()` aus `{base}`

:   Die Funktion `anova()` erlaubt es auch auf anderen Modellen eine ANOVA zu rechnen. Wi nutzen hier die Funktion `lm()`, die einen normalverteilten Messwert $y$ annimmt. Es ginge aber auch mit anderen Modellierungen und der Funktion `glm()` für Zähldaten einer Possionverteilung oder noch anderen Verteilungen. Die `anova()` Funktion ist sehr reudziert, tut aber im Sinne einer ANOVA was die Funktion machen soll.

Mit der Funktion `Anova()` aus `{car}`

:   Das [R Paket `{car}`](https://cran.r-project.org/web/packages/car/index.html) bietet eine Verbesserung der Standardfunktionen der ANOVA an. Insbesondere die Berücksichtigung und die Modellierung eines Interaktionseffektes in einer zweifaktoriellen ANOVA sticht heraus. Daher ist die Funktion hier etwas flexibeler als der Standard. In einer einfaktoriellen ANOVA bemerkst du keinen Unterschied.

Mit den ANOVA Funktionen aus `{afex}`

:   Wir können die ANOVA auch anwenden, wenn wir Messwiederholungen vorliegen haben. Daher bietet sich hier das [R Paket `{afex}`](https://github.com/singmann/afex) an. Du musst bei den Funktionen von `{afex}` immer eine ID mitlaufen lassen, die angibt welche Individuen wiederholt gemessen wurden. Also hat jede Zeile eine Nummer, die beschreibt welche Beobachtung hier vorliegt. Besonders wichtig bei Messungen über die Zeit. Darüber hinaus kann das Paket sehr gut Interaktionen schätzen und Bedarf dort keiner zusätzlichen Optionen.

> *"ANOVAs are generally robust to 'light' heteroscedasticity, but there are various other methods (not available in `{afex}`) for getting robust error estimates."* --- [Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html)

Das Paket `{afex}` kann nicht mit Varianzheterogenität umgehen, aber dafür mit Messwiederholungen. Ich würde das Paket `{afex}` nehmen, wenn ich Messwiederholungen vorliegen habe oder mich die Interaktion in einem zweifaktoriellen Modell interessiert.

Mit den ANOVA Funktionen aus `{WRS2}`

:   Eine Annahme an die ANOVA ist, dass wir es mit normalverteilten Messwerten $y$ sowie Varianzhomogenität in den Faktoren $f$ vorliegen haben. Das R Paket `{WRS2}` mit der hervorragenden Vingette [Robust Statistical Methods Using WRS2](https://cran.r-project.org/web/packages/WRS2/vignettes/WRS2.pdf) erlaubt nun aber diese beiden Annahmen zu umgehen und bietet eine robuste ANOVA an. Robust meint hier, dass wir uns nicht um die Normalverteilung und Varianzhomogenität kümmern müssen.

Mit Excel

:   Hier muss ich sagen, dass es schon etwas weh tut die einfaktorielle und zweifaktorielle ANOVA in Excel zu rechnen. Ich habe dir bei der einfaktoriellen sowie der zweifaktoriellen ANOVA ein Video für die ANOVA in Excel ergänzt. Eigentlich ist es nur der letzte Strohhalm, wenn du keine Zeit mehr hast dich in R nochmal einzuarbeiten.

::: callout-tip
## Weitere Tutorien für die ANOVA

Wir oben schon erwähnt, kann dieses Kapitel nicht alle Themen der ANOVA abarbeiten. Daher präsentiere ich hier eine Liste von Literatur und Links, die mich für dieses Kapitel hier inspiriert haben. Nicht alles habe ich genutzt, aber vielleicht ist für dich was dabei.

-   [ANOVA in R](https://www.datanovia.com/en/lessons/anova-in-r/)
-   [One-Way ANOVA Test in R](https://www.sthda.com/english/wiki/one-way-anova-test-in-r)
-   [Two-Way ANOVA Test in R](https://www.sthda.com/english/wiki/two-way-anova-test-in-r)
-   [MANOVA Test in R: Multivariate Analysis of Variance](https://www.sthda.com/english/wiki/manova-test-in-r-multivariate-analysis-of-variance)
-   [ANOVA in R \| A Complete Step-by-Step Guide with Examples](https://www.scribbr.com/statistics/anova-in-r/)
:::

## Theoretischer Hintergrund

Im folgenden Abschnitt schauen wir uns einmal den theoretischen Hintergrund zu der ANOVA an. Ich fokusiiere mich hier einmal für die Theorie auf die einfaktorielle ANOVA. Die Prinzipien lassen sich dann auch auf die zweifaktorielle und mehrfaktoriellen Algorithmen der ANOVA anwenden. Was dann später noch dazukommt sind dann die Interaktionen. Dabei ist zu bachten, dass wir natürlich eine Interaktion nur in einem zweifaktoriellen Modell beobachten können. Daher hier der Start mit der einfaktoriellen ANOVA und dann die Vertiefung zur Interaktion mit der zweifaktoriellen ANOVA.

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01_small.png){fig-align="center" width="100%"}

> In der ersten Version dieses Kapitels habe ich noch sehr viel beispielhaft für eine einfaktorielle ANOVA durchgerechnet. Wie sich dann in den Jahren herausstellte, hat es dir wenig geholfen, die ANOVA zu verstehen oder anzuwenden. Wer rechnet schon die ANOVA per Hand? Daher hier eben das klassische [lying-to-children](https://en.wikipedia.org/wiki/Lie-to-children) und ich erkläre dir die ANOVA mehr konzeptionell als rein mathematisch korrekt.
:::

Wir müssen jetzt einmal für dei Haupteffekte eines Faktors $A$ oder $B$ unterschieden sowie deren Interaktion untereinander. Deshalb besprechen wir jetzt erstmal einen Haupteffekt eines Faktors $A$ mit drei Levels $A.1$, $A.2$ sowie $A.3$ und arbeiten uns dann vor. Ich habe auf großartige Mathematik und Formeln verzichtet. Du findest die entsprechenden händischen Rechenoperation auf Wikipedia oder in einem entsprechenden statistischen [Lehrbuch zur ANOVA und Statistik](https://s3-us-west-2.amazonaws.com/mtvernon.wsu.edu/uploads/2016/12/Statistics_for_Terrified_Biologists.pdf) wie das verlinkte Buch von @van2019statistics.

### Haupteffekte $f_A$

Für die Theorie konzentrieren wir uns nur auf die einfaktoriele ANOVA. Das heißt wir haben einen Faktor $A$ mit drei Levels $A.1$, $A.2$ sowie $A.3$ vorliegen. Du kannst dir die drei Level als drei Gruppen vorstellen. Entweder sind es verschiedene Düngestufen oder aber eben drei Floharten, die unterschiedlich weit springen. Erinnere dich nochmal an die @fig-anova-intro zu Beginn des Kapitels. Wir wollen in unseren Daten Varianz haben, denn nur dann haben wir auch wirklich einen Unterschied zwischen den Gruppen in unserer Behandlung. Fangen wir also mit der wichtigste Frage einmal an.

Wann sind drei oder mehr Mittelwerte gleich?

:   Für unseren Gedankengang nehmen wir mal drei Mittelwerte für die drei Gruppen $A.1$, $A.2$ sowie $A.3$ an. Wir brauchen ja in der Nullhypothese Gleichheit. Das heißt, dass alle drei Mittelwerte $\bar{y}_{A.1}$, $\bar{y}_{A.2}$ und $\bar{y}_{A.3}$ gleich sein müssen. Wir nennen diese Mittelwerte der Gruppen daher auch lokale Mittelwerte. Wir können also wie folgt schreiben.

$$
\bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

Jetzt kommt der eigentlich Hauptgedanke. Wir können auch einen globalen Mittelwert $\beta_0$ berechnen in dem wir die drei Mittelwerte mitteln oder aber den Faktor vergessen und über alle Beobachtungen den Mittelwert berechnen. Wenn wir mehr Mittelwerte oder eben Gruppen haben, dann ändert sich natürlich der Nenner.

$$
\beta_0 = \cfrac{\bar{y}_{A.1} + \bar{y}_{A.2} + \bar{y}_{A.3}}{3}
$$

Wenn die drei Mittelwerte gleich sind, dann ist auch das globale Mittel $\beta_0$ gleich der drei Mittelwerte. Das klingt jetzt erstmal etwas schräg, aber wir hätten dann folgenden Zusammenhang. Aber das ist eigentlich was wir brauchen. Eine statistische Maßzahl, die Null ist, wenn Gleichheit in den Gruppen vorherrscht.

$$
\mbox{Wenn}\; \beta_0 = 0\; \mbox{dann}\; \bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

In der folgenden @fig-ggplot-anova-intro-null wird dir es vielleicht nochmal klarer. Wir haben hier einmal den globalen Mittelwert $\beta_0$ sowie von lokalen Mittelwerten $\bar{y}_{A.1}$, $\bar{y}_{A.2}$ und $\bar{y}_{A.3}$ der einzelen Gruppen des Faktors $A$ dargsstellt. In der linken Abbildung siehst du, dass die lokalen Mittelwerte der Gruppen alle auf einer Höhe liegen. Die Mittelwerte der Gruppen sind gleich. Es gibt keinen Uterschied. Darüber hinaus sind die Abstände der lokalen Mittelwerte zum gloabeln Mittelwert Null. Die Nullhypothese gilt.

Wenn sich jetzt die lokalen Mittelwerte untereinander unterscheiden, dann liegen die lokalen Mittelwerte nicht mehr auf einer Ebene. Damit entstehen auch positive und negative Abstände von den lokalen Mittelwerten zu dem globalen Mittelwert. Diese Abstände sind nämlich jetzt nicht mehr Null. Daher haben wir auch nicht mehr Gleichkeit vorliegen. Wir können daher die Nullhypothese ablehnen. Je größer die Abstände der lokalen Mittelwerte zum globalen Mittelwert werden, desto mehr würden wir die Nullhypothese ablehnen und an einen Gruppenunterschied glauben.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-null
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Zusammenhang zwischen dem globalen Mittelwert $\\beta_0$ und den drei Mittelwerten $\\bar{y}_{A.1}$, $\\bar{y}_{A.2}$ und $\\bar{y}_{A.3}$ der Gruppen $A.1$, $A.2$ sowie $A.3$. **(A)** Wenn die drei Mittelwerte gleich sidn und damit die Nullhypothese gilt, dann liegen die drei Mittelwerte auf dem globalen Mittelwert. **(B)** Wenn die drei Mittelwerte sich unterschieden, dann kann die Nullhypothese abgelehnt werden und die drei Mittelwerte liegen nicht auf dem globalen Mittel.  *[Zum Vergrößern anklicken]*"

set.seed(202434)
ex_intro_null_lst <- get_intro_data_tbl(mean = c(5, 5, 5), 
                                        sd = c(1, 0.5, 1), ng = c(4, 3, 5))
ex_intro_alt_lst <- get_intro_data_tbl(mean = c(4.5, 1, 8), 
                                       sd = c(1, 0.5, 1), ng = c(4, 3, 5))

get_ex_lst_intro_plot(ex_intro_null_lst) + 
  ggtitle("Nullhypothese annehmen",
          subtitle = "Die Mittelwerte sind gleich") +
  get_ex_lst_intro_plot(ex_intro_alt_lst) + 
  ggtitle("Nullhypothese ablehnen",
          subtitle = "Die Mittelwerte unterscheiden sich") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Damit haben wir jetzt das zentrale Prinzip der ANOVA verstanden. Es geht um die Abstände von lokalen Gruppenmittelwerten zu einem globalen Mittelwert über alle Gruppen.

Wie werden die Abstände von den lokalen Mittelwert zum globalen Mittelwert berechnet?

:   Nun könnten wir einfach sagen, dass wenn die aufsummierten Abstände nicht Null sind, wir einen Effekt in den Gruppen vorliegen haben. Hier tritt wieder das Problem auf, dass wir positive Abweichung und negative Abweichungen von den lokalen Mittelwerten zu dem gloablen mittelwert haben. Daher berechnen wir nicht die Abstände sondern die quadratischen Abstände und summieren diese dann auf. Wir berechnen die Abweichungsquadrate (eng. *sum of squares*, abk. *SS*). Daher sagen wir auch, dass die Abstände der lokalen Mittelwerte zum globalen Mittel als Abweichungsquadrate berechnet werden. In der folgenden Abbildung siehst du einmal die Visualsierung der Berechnung der Abweichungsquadrate des Faktors $A$ oder eben $SS_A$.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-alt-ssa
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Visualsierung der Berechnung der Abweichungsquadrate des Faktors $A$ als $SS_A$ bezeichnet. Für jede Beobachtung wird einmal der Abstand des lokalen Mittelwerts der Gruppe zum globalen Mittelwert berechnet und quadriert. Die Abstände werden dann aufsummiert."

get_ex_lst_intro_alt_ssa_plot(ex_intro_alt_lst) + 
  ggtitle(expression(Berechnung~der~SS[A]~auch~SS[between]),
          subtitle = "Wie streuen die Gruppenmittelwerte um das globale Mittel?")

```

Jetzt tritt aber wiederum ein anderes Problem auf. Je mehr Gruppen wir haben, desto größer werden unsere Abweichungsquadrate. Deshalb mitteln wir auch die Abweichungsquadrate um die mittleren Abweichungsquadrate (eng. *mean of squares*, abk. *MS*) zu erhalten. Jetzt könnten wir natürlich sagen, wenn $MS_A$ gleich Null ist, dann können wir die Nullhypothese nicht ablehnen. Aber hier nochmal ein kurzer Einwurf zur Teststatistik.

Wie sieht eine Teststatistik aus?

:   Eine Teststatistik teilt immer den Effekt (*signal*) durch die Streuung des Effekts (*noise*). Dabei muss eine Teststatistik Null sein, wenn die Nullhypothese gilt. Daher haben wir dann folgenden Zusammenhang.

$$
T_D = \cfrac{\mbox{signal}}{\mbox{noise}} = \cfrac{\mbox{Effekt}}{\mbox{Streuung}}
$$

In unserem Fall wäre dann der Effekt die mittleren Abweichungsquadrate des Faktors A also $MS_A$. Das passt auch in soweit, dass wenn die mittlere Abweichung der lokalen Mittelwerte zum globalen Mittelwert Null ist, dann können wir die Nullhypothese nicht ablehnen. Es fehlt also noch ein statistisches Maß für die Streuung.

Wir haben aber noch die Streuung *innerhalb* der einzelnen Gruppen. Diese Streuung innerhalb der Gruppen nennen wir gerne Reststreuung, da diese nicht von den Gruppen erklärt wird. Oder aber ganz kurz, den Fehler (eng. *error*). Wir berechnen also nochmal die quadrierten Abstände der einzelnen Beobachtungen um die jeweiligen Gruppenmittelwerte und nennen diese dann $SS_{Error}$. Dann summieren wir die quadrierten Abstände einmal auf, wie du in der folgenden Abbildung einmal sehen kannst. Am Ende mitteln wir auch die quadratische Abweichung der Fehler zu $MS_{Error}$ umd die mittlere Abweichung der einzelnen Beobachtungen zu den lokalen Mittelwerten darzustellen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-intro-alt-sse
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Visualsierung der Berechnung der Abweichungsquadrate des Fehlers $Error$ als $SS_{Error}$ bezeichnet. Für jede Beobachtung wird einmal der Abstand zum lokalen Mittelwert der Gruppe berechnet und quadriert. Die Abstände werden dann aufsummiert."

get_ex_lst_intro_alt_sse_plot(ex_intro_alt_lst) +
  ggtitle(expression(Berechnung~des~SS[Error]~auch~SS[within]),
          subtitle = "Wie streuen die Beobachtungen um die Gruppenmittelwerte?")
```

In der folgenden Tabelle siehst du nochmal die wichtigen Begrifflichkeiten der Varianz in einer ANOVA als mittleren quadratischen Abweichung $MS$ zusammengefasst. Die gesamte Varianz wird auch als $MS_{Total}$ bezeichnet und du kennst diese schon als gepoolte Varianz $s^2_p$ aus dem Student t-Test.

|                               |              |                |         |
|-------------------------------|:------------:|:--------------:|:-------:|
| Varianz zwischen den Gruppen  |    $MS_A$    | $MS_{between}$ |         |
| Varianz innerhalb der Gruppen | $MS_{Error}$ | $MS_{within}$  |         |
| Varianz aller Gruppen         | $MS_{Total}$ |  $MS_{Total}$  | $s^2_p$ |

: Zusammenfassung der Begrifflichkeit der mittleren quadratischen Abweichung $MS$ in einer ANOVA. {#tbl-anova-namen}

Da wir jetzt alle statistischen Maßzahlen zusammen haben können wir jetzt auch einen statistischen Test rechnen. Wir haben damit dann einmal als Effekt die mittleren Abweichungsquadrate der lokalen Mittelwerte zum globalen Mittelwert des Faktors $A$ als $MS_A$ vorliegen. Das ist jetzt unser statistisches Maß für den Mittelwertsunterschied oder eben allgemeiner dem Effekt. Auch wenn wir diesen Effekt nicht biologisch interpretieren können. Dann haben wir noch als Streuung den Fehler, als mittlere Abweichungsquadrate der Beobachtungen zu den jeweiligen Gruppenmittewerten. Daraus können wir uns jetzt die Testststatistik $F_D$ der ANOVA bauen.

$$
F_D = \cfrac{MS_A}{MS_{Error}}
$$ mit

-   $MS_A$ gleich der mittleren Abweichungsquadrate der lokalen Mittelwerte zum globalen Mittelwert des Faktors $A$.
-   $MS_{Error}$ mittlere Abweichungsquadrate der Beobachtungen zu den jeweiligen Gruppenmittewerten.

Wenn die Nullhypothese gilt, dann sind die mittleren Abweichungsquadrate der lokalen Mittelwerte zum globalen Mittelwert $MS_A$ gleich Null und die Teststatistik $F_D$ ist ebenfalls Null. Es kann aber keine negativen Werte für die F Statistik geben, da es keien ngeativen Werte für $MS_A$ geben kann. In der folgenden Abbildung siehst du nochmal die F Statistik visualisert.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-fstat
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Visualiserung der F Statistik einer ANOVA mit dem kritischen Wert $F_{\\alpha = 5\\%}$ und der berechneten Teststatistik $F_D$ aus den Daten. Eingezeichnet sind als Flächen das Signifkanzniveau $\\alpha$ gleich 5% und der p-Wert mit $Pr(F_D|H_0)$."

p_f_stat
```

Jetzt bietet es sich an nochmal den Zusammenhang von $MS_A$ und $MS_{Error}$ in der folgenden @fig-ggplot-anova-msa-mse näher zu betrachten. Wir können ja kleine Werte oder große Werte für die mittleren Abweichungsquadrate der lokalen Mittelwerte zum globalen Mittelwert $MS_A$ vorliegen haben. Ebenso können die mittlere Abweichungsquadrate der Beobachtungen zu den jeweiligen Gruppenmittewerten $MS_{Error}$ klein oder groß sein. Wir sehen sofort, dass ein großer Effekt $MS_A > 0$ und ein kleiner Fehler $MS_{Error} \approx 0$ es erleichtern einen signifikanten Unterschied nachzuweisen. Steigt der Fehler oder wird der Effekt klein, wird es schwerer einen signifikanten Unterschied zwischen den Gruppen zu zeigen. Die Gruppenmittelwerte liegen dann meistens auf einer Ebene oder die Fehlerbalken überlappen sich.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-msa-mse
#| fig-align: center
#| fig-height: 6
#| fig-width: 7.5
#| fig-cap: "Visualisierung des Zusammenhangs zwischen den mittleren Abweichungsquadrate der lokalen Mittelwerte zum globalen Mittelwert $MS_A$ sowie der mittleren Abweichungsquadrate der Beobachtungen zu den jeweiligen Gruppenmittewerten $MS_{Error}$. *[Zum Vergrößern anklicken]*"

ex_00_lst <- get_data_tbl(mean = c(5, 5, 5), sd = c(0.2, 0.2, 0.2))
ex_01_lst <- get_data_tbl(mean = c(5, 1, 9), sd = c(0.2, 0.2, 0.2))
ex_10_lst <- get_data_tbl(mean = c(5, 5, 5), sd = c(2, 2, 2))
ex_11_lst <- get_data_tbl(mean = c(5, 1, 9), sd = c(2, 2, 2))

get_ex_lst_plot(ex_00_lst) + 
  ggtitle(expression(MS[A]%~~%0~und~MS[Error]%~~%0),
          "Mittelwerte gleich und Fehler klein") +
  get_ex_lst_plot(ex_01_lst) +
  ggtitle(expression(MS[A]~">"~0~und~MS[Error]%~~%0),
          "Mittelwerte ungleich und Fehler klein") +
  get_ex_lst_plot(ex_10_lst) + 
  ggtitle(expression(MS[A]%~~%0~und~MS[Error]~">"~0),
          "Mittelwerte gleich und Fehler groß") +  
  get_ex_lst_plot(ex_11_lst) +
  ggtitle(expression(MS[A]~">"~0~und~MS[Error]~">"~0),
          "Mittelwerte ungleich und Fehler groß") +  
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Am Ende können wir dann die Abweichungsquadrate $SS$ und die mittleren Abweichungsquadrate $MS$ in einer Übersichtstabelle darstellen. Wir nennen diese Übersichtstabelle auch gerne die Ergebnistabelle der ANOVA. Wir können dann auch die $F_D$ Teststatistik ergänzen. Jeder Faktor hat eine eigene Zeile. Dabei addieren sich dann die $SS_A$ und $SS_{Error}$ zu den gesammten $SS_{Total}$ auf. Die Ergebnistabelle wird dir dann später in R berechnet. Insbesondere die Berechnung der Freiheitsgrade $df$ ist eine eigene Wissenschaft für sich und du würdest diese Berechnung dann in einem statistsichen Buch nachschlagen. Hier dient die Ergebnistabelle dann nur zur Übersicht.

| Quelle | df | Sum of squares (SS) | Mean squares (MS) | Teststatistik F$_{\boldsymbol{D}}$ |
|:--:|:--:|:--:|:--:|:--:|
| $A$ | $df_A$ | $SS_A$ | $MS_A = \cfrac{SS_A}{df_A}$ | $F_{D} = \cfrac{MS_A}{MS_{Error}}$ |
| $Error$ | $df_{Error}$ | $SS_{Error}$ | $MS_{Error} = \cfrac{SS_{Error}}{df_{Error}}$ |  |
| $Total$ | $df_{total}$ | $SS_{Total}$ |  |  |

: Ergebnistabelle der einfaktoriellen ANOVA in der theoretischen Darstellung. Die Abweichungsquadrate $SS$ müssen noch zu den mittleren Abweichungsquadraten $MS$ gemittelt werden. Abschließend wird die $F_D$ Teststatistik als Prüfgröße berechnet. {#tbl-anova-fac1-theo}

Wenn es dann die Ergebnistabelle für die einfaktorielle ANOVA gibt, dann gibt es natürlich auch eine Ergebnistabelle für eine zweifaktorielle ANOVA. Im Folgenden einmal die Ergebnistabelle gezeigt. Wenn du mehr Faktoren in deine ANOVA aufnimmst, dann erhälst du mehr Zeilen. Insbesondere der Interaktionsterm $A \times B$ kann erst auftreten, wenn du zwei oder mhr Faktoren in dein Modell nimmst. Am Ende berechnest du aber immer die F Statistik indem du die mittleren Abweichungsquadrate des entsprechenden Fakotr in der Zeile durch den mittleren Fehler teilst. Es wird eben immer komplexer und hier nimmt uns R die Arbeit dann ab.

| Quelle | df | Sum of squares (SS) | Mean squares (MS) | Teststatistik F$_{\boldsymbol{D}}$ |
|:--:|:--:|:--:|:--:|:--:|
| $A$ | $df_A$ | $SS_{A}$ | $MS_{A} = \cfrac{SS_A}{df_A}$ | $F_{D} = \cfrac{MS_{A}}{MS_{Error}}$ |
| $B$ | $df_B$ | $SS_{B}$ | $MS_{B} = \cfrac{SS_B}{df_B}$ | $F_{D} = \cfrac{MS_{B}}{MS_{Error}}$ |
| $A \times B$ | $df_{A \times B}$ | $SS_{A \times B}$ | $MS_{A \times B} = \cfrac{SS_{A \times B}}{df_{A \times B}}$ | $F_{D} = \cfrac{MS_{A \times B}}{MS_{Error}}$ |
| $Error$ | $df_{Error}$ | $SS_{error}$ | $MS_{Error} = \cfrac{SS_{Error}}{df_{Error}}$ |  |
| $Total$ | $df_{total}$ | $SS_{total}$ |  |  |

: Ergebnistabelle der zweifaktoriellen ANOVA in der theoretischen Darstellung mit Interaktionsterm für die beiden Faktoren. Die Abweichungsquadrate $SS$ müssen noch zu den mittleren Abweichungsquadraten $MS$ gemittelt werden. Abschließend wird die $F_D$ Teststatistik als Prüfgröße für jeden Faktor separat berechnet. {#tbl-anova-fac2-ohne-inter}

Damit wären wir fast schon am Ende der theoretischen Betrachtung des Haupteffekts eines Fakots in der einfaktoriellen ANOVA. Was mir jetzt noch bleibt, ist auf die Varianzhomogenität einzugehen. Wie du sicherlich schon gelesen hast, müssen alle Gruppen die gleiche Varianz haben. Wir berechnen ja auch nur einen Fehlerterm durch den wir dann teilen. Der ist ja für jeden Faktor der gleiche Wert. Daher hier nochmal ein Satz zur Varianzhomogenität.

Die Annahme der Varianzhomogenität theoretisch betrachtet

:   Wir wollen nochmal die Annahme an die Varianuhomogenität theoretisch betrachten und herausfinden, warum wir homogene Varianzen über die Gruppen brauchen. Wir du in der folgenden @fig-ggplot-anova-var-hetero einmal siehst, modelliert die ANOVA unter der Annahme der Varianzhomogenität in den Gruppen die Daten. Wir haben in den linken Plot unsere experimentellen Datan mit starker Varianzheterogenität. Die Varianz in der Gruppe $A.2$ ist viel größer als in den anderen beiden Gruppen. Dabei unterscheiden sich die Gruppen $A.1$ und $A.3$ signifikant. Die beiden Gruppen teilen sich nicht den gleichen Buchstaben des *Compact letter displays*. Wenn wir jetzt die ANOVA rechnen, dann teilen sich alle Gruppen die gemittlete Varianz über *alle* Gruppen. Das sehen wir dann in der rechten Abbilung. Die beiden Gruppen $A.1$ und $A.3$ erhalten viel mehr Streuung und die Gruppe $A.2$ weniger. Am Ende haben alle Gruppen faktisch gleich viel Streuung. So sehen dann die Daten aus, die die ANOVA modelliert. Wir können am Ende keinen signifikanten Unterschied mehr nachweisen. Daher kann es passieren, dasss eine ANOVA keinen Unterschied nachweisen kann, aber `{emmeans}` mit der Adjustierung für Varianzheterogenität dennoch einen Unterschied findet.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-var-hetero
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "Visualisierung der Annahme der Varianzhomogenität in den Gruppen. **(A)** Die experimentellen Daten zeigen eine Varianzheterogenität in den Gruppen. Die Gruppe $A.1$ unterscheidet sich signifikant von der Gruppe $A.3$ dargestellt durch das *Compact letter display*. **(B)** Die ANOVA modelliert gleiche Varianzen in allen Gruppen. Dadurch verschwindet der signifikante Unterschied, da der Fehler über alle Gruppen gemittelt wird *[Zum Vergrößern anklicken]*"

ex_hetero_lst <- get_data_tbl(mean = c(1, 5, 6), sd = c(0.5, 4, 0.5))
ex_homo_lst <- get_data_tbl(mean = c(1, 5, 6), sd = c(1.7, 1.7, 1.7))

get_ex_lst_plot(ex_hetero_lst) + 
  labs(title = "Experimentelle Daten",
       subtitle = "Varianzheterogenität in den Gruppen",
       caption = "Buchstaben zeigen Compact letter display") +
  annotate("label", x = c(5.5, 16.5, 25.5), y = c(4, 13, 9), 
           label = c("A", "AB", "B"), fill = "gray90") +
  get_ex_lst_plot(ex_homo_lst) +
  labs(title = "ANOVA Modellierung",
       subtitle = "Varianzhomogenität in den Gruppen",
       caption = "Buchstaben zeigen Compact letter display") +
  annotate("label", x = c(5.5, 15.5, 25.5), y = c(6, 9.5, 9), 
           label = c("A", "A", "A"), fill = "gray90") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Somit wären wir mit den theoretischen Teil durch. In dem folgenden Kasten sprechen wir nochmal über die Idee der Varianzzerlegung und wie das ganze mit der ANOVA funktioniert. Dann berechnen wir einmal den Effektschätzer der ANOVA. Bis jetzt haben wir ja nur eine Aussage über die Signifikanz, aber noch keinen Effekt berechnet.

Danach verlassen wir dann die einfaktorielle ANOVA und schauen auch schon weiter. Wir betrachten dann die Interaktion in einer zweifaktoriellen ANOVA. Der zweite Faktor in einer zweifaktoriellen ANOVA wird nämlich ähnlich behandelt wie der erste Faktor. Da tut sich dann konzeptionell nicht mehr so viel. Und den statistischen Engel nehme ich dann mit für die Aussage.

::: callout-note
## Exkurs: Die Idee der Varianzzerlegung

Häufig spricht man bei der ANOVA auch von einer Varianzzerlegung. Das ist richtig, verwirrt aber, wenn du damit gedanklich anfängst. Die ANOVA vergleicht primär Mittelwerte und die Nullhypothese ist auch entsprechend gebaut. Was die ANOVA dennoch tut, ist die gloable Streuung oder Varianz als $SS_{Total}$ auf die unterschiedlichen Quellen zu verteilen. Wenn der Faktor $A$ keinen Einfluss hätte dann würde alle Streuung nur durch den Fehler $MS_{Error}$ dargestellt und nichts von der Streuung durch die Verschiebung der lokalen Mittelwerte $MS_A$. In der folgenden Abbildung siehst du den Zusammenhang einmal dargestellt. In der linken Abbdilung vergessen wir einmal, dass wir einen Faktor A haben. Unsere Beobachtungen streuen um den globalen Mittelwert. Wie du dann aber rechts siehst, kommt ein Teil der Streuung durch die lokalen Mittelwerte des Faktors A. Wir können also die Streuung durch die unterschiedlichen Gruppenmittelwerte teilweise erklären. Diese Verschiebungen nennen wir dann auch $\beta_{A.1}$, $\beta_{A.2}$ und $\beta_{A.3}$. Wäre nur der Faktor A ursächlich für die Streuung, dann würden alle Beobachtungen auf den entsprechenden lokalen Mittelwerten liegen. Die Fehlerterme $\epsilon$ wären dann alle Null. Somit kannst du dann am Ende jeden Messwert y einer Beobachtung aus den Informationen des gloabeln Mittelwerts, dem Gruppenmittel und dem entspechenden Restfehler der Beobachtung zurückrechnen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-single-cat-anova 
#| fig-align: center
#| fig-height: 5
#| fig-width: 8
#| fig-cap: "Visualisierung der Varianzzerlegung anhand eines Faktors A mit unterschiedlichen Gruppenmittelwerten. Die Verschiebung der einzelnen Gruppenmittelwerte wird mit $\\beta_{A.1}$, $\\beta_{A.2}$ und $\\beta_{A.3}$ bezeichnet. Die restliche Streuung dann als Fehler $\\epsilon$ der einzelnen Beobachtung zu dem zugehörigen Gruppenmittel. Somit kann jeder Messwert y einer Beobachtung aus den Informationen des gloabeln Mittelwerts, dem Gruppenmittel und dem entspechenden Restfehler der Beobachtung zurückrechnen werden *[Zum Vergrößern anklicken]*"

p_example_fac_1_total + p_example_fac1 +
  plot_layout(width = c(1, 5)) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

### Effektschätzer

Nccdem wir uns mit der Theorie der ANOVA beschäftigt haben und verstehen, wie der Haupteffekt des Faktors A bestimmt wird, müssen wir uns noch Fragen, wie stark ist denn der Effekt nun? Wir rechnen zwar die Abqweichungsquadrate der einzlenen lokalen Mittelwerte zum globalen Mittel mit $SS_A$ aus, aber was sagt uns nun der Wert? Hierzu müssen wir nochmal einen Schritt zurücktreten und über die Abweichungsquadrate im Allgmeinen sprechen. Die gesamten Abweichungquadrate jeder Beobachtung zum globalen Mittelwert $SS_{Total}$ setzen sich aus den Abweichungsquadraten vom Faktor $SS_{Faktor}$, der Interaktion $SS_{Interaktion}$ sowie dem Fehler $SS_{Error}$ zusammen. Wir haben dann folgenden Zusammenhang.

$$
SS_{Total} = SS_{Faktor} + SS_{Interaktion} + SS_{Error} 
$$

mit

-   $SS_{Total}$ den gesamten Abweichungsquadraten jeder Beobachtung zum gloablen Mittel
-   $SS_{Faktor}$ den Abweichungsquadraten der Faktoren im Modell
-   $SS_{Interaktion}$ den Abweichungsquadraten möglicher Interaktionen der Faktoren
-   $SS_{Error}$ dem nicht erkläreten Rest der Abweichungsquadrate

Aus diesem Zusammenhang können wir dann verschiedene Effektschätzer berechnen, je nachdem wie wir dann die einzelnen Abweichungsquadrate ins Verhältnis setzen. Die Hilfeseite des R Pakets `{effectsize}` unter [Effect Sizes for ANOVAs](https://easystats.github.io/effectsize/articles/anovaES.html) stellt eine Reihe von Effektschätzern für die ANOVA vor. Wir konzentrieren uns hier einmal auf die häufigsten angewendeten Effektschätzer. Es gibt immer mehr, aber da musst du dann nochmal selber in die Hilfeseite schauen.

#### Eta$^2$ {.unnumbered .unlisted}

Der häufigste angewendete Effektschätzer ist [Eta squared](https://easystats.github.io/effectsize/articles/anovaES.html#eta2) oder auch $\eta^2$ geschrieben. Wir können $\eta^2$ relativ einfach aus den Abweichungsquadraten des Faktors $SS_A$ geteilt durch die gesamten Abweichungsquadrate $SS_{Total}$ berechnen. Das $\eta^2$ funktioniert besonders gut in der Anwenbdung einer einfaktoriellen ANOVA. Wir haben dann folgenden Zusammenhang.

$$
\eta^2 = \cfrac{SS_A}{SS_{Total}}
$$

mit

-   $SS_A$ den Abweichungsquadraten der lokalen Mittel des Faktor A zum globalen Mittel
-   $SS_{Total}$ den gesamten Abweichungsquadraten jeder Beobachtung zum gloablen Mittel

Wir rechnen hier also im Prinzip einmal einen Anteil aus. Da es sich bei den Abweichungsquadraten faktisch um eine Varianz handelt, können wir sagen, dass wir mit $\eta^2$ den Anteil der Varianz berechnen, der durch den Faktor A erklärt wird. Ich habe den Zusammenhang nochmal in der folgenden @fig-ggplot-anova-eta-venn dargestellt. Auf der linken Seite finden wir ein $\eta^2$ von $0.2$ und damit machen die $SS_A$ nur einen geringen Anteil der $SS_{Total}$ aus. Wir sagen, dass 20% der Varianz in den Daten durch den Faktor A erklärt wird. Der meiste Anteil der Abweichungsquadrate macht der Fehler $SS_{Error}$ aus. In der rechten Abbildung sehen wir dann ein $\eta^2$ von $0.8$ und damit ist der Anteil von $SS_A$ an $SS_{Total}$ groß. Wir sagen, dass 80% der Varianz in den Daten durch den Faktor A erklärt wird.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-eta-venn
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung von $\\eta^2$ für eine einfaktorielle ANOVA mit dem Faktor A. Gezeigt wird der Anteil der Abweichungsquadrate $SS_A$ an den gesamten Abweichungsquadraten $SS_{Total}$. **(A)** Geringer Effekt mit einem $\\eta^2$ von $0.2$. Der Faktor A erklärt nur einen kleinen Teil der Varianz. **(B)**  Starker Effekt mit einem $\\eta^2$ von $0.8$. Der Fakotor A erklärt fast die gesamte Varianz. *[Zum Vergrößern anklicken]*"

p1_eta_venn + p2_eta_venn +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Das R Paket `{effectsize}` hat auch die Funktion `interpret_eta_squared()` implementiert, die ich persönlich nicht so sinnvoll halte, da wir das $\eta^2$ relativ gut biologisch und statistisch erklären können. Das $\eta^2$ sagt dann eben aus, ob wir große oder kleine Messwerte durch unsere Behandlung durch den Faktor A vorliegen haben.

|                |                                               |
|----------------|-----------------------------------------------|
| $\eta^2 = 0.1$ | Faktor A erklärt 10% Varianz vom Messwert $y$ |
| $\eta^2 = 0.5$ | Faktor A erklärt 50% Varianz vom Messwert $y$ |
| $\eta^2 = 0.8$ | Faktor A erklärt 80% Varianz vom Messwert $y$ |

: Interpretation einiger $\eta^2$ Werte für den Faktor A mit einer Behandlung. {#tbl-anova-eta2-inter}

Wenn du ein geplantes Experiment durchführst bei dem du durch Randomisierung und andere Maßnahmen fast alle Einflussgrößen kontrollierst, dann sollest du als Varianzquelle nur onch deinen Behandlungsfaktor A übrigbehalten. So ist dann die Daumenregel, dass wir in einem geplanten Feldexperiment ein $\eta^2$ von mindestens $0.7$ erwarten sollten. Die Streuung deines Messwerts $y$ sollte dann eignentlich nur von deiner Behandlung abhängen.

#### Omega$^2$ und Epsilon$^2$ {.unnumbered .unlisted}

Neben dem $\eta^2$ gibt es auch noch zwei weitere Effektschätzer mit dem [Omega Squared](https://www.statisticshowto.com/omega-squared/) als $\omega^2$ geschrieben sowie dem [Epsilon Squared](https://www.statisticshowto.com/epsilon-squared/) als $\epsilon^2$ dargestellt. Du findest dazu auf der Hilfeseite des R Pakets `{effectsize}` unter [Other Measures of Effect Size](https://easystats.github.io/effectsize/articles/anovaES.html#other-measures-of-effect-size) noch weitere Informationen.

Beide Effektschätzer haben ihre Verwendung eher in der zweifaktoriellen ANOVA, wenn wir dann auch einen Interaktionsterm vorliegen haben. Die Interpretation ist dann nicht mehr so einfach wie bei dem $\eta^2$. Im Allgemeinen kannst du das $\epsilon^2$ wie das Bestimmtheitsmaß $R^2$ in der linearen Regression interpretieren. Ein $\epsilon^2$ gleich 0 ist als kein Effekt und ein $\epsilon^2$ gleich 1 als ein starker Effekt anzusehen. Hier verliert sich das Ganze aber ins ungefähre und ich würde empfehlen dann die Mittelwertsdifferenzen in einem Post-hoc Test zu berechnen. Diese Differenzen der Mittelwerte sind dann direkt interpretierbar und damit vorzuziehen.

Für beide Effektschätzer gibt es dann die Funktionen `interpret_omega_squared()` und `interpret_epsilon_squared()` aus dem R Paket `{effectsize}`, die dir dann bei der Interpretation des Effekts helfen. Hier ist dann nicht mehr eine so einfache biologische Interpretation wie bei dem $\eta^2$ möglich. Insbesondere bei noch komplexeren mehrfaktoriellen Modellen wird die Interpretation schwerer. Ich zeige dir dann die Anwendung einmal in den unteren Beispielen in R. Da einfach mal reingucken.

### Interaktion $f_A \times f_B$

Wenn du mehr als einen Faktor $f_A$ in deinem Modell vorliegen hast, dann kannst du eine Interaktion zwischen den Faktoren vorliegen haben. In diesem Abschnitt schauen wir uns eine Interaktion zwischen einem Faktor $f_A$ und einem Faktor $f_B$ einmal theoretisch näher an. Wir schreiben in R einen Interaktionsterm mit dem Doppelpunkt `:` zwischen den Variablennamen der beiden Faktoren. Wenn wir also die Interaktion zwischen dem Faktor $f_1$ und $f_2$ in R modellieren wollen, dann schreiben wir `fa:fb`. In der mathematischen Schreibweise haben wir dann häufig die Form $f_A \times f_B$ vorliegen. Ich schreibe hier häufig dann die mathematische Notation im Fließtext und natürlich im R Code dann die entsprechende Notation in R.

|                                         |   Mathematisch   |    R    |
|-----------------------------------------|:----------------:|:-------:|
| Interaktion zwischen Faktor $A$ und $B$ | $f_A \times f_B$ | `fa:fb` |

: Vergleich der Schreibweise einer Interaktion zwischen den Faktoren $f_A$ und $f_B$ einmal mathematisch und einmal in R. {#tbl-anova-inter-namen}

Der folgende Abschnitt teilt sich grob in zwei Teile. Einmal der theoretische Hintergrund zur Interaktion und was dort eigentlich die Herausforderungen in der Modellierung sind sowie einen Abschnitt zur visuellen Überprüfung der Interaktion in einer zweifaktoriellen Analyse.

Beginnen wir mit der eigentlichen Problemstellung in einer zweifaktoriellen ANOVA. Wenn wir zwei Faktoren haben, dann müssen wir ja die Abweichungsquadrate den jeweiligen Faktoren zuordnen. Wenn wir keien Interaktion vorliegen haben, dann haben wir den linken Fall in der unteren @fig-ggplot-anova-inter-circ vorliegen. Der Faktor A hat seine Abweichungsquadrate mit $SS_A$ und der Faktor B auch einen Anteil der Abweichungsquadrate mit $SS_B$ vorliegen. Der Rest von den gesamten Abweichungsquadraten $SS_{Total}$ geht dann in den Fehler mit $SS_{Error}$. Wenn wir aber eine Interaktion, wie in der rechten Abbildung vorliegen haben, dann können wir einen Teil der Abweichungsquadrate $SS_{A \times B}$ unterschiedlich zuordnen. Den die Interaktionsabweichungsquadrate $SS_{A \times B}$ könnten wir vollständig $SS_A$ oder $SS_B$ zurechnen oder aber irgendwie aufteilen. Daher gibt es jetzt verschiedene Typen von einer ANOVA, die sich eben darum drehen, wie wir die Interaktionsabweichungsquadrate $SS_{A \times B}$ verteilen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-circ
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung der Interaktion für eine zweifaktorielle ANOVA mit dem Faktor A und B. Gezeigt wird der Anteil der Abweichungsquadrate $SS_A$ und $SS_B$an den gesamten Abweichungsquadraten $SS_{Total}$. **(A)** Keine Interaktion. Alle Abweichungsquadrate können eindeutig einer Quelle zugeordnet werden. **(B)** Starke Interaktion. Ein Teil der Abweichungsquadrate $SS_{A \\times B}$ kann nicht eindeutig einem Faktor zugeordnet werden. *[Zum Vergrößern anklicken]*"

p2_inter_venn + p1_inter_venn +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))  
```

Das zentrale Problem bleibt also, wie will ich die Abweichungsquadrate berechnen? Will ich die gesamten Interaktionsabweichungsquadrate $SS_{A \times B}$ auf den Faktor A geben? Oder wie will ich die Verteilung darstellen. Hier gibt es jetzt bei der ANOVA drei verschiedene Typen. In dem Tutorium [Anova – Type I/II/III SS explained](https://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/lm_cat_unbal_ss_explained.html) findest du noch mehr Informationen und etwas Geschichte dazu. Ich fasse hier einmal die drei Typen zusammen und evrsuche mich mal an einer Empfehlung.

::: panel-tabset
## Type I

Die Type I ANOVA berechnet die Abweichungsquadrate in der sequenziellen Ordnung der Faktoren in dem Modell. Es werden also erst die Abweichungsquadrate für den Faktor A berechnet, dann für den Faktor B was noch von Faktor A an Abweichungsquadraten übrig ist. Am Ende wird dann die Interaktion betrachtet, wo wir dann den Anteil der Abweichungsquadrate finden, die nicht zu dem Faktor A oder Faktor B eindeutig zugeordnet werden konnten. Es macht also einen Unterschied wie du dein Modell baust. Insbesondere wenn du unterschiedliche Anzahlen an Beobachtungen in den Gruppen vorliegen hast.

$$
\begin{aligned}
&SS(A) \; \mbox{für den Faktor A} \\
&SS(B \mid A) \; \mbox{für den Faktor B gegeben Faktor A}\\
&SS(A \times B \mid B, A) \; \mbox{für die Interaktion gegeben Faktor B und A}
\end{aligned}
$$

Die Funktionen `aov()` und `anova()` in R rechnen immer eine Type I ANOVA. Es gibt hier nichts umzustellen, du musst hier auf die Ordnung der Faktoren in deinem Modell achten. Der wichtigere Faktor nach deiner wissenschaftlichen Fragestellung muss immer als erstes ins Modell.

## Type II

Die Type II ANOVA berechnet die Abweichungsquadrate eines Faktors unter der Berücksichtigung des anderen Faktors. Die Type II ANOVA ist damit der Type I ANOVA überlegen, was das finden eines signifkanten Unterschieds ausmacht. Darüber hinaus ist es auch egal welche Reihenfolge wir für unser Modell nehmen. Wenn deine beiden Faktoren im Modell also gleichwertig sind, dann ist die Type II ANOVA auf jeden Fall besser geeignet. Wichtig ist nur, dass die Type II ANOVA nur sinnvoll ist, wenn keine Interaktion zwischen den Faktoren vorliegt.

$$
\begin{aligned}
&SS(A \mid B) \; \mbox{für den Faktor A gegeben Faktor B} \\
&SS(B \mid A) \; \mbox{für den Faktor B gegeben Faktor A}\\
\end{aligned}
$$

Die Type II ANOVA kannst du im R Paket `{car}` mit der Funktion `Anova(..., type = "II")` anwenden. Hier empfiehlt es sich erst eine Type I Anova in `aov()` zu rechnen um zu schauen, ob eine signifikante Interaktion vorliegt. Wenn keine signifikante Interaktion zwischen den Faktoren in der Type I ANOVA vorliegt, dann ist die Type II ANOVA die bessere Wahl.

## Type III

Die Type III ANOVA verwenden wir, wenn wir eine Interaktion in unseren Daten vorliegen haben. Die Type III ANOVA berücksichtigt die jeweilige Interaktion und die Abweichungsquadrate des anderen Faktors B bei der Berechnung der Abweichungsquadrate des Faktors A. Insbesondere bei der Anwesenheit von einer signifkanten Interaktion liefert die Type III ANOVA passende Ergebnisse. Leider lassen sich dadurch die Haupteffekte der Faktoren A und B nicht ohne die Interaktion interpretieren. Da ist dann wieder die Frage im Raum, was will ich eigentlich in der ANOVA nachweisen und wie passt die ANOVA zu meiner wissenschaftlichen Fragestellung?

$$
\begin{aligned}
&SS(A \mid B,\, A \times B) \; \mbox{für den Faktor A gegeben Interaktion und Faktor B} \\
&SS(B \mid A,\, A \times B) \; \mbox{für den Faktor B gegeben Interaktion und Faktor A}\\
\end{aligned}
$$

Wir können die TYPE III Anova in dem R Paket `{car}` mit der Funktion `Anova(..., type = "III")` rechnen. Hier musst du aber aufpassen, wie du das Modell baust, welches du in die Funktion `Anova()` steckst. Dazu dann mehr gleich weiter unten zur Treamtent und Effect Kodierung. Als bessere Alternative bietet sich dann die Funktion `aov_car()` aus dem R Paket `{afex}` an. Heir wird das Modell passend zur Type III Anova kodiert.
:::

Jetzt haben wir da einiges an Zeug gelesen und fragen uns nun, was soll ich denn verwenden? Ich versuche jetzt mich aml an zwei etwas gewagten Empfehlungen für die Modellierung der ANOVA.

Keine Interaktion zwischen den Faktoren A und B

:   Wir verwenden die Type II ANOVA aus dem R Paket `{car}` mit der Funktion `Anova(..., type = "II")`. Hier haben wir die besten Chancen einen Unterschied zu finden und wir müssen nicht entscheiden, welcher Faktor uns wichtiger ist. Die Reihenfolge spielt keine Rolle im Modell.

Interaktion zwischen den Faktoren A und B

:   Wir verwenden die Type III Anova aus dem R Paket `{afex}` mit der Funktion `aov_car()`. Dann wird die Interaktion in den Haupteffekten der Faktoren A und B berücksichtigt. Wie wir dann weitermachen ist dann noch eine andere Sache, aber `{emmeans}` kann auch mit Interaktionen umgehen.

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01_small.png){fig-align="center" width="100%"}

> Welcher ANOVA Typ nun konkret in deiner Modellierung der richtige Typ ist kann ich dir leider Allgemein nicht sagen. Fühl dich aber nicht verunsichert. Auch eine `aov()` liefert gut Ergebnisse im Zusammenspiel mit `{emmeans}` im Post-hoc Test. Das **Aua** hält der statistische Engel aus.
:::

Jetzt haben wir uns mit den Typen der ANOVA beschäftigt. Wie erkenne ich denn nun das wir eine vermutliche Interaktion in den Daten vorliegen haben? Hierfür kann ich dann die visuelle Überprüfung empfehlen. Eine explorative Datenanalyse ist immer der erste Schritt und auch eine vermeidliche Interaktion lässts ich gut erkennen. Dann kannst du auch schauen, ob deine ANOVA Modellierung zu den visualisierten Daten passt.

#### Visuelle Überprüfung {.unnumbered .unlisted}

::: panel-tabset
## Liniendiagramm

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-line
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_line_theo + p2_inter_line_theo + p3_inter_line_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

## Boxplot

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-box
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_box_theo + p2_inter_box_theo + p3_inter_box_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## Barplot

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-inter-theo-bar
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p1_inter_bar_theo + p2_inter_bar_theo + p3_inter_bar_theo +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

#### Interaktion in R {.unnumbered .unlisted}

[Adding Interactions](https://easystats.github.io/effectsize/articles/anovaES.html#adding-interactions)

[R Paket `{interactions}`](https://interactions.jacob-long.com/)

[Interaction analysis in emmeans](https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html)

::::: callout-note
## Exkurs: Treatment coding vs. effect coding

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-contr-sum
#| tbl-cap: "foo"

f1_contr_sum_tbl |> 
  mutate(pos = rep(1:3,3)) |> 
  pivot_wider(names_from = fa, values_from = rsp) |> 
  select(-pos) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-contr-sum-desc
#| tbl-cap: "foo."

f1_contr_sum_tbl  |> 
  group_by(fa) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Mittelwert")) |> 
  tt(width = 0.5, align = "c", theme = "striped")
```

::: panel-tabset
## Treatment coding

```{r}
lm(rsp ~ fa, f1_contr_sum_tbl, contrasts = list(fa = "contr.treatment")) |> 
  coef() |> round(2)
```

## Effect coding

```{r}
lm(rsp ~ fa, f1_contr_sum_tbl, contrasts = list(fa = "contr.sum")) |> 
  coef() |> round(2)
```
:::

Es gibt noch mehr [Contrast codings](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/), je nachdem wie dein Messwert $y$ oder deine Faktoren $f$ beschaffen sind

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f1-effect-coding
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 10
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p2_f1_contr_sum + p1_f1_contr_sum +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A') +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

::: panel-tabset
## Effect coding ohne Interaktion

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-nointer
#| tbl-cap: "foo"

f2_contr_sum_nointer_tbl |> 
  mutate(pos = rep(1:3,6)) |> 
  select(-key) |> 
  pivot_wider(names_from = fb, values_from = rsp) |> 
  select(-pos) |> 
  set_names(c("", "B.1", "B.2")) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-nointer-desc
#| tbl-cap: "foo."

f2_contr_sum_nointer_tbl |> 
  group_by(fa, fb) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Faktor B", "Mittelwert")) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
lm(rsp ~ fa + fb + fa:fb, f2_contr_sum_nointer_tbl, 
   contrasts = list(fa = "contr.sum", fb = "contr.sum")) |> 
  coef() |> round(2)
```

| $y$  |     | $\beta_0$ | $\beta_{A1}$ | $\beta_{B1}$ | $\beta_{A1:B1}$ |
|------|-----|-----------|--------------|--------------|-----------------|
| $40$ | $=$ | $120$     | $-60$        | $+23.3$      | $-3.33$         |

: foot. {#tbl-anova-namen}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f2-effect-coding-no-inter
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p_f2_contr_sum_nointer

```

## Effect coding mit Interaktion

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-inter
#| tbl-cap: "foo"

f2_contr_sum_inter_tbl |> 
  mutate(pos = rep(1:3,6)) |> 
  select(-key) |> 
  pivot_wider(names_from = fb, values_from = rsp) |> 
  select(-pos) |> 
  set_names(c("", "B.1", "B.2")) |> 
  tt(width = 2/3, align = "c", theme = "striped") |> 
  style_tt(i = c(1:3, 7:9), j = 2, color = "#D55E00",
           bold = TRUE)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-contr-sum-inter-desc
#| tbl-cap: "foo."

f2_contr_sum_inter_tbl |> 
  group_by(fa, fb) |> 
  summarise(Mittelwert = mean(rsp)) |> 
  mutate_if(is.numeric, round, 2) |> 
  set_names(c("Faktor A", "Faktor B", "Mittelwert")) |> 
  tt(width = 2/3, align = "c", theme = "striped") |> 
  style_tt(i = c(1, 5), j = 3, color = "#D55E00",
           bold = TRUE)
```

```{r}
lm(rsp ~ fa + fb + fa:fb, f2_contr_sum_inter_tbl, 
   contrasts = list(fa = "contr.sum", fb = "contr.sum")) |> 
  coef() |> round(2)
```

| $y$   |     | $\beta_0$ | $\beta_{A1}$ | $\beta_{B1}$ | $\beta_{A1:B1}$ |
|-------|-----|-----------|--------------|--------------|-----------------|
| $210$ | $=$ | $120$     | $+5$         | $+23.3$      | $+61.67$        |

: foot. {#tbl-anova-namen}

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-f2-effect-coding-inter
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Visualisierung *[Zum Vergrößern anklicken]*"

p_f2_contr_sum_stat_inter

```
:::
:::::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, WRS2, scales,
               readxl, see, car, patchwork, emmeans,
               interactions, effectsize, afex, report,
               performance, conflicted)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

#### Einfaktorieller Datensatz {.unnumbered .unlisted}

```{r}
#| message: false

fac1_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length) |> 
  mutate(animal = as_factor(animal))|> 
  rowid_to_column(".id")
```

Dann schauen wir uns die Daten einmal in der folgenden Tabelle als Auszug einmal an. Wichtig ist hier nochmal, dass du eben einen Faktor `animal` mit drei Leveln also Gruppen vorliegen hast. Wir wolen jetzt die drei Tierarten hinsichtlich ihrer Sprungweite in \[cm\] miteinander vergleichen. Weil wir jetzt mehr als zwei Gruppen vorliegen haben, sprechen wir von einem multiplen Vergleich.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-table
#| tbl-cap: "Tabelle der Sprungweiten in [cm] als Messwert $y$ von Hunde-, Katzen- und Fuchsflöhen. Der Datensatz ist einfaktoriell, da wir nur einen Behandlungsfaktor $x$ mit `animal` vorliegen haben."

fac1_raw_tbl <- read_xlsx("data/flea_dog_cat_fox.xlsx") |>
  select(animal, jump_length)

rbind(head(fac1_raw_tbl, n = 3),
      rep("...", times = ncol(fac1_raw_tbl)),
      tail(fac1_raw_tbl, n = 3)) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-1fac
#| fig-align: center
#| fig-height: 4
#| fig-width: 4
#| fig-cap: "Beispielhafter einfaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten."

ggplot(data = fac1_tbl, 
       aes(x = animal, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = "point", 
               shape=23, size = 3, fill = "gray50") +
  labs(x = "Flohart", y = "Sprungweite in [cm]") +
  theme(legend.position = "none") + 
  scale_fill_okabeito() 
```

#### Zweifaktorieller Datensatz {.unnumbered .unlisted}

Neben dem einfaktoriellen Datensatz wollen wir uns noch den häufigeren Fall mit zwei Faktoren anschauen. Wir haben also nicht nur die drei Floharten vorliegen und wollen wissen ob diese unterschiedlich weit springen. Darüber hinaus haben wir noch einen zweiten Faktor gewählt. Wir haben die Sprungweiten der Hunde-, Katzen- und Fuchsflöhe nämlich an zwei Messorten, der Stadt und dem Dorf, gemessen. Dadurch haben wir jetzt den Faktor `animal` und den Faktor `site` vorliegen. Wiederum fragen wir usn, ob sich die Sprungweite in \[cm\] der drei Floharten in den beiden Messorten unterscheidet. Im Folgenden lade ich einmal den Datensatz in das Objekt `fac2_tbl`.

```{r}
#| message: false

fac2_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
  filter(site %in% c("city", "village")) |> 
  mutate(animal = as_factor(animal),
         site = as_factor(site))|> 
  rowid_to_column(".id")
```

Betrachten wir als erstes einen Auszug aus der Datentabelle. Wir haben hier als Messwert oder Outcome $y$ die Sprungweite `jump_length` vorliegen. Als ersten Faktor die Variable `animal` und als zweiten Faktor die Variable `site` festgelegt.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-2fac-table
#| tbl-cap: "Tabelle der Sprungweiten in [cm] als Messwert $y$ von Hunde-, Katzen- und Fuchsflöhen an zwei verschiedenen Messorten Stadt und Dorf. Der Datensatz ist zweifaktoriell, da wir einen Behandlungsfaktor $x$ mit `animal` und einen zweiten Faktor mit `site` vorliegen haben."

fac2_raw_tbl <- read_xlsx("data/flea_dog_cat_fox_site.xlsx") |> 
  select(animal, site, jump_length) |> 
      filter(site %in% c("city", "village")) 

rbind(head(fac2_raw_tbl, n = 3),
      rep("...", times = ncol(fac2_raw_tbl)),
      tail(fac2_raw_tbl, n = 3)) |> 
  tt(width = 2/3, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-2fac
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Beispielhafter zweifaktorieller Boxplot für die Sprungweiten in [cm] gruppiert nach den Floharten und den beiden Messorten."

ggplot(data = fac2_tbl, 
       aes(x = site, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() + 
  stat_summary(fun.y = mean, geom = "point", aes(group = animal), 
               shape=23, size = 3, fill = "gray50",
               position = position_dodge(0.75)) +
  labs(x = "Flohart", y = "Sprungweite in [cm]", fill = "Tierart") +
  scale_fill_okabeito() 
```

#### Multifaktorieller Datensatz {.unnumbered .unlisted}

```{r}
fac3_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "fac4") |> 
  select(animal, stage, site, season, jump_length) |> 
  mutate(animal = as_factor(animal),
         stage = factor(stage, level = c("juvenile", "adult")),
         site = as_factor(site),
         season = as_factor(season),
         jump_length = round(jump_length, 2))|> 
  rowid_to_column(".id")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac3-table
#| tbl-cap: "foo."

fac3_raw_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "fac4") |> 
  select(animal, stage, site, season, jump_length) |> 
  mutate_if(is.numeric, round, 2)

rbind(head(fac3_raw_tbl, n = 3),
      rep("...", times = ncol(fac3_raw_tbl)),
      tail(fac3_raw_tbl, n = 3)) |> 
  tt(width = 1, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-3fac
#| fig-align: center
#| fig-height: 6
#| fig-width: 7
#| fig-cap: "foo."

ggplot(data = fac3_tbl, 
       aes(x = stage, y = jump_length, fill = animal)) +
  theme_minimal() +
  geom_boxplot() + 
  stat_summary(fun.y = mean, geom = "point", aes(group = animal), 
               shape=23, size = 3, fill = "gray50",
               position = position_dodge(0.75)) +
  labs(x = "Entwicklungsstadium", y = "Sprungweite in [cm]", fill = "Flohart") +
  facet_wrap(~ site:season) +
  scale_fill_okabeito() +
  theme(legend.position = "top")
```

## Test auf Normalverteilung und Varianzhomogenität {#sec-anova-test-pre}

In dem folgenden Abschnitt testen wir einmal auf Normalverteilung in dem Messwert $y$ und Varianzmomogenität in den Faktoren $f_A$ und $f_B$. Die hier vorhandenen Ergebnisse schreibst du meistens nicht in deine Abschlussarbeit oder zeigst dort die hier vorgestellten Abbildungen. Das dient hier nur zur Überprüfung in deinem statistischen Arbeitsprozess. Du findest noch im Tutorium [Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html#homogeneity-of-variances) ein paar mehr Informationen, wenn es um die ANOVA und die Annahmen geht.

::: callout-warning
## Achtung, bitte beachten!

Wenn du keine normalverteilten Daten hast, dann wird häufig empfholen, dass du deinen Messwert $y$ transformieren sollst. Das ist eine Lösung, wenn du dann nur bei deiner ANOVA bleiben würdest oder dich die Effekte auf der Einheit des Messwert $y$ nicht interessieren. Durch eine Transformation von $y$ verlierst du immer die direkte biologische Interpretation der Effekte aus einem statistischen Test.
:::

Ich zeige dir hier einmal die Funktionen `check_normality()` und `check_homogeneity()` aus dem R PAket `{performance}`. Beide Funktionen funktionieren super und man muss nicht so viel programmieren um die Funktionen zum laufen zu kriegen. Dammit du was testen kannst, musst du auch ein Modell haben was du testen kannst. Ich nutze hier einmal das einfaktorielle sowie zweifaktorielle Modell aus einer linearen Regression. Da sind die Annhamen die gleichen wie bei einer ANOVA.

#### Normalverteilung des Messwerts $y$ {.unnumbered .unlisted}

Die Funktion `check_normality()` nutzt den [Shapiro-Wilk-Test](https://de.wikipedia.org/wiki/Shapiro-Wilk-Test) um auf eine Abweichung von der Normalverteilung zu testen.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_normality()
```

::: panel-tabset
## Einfaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-normal-f1
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_normality()` zur Überprüfung der Normalverteilung des Messwerts in einem einfaktoriellen Modell."


lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_normality() |> 
  plot() +
  scale_fill_okabeito()
```

## Zweifaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-normal-f2
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_normality()` zur Überprüfung der Normalverteilung des Messwerts in einem zweifaktoriellen Modell."


lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  check_normality() |> 
  plot() +
  scale_fill_okabeito()
```
:::

#### Varianzhomogenität der Faktoren $f$ {.unnumbered .unlisted}

Die Funktion `check_homogeneity()` nutzt den [Bartlett-Test](https://de.wikipedia.org/wiki/Bartlett-Test) um auf eine Abweichung von der Varianzhomogenität zu testen.

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_homogeneity()
```

::: panel-tabset
## Einfaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-variance-f1
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_homogeneity()` zur Überprüfung der Varianzhomogenität der Faktoren in einem einfaktoriellen Modell."


lm(jump_length ~ animal, data = fac1_tbl) |> 
  check_homogeneity() |> 
  plot() +
  scale_fill_okabeito()
```

## Zweifaktoriell

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-ggplot-check-anova-variance-f2
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Schnelle Abbildung der Residuen aus `check_homogeneity()` zur Überprüfung der Varianzhomogenität der Faktoren in einem zweifaktoriellen Modell."


lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  check_homogeneity() |> 
  plot() +
  scale_fill_okabeito()
```
:::

Weder Normalverteilung noch Varianzhomogenität?

:   In dem Fall kannst du das R Paket `{WRS2}` nutzen, was ich dir in den folgenden Tabs auch immer wieder vorstelle. Das Paket `{WRS2}` kann mit getrimmten Mittelwerten mit nicht normalverteilten Daten sowie Vamrianzhterogenität umgehen. Das ist eine bessere Lösung als die nicht-parametrischen Verfahren, wenn du auf dem ANOVA Pfad bleiben willst.

Eine weitere Möglichkeit ist es deine Daten zu transformieren, wie ich es oben schon erwähnt habe. Hier findest du dann im [Kaptitel zur Transformation von Daten](#sec-eda-transform) mehrere Optionen. Was da die beste Transformation ist, hängt dann stark von deiner wissenschaftlichen Fragestellung ab. Hier kann ich dann leider keine allgemeine Empfehlung abgeben.

## Einfaktorielle ANOVA

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal, data = fac1_tbl) |> 
  tidy()
```

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  anova() |> 
  tidy()
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  tidy()
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy()
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal + Error(.id), data = fac1_tbl) 
```

## `{WRS2}`

```{r}
t1way(jump_length ~ animal, data = fac1_tbl)
```

Values of = 0.10, 0.30, and 0.50 correspond to small, medium, and large effect sizes.

## Excel
:::

#### Effektschätzer {.unnumbered .unlisted}

```{r}
aov(jump_length ~ animal, data = fac1_tbl) |> 
  eta_squared()
```

#### `{report}` {.unnumbered .unlisted}

Das [R Paket `{report}`](https://easystats.github.io/report/)

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  report()
```

```{r}
lm(jump_length ~ animal, data = fac1_tbl) |> 
  Anova() |> 
  report_table()
```

## Zweifaktorielle ANOVA

### Haupteffekte

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  anova() |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  Anova(type = "III") |> 
  tidy()  |> 
  mutate(p.value = pvalue(p.value))
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal + site + animal:site + Error(.id), data = fac2_tbl) 

```

## `{WRS2}`

```{r}
t2way(jump_length ~ animal + site + animal:site, data = fac2_tbl)
```

## Excel
:::

#### Effektschätzer {.unnumbered .unlisted}

```{r}
aov(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  eta_squared()
```

### Interaktion

::: panel-tabset
## `{ggplot}`

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-1
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

fac2_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, group = site)) +
  theme_minimal() +
  stat_summary(fun = "mean", geom = "point") +
  stat_summary(fun = "mean", geom = "line") +
  scale_color_okabeito()
```

## `{interactions}`

[R Paket `{interactions}`](https://interactions.jacob-long.com/)

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-2
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) |> 
  cat_plot(modx = site, pred = animal, geom = "line") +
  theme_minimal() +
  scale_color_okabeito()
```
:::

## Mehrfaktorielle ANOVA

### Haupteffekte

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*site, data = fac3_tbl,
    contrasts = list(
    animal = "contr.sum",
    stage = "contr.sum",
    site = "contr.sum"
  )) |> 
  Anova(type = "III") |> 
  tidy()  |> 
  mutate(p.value = pvalue(p.value))
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*site, data = fac3_tbl,
    contrasts = list(
    animal = "contr.sum",
    stage = "contr.sum",
    site = "contr.sum"
  )) |> 
  Anova(white.adjust = TRUE, type = "III")  |> 
  tidy() |> 
  mutate(p.value = pvalue(p.value))
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal*stage*site + Error(.id), data = fac3_tbl) 
```

## `{WRS2}`

```{r}
t3way(jump_length ~ animal*stage*site, data = fac3_tbl)
```
:::

### Interaktion

::: panel-tabset
## `{ggplot}`

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-3a
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

fac3_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, linetype = stage, 
             group = interaction(site, stage))) +
  theme_minimal() +
  stat_summary(fun = "mean", geom = "point") +
  stat_summary(fun = "mean", geom = "line") +
  scale_color_okabeito()
```

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-3b
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."
fac3_tbl |> 
  ggplot(aes(x = animal, y = jump_length,
             color = site, group = site)) +
  theme_minimal() +
  stat_summary(fun = "mean", geom = "point") +
  stat_summary(fun = "mean", geom = "line") +
  scale_color_okabeito() +
  facet_wrap(~ stage)
```

## `{interactions}`

[R Paket `{interactions}`](https://interactions.jacob-long.com/)

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-interactionplot-4
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo."

lm(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  cat_plot(modx = site, mod2 = stage, pred = animal,  geom = "line") +
  theme_minimal() +
  scale_color_okabeito()
```
:::

@field2013discovering

```{r}
#| message: false
#| warning: false
lm(jump_length ~ animal*stage*site, data = fac3_tbl) |> 
  Anova(type = "III") |>
  epsilon_squared() |> 
  interpret_eta_squared(rules = "field2013")
```

## MANOVA

[Testing the Assumptions of ANOVAs](https://cran.r-project.org/web/packages/afex/vignettes/assumptions_of_ANOVAs.html#sphericity)

[One-Way MANOVA in R](https://www.datanovia.com/en/lessons/one-way-manova-in-r/)

::: panel-tabset
## `{base}`

## `{MANOVA.RM}`

[Das R Paket `{MANOVA.RM}`](https://cran.r-project.org/web/packages/MANOVA.RM/vignettes/Introduction_to_MANOVA.RM.html)

@friedrich2019resampling

## `{car}`

## `{afex}`

## `{WRS2}`
:::

## Stuff {.unnumbered .unlisted}

https://www.datanovia.com/en/lessons/anova-in-r/#three-way-independent-anova

https://rpubs.com/JS24/853604

https://rpubs.com/krystian3000/853580

https://www.graphpad.com/guides/prism/latest/statistics/stat_what_is_three-way_anova_used_f.htm

## Der ANOVA Pfad {.unnumbered .unlisted}

Hier einmal eine Mairmaid Flowchart rein?

## Referenzen {.unnumbered}
