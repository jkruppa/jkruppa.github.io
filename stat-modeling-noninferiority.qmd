```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, openxlsx)
```

# Äquivalenz oder Nichtunterlegenheit {#sec-noninf}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"Absence of evidence is not evidence of absence" --- @altman1995statistics*

In diesem Kapitel wollen wir uns mit Gleichheit beschäftigen. Dabei gibt es zwei Arten von Gleichheit. Zum einen können wir uns die technische Gleichheit anschauen oder aber die medizinische- oder Behandlungsgruppengleichheit. Wir definieren die beiden Settings daher wie folgt.

-   **Technische Gleichheit** wollen wir nachweisen, wenn wir zwei *technische* Messmethoden miteinander vergleichen. Wir messen also einmal ein Wachstum mit dem Verfahren A und einmal mit dem Verfahren B. In beiden Fällen erhalten wir dann eine kontinuierliche Zahl, wie zum Beispiel das Gewicht. Jetzt wollen wir wissen, ob das Verfahren A gleich dem Verfahren B das Wachstum gemessen hat.
-   **Medizinische- oder Behandlungsgleichheit** wollen wir nachweisen, wenn wir verschiedene Behandlungs*gruppen* haben. Damit wollen wir auch verschiedene Hypothesen testen. Diese Behandlungsgruppen vergleichen wir dann zu *einer* Kontrolle oder Standard und wollen nachweisen, dass unsere Behandlungsgruppen *gleich* zu dem Standard sind. Die Anwendung ist auch eher bei Tieren oder Menschen zu finden. Wir wollen hier also explizit keine technische Gleichheit nachweisen.

Je nachdem welche *Gleichheit* du dir anschauen willst, musst du natürlich auch andere statistische Verfahren wählen. Wir schauen uns daher in diesem Kapitel zuerst einmal die technische Gleichheit an - die ich hier mal so benenne - und danach die medizinische Gleichheit, die sich auf das statistische Hypothesentesten bezieht.

::: column-margin
Bei der *technischen* Gleichheit nutzen wir die lineare Regression und deren Gütekriterien. Bei der *medizinischen* Gleichheit drehen wir die statistischen Null- und Alternativehypothese und haben damit andere Probleme. Wir rechnen aber einen klassischen Hypothesentest.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom, readxl,
               effectsize, multcompView, multcomp,
               janitor, see, parameters, yardstick,
               conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::mutate)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Als erstes wollen wir uns einmal die Daten für die Überprüfung der technischen Gleichheit anschauen. Die Daten stammen aus Dronenüberflügen zur Bestimmung der Grasdichte auf Weideflächen aus der Datei `drone_tech.xlsx`. Dabei haben wir zum einen die Grasdichte traditionell mit einem Druckstab gemessen `pressure_stick` und vergleichen diese Werte dann mit den Werten aus dem Dronenüberflug. Der Drohnenüberflug liefert uns Bilder und aus den Bildern extrahieren wir einen RGB-Wert (abk. *Red, Green, Blue*) in der Spalte `drone_rgb` oder einen CMYK-Wert (abk. *Cyan, Magenta, Yellow (Gelb), Key (Schwarz)*) in der Spalte `drone_cmyk`. Wir wollen nun schauen, ob wir die drei Werte sinnvoll in ein Verhältnis setzen können. Ein Auszug aus den Daten ist nochmal in der @tbl-equal-tech-01 dargestellt.

```{r}
#| message: false
#| echo: false

set.seed(20230564)
drone_tbl <- tibble(pressure_stick = rnorm(317, 1000, 200),
                    drone_rgb = -1000 + 1.20 * pressure_stick + rnorm(length(pressure_stick), 100, 60),
                    drone_cmyk = -1200 + 0.2 * pressure_stick + rpois(length(pressure_stick), 1200)) %>% 
  mutate_if(is.numeric, round, 2) %>% 
  filter(drone_rgb > 1 & drone_cmyk > 1)

write.xlsx(drone_tbl, "data/drone_tech.xlsx", rowNames = FALSE)
```

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datentabelle für den technischen Vergleich eines Druckstabes und dem RGB-Werten eines Dronenüberflugs auf die Grasdichte auf Weideflächen."
#| label: tbl-equal-tech-01

rbind(head(drone_tbl, n = 3),
      rep("...", times = ncol(drone_tbl)),
      tail(drone_tbl, n = 3)) %>% 
  kable(align = "c", "pipe")
```

In unserem zweiten Datenbeispiel schauen wir uns die Keimungsdaten nach Behandlung mit sechs biologischen Pilzmittel unter zwei Kältebehandlungen aus der Datei `cold_seeds.xlsx` an. Dabei ist wichtig zu wissen, dass es eine Kontrolle gibt, die das chemische Standardpräparat repräsentiert. Wir wollen jetzt wissen, ob unsere biologischen Alternativen *gleich* gut sind. Das heißt, wir wollen nicht mehr oder weniger als das Standardpräparat sondern gleichviel. Als Outcome zählen wir die Sporen auf den jungen Keimlingen. Da unsere Pflanze auch eine Kältebehandlung überstehen würde, haben wir auch noch die beiden Kältevarianten mit untersucht. In der @tbl-noninf-01 sind die Daten einmal dargestellt.

```{r}
#| message: false
#| echo: false
cold_seed_raw_tbl <- read_excel("data/cold_seeds.xlsx") %>% 
  mutate_if(is.numeric, round, 2)

cold_seed_tbl <- cold_seed_raw_tbl
```

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Nicht transformierter Datensatz zu dem Keimungsexperiment mit biologischen Pilzpräparaten."
#| label: tbl-noninf-01

rbind(head(cold_seed_raw_tbl, n = 6),
      rep("...", times = ncol(cold_seed_raw_tbl)),
      tail(cold_seed_raw_tbl, n = 6)) %>% 
  kable(align = "c", "pipe")
```

Wir müssen jetzt leider nochmal ran und die Daten etwas aufräumen. Zum einen muss die erste Behandlung raus, hier handelt es sich nur um eine positive Kontrolle, ob überhaupt etwas gewachsen ist. Dann wollen wir uns die Daten auch log-transformieren. Das hat den Grund, dass die statistischen Verfahren in der Äquivalenzanalyse eine Normalverteilung verlangen. Mit der log-Transformation erreichen wir log-normalverteilte Daten, die einer Normalverteilung recht nahe kommen. Am Ende wollen wir dann auch die zweite Behandlung so benennen, dass wir auch immer die Kontrolle erkennen.

```{r}
cold_seed_tbl <- cold_seed_tbl %>%   
  clean_names %>% 
  filter(trt != 1) %>% 
  mutate(trt = as_factor(trt),
         log_cold = log(cold),
         log_non_cold = log(non_cold),
         trt = fct_recode(trt, ctrl = "2")) 
```

Es ergibt sich dann die @tbl-noninf-02. Wir werden dann in der folgenden Analyse nur noch die log-transformierten Spalten `log_cold` und `log_non_cold` nutzen.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Transformierter Datensatz zu dem Keimungsexperiment mit biologischen Pilzpräparaten."
#| label: tbl-noninf-02

cold_seed_tab_tbl <- cold_seed_tbl %>% 
  mutate(trt = as.character(trt)) %>% 
  mutate_if(is.numeric, round, 2)

rbind(head(cold_seed_tab_tbl, n = 4),
      rep("...", times = ncol(cold_seed_tab_tbl)),
      tail(cold_seed_tab_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

## Technische Gleichheit

Beginnen wir also mit der Beurteilung von der technischen Gleichheit zweier Verfahren. Ich nutze hier das Wort *technische* Gleichheit, da wir hier nicht zwei Gruppen miteinander vergleichen, sondern eben kontinuierlich gemessene Werte haben und wissen wollen, ob diese gemessenen Werte aus den beiden Verfahren gleich sind. In unserem Beispiel wollen wir wissen, ob wir den Druckstab zum Messen der Grasdichte durch einen Drohnenüberflug erstetzen können. Der Dronenflug produziert Bilder und wir können auf zwei Arten Zahlen aus den Bildern generieren. Wir extrahieren entweder die RGB-Werte der Bilder oder aber die CMYK-Werte. Hier ist natürlich ein Schritt den ich überspringe, wir erhalten am Ende eben einen Wert für ein Bild. Oder andersherum, wir können genau einer Messung mit dem Druckstab ein Bild der Drone zuordnen.

In der @fig-equal-tech-01-1 und in der @fig-equal-tech-01-2 sehen wir den Zusammenhang zwischen dem Druckstab und der Dronenmessung für beide Farbskalenwerte nochmal visualisiert. In einer *idealen* Welt würden alle Punkte auf einer Linie liegen. Das heißt, wir haben einen perfekten Zusammenhang zwischen dem Druckstab und den Farbskalenwerten. So ein perfekter Zusammenhang tritt in der Natur nie auf, deshalb müssen wir uns nun mit statistischen Maßzahlen behelfen.

Wir können die Funktion `geom_smooth()` nutzen um eine lineare Funktion durch die Punkte zu legen. Wir sehen ist der Fehler, dargestellt als grauer Bereich, bei den CMYK-Werten größer. Auch haben wir Punkte die etwas anch oben weg streben. In der RGB-Skala haben wir eher einen linearen Zusammenhang. Im Folgenden wollen wir uns dann einmal die statistischen Maßzahlen zu der Visualisierung anschauen.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-equal-tech-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Vergleich der beiden Farbskalen aus der Dronenmessung zu der Grasdichte durch den Druckstab."
#| fig-subcap: 
#|   - "Dronenmessung mit RGB-Werten."
#|   - "Dronenmessung mit CMYK-Werten."
#| layout-nrow: 1
#| column: page

ggplot(drone_tbl, aes(drone_rgb, pressure_stick)) +
  theme_bw() +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)

ggplot(drone_tbl, aes(drone_cmyk, pressure_stick)) +
  theme_bw() +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE)
```

### Bestimmtheitsmaß $R^2$

Für die genaueren Werte der linearen Funktion nutzen wir dann die Funktion `lm()`. Wir brauchen die statistischen Maßzahlen höchstens, wenn uns eine Umrechung von den Werten von der einen Messung zu der anderen Messung interessiert.

```{r}
#| message: false
#| warning: false
fit_drone <- lm(pressure_stick ~ drone_rgb, data = drone_tbl)
fit_drone %>% model_parameters()
```

Zum einen können wir uns jetzt auch die lineare Funktion und damit den Zusammenhang von dem Druckstab zu der RGB-Farbskala erstellen. Mir der folgenden Formel können wir dann die Werte der Dronen RGB-Farbskala in die Werte des Druckstabes umrechnen.

$$
pressure\_stick = 766.33 + 0.78 \cdot drone\_rgb
$$

Zum anderen erhalten wir mit der Funktion `lm()` dann auch die Möglichkeit das Bestimmtheitsmaß $R^2$ zu berechnen. Du kennst das Bestimmtheitsmaß $R^2$ schon aus dem Kapitel für die Qualität einer linearen Regression. Hier nochmal kurz zusammengefasst, das Bestimmtheitsmaß $R^2$ beschreibt, wie gut die Punkte auf der Geraden liegen. Ein Bestimmtheitsmaß $R^2$ von 1 bedeutet, dass die Punkte perfekt auf der Geraden liegen. Ein Bestimmtheitsmaß $R^2$ von 0, dass die Punkte eher wild um eine potenzielle Graden liegen.

Im Folgenden können wir uns noch einmal die Formel des Bestimmtheitsmaß $R^2$ anschauen um etwas besser zu verstehen, wie die Zusammenhänge mathematisch sind. Zum einen brauchen wir den Mittelwert von $y$ als $\bar{y}$ sowie die Werte der einzelnen Punkte $\bar{y}$ und die Werte auf der Geraden mit $\hat{y}_i$.

$$
\mathit{R}^2 = 
\cfrac{\sum_{i=1}^N \left(\hat{y}_i- \bar{y}\right)^2}{\sum_{i=1}^N \left(y_i - \bar{y}\right)^2}
$$

In der @fig-bestimmtheit-tech-01 sehen wir den Zusammenhang nochmal visualisiert. Wenn die Abstände von dem Mittelwert zu den einzelnen Punkten mit $y_i - \bar{y}$ gleich dem Abstand der Mittelwerte zu den Punkten *auf* der Geraden mit $\hat{y}_i- \bar{y}$ ist, dann haben wir einen perfekten Zusammenhang.

![Auf der linken Seite sehen wir eine Gerade die nicht perfekt durch die Punkte läuft. Wir nehmen ein Bestimmtheitsmaß $R^2$ von ca. 0.7 an. Die Abstände der einzelnen Beobachtungen $y_i$ zu dem Mittelwert der y-Werte $\bar{y}$ ist nicht gleich den Werten auf der Geraden $\hat{y}_i$ zu dem Mittelwert der y-Werte $\bar{y}$. Dieser Zusammenhang wird in der rechten Abbildung mit einem Bestimmtheitsmaß $R^2$ von 1 nochmal deutlich.](images/statistical_modeling_bestimmtheit.png){#fig-bestimmtheit-tech-01 fig-align="center"}

Wir können die Funktion `glance()` nutzen um uns das `r.squared` und das `adj.r.squared` wiedergeben zu lassen.

```{r}
#| message: false

fit_drone %>% 
  glance() %>% 
  select(r.squared)
```

Wir haben wir ein $R^2$ von $0.932$ vorliegen. Damit erklärt unser Modell bzw. die Gerade 93.2% der Varianz. Der Anteil der erklärten Varianz ist auch wunderbar hoch, so dass wir davon ausgehen können, dass der Druckstab und die RGB-Werte der Drone ungefähr das Gleiche wiedergeben.

## Korrelation

Neben der Information wie gut die Punkte auf der Geraden liegen, also wie die Punkte um die Gerade streuen, können wir uns auch die Korrelation und damit die Steigung der Gerade wiedergeben lassen. Das Bestimmtheitsmaß $R^2$ sagt uns nämlich nichts über die Richtung der Geraden aus. Die Korrelation liefert uns die Steigung der Geraden mit dem Vorzeichen.

Wir können hier verschiedene Korrelationsmaße berechnen. Am häufigsten werden wir die Korrelation nach Pearson berechnen, da wir von einem normalverteilten $y$ ausgehen. Wenn dies nicht der Fall sein sollte empfiehlt sich stattdessen den Korrelationkoeffizienten nach Spearman zu nutzen.

```{r}
drone_tbl %$% 
  cor(pressure_stick, drone_rgb, method = "pearson") %>% 
  round(2)

drone_tbl %$% 
  cor(pressure_stick, drone_rgb, method = "spearman") %>% 
  round(2)
```

::: column-margin
Wir nutzen hier den `%$%`-Operator, da wir in die Funktion `cor()` die Spalten übergeben wollen. Die Funktion `cor()` ist relativ alt und möchte daher keinen Datensatz sondern zwei Vektoren.
:::

Nachdem wir die Korrelation berechnet haben, sehen wir das wir einen *positiven* Zusammenhang vorliegen haben. Die Gerade durch die Punkte steigt an und ist fast eine 45$^{\circ}$ Gerade, da wir eine Korrelation nahe 1 vorliegen haben.

### MSE, RMSE, nRMSE und MAE

Neben der Betrachtung der Abweichung vom Mittelwert von $y$ können wir uns auch die Abstände von den geschätzten Punkten *auf* der Geraden $\hat{y}_i$ zu den eigentlichen Punkten anschauen $y_i$. Wir haben jetzt zwei Möglichkeiten die Abstände zu definieren.

1.  Wir schauen uns die quadratischen Abstände mit $(y_i - \hat{y}_i)^2$ an. Wir berechnen dann die mittlere quadratische Abweichung (eng. *mean square error* abk. *MSE*).
2.  Wir schauen uns die absoluten Abstände mit $|y_i - \hat{y}_i|$ an. Wir berechnen dann den mittleren absoluten Fehler (eng. *mean absolute error*, abk. *MAE*).

Im Folgenden betrachten wir erst den MSE und seine Verwandten. Wie wir an der Formel sehen, berechnen wir für den MSE einfach nur die quadratische Abweichung zwischen den Beobachtungen $y_i$ und den Werten auf der berechneten Geraden $\hat{y}_i$. Dann summieren wir alles auf und teilen noch durch die Anzahl der Beobachtungen also Punkte $n$.

$$
MSE = \cfrac{1}{n}\sum^n_{i=1}(y_i - \hat{y}_i)^2
$$

Häufig wollen wir dann nicht die *quadratischen* Abweichungen angeben. Wir hätten dann ja auch die Einheit der Abweichung im Quadrat. Daher ziehen wir die Wurzel aus dem MSE und erhalten den *root mean square error* (abk. *RMSE*). Hierfür gibt es dann keine gute Übersetzung ins Deutsche.

$$
RMSE = \sqrt{MSE} = \sqrt{\cfrac{1}{n}\sum^n_{i=1}(y_i - \hat{y}_i)^2}
$$

Der RMSE ist ein gewichtetes Maß für die Modellgenauigkeit, das auf der gleichen Skala wie das Vorhersageziel angegeben wird. Einfach ausgedrückt kann der RMSE als der durchschnittliche Fehler interpretiert werden, den die Vorhersagen des Modells im Vergleich zum tatsächlichen Wert aufweisen, wobei größere Vorhersagefehler zusätzlich gewichtet werden.

Je näher der RMSE-Wert bei 0 liegt, desto genauer ist das Modell. Der RMSE-Wert wird jedoch auf derselben Skala zurückgegeben wie das Ziel, für das Sie Vorhersagen treffen, und daher gibt es keine allgemeine Regel für die Interpretation von Wertebereichen. Die Interpretation Ihres Wertes kann nur innerhalb Ihres Datensatzes bewertet werden.

```{r}
drone_tbl %>%
  rmse(pressure_stick, drone_rgb)
```

Als letzte Möglichkeit sei noch der normalisierte *root mean square error* (abk. *nRMSE*) genannt. In diesem Fall wird der RMSE nochmal durch den Mittelwert von $y$ geteilt.

$$
nRMSE = \cfrac{RMSE}{\bar{y}} = \cfrac{\sqrt{MSE}}{\bar{y}} = \cfrac{\sqrt{\cfrac{1}{N}\sum^N_{i=1}(y_i - \hat{y}_i)^2}}{\bar{y}}
$$

In wie weit jetzt jedes MSE Abweichungsmaß sinnvoll ist und auch in der Anwendung passen mag, sei einmal dahingestellt. Wichtig ist hier zu Wissen, dass wir die MSE-Fehler nutzen um verschiedene Verfahren zu vergleichen. Ein kleiner Fehler ist immer besser. Ein einzelner MSE-Wert an sich, ist dann immer schwer zu interpretieren.

Als Alternative zu den MSE-Fehlern bietet sich dann der MAE an. Hier schauen wir dann auf die *absoluten* Abstände. Wir nehmen also das Vorzeichen raus, damit sich die Abstände nicht zu 0 aufaddieren. Wir haben dann folgende Formel vorliegen.

$$
MAE = \cfrac{1}{n}\sum^n_{i=1}|y_i - \hat{y}_i|
$$

Der MAE hat gegenüber dem RMSE Vorteile in der Interpretierbarkeit. Der MAE ist der Durchschnitt der absoluten Werte der Fehler. MAE ist grundsätzlich leichter zu verstehen als die Quadratwurzel aus dem Durchschnitt der quadrierten Fehler. Außerdem beeinflusst jede einzelne Abweichung den MAE in direktem Verhältnis zum absoluten Wert der Abweichung, was bei der RMSE nicht der Fall ist. Der MAE ist nicht identisch mit dem mittleren quadratischen Fehler (RMSE), auch wenn einige Forscher ihn so angeben und interpretieren. MAE ist konzeptionell einfacher und auch leichter zu interpretieren als RMSE: Es ist einfach der durchschnittliche absolute vertikale oder horizontale Abstand zwischen jedem Punkt in einem Streudiagramm und der Geraden.

```{r}
drone_tbl %>%
  mae(pressure_stick, drone_rgb)
```

Wir können uns mit der Funktion `metrics()` auch die Fehler zusammenausgeben lassen.

```{r}
drone_tbl %>%
  metrics(pressure_stick, drone_rgb)
```

Wie schon oben geschrieben, der MSE und Co. sind nur in einem Vergleich sinnvoll. Deshalb hier nochmal der Vergleich der beiden Farbskalen der Dronenbilder.

```{r}
drone_tbl %>%
  metrics(pressure_stick, drone_rgb)

drone_tbl %>%
  metrics(pressure_stick, drone_cmyk)
```

Wir schon zu erwarten ist auch hier der Fehler bei den RGB-Werten kleiner als bei den CMYK-Werten. Daher würden wir uns hier für die Umrechnung der RGB-Werte entscheiden.

## Medizinische- oder Behandlungsgleichheit

![](images/caution.png){fig-align="center" width="50%"}

::: callout-important
## Disclaimer - Wichtig! Lesen!

Der folgende Text ist ein *Lehr*text für Studierende. Es handelt sich keinesfalls um eine textliche Beratung für Ethikanträge oder Tierversuchsanträge geschweige den der Auswertung einer klinischen Studie. Alle Beispiel sind im Zweifel an den Haaren herbeigezogen und dienen nur der Veranschaulichung *möglicher* Sachverhalte.

Antragsteller:innen ist die statistische Beratung von einer entsprechenden Institution dringlichst angeraten.
:::

Wir eingangs schon geschrieben wollen wir bei der *Medizinische- oder Behandlungsgleichheit* nachweisen, dass sich verschiedene Behandlungs*gruppen* zu *einer* Kontrolle oder Standard *gleich* oder äquivalent sind. Wir haben es hier als mit einem klassischen Gruppenvergleich zu tun, bei dem wir die Hypothesen drehen. Wenn wir auf Unterschied testen, dann haben wir in der Nullhypothese $H_0$ die Gleichheit zwischen zwei Mittelwerten stehen. Wir wollen die Gleichheit der Mittelwerte ablehnen. Wir schreiben also unsere beiden Hypothesenpaare wie folgt.

::: column-margin
Wie immer gibt es auch tolle Tutorien wie das Tutorium von Daniël Lakens [Equivalence Testing and Interval Hypotheses](https://lakens.github.io/statistical_inferences/09-equivalencetest.html)
:::

Statistischer Test auf Unterschied

:   $$
    \begin{aligned} 
    H_0: \bar{y}_{1} &= \bar{y}_{2} \\  
    H_A: \bar{y}_{1} &\neq \bar{y}_{2} \\   
    \end{aligned}
    $$

Wenn wir jetzt einen statiistischen Teste für die Äquivalenz oder Nichtunterlegenheit rechnen wollen, dann drehen wir das Hypothesenpaar. Wir wollen jetzt in der Nullhypothese die "Ungleichheit" der Mittelwerte ablehnen.

Statistischer Test auf Gleichheit

:   $$
    \begin{aligned} 
    H_0: \bar{y}_{1} &\neq \bar{y}_{2} \\  
    H_A: \bar{y}_{1} &= \bar{y}_{2} \\   
    \end{aligned}
    $$

Und hier beginnt auch schon die Krux. Konnten wir uns relativ einfach einigen, dass ein Mittelwertesunterschied $\Delta$ von 0 eine Gleichheit zwischen den beiden Mittelwerten der beiden Gruppen bedeutet, so ist die Festlegung auf einen Unterschied schon schwieriger. Die Bewertung, ob zwei Mittelwerte sich für zwei Gruppen unterscheiden, kann nur im Kontext der biologischen oder medizinischen Fragestellung beantwortet werden. Die Diskussion, ob ein $\Delta$ von 0.1 noch gleich oder ungleich ist, kann rein numerisch schwer geführt werden. Deshalb gibt es einige Richtlinien und Richtwerte.

Aus dem Grund definieren wir Äquivalenzgrenzen oder Äquivalenzzone. Die Äquivalenzzone wird durch eine untere Äquivalenzgrenze und/oder eine obere Äquivalenzgrenze definiert. Die untere Äquivalenzgrenze (UEG) definiert deine untere Grenze der Akzeptanz für die Mittelwertsdifferenz. Die obere Äquivalenzgrenze (UEL) definiert die obere Grenze der Akzeptanz für die Mittelwertsdifferenz. Jede Abweichung von der Mittelwertsdifferenz, die innerhalb dieses Bereichs der Äquivalenzgrenzen liegt, wird als unbedeutend angesehen. Du kannst hier statt Mittelwertsdifferenz natürlich auch in Anteilen denken, wenn es um das Odds ratio oder Risk ratio geht.

Als erstes Beispiel einer Behörde hier einmal das Zitat der Europäische Behörde für Lebensmittelsicherheit (EFSA) für die Zulassung eines Pilzmittels aus unseren Beispiel. Hier sei angemerkt, dass viele statistische Methoden von einem normalverteilten Outcome oder aber approximativ log-normalverteilten Outcome ausgehen. Deshalb werden die Äquivalenzgrenzen hier auch auf der $log$-Skala benannt.

> "The limits for equivalence were set to $-\cfrac{1}{2}\log$ and $\cfrac{1}{2}\log$ equal to -0.5 and 0.5 because of the log transformation of the outcome." --- [Europäische Behörde für Lebensmittelsicherheit (EFSA)](https://www.efsa.europa.eu/de)

Häufig werden die Effekte aus verschiedenen Studien auch skaliert, damit wir dann die Effekte besser vergleichen können. Als Skalierung bietet sich eine Normalisierung oder Standardisierung an. Als Beispiel in den Pflanzenwissenschaften sei @van2019equivalence genannt. @van2019equivalence führen Analysen zum Schutz vor unbeabsichtigten Auswirkungen von gentechnisch verändertem Mais auf die Umwelt oder die menschliche Gesundheit durch \[[Link](https://www.sciencedirect.com/science/article/pii/S0278691519300572)\]. Hier hilft besonders sich von anderen Studien *vor* dem Experiment zu inspirieren zu lassen. Um eine ausgiebige Literaturrecherche kommt man dann meist nicht rum.

Auch sei noch das Institut für Qualität und Wirtschaftlichkeit im Gesundheitswesen (IQWiG) erwähnt, welches für die Regulierung von Anwendungen in der Humanmedizin zu tun hat. Da sind ja die Grenzen immer etwas fließend. Wann ist ein Medikament *nur* für die Agrarwissenschaften relevant und hate keine Auswirkungen auf den Menschen? Diese Frage lasse ich hier offen. Hier hilft aber auch der Blick in das Papier *Allgemeine Methoden* und dann das Kapitel 9. Hier einmal ein Zitat aus dem Abschnitt zu dem Nachweis zur Gleichheit. Wir sehen. so einfach ist die Sachlage nicht.

> "Umgekehrt erfordert auch die Interpretation nicht statistisch signifikanter Ergebnisse Aufmerksamkeit. Insbesondere wird ein solches Ergebnis nicht als Nachweis für das Nichtvorhandensein eines Effekts (Abwesenheit bzw. Äquivalenz) gewertet." --- Kapitel 9.3.5 Nachweis der Gleichheit in [Allgemeine Methoden des Institut für Qualität und Wirtschaftlichkeit im Gesundheitswesen (IQWiG)](https://www.iqwig.de/ueber-uns/methoden/methodenpapier/)

Schauen wir uns nun nochmal unsere Keimungsdaten nach Behandlung mit sechs biologischen Pilzmittel unter zwei Kältebehandlungen an. Wenn wir den Richtlinien der EFSA folgen, dann rechnen wir auf den $\log$-transformierten Daten. Die $\log$-transformierten Daten sind damit auch approximativ normalverteilt, so dass wir hier dann alle statistischen Methoden nutzen können, die eine Normalverteilung voraussetzen.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-noninf-1
#| fig-align: center
#| fig-height: 6
#| fig-width: 6
#| fig-cap: "test"

cold_seed_tbl %>% 
  pivot_longer(cold:last_col(),
               names_to = "type",
               values_to = "growth") %>% 
  mutate(type = as_factor(type)) %>% 
  ggplot(aes(trt, growth, fill = trt)) +
  theme_bw() +
  geom_boxplot() +
  facet_wrap(~ type, scales = "free_y") +
  scale_fill_okabeito() +
  theme(legend.position = "none")
```

### ANOVA mit Effektschätzer

```{r}
#| message: false
lm_non_cold_fit <- lm(log_non_cold ~ trt, data = cold_seed_tbl)

lm_non_cold_fit %>% anova %>% model_parameters()
```

```{r}
#| message: false
lm_non_cold_fit %>% eta_squared()
```

```{r}
#| message: false
lm_cold_fit <- lm(log_cold ~ trt, data = cold_seed_tbl)

lm_cold_fit %>% anova %>% model_parameters()
```

```{r}
#| message: false
lm_cold_fit %>% eta_squared()
```

### Äquivalenztest

```{r}
res_non_cold <- equivalence_test(lm_non_cold_fit, 
                                 ci = 0.95,
                                 range = c(-0.5, 0.5))
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-noninf-2
#| fig-align: center
#| fig-height: 6
#| fig-width: 6
#| fig-cap: "test"

plot(res_non_cold) +
  theme_minimal()
```

```{r}
res_cold <- equivalence_test(lm_cold_fit, 
                             ci = 0.95,
                             range = c(-0.5, 0.5))
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-noninf-3
#| fig-align: center
#| fig-height: 6
#| fig-width: 6
#| fig-cap: "test"

plot(res_cold) +
  theme_minimal()
```

## Links

https://cran.r-project.org/web/packages/PowerTOST/vignettes/NI.html

https://cran.rstudio.com/web/packages/TOSTER/vignettes/IntroductionToTOSTER.html
