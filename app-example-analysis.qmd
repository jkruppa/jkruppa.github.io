```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, openxlsx)
```

# Beispielhafte Auswertungen {#sec-beispiel-auswertung}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

::: callout-tip
## Beispielhafte Auswertungen per Video

Du findest auf YouTube in der Playlist [Spielweise in R (Level 3)](https://www.youtube.com/playlist?list=PLe51bCp9JvEFZeYClBKad6yurjUzc8jXp) viele der Analysen hier einmal als Video. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Worum geht es in diesem Kapitel? Ich rechne hier fröhlich Dinge und präsentiere dann die Ergebnisse. Das heißt, du findest hier beispielhafte Auswertungen, die eventuell auch deine Problemstellung betreffen.

-   In @sec-app-example-iso schauen wir uns einmal die Erstellung eines Isoplethendiagramms für Münster & Osnabrück aus den frei verfügbaren Daten des Deutschen Wetterdienstes an.
-   In @sec-app-example-number-groups rechnen wir einmal ein simples Beispiel für Zähldaten in zwei Gruppen. Wir haben hier nicht wiederholt gezählt, sondern nur jeweils einmal an einer Stelle.
-   In @sec-app-example-anova-inter rechnen wir nochmal eine zweifaktorielle ANOVA mit Interaktionsterm durch. Wir kriegen dann unser *compact letter display* wie auch die Konfidenzintervalle wieder.
-   In @sec-mult-map-ght rechnen wir einen Games Howell Test für normalverteilte Daten mit Varianzheterogenität. Hier hauen wir ein wenig auf die Pauke und rechnen alles in wenigen Zeilen mit der Funktion `mpa()`. War eine spaßige Auswerung für mich, da ich hier mal wieder programmieren üben konnte.

Je weiter du nach unten in diesem Kapitel kommst, desto wilder wird der R Code. Ich werde noch eine Zeit brauchen, bis ich alles wieder schon mit Text hier verarbeitet habe. Es wird aber immer mal wieder etwas *messy* aussehen. Hier wird eben auch gearbeitet.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, readxl, 
               broom, multcomp, emmeans, effectsize, report,
               see, metR, parameters, multcompView,
               modelsummary, rstatix,
               conflicted)
## resolve some conflicts with same function naming
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Isoplethendiagramm für Münster & Osnabrück {#sec-app-example-iso}

Im Folgenden zeige ich ein Beispiel für die Nutzung der [entgeltfreien Informationen auf der DWD-Website](https://www.dwd-shop.de/index.php/default/kostenfreie-informationen.html). Wir finden dort auf der Seite die [Klimadaten für Deutschland](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html#buehneTop) und natürlich auch die Daten für Münster/Osnabrück. Ich habe mir flux die Tageswerte runtergeladen und noch ein wenig den Header der txt-Datei angepasst. Du findest die Datei [`day_values_osnabrueck.txt`](https://github.com/jkruppa/jkruppa.github.io/tree/master/data) wie immer auf meiner GitHub Seite. Du musst dir für andere Orte die Daten nur entsprechend zusammenbauen. Am Ende brauchen wir noch die [Informationen zu den Tages- und Monatswerten](https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html) damit wir auch verstehen, was wir uns da von der DWD runtergeladen haben. Ich nutze gleich nur einen Ausschnitt aus den Daten.

::: column-margin
Wenn wir [Geocomputation with R](https://geocompr.robinlovelace.net/index.html) machen wollen, dann haben wir natürlich noch viele andere Möglichkeiten. Das verlinkte Buch hilft da weiter.
:::

Dann lesen wir die Daten einmal ein und müssen dann eine Winkelzüge machen, damit wir aus dem Datum `JJJJMMDD` dann jeweils den Monat und den Tag extrahiert kriegen. Dann müssen wir die Monatszahl und die Tageszahl noch in eine Zahl umwandeln. Sonst geht es schlecht mit dem Zeichnen des Konturplots. Wir nehmen dann die Temperaturen `TG`, `TN`, `TM` und `TX` um diese Temperaturen in vier Konturplots zu zeigen.

```{r}
#| message: false
#| echo: true
#| warning: false

weather_tbl <- read_table("data/day_values_osnabrueck.txt") %>% 
  mutate(JJJJMMDD = as.Date(as.character(JJJJMMDD), "%Y%m%d"),
         day = as.numeric(format(JJJJMMDD, "%d")), 
         month = as.numeric(format(JJJJMMDD, "%m")), 
         year = as.numeric(format(JJJJMMDD, "%Y"))) %>% 
  select(month, day, TG, TN, TM, TX) %>% 
  na.omit() %>% 
  gather(temp, grad, TG:TX) %>% 
  mutate(temp = factor(temp, 
                       labels = c("Minimum der Temperatur in 5 cm (TG)",
                                  "Minimum der Temperatur in 2 m (TN)",
                                  "Mittel der Temperatur in 2 m (TM)",
                                  "Maximum der Temperatur in 2 m (TX)")))

```

Nachdem wir ordentlich an den Daten geschraubt haben können wir jetzt in @fig-weather die vier Konturplots sehen. Wir mussten noch das Spektrum der Farben einmal drehen, damit es auch mit den Temperaturfarben passt und wir haben noch ein paar Hilfslinien miteingezeichnet.

```{r}
#| message: false
#| echo: true
#| warning: false
#| label: fig-weather
#| fig-align: center
#| fig-height: 9
#| fig-width: 9
#| fig-cap: "Konturplot der verschiedenen Temperaturen."
#| column: page

ggplot(weather_tbl, aes(month, day, z = grad)) +
  theme_minimal() +
  geom_contour_filled(bins = 13) +
  geom_contour(binwidth = 2, color = "black") +
  facet_wrap(~ temp, ncol = 2) + 
  scale_fill_brewer(palette = "Spectral", direction = -1) +
  scale_x_continuous(breaks = 1:12) +
  geom_vline(xintercept = 1:12, alpha = 0.9, linetype = 2) +
  geom_hline(yintercept = c(5, 10, 15, 20, 25, 30), 
             alpha = 0.9, linetype = 2)

```

## Analyse von Anzahlen in zwei Gruppen {#sec-app-example-number-groups}

In dieser sehr simplen Analyse haben wir zwei Gruppen vorliegen. Die Gruppe 1 ist hat zwei Level oder Behandlungen abgekürzt mit I und II. Die Gruppe 2 hat insgesamt vier Level oder eben Behandlungen, die wir mit A, B, C und D bezeichnen. Wir haben jetzt für die jeweiligen Kombinationen auf dem Feld etwas *gezählt*. Wir haben also für jede dieser Kombinationen nur eine Zahl. Es ergbit sich somit die folgende Matrix an Zahlen.

```{r}
rel_mat <- matrix(c(45, 14, 4, 0,
                    25, 32, 5, 1), nrow = 2, byrow = TRUE,
                  dimnames = list(c("I", "II"), c("A", "B", "C", "D")))
rel_mat
```

Nun können wir den $\mathcal{X}^2$-Test nutzen, um zu testen, ob die Zahlen in der Matrix bzw. auf unseren Feld gelcihverteilt sind. Die Nullhypothese lautet, dass es keinen Zusammenhang zwischen der Gruppe 1 und der Gruppe 2 auf dem Feld gibt. Die Zahlen sind also rein zufällig in dieser Anordnung.

```{r}
#| warning: false
chisq.test(rel_mat)
```

Wir erhalten einen sehr kleinen $p$-Wert mit $0.003$. Wir können daher die Nullhypothese ablehnen, da der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$ mit 5%. Wir haben ein signifikantes Ergebnis. Wir können von einen Zusamenhang zwischen den beiden Gruppen ausgehen.

Mit Cramers V können wir auch noch die Effektstärke für einen $\mathcal{X}^2$-Test berechnen.

```{r}
cramers_v(rel_mat) 
```

Der Effekt ist mit $0.33$ nicht besonders stark. Du kannst Cramers V wie die Korrelation interpretieren. Ein V von 0 bedeutet keinen Zusammenhang und ein V von 1 einen maximalen Zusammenhang. Wir wollen uns die Daten dann nochmal in einer Abbidlung anschauen. Dafür müssen wir die Matrix erstmal in einen Datensatz umwandeln und die Gruppen zu Faktoren machen.

```{r}
plot_tbl <- rel_mat %>% 
  as_tibble(rownames = "group1") %>% 
  gather(A:D, key = "group2", value = "value") %>% 
  mutate(group1 = as_factor(group1),
         group2 = as_factor(group2))
```

In @fig-app-count-1 sehen wir die Matrix der Zähldaten für die beiden Gruppen nochmal visualisiert. Beim betrachten fällt auf, dass die beiden Level C und D kaum Zähldaten enthalten. Hier wäre zu überlegen die beiden Level aus der Analyse herauszunehmen und einen klassischen $\mathcal{X}^2$-Test auf einer 2x2 Kreuztabelle zu rechnen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Barplot der Zähldaten aus der Matrix. 
#| label: fig-app-count-1

ggplot(plot_tbl, aes(x = group2, y = value, fill = group1)) +
  theme_bw() +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(x = "Gruppe 2", y = "Anzahl", fill = "Gruppe 1") +
  scale_fill_okabeito() 
```

## Auswertung zweifaktorielle ANOVA mit Interaktion {#sec-app-example-anova-inter}

Hier kommt jetzt ein schönes Beispiel für eine Auswertung von einem dreifaktoriellen Design mit einer ANOVA. Passenderweise haben wir auch einen Interaktionsterm vorliegen. Unser dreifaktoriellen Design ist auch kein echtes dreifaktorielles Design. Wir müssen uns hier entscheiden, welcher der zwei Blockfaktoren nun unsere Wiederholung sein soll. Aber schreiben wir erstmal unser Modell auf, bevor wir das Modell mit Inhalt füllen.

$$
y \sim  f_1 + b_1 + b_2
$$

In unserem Beispiel schauen wir uns das Pflanzenwachstum `growth` in einer Klimakammer mit verschiedenen Belichtungsstufen `light_intensity` sowie der Position der Pflanze in der Lichtkammer. Die Pflanze hat eine Position im `rack` und dann im `layer`. So ergibt sich dann für uns folgendes ausgeschriebenes Modell.

$$
growth \sim light\_intensity + layer + rack
$$

In dieser Form wird unser Modell aber leider nicht funktionieren. Wir hätten dann keine Wiederholungen mehr. Jede Pflanze würe dann exakt durch eine Faktorkombination beschrieben. Wir sehen gleich das Problem visualisiert. Vorher müssen wir uns aber einmal die Daten einlesen und eine Menge Faktoren erschaffen. Achtung, das Erschaffen der Faktoren ist hier sehr wichtig! Im Orginaldatensatz stehen nur Zahlen für die Faktoren. Wir kriegen dann ein echtes Problem.

```{r}
light_tbl <- read_excel("data/light_intensity_data.xlsx") %>% 
  mutate(rack = factor(rack, labels = c("left", "middle", "right")),
         layer = factor(layer, labels = c("1st", "2nd", "3rd")),
         light_intensity = factor(light_intensity, labels = c("low", "mid", "high")),
         growth = as.numeric(growth))
```

In der @tbl-app-light sehen wir nochmal einen Ausschnitt aus den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-app-light
#| tbl-cap: Auszug aus dem Daten zu der Lichtintensität.
#| column: page

light_raw_tbl <- light_tbl %>% 
  mutate(rack = as.character(rack),
         layer = as.character(layer),
         light_intensity = as.character(light_intensity))

rbind(head(light_raw_tbl),
      rep("...", times = ncol(light_raw_tbl)),
      tail(light_raw_tbl)) %>% 
  kable(align = "c", "pipe")
```

Nachdem wir die Daten eingelesen haben, schauen wir uns den Sachverhalt einmal für die drei Faktoren über die Level der einzelnen Faktoren an. Wir nutzen dafür die Funktion `datasummary_crosstab()` aus dem R Paket `modelsummary`. Wir können uns hier die Anzahl der Beobachtungen je Faktorlevelkombination einmal anschauen.

```{r}
datasummary_crosstab(light_intensity ~ layer * rack, data = light_tbl,
                     statistic = NULL)
```

Wir sehen eine Menge Nullen. Das heißt, dass diese Faktorlevelkombinationen keine Beobachtungen haben. Dann können wir auch über diese Kombinationen keine Aussage treffen. Wenn wir *entweder* `rack` oder `layer` entfernen, sieht die Sache schon besser aus. Wir haben jetzt alle Faktorlevelkombinationen belegt. Wir müssen uns dann nur noch entscheiden, welchen Faktor wir ins Modell nehmen wollen.

```{r}
#| layout-ncol: 2

datasummary_crosstab(light_intensity ~ layer, data = light_tbl,
                     statistic = NULL)

datasummary_crosstab(light_intensity ~ rack, data = light_tbl,
                     statistic = NULL)
```

::: column-margin
Das R Paket [modelsummary](https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html) bietet hier eine sehr große Auswahl an tollen Funktionen an um seine Daten übersichtlich zu gestalten.
:::

Für die Entscheidung welcher der beiden Faktoren `rack` oder `layer` mit ins Modekll soll, schauen wir uns einmal die Boxplots für die jeweiligen Fakoten an. In @fig-app-anova-interaction-1 sehen wir einmal die Boxplots aufgeteilt nach `rack`.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Boxplots des Pflanzenwachstums aufgeteilt nach `rack`."
#| label: fig-app-anova-interaction-1

ggplot(light_tbl, aes(light_intensity, growth, fill = rack)) +
  theme_bw() +
  geom_boxplot() +
  scale_fill_okabeito()
```

Und wir sehen schon, da stimmt was nicht. Die Annahme der ANOVA ist, dass sich der Trend im ersten Faktorlevel für alle im Faktor über die anderen Faktoren gleicht. Das liest sich kryptisch, aber verdeutlichen wir es mal. Im Level `low` steigen alle Level des Faktors `rack` an. Wenn *keine* Interaktion vorliegen würde, dann müssten dieses Muster in dem Level `mid` und `high` ebenfalls annährend zu beobachten sein. Tut es aber nicht. Wir haben eine Interaktion zwischen `light_intensity` und `rack` visuell bestätigt.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Boxplots des Pflanzenwachstums aufgeteilt nach `layer`."
#| label: fig-app-anova-interaction-2

ggplot(light_tbl, aes(light_intensity, growth, fill = layer)) +
  theme_bw() +
  geom_boxplot()  +
  scale_fill_okabeito()
```

Dieses wirre Muster sehen wir dann auch in @fig-app-anova-interaction-2. Hier passen die Trends des Faktors `layer` über die Faktorlevel `low`, `mid` und `high` auch wieder nicht. Schauen wir uns jetzt nochmal die ganze Sache aufgeteilt nach `rack` und `layer` an. Vielelicht werden wir dann etwas schlauer oder das Problem wird noch klarer.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Boxplots des Pflanzenwachstums aufgeteilt nach `rack` und `layer`."
#| label: fig-app-anova-interaction-3

ggplot(light_tbl, aes(light_intensity, growth, fill = rack)) +
  theme_bw() +
  geom_boxplot() +
  facet_wrap(~ layer)  +
  scale_fill_okabeito()
```

Jetzt sehen wir etwas mehr. Im `1st` Level liegen alle `rack`-Level auf einer Ebene. Ebenso liegen alle `rack`-Level auf einer Ebene im `2n` Level. Das ganze Problem der Interaktion entsteht im `3rd` Level. Hier ging etwas drunter und drüber im Pflanzenwachstum. Wir wissen jetzt, dass das dritte Layer anscheinend defekt war oder irgendwas dort mit den Racks nicht gestimmt hat.

Wir könnten jetzt das dritte Layer aus der Analyse werfen. Das wäre aber nur eine Möglichkeit. Wenn wir das tuen würden, dann würde wir auch die Interaktion los werden. Das wollen wir hier aber nicht, wir ziehen jetzt die Analyse einmal mit der Interaktion durch. Dafür bauen wir uns jetzt das lineare Modell und schauen uns einmal die ANOVA an.

```{r}
#| warning: false
#| message: false

fit_1 <- lm(growth ~ light_intensity + layer + light_intensity:layer, 
            data = light_tbl)
fit_1 %>% model_parameters()
```

Erstmal sehen wir an den Modellparameters, dass hier wieder etwas nicht stimmt. Wir würden erwarten, dass der Effekt des Layers immer gleich ist. Hier ist der Effekt von dem `2nd` Layer zu dem `3rd` Layer fast dreimal so stark. Und eigentlich sollten die Layer den gleichen Effekt haben. Nämlich eigentlich keinen oder einen Effekt weit unter dem von der Lichtintensität. Das Layer ist eine technische Komponente.

```{r}
#| warning: false
#| message: false

fit_1 %>% anova() %>% model_parameters()
```

Wir sehen die visuelle Interaktion auch in der ANOVA Ausgabe als hoch signifikanten Term `light_intensity:layer` mit dem $p$-Wert $<0.001$. Im Anschluss rechnen wir jetzt die paarweisen Vergleiche mit der Funktion `emmeans()`. Mit dem `|` geben wir an, dass wir die paarweisen Vergleiche für die Level von `light_intensity` getrennt für die Level vom `layer` rechnen wollen. Wenn du *keine* Adjustierung des $\alpha$-Niveaus für die multiplen Vergleiche möchtest, dann wähle einfach die Option `adjust = "none"`. Wir nutzen dann die Ausgabe nicht direkt sondern werden noch die Ausgabe etwas aufhübschen.

```{r}
comp_1_obj <- fit_1 %>% 
  emmeans(specs = ~ light_intensity | layer) %>% 
  contrast(method = "pairwise", adjust = "bonferroni") 
```

In dem Objekt `comp_1_obj` sind eine Menge Informationen enthalten. Ich kürze mir immer die Informationen und sortiere nochmal die Ergebnisse. Wir erhalten dann eine saubere Wiedergabe.

```{r}
comp_1_obj %>% 
  summary %>% 
  as_tibble %>% 
  select(contrast, layer, p.value) %>% 
  mutate(p.value = format.pval(p.value, eps = 0.001, digits = 2))
```

Nach der Adjustierung für die multiplen Vergleiche haben wir nur noch einen Effekt in dem `3rd` Layer. Sonst haben die Lichtintensitäten keinen Einfluss auf die Wuchshöhe der Pflanzen. Da wir wissen, dass das `3rd` Layer auch das defekte Layer war, sehen wir hier schon, dass wir keinen wirklichen Effekt durch das Licht vorliegen haben. Alles was wir gefunden haben, ist eben ein defektes `3rd` Layer.

Die 95% Konfidenzintervalle erhalten wir mit der Funktion `confint()`. Die Ergebnisse sind natürlich die gleichen. Wir sehen wieder keinen Unterschied zwischen den Lichtintensitäten außer in dem `3rd` Layer.

```{r}
ci_obj <- comp_1_obj %>% 
  confint() %>% 
  as_tibble() %>% 
  select(contrast, layer, estimate, conf.low = lower.CL, conf.high = upper.CL) 

ci_obj
```

In der @fig-app-anova-interaction-4 sehen wir dann die berechneten 95% Konfidenzintervalle nochmal visualisiert. Wenn wir einen Effekt haben, dann im `3rd` Layer. In den restlichen 95% Konfidenzintervallen ist die Null mit enthalten, wir können also die Nullhypothese auf Gleichheit des Gruppenvergleiches nicht ablehnen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Die 95% Konfidenzintervalle für die paarweisen Vergleiche aufgeteilt `layer`."
#| label: fig-app-anova-interaction-4

ggplot(ci_obj, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high,
                   color = layer, group = layer)) +
  geom_hline(yintercept=0, linetype="11", colour="grey60") +
  geom_errorbar(width=0.1, position = position_dodge(0.5)) + 
  geom_point(position = position_dodge(0.5)) +
  scale_color_okabeito() +
  coord_flip() +
  theme_classic()
```

Neben der Darstellung mit 95% Konfidenzintervallen ist auch die Darstellung mit dem *compact letter display* sehr beliebt. Wir nutzen dafür dann die Funktion `cld()`. Wir adjustieren uns wieder die Vergleiche nach Bonferroni. Im Weiteren trenne wir die Vergleiche auch wieder nach den Leveln für den Faktor `layer` auf.

```{r}
cld_obj <- fit_1 %>% 
  emmeans(specs = ~ light_intensity | layer)  %>%
  cld(Letters = letters, adjust = "bonferroni") 

cld_obj
```

Wir sehen wieder, dass wir nur in dem `3rd` Layer Buchstabenunterschiede haben. Daher haben wir auch nur im `3rd` Layer signifikante Ergebnisse. Wichtig ist, dass wir die Buchstaben nur pro Level des Layers vergleichen können, aber auf keinen Fall über die Layer hinweg. Das geht dann leider nicht. Die Ausgabe der Funktion `emmeans()` schlägt noch andere Darstellungsformen für die Vergleiche vor, du kannst gerne einmal die Funktionen `pairs()`, `pwpp()` oder `pwpm()` ausprobieren und schauen, ob dir die Visualisierung mehr sagt. Im @sec-posthoc-emmeans gehe ich nochmal auf die verschiedene Darstellungsformen in `emmeans` ein.

Wenn wir das *compact letter display* mit deinem Barplot verbinden wollen, müssen wir uns etwas strecken. Zuerst sortieren wir die Ausgabe von `cld_obj` wieder in die korrekte Reihenfolge der Faktorenlevel. Dann können wir die Spalte `.group` direkt in `ggplot()` verwenden.

```{r}
cld_sort_obj <- cld_obj %>% 
  as_tibble() %>% 
  select(light_intensity, layer, .group) %>% 
  arrange(layer, light_intensity)
```

In @fig-app-anova-interaction-5 sehen wir die Ausgabe des Barplots für die Daten und dann an die Balken geschrieben das *compact letter display*. Wichtig ist hier, dass die Buchstaben immer nur für *ein* Layer gelten. Wir können wegen der Interaktion nicht die Layer untereinander mit den Buchstaben vergleichen. Wir sehen wiederum, dass wir keine relevanten signifikanten Ergebnisse aus dem Experiment mitnehmen können.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Barplots für die Mittelwerte mit den entsprechenden Standardabweichungen und dem *compact letter display* für die paarweisen Vergleiche. Achtung die *letter* gelten nur in einem Level des Layers."
#| label: fig-app-anova-interaction-5


stat_tbl <- light_tbl %>% 
  group_by(light_intensity, layer) %>% 
  summarise(mean = mean(growth),
            sd = sd(growth))

ggplot(stat_tbl, aes(x = layer, y = mean, group = light_intensity, 
                     fill = light_intensity)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),
                width = 0.2, position = position_dodge(0.9)) +
  annotate("text", 
           x = c(0.7, 1, 1.3, 1.7, 2, 2.3, 2.7, 3, 3.3), 
           y = c(22, 21, 23, 24, 20, 23, 39, 25, 9), 
           label = pluck(cld_sort_obj, ".group")) +
  theme_bw() +
  labs(fill = "Behandlung")  +
  scale_fill_okabeito()

```

## Multiples Testen mit Games Howell Test {#sec-mult-map-ght}

multcompView, rstatix

```{r}
soil_tbl <- read_excel("data/soil_1fac_data.xlsx") %>% 
  mutate(variante = str_c(variante, "_", amount),
         variante = as_factor(variante),
         across(where(is.numeric), round, 2)) %>% 
  select(-amount)
```

In der @tbl-app-soil sehen wir nochmal einen Ausschnitt aus den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-app-soil
#| tbl-cap: Auszug aus dem Daten zu der Lichtintensität.
#| column: page

soil_raw_tbl <- soil_tbl %>% 
  mutate(variante = as.character(variante))

rbind(head(soil_raw_tbl),
      rep("...", times = ncol(soil_raw_tbl)),
      tail(soil_raw_tbl)) %>% 
  kable(align = "c", "pipe")
```

```{r}
soil_lst <- soil_tbl %>%
  gather(key, value, fe:height) %>%
  split(.$key) %>%
  map(~select(.x, -key))

soil_lst %>% 
  map(~games_howell_test(value ~ variante, data = .x)) %>% 
  map(~mutate(.x, contrast = str_c(.x$group1, "-", .x$group2))) %>% 
  map(~pull(.x, p.adj, contrast)) %>% 
  map(~multcompLetters(.x)$Letters) %>% 
  bind_rows(.id = "outcome") 
```

## Auswertung von Gewichten

```{r}
#| echo: false
data_tbl <- expand_grid(trt = 1:3, 
                        block = 1:3,
                        rep = 1:4) %>% 
  mutate(rsp = 10 + 2 * trt + block + rnorm(n(), 0, 2),
         trt = factor(trt, labels = c("low", "mid", "high")),
         block = factor(block, labels = c("I", "II", "III")))
```

```{r}
#| echo: false
data_tbl %>% 
  mutate(rsp = round(rsp, 2)) %>% 
  kable(align = "c", "pipe")
```

### Explorative Datenanalyse (EDA)

```{r}
ggplot(data_tbl, aes(trt, rsp, color = block)) +
  geom_boxplot()
```

```{r}
#| message: false

stat_tbl <- data_tbl %>% 
  group_by(trt, block) %>% 
  summarise(mean = mean(rsp),
            sd = sd(rsp),
            se = sd/sqrt(n()))

ggplot(stat_tbl, aes(x = trt, y = mean, fill = block)) + 
    geom_bar(position = position_dodge(), stat = "identity") +
    geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),
                  width = 0.2,
                  position = position_dodge(.9))
```

### Lineares Modell

```{r}
fit_1 <- lm(rsp ~ trt + block, data = data_tbl)

```

### ANOVA

```{r}
fit_1 %>% anova
```

### Gruppenvergleich mit dem `multcomp` Paket

https://broom.tidymodels.org/reference/tidy.glht.html

```{r}

fit_1 %>% 
  glht(linfct = mcp(trt = "Tukey")) %>% 
  tidy %>% 
  select(contrast, estimate, adj.p.value) %>% 
  mutate(across(where(is.numeric), round, 4))



```

### Gruppenvergleich mit der `emmeans` Paket

https://broom.tidymodels.org/reference/tidy.emmGrid.html

```{r}
fit_1 %>% 
  emmeans("trt") %>% 
  contrast(method = "pairwise") %>% 
  tidy %>% 
  select(contrast, estimate, adj.p.value) %>% 
  mutate(across(where(is.numeric), round, 4))

```

## Auswertung von Boniturnoten

```{r}
#| echo: false 

data_tbl <- tibble(block = 1:5,
                   A = c(2,3,4,3,2),
                   B = c(7,9,8,9,7),
                   C = c(6,5,4,7,4),
                   D = c(2,4,1,2,3),
                   E = c(4,5,3,7,6)) %>%
  gather(key = "variety", value = "rating", A:E) %>% 
  mutate(variety = as_factor(variety),
         block = factor(block, labels = c("I", "II", "III", "IV", "V"))) %>% 
 select(variety, block, rating)


data_tbl <- tibble(block = rep(1:3, each = 5),
                   A = c(2,3,3,4,1,3,2,2,4,4,2,2,3,1,2),
                   B = c(8,9,8,9,7,7,7,8,8,7,8,9,7,9,8),
                   C = c(6,5,5,6,4,4,5,3,6,4,7,6,4,6,4),
                   D = c(2,4,1,2,2,2,4,4,1,3,3,4,2,1,3),
                   E = c(4,4,2,7,5,4,3,4,7,7,5,5,4,6,6)) %>%
  gather(key = "variety", value = "rating", A:E) %>% 
  mutate(variety = as_factor(variety),
         block = factor(block, labels = c("I", "II", "III"))) %>% 
  select(variety, block, rating) %>% 
  arrange(variety, block)  

#data_tbl <- tibble(A = sample(1:9, 18, replace = TRUE, 
#                              prob = c(0, 0, 0, 0, 0.1, 0.2, 0.4, 0.2, 0.1)),
 #                  B = sample(1:9, 18, replace = TRUE, 
  #                            prob = c(0, 0, 0.1, 0.2, 0.4, 0.2, 0.1, 0, 0)),
   #                C = sample(1:9, 18, replace = TRUE, 
    #                          prob = c(0, 0, 0, 0.1, 0.2, 0.4, 0.2, 0.1, 0)),
     #              D = sample(1:9, 18, replace = TRUE, 
      #                        prob = c(0, 0, 0, 0, 0, 0.1, 0.2, 0.4, 0.3))) %>% 
  #gather(key = "trt", value = "rating") %>% 
  #mutate(trt = as_factor(trt), 
   #      block = rep(gl(3, 6), 4),
    #     block = factor(block, labels = c("I", "II", "III"))) %>% 
#  select(trt, block, rating)

```

```{r}
#| echo: false
data_tbl %>% 
  kable(align = "c", "pipe")
```

### Explorative Datenanalyse (EDA)

```{r}
#| message: false

ggplot(data_tbl, aes(variety, rating, color = block)) +
  geom_boxplot() +
  geom_dotplot(aes(fill = block), binaxis = "y", stackdir='center', 
               position=position_dodge(0.8))  

```

```{r}
#| message: false

ggplot(data_tbl, aes(variety, rating, fill = block)) +
  geom_dotplot(binaxis = "y", stackdir='center', 
               position=position_dodge(0.8)) +
  stat_summary(fun = median, fun.min = median, fun.max = median,
               geom = "crossbar", width = 0.5, 
               position=position_dodge(0.8)) 

```

### Friedman Test

```{r}

#friedman.test(rating ~ variety | block, data = data_tbl)

data_tbl <- tibble(Block = 1:4,
                   Sorte_1 = c(2,3,4,3),
                   Sorte_2 = c(7,9,8,9),
                   Sorte_3 = c(6,5,4,7),
                   Sorte_4 = c(2,4,1,2),
                   Sorte_5 = c(4,5,3,7)) %>%
  gather(key, value, Sorte_1:Sorte_5)

friedman.test(value ~ key | Block, data = data_tbl)


```

## Auswertung von Infektionsstatus
