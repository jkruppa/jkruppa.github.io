```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Die ANCOVA {#sec-ancova}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"It's better to solve the right problem approximately than to solve the wrong problem exactly." --- John Tukey*

[Eine Kovariate ist eine Variable, die mit berücksichtigt wird, um mögliche verzerrende Einflüsse auf die Analyseergebnisse (Konfundierung) abzuschätzen oder zu verringern.]{.aside}

Eigentlich hat sich die Analysis of Covariance (ANCOVA) etwas überlebt. Wir können mit dem statistischen Modellieren *eigentlich* alles was die ANCOVA kann plus wir erhalten auch noch Effektschätzer für die Kovariaten und die Faktoren. Dennoch hat die ANCOVA ihren Platz in der Auswertung von Daten. Wenn du ein oder zwei Faktoren hast plus eine numerische Variable, wie das Startgewicht, für die du die Analyse adjustieren möchtest, dann ist die ANCOVA für dich gemacht.

Also kurz gesprochen adjustiert die Analysis of Covariance (ANCOVA) die Faktoren einer ANOVA um eine kontinuierliche Covariate. Adjustiert bedeutet in dem Fall, dass die Effekte des unterschiedlichen Startgewichts von Pflanzen durch das Einbringen der Kovariate mit in der statistischen Analyse berücksichtigt werden. Wir werden hier auch nur über die Nutzung in R sprechen und auf die theoretische Herleitung verzichten.

Wir können die *einfaktorielle* ANCOVA in folgender Form schreiben. Wir haben haben einen Faktor $x_1$ und eine Kovariate oder aber ein numerisches $x_2$. Damit sähe die ANCOVA wie folgt aus.

$$
y \sim x_1 + x_2
$$

Damit ist die ANCOVA aber sehr abstrakt beschrieben. Der *eine* Faktor kommt damit gar nicht zur Geltung. Deshalb schreiben wir die ANCOVA wie folgt mit einem $f_1$ für den Faktor und einem $c_1$ für eine numerische Kovariate. Damit haben wir einen bessere Übersicht.

$$
y \sim f_1 + c_1
$$

Somit erklärt sich die zweifaktorielle ANCOVA schon fast von alleine. Wir erweitern einfach das Modell um einen zweiten Faktor $f_2$ und haben somit eine zweifaktorielle ANCOVA.

$$
y \sim f_1 + f_2 + c_1
$$

Im Folgenden schauen wir uns einmal die Daten und die Hypothesen zu einer möglichen Fragestellung an.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom, quantreg,
               see, performance, emmeans, multcomp, janitor,
               parameters)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Für unser Beispiel nutzen wir die Daten der Sprungweite in \[cm\] von Flöhen auf Hunde-, Katzen- und Füchsen. Damit haben wir den ersten Faktor `animal` mit drei Leveln. Als Kovariate schauen wir uns das Gewicht als numerische Variable an. Schlussendlich brauchen wir noch das Outcome `jump_length` als $y$. Für die zweifaktorielle ANCOVA nehmen wir noch den Faktor `sex` mit zwei Leveln hinzu.

```{r}
#| message: false

ancova_tbl <- read_csv2("data/flea_dog_cat_length_weight.csv") %>%
  select(animal, sex, jump_length, weight) %>% 
  mutate(animal = as_factor(animal))
```

In der @tbl-model-1 ist der Datensatz `ancova_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Datensatz zu der Sprunglänge in [cm] von Flöhen auf Hunde-, Katzen- und Füchsen.
#| label: tbl-model-1

ancova_raw_tbl <- ancova_tbl %>% 
  mutate(animal = as.character(animal))
rbind(head(ancova_raw_tbl),
      rep("...", times = ncol(ancova_raw_tbl)),
      tail(ancova_raw_tbl)) %>% 
  kable(align = "c", "pipe")

```

Unser zweiter Datensatz ist ein Anwendungsdatensatz aus dem Gemüsebau. Wir schauen uns das Wachstum von drei Gurkensorten über siebzehn Wochen an. Die Gurkensorten sind hier unsere Versuchsgruppen. Da wir es hier mit echten Daten zu tun haben, müssen wir uns etwas strecken damit die Daten dann auch passen. Wir wollen das Wachstum der drei Gurkensorten *über* die Zeit betrachten - also faktisch den Verlauf des Wachstums.

```{r}
#| message: false
#| warning: false

gurke_raw_tbl <- read_excel("data/wachstum_gurke.xlsx") %>% 
  clean_names() %>% 
  select(-pfl, -erntegewicht) %>% 
  mutate(versuchsgruppe = as_factor(versuchsgruppe)) 
```

In der @tbl-model-2 sehen wir einmal die rohen Daten dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz zu dem Längen- und Dickenwachstum von Gurken."
#| label: tbl-model-2

ancova_raw_2_tbl <- gurke_raw_tbl %>% 
  mutate(versuchsgruppe = as.character(versuchsgruppe))
rbind(head(ancova_raw_2_tbl),
      rep("...", times = ncol(ancova_raw_2_tbl)),
      tail(ancova_raw_2_tbl)) %>% 
  kable(align = "c", "pipe")

```

Wir haben zwei Typen von Daten für das Gurkenwachstum. Einmal messen wir den Durchmesser für jede Sorte (`D` im Namen der Versuchsgruppe) oder aber die Länge (`L` im Namen der Versuchsgruppe). Wir betrachten hier nur das Längenwachstum und deshalb filtern wir erstmal nach allen Versuchsgruppen mit einem `L` im Namen. Dann müssen wir die Daten noch in Long-Format bringen. Da wir dann auch noch auf zwei Arten die Daten über die Zeit darstellen wollen, brauchen wir einmal die Zeit als Faktor `time_fct` und einmal als numerisch `time_num`. Leider haben wir auch Gurken mit einer Länge von 0 cm. Diese Gurken schmeißen wir am Ende mal raus. Auch haben wir ab Woche 14 keine Messungen mehr in der Versuchsgruppe `Prolong`, also nehmen wir auch nur die Daten bis zur vierzehnten Woche.

```{r}
gurke_time_len_tbl <- gurke_raw_tbl %>% 
  filter(str_detect(versuchsgruppe, "L$")) %>% 
  mutate(versuchsgruppe = factor(versuchsgruppe, 
                                 labels = c("Proloog", "Quarto", "Katrina"))) %>% 
  pivot_longer(cols = t1:t17,
               values_to = "length",
               names_to = "time") %>% 
  mutate(time_fct = as_factor(time),
         time_num = as.numeric(time_fct)) %>% 
  filter(length != 0) %>% 
  filter(time_num <= 14)
```

## Hypothesen für die ANCOVA

Wir haben für jeden Faktor der ANCOVA ein Hypothesenpaar sowie ein Hypothesenpaar für die Kovariate. Im Folgenden sehen wir die jeweiligen Hypothesenpaare.

Einmal für `animal`, als Haupteffekt. Wir nennen einen Faktor den Hauptfaktor, weil wir an diesem Faktor am meisten interessiert sind. Wenn wir später einen Posthoc Test durchführen würden, dann würden wir diesen Faktor nehmen. Wir sind primär an dem Unterschied der Sprungweiten in \[cm\] in Gruppen Hund, Katze und Fuchs interessiert.

$$
\begin{aligned}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{aligned}
$$

[Du kannst mehr über Geraden sowei lineare Modelle und deren Eigenschaften im @sec-modeling-simple-stat erfahren.]{.aside}

Für die Kovariate testen wir anders. Die Kovariate ist ja eine numerische Variable. Daher ist die Frage, wann gibt es keinen Effekt von `weight` auf die Sprunglänge? Wenn wir eine parallele Linie hätten. Das heißt, wenn sich der Wert von `weight` ändert, ändert sich der Wert von `jump_length` nicht. Wir schreiben, dass sich die Steigung der Geraden nicht ändert. Wir bezeichnen die Steigung einer Graden mit $\beta$. Wenn kein Effekt vorliegt und die Nullhpyothese gilt, dann ist die Steigung der Geraden $\beta_{weight} = 0$.

$$
\begin{aligned}
H_0: &\; \beta_{weight} = 0\\
H_A: &\; \beta_{weight} \neq 0
\end{aligned}
$$

Du kannst dir überlegen, ob due die Interaktion zwischen dem Faktor und der Kovariate mit ins Modell nehmen willst. Eigentlich schauen wir uns immer nur die Interaktion zwischen den Faktoren an. Generell schreiben wir eine Interaktionshypothese immer in Prosa.

$$
\begin{aligned}
H_0: &\; \mbox{keine Interaktion}\\
H_A: &\; \mbox{eine Interaktion zwischen animal und site}
\end{aligned}
$$

Wir haben also jetzt die verschiedenen Hypothesenpaare definiert und schauen uns jetzt die ANCOVA in R einmal in der Anwendung an.

## Die einfaktorielle ANCOVA in R

[Du kannst mehr über Geraden sowie lineare Modelle und deren Eigenschaften im @sec-modeling-simple-stat erfahren.]{.aside}

Wir können die ANCOVA ganz klassisch mit dem linaren Modell fitten. Wir nutzen die Funktion `lm()` um die Koeffizienten des linearen Modellls zu erhalten. Wir erinnern uns, wir haben haben einen Faktor $f_1$ und eine Kovariate bezwiehungsweise ein numerisches $c_1$. In unserem Beispiel sieht dann der Fit des Modells wie folgt aus.

```{r}
fit_1 <- lm(jump_length ~ animal + weight + animal:weight, data = ancova_tbl)
```

Nachdem wir das Modell in dem Objekt `fit_1` gespeichert haben können wir dann das Modell in die Funktion `anova()` pipen. Die Funktion erkennt, das wir eine ANCOVA rechnen wollen, da wir in unserem Modell einen Faktor und eine Kovariate mit enthalten haben.

```{r}
fit_1 %>% anova 
```

In der ANCOVA erkennne wir nun, dass der Faktor `animal` signifikant ist. Der $p$-Wert ist mit $<0.001$ kleiner das das Signifikanzniveau $\alpha$ von 5%. Ebenso ist die Kovariate `weight` signifikant. Der $p$-Wert ist ebenfalls mit $<0.001$ kleiner das das Signifikanzniveau $\alpha$ von 5%. Wir können also schlussfolgern, dass sich mindestens eine Gruppenvergleich der Level des Faktors `animal` voneinander unterscheidet. Wir wissen auch, dass mit der Zunahme des Gewichts, die Sprunglänge sich ändert.

[Die ANCOVA liefert keine Informationen zu der Größe oder der Richtung des Effekts der Kovariate.]{.aside}

Was wir nicht wissen, ist die Richtung. Wir wissen nicht, ob mit ansteigenden Gewicht sich die Sprunglänge erhöht oder vermindert. Ebenso wenig wissen wir etwas über den Betrag des Effekts. Wieviel weiter springen denn nun Flöhe mit 1 mg Gewicht mehr? Wir haben aber die Möglichkeit, den Sachverhalt uns einmal in einer Abbildung zu visualisieren. In @fig-stat-ancova-01 sehen wir die Daten einmal als Scatterplot dargestellt.

```{r}
#| message: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Scatterplot der Daten zur einfaktoriellen ANCOVA.
#| label: fig-stat-ancova-01

ggplot(ancova_tbl, aes(weight, jump_length, color = animal)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_bw() +
  geom_point() +
  labs(color  = "Tierart", shape = "Geschlecht")  
  
```

Der @fig-stat-ancova-01 können wir jetzt die positive Steigung entnehmen sowie die Reihenfolge der Tierarten nach Sprungweiten. Die ANCOVA sollte immer visualisiert werden, da sich hier die Stärke der Methode mit der Visualiserung verbindet.

## Die zweifaktorielle ANCOVA in R

Die zweifaktorielle ANCOVA erweitert die einfaktorielle ANCOVA um einen weiteren Faktor. Das ist manchmal etwas verwirrend, da wir auf einmal drei oder mehr Terme in einem Modell haben. Klassischerweise haben wir nun zwei Faktoren $f_1$ und $f_2$ in dem Modell. Weiterhin haben wir nur eine Kovariate $c_1$. Damit sehe das Modell wie folgt aus.

$$
y \sim f_1 + f_2 + c_1
$$

Wir können das Modell dann in R übertragen und ergänzen noch den Interaktionsterm für die Faktoren `animal` und `sex` in dem Modell. Das Modell wird klassisch in der Funktion `lm()` gefittet.

```{r}
fit_2 <- lm(jump_length ~ animal + sex + weight + animal:sex, data = ancova_tbl)
```

Nach dem Fit können wir das Modell in dem Obkjekt `fit_2` in die Funktion `anova()` pipen. Die Funktion erkennt die Struktur des Modells und gibt uns eine ANCOVA Ausgabe wieder.

```{r}
fit_2 %>% anova 
```

In der ANCOVA erkennne wir nun, dass der Faktor `animal` signifikant ist. Der $p$-Wert ist mit $<0.001$ kleiner das das Signifikanzniveau $\alpha$ von 5%. Ebenso ist der Faktor `sex` signifikant. Der $p$-Wert ist mit $<0.001$ kleiner das das Signifikanzniveau $\alpha$ von 5%. Die Kovariate `weight` ist nicht mehr signifikant. Der $p$-Wert ist mit $0.94$ größer das das Signifikanzniveau $\alpha$ von 5%. Wir können also schlussfolgern, dass sich mindestens eine Gruppenvergleich der Level des Faktors `animal` voneinander unterscheidet. Ebenso wie können wir schlussfolgern, dass sich mindestens eine Gruppenvergleich der Level des Faktors `site` voneinander unterscheidet. Da wir nur zwei Level in dem Faktor `sex` haben, wissenwir nun, dass sich die beiden Geschlechter der Flöhe in der Sprungweite unterscheiden. Wir wissen auch, dass mit der Zunahme des Gewichts, sich die Sprunglänge nicht ändert.

In @fig-stat-ancova-02 sehen wir nochmal den Zusammenhang dargestellt. Wenn wir die Daten getrennt für den Faktor `sex` anschauen, dann sehen wir, dass das Gewicht keinen Einfluss mehr auf die Sprungweite hat.

```{r}
#| message: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Scatterplot der Daten zur einfaktoriellen ANCOVA aufgetelt nach dem Geschlecht der Flöhe.
#| label: fig-stat-ancova-02

ggplot(ancova_tbl, aes(weight, jump_length, color = animal)) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_okabeito() +
  theme_bw() +
  geom_point() +
  labs(color  = "Tierart", shape = "Geschlecht") +
  facet_wrap(~ sex, scales = "free_x")
  
```

Nach einer berechneten ANCOVA können wir zwei Fälle vorliegen haben.

[Wenn du in deinem Experiment keine *signifikanten* Ergebnisse findest, ist das nicht schlimm. Du kannst deine Daten immer noch mit der explorativen Datenanalyse auswerten wie in @sec-eda-ggplot beschrieben.]{.aside}

1)  Wir habe eine nicht signifkante ANCOVA berechnet. Wir können die Nullhypothese $H_0$ nicht ablehnen und die Mittelwerte über den Faktor sind vermutlich alle gleich. Wir enden hier mit unserer statistischen Analyse.
2)  Wir haben eine signifikante ANCOVA berechnet. Wir können die Nullhypothese $H_0$ ablehnen und mindestens ein Gruppenvergleich über mindestens einen Faktor ist vermutlich unterschiedlich. Wir können dann in @sec-posthoc eine Posthoc Analyse rechnen.

## Linearer Trendtest

> *"Make use of time, let not advantage slip." --- William Shakespeare*

Im Folgenden schauen wir uns dann die Auswertung der Gurkendaten einmal genauer an. Für mehr Informationen zu dem Paket `emmeans` und den entsprechenden Funktionen dann bitte einmal in das Kapitel @sec-posthoc schauen. In der @fig-ancova-gurke-03 sehen wir die Daten einmal als Scatterplot. Die durchgezogene Gerade stellt den Verlauf der Mittelwerte über die Versuchsgruppen dar. Die gestrichelte Linie zeigt den Median über die Gruppen. Wir wollen jetzt der Frage nachgehen, ob es einen Unterschied zwischen den Gurkensorten `versuchsgruppen` über den zeitlichen Verlauf der vierzehn Wochen gibt.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-ancova-gurke-03
#| fig-align: center
#| fig-height: 5
#| fig-width: 8
#| fig-cap: "Scatterplot des Längenwachstums der drei Gurkensorten über vierzehn Wochen. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar."

ggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +
  theme_bw() +
  geom_point() +
  stat_summary(fun = "mean", geom = "line") +
  stat_summary(fun = "median", geom = "line", linetype = 2) +
  scale_color_okabeito()
```

Unser erstes Modell was wir uns anschauen wollen ist nochmal eine klassische zweifaktorielle ANOVA mit einem Interaktionsterm. Wir wollen raus finden ob die Länge von den Gurken von den Sorten ($f_1$), dem zeitlichen Verlauf ($f_2$) und der Interaktion zwischen der Sorten und der Zeit abhängt ($f_1:f_2$). Wir stellen nun folgendes lineares Modell für die zweifaktorielle ANOVA auf.

$$
length \sim \overbrace{versuchsgruppe}^{f_1} + \underbrace{time\_fct}_{f_2} + \overbrace{versuchsgruppe:time\_fct}^{f_1:f_2}
$$

Dieses Modell können wir dann auch in R einmal über die Funktion `lm()` abbilden.

```{r}
#| message: false
#| warning: false

time_fct_fit <- lm(length ~ versuchsgruppe + time_fct + versuchsgruppe:time_fct, 
                   gurke_time_len_tbl)
```

Nun wollen wir auch überprüfen, ob es eine Interaktion zwischen den Versuchsgruppen und dem zeitlichen Verlauf gibt. Das ganze schauen wir uns neben einer ANOVA auch einmal graphisch mit der Funktion `emmip()` an. Wenn wir keine signifikante Interaktion erwaten würden, dann müssten die drei Versuchgruppe über den zeitlichen Verlauf gleichmäßig ansteigen. Wir sehen in der @fig-stat-ancova-08, dass dies nicht der Fall ist. Wir nehmen daher eine Interaktion zwischen den Versuchsgruppen und dem zeitlichen Verlauf an.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Interaktionsplot über den zeitlichen Verlauf für alle drei Sorten.
#| label: fig-stat-ancova-08

emmip(time_fct_fit, versuchsgruppe ~ time_fct, CIs = TRUE) +
  theme_bw() +
  scale_color_okabeito()

```

Nochmal kurz mit der ANOVA überprüft und wir sehen eine signifikante Interaktion.

```{r}
#| message: false
#| warning: false
time_fct_fit %>% anova %>% model_parameters()
```

Wir haben eben einmal die Zeit als Faktor mit ins Modell genommen, da wir so für jeden Zeitpunkt einen Mittelwert schätzen können. Wenn wir eine einfaktorielle ANCOVA rechnen, dann geht die Zeit als numerische Kovariate ($c_1$) linear in das Modell ein. Wir haben also von jedem Zeitpunkt zum nächsten den gleichen Anstieg. Wir modellieren ja auch einen linearen Zusammenhang. Hier einmal das Modell für die ANCOVA.

$$
length \sim \overbrace{versuchsgruppe}^{f_1} + \underbrace{time\_num}_{c_1} + \overbrace{versuchsgruppe:time\_num}^{f_1:c_1}
$$

Wir fitten wieder das Modell in R mit der Funktion `lm()`.

```{r}
time_num_fit <- lm(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, gurke_time_len_tbl)
```

Auch hier einmal die Überprüfung auf eine Interaktion mit der ANCOVA. Wir sehen, dass wir eine signifikante Interaktion zwischen den Versuchsgruppen und dem zeitlichen verlauf vorliegen haben.

```{r}
time_num_fit %>% anova() %>% model_parameters()
```

In der @fig-stat-ancova-05 sehen wir dann nochmal das Modell im Interaktionsplot. In beiden Abbildungen sehe wir den linearen Zusammenhang. Die Interaktion drückt sich in der unterschiedlichen Steigung der Versuchsgruppen über den zeitlichen Verlauf aus. Wir können durch die Option `at =` entscheiden für welche Zeitpunkte wir uns die 95% Konfidenzintervalle anzeigen lassen wollen, wie in der linken Abbildung exemplarisch für die Zeitpunkte 1 Woche, 7 Wochen und 14 Wochen. Oder aber wir lassen uns alle durch die Option `cov.reduce = FALSE` anzeigen, wie in der rechten Abbildung gezeigt.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 4
#| label: fig-stat-ancova-05
#| fig-cap: "Interaktionsplot über den zeitlichen Verlauf für alle drei Sorten."
#| fig-subcap: 
#|   - "An drei Zeitpunkten."
#|   - "Über alle Zeitpunkte."
#| layout-nrow: 1

emmip(time_num_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      at = list(time_num = c(1, 7, 14))) +
  theme_bw() +
  scale_x_continuous(breaks = 1:14) +
  scale_color_okabeito()

emmip(time_num_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_x_continuous(breaks = 1:14) +
  scale_color_okabeito()
```

Jetzt kommt eigentlich der spannende Teil, wir wollen jetzt über den zeitlichen Verlauf einen statistischen Test rechnen, ob wir einen Trend in den verschiedenen Versuchsgruppen haben. Wir rechnen also einen Trendtest über die Kovariate $c_1$ für die drei Gruppen getrennt. Das können wir mit der Funktion `emtrends()` durchführen. Hier musst du angeben welche deine Kovariate `var` ist. In unserem Fall ist die Kovariate natürlich `time_num`.

```{r}
emtrends(time_num_fit, ~ versuchsgruppe, var = "time_num", infer = TRUE)
```

Die Spalte `time_num.trend` zeigt uns jetzt den linearen Anstieg über die Zeit für die jeweilige Versuchsgruppe. Das heißt jede Woche wächst die Sorte Proloog um $1.857cm$ an Länge. In der gleichen Art können wir auch die anderen Werte in der Spalte interpretieren. Jetzt stellt sich natürlich die Frage, ob dieses Längenwachstum *untereinander* unterschiedlich ist. Dafür könne wir dann leicht den Code abändern und setzen das Wort `pairwise` vor die Tilde. Dann testet die Funktion auch alle paarweisen Vergleiche. Wir nutzen jetzt noch die Funktion `model_parameters()` um eine schönere Ausgabe zu erhalten.

```{r}
emtrends(time_num_fit, pairwise ~ versuchsgruppe, var = "time_num", infer = TRUE) %>% 
  model_parameters()
```

Wir sehen wieder erst die Trends, die kennen wir schon. Dann sehen wir die Kontraste oder auch paarweisen Vergleiche. Das kannst du schnelle nachrechnen, der Unterschied von Proloog zu Quarto ist $1.48 - 0.45 = 1.03$. Damit können wir dann auch über den *gesamten* zeitlichen Verlauf testen, ob ein Unterschied zwischen den Sorten vorliegt.

Wir sind jetzt schon sehr weit gekommen, aber wir könnten auch einen nicht-linearen Zusammenhang zwsichen der Zeit und dem Längenwachstum von Gurken annehmen. Das würde auch biologisch etwas mehr Sinn ergeben. Deshalb modellieren wir den Einfluss der Zeit `time_num` durch einen Exponenten hoch drei. Daher schreiben wir mathematisch $(time\_num)^3$.

$$
length \sim \overbrace{versuchsgruppe}^{f_1} + \underbrace{(time\_num)^3}_{c_1} + \overbrace{versuchsgruppe:(time\_num)^3}^{f_1:c_1}
$$

Den Exponenten schreiben wir dann entsprechend in R mit `poly(time_num, 3)` in die Formel. Die Funktion `poly()` nutzen wir innerhalb von Formelaufrufen um einen Exponenten einzufügen.

```{r}
time_num_poly_fit <- lm(length ~ versuchsgruppe * poly(time_num, 3), gurke_time_len_tbl)
```

In der @fig-stat-ancova-06 sehen wir dann nochmal die Anpassung des Modells und wir sehen, dass unser Modell besser zu den Daten passt. Das sieht schon sehr viel sauberer aus, als der brutale lineare Zusammenhang, den wir vorher hatten. Du musst hier etwas mit den Exponenten spielen und ausprobieren, welcher da am besten passt.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Interaktionsplot über den zeitlichen Verlauf für alle drei Sorten mit einer kubischen Anpassung der Regression.
#| label: fig-stat-ancova-06
emmip(time_num_poly_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()
```

Jetzt wollen wir die Analyse nochmal auf die Spitze treiben. Wir schauen uns jetzt an den Zeitpunkten 1 Woche, 7 Wochen und 14 Wochen den Unterschied zwischen den Sorten einmal an. Das machen wir indem wir zu der Funktion `emmeans()` die Optione `at = list(time_num = c(1, 7, 14))` ergänzen. Am Ende lassen wir uns noch das *compact letter display* wiedergeben.

```{r}
emmeans(time_num_poly_fit, pairwise ~ versuchsgruppe | time_num, 
        at = list(time_num = c(1, 7, 14))) %>% 
  cld(Letters = letters) 
```

Was erkennen wir? Wir sehen, dass sich in der ersten Woche die Sorten noch nicht voneinander unterscheiden. Erst in der Woche sieben sehen wir einen Unterschied von Proloog zu dem Rest der Sorten. In der letzten Woche unterscheiden sich dann alle Sorten voneinander. Wie stark, kannst du aus der Spalte `emmean` entnehmen, dort steht der Mittelwert für die jeweilige Sorte zu dem jeweiligen Zeitpunkt.

Abschließend wollen wir nochmal schauen, wie sich der Trend in den verschiedenen Modellierungen der Exponenten zeigen würde. Wir müssen dafür bei der Funktion `emtrends()` angeben bis zu welchen maximalen Exponenten, bei uns hoch Drei, die Funktion rechnen soll. Deshalb setzen wir `max.degree = 3`. Dann noch `pairwise` vor die Tilde gesetzt, damit wir dann auch die paarweisen Vergleiche für die Sorten und Verläufe angezeigt kriegen. Achtung, jetzt kommt eine lange Ausgabe.

```{r}
emtrends(time_num_poly_fit, pairwise ~ versuchsgruppe, var = "time_num", infer = TRUE,
         max.degree = 3) 
```

Was sehen wir in diesem Fall? In der linearen Modellierung der Zeit haben wir sehr viele signifikante Ergebnisse. Leider entspricht der lineare verlauf über die Zeit nicht so den beobachteten Daten. Bei der kubischen Modellierung, also hoch Drei, haben wir dann in der Abbildung eine bessere Modellierung. Die Effekte reichen dann aber nicht aus um über den gesamten zeitlichen Verlauf, Betonung liegt auf dem gesamten zeitlichen Verlauf, einen Unterschied zeigen zu können.

Daher müsste man hier einmal überlegen, ob man nicht die frühen Wochen aus den Daten entfernt. Hier sind die Gurlen noch sehr ähnlich, so dass wir hier eigentlich auch keinen Unterschied erwarten. Sonst könntest du nochmal mit einer $\log$-Transformation der Länge spielen, dann verlierst du zwar die direkte biologische Interpretierbarkeit der Effektschätzer, aber dafür könnte der Verlauf über die Zeit *besser* aufgesplittet werden. Das Problem sind ja hier sehr kleine Werte zu Anfang und sehr große Werte zum Ende.
