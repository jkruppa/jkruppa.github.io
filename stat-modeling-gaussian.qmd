```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, patchwork)
```

# Gaussian Regression {#sec-gaussian}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-gaussian.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

Selten nutzen wir eine multiple gaussian lineare Regression alleine. Häufig haben wir dann ein normalverteiltes Outcome, weshalb wir die Gaussian Regression überhaupt rechnen, und dann noch mehrere Faktoren über die wir eine Aussagen treffen wollen. Wir sind dann eher im Bereich der Posthoc-Tests als in wirklich einer Interpretation einer Gaussian Regression. Dennoch müssen wir wissen, ob die Gaussian Regression gut funktioniert hat. Die Überprüfung der Modellierung können wir dann in diesem Kapitel einmal durchgehen.

## Annahmen an die Daten

Im folgenden Kapitel zu der multiplen gaussian linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form *ideal* sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.

-   Wenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das @sec-missing zu Imputation von fehlenden Werten.
-   Wenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das @sec-outlier zu Ausreißer in den Daten.
-   Wenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das @sec-variable-selection bei der Variablenselektion.

Daher sieht unser Modell wie folgt aus. Wir haben ein $y$ und $p$-mal $x$. Wobei $p$ für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren ist unser $y$ normalverteilt. Das ist hier sehr wichtig, denn wir wollen ja eine multiple gaussian lineare Regression rechnen.

$$
y \sim x_1 + x_2 + ... + x_p 
$$

Wir können in dem Modell auch Faktoren $f$ haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in @sec-posthoc nochmal nachlesen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               see, performance, scales, parameters,
               olsrr, readxl, car, gtsummary)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Im Folgenden schauen wir uns die Daten eines Pilotprojektes zum Anbau von Kichererbsen in Brandenburg an. Wir haben an verschiedenen anonymisierten Bauernhöfen Kichererbsen angebaut und das Trockengewicht als Endpunkt bestimmt. Darüber hinaus haben wir noch andere Umweltparameter erhoben und wollen schauen, welche dieser Parameter einen Einfluss auf das Trockengewicht hat. In @sec-example-chickpea findest du nochmal mehr Informationen zu den Daten.

```{r}
#| message: false

chickpea_tbl <- read_excel("data/chickpeas.xlsx") 

```

In der @tbl-gaussian-chickpea ist der Datensatz `chickenpea_tbl` nochmal als Ausschnitt dargestellt. Insgesamt haben wir $n = 95$ Messungen durchgeführt. Wir sehen, dass wir verschiedene Variablen gemessen haben. Unter anderem, ob es geregent hat oder an welcher Stelle in Brandenburg die Messungen stattgefunden haben. Ebenso haben wir geschaut, ob ein Wald in der Nähe der Messung war oder nicht. Wir nehmen als Outcome $y$ das normalverteilte Trockengewicht `dryweight`.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-gaussian-chickpea
#| tbl-cap: Auszug aus dem Daten zu den Kichererbsen in Brandenburg.
#| column: page


chickpea_tbl <- read_excel("data/chickpeas.xlsx") 

rbind(head(chickpea_tbl, 4),
      rep("...", times = ncol(chickpea_tbl)),
      tail(chickpea_tbl, 4)) %>% 
  kable(align = "c", "pipe")

```

Im Folgenden werden wir die Daten nur für das Fitten eines Modells verwenden. In den anderen oben genannten Kapiteln nutzen wir die Daten dann anders.

## Fit des Modells

Wir rechnen jetzt den Fit für das vollständige Modell mit allen Variablen in dem Datensatz. Wir sortieren dafür einmal das $y$ mit `dryweight` auf die linke Seite und dann die anderen Variablen auf die rechte Seite des `~`. Wir haben damit unser Modell `chickenpea_fit` wie folgt vorliegen.

```{r}
chickenpea_fit <- lm(dryweight ~ temp + rained + location + no3 + fe + sand + forest, 
                   data = chickpea_tbl)
```

Soweit so gut. Wir können uns zwar das Modell mit der Funktion `summary()` anschauen, aber es gibt schönere Funktionen, die uns erlauben einmal die Performance des Modells abzuschätzen. Also zu klären, ob soweit alles geklappt hat und wir mit dem Modell weitermachen können.

## Performance des Modells

Da ich die Daten selber gebaut habe, ist mir bekannt, dass das Outcome `dryweight` normalverteilt *ist*. Immerhin habe ich die Daten aus einer Normalverteilung gezogen. Manchmal will man dann doch Testen, ob das Outcome $y$ einer Normalverteilung folgt. Das R Paket `oslrr` bietet hier eine Funktion `ols_test_normality()`, die es erlaubt mit allen bekannten statistischen Tests auf Normalverteilung zu testen. Wenn der $p$-Wert kleiner ist als das Signifikanzniveau $\alpha$, dann können wir die Nullhypothese, dass unsere Daten gleich einer Normalverteilung wären, ablehnen.

::: column-margin
Das [R Paket `olsrr`](https://olsrr.rsquaredacademy.com/articles/intro.html) erlaubt eine weitreichende Diagnostik auf einem normalverteilten Outcome $y$.
:::

```{r}
ols_test_normality(chickenpea_fit) 
```

Wir sehen, testen wir viel, dann kommt immer was signifikantes raus. Um jetzt kurz einen statistischen Engel anzufahren, wir nutzen *wenn überhaupt* den Shapiro-Wilk-Test oder den Kolmogorov-Smirnov-Test. Für die anderen beiden steigen wir jetzt hier nicht in die Theorie ab.

Nachdem wir die Normalverteilung nochmal überprüft haben wenden wir uns nun dem Wichtigen zu. Wir schauen jetzt auf die Varianz des Modells. Um zu überprüfen, ob das Modell funktioniert können wir uns den Anteil der erklärten Varianz anschauen. Wie viel erklären unsere $x$ von der Varianz des Outcomes $y$? Wir betrachten dafür das Bestimmtheitsmaß $R^2$. Da wir mehr als ein $x$ vorliegen haben, nutzen wir das adjustierte $R^2$. Das $R^2$ hat die Eigenschaft immer größer und damit besser zu werden je mehr Variablen in das Modell genommen werden. Wir können dagegen Adjustieren und daher das $R^2_{adj}$ nehmen.

```{r}
r2(chickenpea_fit)
```

Wir erhalten ein $R^2_{adj}$ von $0.87$ und damit erklärt unser Modell ca 87% der Varianz von $y$ also unserem Trockengewicht. Das ist ein sehr gutes Modell. Je nach Anwendung sind 60% bis 70% erklärte Varianz schon sehr viel.

Im nächsten Schritt wollen wir nochmal überprüfen, ob die Varianzen der Residuen auch homogen sind. Das ist eine weitere Annahme an ein gutes Modell. Im Prinzip überprüfen wir hier, ob unser Ourtcome auch wirklcih normalveteilt ist bzw. der Annahme der Normalverteilung genügt. Wir nutzen dafür die Funktion `check_heteroscedasticity()` aus dem R Paket `performance`.

```{r}
check_heteroscedasticity(chickenpea_fit)
```

Auch können wir uns einmal numerisch die VIF-Werte anschauen um zu sehen, ob Variablen mit anderen Variablen ungünstig stark korrelieren. Wir wollen ja nur die Korrelation des Modells, also die $x$, mit dem Outcome $y$ modellieren. Untereinander sollen die Variablen $x$ alle unabhängig sein. Für können uns die VIF-Werte für alle kontinuierlichen Variablen berechnen lassen.

```{r}
vif(chickenpea_fit)
```

Alle VIF-Werte sind unter dem Threshold von 5 und damit haben wir hier keine Auffälligkeiten vorliegen.

Damit haben wir auch überprüft, ob unsere Varianzen homogen sind. Also unsere Residuen annähend normalverteilt sind. Da unsere Daten groß genug sind, können wir das auch ohne weiteres Anwenden. Wenn wir einen kleineren Datensatz hätten, dann wäre die Überprüfung schon fraglicher. bei kleinen Fallzahlen funktioniert der Test auf Varianzheterogenität nicht mehr so zuverlässig.

In @fig-normal-model-check sehen wir nochmal die Visualisierung verschiedener Modellgütekriterien. Wir sehen, dass unsere beobachte Verteilung des Trockengewichts mit der vorhergesagten übereinstimmt. Ebenso ist der Residualplot gleichmäßig und ohne Struktur. Wir haben auch keine Ausreißer, da alle unsere Beobachtungen in dem gestrichelten, blauen Trichter bleiben. Ebenso zeigt der QQ-Plot auch eine approximative Normalverteilung der Residuen. Wir haben zwar leichte Abweichungen, aber die sind nicht so schlimm. Der Großteil der Punkte liegt auf der Diagonalen. Ebenso gibt es auch keine Variable, die einen hohen VIF-Wert hat und somit ungünstig mit anderen Variablen korreliert.

```{r}
#| echo: true
#| message: false
#| label: fig-normal-model-check
#| fig-align: center
#| fig-height: 8
#| fig-width: 8
#| fig-cap: "Ausgabe ausgewählter Modelgüteplots der Funktion `check_model()`."

check_model(chickenpea_fit, colors = cbbPalette[6:8], 
            check = c("qq", "outliers", "pp_check", "homogeneity", "vif")) 

```

## Interpretation des Modells

Nachdem wir nun sicher sind, dass das Modell unseren statistischen Ansprüchen genügt, können wir jetzt die Ergebnisse des Fits des Modells einmal interpretieren. Wir erhalten die Modellparameter über die Funktion `model_parameters()` aus dem R Paket `parameters`.

```{r}
#| message: false

chickenpea_fit %>% 
  model_parameters()
```

Schauen wir uns die einzelnen Zeilen aus der Ausgabe einmal in Ruhe an. Wir sind eigentlich nur an den Spalten `Coefficient` für das $\beta$ als Effekt der Variablen sowie der Spalte `p` als $p$-Wert für die Variablen interessiert. Wir testen immer als Nullhypothese, ob sich der Parameter von 0 unterscheidet.

-   `(Intercept)` beschreibt den den $y$-Achsenabschnitt. Wir brauen den Intercept selten in der Interpretation. Wir nehmen hier erstmal hin, dass wir einen von 0 signifikant unterschiedlichen Intercept haben. Meist löschen wir den Intrcept auch aus der finalen Tabelle raus.
-   `temp` beschreibt den Effekt der Temperatur. Wenn die Temperatur um ein Grad ansteigt, dann erhalten wir $1.75$ mehr Trockengewicht als Ertrag. Darüber hinaus ist der Effekt der Temperatur signifikant.
-   `rained [low]` beschreibt den Effekt des Levels `low` des Faktors `rained` im Vergleich zum Level `high`. Daher haben wir bei wenig Regen einen um $1.33$ höheren Ertrag als bei viel Regen.
-   `location [northeast]` beschreibt den Effekt des Levels `northeast` zu dem Level `north` des Faktors `location`. Wir haben also einen $-1.38$ kleineren Ertrag an Kichererbsen als im Norden von Brandenburg. Wenn du hier eine andere Sortierung willst, dann musst du mit der Funktion `factor()` die Level anders sortieren.
-   `location [west]` beschreibt den Effekt des Levels `west` zu dem Level `north` des Faktors `location`. Wir haben also einen $-2.40$ kleineren Ertrag an Kichererbsen als im Norden von Brandenburg. Wenn du hier eine andere Sortierung willst, dann musst du mit der Funktion `factor()` die Level anders sortieren.
-   `no3` beschreibt den Effekt von Nitrat im Boden. Wenn wir die Nitratkonzentration um eine Einheit erhöhen dann steigt der Ertrag um $1.11$ an. Wir haben hier einen $p$-Wert von $0.012$ vorliegen und können hier von einem signifkianten Effekt sprechen.
-   `fe` beschreibt den Effekt des Eisens im Boden auf den Ertrag an Kichererbsen. Wenn die Konzentration von Eisen um eine Einheit ansteigt, so sinkt der Ertrag von Kichererbsen um $-0.72$ ab.
-   `sand` beschreibt den Anteil an Sand in der Bodenprobe. Wenn der Anteil an Sand um eine Einheit ansteigt, so steigt der Ertrag an Kichererbsen um $3.03$ an. Dieser Effekt ist auch hoch signifikant. Kichererbsen scheinen sandigen Boden zu bevorzugen.
-   `forest [>1000m]` beschreibt die Nähe des nächsten Waldstückes als Faktor mit zwei Leveln. Daher haben wir hier einen höheren Ertrag von $0.67$ an Kichererbsen, wenn wir weiter weg vom Wald messen `>1000` als Nahe an dem Wald `<1000`.

Das war eine Wand an Text für die Interpretation des Modells. Was können wir zusammenfassend mitnehmen? Wir haben drei signifikante Einflussfaktoren auf den Ertrag an Kichererbsen gefunden. Zum einen ist weniger Regen signifikant besser als viel Regen. Wir brauchen mehr Nitrat im Boden. Im Weiteren ist ein sandiger Boden besser als ein fetter Boden. Am Ende müssen wir noch schauen, was die nicht signifikanten Ergebnisse uns für *Hinweise* geben. Der Ort der Messung ist relativ unbedeutend. Es scheint aber so zu sein, dass im Norden mehr Ertrag zu erhalten ist. Hier müsste man einmal schauen, welche Betriebe hier vorliegen und wie die Bodenbeschaffenheit dort war. Im Weiteren sehen wir, dass anscheinend ein Abstand zum Wald vorteilhaft für den Ertrag ist. Hier könnte Wildfraß ein Problem gewesen sein oder aber zu viel Schatten. Auch hier muss man nochmal auf das Feld und schauen, was das konkrete Problem sein könnte. Hier endet die Statistik dann.

## Und weiter?

Nach einer Gaussian Regression wollen wir dann häufig noch mit dem Modell weiter rechnen. Wir haben dann meist die Wahl zwischen zwei folgenden Fällen.

1)  Wir wollen eine [mehrfaktorielle ANOVA](#sec-anova) oder eine [mehrfaktorielle ANCOVA](#sec-ancova). Je nachdem wie viele Fakoteren $f$ oder Covariaten $c$ wir in den Daten haben.
2)  Wir wollen eine [Posthoc Analyse](#sec-posthoc) rechnen und die Level eines Faktores gegeben den anderen Variablen in dem Datensatz miteiander vergleichen. Wir rechnen also einen klassischen Mittelwertsvergleich.
