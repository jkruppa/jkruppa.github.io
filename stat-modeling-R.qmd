```{r echo = FALSE}
#| echo: false
#| warning: false
#| message: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, see,
               latex2exp, patchwork, parsnip, conflicted)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
conflicts_prefer(dplyr::filter)
```

# Modellieren in R {#sec-modeling-R}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-R.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Ich weiß nicht weiter; Ich will mich verändern; Doch wie fang ich's an?" --- Tocotronic, Die Unendlichkeit*

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Stand-By (seit 01.2025)

Dieses Kapitel ist auf Stand-By gesetzt, da ich die Thematik des Kapitels aktuell nicht in meiner Lehre oder der statistischen Beratung benötige. Archivierte Kapitel werden nicht von mir weiter gepflegt oder ergänzt. Auftretende Fehler werden aber natürlich beseitigt, wenn die Fehler mir auffallen.
:::

Dieses Startkapitel gibt dir nochmal eine Übersicht über das statistische Modellieren in R. Hier liegt vor allem der Fokus auf R. Es gibt eben eine Reihe von *zusätzlichen* Pakten, die es dir erlauben noch mehr aus einem statistischen Modell rauszuholen. Am Ende wurde es mir dann aber zu detailliert alle Pakete in jedem Kapitel vorzustellen und anzuwenden. Das ist auch nicht immer sinnig. Häufig willst du erstmal *nur* das Modell rechnen. Später kannst du dann noch tiefer ins Detail gehen oder aber komplexere Verfahren nutzen. Ich tue mich also etwas schwer dieses Kapitel einzuordnen. Entweder packen wir es ans Ende vom statistischen Modellieren und schauen, dann wie wir alles in R machen. Das steht aber etwas der Intuition entgegen, dass wir in jedem Kapitel zum statistischen Modellieren ja schon was selber machen wollen. In R gibt es dazu dann noch sehr gute Pakete, die das Modellieren sehr viel einfacher machen, dabei dann aber auch für den Anfänger etwas komplexer sind. Ich habe mich daher entschieden, diese aktuelle und komplexere Modellierung einmal hier am Anfang vorzustellen und in den folgenden Kapiteln teilweise darauf zu verweisen, wenn ich es sinnig fand. Du kannst alle Modelle auf althergebrachte Art und Weise rechnen ohne was zu verpassen. Aber manchmal möchte man dann auch effizienter Modellieren. Dafür ist dann dieses Kapitel da: Eine erweiterte Idee von der statistischen Modellierung zu erlangen. Fangen wir also erstmal mit der naheliegenden Frage an.

Was modellieren wir eigentlich?

:   Wir modellieren die Varianz in den Daten oder anders formuliert, wir versuchen die Varianz in den Daten den jeweiligen Quellen zuzuordnen und darüber dann neue Erkenntnisse zu erlangen.

**Was ist ein Modell**

[Statistical Thinking for the 21st Century --- What is a model?](https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html#what-is-a-model)

[Models are about what changes, and what doesn't](https://magesblog.com/post/modelling-change/)

![foo](images/average.jpg){#fig-pretest-barplot-02 fig-align="center" width="100%"}

Als nächstes wollen wir uns die Frage stellen, was ist eigentlich das ziel des Modellierens? Wir wollen ja mit der Modellierung der Varianz irgendwas erreichen. In der @fig-scatter-modeling-R-01 siehst du einmal die drei großen Fragefelder, die wir mit einer Modellierung bearbeiten können.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-scatter-modeling-R-01
#| fig-align: center
#| fig-height: 5
#| fig-width: 15
#| fig-cap: "Verschiedene Ziele und Möglichkeiten des statistischen Modellierens. Grob können die Möglichkeiten in drei große thematische Zusammenhänge eingeteilt werden. **(A)** *Kausales Modell* -- Wie verändert sich $y$, wenn sich $x_1$ ändert? Wie ist der numerische Zusammenhang zwischen $y$ und $x$? **(B)** *Prädikitives Modell* -- Wenn $y$ und $x$ gemessen wurden, wie sehen dann die Werte von $y$ für neue $x$-Werte aus? Können wir mit $x$ die Werte in $y$ vorhersagen? **(C)** *Clusteranalyse* -- Haben wir in unseren Variablen $x_1$ und $x_2$ eine oder mehrere unbekannte Cluster vorliegen? Wie gehören die Beobachtungen gegeben $x_1$ und $x_2$ zusammen? *[Zum Vergrößern anklicken]*"

source("images/R/stat-modeling-R-01.R")

p11 + p12 + p13 +
  plot_layout(ncol = 3) +
  plot_annotation(tag_levels = 'A') 

```

In diesem Kapitel wollen wir uns auch mit dem Thema marginale Effektmodelle (eng. *marginal effect models*) beschäftigen. Auch hier ist der deutsche Begriff nicht gebräuchlich, so dass ich mich hier dann immer auf die *marginal effect models* beziehen werde. Ein zweideutiger Aspekt der *marginal effect models* besteht darin, dass das Wort "marginal" auf zwei verschiedene und etwas entgegengesetzte Arten verwendet wird:

-   Bei "marginalen Effekten" (eng. *marginal effects*) beziehen wir uns auf die Auswirkung einer winzigen (marginalen) Änderung des Regressors auf das Ergebnis. Dies ist eine Steigung oder eine Ableitung.
-   Der Begriff "marginaler Mittelwert" (eng. *marginal means*) bezieht sich auf den Prozess der Marginalisierung über die Zeilen eines Vorhersagerasters. Dies ist ein Durchschnitt oder ein Integral.

Mehr dazu dann in dem Abschnitt zu den *marginal effect models* und dem [R Paket `{marginaleffects}`](https://marginaleffects.com/).

Dafür verweise ich auf @heiss2022 und das Onlinetutorium [Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/). Heiss erklärt dort sehr schön die Zusammenhänge. Dazu dann noch der Verweis auf die Webseite [Model to Meaning](https://marginaleffects.com/bonus/get_started.html) von @heiss2024 um nochmal tiefer in das Modellieren von Daten einzusteigen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, emmeans, multcomp, conflicted)
conflicts_prefer(dplyr::select)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Theoretisches Modellieren in R

### R Pakete

Neben den R Paketen, die wir in den jeweiligen Kapiteln brauchen, kommen noch folgende R Pakete immer wieder dran. Deshalb sind die R Pakete hier schon mal mit den jeweiligen Internetseiten aufgeführt.

-   Das Buch [Tidy Modeling with R](https://www.tmwr.org/) gibt nochmal einen tieferen Einblick in das Modellieren in R. Wir immer, es ist ein Vorschlag aber kein Muss.
-   Das [R Paket `{parameters}`](https://easystats.github.io/parameters/index.html) nutzen wir um die Parameter eines Modells aus den Fits der Modelle zu extrahieren. Teilweise sind die Standardausgaben der Funktionen sehr unübersichtich. Hier hilft das R Paket.
-   Das [R Paket `{performance}`](https://easystats.github.io/performance/) hilft uns zu verstehen, ob die Modelle, die wir gefittet haben, auch funktioniert haben. In einen mathematischen Algorithmus können wir alles reinstecken, fast immer kommt eine Zahl wieder raus.
-   Das [R Paket `{tidymodels}`](https://tidymodels.tidymodels.org/) nutzen wir als *das* R Paket um mit Modellen umgehen zu können und eine *Vorhersage neuer Daten* zu berechnen. Das Paket `{tidymodels}` ist wie das Paket `{tidyverse}` eine Sammlung an anderen R Paketen, die wir brauchen werden.

### Quantity and tests

[Kontrafaktisches Konditional](https://de.wikipedia.org/wiki/Kontrafaktisches_Konditional?wprov=sfti1)

> "Wenn ... der Fall wäre, dann wäre ..."

[Counterfactual comparisons](https://marginaleffects.com/chapters/comparisons.html)

### Generalisierung von `lm()` zu `glm()` und `[g]lmer()`

-   Die Funktion `lm()` nutzen wir, wenn das Outcome $y$ einer Normalverteilung folgt.
-   Die Funktion `glm()` nutzen wir, wenn das Outcome $y$ einer *andere* Verteilung folgt.
-   Die Funktion `lmer()` nutzen wir, wenn das Outcome $y$ einer Normalverteilung folgt *und* wir noch einen Block- oder Clusterfaktor vorliegen haben.
-   Die Funktion `glmer()` nutzen wir, wenn das Outcome $y$ einer *andere* Verteilung folgt *und* wir noch einen Block- oder Clusterfaktor vorliegen haben.

![Übersicht der Namen der Funktionen in R für das lm(), glm() und glmer().](images/glm-01.png){#fig-glm-01 fig-align="center" width="100%"}

In @fig-glm-02 sehen wir wie wir den Namen einer Regression bilden. Zuerst entscheiden wir, ob wir nur ein $x$ haben oder mehrere. Mit einem $x$ sprechen wir von einem simplen Modell, wenn wir mehrere $x$ haben wir ein multiples Modell. Im nächsten Schritt benennen wir die Verteilung für das Outcome $y$. Dann müssen wir noch entscheiden, ob wir ein gemischtes Modell vorliegen haben, dann schreiben wir das hin. Sonst lassen wir den Punkt leer. Anschließend kommt noch lineares Modell hinten ran.

![Wie bilde ich den Namen einer Regression? Erst beschreiben wir das $x$, dann das $y$. Am Ende müssen wir noch sagen, ob wir ein gemischtes Modell vorliegen haben oder nicht.](images/glm-02.png){#fig-glm-02 fig-align="center" width="100%"}

[Das R Paket `{tidymodels}`](https://www.tidymodels.org/)

[Tidy Modeling with R](https://www.tmwr.org/)

Veraltet aber manchmal ganz nützlich das [R Paket `{modelr}`](https://modelr.tidyverse.org/)

### Konfidenzintervall vs. Prädiktionsintervall

Ein Konfidenzintervall gibt den Wertebereich für einen gesuchten Parameter der Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit an. Ein Prognoseintervall gibt den Wertebereich für einen individuellen, zukünftig zu beobachtenden Wert mit einer bestimmten Wahrscheinlichkeit an.

#### Konfidenzintervall {.unnumbered .unlisted}

Text

Konfidenzintervall

:   Ein Konfidenzintervall gibt den Wertebereich für einen gesuchten Parameter der Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit an.

#### Prädiktionsintervall {.unnumbered .unlisted}

Text

Prädiktionsintervall

:   Ein Prädiktionsintervall (auch Vorhersageintervall oder Prognoseintervall) gibt den Wertebereich für einen individuellen, zukünftig zu beobachtenden Wert mit einer bestimmten Wahrscheinlichkeit an.

[Quantile Regression Forests for Prediction Intervals](https://www.bryanshalloway.com/2021/04/21/quantile-regression-forests-for-prediction-intervals/)

[The difference between prediction intervals and confidence intervals](https://robjhyndman.com/hyndsight/intervals/)

[P-values for prediction intervals](https://robjhyndman.com/hyndsight/forecasting-pvalues.html) machen keinen Sinn

[How NASA didn’t discover the hole in the ozone layer](https://robjhyndman.com/hyndsight/ozone-hole-anomaly.html)

## Praktisches Modellieren in R

### Marginal Effect Models

[R Paket `{ggeffects}`](https://strengejacke.github.io/ggeffects/articles/ggeffects.html)

[R Paket `{modelbased}`](https://easystats.github.io/modelbased/)

[R Paket `{marginaleffects}`](https://marginaleffects.com/)

### Visualisierung

[R Paket `{ggeffects}`](https://strengejacke.github.io/ggeffects/articles/ggeffects.html)

[R Paket `{gtsummary}`](https://www.danieldsjoberg.com/gtsummary/index.html)

[Display univariate regression model results in table](https://www.danieldsjoberg.com/gtsummary/reference/tbl_uvregression.html)

### ...mit `{purrr}`

`map()` für mehrere Endpunkte wie bei den Spinatdaten in Application gezeigt.

`map2()` mit Familie für `glm` zeigen, wenn wir unterschiedliche Outcomes haben.

```{r}
#| warning: false
#| message: false
cutting_tbl <- read_excel("data/multiple_outcomes.xlsx") |> 
  mutate(trt = as_factor(trt),
         block = as_factor(block)) |> 
  mutate_if(is.numeric, round, 2)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-model-r-multiple-out
#| tbl-cap: "Auszug aus den Daten ."

cutting_raw_tbl <- cutting_tbl |>
  mutate_all(as.character)
  

rbind(head(cutting_raw_tbl, 4),
      rep("...", times = ncol(cutting_raw_tbl)),
      tail(cutting_raw_tbl, 4)) |>
  kable(align = "c", "pipe")

```

```{r}
family_lst <- lst(shoot = binomial(),
                  leaf = quasipoisson(),
                  flower = quasipoisson(),
                  fruit = quasipoisson(),
                  ca = gaussian(), 
                  drymatter = gaussian(), 
                  freshweight = gaussian(), 
                  height = gaussian())
```

```{r}
cutting_long_tbl <- cutting_tbl |>
  pivot_longer(cols = shoot:last_col(),
               names_to = "outcome",
               values_to = "rsp") |>
  arrange(outcome, trt, block)
```

```{r}
cutting_lst <- cutting_long_tbl |>
  split(~outcome)
```

```{r}
#| message: false
#| warning: false
glm_lst <- cutting_lst %>% 
  map2(family_lst, 
       ~glm(rsp ~ trt + block + trt:block, 
            data = .x, family = .y))  
  
glm_lst %>% 
  map(pluck, "family")

glm_lst %>% 
  map(car::Anova)

emm_lst <- glm_lst %>% 
  map(~emmeans(.x, specs = ~ trt, type = "response")) 

emm_lst %>% 
  map(~contrast(.x, method = "pairwise", adjust = "bonferroni")) %>% 
  map(as_tibble) %>% 
  bind_rows(.id = "outcome")

emm_lst %>% 
  map(~cld(.x, Letters = letters, adjust = "bonferroni")) %>% 
  map(as_tibble) %>% 
  bind_rows(.id = "outcome") %>% 
  select(outcome, trt, .group)  %>% 
  print(n = 28)
```

## Verschiebebahnhof

[R Paket `{parsnip}`](https://parsnip.tidymodels.org/)

in diesem Kapitel wollen Fokus auf `{parsnip}` und dann als Kasten in allen anderen möglichen Modellierungen ergänzen?

[Tidymodels, interactions and anova - a short tutorial](https://www.thomasvanhoey.com/post/2021-10-12-tidymodels-interactions/)

:::: callout-note
## XX Regression in `{parsnip}`

Auch hier können wir die XX Regression in dem R Paket `{parsnip}` realisieren. Ein Vorteil von `{parsnip}` ist, dass wir die Funktionen sehr gut mit dem `|>`-Operator nutzen können. Das ist bei den Funktionen `glm()` und `lm()` in der ursprünglichen Implementierung ja leider nur etwas umständlicher möglich. Deshalb hier einmal die *bessere* Implementierung.

::: panel-tabset
## `{parsnip}`

```{r}
linreg_reg_fit <- linear_reg() |> 
  set_engine("lm") |> 
  fit(jump_length ~ grp, data = simple_tbl) 
```

Dann die ANOVA

```{r}
linreg_reg_fit|>  
  extract_fit_engine() |> 
  anova()
```

## `{base}`

```{r}
linreg_reg_fit <- lm(jump_length ~ grp, data = simple_tbl)
```

```{r}
linreg_reg_fit|>  
  anova()
```
:::

Eine detailliertere Einführung mit mehr Beispielen für die Nutzung vom [R Paket `{parsnip}`](https://parsnip.tidymodels.org/articles/Examples.html) findest du im Kapitel [Modellieren in R](#sec-modeling-R). Hier soll es dann bei der kurzen Gegenüberstellung bleiben.
::::

## Referenzen {.unnumbered}
