```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```


# Robust und Quantile Regression {#sec-reg-quantile}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"All models are approximations. Essentially, all models are wrong, but some are useful. However, the approximate nature of the model must always be borne in mind." --- George E. P. Box*

In diesem Kapitel geht es um zwei Arten der Regression, die immer wieder genannt werden, aber dennoch eine Art Nischendasein fristen. Zum einen möchte ich hier die robuste Regression (eng. *robust regression*) und zum anderen die Quantilsregression (eng. *quantile regression*) vorstellen. Die robuste Regression ist faktisch statistisch tot. Das heißt, die Implementierungen werden kaum weiterentwickelt und auch findet methodische Forschung nur in der theoretischen Nische statt. Zwar wird die robuste Regression in ihrer ursprünglichen Form als Regression angewendet, aber das reicht meistens nicht. Selten wollen wir nur durch ein paar Punkte eine Gerade ziehen und uns über das gute Modell erfreuen. Wir haben mit dem Modell meist mehr vor. Wir wollen eine ANOVA rechnen und dann auch einen wie auch immer gearteten Mittelwertsvergleich. Wenn dies zwar theoretisch möglich ist, praktisch aber nicht implementiert, dann wollen und können wir die Methoden nur eingeschränkt verwenden. Bei der Quantilsregression sieht es etwas anders aus, hier können wir dann schon den ein oder anderen Mittelwertsvergleich rechnen. Was bei der Quantilsregression eher problematisch ist, ist das das Modell nicht immer konvergiert oder aber nicht algorithmisch eine Lösung für einen spezifischen Datensatz findet. In diesem Datensatz dann den einen Grund zu finden, ist dann meist so aufwendig, dass wir es auch gleich mit der Quantilsregression lassen können.

Der Charme der Quantilesregression ist ja am Ende, dass wir auch den Median als Quantile auswählen können. So haben wir dann die Möglichkeit eine Regression auf den Medianen zu rechnen. Wir vergleichen damit dann auch die Mediane und sind so nicht mehr auf die Normalverteilung unseres Outcomes wie in der gewöhnlichen Regression angewiesen. Also eigentlich eine tolle Sache, wenn wir nur an den Mittelwertsvergleichen interessiert sind. Eine klassische ANOVA geht leider nicht auf einer Medianregression. Eine klassische ANOVA wäre aber mit nicht parametrischen Methoden sowieso nicht möglich gewesen. Wir verlieren also nicht so viel, gewinnen aber etwas, wenn das Modell konvergiert und ein Ergebnis liefert.

In diesem Kapitel brechen wir etwas die bisherige Struktur der Regressionskapitel auf. Wir schauen uns hier zuerst die beiden Modelle an und entscheiden dann, ob wir die Modelle für die ANOVA oder den Gruppenvergleich *überhaupt* nutzen können. Am Ende vergleichen wir dann einmal alle Modell mit dem fantastische Paket `modelsummary` mit der gleichnamigen Funktion. Hier hilft dann wie immer die tolle [Hilfsseite von modelsummary](https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html) zu besuchen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.


```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom, quantreg,
               see, performance, emmeans, multcomp, janitor,
               parameters, effectsize, MASS, modelsummary)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```


Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Für unser erstes Beispiel nutzen wir die Daten aus einem Wachstumsversuch mit Basilikum mit vier Bodenbehandlungen und vier Blöcken, die Blöcke sind eigentlich Gewächshaustische. Wir wollen also einen klassischen Gruppenvergleich mit Berücksichtigung der Blockstruktur rechnen.


```{r}
basi_tbl <- read_excel("data/keimversuch_basilikum_block.xlsx") %>%
  clean_names() %>% 
  mutate(versuchsgruppe = as_factor(versuchsgruppe)) %>% 
  select(versuchsgruppe, block_1:block_4)
```


In @tbl-model-1 sehen wir einmal die Daten im Wide-Format. Wir haben also das Frischgewicht der Basilikumpflanzen gemessen und wollen wissen, ob die verschiedenen Bodenarten einen Einfluss auf das Wachstum haben.


```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz des Frischegewichts von Basilikumpflanzen auf vier Tischen bzw. Blöcken in vier Versuchsgruppen."
#| label: tbl-model-1

basi_raw_tbl <- basi_tbl %>% 
  mutate(versuchsgruppe = as.character(versuchsgruppe))
rbind(head(basi_raw_tbl),
      rep("...", times = ncol(basi_raw_tbl)),
      tail(basi_raw_tbl)) %>% 
  kable(align = "c", "pipe")

```


Da wir die Daten im Wide-Format vorliegen haben, müssen wir die Daten nochmal in Long-Format umwandeln. Wie immer nutzen wir dafür die Funktion `pivot_longer()`.


```{r}
#| message: false
#| warning: false
basi_block_tbl <- basi_tbl %>% 
  pivot_longer(cols = block_1:block_4,
               values_to = "weight",
               names_to = "block") %>% 
  mutate(block = as_factor(block))
```


In der @fig-robust-basi-00 siehst du einmal die Daten als Dotplots mit Mittelwert und Standardabweichung. Wir machen hier mal einen etwas komplizierteren Plot, aber immer nur Barplot ist ja auch langweilig.


```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-robust-basi-00
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Dotplot des Frischegewichts von Basilikumpflanzen auf vier Tischen bzw. Blöcken in vier Versuchsgruppen mit Mittelwert und Standardabweichung."

ggplot(basi_block_tbl, aes(versuchsgruppe, weight, color = block)) +
  theme_bw() +
  scale_color_okabeito() +
  geom_point(position = position_dodge(0.5), shape = 4, size = 2.5) +
  stat_summary(fun.data="mean_sdl", fun.args = list(mult = 1), 
               geom="pointrange", position = position_dodge(0.5))  +
  stat_summary(fun = "mean", fun.min = "min", fun.max = "max", geom = "line",
               position = position_dodge(0.5)) 
```


Unser zweiter Datensatz ist ein Anwendungsdatensatz aus dem Gemüsebau. Wir schauen uns das Wachstum von drei Gurkensorten über siebzehn Wochen an. Die Gurkensorten sind hier unsere Versuchsgruppen. Da wir es hier mit echten Daten zu tun haben, müssen wir uns etwas strecken damit die Daten dann auch passen. Wir wollen das Wachstum der drei Gurkensorten *über* die Zeit betrachten - also faktisch den Verlauf des Wachstums. Wir ignorieren hier einmal die abhängige Datenstruktur über die Zeitpunkte.

::: column-margin
Mit einer abhängigen Datenstruktur müssten wir eigentlich ein lineares gemischtes Modell rechnen. Aber wir nutzen hier die Daten einmal anders.
:::

Im Weiteren haben wir zwei Typen von Daten für das Gurkenwachstum. Einmal messen wir den Durchmesser für jede Sorte (`D` im Namen der Versuchsgruppe) oder aber die Länge (`L` im Namen der Versuchsgruppe). Wir betrachten hier nur das Längenwachstum und deshalb filtern wir erstmal nach allen Versuchsgruppen mit einem `L` im Namen. Am Ende schmeißen wir noch Spalten raus, die wir nicht weiter brauchen.


```{r}
#| message: false
#| warning: false

gurke_raw_tbl <- read_excel("data/wachstum_gurke.xlsx") %>% 
  clean_names() %>% 
  filter(str_detect(versuchsgruppe, "L$")) %>% 
  select(-pfl, -erntegewicht) %>% 
  mutate(versuchsgruppe = factor(versuchsgruppe, 
                                 labels = c("Katrina", "Proloog", "Quarto"))) 
```


In der @tbl-model-2 sehen wir einmal die rohen Daten dargestellt.


```{r}
#| message: false
#| echo: false
#| tbl-cap: "Datensatz zu dem Längen- und Dickenwachstum von Gurken."
#| label: tbl-model-2

gurke_raw_2_tbl <- gurke_raw_tbl %>% 
  mutate(versuchsgruppe = as.character(versuchsgruppe))
rbind(head(gurke_raw_2_tbl),
      rep("...", times = ncol(gurke_raw_2_tbl)),
      tail(gurke_raw_2_tbl)) %>% 
  kable(align = "c", "pipe")

```


Dann müssen wir die Daten noch in Long-Format bringen. Da wir dann auch noch auf zwei Arten die Daten über die Zeit darstellen wollen, brauchen wir einmal die Zeit als Faktor `time_fct` und einmal als numerisch `time_num`. Leider haben wir auch Gurken mit einer Länge von 0 cm, diese Gruken lassen wir jetzt mal drin, da wir ja eine robuste Regression noch rechnen wollen. Auch haben wir ab Woche 14 keine Messungen mehr in der Versuchsgruppe `Prolong`, also nehmen wir auch nur die Daten bis zur vierzehnten Woche.


```{r}
gurke_time_len_tbl <- gurke_raw_tbl %>% 
  pivot_longer(cols = t1:t17,
               values_to = "length",
               names_to = "time") %>% 
  mutate(time_fct = as_factor(time),
         time_num = as.numeric(time_fct)) %>% 
  filter(time_num <= 14)
```


In der @fig-robust-gurke-00 sehen wir dann nochmal den Scatterplot für das Gurkenwachstum. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar.


```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-robust-gurke-00
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Scatterplot des Längenwachstums der drei Gurkensorten über vierzehn Wochen. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar."

ggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +
  theme_bw() +
  geom_point2(position = position_dodge(0.5)) +
  stat_summary(fun = "mean", geom = "line") +
  stat_summary(fun = "median", geom = "line", linetype = 2) +
  scale_x_continuous(breaks = 1:14) +
  scale_color_okabeito()
```


## Gewöhnliche lineare Regression

(eng. *ordinary linear regression*)


```{r}
#| message: false
#| warning: false
basi_lm_fit <- lm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
```

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Interaktionsplot über die Versuchsgruppen und Blöcke.
#| label: fig-stat-robust
emmip(basi_lm_fit, versuchsgruppe ~ block, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()
```


### ANOVA


```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  anova() %>% 
  model_parameters()
```

```{r}
pf(1.14, 9, 64, lower.tail = FALSE)
```

```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  eta_squared()
```


### Gruppenvergleich


```{r}
#| message: false
#| warning: false
basi_lm_fit %>% 
  emmeans(specs = ~ versuchsgruppe | block) %>%
  cld(Letters = letters, adjust = "none") 
```


## Robuste Regression {#sec-robust-reg}

Bei einer robusten Regression werden jeder Beobachtung auf der Grundlage ihres Residuums unterschiedliche Gewichte (eng. *robustness weights*) von 0 bis 1 zugewiesen. Wir kennen ja ein Residuum als die Differenz zwischen den beobachteten und den vorhergesagten Werten der Daten. Die vorhergesagten Daten sind ja die Punkte auf der Geraden. Je kleiner also das Residuum ist, desto größer ist die Gewichtung und desto näher liegt eine Beobachtung an der geschätzten Geraden. Wir bestrafen also Punkte, die weit weg von unserer potenziellen Gerade liegen.

::: column-margin
Ein englisches Tutorium gibt es dann nochmal ausführlicher unter [R demo \| Robust Regression (don't depend on influential data!)](https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression/)

Ebenso liefert auch das Tutorium [Robust regression \| R data analysis example](https://stats.oarc.ucla.edu/r/dae/robust-regression/) einen Überblick.
:::

Schauen wir uns das Problem an einem kleinen Spieldatensatz einmal an.


```{r}
#| message: false
#| warning: false
reg_tbl <- tibble(x = c(0, 1, 2, 3, 4, 5, 6, 7),
                  y = c(1, 1.5, 2.3, 2.8, 4.1, 5.3, 0, 6.8))
```

```{r}
#| message: false
#| warning: false
reg_lm_fit <- lm(y ~ x, reg_tbl)
reg_rlm_fit <- rlm(y ~ x, reg_tbl)
```


@fig-stat-robust-demo


```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "Scatterplot für den Unterschied zwischen einer robusten und gewöhnlichen Regression. Die gewöhnliche Regression ist blau, die robuste Regression rot."
#| label: fig-stat-robust-demo

ggplot(reg_tbl, aes(x, y, label = x)) +
  theme_bw() +
  geom_label() +
  geom_line(aes(y = predict(reg_lm_fit)), color = cbbPalette[3]) +
  geom_line(aes(y = predict(reg_rlm_fit)), color = cbbPalette[7]) 

```


In unserem Beispiel ist die Beobachtung 6 der Ausreißer. In einer normalen Regression erhält diese Beobachtung sehr viel Gewicht. Die Gerade wird dadurch nach unten gezogen. In einer robusten Regression erhält eine Beobachtung mit einem großen Residuum sehr wenig Gewicht, in diesem konstruierten Beispiel fast 0. Daher können wir sagen, das unser Modell *robust* gegen Ausreißer ist.

Okay, soweit lernt es jeder und die Idee der robusten Regression ist auch ziemlich einleuchtend. Aber in der Wissenschaft zeichnen wir keine Gerade durch Punkte und freuen uns drüber, dass die eine gerade besser passt als die andere Gerade.

Unbeliebt?

[History and unpopularity of robust regression](https://en.wikipedia.org/wiki/Robust_regression#History_and_unpopularity_of_robust_regression)

@stromberg2004write

Gibt es in biologischen Daten eigentlich überhaupt Ausreißer? Oder müssten wir nicht Ausreißer besonders betrachten, weil die Ausreßer dann doch mehr über die Daten verraten?

Es gibt noch das R Paket `robustbase` aber hier sind die Funktionen von `emmeans` nicht zugänglich.


```{r}
#| message: false
#| warning: false
basi_rob_fit <- rlm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
```


### ANOVA

Dann wollen wir einmal eine zweifaktorielle ANOVA auf den Modell der robusten Regression rechnen. Leider kann ich schon gleich sagen, dass wir hier ein Problem kriegen. Es ist nicht ganz klar unter Theoretikern welche Anzahl an Beobachtungen für die Residuen in der robusten Regression genutzt werden soll. Welche Beobachtungen werden den im Modell berücksichtigt und welche nicht? Daher ist dann der Wert für die Freiheitsgrade $df$ leer und wir erhalten keine $F$-Statistik und dann auch keine $p$-Werte. Für mich super unbefriedigend, so kann man dann auch keine Funktionen richtig nutzen.


```{r}
#| message: false
#| warning: false
basi_rob_aov <- basi_rob_fit %>% 
  anova() %>% 
  tidy()
basi_rob_aov
```


Was als Freiheitsgrad für die Residuen nehmen? In unserem Datensatz haben wir `r nrow(basi_block_tbl)` Basilikumpflanzen und somit auch Beobachtungen vorliegen. Wir setzen jetzt einfach brutal die Freiheitsgrade `df` für die Residuen auf 80 und können dann die Mean Squares für die Residuen berechnen. Also einmal flott die `meansq` für die Residuen durch die Anzahl an Beobachtungen geteilt.


```{r}
ms_resid <- 527 / 80
```


Mit den Mean Square der Residuen können wir dann auch die $F$-Werte berechnen. Den rechnerischen Weg kennen wir ja schon aus der zweifaktoriellen ANOVA.


```{r}
f_calc <- basi_rob_aov$meansq / ms_resid
```


Wie kriegen wir jetzt aus den ganzen berechneten $F$-Werten die entsprechenden $p$-Werte? Die $p$-Werte sind die Fläche rechts von den berechneten Werten. Wir können die Funktion `pf()` nutzen um diese Flächen zu berechnen. Wir machen das einmal beispielhaft für einen $F_{calc} = 3.41$ für 4 Gruppen mit $df_1 = 4 - 1 = 3$ und 12 Beobachtungen $df_2 = 12$. Die Berechnung von $df_2$ ist statistisch *falsch* aber für unseren MacGyver Hack hinreichend.


```{r}
pf(3.41, 3, 12, lower.tail = FALSE) %>% round(3)
```


Und siehe da, wir erhalten einen $p$-Wert von $0.053$. Nun können wir das nicht nur für einzelnen $F$-Werte machen sondern auch für unseren ganzen Vektor `f_calc`. Als $df_2$ setzen wir die Anzahl an Basilikumpflanzen.


```{r}
p_vec <- pf(f_calc, c(3, 3, 9), c(80, 80, 80), lower.tail = FALSE) %>% 
  scales::pvalue()
```


Die berechneten $F$-Werte und $p$-Werte können wir jetzt in die ANOVA Tabelle ergänzen.


```{r}
basi_rob_aov %>% 
  mutate(statistic = f_calc, 
         p.value = p_vec)
```


Das war jetzt ein ganz schöner Angang und den $p$-Werten ist nur approximativ zu trauen, aber wenn wir weit vom Signifikanzniveau $\alpha$ gleich 5% sind, dann macht eine numerische Ungenauigkeit auch nicht viel aus. Achtung deshalb bei $p$-Werten nahe des Signifikanzniveau $\alpha$, hier ist dann die Aussage mit Vorsicht zu treffen oder eher nicht möglich.

Glücklicherweise können wir aus den Sum of squares dann unsere $\eta^2$-Werte für die erklärte Varianz unserer ANOVA berechnen. Das ist dann doch schon mal was. Wir sehen, dass die Blöcke am meisten der Varianz erklären und die Versuchsgruppen sehr wenig. Das ist für das Modell dann nicht so schön, deckt sich aber mit den Ergebnissen gewöhnlichen Regression. Wir erhalten eine Konfidenzintervalle, woran du schon erkennen kannst, dass in der Ausgabe der ANOVA der robusten Regression was fehlt.


```{r}
#| message: false
#| warning: false
basi_rob_fit %>% 
  eta_squared()
```


### Gruppenvergleich

Dafür geht der Gruppenvergleich für die robuste Regression wie von alleine. Wir haben keine Interaktion vorliegen, daher müssen wir auch nicht den Block berücksichtigen. Das wir in Block 1 ein Problem haben, steht dann aber auf einem anderen Blatt. Da aber *alle* Basilikumpflanzen immer im Block 1 kleiner sind, passt es dann wieder im Sinne keiner Interaktion. Mit Interaktion hätten wir sonst `versuchsgruppe | block` statt nur `versuchsgruppe` hinter die Tilde geschrieben. Dann wollen wir noch das *compact letter disply* und alles ist wie es sein sollte.


```{r}
#| message: false
#| warning: false
basi_rob_fit %>% 
  emmeans(specs = ~ versuchsgruppe) %>%
  cld(Letters = letters, adjust = "none") 
```


Wir sehen also, dass sich Erde+Fließ und Erde nicht unterscheiden. Die beiden aber dann von Perlite+Fließ sowie Erde+Perlite. Am Ende unterscheiden sich Perlite+Fließ und Erde+Perlite nicht.

## Quantilsregression {#sec-quantile-reg}

::: column-margin
Ein englisches Tutorium gibt es dann nochmal ausführlicher unter [Quantile Regression as an useful Alternative for Ordinary Linear Regression](https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression/)
:::


```{r}
#| message: false
#| warning: false
time_rq_lin_fit <- rq(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, tau = 0.5,
                      gurke_time_len_tbl)
time_rq_quad_fit <- rq(length ~ versuchsgruppe * poly(time_num, 2), tau = 0.5, 
                       gurke_time_len_tbl)
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-robust-gurke-01
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Scatterplot des Längenwachstums der drei Gurkensorten über vierzehn Wochen. Die gestrichtelten Linien stellen den Median und die durchgezogene Line den Mittelwert der Gruppen dar."

ggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +
  theme_bw() +
  geom_point2(position = position_dodge(0.5)) +
  scale_color_okabeito() +
  geom_line(aes(y = predict(time_rq_quad_fit), linetype = "Quadratic")) +
  geom_line(aes(y = predict(time_rq_lin_fit), linetype = "Linear")) +
  scale_x_continuous(breaks = 1:14) +
  labs(linetype = "", color = "")
```


### ANOVA

Machen wir es kurz. Die ANOVA ist für die Quantilsregression nicht implementiert und damit auch nicht anwendbar. Damit können wir aber leben, wenn wir die ANOVA nur als Vortest ansehen. Wir müssen dann eine mögliche Interaktion visuell überprüfen. Um die Interaktion visuell zu überprüfen nutzen wir die Funktion `emimp()` aus dem R Paket `emmeans`. Wir sehen in der @fig-rob-inter-time, dass sich die Gerade für die Versuchsgruppen über die Zeit nicht schneiden, was gegen eine starke Interaktion spricht. Die Steigung ist aber für alle drei Versuchsgruppen über die Zeit nicht gleich, wir haben zumindest eine mittlere Interaktion.


```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| label: fig-rob-inter-time
#| fig-cap: "Interaktionsplot über den zeitlichen Verlauf für alle drei Sorten für die Quantilesregression."
#| fig-subcap: 
#|   - "Linear"
#|   - "Quadratic"
#| layout-nrow: 1
emmip(time_rq_lin_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()

emmip(time_rq_quad_fit, versuchsgruppe ~ time_num, CIs = TRUE, 
      cov.reduce = FALSE) +
  theme_bw() +
  scale_color_okabeito()
```


Wir würden also in unseren Gruppenvergleich der Mediane auf jeden Fall die Interaktion mit rein nehmen und die `emmeans()` Funktion entsprechend mit dem `|` anpassen.

### Gruppenvergleich

Wenn wir den Gruppenvergleich in `emmeans()` rechnen wollen, dann geht es nur dem Spezialfall der Median-Regression. Wir müssen also zwangsweise in der Quantilesregression `rq()` das `tau = 0.5` setzen um dann eine Median-Regression zu rechnen. Sonst können wir nicht `emmeans` nutzen.


```{r}
#| message: false
#| warning: false

time_rq_quad_fit %>% 
  emmeans(pairwise ~ versuchsgruppe | time_num, infer  = TRUE,
          adjust = "none", at = list(time_num = c(1, 7, 14))) %>%
  cld(Letters = letters, adjust = "none") 

```


## Modellvergleich

### Basilikumdaten

Für den Modellvergleich der gewöhnlichen, robusten und medianen Regression nutzen wir nochmal den Datensatz für das Basilikumwachstum. In einem ersten Schritt fitten wir wieder alle Modelle und achten darauf, dass wir bei der Quantilesregression angeben welches Quantile wir wollen. Wir wählen mit `tau = 0.5` dann den Median und rechnen so eine Medianregression.


```{r}
#| message: false
#| warning: false
basi_lm_fit <- lm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
basi_rlm_fit <- rlm(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl)
basi_rq_fit <- rq(weight ~ versuchsgruppe + block + versuchsgruppe:block, basi_block_tbl,
                  tau = 0.5)
```


Im Folgenden nutzen wir dann das fantastische Paket `modelsummary` mit der gleichnamigen Funktion um uns einmal die Modelle im Vergleich anzuschauen. Hier hilft dann wie immer die tolle [Hilfsseite von modelsummary](https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html) zu besuchen. Ich möchte nur nicht den Intercept und die Schätzer für die Blöcke haben, deshalb fliegen die hier einmal raus.


```{r}
modelsummary(lst("Ordinary" = basi_lm_fit,
                 "Robust" = basi_rlm_fit,
                 "Quantile" = basi_rq_fit),
             estimate  = "{estimate}",
             statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"),
             coef_omit = "Intercept|block")
```


Wie wir sehen sehen haben nicht alle Modelle die gleichen Informationen zurüch gegeben. Insbesondere das fehlen des Bestimmtheitsmaßes $R^2$ bei der robusten Regression ist schmerzlich, da wir hier dann nicht die Möglichkeit haben eine Aussage über die erklärte Varianz der robusten Regression zu treffen. Auch fehlt bei der Medianregression das adjustierte $R^2$, was die Nutzung bei Modellen mit mehr als einer Einflussvariable $x$ im Modell erschwert bis nutzlos macht. Daher bleibt uns am Ende nur das AIC oder BIC, wobei wir dort den kleinsten Wert als besser erachten. Die AIC und BIC Werte sind somit am besten für die Quantilesregression. Dafür ist dann aber der Fehler RMSE bei der gewöhnlichen Regression am niedrigsten. Und so stehe ich wieder davor und weiß nicht was das beste Modell ist. Hier müsste ich dann nochmal überlegen, ob ich lieber über Mittelwerte oder Mediane berichten möchte und das ist ohne die Forschungsfrage nicht hier zu lösen.

### Gurkendaten


```{r}
#| message: false
#| warning: false
time_lm_fit <- lm(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, gurke_time_len_tbl)
time_rlm_fit <- rlm(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, gurke_time_len_tbl)
time_rq_fit <- rq(length ~ versuchsgruppe + time_num + versuchsgruppe:time_num, tau = 0.5,
                  gurke_time_len_tbl)
```


Auch hier nutzen wir dann das fantastische Paket `modelsummary` mit der gleichnamigen Funktion um uns einmal die Modelle im Vergleich anzuschauen.


```{r}
modelsummary(lst("Ordinary" = time_lm_fit,
                 "Robust" = time_rlm_fit,
                 "Quantile" = time_rq_fit),
             estimate  = "{estimate}",
             statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"),
             coef_omit = "Intercept|time_num")
```


Hier sieht es ähnlich aus wie bei den Modellvergleichen von den Basilikumdaten. Nur hier wissen wir, dass wir Ausreißer in der Form von Gurken mit einer Länge von 0 cm in den Daten haben. Daher sehen wir auch, dass die robuste Regression und die Medianregression ein niedrigeres AIC und BIC haben. Für mich interessant ist, dass der Fehler RMSE wieder am kleinsten bei der gewöhnlichen Regression ist, das mag aber auch an der Berechnung liegen. Da wir Ausreißer haben, sind natürlich dann auch die robuste Regression und die Medianregression vorzuziehen. Da die Medianregression den kleineren AIC Wert hat, nehmen wir dann die Medianregression als die beste Regression an.

Vermutlich wäre es aber schlauer zuerst die Daten zu bereinigen und die Gurken mit einem Wachstum von 0 cm zu entfernen. Auch die anderen Wachstumskurven von anderen Gurken sind etwas wirr. Da müsste man auch nochmal ran und schauen, ob nicht die Gurken lieber aus der Analyse raus müssen. Am Ende ist dann natürlich die Frage, ob man die Daten dann nicht doch lieber über ein gemischtes Modell auswertet, da natürlich die Zeitpunkte voneinander abhängig sind. Aber wie immer im Leben, alles geht nicht.

## Referenzen {.unnumbered}

