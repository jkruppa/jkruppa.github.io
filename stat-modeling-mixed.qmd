```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, simstudy)
```

# Lineare gemischte Modelle {#sec-mixed}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

::: column-margin
Dieses Kapitel basiert auf dem tollen [Tutorium von Gabriela K Hajduk](https://ourcodingclub.github.io/tutorials/mixed-models/). Die Daten und Inhalte wurden von mir angepasst und teilweise gekürzt sowie inhaltlich angepasst.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom, see,
               multcomp, emmeans, lme4, broom.mixed,
               parameters, ggridges, scales, performance)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

In diesem fiktiven Datenbeispiel wollen wir uns die Testscores eines Intelligentest bei $N = 480$ Drachen anschauen. Wir sind dafür an acht Berge gefahren und haben die dortigen Drachen an den drei Flanken des Berges getestet. Daher hat der Faktor `mountain_range` acht Level mit Bavarian, Ligurian, Emmental, Central, Maritime, Southern, Julian, und Sarntal. Die drei Flanken des Berges bilden wir im Faktor `site` mit den Leveln north, east und south ab. In @fig-mountain-site sehen wir eine Skizze für drei Berge mit den jeweiligen Flanken, wo gemessen wurde.

![Beispiel für drei der acht Berge mit *Bavarian*, *Central* und *Julian*. Auf jeden der acht Berge wurden an drei Seiten *north*, *east* und *south* die Testscores der dort lebenden Drachen erhoben.](images/mountain.png){#fig-mountain-site fig-align="center" width="90%"}

Die Daten liegen in dem Datensatz `dragons.csv` ab. Wir müssen aber noch einen Faktor `body_length_cat` bilden in dem wir die `body_length` der einzelnen Drachen in Kategorien umwandeln. Wir wollen später noch Gruppenvergleiche rechnen und brauchen daher einen Faktor mit Leveln. Daher nutzen wir die Funktion `case_when()` um einen Faktor mit fünf Größenkategorien zu bilden. Danach müssen wir wie immer noch die `character` Spalten in die entsprechenden Faktoren umwandeln.

```{r}

dragons_tbl <- read.csv2("data/dragons.csv") %>% 
  mutate(body_length_cat = 
           case_when(body_length < 170 ~ "tiny",
                     body_length >= 170 & body_length < 180 ~ "small",
                     body_length >= 180 & body_length < 200 ~ "medium",
                     body_length >= 200 & body_length < 220 ~ "large",
                     body_length >= 220 ~ "gigantic"),
         body_length_cat = as_factor(body_length_cat),
         mountain_range = as_factor(mountain_range),
         site = factor(site, labels = c("north", "east", "south"))) %>% 
  select(test_score, body_length, body_length_cat, everything())

```

Es ergibt sich dann der Datensatz wie in @tbl-dragon gezeigt. Wir belassen die Körperlänge der Drachen in der kontinuierlichen Form nochmal mit in den Daten.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-dragon
#| tbl-cap: Datensatz der Testscores für die Drachen auf verschiedenen Bergen und dort an verschiedenen Flanken der Berge.
#| column: page

dragons_raw_tbl <- dragons_tbl %>% 
  mutate(body_length_cat = as.character(body_length_cat),
         mountain_range = as.character(mountain_range),
         site = as.character(site))

rbind(head(dragons_raw_tbl, n = 4),
      rep("...", times = ncol(dragons_raw_tbl)),
      tail(dragons_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Bevor wir mit dem Modellieren beginnen, wollen wir erstmal visuell überprüfen, ob unser Outcome $y$ mit dem Testscore auch normalverteilt ist. Wir benötigen für das *klaissche* lineare gemischte Modell ein normalverteiltes Outcome $y$. In @fig-mixed-1 sehen wir das Histogramm der Verteilung des Testscores für alle $N = 480$ Drachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-1

ggplot(dragons_tbl, aes(test_score)) +
  geom_histogram() +
  theme_bw() 
```

Wir können in der @fig-mixed-2 auch nochmal schauen, ob die Annahme der annährenden Normalverteilung für unseren Testscore auch für jedes Level unseres Faktors der Körperlängen gegeben ist. Wir sehen auch hier, dass der Testscore einer Normalverteilung über alle Kategorien der Körperlänge folgt.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Histogramm des Testscores aufgeteilt nach Kategorie der Körpergröße zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores für alle Kategorien der Körpergröße.
#| label: fig-mixed-2

ggplot(dragons_tbl, aes(y = body_length_cat, x = test_score, fill = body_length_cat)) +
  theme_bw() +
  stat_density_ridges() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Natürlich können wir uns hier noch weitere Abbildungen erstellen, aber hier soll es erstmal reichen. Wir sehen, dass der Testscore einer Normalverteilung folgt und dass die Varianzen vermutlich homogen sind, da die Histogramme ungefähr gleich breit sind. Ja, ein wenig unterscheiden sich die Verteilungen, aber so gravierend ist es erstmal nicht.

## Modellierung

Im Folgenden wollen wir uns verschiedene statistische Modelle anschauen um uns dem linearen gemischten Modell einmal anzunähern. Dabei beginnen wir mit einem simplen Gaussian lineare Modell mit einem Faktor $f_1$:

$$
y \sim f_1
$$

Wir haben also nur einen Faktor in unserem Modell vorliegen und ignorieren die restlichen in den Daten vorhandenen Variablen.

Als zweites Modell betrachten wir eine multiples Gaussian lineares Modell mit einem Faktor $f_1$ und einem Blockfaktor $b_1$:

$$
y \sim f_1 + b_1
$$

Jetzt erweitern wir das Modell nochmal um einen Block oder auch Clustereffekt. Das heißt, wir haben alle Beobachtungen nicht auf einem Feld oder in einem Stall durchgeführt, sondern an mehreren Orten.

Der eigentliche Bruch kommt jetzt. Wie wollen wir den Effekt des Blocks betrachten? Hier entscheidet sich, ob wir den Block als festen Effekt (eng. *fixed effect*) oder als zufälligen Effekt (eng. *random effect*) ausweisen wollen. Zuerst ist dies eine Modellierungsentscheidung. Wir müssen uns also zwischen zwei Modellen entscheiden. Daher können wir auch beide Arten bauen und dann Modelle vergleichen. Machen wir dann auch am Ende des Kapitels.

::: column-margin
Die Idee hinter dem Modell mit **festen Effekten** ist, dass die beobachteten Effektgrößen von Block zu Block variieren können, was aber nur auf den Stichprobenfehler $\epsilon$ zurückzuführen ist. In Wirklichkeit sind die wahren Effektgrößen alle gleich: Sie sind fix. (siehe auch [The Fixed-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#fem))
:::

::: column-margin
Das Modell der **zufälligen Effekte** geht davon aus, dass es nicht nur eine wahre Effektgröße gibt, sondern eine Verteilung der wahren Effektgrößen. Das Ziel des Modells mit zufälligen Effekten ist es daher nicht, die eine wahre Effektgröße aller Studien zu schätzen, sondern den Mittelwert der Verteilung der wahren Effekte. (siehe auch [The Random-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem))
:::

Daher kommt jetzt als drittes Model ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor $f_1$ und einem zufälligen Blockfaktor $z_1$:

$$
y \sim f_1 + 1|z_1
$$

Wir schreiben in R den Term für da zufällige Modell in der Form $z_0|z_1$. Meist setzen wir den Intercept $z_0$ für den zufälligen Effekt auf `1`.

Abschießend schauen wir uns noch ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor $f_1$ und einem zufälligen Blockfaktor $z_2$ genested in einem einem zufälligen Blockfaktor $z_1$:

$$
y \sim f_1 + 1|z_1/z_2
$$

[Wir sagen *nested*, wenn wir meinen, dass ein Faktor in einen anderen Faktor verschränkt ist. Die Klassen einer Schule sind in der Schule genested.]{.aside}

Das heißt, dass der zufällige Blockfaktor $z_2$ in den zufälligen Blockfaktor $z_1$ genested ist. Das heist, die Faktorlevel des Blockfaktors $z_2$ finden sich jeweils nur in jeweils einem der Faktorlevel des Blocks $z_1$. Das klingt jetzt etwas schräg, also einmal ein Beispiel. Wir haben eine Schule, dann sind die Schulklassen dieser Schule in der Schule genested. Es gibt diese spezifischen Klassen mit den Schülern schlichtweg nicht in anderen Schulen.

Bevor wir jetzt mit dem Modellieren beginnen, müssen wir noch kurz in einem QQ-Plot schauen, ob unser Ourcome `testscore` auch ungefähr normalverteilt ist. @fig-mixed-6 zeigt den QQ-Plot des Testscores. Wir sehen, dass der Hauptteil der Beobachtungen auf der Geraden liegt und wir nehmen daher an, dass der Testscore zumindest approximativ normalverteilt ist. Wir können also mit einem gaussian linearen gemischten Modell weitermachen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: QQ-Plot zu Überprüfung, ob der Testscore einer Normalverteilung folgt. Die Punkte liegen ungefähr auf der Geraden als Winkelhalbierende, so dass wi eine Normalverteilung des Testscores annehmen können.
#| label: fig-mixed-6

ggplot(dragons_tbl, aes(sample = test_score)) +
  stat_qq() + stat_qq_line(color = "red") +
  theme_bw() +
  scale_color_okabeito()
```

Schauen wir uns nun als erstes das Modell `lm_simple_fit` einmal an. Wir bauen das Modell nur mit der Faktorvariable `body_length_cat`. Wir erhalten dann gleich die Ausgabe des Modells über die Funktion `model_parameters()` in einer aufgearbeiteten Form.

```{r}
#| message: false
#| warning: false
#| column: page

lm_simple_fit <- lm(test_score ~ body_length_cat, data = dragons_tbl)

lm_simple_fit %>% model_parameters()

```

Der Intercept beinhaltet den Mittelwert für die Drachen des Levels `[tiny]`. Die jeweiligen Koeffizienten dann die Abweichung von den Drachen des Levels `[tiny]`. Daher sind Drachen des Levels `[small]` ungefähr um $2.63$ Einheiten intelligenter. Wir sehen dann an dem $p$-Wert, ob sich die Koeffizienten signifikant von 0 unterscheiden. In @fig-mixed-3 sehen wir nochmal die Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße. Wir erkennen, dass die kleineren Drachen tendenziell dümmer sind als die großen Drachen. Wir sehen zwei Plateaus.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße.
#| label: fig-mixed-3

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = body_length_cat)) +
  theme_bw() +
  geom_boxplot() +
  theme(legend.position = "none") +
  scale_fill_okabeito() 
```

Nun haben wir aber nicht nur die Körpergrößen gemessen sondern auch auf welchem Berg wir die jeweiligen Drachen gefunden haben. Nun könnte es sein, dass der Berg einen viel größeren Einfluss auf die Inteliegenz hat als die Drachenkörpergröße. Wir könnten einen Confoundereffekt durch die Berge vorliegen haben. Ergänzen wir also das Modell um den Faktor `mountain_range` und erhalten das Modell `lm_mountain_fit`.

```{r}
#| message: false
#| warning: false
#| column: page

lm_mountain_fit <- lm(test_score ~ body_length_cat + mountain_range, data = dragons_tbl)
lm_mountain_fit %>% model_parameters()
```

Wie wir sehen, werden nun die Körpergrößen der Drachen nicht mehr als signifikant ausgegeben. Die Effekte der Körpergröße auf den Testscore sind auch viel kleiner geworden, wenn wir die `mountain_range` mit in das Modell nehmen. Anscheinend hat der Berg auf dem wir den Drachen getroffen haben einen viel größeren Einfluss auf die Intelligenz als die Körpergröße. Wir können uns den Zusammenhang zwischen dem Testscore und dem Berg auch in der @fig-mixed-4 einmal anschauen.

Eigentlich würden wir erwarten, dass es keinen Effekt der Berge auf den Testscore der Drachen gibt. Es müsste eigentlich egal sein, wo wir einen Drachen befragen, wenn wir nur an der Körpergröße und dem Testscore interessiert sind. Wir sehen jedoch in der @fig-mixed-4 einen klaren Unterschied zwischen den Bergen im Bezug auf den Testscore.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung.
#| label: fig-mixed-4

ggplot(dragons_tbl, aes(mountain_range, test_score, fill = mountain_range)) +
  geom_boxplot() +
  theme_bw() +
  theme(legend.position = "none") +
  scale_fill_okabeito()
```

In der @fig-mixed-5 sehen wir den Zusammenhang von Testscore und der Körpergröße sowie den Bergen auf denen das Interview stattgefunden hat. so langsam dämmert uns warum wir hier einen Effekt der Körperlänge zu dem Testscore sehen. Die kleineren Drache sind alle nur auf bestimmten Bergen zu finden! Betrachten wir die Berge mit in dem Modell, dann hat die Körpergröße keinen Einfluß mehr.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße.
#| label: fig-mixed-5

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain")
```

Der Zusammenhang wird vielleicht in @fig-mixed-7 nochmal klarer. Hier schauen wir uns den Zusamenhang wieder für die Körperlänge getrennt für die Berge an. Nur zeichnen wir jetzt jeden einzelnen Berg in ein Subplot. Wir sehen, dass es hier fast keinen Unterschied macht, wie lang die Drachen sind. Der Testscore ist immer gleich. Was einen Unterschied macht, sind die Berge.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße in getrennten Subplots.
#| label: fig-mixed-7

ggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +
  geom_boxplot(position = position_dodge(preserve = "single")) +
  theme_bw() +
  scale_fill_okabeito() +
  labs(fill = "Mountain") +
  theme(legend.position = "none") +
  facet_wrap(~ mountain_range) 
```

Schauen wir uns nun einmal ein lineares gemischtes Modell an. Wir nutzen daszu das R Paket `lme4`. Wir haben auch noch andere Pakete zur Aswahl, aber wir nutzen hier erstmal das gängiste Paket. Um ein lineares gemischtes Modell in R zu schätzen nutzen wir die Funktion `lmer()`. Die Funktion `lmer()` nimmt an, dass das Outcome `test_score` normalverteilt ist. Wir haben diese Annahme ja weiter oben in dem QQ-Plot überprüft.

In einem lineare gemischten Modell müssen wir die *festen* Effekte sowie die *zufälligen* Effekte definieren. Die festen Effekte werden ganz normal wie wir es gewohnt sind in das Modell eingegeben. Die zufälligen Effkete schreiben wir in eine Klammer in der Form `(1|)`.

Wir schreiben `(1|moutain_range)` und definieren damit die Variable `mountain_range` als zufälligen Effekt im Modell. Wir schreiben `1|` vor `mountain_range`, da wir für jeden Berg die gleiche Steigung von Körperlänge und Testscore annehmen. Wir können dann später noch das Model komplizierter aufbauen und jedem Berg eine eigene Steigung erlauben. Bauen wir uns jetzt erstmal ein lineares gemischtes Modell mit einem festen Effekt `body_length_cat` und einem zufälligen Effekt `(1|mountain_range)`.

```{r}
#| message: false
#| warning: false

lmer_1_fit <- lmer(test_score ~ body_length_cat + (1 | mountain_range), data = dragons_tbl)
lmer_1_fit %>% model_parameters()
```

Unser Model sieht etwas aufgeräumter aus. Als feste Effekte haben wir nur noch die Körperlänge `body_length_cat` und die dazugehörigen Koeffizienten des Modells. Unsere Variable `mountain_range` verschwindet dann in den zufälligen Effekten. Die Funktion `summary` liefert uns den gesamten Ausdruck, der etwas überwältigend ist. Vieles brauchen wir auch nicht davon.

```{r}
#| message: false
#| warning: false

lmer_1_fit %>% summary()
```

Was wir extrahieren wollen ist die Information von den zufälligen Effekten. Wir wollen wissen, wieviel Varianz durch die zufälligen Effekte erklärt wird. Wir nutzen dazu die Funktion `VarCorr()`, die uns erlaubt die Information zu en zufälligen Effekten zu extrahieren und auszugeben.

```{r}
print(VarCorr(lmer_1_fit), comp = "Variance")
```

Wieviel Varianz erklären nun die Berge? Wir können die erklärte Varianz der zufälligen Effekte einfach berechnen. Wir vergleichen die erklärte Varianz von `mountain_range` mit der gesamten Varianz. Die gesamte Varianz ist die Varianz aller zufälligen Effekte plus der residualen Vamrianz. Wir erhalten dann $R^2_{random} = 339.7/(339.7 + 223.8) \approx 0.60$. Wir sehen, dass ca. 60% der Varianz in unseren Daten von der Variable `mountain_range` verursacht wird.

Wir können die Funktion `model_performance()` nutzen um mehr über den Fit des Modells zu erfahren. Das `R2 (cond.)` ist faktisch das gleiche wie wir gerade oben berechnet haben. Wir benötigen also nicht immer den Ausdruck der zufälligen Effekte. Wir können auch die Informationen aus der Funktion `model_performance()` nehmen.

```{r}
lmer_1_fit %>% model_performance()
```

In der Abbildung @fig-mixed-8 schauen wir uns nochmal an, ob wir das Modell auch gut gefittet haben. Der Residualplot sieht gut aus, wir erkennen kein Muster. Ebenso sieht der QQ-Plot gut aus, die Beobachtungen liegen alle auf der Geraden. Wir sind mit dem Modell soweit erstmal ganz zufrieden.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-mixed-8
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Visuelle Überprüfung des Modells mit dem Residual und QQ-Plot."
#| fig-subcap: 
#|   - "Residualplot"
#|   - "QQ-Plot"
#| layout-nrow: 1
#| column: page

augment(lmer_1_fit) %>% 
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  scale_color_okabeito()

ggplot(tibble(.resid = resid(lmer_1_fit)), aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  theme_bw()
```

Wir haben noch eine Variable in unseren Daten ignoriert. Wir haben uns bis jetzt nicht die Variabl `site` angeschaut. Auf jedem Berg haben wir die Drachen noch auf verschiedenen Flanken des Berges `site` befragt. Das heißt, wir haben die Variable `site`, die in der Variable `mountain_site` genestet ist. Wir schreiben daher ein neues Modell und nutzen die Schreibweise `(1|mountain_range/site)` um zu beschreiben, dass `site` immer zusamen in einem Berg vorkommt. Schaue dir dazu nochmal die Abbidlung ganz zu Beginn dieses Kapitels an um die Zusammenhänge nochmal visualisiert zu bekommen.

```{r}
#| message: false
#| warning: false

lmer_2_fit <- lmer(test_score ~ body_length_cat + (1|mountain_range/site), data = dragons_tbl) 
lmer_2_fit %>% model_parameters()
```

Das Modell hat nun einen weiteren zufälligen Effekt. Es werden jetzt auch nochmal für jeden Berg die Flankeneffekte mit berücksichtigt. Hat das überhaupt einen Einfluss auf das Modell? Schauen wir uns einmal die Modellgüte mit der Funktion `model_performance()` an.

```{r}
#| message: false
#| warning: false
#| column: page

lmer_2_fit %>% model_performance()
```

Wir sehen, dass sich die erklärte varianz leicht erhöht hat. Die $R^2_{random}$ liegt jetzt bei $0.623$ also fast 62%. Etwas besser als vorher, aber auch nicht unbedingt sehr viel mehr.

Wie können wir nun unsere vier Modelle miteinander vergleichen? Wir haben ja folgende Modelle vorliegen:

-   Das simple lineare Modell `lm_simple_fit` mit `test_score ~ body_length_cat`.
-   Das multiple lineare Modell `lm_mountain_fit` mit `test_score ~ body_length_cat + mountain_range`.
-   Das gemischte lineare Modell `lmer_1_fit` mit `test_score ~ body_length_cat + (1|mountin_range)`.
-   Das genestete gemischte lineare Modell `lmer_2_fit` mit `test_score ~ body_length_cat + (1|mountain_range/site)`.

Um die Modelle miteinander zu vergleichen können wir die Funktion `compare_performance()` nutzen. Wir erhalten mit der Option `rank = TRUE` auch eine Sortierung der Modelle wieder. Das beste Modell steht dann ganz oben.

```{r}
#| message: false
#| warning: false

compare_performance(lm_simple_fit, lm_mountain_fit, lmer_1_fit, lmer_2_fit, rank = TRUE)
```

In diesem Beispiel wäre sogar eine multiple lineare Regression das beste Modell. Wir würden also auch mit zwei festen Effekten die Variabilität der Berge richtig mdellieren. Der Effekt der Flanken auf den Testscore scheint ziemlich klein zu sein, so dass wir auch auf die Variable `site` verzichten können.

Was machen wir jetzt noch zum Schluß? Wir machen noch einen paarweisen Vergleich über alle Level der Vaeiable `body_length_cat`. Ich will hier nochmal zeigen, wie du einen multiplen Vergleich mit einem gemischten Modell in R rechnen kannst. Wir nutzen hier dann das R Paket `emmeans` um das *compact letter display* nutzen zu können.

Als erstes nutzen wir die Funktion `emmeans` um die multiplen Vergleich über alle Level des Faktors `body_length_cat` zurechnen.

```{r}
res_lmer <- lmer_2_fit %>% 
  emmeans(~ body_length_cat) 
```

Im Weiteren nutzen wir jetzt das Objekt `res_lmer` um die Vergleiche zu rechnen und zu asjustieren. Wir nutzen die Bonferroni Methode für die Adjustierung der $p$-Werte.

```{r}
res_lmer %>% 
  contrast(method = "pairwise", adjust = "bonferroni") 
```

Wenn wir an dem *compact letter display* interessiert sind, dann müsen wir die Funktion `cld()` nutzen. Was wir brauchen, hängt dann immer davon ab, was wir zeigen wollen und was die Fragestellung ist.

```{r}
res_lmer_cld <- res_lmer %>% 
  cld(adjust = "bonferroni", Letters = letters) %>% 
  tidy() %>% 
  select(body_length_cat, estimate, conf.low, conf.high, .group) %>% 
  mutate(across(where(is.numeric), round, 2))

res_lmer_cld 
```

An dem *compact letter display* sehen wir schon, dass es keinen Unterschied zwischen den Gruppen bzw. Leveln des Faktors `body_length_cat` gibt. Wir sehen bei allen Leveln ein `a`. Wir haben keine signifikante Unterschiede.

In @fig-cld-lmer siehst du nochmal die Daten zusammen mit dem *compact letter display* dargestellt.

```{r}
#| message: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Scatterplot der Körperlängen zusammen mit den 95% Konfidenzintervall und dem *compact letter display*.
#| label: fig-cld-lmer

ggplot() +
  theme_bw() +
  geom_point(data = dragons_tbl, aes(x = body_length_cat, y = test_score)) +
  geom_text(data = res_lmer_cld, 
            aes(x = body_length_cat , y = estimate, label = .group),
            position = position_nudge(x = 0.2), color = "red") +
  geom_errorbar(data = res_lmer_cld,
                aes(ymin = conf.low, ymax = conf.high, x = body_length_cat),
                color = "red", width = 0.1,
                position = position_nudge(x = 0.1)) +
  geom_point(data = res_lmer_cld, 
             aes(x = body_length_cat , y = estimate),
             position = position_nudge(x = 0.1), color = "red") +
  scale_color_okabeito() +
  labs(x = "Körperlänge in Kategorien", y = "Testscore", 
       caption = "Schwarze Punkte stellen Rohdaten dar.
       Rote Punkte und Fehlerbalken stellen bereinigte Mittelwerte mit 95% Konfidenzgrenzen pro Behandlung dar.
       Mittelwerte, mit einem gemeinsamen Buchstaben, sind nicht signifikant unterschiedlich.")

```

Manchmal wollen wir auch die 95% Konfidenzintervalle anzeigen, dann müssen wir wiederum die Funktion `contrast()` nutzen. Wir lassen uns auch hier die adjustoerten $p$-Werte wiedergeben. Wir nutzen dann das Objekt `res_lmer_tbl` um die 95% Konfidenzintervalle zu plotten.

```{r}
res_lmer_tbl <- res_lmer %>% 
  contrast(method = "pairwise") %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(p.value = pvalue(adj.p.value),
         across(where(is.numeric), round, 2)) %>% 
  select(contrast, estimate, p.value,
         conf.low, conf.high) 

res_lmer_tbl
```

In @fig-emmeans-lmer-ci sehen wir die 95% Konfidenzintervalle für alle paarweisen Vergleiche der Körperlängen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: Abbildung der 95% Konfidenzintervallefür alle paarweisen Vergleiche der Körperlängen.
#| label: fig-emmeans-lmer-ci

ggplot(res_lmer_tbl, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +
  geom_hline(yintercept=0, linetype="11", colour="grey60") +
  geom_errorbar(width=0.1) + 
  geom_point() +
  coord_flip() +
  theme_bw()  +
  labs(x = "Vergleich", y = "Mittelwertsunterschied des Gewichtes [kg/ha]",
       caption = "Schwarze Punkte stellen die bereinigten Mittelwertsunterschiede mit 95% Konfidenzgrenzen dar.
       Enthält ein 95% Konfidenzintervalle die 0 ist es nicht signifikant unterschiedlich.")
```

## Nested

https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified

https://www.statology.org/nested-anova-in-r/
