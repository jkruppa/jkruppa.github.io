# Statistisches Testen

```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

Das statistische Testen - eine Geschichte voller Missverständnisse. Wir wollen uns in diesem Kapitel mit den Grundlagen des frequentistischen Hypothesentestens beschäftigen.

[Wir schreiben $\boldsymbol{Pr}$ und meinen damit eine Wahrscheinlichkeit (eng. *probability*). Häufig wird auch nur das $P$ verwendet, aber dann kommen wir wieder mit anderen Konzepten in die Quere.]{.aside}

Der p-Wert oder $Pr(T|H_0)$ ist eine Wahrscheinlichkeit. Eine Wahrscheinlichkeit kann die Zahlen von 0 bis 1 annehmen. Dabei sind die Grenzen einfach zu definieren. Eine Wahrscheinlichkeit von $Pr(A) = 0$ bedeutet, dass das Ereignis A nicht auftritt; eine Wahrscheinlichkeit von $Pr(A) = 1$ bedeutet, dass das Ereignis A eintritt. Der Zahlenraum dazwischen stellt jeden von uns schon vor große Herausforderungen. Der Unterschied zwischen 40% und 60% für den Eintritt des Ereignisses A sind nicht so klar zu definieren, wie du auf den ersten Blick meinen magst.

Ein frequentistischer Hypothesentest beantwortet die Frage, mit welcher Wahrscheinlichkeit $Pr$ die Daten $D$ aus dem Experiment zu beobachten wären, wenn es keinen Effekt gäbe ($H_0$ ist wahr).

**Wahrscheinlichkeit - Tea drinking Lady ergänzen**

Im Englischen gibt es die Begrifflichkeiten einer *Likelihood* und einer *Probability* in der Statistik. Meist wird beides ins Deutsche ungenau mit Wahrscheinlichkeit übersetzt oder wir nutzen einfach *Likelihood*. Was aber auch nicht so recht weiterhilft. Es handelt sich hierbei aber um zwei unterschiedliche Konzepte. Deshalb Übersetzen wir *Likelihood* mit Plausibilität und *Probability* mit Wahrscheinlichkeit.

[**Likelihood** heißt Plausibilität und **Probability** heißt Wahrscheinlichkeit.]{.aside}

-   **Zum Lernen und Verstehen** des statistischen Testen nutzen wir das Konzept der Teststatistik $T$ (siehe @sec-teststatistik)
-   **Zur Anwendung** nutzen wir das Konzept des p-Wertes $Pr(T|H_0)$ (siehe @sec-pwert) und das Konzept der 95% Konfidenzintervalle (siehe @sec-ki)

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Abhängig von der Lernstufe - daher welche [Veranstaltung](#sec-vorlesungen-hs) du gerade bei mir besuchst - kommt nicht *alles* dran in der Klausur. Bitte gleiche die Inhalte, die ich in der aktuellen Vorlesung unterrichte, mit dem Material hier ab. Als Faustregel gilt, je höher die Lernstufe desto mehr musst du von dem statistischen Testen Wissen und Verstehen.
:::

## Fischer vs. Neyman-Pearson

@wasserstein2019moving

[The American Statistician, Volume 73, Issue sup1 (2019)](https://www.tandfonline.com/toc/utas20/73/sup1)

## Die Hypothesen

Wir können auf allen Daten einen statistischen Test rechnen und erhalten statistische Maßzahlen wie eine Teststatistik oder einen p-Wert. Nur leider können wir mit diesen statistischen Maßzahlen nicht viel anfangen ohne die Hypothesen zu kennen. Jeder statistische Test testet eine Nullhypothese. Ob diese Hypothese dem Anwender nun bekannt ist oder nicht, ein statistischer Test testet eine Nullhypothese. Daher müssen wir uns immer klar sein, was die entsprechende Nullhypothese zu unserer Fragestellung ist. Wenn du hier stockst, ist das ganz normal. Eine Fragestellung mit einer statistischen Hypothese zu verbinden ist nicht immer so einfach gemacht. Im [Anhang @sec-beispiel-auswertung] findest du verschiedene Beispiele zu Auswertungen von Datenbeispielen.

::: callout-important
## Die Nullhypothese $H_0$ und die Alternativehypothese $H_A$

Die Nullhypothese $H_0$ nennen wir auch die Null oder Gleichheitshypothese. Die Nullhypothese sagt aus, dass zwei Gruppen gleich sind oder aber kein Effekt zu beobachten ist.

$$
H_0: \bar{y}_{A} = \bar{y}_{B}
$$

Die Alternativehypothese $H_A$ oder $H_1$ auch Alternative genannt nennen wir auch Unterschiedshypothese. Die Alternativehypothese besagt, dass ein Unterschied vorliegt oder aber ein Effekt vorhanden ist.

$$
H_A: \bar{y}_{A} \neq \bar{y}_{B}
$$
:::

Als Veranschaulichung nehmen wir das Beispiel aus @sec-example-2. Wir formulieren als erstes die Fragestellung. Eine Fragestellung endet mit einem Fragezeichen.

*Liegt ein Unterschied zwischen den Sprungweiten von Katzen und Hundeflöhen vor?*

Wir können die Frage auch anders formulieren.

*Springen Hunde und Katzenflöhe unterschiedlich weit?*

Wichtig ist, dass wir eine primäre Fragestellung formulieren. Wir können auch mehrere Fargen an einen Datensatz haben. Das ist auch vollkommen normal. Nur hat *jede* Fragestellung ein eigenes Hypothesenpaar. Wir bleiben aber bei dem simplen Beispiel.

Wie sieht nun die statistische Hypothese in diesem Beispiel aus? Wir wollen uns die Sprungweite in \[cm\] anschauen. In diesem Fall wollen wir die *mittlere* Sprungweite der Hundeflöhe $\bar{y}_{dog}$ mit der *mittleren* Sprungweite der Katzenflöhe $\bar{y}_{cat}$ vergleichen. Es ergibt sich folgendes Hypothesenpaar.

```{=tex}
\begin{align*} 
H_0: \bar{y}_{dog} &= \bar{y}_{cat} \\  
H_A: \bar{y}_{dog} &\neq \bar{y}_{cat} \\   
\end{align*}
```
[Das **Falisifkationsprinzip** - wir können nur Ablehnen - kommt hier zusammen mit der **frequentistischen Statistik** in der wir nur eine Wahrscheinlichkeitsaussage über das Auftreten der Daten $D$ - unter der Annahme $H_0$ gilt - treffen können.]{.aside}

Es ist wichtig sich in Erinnerung zu rufen, dass wir nur und ausschließlich Aussagen über die Nullhypothese treffen werden. Das *frequentistische* Hypothesentesten kann nichts anders. Wir kriegen keine Aussage über die Alternativhypothese sondern nur eine Abschätzung der Wahrscheinlichkeit des Auftretens der Daten im durchgeführten Experiment, wenn die Nullhypothese wahr wäre.

## Die Testentscheidung...

In den folgenden Kapiteln werden wir verschiedene statistische Tests kennenlernen. Alle statistischen Tests haben gemein, dass ein Test eine Teststatistik $T_{calc}$ berechnet. Darüber hinaus liefert jeder Test auch einen p-Wert (eng. *p-value*). Manche statistischen Test geben auch ein 95% Konfidenzintervall wieder. Eine Testentscheidung gegen die Nullhypothese $H_0$ kann mit jedem der drei statistischen Maßzahlen durchgeführt werden. Die Regel für die Entscheidung, ob die Nullhypothese $H_0$ abgelehnt werden kann, ist nur jeweils anders. In @tbl-comp-t-p-ki sind die Entscheidungsregeln einmal zusammengefasst.

::: column-page
|                |        **Teststatistik**         |              **p-Wert**              |             **95% Konfidenzintervall**              |
|:--------------:|:--------------------------------:|:------------------------------------:|:---------------------------------------------------:|
|                |     $\boldsymbol{T_{calc}}$      | $\boldsymbol{Pr(\geq T_{calc}|H_0)}$ |            $\boldsymbol{KI_{1-\alpha}}$             |
| H$_0$ ablehnen | $T_{calc} \geq T_{\alpha = 5\%}$ | $Pr(\geq T_{calc}| H_0) \leq \alpha$ | $\Delta_{A-B}$: enthält [*nicht*]{.underline} **0** |
| H$_0$ ablehnen |                                  |                                      | $\Delta_{A/B}$: enthält [*nicht*]{.underline} **1** |

: Zusammenfassung der statistischen Testentscheidung unter der Nutzung der Teststatistik, dem p-Wert und dem 95% Konfidenzintervall. Die Entscheidung nach der Teststatistik ist veraltet und dient nur dem konzeptionellen Verständnisses. In der Forschung angewandt wird der p-Wert und das 95% Konfidenzintervall. Im Fall des 95% Konfidenzintervalls müssen wir noch unterschieden, ob wir einen Mittelwertsunterschied $\Delta_{A-B}$ oder aber einen Anteilsunterschied $\Delta_{A/B}$ betrachten. {#tbl-comp-t-p-ki}
:::

Wir wollen in den folgenden Abschnitten die jeweiligen Entscheidungsregeln eines statistisches Tests einmal durchgehen.

-   Die Testentscheidung gegen die Nullhypothese anhand der Teststatistik in @sec-teststatistik
-   Die Testentscheidung gegen die Nullhypothese anhand dem p-Wert in @sec-pwert
-   Die Testentscheidung gegen die Nullhypothese anhand des 95% Konfidenzintervall in @sec-ki

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Streng genommen gilt die Regel $T_{calc} \geq T_{\alpha = 5\%}$ nur für eine Auswahl an statistischen Tests siehe dazu auch @sec-teststatistik. Bei manchen statistischen Tests ist die Entscheidung gedreht. Hier lassen wir das aber mal so stehen...
:::

### ... anhand der Teststatistik {#sec-teststatistik}

Wir wollen uns dem frequentistischen Hypothesentesten über die Idee der Teststatistik annähern. Im folgenden sehen wir die Formel für den t-Test. Den t-Test werden wir im @sec-ttest uns nochmal detaillierter anschauen. Hier nutzen wir die vereinfachte Formel um das Konzept zu verstehen.

$$
T_{calc}=\cfrac{\bar{y}_A-\bar{y}_B}{s_{p} \cdot \sqrt{2/n_g}}
$$

mit

-   $\bar{y}_A$ dem Mittelwert für die Gruppe A.
-   $\bar{y}_B$ dem Mittelwert für die Gruppe B.
-   $s_{p}$ der gepoolten Standardabweichung mit $s_p = \tfrac{s_A + s_B}{2}$.
-   $n_g$ der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.

Wir benötigen also zwei Mittelwerte $\bar{y}_A$ und $\bar{y}_B$ und deren gepoolte Standardabweichung $s_p$ sowie die Anzahl der Beobachtungen je Gruppe $n_g$. Wenden wir die Formel des t-Tests einmal auf den folgenden Beispieldatensatz an. In @tbl-dog-cat-small-delta ist eine Datenbeispiel gegeben.

```{r}
#| echo: false
#| label: tbl-dog-cat-small
#| tbl-cap: Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.
data_tbl <- tibble(animal = gl(2, 4, labels = c("cat", "dog")),
                   jump_length = c(8.5, 9.9, 8.9, 9.4, 8.0, 7.2, 8.8, 7.5)) 

data_tbl %>% 
  kable(align = "c", "pipe")

mean_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean_animal = round(mean(jump_length), 1),
            sd_animal = round(sd(jump_length), 1))

mean_cat <- mean_tbl$mean_animal[1]
mean_dog <- mean_tbl$mean_animal[2]
sd_cat <- mean_tbl$sd_animal[1]
sd_dog <- mean_tbl$sd_animal[2]
sd_p <- (sd_cat + sd_dog)/2
t_calc <- round((mean_cat - mean_dog)/((sd_cat + sd_dog)/2 * sqrt(2/4)), 2)
t_k <- round(qt(0.025, 6, lower.tail=FALSE), 2)

```

Wir berechnen nun die Mittelwerte und die Standardabweichungen aus der obigen Datentabelle. Die Werte setzen wir dann in die Formel ein.

$$
T_{calc}=\cfrac{`r mean_cat` - `r mean_dog`}{\cfrac{(`r sd_cat` + `r sd_dog`)}{2} \cdot \sqrt{2/4}} = `r t_calc`
$$

mit

-   $\bar{y}_{cat} = `r mean_cat`$ dem Mittelwert für die Gruppe *cat*.
-   $\bar{y}_{dog} = `r mean_dog`$ dem Mittelwert für die Gruppe *dog*.
-   $s_p = `r sd_p`$ der gepoolten Standardabweichung mit $s_p = \tfrac{`r sd_cat` + `r sd_dog`}{2}$.
-   $n_g = 4$ der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.

Wir haben nun die Teststatistik $T_{calc} = `r t_calc`$ berechnet. In der ganzen Rechnererei verliert man manchmal den Überblick. Erinnern wir uns, was wir eigentlich wollten. Die Frage war, ob sich die mittleren Sprungweiten der Hunde- und Katzenflöhe unterschieden. Wenn die $H_0$ wahr wäre, dann wäre der Unterschied $\Delta$ der beiden Mittelwerte der Hunde- und Katzenflöhe gleich null. Oder nochmal in der Analogie der t-Test Formel, dann wäre im Zähler $\Delta = \bar{y}_{cat} - \bar{y}_{dog} = 0$. Wenn die Mittelwerte der Sprungweite \[cm\] der Hunde- und Katzenflöhe gleich wäre, dann wäre die berechnete Teststatistik $T_{calc} = 0$, da im Zähler Null stehen würde. Die Differenz von zwei gleichen Zahlen ist Null.

Je größer die berechnete Teststatistik $T_{calc}$ wird, desto unwahrscheinlicher ist es, dass die beiden Mittelwerte per Zufall gleich sind. Wie groß muss nun die berechnete Teststatistik $T_{calc}$ werden damit wir die Nullhypothese ablehnen können?

::: column-page
![Die t-Verteilung aller möglichen $T_{calc}$ wenn die Nullhypothese wahr ist. Der Mittelwert der t-Verteilun ist $T=0$. Wenn wir keinen Effekt erwarten würden dann wären die beiden Mittelwerte $\bar{y}_1$ und $\bar{y}_2$ gleich groß. Die Differenz wäre 0. Je größer der $T_{calc}$ wird desto weniger können wir davon ausgehen, dass die beiden Mittelwerte gleich sind. Liegt der $T_{calc}$ über dem kritischen Wert von $T_{\alpha = 5\%}$ dann wir die Nullhypothese abgelehnt.](images/t-verteilung_01.png){#fig-teststatistik-01 fig-align="center"}
:::

In @fig-teststatistik-01 ist die Verteilung aller möglichen $T_{calc}$ Werte unter der Annahme, dass die Nullhypothese wahr ist, dargestellt. Wir sehen, dass die t-Verteilung am höchsten bei $T_{calc} = 0$ ist und niedrigeren Werte mit steigenden t-Werten annimmt. Wenn $T = 0$ dann sind auch die Mittelwerte gleich. Je größer unsere berechnete Teststatistik $T_{calc}$ wird, desto unwahrscheinlicher ist es, dass die Nullhypothese gilt. Die t-Verteilug ist so gebaut, dass die Fläche $A$ unter der Kurve gleich $A=1$ ist. Wir können nun den kritschen Wert $T_{\alpha = 5\%}$ berechnen an dem rechts von dem Wert eine Fläche von 0.05 oder 5% liegt. Sommit liegt dann links von dem kritischen Wert die Fläche von 0.95 oder 95%. Den kritischen Wert $T_{\alpha = 5\%}$ können wir statistischen Tabellen entnehmen. Oder wir berechnen den kritischen Wert direkt in R mit $T_{\alpha = 5\%} = `r t_k`$.

Kommen wir zurück zu unserem Beispiel. Wir haben in unserem Datenbeispiel für den Vergleich von der Sprungweite in \[cm\] von Hunde- und Katzenflöhen eine Teststatistik von $T_{calc} = `r t_calc`$ berechnet. Der kritische Wert um die Nullhypothese abzulehnen liegt bei $T_{\alpha = 5\%} = `r t_k`$. Wenn $T_{calc} \geq T_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt. In unserem Fall ist $`r t_calc` \geq `r t_k`$. Wir können die Nullhypothese ablehnen. Es gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

*Es gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen.* Die Aussage ist **statistisch** falsch. Wir können im frequentistischen Hypothesentesten keine Aussage über die $H_A$ treffen. Im Sinne der Anwendbarkeit soll es hier so stehen bleiben.
:::

::: callout-important
## Entscheidung mit der berechneten Teststatistik

Bei der Entscheidung mit der Teststatistik müssen wir zwei Fälle unterschieden.

(1) Bei einem t-Test und einem $\mathcal{X}^2$-Test gilt, wenn $T_{calc} \geq T_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt.

(2) Bei einem Wilcoxon-Mann-Whitney-Test gilt, wenn $T_{calc} < T_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt.

**Achtung --** Wir nutzen die Entscheidung mit der Teststatistik *nur und ausschließlich* in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik *keine* Verwendung mehr.
:::

### ... anhand dem p-Wert {#sec-pwert}

$$
Pr(T|H_0)
$$

$$
Pr(T_{calc}|H_0)
$$

$$
Pr\left(\left.T_{calc}=\cfrac{\bar{y}_1-\bar{y}_2}{s_{y_1,\,y_2} \cdot \sqrt{2/n_g}}\right| H_0{:}\; \bar{y}_1-\bar{y}_2=0\right)
$$

$$
Pr\left(\left.T_{calc}\right| \Delta_{y_1,\,y_2}=0\right)
$$

$$
\text{Pr}(D | H_0)
$$

::: column-page
![kjk](images/t-verteilung_03.png){#fig-teststatistik-03 fig-align="center"}
:::

::: column-page
![kjk](images/t-verteilung_04.png){#fig-teststatistik-04 fig-align="center"}
:::

::: callout-note
## Der $\alpha$-Fehler und $\beta$-Fehler als Rauchmelderanalogie

Häufig verwirrt die etwas theoretische Herangehensweise an den $\alpha$-Fehler und $\beta$-Fehler. Wir versuchen hier nochmal die Analogie eines Rauchmelders und dem Feuer im Haus.

![Andere Art der Darstellung des $\alpha$-Fehlers als *Alarm without fire* und dem $\beta$-Fehler als *Fire without alarm*. Je nachdem wie empfindlich wir den Alarm (den statistischen Test) über das $\alpha$ einstellen, desto mehr Alarm bekommen wir ohne das ein Effekt vorhanden wäre.](images/t-verteilung_05.png){#fig-teststatistik-05 fig-align="center" width="80%"}

-   $\boldsymbol{\alpha}$**-Fehler**: Alarm without fire. Der statistische Test schlägt Alarm und wir sollen die $H_0$ ablehnen, obwohl die $H_0$ in Wahrheit gilt und kein Effekt vorhanden ist.
-   $\boldsymbol{\beta}$**-Fehler**: Fire without alarm. Der statistische Test schlägt *nicht* an und wir sollen die $H_0$ beibehalten, obwohl die $H_0$ in Wahrheit *nicht* gilt und *ein* Effekt vorhanden ist.
:::

Wir wollen einmal den Zusammenhang zwischen $\bar{y}_A$, $\bar{y}_B$, $s$ und $n$ uns näher anschauen. Wir können die Formel des t-Tests wie folgt vereinfachen.

$$
T_{calc}=\cfrac{\bar{y}_A-\bar{y}_B}{s_{p} \cdot \sqrt{2/n_g}}
$$

Für die Betrachtung der Zusammenhänge wandeln wir $\sqrt{2/n_g}$ in $1/n$ um. Dadurch wandert die Fallzahl $n$ in den Zähler. Die Standardabweichung verallgemeinern wir zu $s$ und damit allgemein zur Streuung. Abschließend betrachten wir $\bar{y}_A-\bar{y}_B$ als den Effekt $\Delta$. Es ergibt sich folgende vereinfachte Formel.

$$
T_{calc} = \cfrac{\Delta \cdot n}{s}
$$

Wir können uns nun die Frage stellen, wie ändert sich die Teststatistik $T_{calc}$ in Abhängigkeit vom Effekt $\Delta$, der Fallzahl $n$ und der Streuung $s$ in den Daten. Die @tbl-t-und-p zeigt die Zusammenhänge auf. Die Aussagen in der Tabelle lassen sich generalisieren. So bedeutet eine steigende Fallzahl meist mehr signifikante Ergebnisse. Eine stiegende Streuung reduziert die Signifikanz eines Vergleichs. Ein Ansteigen des Effektes führt zu mehr signifikanten Ergebnissen.

|                   | $\boldsymbol{T_{calc}}$ | $\boldsymbol{Pr(\geq T_{calc}|H_0)}$ |                     | $\boldsymbol{T_{calc}}$ | $\boldsymbol{Pr(\geq T_{calc}|H_0)}$ |
|:-----------------:|:-----------------------:|:------------------------------------:|:-------------------:|:-----------------------:|:------------------------------------:|
| $\Delta \uparrow$ |         steigt          |                sinkt                 | $\Delta \downarrow$ |          sinkt          |                steigt                |
|   $s \uparrow$    |          sinkt          |                steigt                |   $s \downarrow$    |         steigt          |                sinkt                 |
|   $n \uparrow$    |         steigt          |                sinkt                 |   $n \downarrow$    |          sinkt          |                steigt                |

: Zusammenhang von der Teststatistik $T_{calc}$ und dem p-Wert Pr(\geq T\_{calc}\|H_0) in Abhängigkeit vom Effekt $\Delta$, der Fallzahl $n$ und der Streuung $s$. {#tbl-t-und-p}

::: callout-important
## Entscheidung mit dem p-Wert

Wenn der p-Wert $\leq \alpha$ dann wird die Nullhypothese (H$_0$) abgelehnt. Das Signifikanzniveau $\alpha$ wird als Kulturkonstante auf 5% oder 0.05 gesetzt. Die Nullhypothese (H$_0$) kann auch Gleichheitshypothese gesehen werden. Wenn die H$_0$ gilt, liegt kein Unterschied zwischen z.B. den Behandlungen vor.
:::

### ... anhand des 95% Konfidenzintervall {#sec-ki}

![kj](images/ci-01.png){#fig-ki fig-align="center" width="100%"}

@fig-ki

-   $(\bar{y}_{1}-\bar{y}_{2})$ ist der Effekt. In diesem Fall der Mittelwertsunterschied. Wir finden den Effekt als Punkt in der Mitte des Intervals.
-   $T_{\alpha = 5\%} \cdot \frac {s}{\sqrt{n}}$ ist ein fester Wert, der die Arme des Intervals bildet. Wir vereinfachen die Formel mit $s_p$ für die gepoolte Standardabweichung und $n_g$ für die Fallzahl der beiden Gruppen. Wir nehmen an das beide Gruppen die gleiche Fallzahl $n_1 = n_2$ haben.

![kjasdsa](images/ci-02.png){#fig-relevanz fig-align="center"}

@fig-relevanz

(a) Nicht signifikant und nicht relevant
(b) Signifikant und nicht relevant
(c) Signifikant und relevant
(d) Signifikant und nicht relevant
(e) bla

$$
\left[
(\bar{y}_{dog}-\bar{y}_{cat}) - 
T_{\left( 1-\tfrac{\alpha}{2} \right)} \cdot \frac {s_p}{\sqrt{n_g}}; \;
(\bar{y}_{dog}-\bar{y}_{cat}) + 
T_{\left( 1-\tfrac{\alpha}{2} \right)} \cdot \frac {s_p}{\sqrt{n_g}};
\right]
$$

::: callout-important
## Entscheidung mit dem 95% Konfidenzintervall

Bei der Entscheidung mit dem 95% Konfidenzinterval müssen wir zwei Fälle unterscheiden.

(1) Entweder schauen wir uns einen Mittelwertsunterschied ($\Delta_{A-B}$) an, dann können wir die Nullhypothese (H$_0$) *nicht* ablehnen, wenn die 0 im 95% Konfidenzinterval ist.

(2) Oder wir schauen uns einen Anteilsunterschied ($\Delta_{A/B}$) an, dann können wir die Nullhypothese (H$_0$) *nicht* ablehnen, wenn die 1 im 95% Konfidenzinterval ist.
:::

### Einseitig oder zweiseitig?

::: column-page
![kjk](images/t-verteilung_02.png){#fig-teststatistik-02 fig-align="center"}
:::

::: callout-note
## Einseitig oder zweiseitig im Spiegel der Regulierungsbehörden

[Allgemeine Methoden des IQWiG](https://www.iqwig.de/ueber-uns/methoden/methodenpapier/)

*Zur besseren Vergleichbarkeit mit 2-seitigen statistischen Verfahren wird in einigen Guidelines für klinische Studien eine Halbierung des üblichen Signifikanzniveaus von 5 % auf 2,5 % gefordert.* -- [Allgemeine Methoden Version 6.1 vom 24.01.2022, p. 180](https://www.iqwig.de/methoden/allgemeine-methoden-v6-1.pdf)
:::

## Der Effektschätzer

[Doing Meta-Analysis with R: A Hands-On Guide](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html)

[Der Effektschätzer wird auch gerne Theta $\boldsymbol{\theta}$ genannt. Da wir dann aber später noch mit anderen Konzepten in die Quere kommen, nutze ich das etwas intuitivere Delta $\boldsymbol{\Delta}$.]{.aside}

### Unterschied zweier Mittelwerte

Wir berechnen zwei Mittelwerte $\bar{y}_1$ und $\bar{y}_2$. Wenn wir wissen wollen wie groß der Effekt zwischen den beiden Mittelwerten ist, dann bilden wir die Differenz. Wir berechnen das $\Delta$ von $y_1$ und $y_2$ indem wir die Diffenz bilden.

$$
\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2
$$

Wenn es keinen Unterschied zwischen den beiden Mittelwerten $\bar{y}_1$ und $\bar{y}_2$ gibt, dann ist die Differenz $\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2$ gleich 0.

$$
H_0: \Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2 = 0
$$

In @tbl-dog-cat-small-delta ist eine Datenbeispiel gegeben.

```{r}
#| echo: false
#| label: tbl-dog-cat-small-delta
#| tbl-cap: Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.
data_tbl <- tibble(animal = gl(2, 4, labels = c("cat", "dog")),
                   jump_length = c(8.0, 7.9, 8.3, 9.1, 8.0, 7.8, 9.2, 7.7)) 

data_tbl %>% 
  kable(align = "c", "pipe")

mean_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean_animal = round(mean(jump_length), 1))

mean_cat <- mean_tbl$mean_animal[1]
mean_dog <- mean_tbl$mean_animal[2]

```

Nehmen wir an, wir berechnen für die Sprungweite \[cm\] der Hundeflöhe einen Mittelwert von $\bar{y}_{dog} = `r mean_dog`$ und für die Sprungweite \[cm\] der Katzenflöhe einen Mittelwert von $\bar{y}_{cat} =`r mean_cat`$. Wie große ist nun der Effekt? Oder anders gesprochen, welchen Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu sein? Was ist also der Effekt von `animal`? Wir rechnen $\bar{y}_{dog} - \bar{y}_{cat} = 8.2 - 8.3 = -0.1$. Zum einen wissen wir jetzt "die Richtung". Da wir ein Minus vor dem Mittelwertsunterschied haben, müssen die Katzenflöhe weiter springen als die Hundeflöhe, nämlich 0,1cm. Dennoch ist der Effekt sehr klein.

### Unterschied zweier Anteile

Neben den Unterschied zweier Mittelwerte ist auch häufig das Interesse an dem Unterschied zwischen zwei Wahrscheinlichkeiten oder auch Anteilen. Ebenso kann die Chance berechnet werden. Hier tritt häufig Verwirrung auf, daher hier zuerst ein Beispiel.

|            |       |                   |                   |
|:----------:|:-----:|:-----------------:|:-----------------:|
|            |       |   **Infected**    |                   |
|            |       |     *Yes (1)*     |     *No (0)*      |
| **Animal** | *Dog* | $23_{\;\Large a}$ | $10_{\;\Large b}$ |
|            | *Cat* | $18_{\;\Large c}$ | $14_{\;\Large d}$ |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils. {#tbl-2x2-ratio-delta}

Aus der @tbl-2x2-ratio-delta können wir entnehmen, dass 23 Hunde mit Flöhen infiziert sind und 10 Hunde keine Infektion aufweisen. Bei den Katzen haben wir 18 infizierte und 14 gesunde Tiere beobachtet. Wir können nun zwei Arten von Anteilen berechnen. Das bekanntere ist die Frequenz oder Wahrscheinlichkeit oder Risk Ratio (RR). Das andere ist das Chancenverhältnis oder Odds Ratio (OR). Beide kommen in der Statistik vor und sind unterschiedlich zu interpretieren.

#### Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)

$$
Pr(\mbox{dog}|\mbox{infected}) = \cfrac{a}{a+c} = \cfrac{23}{23+10} \approx 0.67
$$

$$
Pr(\mbox{cat}|\mbox{infected}) = \cfrac{b}{b+d} = \cfrac{18}{18+14} \approx 0.56
$$

$$
\Delta_{y_1/y_2} = RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} =  \cfrac{0.67}{0.56} \approx 1.2 
$$

#### Chancenverhältnis oder Odds Ratio (OR)

$$
Odds(\mbox{dog}|\mbox{infected}) = a:b = 23:10 = \cfrac{23}{10} = 2.3
$$

$$
Odds(\mbox{cat}|\mbox{infected}) = c:d = 18:14 = \cfrac{18}{14} \approx 1.29 
$$

$$
\Delta_{y_1/y_2} = OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = \cfrac{a \cdot d}{b \cdot c} = \cfrac{2.30}{1.29} \approx 1.78
$$

Wann liegt nun kein Effekt bei einem Anteil wie dem RR oder OR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe. Dies gilt sowohl fürdas RR als auch das OR.

$$
H_0: RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} = 1
$$

$$
H_0: OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = 1
$$

::: callout-important
## Stärke eines Effektes

Du musst immer den Effekt, hier den Mittelwertsunterschied, im Kontext der Fragestellung bzw. des Outcomes $y$ bewerten. Der numerische Unterschied von 0,1cm kann in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein Unterschied von 0,1cm sehr viel sein. Oder aber sehr wenig, wenn wir uns das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage, ob ein Unterschied von 6% viel oder wenig ist...
:::

::: callout-tip
## Effektschätzer

Wenn wir uns einen Unterschied eines **Mittelwerts** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn das $\Delta$ zwischen $A$ und $B$ gleich 0 ist. Die Nullhypothese gilt.

$$
\Delta_{A-B} = A - B = 0
$$ Wenn wir uns einen Unterschied eines **Anteils** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn das $\Delta$ zwischen $A$ und $B$ gleich 1 ist. Die Nullhypothese gilt.

$$
\Delta_{A/B} = \cfrac{A}{B} = 1
$$

Dieses Wissen brauchen wir um später die Signifikanzschwelle bei einem 95% Konfidenzintervall richtig zu setzen und interpretieren zu können.
:::

## Referenzen {.unnumbered}
