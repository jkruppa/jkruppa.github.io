[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bio Data Science",
    "section": "",
    "text": "Auf den folgenden Seiten wirst du eine Menge über Statistik oder Data Science lernen. Du musst dafür nicht eine meiner Veranstaltungen besuchen. Gerne kannst du hier und dort einmal schauen, ob etwas für dich dabei ist. Das Skript wird fortlaufend von mir ergänzt. Neben dem Skript gibt es auch noch die erklärenden YouTube Videos. Ich freue mich, dass du Lust hast hier etwas zu lernen… oder aber du musst – da bald eine Klausur ansteht. Wie auch immer – schau dich einfach mal um. Im Anhang findest du auch einen kleinen Leitfaden für das Schreiben einer Abschlussarbeit. Vielleicht hilft dir das ja.\n\n\n\n\n\n\nGesammelte Klausurfragen Bio Data Science\n\n\n\n\n\nDu findest die gesammelten Klausurfragen auf GitHub. Die Klausurfragen zu den einzelnen Vorlesungen in einem Modul werden in den entsprechenden Übungen besprochen. Bitte komme in die Übungen.\n\n\n\n\n\nDu liest hier gerade das Skript für meine Vorlesungen an der Hochschule Osnabrück an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL). Wie immer Leben kannst du auf verschiedene Arten und Weisen den Stoff, den ich vermitteln will, lernen. Daher gibt es noch zwei andere Möglichkeiten. Zum einen Lernen auf YouTube, mit meinen Lernvideos oder du schaust dir das Material auf GitHub an. Auf GitHub habe ich auch Informationen, die du vielleicht brauchen kannst. Ebenso findest du im Kapitel 2 noch andere Literaturempfehlungen.\n\n\n\n\n\n\n\nWenn du möchtest kannst du auf YouTube unter https://www.youtube.com/c/JochenKruppa noch einige Lehrvideos als Ergänzung schauen. In den Videos wiederhole ich Inhalte und du kannst auf Pause drücken um nochmal Programmierschritte nachverfolgen zu können.\n\n\n\n\n\n\n\n\nAlle Materialien von mir findest du immer auf GitHub unter https://github.com/jkruppa/teaching. Selbst wenn du nicht mehr in einem meiner Kurse bist, kannst du so auf die Lehrinhalte immer nochmal zugreifen und die aktuellen Versionen haben. Auf GitHub liegt auch immer eine semesteraktuelle Version der gesammelten Klausurfragen für meine Module.\n\n\n\n\nWie erreichst du mich? Am einfachsten über die gute, alte E-Mail. Bitte bachte, dass gerade kurz vor den Prüfungen ich mehr E-Mails kriege. Leider kann es dann einen Tick dauern.\n\n\n\n\n\nEinfach an j.kruppa@hs-osnabrueck.de schreiben. Du findest hier auch eine kurze Formulierungshilfe. Einfach auf den Ausklapppfeil klicken.\nBitte gib immer in deiner E-Mail dein Modul - was du belegst - mit an. Pro Semester unterrichte ich immer drei sehr ähnlich klingende Module. Daher schau nochmal hier in der Liste, wenn du unsicher bist.\n\n\n\n\n\n\nE-Mailvorlage mit beispielhafter Anrede\n\n\n\n\n\nHallo Herr Kruppa,\n… ich belege gerade Ihr Modul Modulname und hätte eine Bitte/Frage/Anregung…\n… ich benötige Hilfe bei der Planung/Auswertung meiner Bachelorarbeit…\nMit freundlichen Grüßen\nM. Muster"
  },
  {
    "objectID": "organisation.html",
    "href": "organisation.html",
    "title": "1  Organisation",
    "section": "",
    "text": "Den Teil kannst du hier überspringen, wenn es dich nicht so richtig interessiert, was ich alles an Vorlesungen anbiete. Wenn es dir um statistische Inhalte geht, dann gehe einfach weiter in das nächste Kapitel."
  },
  {
    "objectID": "organisation.html#sec-vorlesungen-hs",
    "href": "organisation.html#sec-vorlesungen-hs",
    "title": "1  Organisation",
    "section": "1.1 Vorlesungen an der Hochschule Osnabrück",
    "text": "1.1 Vorlesungen an der Hochschule Osnabrück\nVon mir angebotene Vorlesungen werden an der Hochschule Osnabrück an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) in ILIAS verwaltet. Alle notwendigen Informationen und Materialien sind auf ILIAS unter https://lms.hs-osnabrueck.de/ zu finden. Wenn du in dem Kurs nicht angemeldet bist, dann kontaktiere mich bitte per Mail. Auch die Kommunikation erfolgt von meiner Seite aus über ILIAS.\nAuf ILIAS findest du alle aktuellen Kursinformationen und erhälst auch die Mails, wenn Änderungen im Kursablauf stattfinden.\nWenn du nicht in der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) studierst oder aber in einem Studiengang, der meine Module nicht anbietet, steht es dir natürlich frei, sich in meine Vorlesungen zu setzten. Du findest in Tabelle 1.1 eine Übersicht der angebotenen Module und auch die inhaltliche Ordnung nach Lernstufe. Bitte informiere dich in deinem Studierendensekretariat über die Modalitäten zur Prüfungsteilnahme.\n\n\nTabelle 1.1— Angebotene Statistik Module an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL). Die Stufe gibt das Lernniveau an.\n\n\nStufe\nLandwirtschaft; Angewandte Pflanzenbiologie – Gartenbau, Pflanzentechnologie\nWirtschafts- ingenieurwesen Agrar / Lebensmittel\nBioverfahrenstechnik in Agrar- und Lebensmittelwirtschaft\n\n\n\n\n1\nMathematik und Statistik\nStatistik\nAngewandte Statistik für Bioverfahrenstechnik\n\n\n2\nAngewandte Statistik und Versuchswesen\nAngewandte Statistik und Versuchswesen\n\n\n\n3\nSpezielle Statistik und Versuchswesen\n\n\n\n\n\n\nEine inhaltliche Übersicht findet sich auf dem Google Spreadsheet. Die Planung ist aktuell (Stand Sommer 2022) noch nicht abgeschlossen. Im Zweifel einfach bei mir einmal per Mail anfragen."
  },
  {
    "objectID": "organisation.html#sec-r-tutorium",
    "href": "organisation.html#sec-r-tutorium",
    "title": "1  Organisation",
    "section": "1.2 R Tutorium",
    "text": "1.2 R Tutorium\nIm Rahmen der statistischen Beratung bieten wir auch ein R Tutorium für alle Mitglieder:innen der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) an. Die aktuellen Termine findest du in Tabelle 1.2.\nIm R Tutorium besprechen wir aktuelle Themen der Teilnehmer:innen. Meist sind dies aktuelle Fragen zu den BAchelorarbeiten. Auch wenn du kein dringendes Problem hats, kannst du gerne kommen und dir die Fragestellungen anhören. Bitte beachte folgende Hinweise zu den Terminen.\n\n\n\n\n\n\nHinweise zu dem R Tutorium\n\n\n\nDas R Tutorium findet nicht im Prüfungszeitraum der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) statt.\nDas R Tutorium findet nicht im Februar und März statt.\nDas R Tutorium findet nicht im August und September statt.\n\n\n\n\nTabelle 1.2— Aktuelle Termine des R Tutoriums im Semester\n\n\nTermin\nUhrzeit\nRaum\nAnmerkung\n\n\n\n\nnächste\nTermine\nab\nOktober 2022"
  },
  {
    "objectID": "organisation.html#statistische-beratung",
    "href": "organisation.html#statistische-beratung",
    "title": "1  Organisation",
    "section": "1.3 Statistische Beratung",
    "text": "1.3 Statistische Beratung\nIch biete auch Termine für die statistische Beratung von Abschlussarbeiten sowie Projekten an. Dafür musst du mir einfach nur eine E-Mail schreiben und dann erhälst du einen Termin innerhalb der nächsten zwei Wochen.\nDie Beratung ist grundsätzlich anonym und vertraulich. Wenn du willst kannst du gerne noch dein:e Betreuer:in mitbringen. Das ist aber keine Voraussetzung oder Notwendigkeit."
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "2  Literatur",
    "section": "",
    "text": "Was ist gute Literatur? Immer schwer zu beurteilen. Im folgenden liste ich einige Literaturquellen auf. Zum einen basiert eine Menge von dem R Code auf Wickham (2016) zum Anderen möchtest du dich vielleicht nochmal rechts oder links weiter bilden. Du musst aber nicht um die Klausur bestehen zu können. Siehe es eher als ein Angebot.\nNeben diesem Modul musst du vermutlich noch andere Module belegen. Deshalb hier eine Auswahl Literatur, die dir helfen mag. Zum einen ist die Literatur anders geschrieben und zum anderen sind dort andere Imhalte."
  },
  {
    "objectID": "literature.html#parametrische-statistik",
    "href": "literature.html#parametrische-statistik",
    "title": "2  Literatur",
    "section": "2.1 Parametrische Statistik",
    "text": "2.1 Parametrische Statistik\n\n\n\n\n\nDormann (2013) liefert ein tolles deutsches Buch für die Vertiefung in die Statistik. Insbesondere wenn du wissenschaftlich Arbeiten willst weit über die Bachelorarbeit hinaus. Dormann baut in seinem Buch eine hervorragende Grundlage auf. Das Buch ist an der Hochschule Osnabrück kostenlos über den Link zu erhalten."
  },
  {
    "objectID": "literature.html#r-for-data-science",
    "href": "literature.html#r-for-data-science",
    "title": "2  Literatur",
    "section": "2.2 R for Data Science",
    "text": "2.2 R for Data Science\n\n\n\n\n\nWickham (2016) ist die Grundlage für die R Programmierung. Das Material von Wickahm findet sich kostenlos online unter https://r4ds.had.co.nz/ und https://www.tidyverse.org/. Wir werden uns hauptsächlich mit R wie es Wickham lehrt beschäftigen. Somit ist Wickham unsere Grundlage für R."
  },
  {
    "objectID": "literature.html#practical-statistics-for-data-scientists",
    "href": "literature.html#practical-statistics-for-data-scientists",
    "title": "2  Literatur",
    "section": "2.3 Practical Statistics for Data Scientists",
    "text": "2.3 Practical Statistics for Data Scientists\n\n\n\n\n\nBruce (2020) schreibt ein Buch für den Anwender. Ohne Vorkenntnisse ist das Buch vermutlich etwas schwer zu lesen. Dafür bietet das Buch aber nach einem Statistikkurs sehr gute Anknüpfungspunkte Richtung maschinelles Lernen und somit der Klassifikation. Das Buch ist auch hier in der englischen Version und hier in der deutschen Version zu erhalten. Beide Links benötigen den Zugang über die Hochschule Osnabrück."
  },
  {
    "objectID": "literature.html#data-science-for-agriculture-in-r",
    "href": "literature.html#data-science-for-agriculture-in-r",
    "title": "2  Literatur",
    "section": "2.4 Data Science for Agriculture in R",
    "text": "2.4 Data Science for Agriculture in R\n\n\n\n\n\nSchmidt liefert auf der Webseite https://schmidtpaul.github.io/DSFAIR/index.html eine tolle Sammlung an experimentellen Designs bzw. Versuchsanlagen samt der Auswertung in R. Ohne Vorkenntnisse schwer zu verstehen. Sollte aber nach einem Kurs Statistik dann möglich sein. Gerne hier auch mich fragen, dann können wir gemeinsam das passende Design raussuchen und besprechen."
  },
  {
    "objectID": "literature.html#odds-ends",
    "href": "literature.html#odds-ends",
    "title": "2  Literatur",
    "section": "2.5 Odds & Ends",
    "text": "2.5 Odds & Ends\n\n\n\n\n\nAm Ende dann noch eine Mathebuch von Weisberg zu finden unter https://jonathanweisberg.org/vip/. Eigentlich eher ein Buch über Wahrscheinlichkeiten und wenn ein Buch am Ende stehen muss, dann ist es dieses Buch. Ich finde es sehr spannend zu lesen, aber das ist dann vermutlich special intrest."
  },
  {
    "objectID": "literature.html#referenzen",
    "href": "literature.html#referenzen",
    "title": "2  Literatur",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nBruce, Peter, Andrew Bruce, und Peter Gedeck. 2020. Practical statistics for data scientists: 50+ essential concepts using R and Python. O’Reilly Media.\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer.\n\n\nWickham, Hadley, und Garrett Grolemund. 2016. R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "\n3  Einführung\n",
    "section": "",
    "text": "In diesem Kapitel nenne ich die wichtigsten Lernziele, die nach dem Lesen des Skriptes von dir erreicht worden sein sollten. Je nach besuchten Kurs kann natürlich nicht alles geschafft worden sein. So sehe diese Übersicht als Einführung für das was später kommt. Wenn du die Beispiele hir verstehst, dann hast du eine gute und solide Grundlage in Statistik und Bio Data Science."
  },
  {
    "objectID": "preface.html#ein-wort-der-warnung",
    "href": "preface.html#ein-wort-der-warnung",
    "title": "\n3  Einführung\n",
    "section": "Ein Wort der Warnung…",
    "text": "Ein Wort der Warnung…\nWenn du dieses Bild eines niedergeschlagenen Engels der Statistik siehst…\n\n\n\n\n… dann bedeutet der niedergeschlagene Engel der Statistik:\n\nWir opfern Genauigkeit für Anwendbarkeit. Ja, manchmal ist es eben statstisch nicht richtig was hier steht, aber aus Gründen der Anwendung fahren wir mal über den Engel drüber. Schade.\nWir sind hier Anfänger und Anwender. Später kannst du noch tiefer ins Detail gehen. Hier wollen wir die Grundlagen lernen. Das hat dann einen Preis an Richtigkeit.\nWir wollen fertig werden. Durch geschicktes Manövrieren können wir an einen Punkt kommen, wo kein statistischer Test mehr passt. Das wollen wir nicht. Deshalb zahlen wir hier auch einen Preis. Passt aber.\n\nDeshalb konzentrieren wir uns auf einige wichtige Lernziele, die wir jetzt einmal nacheinander durchgehen."
  },
  {
    "objectID": "preface.html#lernziel-1-eine-explorative-datananalyse-durchführen",
    "href": "preface.html#lernziel-1-eine-explorative-datananalyse-durchführen",
    "title": "\n3  Einführung\n",
    "section": "\n3.1 Lernziel 1: Eine explorative Datananalyse durchführen",
    "text": "3.1 Lernziel 1: Eine explorative Datananalyse durchführen\nGleich zu Beginn R Code zu zeigen und eine entsprechende Abbildung ist vielleicht ungewöhnlich, aber wir wollen zu dieser Abbildung 3.1 hin. In Abbildung 3.1 siehst du einen Boxplot. Und wie wir aus den Daten flea_dog_cat.xlsx einen Boxplot erstellen, das soll uns in den nächsten Kapitel beschäftigen. Dafür müssen wir nämlich eine Menge in dem Codeblock verstehen und dann auch Anwenden können. Und natürlich lernen was eigentlich ein Boxplot ist und was in einem Boxplot eigentlich dargestellt ist.\nData\n\n\n\n\nAbbildung 3.1— Boxplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nHier ist der Codeblock der in R die Abbildung 3.1 erstellt.\n\n## Einlesen von Daten aus Excel\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n## Umformen der <chr> Spalte in einen Factor <fct>\ndata_tbl <- data_tbl %>% \n  mutate(animal = as_factor(animal))\n\n## Auswählen der wichtigen Spalten für den Boxplot\ndata_tbl <- data_tbl %>% \n  select(animal, jump_length) \n\n## Generieren des Boxplots in ggplot()\nggplot(data_tbl, aes(x = animal, y = jump_length, \n                     fill = animal)) +\n  geom_boxplot() +\n  geom_jitter() +\n  labs(x = \"Tierart\", y = \"Sprungweite in [cm]\", \n       fill = \"Tierart\") +\n  scale_x_discrete(labels = c(\"Hund\", \"Katze\")) +\n  theme_bw()\n\nWir müssen nun folgende Dinge lernen um den Codeblock zu verstehen:\n\nWir müssen das Datenbeispiel verstehen. Was sind das eigentlich für Daten, die wir da abbilden? Was sind überhaupt Daten im Sinne der Statistik bzw. für R.\nWir müssen den R Code verstehen. Von einzelnen wichtigen Opertatoren wie -> und %\\>% zu dem den Unterschieden von Worten und Objekten.\nWie kriegen wir Daten aus Excel in R hinein? Wir können die Daten ja nicht einfach in R eintragen sondern haben die Daten ja meist in einer (Excel) Datei wie flea_dog_cat.xlsx.\nWas ist eigentlich ein Boxplot und welche statistsichen Maßzahlen werden hier eigentlich abgebildet?\nWie funktioniert eigentlich die Funktioen ggplot() mit der wir den Boxplot erstellt haben?\n\nAll diese Fragen und weitere Fragen, die sich diesen Fragen anschließen, wollen wir uns in den nächsten Kapitel anschauen. Leider kann ich hier nur linear schreiben. Deshalb musst du eventuell mal ein Kapitel wiederholen oder etwas quer lesen. Du kanst dir ja auch nicht immer alles auf einmal merken."
  },
  {
    "objectID": "preface.html#lernziel-2-rstudio-und-r",
    "href": "preface.html#lernziel-2-rstudio-und-r",
    "title": "\n3  Einführung\n",
    "section": "\n3.2 Lernziel 2: RStudio und R",
    "text": "3.2 Lernziel 2: RStudio und R\nUm Data Science durchführen zu können musst du etwas Programmieren können. Wir programmieren in R und nutzen die Software um Abbildungen zu erstellen und Analysen zu rechnen.\nWir arbeiten in R und nutzen dafür das RStudio. Führe einfach folgende Schritte aus um erst R zu installieren und dann das RStudio.\n\nR installieren unter https://cran.rstudio.com/\n\nRStudio installieren unter https://www.rstudio.com/products/rstudio/download/#download\n\n\nBitte die Reihenfolge beachten. Beide Schritte kannst du dir auch nochmals im Video anschauen oder aber du kommst in das R Tutorium was regelmäßig an der Hochschule Osnabrück von mir angeboten wird. Die Termine findest du im Kapitel 1.2.\n\n\n\n\n\n\nWas ist eigentlich RStudio und woher kriege ich das?\n\n\n\nDu findest auf YouTube Einführung in R - Teil 01 - Installation von RStudio und R als Video. Ich gehe in dem Video einmal alle wichtigen Schritte durch und so kannst du dir Rstudio und R installieren."
  },
  {
    "objectID": "preface.html#lernziel-3-statistische-versuche-verstehen",
    "href": "preface.html#lernziel-3-statistische-versuche-verstehen",
    "title": "\n3  Einführung\n",
    "section": "\n3.3 Lernziel 3: Statistische Versuche verstehen",
    "text": "3.3 Lernziel 3: Statistische Versuche verstehen\nWie funktioniert ein statistischer Versuch? Ich könnte auch wissenschaftliches Experiment schreiben, aber ein wissenschaftliches Experiment ist sehr abstrakt. Wir wollen ja einen Versuch durchführen und danach - ja was eigentlich? Was wollen wir nach dem Versuch haben? Meistens eine neue Erkenntnis. Um diese Erkenntnis zu validieren oder aber abzusichern nutzen wir Statistik. Dazu musst du noch wissen, dass wir eine spezielle Form der Statistik nutzen: die frequentistische Statistik.\nEine biologische Wiederholung beinhaltet ein neues Tier, Pflanze oder Mensch. Eine technische Wiederholung ist die gleiche Messung an dem gleichen Tier, Pflanze oder Mensch.\nWir nennen das Outcome auch Endpunkt, Response oder kurz \\(y\\).\nDie frequentistische Statistik basiert - wie der Name andeutet - auf Wiederholungen in einem Versuch. Daher der Name frequentistisch. Also eine Frequenz von Beobachtungen. Ist ein wenig gewollt, aber daran gewöhnen wir uns schon mal. Konkret, ein Experiment welches wir frequentistisch Auswerten wollen besteht immer aus biologischen Wiederholungen. Wir müssen also ein Experiment planen in dem wir wiederholt ein Outcome an vielen Tieren, Pflanzen oder Menschen messen. Auf das Outcome gehen wir noch später ein. Im Weiteren konzentrieren wir uns hier auf die parametrische Statistik. Die parametrische Statistik beschäftigt sich mit Parametern von Verteilungen. Ein schwieriger Satz. Schauen wir uns einmal eine Verteilung an.\n\n3.3.1 Possionverteilung\nAbbildung 3.2 zeigt eine Poissonverteilung. Eine Poissonverteilung beschreibt Zähldaten. Mehr zu der Poissonverteilung findest du im Kapitel 16. Wir zählen bei 39 Hunden wiviele Flöhe jeder Hund jeweils hatte. Danach zeichnen wir uns einen Dotplot der die Verteilung der Anzahl Flöhe auf den Hunden wiederspiegelt.\n\n\n\n\nAbbildung 3.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nParameter sind Zahlen, die eine Verteilungskurve beschreiben.\nEine Verteilung hat Parameter. Parameter sind die Eigenschaften einer Verteilung, die notwendig sind um eine Verteilung vollständig zu beschreiben.\nIm Falle der Possionverteilung brauchen wir nur einen Paramter für den höchsten Punkt der Kurve. Wir nennen diesen Punkt Lambda (\\(\\lambda\\)). Die Ausbreitung der Kurve ist eine Funktion von \\(\\lambda\\) und steigt mit \\(\\lambda\\) an.\n\n3.3.2 Normalverteilung\nAbbildung 3.3 zeigt eine Normalverteilung. Mehr zu der Poissonverteilung findest du im Kapitel 15. Hier haben wir das Flohgewicht von den Flöhen von 24 Hunden gemessen, die mit Flöhen befallen waren. Wir sehen, dass sich eine Glockenkurve bildet oder zumindestens etwas ähnliches. Wir können annehmen, dass das Gewicht approximativ normalverteilt ist.\nWir nutzen das Wort approximativ wenn wir sagen wollen, dass ein Outcome näherungsweise normalverteilt ist.\n\n\n\n\nAbbildung 3.3— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nIm Falle der Normalverteilung brauchen wir einen Paramter für den höchsten Punkt der Kurve, sowie einen Parameter für die Ausbreitung, also wie weit geht die Kurve nach links und nach rechts. Der Mittelwert \\(\\bar{y}\\) beschriebt den höchsten Punkt einer Normalverteilung. Die Standardabweichung \\(s_y\\) beschreibt die Ausbreitung einer Normalverteilung.\n\n\n\n\n\n\nWie gehen wir nun vor, wenn wir ein Experiment durchführen wollen?\n\n\n\n\nWir müssen auf jeden Fall wiederholt ein Outcome an verschiedenen Tieren, Pflanzen oder Menschen messen.\nWir überlegen uns aus welcher Verteilungsfamilie unser Outcome stammt, damit wir dann die entsprechende Verfahren zur Analyse nehmen können."
  },
  {
    "objectID": "preface.html#lernziel-4-falsifikationsprinzip",
    "href": "preface.html#lernziel-4-falsifikationsprinzip",
    "title": "\n3  Einführung\n",
    "section": "\n3.4 Lernziel 4: Falsifikationsprinzip",
    "text": "3.4 Lernziel 4: Falsifikationsprinzip\nWenn wir ein Experiment durchführen dann erheben wir einmalig Daten \\(D_1\\). Wir könnten das Experiment wiederholen und erneut Daten \\(D_2\\) erheben. Wir können das Experiment \\(j\\)-mal wiederholen und haben dann Daten von \\(D_1,..., D_j\\). Dennoch werden wir nie alle Daten erheben können, die mit einem Experiment verbunden sind.\nStrukturgleichkeit erreichen wir durch Randomisierung.\nNehmen wir das Beispiel, dass wir die Sprungweite von Hunde- und Katzenflöhen vergleichen wollen. Wir können nicht alle Hunde- und Katzenflöhe messen. Wir können nur eine Stichprobe an Daten \\(D_1\\) erheben. Über diese Daten \\(D_1\\) können wir dann später durch statistische Algorithmen eine Aussage treffen. Wichtig ist hier sich zu merken, dass wir eine Grundgesamtheit haben aus der wir eine Stichprobe ziehen. Wir müssen darauf achten, dass die Stichprobe repräsentativ ist und damit strukturgleich zur Grundgesamtheit ist. Die Strukturgleichkeit erreichen wir durch Randomisierung. Wir veranschaulichen diesen Zusammenhang in Abbildung 3.4. Ein Rückschluß von der Stichprobe ist nur möglich, wenn die Stichprobe die Grundgesamtheit repräsentiert. Auch eine Randomisierung mag dieses Ziel nicht immer erreichen. Im Beispiel der Hundeflöhe könnte wir eine Art an Flöhen übersehen und diese Flohart nicht mit in die Stichprobe aufnehmen. Ein Rückschluß auf diese Flohart wäre dann mit unserem Experiment nicht möglich.\n\n\nAbbildung 3.4— Abbildung über die Grundgesamtheit und die Stichprobe(n) \\(D_1\\) bis \\(D_j\\). Durch Randomisierung wird Sturkturgleichheit erreicht, die dann einen Rückschluß von der Stichprobe auf die Grundgesamtheit erlaubt. Jede Stichprobe ist anders und nicht jede Randomisierung ist erfolgreich was die Strukturgleicheit betrifft.\n\n\nTabelle 3.1 zeigt nochmal die Zusammenfassung von der Grundgesamtheit un der Stichprobe im Vergleich. Wichtig ist zu merken, dass wir mit unserem kleinen Experiment Daten \\(D\\) generieren mit denen wir einen Rückschluß und somit eine Verallgemeinerung erreichen wollen.\n\n\nTabelle 3.1— Vergleich von Grundgesamtheit und Stichprobe.\n\n\n\n\n\nGrundgesamtheit\nStichprobe\n\n\n\n… \\(n\\) ist riesig bis unfassbar.\n… \\(n\\) von \\(D\\) ist klein.\n\n\n… der Mittelwert wird mit \\(\\mu_y\\) beschrieben.\n… der Mittelwert wird mit \\(\\bar{y}\\) beschrieben.\n\n\n… die Varianz wird mit \\(\\sigma^2\\) beschrieben.\n… die Varianz wird mit \\(s^2\\) beschrieben.\n\n\n… die Standardabweichung wird mit \\(\\sigma\\) beschrieben.\n… die Standardabweichung wird mit \\(s\\) beschrieben."
  },
  {
    "objectID": "example-preface.html",
    "href": "example-preface.html",
    "title": "Datenbeispiele",
    "section": "",
    "text": "Wir brauchen am Anfang erstmal ein simples Beispiel. Konkrete Zahlen mit denen wir arbeiten können und Grundlagen aufbauen können. Was liegt da näher als sich einmal am Kopf zu kratzen und zu fragen, was juckt den da? Genau! Flöhe. Wir schauen uns einmal Flöhe auf Hunden und Katzen an. Daran können wir viel über Zahlen und Buchstaben in der Statistik und dann im Programmieren lernen."
  },
  {
    "objectID": "example-preface.html#von-flöhen-und-hunden",
    "href": "example-preface.html#von-flöhen-und-hunden",
    "title": "Datenbeispiele",
    "section": "Von Flöhen und Hunden",
    "text": "Von Flöhen und Hunden\nIn unserem ersten Beispiel in Kapitel 4 geht es darum einmal ein Gefühl für Daten zu kriegen. Also was sind diese Zahlen und Buchstaben eigentlich? Wie sind Daten aufgebaut und wie musst du Daten bauen, so dass wir auch mit den Daten arbeiten können? Wir schauen uns dafür einmal Flöhe auf Hunden an und fragen uns welche Typen von Zahlen können wir erheben?"
  },
  {
    "objectID": "example-preface.html#von-flöhen-hunden-und-katzen",
    "href": "example-preface.html#von-flöhen-hunden-und-katzen",
    "title": "Datenbeispiele",
    "section": "Von Flöhen, Hunden und Katzen",
    "text": "Von Flöhen, Hunden und Katzen\nIn unserem zweiten Beispiel in Kapitel 5 erweitern wir unserer erstes Beispiel aus Kapitel 4 um die Katzen. Das heist, dass eigentlich alles gleich bleibt. Wir schauen usn zusätlich noch als zweite Gruppe die Katzen an. Nun können wir die Frage stellen, unterscheiden sich Flöhe auf Hunden und Katzen gegeben von gemessenen Eigenschaften?"
  },
  {
    "objectID": "example-preface.html#gummibärchen",
    "href": "example-preface.html#gummibärchen",
    "title": "Datenbeispiele",
    "section": "Gummibärchen",
    "text": "Gummibärchen\nDie beiden Datensätze aus Kapitel 4 und Kapitel 5 sind klein. Wir schauen uns nur wenige Beobachtungen an. Du könntest sagen, dass eigentlich Statistik nicht so notwendig ist, da du ja Unterschiede oder Gleichheit schon an den Daten siehst. In dem Gummibärchendatensatz aus XX schauen wir uns sehr viel mehr Beoachtungen an. Mehrere hundert Studierende haben an dem Datensatz schon mitgewirkt, so dass der Datensatz ziemlich groß ist. So einfach lassen sich nun keine Schlüsse mehr ziehen."
  },
  {
    "objectID": "example-preface.html#palmer-penguins",
    "href": "example-preface.html#palmer-penguins",
    "title": "Datenbeispiele",
    "section": "Palmer Penguins",
    "text": "Palmer Penguins\nPalmer Penguins"
  },
  {
    "objectID": "example-fleas-dogs.html",
    "href": "example-fleas-dogs.html",
    "title": "4  Von Flöhen und Hunden",
    "section": "",
    "text": "In unserem ersten Beispiel wollen wir uns verschiedene Daten \\(D\\) von Hunden und Hundeflöhen anschauen. Unter anderem sind dies die Sprungweite, die Anzahl an Flöhen, die Boniturnoten auf einer Hundemesse sowie der Infektionsstatus. Hier nochmal detailiert, was wir uns im folgenden im Kapitel einmal anschauen wollen.\nJe nachdem was wir messen, nimmt \\(Y\\) andere Zahlenräume an. Wir sagen, \\(Y\\) folgt einer Verteilung. Die Sprungweite ist normalverteilt, die Anzahl an Flöhen folgt einer Poisson Verteilung, die Boniturnoten sind multinominal/ordinal bzw. kategorial verteilt. Der Infektionsstatus ist binomial verteilt. Wir werden uns später die Verteilungen anschauen und visualisieren. Das können wir hier aber noch nicht. Wichtig ist, dass du schon mal gehört hast, dass \\(Y\\) unterschiedlich verteilt ist, je nachdem welche Dinge wir messen."
  },
  {
    "objectID": "example-fleas-dogs.html#palmer-penguins",
    "href": "example-fleas-dogs.html#palmer-penguins",
    "title": "4  Von Flöhen und Hunden",
    "section": "\n4.1 Palmer Penguins",
    "text": "4.1 Palmer Penguins\nPalmer Penguins"
  },
  {
    "objectID": "example-fleas-dogs-cats.html",
    "href": "example-fleas-dogs-cats.html",
    "title": "5  Von Flöhen, Hunden und Katzen",
    "section": "",
    "text": "Wir wollen jetzt das Beispiel von den Hunden und Flöhen um eine Spezies erweitern. Wir nehmen noch die Katzen mit dazu und fragen uns, wie sieht es mit der Sprungfähigkeit von Katzen und Hundeflöhen aus? Konzentrieren wir uns hier einmal auf die Sprungweite. Wir können wie in dem Beispiel 4 die Sprungweiten [cm] wieder aufschreiben:\n\\[\nY_{jump} = \\{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\\}.\n\\]\nWenn wir jetzt die Sprungweiten der Hundeflöhe mit den Katzenflöhen vergleichen wollen haben wir ein Problem. Beide Zahlenvektoren heißen gleich, nämlich \\(Y_{jump}\\). Wir könnten jeweils in die Indizes noch \\(dog\\) und \\(cat\\) schreiben als \\(Y_{jump,\\, dog}\\) und \\(Y_{jump,\\, cat}\\) und erhalten folgende Vektoren.\n\\[\nY_{jump,\\, dog} = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}\n\\]\n\\[\nY_{jump,\\, cat} = \\{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\\}\n\\]\nDadurch werden die Indizes immer länger und unübersichticher. Auch das \\(Y\\) einfach \\(Y_{dog}\\) oder \\(Y_{cat}\\) zu nennen ist keine Lösung - wir wollen uns vielleicht später nicht nur die Sprungweite vergleichen, sondern vielleicht auch die Anzahl an Flöhen oder den Infektionsstatus. Dann ständen wir wieder vor dem Problem die \\(Y\\) für die verschiedenen Outcomes zu unterscheiden. Daher erstellen wir uns die Tabelle 5.1. Wir haben jetzte eine Datentabelle.\nIntuitiv ist die Tabelle 5.1 übersichtlich und beinhaltet die Informationen die wir wollten. Dennoch haben wir das Probem, das wir in dieser Tabelle 5.1 nicht noch weitere Outcomes angeben können. Wir können die Anzahl an Flöhen auf den Hunde und Katzen nicht darstellen. Als Lösung ändern wir die Tabelle 5.1 in das Long-Format. Dargestellt in Tabelle 5.2. Jede Beobachtung belegt nun eine Zeile. Dies ist sehr wichtig im Kopf zu behalten, wenn du eigene Daten in z.B. Excel eingibts."
  },
  {
    "objectID": "example-fleas-dogs-cats.html#palmer-penguins",
    "href": "example-fleas-dogs-cats.html#palmer-penguins",
    "title": "5  Von Flöhen, Hunden und Katzen",
    "section": "\n5.1 Palmer Penguins",
    "text": "5.1 Palmer Penguins\nPalmer Penguins"
  },
  {
    "objectID": "example-outro.html",
    "href": "example-outro.html",
    "title": "\n6  Zusammenfassung Datenbeispiele\n",
    "section": "",
    "text": "Was war der Sinn der Reise?\n\n\n\nWir nutzen nur das Long-Format für die Erstellung einer Datentabelle! Nur eine Long-Format Tabelle können wir in R später weiterverarbeiten.\n\n\nNun haben wir Tabelle 5.2 mit Daten zu verschiedenen Oucomes, wie Sprungweite [cm], Anzahl an Flöhen auf Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus. Die Tabelle 5.2 ist zwar nicht groß aber auch nicht wirklich klein. Im nächsten Kapitel wollen wir uns damit beschäftigen, die Zahlen in der Tabelle sinnvoll zusammenzufassen."
  },
  {
    "objectID": "programing-preface.html",
    "href": "programing-preface.html",
    "title": "Daten in R",
    "section": "",
    "text": "Im vorherigen Kapitel haben wir die Datentabelle Tabelle 5.2 erschaffen. Bevor wir uns weiter mit statistischen Kennzahlen beschäftigen, wollen wir uns einmal die Realisierung der Tabelle Tabelle 5.2 in R anschauen. Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu können. Wir wollen später R nutzen um die explorative Datenanalyse anzuwenden. Über die explorative Datenanalyse lernen wir in späteren Kapiteln mehr.\n\n\n\n\n\n\nEinführung in R per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "programing-letters-numbers.html",
    "href": "programing-letters-numbers.html",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "",
    "text": "Im vorherigen Kapitel haben wir die Datentabelle Tabelle 5.2 erschaffen. Bevor wir uns weiter mit statistischen Kennzahlen beschäftigen, wollen wir uns einmal die Realisierung der Tabelle Tabelle 5.2 in R anschauen. Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu können. Nun haben wir Tabelle Tabelle 5.2 mit Daten zu verschiedenen Oucomes, wie Sprungweite [cm], Anzahl an Flöhen auf Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus. Die Tabelle Tabelle 5.2 ist zwar nicht groß aber auch nicht wirklich klein. Wir wollen uns nun damit beschäftigen, die Zahlen sinnvoll in R darzustellen."
  },
  {
    "objectID": "programing-letters-numbers.html#daten-in-r-sind-tibble",
    "href": "programing-letters-numbers.html#daten-in-r-sind-tibble",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.1 Daten in R sind tibble()\n",
    "text": "7.1 Daten in R sind tibble()\n\nIm folgenden sehen wir die Datentabelle Tabelle 5.2 in R als tibble dargestellt. Was ist nun ein tibble? Ein tibble ist zu aller erst ein Speicher für Daten in R. Das heist wir haben Spalten und Zeilen. Jede Spalte repräsentiert eine Messung oder Variable und die Zeilen jeweils eine Beobachtung.\n\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <int> <dbl> <lgl>   \n 1 dog            5.7         18     8 FALSE   \n 2 dog            8.9         22     7 TRUE    \n 3 dog           11.8         17     5 TRUE    \n 4 dog            8.2         12     6 FALSE   \n 5 dog            5.6         23     7 TRUE    \n 6 dog            9.1         18     7 FALSE   \n 7 dog            7.6         21     9 FALSE   \n 8 cat            3.2         12     9 TRUE    \n 9 cat            2.2         13     5 FALSE   \n10 cat            5.4         11     7 FALSE   \n11 cat            4.1         12     8 FALSE   \n12 cat            4.3         16     6 TRUE    \n13 cat            7.9          9     6 FALSE   \n14 cat            6.1          7     8 FALSE   \n\n\nAls erstes erfahren wir, dass wir einen A tibble: 14 x 5 vorliegen haben. Das heist, wir haben 14 Zeile und 5 Spalten. In einem tibble wird immer in der ersten Zeile angezeigt wieviele Beobachtungen wir in dem Datensatz haben. Wenn das tibble zu groß wird, werden wir nicht mehr das ganze tibble sehen sondern nur noch einen Ausschnitt. Im Weiteren hat jede Spalte noch eine Eigenschaft unter dem Spaltennamen\n\n\n<chr> bedeutet character. Wir haben also hier Worte vorliegen.\n\n<dbl> bedeutet double. Ein double ist eine Zahl mit Kommastellen.\n\n<int> bedeutet integer. Ein integer ist eine ganze Zahl ohne Kommastellen.\n\n<lgl> bedeutet logical oder boolean. Hier gibt es nur die Ausprägung wahr oder falsch. Somit TRUE oder FALSE. Statt den Worten TRUE oder FALSE kann hier auch 0 oder 1 stehen.\n\n<str> bedeutet string der aus verschiedenen character besteht kann, getrennt durch Leerzeichen.\n\n\n\n\n\n\n\nThis book was originally created using bookdown and published at https://rstudio-education.github.io/hopr/. This site is a port of the original book source to the Quarto publishing system in order to provide an example of it’s use.\n\n\n\nEinführung in R - Teil 06 - Zahlen, Buchstaben, Skalenniveau - Was ist das eigentlich?\n\n\n\n\n\n\n\n\n\n\n\nVariablenname\nBeispiel\nR\nInfomatik\nSkalenniveau\nVerteilungsfamilie\n\n\n\nweight\n12.3, 12.4, 5.4, 21.3, 13.4\nnumeric\ndouble\ncontinuous\nGaussian\n\n\ncount\n5, 0, 12, 23, 1, 4, 21\ninteger\ninteger\ncontinuous\nPoisson\n\n\ndosis\nlow, mid, high\nordered\n\ncategorical / discrete / ordinal\nOrdinal\n\n\nfield\nmainz, berlin, kiel\nfactor\n\ncategorical / discrete\nMultinomial\n\n\ncancer\n0, 1\nfactor\n\ndichotomous / binary / nominal\nBinomial\n\n\ntreatment\n“placebo”, “aspirin”\ncharacter\ncharacter/string\ndichotomous / binary / nominal\nBinomial\n\n\nbirth\n2001-12-02, 2005-05-23\ndate"
  },
  {
    "objectID": "programing-letters-numbers.html#faktoren-als-wörter-zu-zahlen",
    "href": "programing-letters-numbers.html#faktoren-als-wörter-zu-zahlen",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.2 Faktoren als Wörter zu Zahlen",
    "text": "7.2 Faktoren als Wörter zu Zahlen\nEin Computer und somit auch eine Programmsprache wie R kann keine Buchstaben verrechnen. Ein Programm kann nur mit Zahlen rechnen. Wir haben aber in der Datentabelle Tabelle 5.2 in der Spalte animal Buchstaben stehen. Da wir hier einen Kompromiss eingehen müssen führen wir Faktoren ein. Ein Faktor kombiniert Buchstaben mit Zahlen. Wir als Anwender sehen die Buchstaben, die Wörter bilden. Intern steht aber jedes Wort für eine Zahl, so dass R mit den Zahlen rechnen kann. Klingt ein wenig kryptisch, aber wir schauen uns einen factor einmal an.\n\nas_factor(data_tbl$animal[1:8])\n\n[1] dog dog dog dog dog dog dog cat\nLevels: dog cat\n\n\nMit dem $ Zeichen können wir uns eine einzelne Zeile aus dem Datensatz data_tbl rausziehen. Du kannst dir das $ wie einen Kleiderbügel und das data_tbl als einen Schrank für Kleiderbügel verstellen. An dem Kleiderbügel hängen dann die einzelnen Zahlen und Worte. Im Weiteren nehmen wir nicht den ganzen Vektor animal mit vierzehn Einträgen sondern nur die ersten acht. Das machen wir mit [1-8] hinter dem animal. Schauen wir auf das Ergebnis, so erhalten wir sieben Mal dog und einmal cat. Insgesamt die ersten acht Einträge der Datentabelle. Darüber hinaus sehen wir auch, dass die der Faktor jetzt Levels hat. Exakt zwei Stück. Jeweils einen für dog und einen für cat.\n\nanimal <- c(\"dog\", \"dog\", \"dog\", \"cat\", \"cat\", \"cat\")\n\nas.factor(animal)\n\n[1] dog dog dog cat cat cat\nLevels: cat dog\n\nfactor(animal, levels = c(\"dog\", \"cat\"))\n\n[1] dog dog dog cat cat cat\nLevels: dog cat\n\nfactor(animal, labels = c(\"katze\", \"hund\"))\n\n[1] hund  hund  hund  katze katze katze\nLevels: katze hund\n\nas_factor(animal)\n\n[1] dog dog dog cat cat cat\nLevels: dog cat\n\ndose <- c(\"low\", \"low\", \"mid\", \"mid\", \"high\", \"high\")\n\nas.factor(dose)\n\n[1] low  low  mid  mid  high high\nLevels: high low mid\n\nfactor(dose, levels = c(\"low\", \"mid\", \"high\"))\n\n[1] low  low  mid  mid  high high\nLevels: low mid high"
  },
  {
    "objectID": "programing-letters-numbers.html#der-zuweisungspfeil--",
    "href": "programing-letters-numbers.html#der-zuweisungspfeil--",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.3 Der Zuweisungspfeil <-\n",
    "text": "7.3 Der Zuweisungspfeil <-\n\nMit dem Zuweisungspfeil speichern wir Dinge in Objekte in R. Das heist wir speichern damit intern in R Datensätze und viele andere Sachen, die wir dan später wieder verwenden wollen. Schauen wir uns das einmal im Beispiel an. Schrieben wir nur den Vektor c() mit Hunden und Katzen darin, so erscheint eine Ausgabe in R.\n\nc(\"dog\", \"dog\", \"cat\", \"cat\", \"fox\", \"fox\")\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\"\n\n\nSchreiben wir den gleichen Vektor und nutzen den Zuweisungspfeil, dann wird der Vektor in dem Objekt animal gespeichert.\n\nanimal <- c(\"dog\", \"dog\", \"cat\", \"cat\", \"fox\", \"fox\")\n\nWie kommen wir jetzt an die Sachen, die in animal drin sind? Wir können einfach animal in R schreiben und dann wird uns der Inhalt von animal ausgegeben.\n\nanimal\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\""
  },
  {
    "objectID": "programing-letters-numbers.html#von-wörtern-und-objekten",
    "href": "programing-letters-numbers.html#von-wörtern-und-objekten",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.4 Von Wörtern und Objekten",
    "text": "7.4 Von Wörtern und Objekten\nDas mag etwas verwirrend sein, denn es gibt in R Wörter string <str> oder character <chr>. Wörter sind was anderes als Objekte. Streng genommen sind beides Wörter, aber in Objekten werden Dinge gespeichert wohin gegen das Wort einfach ein Wort ist. Deshalb kennezeichnen wir Wörter auch mit \"wort\" und zeigen damit, dass es sich hier um einen String handelt.\n\n7.4.1 Ein string <str> oder character <chr>\n\nWir tippen \"animal\" in R und erhalten \"animal\" zurück.\n\n\"animal\"\n\n[1] \"animal\"\n\n\n\n7.4.2 Ein Objekt\nWir tippen animal ohne die Anführungszeichen in R und erhalten den Inhalt von animal ausgegeben.\n\nanimal\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\"\n\n\nSollte es das Objekt animal nicht geben, also nicht über den Zuweisungspfeil <- erschaffen worden, dann wird eine Fehlermeldung von R ausgegeben:\nFehler in eval(expr, envir, enclos) : Objekt 'animal' nicht gefunden"
  },
  {
    "objectID": "programing-letters-numbers.html#die-pipe",
    "href": "programing-letters-numbers.html#die-pipe",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.5 Die Pipe %>%\n",
    "text": "7.5 Die Pipe %>%\n\nIm Weiteren nutzen wir den Pipe Operator dargestellt als %\\>%. Du kannst dir den Pipe Operator als eine Art Röhre vorstellen in dem die Daten verändert werden und dann an die nächste Funktion weitergeleitet werden. Nehmen wir nochmal das Beispiel von weiter oben. Wir wollen die character Spalte aus dem Datensatz data_tbl extrahieren und dann in einen Faktor umwandeln.\n\nanimal_1_tbl <- select(data_tbl, animal, jump_length)\nanimal_2_tbl <- filter(animal_1_tbl, jump_length >= 4)\nsort(animal_2_tbl$jump_length)\n\n [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8\n\ndata_tbl %>% \n  select(animal, jump_length) %>% \n  filter(jump_length >= 4) %>% \n  pull(jump_length) %>% \n  sort\n\n [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8\n\n\nZuerst siehst du das alte Beispiel und dann die Nutzung des Pipe Operators %>%. Das Ergebnis ist das gleiche, aber der Code ist einfacher zu lesen. Wir nehmen den Datensatz data_tbl leiten den Datensatz in den Funktion pull() und ziehen uns damit den Vektor animal aus dem Datensatz. Den Vektor leiten wir dann weiter in die Funktion extract() und nehmen nur die ersten 5 Werte aus dem Vektor."
  },
  {
    "objectID": "programing-letters-numbers.html#daten-bearbeiten",
    "href": "programing-letters-numbers.html#daten-bearbeiten",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.6 Daten bearbeiten",
    "text": "7.6 Daten bearbeiten\nIm folgenden wollen wir den Datensatz data_tbl in R bearbeiten. Das heist wir wollen Spalten auswählen mit select() oder Zeilen auswählen mit filter(). Schlussendlich wollen wir auch die Eigenschaften von Spalten mit der Funktion mutate ändern\n\n7.6.1 Spalten wählen mit select()\n\nhttps://dplyr.tidyverse.org/reference/select.html\n\ndata_tbl %>% \n  select(animal, jump_length, flea_count)\n\n# A tibble: 14 × 3\n   animal jump_length flea_count\n   <chr>        <dbl>      <int>\n 1 dog            5.7         18\n 2 dog            8.9         22\n 3 dog           11.8         17\n 4 dog            8.2         12\n 5 dog            5.6         23\n 6 dog            9.1         18\n 7 dog            7.6         21\n 8 cat            3.2         12\n 9 cat            2.2         13\n10 cat            5.4         11\n11 cat            4.1         12\n12 cat            4.3         16\n13 cat            7.9          9\n14 cat            6.1          7\n\n\n\n7.6.2 Zeilen wählen mit filter()\n\nhttps://dplyr.tidyverse.org/reference/filter.html\n\ndata_tbl %>% \n  filter(animal %in% c(\"dog\"))\n\n# A tibble: 7 × 5\n  animal jump_length flea_count grade infected\n  <chr>        <dbl>      <int> <dbl> <lgl>   \n1 dog            5.7         18     8 FALSE   \n2 dog            8.9         22     7 TRUE    \n3 dog           11.8         17     5 TRUE    \n4 dog            8.2         12     6 FALSE   \n5 dog            5.6         23     7 TRUE    \n6 dog            9.1         18     7 FALSE   \n7 dog            7.6         21     9 FALSE   \n\n\n\ndata_tbl %>% \n  filter(flea_count > 15)\n\n# A tibble: 7 × 5\n  animal jump_length flea_count grade infected\n  <chr>        <dbl>      <int> <dbl> <lgl>   \n1 dog            5.7         18     8 FALSE   \n2 dog            8.9         22     7 TRUE    \n3 dog           11.8         17     5 TRUE    \n4 dog            5.6         23     7 TRUE    \n5 dog            9.1         18     7 FALSE   \n6 dog            7.6         21     9 FALSE   \n7 cat            4.3         16     6 TRUE    \n\n\n\ndata_tbl %>% \n  filter(infected == TRUE)\n\n# A tibble: 5 × 5\n  animal jump_length flea_count grade infected\n  <chr>        <dbl>      <int> <dbl> <lgl>   \n1 dog            8.9         22     7 TRUE    \n2 dog           11.8         17     5 TRUE    \n3 dog            5.6         23     7 TRUE    \n4 cat            3.2         12     9 TRUE    \n5 cat            4.3         16     6 TRUE    \n\n\n\n7.6.3 Spalten ändern mit mutate()\n\nhttps://dplyr.tidyverse.org/reference/mutate.html\n\ndata_tbl %>% \n  mutate(animal = as_factor(animal))\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <fct>        <dbl>      <int> <dbl> <lgl>   \n 1 dog            5.7         18     8 FALSE   \n 2 dog            8.9         22     7 TRUE    \n 3 dog           11.8         17     5 TRUE    \n 4 dog            8.2         12     6 FALSE   \n 5 dog            5.6         23     7 TRUE    \n 6 dog            9.1         18     7 FALSE   \n 7 dog            7.6         21     9 FALSE   \n 8 cat            3.2         12     9 TRUE    \n 9 cat            2.2         13     5 FALSE   \n10 cat            5.4         11     7 FALSE   \n11 cat            4.1         12     8 FALSE   \n12 cat            4.3         16     6 TRUE    \n13 cat            7.9          9     6 FALSE   \n14 cat            6.1          7     8 FALSE   \n\n\n\ndata_tbl %>% \n  mutate(long_jump = if_else(jump_length > 7, TRUE, FALSE)) %>% \n  select(animal, jump_length, long_jump)\n\n# A tibble: 14 × 3\n   animal jump_length long_jump\n   <chr>        <dbl> <lgl>    \n 1 dog            5.7 FALSE    \n 2 dog            8.9 TRUE     \n 3 dog           11.8 TRUE     \n 4 dog            8.2 TRUE     \n 5 dog            5.6 FALSE    \n 6 dog            9.1 TRUE     \n 7 dog            7.6 TRUE     \n 8 cat            3.2 FALSE    \n 9 cat            2.2 FALSE    \n10 cat            5.4 FALSE    \n11 cat            4.1 FALSE    \n12 cat            4.3 FALSE    \n13 cat            7.9 TRUE     \n14 cat            6.1 FALSE    \n\n\n\n\n\n\n\n\nDie Funktionen select(), filter() und mutate() in R\n\n\n\nBitte schaue dir auch die Hilfeseiten der Funktionen an. In diesem Skript kann ich nicht alle Funktionalitäten der Funktionen zeigen. Oder du kommst in das R Tutorium welches ich anbiete und fragst dort nach den Möglichkeiten Daten in R zu verändern."
  },
  {
    "objectID": "programing-letters-numbers.html#mehr-informationen-durch-glimpse-und-str",
    "href": "programing-letters-numbers.html#mehr-informationen-durch-glimpse-und-str",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.7 Mehr Informationen durch glimpse() und str()\n",
    "text": "7.7 Mehr Informationen durch glimpse() und str()\n\n\nglimpse(data_tbl)\n\nRows: 14\nColumns: 5\n$ animal      <chr> \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"cat\", \"c…\n$ jump_length <dbl> 5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6, 3.2, 2.2, 5.4, 4.1, 4.…\n$ flea_count  <int> 18, 22, 17, 12, 23, 18, 21, 12, 13, 11, 12, 16, 9, 7\n$ grade       <dbl> 8, 7, 5, 6, 7, 7, 9, 9, 5, 7, 8, 6, 6, 8\n$ infected    <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE,…\n\nstr(data_tbl)\n\ntibble [14 × 5] (S3: tbl_df/tbl/data.frame)\n $ animal     : chr [1:14] \"dog\" \"dog\" \"dog\" \"dog\" ...\n $ jump_length: num [1:14] 5.7 8.9 11.8 8.2 5.6 9.1 7.6 3.2 2.2 5.4 ...\n $ flea_count : int [1:14] 18 22 17 12 23 18 21 12 13 11 ...\n $ grade      : num [1:14] 8 7 5 6 7 7 9 9 5 7 ...\n $ infected   : logi [1:14] FALSE TRUE TRUE FALSE TRUE FALSE ..."
  },
  {
    "objectID": "programing-letters-numbers.html#pakete-und-library",
    "href": "programing-letters-numbers.html#pakete-und-library",
    "title": "\n7  Von Buchstaben und Zahlen\n",
    "section": "\n7.8 Pakete und library()\n",
    "text": "7.8 Pakete und library()\n\nIn der Vanilla1 Variante hat R sehr wenige Funktionen. Ohne zusätzliche Pakete ist R mehr ein sehr potenter Taschenrechner. Leider mit der Funktionalität aus den 90’zigern, was die Programmierumgebeung und die Funktionen angeht. Das wollen wir aber nicht. Wir wollen auf den aktuellen Stand der Technik und auch Sprache programmieren. Daher nutzen wir zusätzliche R Pakete.1 Als Vanilla beschreibt man in der Informatikerwelt ein Programm, was keine zusätzlichen Pakete geladen hat. Also die reinst Form ohne zusätzlichen Geschmack.\n\n\nAbbildung 7.1— Auf den Reiter Packages klicken und dann Install. In der deutschen version vom RStudio mögen die Begriffe leicht anders sein.\n\n\nIn Abbildung 7.1 wird gezeigt wie du ein zusätzliches Paket installieren kannst. Hierbei ist nochmal wichtig den semantischen Unterschied zu wissen. Es gibt das Paket tidyverse was wir viel nutzen. Wir isnatllieren einmalig Pakete der Funktion install.packages() oder eben wie in Abbildung 7.1 gezeigt. Wir nutzen die Funktion library() um ein Paket in R zu laden. Ja, es müsste anders heisen, tut es aber nicht.\n\n## Das Paket tidyverse installieren - einmalig\ninstall.packages(tidyverse)\n\n## Das Paket tidyverse laden - jedes Mal\nlibrary(tidyverse)\n\nNun muss man sich immer merken, ob das Paket schon installiert ist oder man schreibt relativ viele library() untereinander. Das passiert schnell, wenn du viele Pakete laden willst. Dafür erlaubt dir das Paket pacman eine Vereinfachung. Die Funktion p_load() installiert Pakete, wenn die Pakete nicht installiert sind. Sollten die Pakete installiert sein, so werden die Pakete geladen. Du musst nur einmal install.packages(pacman) ausführen um das Paket pacman zu installieren.\n\npacman::p_load(tidyverse, magrittr, readxl)\n\nSchlussendlich gibt es noch die Möglichkeit sich alles nochmal bei YoTube anzuschauen.\n\n\n\n\n\n\nUnterschied von Packages und Libraries in R\n\n\n\nDu findest auf YouTube Einführung in R - Teil 03 - Unterschied Packages und Libraries in R als Video. Hier erkläre ich nochmal den Ablauf zwischen Installieren eines Paketes und dem Laden eines Paketes."
  },
  {
    "objectID": "programing-import.html",
    "href": "programing-import.html",
    "title": "\n8  Daten in R einlesen\n",
    "section": "",
    "text": "Gängige Fehler beim Einlesen von Dateien in R"
  },
  {
    "objectID": "programing-import.html#genutzte-r-pakete-für-das-kapitel",
    "href": "programing-import.html#genutzte-r-pakete-für-das-kapitel",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.1 Genutzte R Pakete für das Kapitel",
    "text": "8.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, janitor)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "programing-import.html#importieren-mit-rstudio",
    "href": "programing-import.html#importieren-mit-rstudio",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.2 Importieren mit RStudio",
    "text": "8.2 Importieren mit RStudio\nWir können das RStudio nutzen um Daten mit Point-and-Klick rein zuladen und dann den Code wieder in den Editor kopieren. Im Prinzip ist dieser Weg der einfachste um einmal zu sehen, wie ein pfad funktioniert und der Code lautet. Später benötigt man diese ‘Krücke’ nicht mehr. Wir nutzen dann direkt den Pfad zu der Datei. Abbildung 8.1 zeigt einen Ausschnitt, wo wir im RStudio die Import Dataset Funktionalität finden.\n\n\nAbbildung 8.1— Auf den Reiter Einviroment klicken und dann Import Dataset. In der deutschen version vom RStudio mögen die Begriffe leicht anders sein.\n\n\n\n\n\n\n\n\nImportieren mit RStudio als Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 21.0 - Daten importieren mit RStudio - Point and Klick als Video. Point and Klick ist als Video einfacher nachzuvollziehen als Screenshots in einem Fließtext."
  },
  {
    "objectID": "programing-import.html#sec-pfad",
    "href": "programing-import.html#sec-pfad",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.3 Importieren per Pfad",
    "text": "8.3 Importieren per Pfad\nIn Abbildung 8.2 können wir sehen wie wir den Pfad zu unserer Excel Datei flea_dog_cat.xlsx finden. Natürlich kannst du den Pfad auch anders herausfinden bzw. aus dem Explorer oder Finder kopieren.\n\n\nAbbildung 8.2— Durch den Rechts-Klick auf die Eigenschaften einer Datei kann man sich den Pfad zur Datei anzeigen lassen. Achtung! Unter Windows muss der Slash \\ noch in den Backslash / gedreht werden.\n\n\nNachdem wir den Pfad gefunden haben, können wir den Pfad in die Funktion read_excel() kopieren und die Datei in das Objekt data_tbl einlesen. Ja, es wird nichts in der R Console ausgegeben, da sich die Daten jetzt in dem Object data_tbl befinden.\n\n## Ganzer Pfad zur Datei flea_dog_cat.xlsx\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n\n\n\n\n\n\nUnterschied zwischen \\ in Windows und / in R\n\n\n\nAchte einmal auf den Slash im Pfad in R und einem im Pfsd in Windows. Einmal ist es der Slash \\ im Dateipfad und einmal der Backslash /. Das ist sehr ärgerlich, aber dieses Problem geht zurück in die 80’ziger. Bill hat entschieden für sein Windows / zu nutzen und Steve (und Unix) eben /. Und mit dieser Entscheidung müssen wir jetzt leben…"
  },
  {
    "objectID": "programing-import.html#sec-umlaute",
    "href": "programing-import.html#sec-umlaute",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.4 Auf ein englisches Wort in Dateien",
    "text": "8.4 Auf ein englisches Wort in Dateien\nEin großes Problem in Datein sind Umlaute (ä,ö,ü) oder aber andere (Sonder)zeichen (ß, ?, oder #). Als dies sollte vermieden werden. Eine gute Datei für R beinhaltet nur ganze Wörter, Zahlen oder aber leere Felder. Ein leeres Feld ist ein fehlender Wert. Abbildung 8.3 zeigt eine gute Exceldatentablle. Wir schreiben jump_length mit Unterstrich um den Namen besser zu lesen zu können. Sonst ist auch alles in Englisch geschrieben. Wir vermeiden durch die neglische Schreibweise aus versehen einen Umlaut oder anderweitig problematische Zeichen zu verwenden. Später können wir alles noch für Abbildungen anpassen.\n\n\nAbbildung 8.3— Beispiel für eine gute (Excel)Datentabelle. Keine Umlaute sind vorhanden und die Spaltennamen haben keine Leerzeichen oder Sonderzeichen."
  },
  {
    "objectID": "programing-import.html#sec-spalten",
    "href": "programing-import.html#sec-spalten",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.5 Spaltennamen in der (Excel)-Datei",
    "text": "8.5 Spaltennamen in der (Excel)-Datei\nDie Funktion clean_names() aus dem R Paket janitor erlaubt es die Spaltennamen einer eingelesenen Datei in eine für R gute Form zu bringen.\n\nKeine Leerzeichen in den Spaltennamen.\nAlle Spaltennamen sind klein geschrieben.\n\n\ndata_tbl %>% \n  clean_names()\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            5.7         18     8        0\n 2 dog            8.9         22     7        1\n 3 dog           11.8         17     5        1\n 4 dog            8.2         12     6        0\n 5 dog            5.6         23     7        1\n 6 dog            9.1         18     7        0\n 7 dog            7.6         21     9        0\n 8 cat            3.2         12     9        1\n 9 cat            2.2         13     5        0\n10 cat            5.4         11     7        0\n11 cat            4.1         12     8        0\n12 cat            4.3         16     6        1\n13 cat            7.9          9     6        0\n14 cat            6.1          7     8        0\n\n\n\n8.5.1 Datenbeispiel"
  },
  {
    "objectID": "programing-import.html#wide-format",
    "href": "programing-import.html#wide-format",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.6 Wide format",
    "text": "8.6 Wide format\n\n\ndog\ncat\n\n\n\n5.2\n10.1\n\n\n4.9\n9.4\n\n\n12.1\n11.8\n\n\n8.2\n6.7\n\n\n5.6\n8.2\n\n\n9.1\n9.1\n\n\n7.4\n7.1\n\n\n\n\njump_wide_tbl <- tibble(dog = c(5.2, 4.9, 12.1, 8.2, 5.6, 9.1, 7.4),\n                   cat = c(10.1, 9.4, 11.8, 6.7, 8.2, 9.1, 7.1))\n\njump_wide_tbl\n\n# A tibble: 7 × 2\n    dog   cat\n  <dbl> <dbl>\n1   5.2  10.1\n2   4.9   9.4\n3  12.1  11.8\n4   8.2   6.7\n5   5.6   8.2\n6   9.1   9.1\n7   7.4   7.1"
  },
  {
    "objectID": "programing-import.html#long-format",
    "href": "programing-import.html#long-format",
    "title": "\n8  Daten in R einlesen\n",
    "section": "\n8.7 Long format",
    "text": "8.7 Long format\n\njump_tbl <- tibble(dog = c(5.2, 4.9, 12.1, 8.2, 5.6, 9.1, 7.4),\n                   cat = c(10.1, 9.4, 11.8, 6.7, 8.2, 9.1, 7.1)) %>%\n  gather(key = \"animal\", value = \"jump_length\")\njump_tbl\n\n# A tibble: 14 × 2\n   animal jump_length\n   <chr>        <dbl>\n 1 dog            5.2\n 2 dog            4.9\n 3 dog           12.1\n 4 dog            8.2\n 5 dog            5.6\n 6 dog            9.1\n 7 dog            7.4\n 8 cat           10.1\n 9 cat            9.4\n10 cat           11.8\n11 cat            6.7\n12 cat            8.2\n13 cat            9.1\n14 cat            7.1\n\n\n\n\n\n\ntreatment\nblock\nrep_1\nrep_2\nrep_3\nrep_4\nrep_5\nrep_6\n\n\n\nA\n1\n15.61\n13.78\n17.91\n16.89\n19.87\n19.93\n\n\nA\n2\n14.38\n12.96\n15.55\n16.23\n14.57\n17.03\n\n\nA\n3\n10.76\n12.80\n17.90\n15.14\n20.59\n18.42\n\n\nA\n4\n18.48\n17.19\n16.23\n18.23\n13.14\n16.98\n\n\nB\n1\n12.47\n16.82\n16.78\n16.87\n17.54\n20.31\n\n\nB\n2\n15.01\n15.81\n16.70\n20.11\n20.41\n17.66\n\n\nB\n3\n17.53\n15.92\n17.01\n16.22\n19.45\n20.05\n\n\nB\n4\n16.94\n14.84\n21.23\n16.81\n14.37\n17.89\n\n\nC\n1\n14.22\n16.91\n20.19\n16.12\n18.85\n15.84\n\n\nC\n2\n15.07\n13.09\n15.84\n16.09\n15.57\n21.12\n\n\nC\n3\n12.37\n15.68\n17.74\n18.30\n15.04\n17.37\n\n\nC\n4\n14.41\n17.36\n18.29\n13.97\n18.80\n16.78\n\n\nD\n1\n13.36\n13.60\n16.60\n16.80\n18.22\n21.75\n\n\nD\n2\n14.31\n15.55\n19.55\n16.38\n20.15\n16.82\n\n\nD\n3\n13.17\n16.51\n19.70\n17.91\n18.41\n16.96\n\n\nD\n4\n16.66\n15.87\n21.75\n16.67\n21.03\n18.42\n\n\n\n\n\n\ndata_tbl %>% \n  gather(rep, value, rep_1:rep_6) %>% \n  arrange(treatment, block)\n\n# A tibble: 96 × 4\n   treatment block rep   value\n   <fct>     <int> <chr> <dbl>\n 1 A             1 rep_1  15.6\n 2 A             1 rep_2  13.8\n 3 A             1 rep_3  17.9\n 4 A             1 rep_4  16.9\n 5 A             1 rep_5  19.9\n 6 A             1 rep_6  19.9\n 7 A             2 rep_1  14.4\n 8 A             2 rep_2  13.0\n 9 A             2 rep_3  15.6\n10 A             2 rep_4  16.2\n# … with 86 more rows"
  },
  {
    "objectID": "programing-outro.html",
    "href": "programing-outro.html",
    "title": "\n9  Einführende Datenbeispiele\n",
    "section": "",
    "text": "Wir brauchen am Anfang erstmal ein Beispiel. Konkrete Zahlen mit denen wir arbeiten können und Grundlagen aufbauen können. Was liegt da näher als sich einmal am Kopf zu kratzen und zu fragen, was juckt den da? Genau! Flöhe. Wir schauen uns einmal Flöhe auf Hunden und Katzen an. Daran können wir viel über Zahlen und Buchstaben in der Statistik und dann im Programmieren lernen.\nNun haben wir Tabelle 5.2 mit Daten zu verschiedenen Oucomes, wie Sprungweite [cm], Anzahl an Flöhen auf Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus. Die Tabelle 5.2 ist zwar nicht groß aber auch nicht wirklich klein. Im nächsten Kapitel wollen wir uns damit beschäftigen, die Zahlen in der Tabelle sinnvoll zusammenzufassen."
  },
  {
    "objectID": "programing-outro.html#palmer-penguins",
    "href": "programing-outro.html#palmer-penguins",
    "title": "\n9  Einführende Datenbeispiele\n",
    "section": "\n9.1 Palmer Penguins",
    "text": "9.1 Palmer Penguins\nPalmer Penguins"
  },
  {
    "objectID": "eda-preface.html",
    "href": "eda-preface.html",
    "title": "Explorative Datenanalyse",
    "section": "",
    "text": "Im vorherigen Kapitel haben wir die Datentabelle Tabelle 5.2 erschaffen. Bevor wir uns weiter mit statistischen Kennzahlen beschäftigen, wollen wir uns einmal die Realisierung der Tabelle Tabelle 5.2 in R anschauen. Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu können. Wir wollen später R nutzen um die explorative Datenanalyse anzuwenden. Über die explorative Datenanalyse lernen wir in späteren Kapiteln mehr.\n\n\n\n\n\n\nEinführung in R per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "eda-descriptive.html",
    "href": "eda-descriptive.html",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "",
    "text": "Wir nutzen die deskriptive Statistik um Zahlen zusammenzufassen.  Wichtig ist zu wissen, dass wir mehrere Zahlen durch meist eine oder zwei Zahlen beschreiben wollen.Eigentlich schätzen wir die Parameter einer Verteilung. Aber das kommt nochmal später genauer, wenn wir wissen was Verteilungen sind..\nNehmen wir nun das Beispiel von den Sprungweiten von Hundeflöhen. Wir messen sieben Sprungweiten von sieben Hundeflöhen und messen dabei folgende Werte in [cm]: 5.7, 8.9, 11.8, 8.2, 5.6, 9.1 und 7.6. Wir schreiben nun y als einen Vektor in der Form\n\\[\ny = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}.\n\\]\nIn R würde der Vektor wie etwas anders aussehen.\nWir wollen nun die Zahlen in \\(y\\) beschrieben und durch wenige andere Zahlen zusammenfassen. Einige der statistischen Maßzahlen sind dir vermutlich schon bekannt, andere eher neu."
  },
  {
    "objectID": "eda-descriptive.html#mittelwert",
    "href": "eda-descriptive.html#mittelwert",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.1 Mittelwert",
    "text": "10.1 Mittelwert\nDer Mittelwert einer Zahlenreihe beschreibt den Schwerpunkt der Zahlen. Der Mittelwert wird auch als Lageparameter benannt.  Wir schreiben den Mittelwert mit einem Strich über den Vektor, der die Zahlen enthält. Im folgenden ist die Formel für den Mittelwert der Sprungweite in [cm] der Hunde gezeigt. Der Mittelwert ist in dem Sinne eine künstliche Zahl, da der Mittlwert häufig nicht in den beobachteten Zahlen vorkommt.Der Mittelwert und der Median sind zwei Lageparameter einer Verteilung. Beide beschreiben die Stelle, wo die Verteilungskurve am höchsten ist.\n\n\n\n\n\n\nWir werden immer mal wieder Formeln vereinfachen. Zum Beispiel nur \\(\\sum\\) schreiben anstatt \\(\\sum_i^n\\), wenn wir einen Vektor aufsummieren und uns die Indizes sparen…\n\\[\n\\bar{y} = \\sum_{i=1}^{n}\\cfrac{x_i}{n} =\n\\cfrac{5.7 + 8.9 + 11.8 + 8.2 + 5.6 + 9.1 + 7.6}{7} =\n8.13\n\\]\nIm Durchschnitt oder im Mittel springen Hundeflöhe 8.13 cm weit.\nIn der Abbildung 10.1 wollen wir die Formel nochmal visualisieren. Vielleicht fällt dir dann der Zusammenhang von dem Index \\(i\\) und der gesamten Fallzahl \\(n\\) leichter.\n\n\nAbbildung 10.1— Zusamenhang zwischen \\(y\\) sowie dem Index \\(i\\) in der Formel für den Mittelwert.\n\n\nIn R können wir den Mittelwert einfach mit der Funktion mean() berechnen. Wir wollen dann den Mittelwert noch auf die zweite Kommastelle runden. Das machen wir dann mit der Funktion round().\n\ny %>% mean %>% round(2)\n\n[1] 8.13\n\n\nWir erhalten das gleiche Ergebnis wie oben in unserer händischen Rechnung. Die Hundeflöhe springen im Mittel 8.13 cm weit.\nDer Mittelwert ist eine bedeutende Maßzahl der Normalverteilung. Daher merken wir uns hier schon mal, dass wir den Mittelwert brauchen werden. Auch wenn wir darüber nachdenken ob sich zwei Gruppen unterscheiden, so nutzen wir hierzu den Mitelwert. Unterscheiden sich die mittleren Sprungweiten in [cm] von Hunde- und Katzenflöhen?"
  },
  {
    "objectID": "eda-descriptive.html#spannweite",
    "href": "eda-descriptive.html#spannweite",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.2 Spannweite",
    "text": "10.2 Spannweite\nDie Spannweite erlaubt uns zu überprüfen was die kleinste Zahl und die größte Zahl ist. Also uns das Minimum und das Maximum einer Zahlenreihe anzuschauen. Auf den ersten Blick mag das nicht so sinnig sein, aber wenn wir uns hunderte von Beobachtungen anschauen, wollen wir wissen, ob wir nicht einen Fehler bei Eintragen der Daten gemacht haben. Wir wissen eigentlich, dass z.B keine negativen Zuwachsraten auftreten können.\nDie Spannweite dient dazu in einem Datensatz zu übersprüfen ob die Spalte, oder auch Variable genannt, den richtigen Zahlenraum aufweist. Das machen wir durch die Funktion range().\n\\[\ny_{range} = y_{max} - y_{min} = 12.1 - 4.9 = 7.2\n\\] Die Hundeflöhe springen in einer Spannweite von 7.2 cm. Das kommt einem normal vor. Die Spannweite ist nicht übertrieben groß. Der minimale Wert ist 4.9 und der maximale Wert it 12.1 und somit sind beide Zahlen in Ordnung. Keine der beiden Zahlen ist übertrieben groß oder gar negativ.\nIn R können wir die Spannweite mit range() wie folgt berechnen. Wir erhalten den minmialen udn maximalen Wert.\n\nrange(y) \n\n[1]  5.6 11.8\n\n\nWir merken uns, dass die Spannweite eine Maßzahl für die Validität der Daten ist. Hat das Experiment geklappt oder kamen da nur komische Zahlen bei raus, die wir so in der Realität nicht erwarten würden. Zum Beispiel negative Sprungweiten, weil wir einmalauf das Minuszeichen gekommen sind."
  },
  {
    "objectID": "eda-descriptive.html#varianz",
    "href": "eda-descriptive.html#varianz",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.3 Varianz",
    "text": "10.3 Varianz\nBis jetzt können wirmit dem Mittelwert \\(\\bar{y}\\) die Lage oder den Mittelpunkt unserer Zahlenreihe beschreiben. Uns fehlt damit aber die Information über die Streuung der Zahlen. Sind die Zahlen alle eher gleich oder sehr verschieden? Liegen die Zahlen daher alle bei dem Mittelwert oder sind die Zahlen weit um den Mittelwert gestreut.\nDie Streuung der Zahlen um den Mittelwert beschreibt die Varianz oder auch \\(s^2\\). Wir berechnen die Varianz indem wir von jeder Zahl den Mittelwert aller Zahlen abziehen und dann das Ergebnis quadrieren. Das machen wir für alle Zahlen und addieren dann die Summe auf. Wir erhalten die Quadratsumme von \\(y\\).\nAbweichungsquadrate sind ein wichtiges Konzept in der Statistik. Wenn wir wissen wollen, wie groß eine Abweichung von einer Zahl zu einer anderen ist, dann nutzen wir immer das Quadrat der Abweichung und bilden die Quadratsumme..\n\\[\ns^2 = \\sum_{i=1}^n\\cfrac{(y_i - \\bar{y})^2}{n-1} = \\cfrac{(5.7 -\n8.13)^2 + ... + (7.6 - 8.13)^2}{7-1} = 4.6\n\\]\nDie Varianz berschreibt also die Streuung der Zahlen im Quadrat um den Mittelwert. Das heißt in unserem Beispiel, dass die Sprungweite eine Varianz von 4.6 cm\\(^2\\) hat. Wir können Quadratzentimeter schlecht interpretieren. Deshalb führen wir gleich die Wuzel der Varianz ein: die Standardabweichung.\nIn R lässt sich die Varianz einfach durch die Funktion var() berechnen.\n\ny %>% var %>% round(2) \n\n[1] 4.6\n\n\nWir benötigen die Varianz häufig nur als Zwischenschritt um die Standardabweichung zu berechnen. Das Konzept der Abweichungsquadrate benötigen wir aber in der Varianzanalyse (ANOVA) und für die Beschreibung einer Normalverteilung."
  },
  {
    "objectID": "eda-descriptive.html#standardabweichung",
    "href": "eda-descriptive.html#standardabweichung",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.4 Standardabweichung",
    "text": "10.4 Standardabweichung\nDie Standardabweichugn ist die Wurzel der Varianz. Wo die Varianz die Abweichung der Sprungweite in [cm\\(^2\\)] beschreibt, beschreibt die Standardabweichung die Streung der Sprungweite in [cm].\n\\[\ns = \\sqrt{s^2} = \\sqrt{4.6} = 2.14\n\\] Wir schreiben immer den Mittelwert plusminus die Standardabweichung. Also immer \\(\\bar{y} \\pm s\\).\nWir können also schreiben, dass die Flöhe im Mittel 8.13 \\(\\pm\\) 2.14cm weit springen. Somit haben wir die Lage und die Streuung der Zahlenreihe \\(y\\) der Sprungweite in [cm] mit zwei Zahlen beschrieben.\nIn R können wir die Standardabweichung einfach mit der Funktion sd() berechnen.\n\ny %>% sd %>% round(2) \n\n[1] 2.14"
  },
  {
    "objectID": "eda-descriptive.html#mittelwert-und-varianz---eine-herleitung",
    "href": "eda-descriptive.html#mittelwert-und-varianz---eine-herleitung",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.5 Mittelwert und Varianz - eine Herleitung",
    "text": "10.5 Mittelwert und Varianz - eine Herleitung\nWas ist der Mitelwert und die Varianz genau? Schauen wir uns das einmal in Abbildung 10.2 an. Die graue Linie oder Grade beschreibt den Mittelwert der fünf Beobachtungen. Die fünf Beobachtungen sind als blaue Punkt dargestellt. Auf der x-Achse ist nur der Index des Punktes. Das heißt \\(y_1\\) ist der erste Punkte, das der Index \\(i\\) gleich 1 ist.\n\n\nAbbildung 10.2— Die graue Linie beschreibt den Mittelwert der genau so durch die blauen Punkte geht, dass die Abstände der Punkte oberhalb und unterhalb zu Null aufaddieren. Die Linie liegt in der Mitte der Punkte. Die quadrierten Abstände sind die Varainz der blauen Punkte. Auf der x-Achse ist der Index des Punktes eingetragen.\n\n\nWenn wir die Summe der Abweichungen von \\(y_1\\) bis \\(y_5\\) zu dem Mittelwert bilden, so wird diese Summe 0 sein. Der Mittelwert liegt genau in der Mitte der Punkte. In unserem Beispiel ist der Mittelwert \\(\\bar{y} = 5.8\\). Wi können jetzt die Abstände wie in der folgenden Tabelle berechnen.\n\n\n\n\n\n\n\n\n\n\nIndex \\(i\\)\n\ny\n\\(\\boldsymbol{\\epsilon}\\)\n\\(\\boldsymbol{y_i - \\bar{y}}\\)\nWert\n\n\n\n1\n5\n\\(\\epsilon_1\\)\n\\(y_1 - \\bar{y}\\)\n\\(5 - 5.8 = -0.8\\)\n\n\n2\n7\n\\(\\epsilon_2\\)\n\\(y_2 - \\bar{y}\\)\n\\(7 - 5.8 = 1.2\\)\n\n\n3\n6\n\\(\\epsilon_3\\)\n\\(y_3 - \\bar{y}\\)\n\\(6 - 5.8 = 0.2\\)\n\n\n4\n4.5\n\\(\\epsilon_4\\)\n\\(y_4 - \\bar{y}\\)\n\\(4.5 - 5.8 = -1.3\\)\n\n\n5\n6.5\n\\(\\epsilon_5\\)\n\\(y_5 - \\bar{y}\\)\n\\(6.5 - 5.8 = 0.7\\)\n\n\n\n\n\n\n\nWir nennen die Abstände \\(y_i - \\bar{y}\\) nach dem griechischen Buchstaben Epsilon \\(\\epsilon\\). Das \\(\\epsilon\\) soll an das \\(e\\) von Error erinnern. So meint dann Error eben auch Abweichung. Ja, es gibt hier viele Worte für das gleiche Konzept.\nWir berechnen einen Mittelwert von den Epsilons mit \\(\\bar{\\epsilon} = 0\\). Ein Mittelwert nahe Null bzw. von Null wundert uns nicht. Wir haben die Gerade ja so gebaut, das nach oben und unten die gleichen Abstände sind. Die Varianz \\(s^2\\) der \\(y\\) ist \\(s_y^2 = 1.075\\) und die Varianz von \\(\\epsilon\\) ist \\(s_{\\epsilon}^2 = 1.075\\). In beiden Fällen ist die Zahl gleich. Wir können uns merken, dass die Epsilons einen Mittelwert von 0 haben und eine Varianz von \\(s_y^2\\).\nWir schreiben auch, dass die Residuen genannt \\(\\epsilon\\) normalverteilt sind mit \\(\\mathcal{N}(0, s_y^2)\\)."
  },
  {
    "objectID": "eda-descriptive.html#standardfehler-oder-standard-error-se",
    "href": "eda-descriptive.html#standardfehler-oder-standard-error-se",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.6 Standardfehler oder Standard Error (SE)",
    "text": "10.6 Standardfehler oder Standard Error (SE)\nWenn wir den Mittelwert der Sprungweiten berichten dann gehört die Standardabweichung der Sprungweiten mit als beschreibendes Maß dazu. Wir berichten keinen Mittelwert ohne Standardabweichung.\nNun ist es aber so, dass der Mittelwert und die Standardabweichung von der Fallzahl abhängen. Je mehr Fallzahl bzw. Beoabchtungen wir haben, desto genauer wird der Mittelwert sein. Oder anders ausgedrückt \\(\\bar{y}\\) wird sich \\(\\mu_y\\) annähern. Das gleiche gilt auch für die Standardabweichung \\(s_y\\), die sich \\(\\sigma_y\\) mit steigender Fallzahl annähert.\nAus diesem Grund brauchen wir noch einen Fehler bzw. eine Maßzahl für die Streuung, die unabhängig von der Fallzahl ist. Wir skalieren also die Standardabweichung mit der Fallzahl indem wir die Standardbweichung durch die Wurzel der Fallzahl teilen.\n\\[\nSE = \\cfrac{s}{\\sqrt{n}} = \\cfrac{2.14}{2.65} = 0.81\n\\]\nWir müssten ein Paket in R laden um den Standardfehler zu berechnen. Das Laden von zusätzlichen Paketen wollen wir hier aber vermeiden; wir können den Standardfehler auch einfach selber berechnen.\n\nse <- sd(y)/sqrt(length(y))\nse %>% round(2)\n\n[1] 0.81\n\n\nWir erhalten einen Standardfehler von 0.81. Diese Zahl ist in dem Sinne nicht zu interpretieren, da wir hier nur Experimente losgelöst von deren Fallzahl miteinander vergleichen können. Auf der anderen Seite können wir ohne die berichtete Fallzahl nicht vom Standardfehler auf die Standardabweichung schließen.\nWir berichten den Standardfehler immer zusammen mit der Fallazhl, so dass die Standardabweichung berechnet werden kann.\nWir benötigen den Standardfehler eigentlich nicht zum Berichten von Ergebnissen. Der Standardfehler ist nicht als Zahl interpretierbar und somit eine reine statistische Größe. Tabelle 10.1 zeigt die Zusammenfassung und den Vergleich von Standardabweichung und Standardfehler.\n\n\nTabelle 10.1— Zusammenfassung und Vergleich von Standardabweichung und Standardfehler\n\n\n\n\n\nStandardabweichung\nStandardfehler\n\n\n\n… ist eine Aussage über die Streuung der erhobenen Werte einer Stichprobe.\n… ist eine Aussage über die Genauigkeit des Mittelwertes einer Stichprobe.\n\n\n… hängt von der biologischen Variabilität ab.\n… abhängig von der Messgenauigkeit\n\n\n… ist ein beschreibendes Maß.\n… ist ein statistisches Maß.\n\n\n… ist nur wenig durch die Größe der Stichprobe beineinflussbar.\n… steht im direkten Verhältnis zur Größe der Stichprobe.\n\n\n\n\n\n\nDer Standardfehler oder Standard Error (SE) oder Standard Error of the Mean (SEM) wird uns wieder beim statistischen Testen und dem t-Test begegnen.\n\\[\nT_{calc} = \\cfrac{\\bar{y_1} - \\bar{y_2}}{s_p \\cdot \\sqrt{\\tfrac{2}{n}}} \\approx \\cfrac{\\bar{y_1} - \\bar{y_2}}{SEM}\n\\]\nDer Nenner beim t-Test kann als Standardfehler gesehen werden. Wir benötigen den Standardfehler also im Kontext des statistischen Testen als eine statististische Maßzahl."
  },
  {
    "objectID": "eda-descriptive.html#median",
    "href": "eda-descriptive.html#median",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.7 Median",
    "text": "10.7 Median\nWir wollen uns jetzt noch eine andere Art der Zusammenfassung von Zahlen anschauen. Anstatt mit den Zahlen zu rechnen, sortieren wir jetzt die Zahlen aus dem Vektor \\(y = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}\\) nach dem Rang. Wir rechnen dann mit den Rängen. Die kleinste Zahl kriegt den kleinsten Rang. Wir können R nutzen über due Funktion sort() um den Vektor \\(y\\) zu sortieren.\n\ny %>% sort()\n\n[1]  5.6  5.7  7.6  8.2  8.9  9.1 11.8\n\n\nDer Median \\(\\tilde{y}\\) ist die mittlere Zahl eines Zahlenvektors. Wir haben hier sieben Zahlen, also ist der Median die vierte Zahl. Wir müssen hier aber zwischen einr ungeraden Anzahl und einer geraden Anzahl unterscheiden.\n\n\nUngerade Anzahl von Zahlen, der Median ist die mittlere Zahl des Vektors \\(y\\): \\[\n5.6,  5.7,  7.6,  \\underbrace{8.2,}_{Median}  8.9,  9.1, 11.8\n\\]\n\n\nIn R können wir den Median einfach mit der Funktion median()berechnen.\n\nmedian(y) \n\n[1] 8.2\n\n\n\n\nGerade Anzahl von Zahlen, der Median ist der Mittelwert der beiden mittleren Zahlen des Vektors \\(y\\): \\[\n5.6,  5.7,  7.6,  \\underbrace{8.2, 8.9,}_{Median = \\tfrac{8.2+8.9}{2}=8.55} 9.1, 11.8, \\color{blue}{13.1}\n\\]\n\n\nIn R können wir den Median wieder einfach mit der Funktion median()berechnen. Wir müssen nur die Zahl 13.1 zu dem Vektor y mit der Funktion c() hinzufügen.\n\nc(y, 13.1) %>% median() \n\n[1] 8.55\n\n\nWenn der Mittelwert stark von dem Median abweicht, deutet dies auf eine schiefe Verteilung oder aber Ausreißer in den Daten hin. Wir müssen dann in der explorativen Datenanalyse der Sachlage nachgehen\nDer Median ist eine Alternative zu dem Mitelwert. Insbesondere in Fällen, wo es sehr große Zahlen gibt, die den Mittelwert in der Aussage verzerren, kann der Median sinnvoll sein.\n\n\n\n\n\n\nMedian versus Mittelwert\n\n\n\nZur Veranschaulichung des Unterschiedes zwischen Median und Mittelwert nehmen wir die Mietpreise in New York. Der mittlere Mietpreis für eine 2-Zimmerwohnung in Manhattan liegt bei 5000$ pro Monat. In den mittleren Mietpreis gehen aber auch die Mieten der Billionaires’ Row mit ein. Der mediane Mietpreis liegt bei 4000$. Die hohen Mieten ziehen den Mittelwert nach rechts."
  },
  {
    "objectID": "eda-descriptive.html#quantile-und-quartile",
    "href": "eda-descriptive.html#quantile-und-quartile",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.8 Quantile und Quartile",
    "text": "10.8 Quantile und Quartile\nBei dem Mittelwert beschreibt die Standardabweichung die Streuung der Daten um den Mitelwert. Bei dem Median sind dies die Quartile. Die Quartile beschreiben die Streuung der Daten um den Median. Um die Quartile bestimmen zu können, teilen wir die Daten in 100 Quantile. Du kannst dir Quantile wie Prozente vorstellen. Wir schneiden die Daten also in 100 Scheiben. Das geht natürlich erst wirklich, wenn wir hundert Zahlen haben. Deshalb hilft man sich mit Quartilen - von Quarta, ein Viertel - aus. Tabelle 10.2 zeigt den Zusammenhang.\n\n\nTabelle 10.2— Zusammenfassung und Vergleich von Quantilen, Quartilen und Median\n\nQuantile\nQuartile\nMedian\n\n\n\n25% Quantile\n1\\(^{st}\\) Quartile\n\n\n\n50% Quantile\n2\\(^{nd}\\) Quartile\nMedian\n\n\n75% Quantile\n3\\(^{rd}\\) Quartile\n\n\n\n\n\nWir bestimmen die Quartile wie den Median. Wir müssen unterscheiden, ob wir eine ungerade Anzahl an Zahlen oder eine gerade Anzahl an Zahlen vorliegen haben.\n\nUngerade Anzahl von Zahlen, das 1\\(^{st}\\) Quartile ist die mittlere Zahl des unteren Mittels und das 3\\(^{rd}\\) Quartile ist die mittlere Zahl des oberen Mittels des Vektors \\(y\\): \\[\n5.6,  \\underbrace{5.7,}_{1st\\ Quartile}  7.6,  8.2,  8.9,  \\underbrace{9.1,}_{3rd\\ Quartile} 11.8\n\\]\nGerade Anzahl von Zahlen, das 1\\(^{st}\\) Quartile ist der Mittelwert der beiden mittleren Zahl des unteren Mittels und das 3\\(^{rd}\\) Quartile ist der Mitelwert der beiden mittleren Zahlen des oberen Mittels des Vektors \\(y\\): \\[\n5.6,  \\underbrace{5.7, 7.6,}_{1st\\ Quartile = \\tfrac{5.7+7.6}{2}=6.65}    8.2,  8.9,  \\underbrace{9.1, 11.8}_{3rd\\ Quartile = \\tfrac{9.1+11.8}{2}=10.45} \\color{blue}{13.1}\n\\]\n\nDas 95% Quantile und das 97.25% Quantile werden wir später nochmal im statistischen Testen brauchen. Auch hier ist die Idee, dass wir die Daten in hundert Teile schneiden und uns dann die extremen Zahlen anschauen.\nIn R können wir den Median einfach mit der Funktion quantile() berechnen. Wir berechnen hier das 25% Quantile also das 1\\(^{st}\\) Quartile sowie das 50% Quantile also den Median und das 75% Quantile also das 3\\(^{rd}\\) Quartile.\n\ny %>% quantile(probs = c(0.25, 0.5, 0.75)) %>% round(2)\n\n 25%  50%  75% \n6.65 8.20 9.00 \n\nc(y, 13.1) %>% quantile(probs = c(0.25, 0.5, 0.75)) %>% round(2) \n\n 25%  50%  75% \n7.12 8.55 9.77 \n\n\nWarum unterscheiden sich die händisch berechneten Quartile von den Quartilen aus R? Es gibt verschiedene Arten der Berechnung. In der Klausur nutzen wir die Art und Weise wie die händische Berechnung hier beschrieben ist. Später in der Anwendung nehmen wir die Werte, die R ausgibt. Die Abweichungen sind so maginal, dass wir diese Abweichungen in der praktischen Anwendung ignorieren wollen."
  },
  {
    "objectID": "eda-descriptive.html#interquartilesabstand-iqr",
    "href": "eda-descriptive.html#interquartilesabstand-iqr",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.9 Interquartilesabstand (IQR)",
    "text": "10.9 Interquartilesabstand (IQR)\nDer Interquartilesabstand (IQR) beschreibt den Abstand zwischen dem 1\\(^{st}\\) Quartile und dem 3\\(^{rd}\\) Quartile. Daher ist der Interquartilesabstand (IQR) ähnlich der Spannweite zwischen dem maximalen und minimalen Wert. Wir benötigen das Interquartilesabstand (IQR) in der explorativen Datenanalyse wenn wir einen Boxplot erstellen wollen.\n\\[\nIQR = 3^{rd}\\,\\mbox{Quartile} - 1^{st}\\,\\mbox{Quartile} = 9.1 - 5.7 = 3.4\n\\]"
  },
  {
    "objectID": "eda-descriptive.html#zusammenfassen-von-daten-per-faktor",
    "href": "eda-descriptive.html#zusammenfassen-von-daten-per-faktor",
    "title": "\n10  Deskriptive Statistik\n",
    "section": "\n10.10 Zusammenfassen von Daten per Faktor",
    "text": "10.10 Zusammenfassen von Daten per Faktor\nGut und soll ich jetzt für jeden Faktorlevel überall den Mittelwert mit mean() berechnen? Geht das nicht einfacher? Ja, geht es. Im folgenden siehst du, wie du den verschiedene deskriptive Maßzahlen in einem Rutsch berechnen kannst.\n\ndata_tbl %>%\n  mutate(animal = as_factor(animal)) %>%\n  group_by(animal) %>%\n  summarise(mean = mean(jump_length),\n            sd = sd(jump_length),\n            median = median(jump_length),\n            quantiles = quantile(jump_length, \n                                 probs = c(0.25, 0.5, 0.75))) %>% \n  mutate(across(where(is.numeric), round, 2))\n\n# A tibble: 6 × 5\n# Groups:   animal [2]\n  animal  mean    sd median quantiles\n  <fct>  <dbl> <dbl>  <dbl>     <dbl>\n1 dog     8.13  2.14    8.2      6.65\n2 dog     8.13  2.14    8.2      8.2 \n3 dog     8.13  2.14    8.2      9   \n4 cat     4.74  1.9     4.3      3.65\n5 cat     4.74  1.9     4.3      4.3 \n6 cat     4.74  1.9     4.3      5.75"
  },
  {
    "objectID": "eda-ggplot.html",
    "href": "eda-ggplot.html",
    "title": "\n11  Visualisierung von Daten\n",
    "section": "",
    "text": "Ein wichtiger Teil in der Analyse von Daten ist die Visualisierung. Wir glauben keine Auswertung eines mathematischen Algorithmus, wenn wir nicht die Bestätigung in einer Abbildung sehen. Daher ist die Visualisierung die Grundlage für ein fundiertes, wissenschaftliches Arbeiten. In diesem Kapitel stelle ich dir verschiedene Abbilungen vor, die uns helfen werden zu Verstehen ob es einen Zusammenhang zwischen Y und X gibt."
  },
  {
    "objectID": "eda-ggplot.html#genutzte-r-pakete-für-das-kapitel",
    "href": "eda-ggplot.html#genutzte-r-pakete-für-das-kapitel",
    "title": "\n11  Visualisierung von Daten\n",
    "section": "\n11.1 Genutzte R Pakete für das Kapitel",
    "text": "11.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, ggmosaic, janitor)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "eda-ggplot.html#grundlagen-in-ggplot",
    "href": "eda-ggplot.html#grundlagen-in-ggplot",
    "title": "\n11  Visualisierung von Daten\n",
    "section": "\n11.2 Grundlagen in ggplot()",
    "text": "11.2 Grundlagen in ggplot()\nIm Gegensatz zu dem Pipe-Operator %>% nutzt ggplot den Operator + um die verschiedenen ggplot Funktionen (geom_) miteinander zu verbinden.\nWir nutzen in R das R Paket ggplot2 um unsere Daten zu visualisieren. Die zentrale Idee von ggplot2 ist, dass wir uns eine Abbildung wie ein Sandwich bauen. Zuerst legen wir eine Scheibe Brot hin und legen uns dann Scheibe für Scheibe weitere Schichten übereinander. Oder die Idee eines Bildes, wo wir erst die Leinwand definieren und dann Farbschicht über Farbschicht auftragen. Das Konzept von ggplot2ist schlecht zu beschreiben deshalb habe ich auch noch zwei Videos hierfür gemacht. Um den Prozess von ggplot2 zu visualisieren…\n\n\n\n\n\n\nGrundlagen von ggplot() im Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 16.0 - Trockenübung ggplot2 simpel und einfach erklärt als Video.\nSowie auch auf YouTube Einführung in R - Teil 16.1 - Abbildungen mit ggplot in R erstellen. Idee und Konzept von ggplot als Video. Also alles nochmal als Video - vielleicht einfacher nachzuvollziehen als in einem Fließtext.\n\n\nDie Funktion ggplot() ist die zentrale Funktion, die die Leinwand erschafft auf der wir dann verschiedene Schichten aufbringen werden. Diese Schichten heißen geom. Es gibt nicht nur ein geom sondern mehrere. Zum Beispiel das geom_boxplot für die Erstellung von Boxplots, das geom_histogram für die Erstellung von Histogrammen. Die Auswahl ist riesig. Die einzelnen Schichten werden dann über den Operator + miteinander verbunden. Soviel erstmal zur Trockenübung. Schauen wir uns das ganze einmal an einem Beispiel an.\n\n11.2.1 Datenbeispiel\nWir importieren den Datensatz flea_cat_dog.xlsx und wollen einzelne Variablen visualisieren. Wir kennen den Datensatz schon aus dem Kapitel 5. Dennoch nochmal hier der Datensatz in Tabelle 11.1.\n\nflea_dog_cat_tbl <- read_excel(\"data/flea_dog_cat.xlsx\") %>% \n  mutate(animal = as_factor(animal))\n\nSpaltennamen sind in Englisch und haben keine Leerzeichen. Die Funktion clean_names() aus dem R Paket janitor ist hier eine Hilfe.\nIm folgenden ist es wichtig, dass du dir die Spaltennamen merkst. Wir können nur die exakten, wortwörtlichen Spaltennamen verwenden. Sonst erhalten wir einen Fehler. Deshalb haben wir auch keine Leerzeichen in den Spaltennamen.\n\n\n\n\nTabelle 11.1— Beispieldatensatz für Eigenschaften von Flöhen von zwei Tierarten.\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n7\n1\n\n\ndog\n11.8\n17\n5\n1\n\n\ndog\n8.2\n12\n6\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n9\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n8\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n8\n0\n\n\n\n\n\n\n\n11.2.2 Erste Abbildung in ggplot()\nDer folgende R Code erstellt die Leinwand in der Abbildung 11.1 für die folgende, zusätzliches Schichten (geom).\n\nggplot(data = flea_dog_cat_tbl, \n       aes(x = animal , y = jump_length))\n\nWir schauen uns einmal den Code im Detail an.\n\n\nggplot ruft die Funktion auf. Die Funktion ist dafür da den Plot zu zeichnen.\n\ndata = flea_dog_cat_tbl bennent den Datensatz aus dem der Plot gebaut werden soll.\n\naes()ist die Abkürzung für aesthetics und beschreibt, was auf die x-Achse soll, was auf die y-Achse soll sowie ob es noch andere Faktoren in den Daten gibt.\n\n\nx braucht den Spaltennamen für die Variable auf der x-Achse.\n\ny braucht den Spaltennamen für die Variable auf der y-Achse.\n\n\n\nFaktoren meint hier andere Gruppenvariablen. Variablen sind ein anderes Wort für Spalten. Also Variablen die wir mit as_factorerschaffen haben.\n\n\n\n\nAbbildung 11.1— Leere ggplot() Leinwand mit den Spalten animal und jump_length aus dem Datensatz flea_dog_cat_tbl.\n\n\n\n\nWir sehen, dass wir nichts sehen in Abbildung 11.1. Der Grund ist, dass wir noch kein geom hinzugefügt haben. Das geom beschreibt nun wie die Zahlen in der Datentabelle flea_dog_cat_tbl visualisiert werden sollen."
  },
  {
    "objectID": "eda-ggplot.html#häufig-verwendete-abbildungen",
    "href": "eda-ggplot.html#häufig-verwendete-abbildungen",
    "title": "\n11  Visualisierung von Daten\n",
    "section": "\n11.3 Häufig verwendete Abbildungen",
    "text": "11.3 Häufig verwendete Abbildungen\nIn diesem Kapitel wollen wir durch die häufigsten und wichtigsten Abbildungen in der explorativen Datenanalyse durchghen. Das wären im folgenden diese Abbildungen:\n\n\nHistogramm in Kapitel 11.3.1 für mehr als 20 Beobachtungen (pro Gruppe). Wir nutzen ein Histogramm um die Verteilung einer Variable zu visualisieren.\n\nBoxplot in Kapitel 11.3.3 für 5 bis 20 Beobachtungen (pro Gruppe). Ebenso wie bei einem Histogramm, geht es bei einem Boxplot auch um die Verteilung der einer Variable.\n\nDotplot in Kapitel 11.3.4 für 3 bis 5 Beobachtungen (pro Gruppe). Hier geht es weniger um die Verteilung der Variable, sondern darum die wenigen Beobachtungen zu visualisieren.\n\nScatterplot in Kapitel 11.3.5 für zwei kontinuierliche Variablen. Auch xy-Plot genannt. Die Abbildung, die dir bekannt sein müsste. Wir zeichnen hier eine Grade durch eine Punktewolke.\n\nMosaicplot in Kapitel 11.3.6 für zwei diskrete Variablen. Eine etwas seltene Abbildung, wenn wir Variablen abbilden wollen, die diskret sind bzw. aus Kategorien bestehen.\n\nKonkret ist eine Variable gleich einer Spalte in einem Datensatz.\n\n\n\n\n\n\nHistogramm, Boxplot, Scatterplot und Mosaicplot im Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 16.2 - Histogramm, Boxplot, Scatterplot und Mosaicplot mit ggplot in R als Video. Weitere Videos werden dann noch folgen und ergänzt.\n\n\n\n11.3.1 Histogramm\nWir nutzen für die Erstellung eines Histogramms den Datensatz dog_fleas_hist.csv. Wir brauchen für ein anständiges Histogramm, wo du auch was erkennen kannst, mindestens 20 Beobachtung. Am besten mehr. Deshalb schauen wir uns jetzt einmal 39 Hunde an und zählen wieviele Flöhe die Hunde jeweils haben flea_count. Darüber hinaus bestimmen wir auch noch das mittlere Gewicht der Flöhe auf dem jeweiligen Hund flea_weight.\n\ndog_fleas_tbl <- read_csv(\"data/dog_fleas_hist.csv\")\n\n\n\n\n\nTabelle 11.2— Beispieldatensatz für die Anzahl an Flöhen auf 39 Hunden. Gezählt wurde die Anzahl an Flöhen flea_count und das gemittelte Gewicht der Flöhe flea_weight.\n\nflea_count\nflea_weight\n\n\n\n0\n0.00\n\n\n1\n7.43\n\n\n4\n21.04\n\n\n2\n20.07\n\n\n1\n21.90\n\n\n0\n0.00\n\n\n2\n24.96\n\n\n1\n27.08\n\n\n5\n16.58\n\n\n1\n19.92\n\n\n0\n0.00\n\n\n0\n0.00\n\n\n2\n24.63\n\n\n4\n21.64\n\n\n3\n20.97\n\n\n1\n23.15\n\n\n0\n0.00\n\n\n3\n14.91\n\n\n1\n19.39\n\n\n2\n17.66\n\n\n1\n19.15\n\n\n1\n25.10\n\n\n2\n26.38\n\n\n2\n19.33\n\n\n2\n13.29\n\n\n1\n17.81\n\n\n0\n0.00\n\n\n2\n23.56\n\n\n1\n18.64\n\n\n1\n15.64\n\n\n3\n19.88\n\n\n1\n18.40\n\n\n1\n25.17\n\n\n0\n0.00\n\n\n0\n0.00\n\n\n\n\n\n\nTabelle 11.2 zeigt den Datensatz dog_fleas_hist.csv. Wir wollen jetzt die Variable flea_count und flea_weight jeweils abbilden.\n\n\n\n\nAbbildung 11.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\nggplot(data = dog_fleas_tbl, aes(x = flea_weight)) +\n  geom_histogram(binwidth = 1, fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Gewicht [mg]\", y = \"Anzahl\") \n\n\n\nAbbildung 11.3— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\n\n\n\nAbbildung 11.4— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nWenn wir viele Beobachtungen haben. Viele meint mehr als zwanzig Beobachtungen.\n\n\n[1] 13.29 14.91 15.64 16.58 17.66 17.81 18.40 18.64\n\n\n\n\nAn 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\n\n\n\nAn 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\n11.3.2 Density Plot\n\nggplot(data = dog_fleas_tbl, aes(x = flea_count)) +\n  geom_density(fill = \"gray\", color = \"black\") +\n  theme_bw()\n\n\n\nAbbildung 11.5— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\nggplot(data = dog_fleas_tbl, aes(x = flea_weight)) +\n  geom_density(fill = \"gray\", color = \"black\") +\n  theme_bw()\n\n\n\nAbbildung 11.6— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nWenn wir viele Beobachtungen.\n\n11.3.3 Boxplot\n\n\nAbbildung 11.7— kjasdsaddssd\n\n\nAbbildung 11.7\n\n\nAbbildung 11.8— kjasdsaddssd\n\n\n\n\nAbbildung 11.9— kjasdsaddssd\n\n\nAbbildung 11.7\nAbbildung 11.8\nAbbildung 11.9\n\ndog_fleas_tbl <- read_csv(\"data/dog_fleas_hist.csv\")\n\n\n\n\n\nAbbildung 11.10— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\ndog_fleas_tbl <- read_csv(\"data/dog_fleas_hist.csv\")\n\n\ndata_tbl <- read_excel(file.path(\"data/germination_data.xlsx\"))\n\n\ndata_tbl %>% kable(align = \"c\", \"pipe\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\nt1\nt2\nt3\nt4\nfreshmatter\ndrymatter\ncount_small_leaf\ncount_large_leaf\nroot_intensity\nroot_health\nleaf_quality\n\n\n\ncontrol\n16\n21\n23\n23\n13.7\n0.98\n2\n12\n9\n9\n9\n\n\ncontrol\n17\n19\n18\n24\n18.1\n1.31\n4\n12\n8\n9\n9\n\n\ncontrol\n16\n22\n23\n24\n14.4\n1.01\n4\n12\n7\n9\n9\n\n\ncontrol\n9\n17\n18\n21\n10.7\n0.74\n2\n12\n8\n9\n9\n\n\ncontrol\n17\n21\n22\n24\n15.9\n1.11\n2\n12\n7\n9\n9\n\n\nlow\n18\n22\n21\n21\n26.4\n1.90\n10\n18\n6\n8\n8\n\n\nlow\n17\n19\n20\n20\n24.3\n1.68\n8\n14\n5\n7\n7\n\n\nlow\n15\n15\n15\n15\n27.1\n1.87\n6\n18\n5\n8\n8\n\n\nlow\n19\n24\n24\n23\n27.2\n1.80\n4\n18\n6\n7\n7\n\n\nlow\n17\n19\n22\n22\n18.2\n1.22\n6\n18\n6\n8\n7\n\n\nmid\n16\n21\n21\n24\n20.9\n1.31\n6\n8\n4\n9\n5\n\n\nmid\n19\n27\n30\n30\n19.4\n1.41\n4\n8\n4\n8\n3\n\n\nmid\n16\n23\n26\n25\n21.5\n1.44\n4\n14\n4\n8\n4\n\n\nmid\n15\n22\n21\n22\n24.0\n1.56\n6\n11\n2\n9\n3\n\n\nmid\n20\n25\n25\n25\n25.8\n1.77\n6\n11\n5\n9\n1\n\n\nhigh\n22\n25\n25\n24\n30.9\n2.22\n6\n24\n8\n5\n4\n\n\nhigh\n25\n25\n26\n26\n36.3\n2.52\n2\n19\n9\n5\n8\n\n\nhigh\n15\n19\n19\n19\n25.6\n1.82\n4\n22\n9\n7\n7\n\n\nhigh\n17\n22\n22\n22\n33.3\n2.27\n6\n22\n9\n6\n8\n\n\nhigh\n22\n22\n22\n22\n30.4\n2.14\n6\n22\n9\n6\n9\n\n\n\n\n\n\ndata_tbl <- data_tbl %>% \n  select(treatment, freshmatter, drymatter, root_health)\n\n\nggplot(data = data_tbl, aes(x = treatment, y = freshmatter,\n                            fill = treatment)) +\n  geom_boxplot() +\n  theme_bw()\n\n\n\nAbbildung 11.11— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\n\nggplot(data = data_tbl, aes(x = treatment, y = freshmatter,\n                            fill = treatment)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.25, shape = 1) +\n  theme_bw()\n\n\n\nAbbildung 11.12— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nWenn wir wenige Beobachtungen haben.\n\n11.3.4 Dotplot\nWenn wir ganz wenige Beobachtungen haben.\n\nggplot(data = data_tbl, aes(x = treatment, y = root_health,\n                            fill = treatment)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\") +\n  theme_bw()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(data = data_tbl, aes(x = freshmatter, fill = treatment)) +\n  geom_dotplot(method=\"histodot\", binwidth = 2.5) +\n  theme_bw()\n\n\n\n\n\nggplot(data = data_tbl, aes(x = treatment, y = freshmatter,\n                            fill = treatment)) +\n  geom_violin() +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", fill = \"black\") +\n  theme_bw()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(data = data_tbl, aes(x = treatment, y = root_health,\n                            fill = treatment)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\") +\n  stat_summary(fun = median, fun.min = median, fun.max = median,\n               geom = \"crossbar\", width = 0.5) +\n  theme_bw()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`.\n\n\n\n\n\n\n11.3.5 Scatterplot\n\nggplot(data = data_tbl, aes(x = freshmatter, y = drymatter)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  theme_bw()\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n11.3.6 Mosaic Plot\n\nflea_dog_cat_tbl %>%\n  tabyl(animal, infected) \n\n animal 0 1\n    dog 4 3\n    cat 5 2\n\nggplot(data = flea_dog_cat_tbl) +\n  geom_mosaic(aes(x = product(animal, infected), fill = animal)) \n\n\n\n\n\n11.3.7 Abbildungen beschriften\n\nggplot(data = data_tbl, aes(x = treatment, y = freshmatter,\n                            fill = treatment)) +\n  geom_boxplot() +\n  labs(title = \"Frischgewicht in Abhängigkeit von der Behandlung\",\n       x = \"Behandlung\", y = \"Frischgewicht in kg/ha\",\n       fill = \"Behandlung\") +\n  theme_bw()\n\n\n\n\nhttps://ggplot2.tidyverse.org/reference/index.html"
  },
  {
    "objectID": "stat-tests-preface.html",
    "href": "stat-tests-preface.html",
    "title": "Frequentistische Hypothesentests",
    "section": "",
    "text": "Logik der Forschung\n\n\n\n„Das ist die Logik der Forschung, die nie verifizieren, sondern immer nur jene Erklärungen beibehalten kann, die beim derzeitigen Erkenntnisstand am wenigsten falsifiziert sind.” – Wößmann, L.\nWir ersetzen schlechte Modelle (der Wirklichkeit) durch weniger schlechte Modelle (der Wirklichkeit)."
  },
  {
    "objectID": "stat-tests-preface.html#der-t-test",
    "href": "stat-tests-preface.html#der-t-test",
    "title": "Frequentistische Hypothesentests",
    "section": "Der t-Test",
    "text": "Der t-Test\nKapitel 13\n\n\n\n\n\n\nWas macht der t-Test?\n\n\n\nDer t-Test vergleicht die Parameter zweier Normalverteilungen miteinander.\nDie Parameter einer Normalverteilung sind der Mittelwert und die Standardabweichung.\n\\(\\mathcal{N}(0, 1)\\)\n\n\n\n\n\n\n\n\nEinführung in den t-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-preface.html#die-anova",
    "href": "stat-tests-preface.html#die-anova",
    "title": "Frequentistische Hypothesentests",
    "section": "Die ANOVA",
    "text": "Die ANOVA\n\n\n\n\n\n\nWas macht die ANOVA?\n\n\n\nDie ANOVA vergleicht die Parameter mehrerer Normalverteilungen miteinander.\nDie Parameter einer Normalverteilung sind der Mittelwert und die Standardabweichung.\n\\(\\mathcal{N}(0, 1)\\)\n\n\n\n\n\n\n\n\nEinführung in die ANOVA per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-preface.html#der-wilcoxon-mann-whitney-test",
    "href": "stat-tests-preface.html#der-wilcoxon-mann-whitney-test",
    "title": "Frequentistische Hypothesentests",
    "section": "Der Wilcoxon-Mann-Whitney-Test",
    "text": "Der Wilcoxon-Mann-Whitney-Test\n\n\n\n\n\n\nWas macht der Wilcoxon-Mann-Whitney-Test?\n\n\n\nDer Wilcoxon-Mann-Whitney-Test vergleicht die Mediane zweier beliebiger Verteilungen miteinander.\n\n\n\n\n\n\n\n\nEinführung in den Wilcoxon-Mann-Whitney-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-preface.html#der-kruskal-wallis-test",
    "href": "stat-tests-preface.html#der-kruskal-wallis-test",
    "title": "Frequentistische Hypothesentests",
    "section": "Der Kruskal-Wallis-Test",
    "text": "Der Kruskal-Wallis-Test\n\n\n\n\n\n\nWas macht der Kruskal-Wallis-Test?\n\n\n\nDer Kruskal-Wallis-Test vergleicht die Mediane mehrerer beliebiger Verteilungen miteinander.\n\n\n\n\n\n\n\n\nEinführung in den Kruskal-Wallis-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-preface.html#lineare-regression",
    "href": "stat-tests-preface.html#lineare-regression",
    "title": "Frequentistische Hypothesentests",
    "section": "Lineare Regression",
    "text": "Lineare Regression\n\n\n\n\n\n\nWas macht die lineare Regression?\n\n\n\nEine Regression ist der Mittelwert als Linie durch eine Punktwolke.\n\n\n\n\n\n\n\n\nEinführung in die lineare Regression per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-preface.html#der-mathcalx2-test",
    "href": "stat-tests-preface.html#der-mathcalx2-test",
    "title": "Frequentistische Hypothesentests",
    "section": "Der \\(\\mathcal{X}^2\\)-Test",
    "text": "Der \\(\\mathcal{X}^2\\)-Test\n\n\n\n\n\n\nWas macht der \\(\\mathcal{X}^2\\)-Test?\n\n\n\nEin \\(\\mathcal{X}^2\\)-Test vergleicht die Anteile zweier Gruppen.\n\n\n\n\n\n\n\n\nEinführung in den \\(\\mathcal{X}^2\\)-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-decision.html#fischer-vs.-neyman-pearson",
    "href": "stat-tests-decision.html#fischer-vs.-neyman-pearson",
    "title": "\n12  Statistisches Testen\n",
    "section": "\n12.1 Fischer vs. Neyman-Pearson",
    "text": "12.1 Fischer vs. Neyman-Pearson"
  },
  {
    "objectID": "stat-tests-decision.html#die-testentscheidung",
    "href": "stat-tests-decision.html#die-testentscheidung",
    "title": "\n12  Statistisches Testen\n",
    "section": "\n12.2 Die Testentscheidung…",
    "text": "12.2 Die Testentscheidung…\n\n\n\nTabelle 12.1— test\n\n\n\n\n\n\n\n\n\nTeststatistik\np-Wert\n95% Konfidenzintervall\n\n\n\n\\(T_{calc}\\)\n\\(Pr(\\geq T_{\\alpha}|H_0)\\)\nKI\\(_{1-\\alpha}\\)\n\n\n\nH\\(_0\\) ablehnen\n\\(T_{calc} \\geq T_{\\alpha = 5\\%}\\)\n\\(Pr(\\geq T_{\\alpha}| H_0) \\leq \\alpha\\)\nBei \\(\\Delta_{A-B}\\): enthält nicht 0 oder bei \\(\\Delta_{A/B}\\): enthält nicht 1\n\n\n\n\n\nDas ist ein Text Tabelle 12.1\n\n12.2.1 … anhand der Teststatistik \\(T_{calc}\\)\n\n\n\nAbbildung 12.1— kjk\n\n\nAbbildung 12.1\n\n\n\n\n\n\nEntscheidung mit der berechneten Teststatistik\n\n\n\nBei der Entscheidung mit der Teststatistik müssen wir zwei Fälle unterschieden.\n\nBei einem t-Test und einem \\(\\mathcal{X}^2\\)-Test gilt, wenn \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\nBei einem Wilcoxon-Mann-Whitney-Test gilt, wenn \\(T_{calc} < T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\n\nAchtung – Wir nutzen die Entscheidung mit der Teststatistik nur und ausschließlich in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik keine Verwendung mehr.\n\n\n\n12.2.2 … anhand dem p-Wert \\(Pr(T|H_0)\\)\n\n\n\n\n\n\n\nEntscheidung mit dem p-Wert\n\n\n\nWenn der p-Wert \\(\\leq \\alpha\\) dann wird die Nullhypothese (H\\(_0\\)) abgelehnt. Das Signifikanzniveau \\(\\alpha\\) wird als Kulturkonstante auf 5% oder 0.05 gesetzt. Die Nullhypothese (H\\(_0\\)) kann auch Gleichheitshypothese gesehen werden. Wenn die H\\(_0\\) gilt, liegt kein Unterschied zwischen z.B. den Behandlungen vor.\n\n\n\n12.2.3 … anhand des 95% Konfidenzintervall\n\n\nAbbildung 12.2— kj\n\n\nAbbildung 12.2\n\n\n\\((\\bar{y}_{1}-\\bar{y}_{2})\\) ist der Effekt. In diesem Fall der Mittelwertsunterschied. Wir finden den Effekt als Punkt in der Mitte des Intervals.\n\n\\(T_{\\alpha = 5\\%} \\cdot \\frac {s_p}{\\sqrt{n_g}}\\) ist ein fester Wert, der die Arme des Intervals bildet. Wir vereinfachen die Formel mit \\(s_p\\) für die gepoolte Standardabweichung und \\(n_g\\) für die Fallzahl der beiden Gruppen. Wir nehmen an das beide Gruppen die gleiche Fallzahl \\(n_1 = n_2\\) haben.\n\n\n\nAbbildung 12.3— kjasdsa\n\n\nAbbildung 12.3\n\nNicht signifikant und nicht relevant\nSignifikant und nicht relevant\nSignifikant und relevant\nSignifikant und nicht relevant\n\n\\[\n\\left[\n(\\bar{y}_{dog}-\\bar{y}_{cat}) -\nT_{\\left( 1-\\tfrac{\\alpha}{2} \\right)} \\cdot \\frac {s_p}{\\sqrt{n_g}}; \\;\n(\\bar{y}_{dog}-\\bar{y}_{cat}) +\nT_{\\left( 1-\\tfrac{\\alpha}{2} \\right)} \\cdot \\frac {s_p}{\\sqrt{n_g}};\n\\right]\n\\]\n\n\n\n\n\n\nEntscheidung mit dem 95% Konfidenzintervall\n\n\n\nBei der Entscheidung mit dem 95% Konfidenzinterval müssen wir zwei Fälle unterscheiden.\n\nEntweder schauen wir uns einen Mittelwertsunterschied (\\(\\Delta_{A-B}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 0 im 95% Konfidenzinterval ist.\nOder wir schauen uns einen Anteilsunterschied (\\(\\Delta_{A/B}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 1 im 95% Konfidenzinterval ist.\n\n\n\n\n12.2.4 Einseitig oder zweiseitig?"
  },
  {
    "objectID": "stat-tests-decision.html#der-effektschätzer-delta",
    "href": "stat-tests-decision.html#der-effektschätzer-delta",
    "title": "\n12  Statistisches Testen\n",
    "section": "\n12.3 Der Effektschätzer \\(\\Delta\\)\n",
    "text": "12.3 Der Effektschätzer \\(\\Delta\\)\n\n\n12.3.1 Unterschied zweier Mittelwerte\nWir berechnen zwei Mittelwerte \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\). Wenn wir wissen wollen wie groß der Effekt zwischen den beiden Mittelwerten ist, dann bilden wir die Differenz. Wir berechnen das \\(\\Delta\\) von \\(y_1\\) und \\(y_2\\) indem wir die Diffenz bilden.\n\\[\n\\Delta_{y_1-y_2} = \\bar{y}_1 - \\bar{y}_2\n\\]\nWenn es keinen Unterschied zwischen den beiden Mittelwerten \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\) gibt, dann ist die Differenz \\(\\Delta_{y_1-y_2} = \\bar{y}_1 - \\bar{y}_2\\) gleich 0.\n\\[\nH_0: \\Delta_{y_1-y_2} = \\bar{y}_1 - \\bar{y}_2 = 0\n\\]\nIn Tabelle 12.2 ist eine Datenbeispiel gegeben.\n\n\n\n\nTabelle 12.2— Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.\n\nanimal\njump_length\n\n\n\ncat\n8.0\n\n\ncat\n7.9\n\n\ncat\n8.3\n\n\ncat\n9.1\n\n\ndog\n8.0\n\n\ndog\n7.8\n\n\ndog\n9.2\n\n\ndog\n7.7\n\n\n\n\n\n\nNehmen wir an, wir berechnen für die Sprungweite [cm] der Hundeflöhe einen Mittelwert von \\(\\bar{y}_{dog} = 8.2\\) und für die Sprungweite [cm] der Katzenflöhe einen Mittelwert von \\(\\bar{y}_{cat} =8.3\\). Wie große ist nun der Effekt? Oder anders gesprochen, welchen Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu sein? Was ist also der Effekt von animal? Wir rechnen \\(\\bar{y}_{dog} - \\bar{y}_{cat} = 8.2 - 8.3 = -0.1\\). Zum einen wissen wir jetzt “die Richtung”. Da wir ein Minus vor dem Mittelwertsunterschied haben, müssen die Katzenflöhe weiter springen als die Hundeflöhe, nämlich 0,1cm. Dennoch ist der Effekt sehr klein.\n\n12.3.2 Unterschied zweier Anteile\nNeben den Unterschied zweier Mittelwerte ist auch häufig das Interesse an dem Unterschied zwischen zwei Wahrscheinlichkeiten oder auch Anteilen. Ebenso kann die Chance berechnet werden. Hier tritt häufig Verwirrung auf, daher hier zuerst ein Beispiel.\n\n\nTabelle 12.3— Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils.\n\n\n\n\nInfected\n\n\n\n\n\nYes (1)\nNo (0)\n\n\nAnimal\nDog\n\\(23_{\\;\\Large a}\\)\n\\(10_{\\;\\Large b}\\)\n\n\n\nCat\n\\(18_{\\;\\Large c}\\)\n\\(14_{\\;\\Large d}\\)\n\n\n\n\nAus der Tabelle 12.3 können wir entnehmen, dass 23 Hunde mit Flöhen infiziert sind und 10 Hunde keine Infektion aufweisen. Bei den Katzen haben wir 18 infizierte und 14 gesunde Tiere beobachtet. Wir können nun zwei Arten von Anteilen berechnen. Das bekanntere ist die Frequenz oder Wahrscheinlichkeit oder Risk Ratio (RR). Das andere ist das Chancenverhältnis oder Odds Ratio (OR). Beide kommen in der Statistik vor und sind unterschiedlich zu interpretieren.\n\n12.3.2.1 Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)\n\\[\nPr(\\mbox{dog}|\\mbox{infected}) = \\cfrac{a}{a+c} = \\cfrac{23}{23+10} \\approx 0.67\n\\]\n\\[\nPr(\\mbox{cat}|\\mbox{infected}) = \\cfrac{b}{b+d} = \\cfrac{18}{18+14} \\approx 0.56\n\\]\n\\[\n\\Delta_{y_1/y_2} = RR = \\cfrac{Pr(\\mbox{dog}|\\mbox{infected})}{Pr(\\mbox{cat}|\\mbox{infected})} =  \\cfrac{0.67}{0.56} \\approx 1.2\n\\]\n\n12.3.2.2 Chancenverhältnis oder Odds Ratio (OR)\n\\[\nOdds(\\mbox{dog}|\\mbox{infected}) = a:b = 23:10 = \\cfrac{23}{10} = 2.3\n\\]\n\\[\nOdds(\\mbox{cat}|\\mbox{infected}) = c:d = 18:14 = \\cfrac{18}{14} \\approx 1.29\n\\]\n\\[\n\\Delta_{y_1/y_2} = OR =  \\cfrac{Odds(\\mbox{dog}|\\mbox{infected})}{Odds(\\mbox{cat}|\\mbox{infected})} = \\cfrac{a \\cdot d}{b \\cdot c} = \\cfrac{2.30}{1.29} \\approx 1.78\n\\]\nWann liegt nun kein Effekt bei einem Anteil wie dem RR oder OR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe. Dies gilt sowohl fürdas RR als auch das OR.\n\\[\nH_0: RR = \\cfrac{Pr(\\mbox{dog}|\\mbox{infected})}{Pr(\\mbox{cat}|\\mbox{infected})} = 1\n\\]\n\\[\nH_0: OR =  \\cfrac{Odds(\\mbox{dog}|\\mbox{infected})}{Odds(\\mbox{cat}|\\mbox{infected})} = 1\n\\]\n\n\n\n\n\n\nStärke eines Effektes\n\n\n\nDu musst immer den Effekt, hier den Mittelwertsunterschied, im Kontext der Fragestellung bzw. des Outcomes \\(y\\) bewerten. Der numerische Unterschied von 0,1cm kann in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein Unterschied von 0,1cm sehr viel sein. Oder aber sehr wenig, wenn wir uns das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage, ob ein Unterschied von 6% viel oder wenig ist…\n\n\n\n\n\n\n\n\nEffektschätzer\n\n\n\nWenn wir uns einen Unterschied eines Mittelwerts anschauen, dann haben wir keinen Effekt vorliegen, wenn das \\(\\Delta\\) zwischen \\(A\\) und \\(B\\) gleich 0 ist. Die Nullhypothese gilt.\n\\[\n\\Delta_{A-B} = A - B = 0\n\\] Wenn wir uns einen Unterschied eines Anteils anschauen, dann haben wir keinen Effekt vorliegen, wenn das \\(\\Delta\\) zwischen \\(A\\) und \\(B\\) gleich 1 ist. Die Nullhypothese gilt.\n\\[\n\\Delta_{A/B} = \\cfrac{A}{B} = 1\n\\]\nDieses Wissen brauchen wir um später die Signifikanzschwelle bei einem 95% Konfidenzintervall richtig zu setzen und interpretieren zu können."
  },
  {
    "objectID": "stat-tests-ttest.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-tests-ttest.html#genutzte-r-pakete-für-das-kapitel",
    "title": "13  Der t-Test",
    "section": "\n13.1 Genutzte R Pakete für das Kapitel",
    "text": "13.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, broom)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-tests-ttest.html#die-wichtigkeit-des-t-tests",
    "href": "stat-tests-ttest.html#die-wichtigkeit-des-t-tests",
    "title": "13  Der t-Test",
    "section": "\n13.2 Die Wichtigkeit des t-Tests",
    "text": "13.2 Die Wichtigkeit des t-Tests\n\\[\n\\text{Teststatistik} = \\cfrac{\\text{Signal}}{\\text{Noise}}\n\\]\n\n\n\n\nTabelle 13.1— test caption\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n7\n1\n\n\ndog\n11.8\n17\n5\n1\n\n\ndog\n8.2\n12\n6\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n9\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n8\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n8\n0\n\n\n\n\n\n\nBeispieldaten sind in Tabelle 13.1 abgebildet.\n\n\n\n\nAbbildung 13.1— Boxplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nDas ist das Beispiel Abbildung 13.1\n\n\n\n\nAbbildung 13.2— Dotplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nDas ist das Beispiel Abbildung 13.2"
  },
  {
    "objectID": "stat-tests-ttest.html#student-t-test",
    "href": "stat-tests-ttest.html#student-t-test",
    "title": "13  Der t-Test",
    "section": "\n13.3 Student t-Test",
    "text": "13.3 Student t-Test\n\nsum_tbl <- data_tbl %>% \n  group_by(animal) %>% \n  summarise(mean = round(mean(jump_length), 2), sd = round(sd(jump_length), 2)) \n\nsd_pool <- (sum_tbl$sd[1] + sum_tbl$sd[2])/2\nt_student <- round((sum_tbl$mean[1] - sum_tbl$mean[2])/(sd_pool * sqrt(2/7)), 2)\n\n\\[\nT_{calc} = \\cfrac{\\bar{y}_1-\\bar{y}_2}{s_{pooled} \\cdot \\sqrt{\\cfrac{2}{n_{group}}}}\n\\]\nFoo\n\n\n\n\n\n\nEigentlich wäre hier folgende Formel richtig…\n\\[\ns_{pooled} = \\sqrt{\\frac{1}{2} (s^2_{y_1} + s^2_{y_2})}\n\\] …aber auch hier erwischen wir einen Statistikengel um es etwas einfacher zu machen.\n\\[\ns_{pooled} = \\cfrac{s_{y_1} + s_{y_2}}{2}\n\\]\n\\[\ns_{pooled} = \\cfrac{2.14 + 1.9}{2} = 2.02\n\\]\n\\[\nT_{calc} = \\cfrac{8.13- 4.74}{2.02 \\cdot \\sqrt{\\cfrac{2}{7}}} = 3.14\n\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  jump_length by animal\nt = 3.12528, df = 12, p-value = 0.0087684\nalternative hypothesis: true difference in means between group dog and group cat is not equal to 0\n95 percent confidence interval:\n 1.0253394 5.7460892\nsample estimates:\nmean in group dog mean in group cat \n        8.1285714         4.7428571 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = TRUE) %>% \n  tidy() \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>\n1     3.39      8.13      4.74      3.13 0.00877        12     1.03      5.75\n# … with 2 more variables: method <chr>, alternative <chr>"
  },
  {
    "objectID": "stat-tests-ttest.html#welch-t-test",
    "href": "stat-tests-ttest.html#welch-t-test",
    "title": "13  Der t-Test",
    "section": "\n13.4 Welch t-Test",
    "text": "13.4 Welch t-Test\n\\[\nT_{calc} = \\cfrac{\\bar{y_1} - \\bar{y_2}}{\\sqrt{\\cfrac{s^2_{y_1}}{n} + \\cfrac{s^2_{y_2}}{m}}}\n\\]\nHier muss man noch bedenken, dass die Freiheitsgrade anders berechnte werden Die Freiheitsgrade werden mit11 \\[df = \\cfrac{\\left(\\cfrac{s^2_{y_1}}{n} +\n\\cfrac{s^2_{y_2}}{m}\\right)^2}{\\cfrac{\\left(\\cfrac{s^2_{y_1}}{n}\\right)^2}{n-1} + \\cfrac{\\left(\\cfrac{s^2_{y_2}}{m}\\right)^2}{m-1}}\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  jump_length by animal\nt = 3.12528, df = 11.8307, p-value = 0.008906\nalternative hypothesis: true difference in means between group dog and group cat is not equal to 0\n95 percent confidence interval:\n 1.0215869 5.7498416\nsample estimates:\nmean in group dog mean in group cat \n        8.1285714         4.7428571 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = FALSE) %>% \n  tidy() \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>\n1     3.39      8.13      4.74      3.13 0.00891      11.8     1.02      5.75\n# … with 2 more variables: method <chr>, alternative <chr>"
  },
  {
    "objectID": "stat-tests-ttest.html#verbundener-t-test-paired-t-test",
    "href": "stat-tests-ttest.html#verbundener-t-test-paired-t-test",
    "title": "13  Der t-Test",
    "section": "\n13.5 Verbundener t-Test (Paired t-Test)",
    "text": "13.5 Verbundener t-Test (Paired t-Test)\n\\[\nT_{calc} = \\sqrt{n}\\cfrac{\\bar{d}}{s_d}\n\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  jump_length by animal\nt = 3.76033, df = 6, p-value = 0.0093949\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.1825691 5.5888595\nsample estimates:\nmean difference \n      3.3857143 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, paired = TRUE) %>% \n  tidy() \n\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>      \n1     3.39      3.76 0.00939         6     1.18      5.59 Paired t-… two.sided"
  },
  {
    "objectID": "stat-tests-ttest.html#rest-formeln",
    "href": "stat-tests-ttest.html#rest-formeln",
    "title": "13  Der t-Test",
    "section": "\n13.6 Rest Formeln",
    "text": "13.6 Rest Formeln\n\\[\nPr\\left(\\left.\\cfrac{\\bar{y}_1-\\bar{y}_2}{s_{y_1,\\,y_2} \\cdot \\sqrt{2/n_g}}\\right| \\bar{y}_1-\\bar{y}_2=0\\right)\n\\]\n\\[\nPr\\left(\\left.\\cfrac{\\Delta_{y_1,\\, y_2}}{s_{y_1,\\,y_2} \\cdot \\sqrt{2/n_g}}\\right| \\Delta_{y_1,\\,y_2}=0\\right)\n\\]\n\\[\nPr\\left(\\left.T_{\\alpha = 5\\%}\\right| \\Delta_{y_1,\\,y_2}=0\\right)\n\\]\n\\[\nT = \\cfrac{\\Delta \\cdot n}{s}\n\\]\n\\[\n\\text{Pr}(D | H_0)\n\\]\n\\[\\begin{align*}\nT_{calc} &= \\cfrac{7.24 - 9.71}{6.45 \\cdot \\sqrt{\\frac{2}{7.5}}} \\\\  \n&= \\cfrac{-2.47}{6.45 \\cdot 0.52} \\\\\n&= \\cfrac{-2.47}{3.354} = -0.73\n\\end{align*}\\]\n\\[\\begin{align*}\nH_0: \\bar{y}_{dog} &= \\bar{y}_{cat} \\\\  \nH_A: \\bar{y}_{dog} &\\neq \\bar{y}_{cat} \\\\   \n\\end{align*}\\]"
  },
  {
    "objectID": "stat-tests-chi-test.html",
    "href": "stat-tests-chi-test.html",
    "title": "\n14  \\(\\mathcal{X}^2\\)-Test\n",
    "section": "",
    "text": "Text Tabelle 14.1\n\n\nTabelle 14.2— Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils.\n\n\n\n\n\n\n\n\n\n\n\nInfected\n\n\n\n\n\n\nYes (1)\nNo (0)\n\n\n\nAnimal\nDog\n\\(\\cfrac{41 \\cdot 33}{65} = 20.82\\)\n\\(\\cfrac{24 \\cdot 33}{65} = 12.18\\)\n\\(\\mathbf{33}\\)\n\n\n\nCat\n\\(\\cfrac{41 \\cdot 32}{65} = 20.18\\)\n\\(\\cfrac{24 \\cdot 32}{65} = 11.82\\)\n\\(\\mathbf{32}\\)\n\n\n\n\n\\(\\mathbf{41}\\)\n\\(\\mathbf{24}\\)\n\\(n = 65\\)\n\n\n\n\nText Tabelle 14.2\n\\[\n\\chi^2 = \\cfrac{(O - E)^2}{E}\n\\]\n\\[\\begin{align*}\n\\chi^2 &= \\cfrac{(23 - 20.82)^2}{20.82} + \\cfrac{(10 - 12.18)^2}{12.18} + \\\\\n&\\phantom{=}\\;\\; \\cfrac{(18 - 20.18)^2}{20.18} + \\cfrac{(14 - 11.82)^2}{11.82} = 1.25\n\\end{align*}\\]\nTest\n\nmat <- matrix(c(23, 10, 18, 14), byrow = TRUE, nrow = 2)\nchisq.test(mat, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  mat\nX-squared = 1.26134, df = 1, p-value = 0.2614\n\n\n\\(\\chi^2_{\\alpha=5\\%} = 3.84\\)"
  },
  {
    "objectID": "distributions-preface.html",
    "href": "distributions-preface.html",
    "title": "Verteilungen",
    "section": "",
    "text": "https://rstudio-pubs-static.s3.amazonaws.com/100906_8e3a32dd11c14b839468db756cee7400.html"
  },
  {
    "objectID": "distributions-preface.html#normalverteilung",
    "href": "distributions-preface.html#normalverteilung",
    "title": "Verteilungen",
    "section": "Normalverteilung",
    "text": "Normalverteilung\nKapitel 15"
  },
  {
    "objectID": "distributions-preface.html#poissonverteilung",
    "href": "distributions-preface.html#poissonverteilung",
    "title": "Verteilungen",
    "section": "Poissonverteilung",
    "text": "Poissonverteilung\nKapitel 16\nHundeffloh Beispiel in groß!!! Dormann (2013) Hurlbert (1984)\n\n\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer.\n\n\nHurlbert, Stuart H. 1984. „Pseudoreplication and the design of ecological field experiments“. Ecological monographs 54 (2): 187–211."
  },
  {
    "objectID": "distributions-normal.html",
    "href": "distributions-normal.html",
    "title": "15  Die Normalverteilung",
    "section": "",
    "text": "Abbildung 15.1— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung 15.1\n\n\n\n\nAbbildung 15.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung 15.2"
  },
  {
    "objectID": "distributions-poisson.html",
    "href": "distributions-poisson.html",
    "title": "16  Die Poissonverteilung",
    "section": "",
    "text": "An 39 Hunden wurde die Anzahl an Flöhen gezählt."
  },
  {
    "objectID": "app-example-analysis.html#genutzte-r-pakete-für-das-kapitel",
    "href": "app-example-analysis.html#genutzte-r-pakete-für-das-kapitel",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.1 Genutzte R Pakete für das Kapitel",
    "text": "A.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, \n               broom, multcomp, emmeans, \n               conflicted)\n\n## resolve some conflicts with same function naming\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-gewichten",
    "href": "app-example-analysis.html#auswertung-von-gewichten",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.2 Auswertung von Gewichten",
    "text": "A.2 Auswertung von Gewichten\n\n\n\n\n\n\n\ntrt\nblock\nrep\nrsp\n\n\n\nlow\nI\n1\n11.03\n\n\nlow\nI\n2\n14.29\n\n\nlow\nI\n3\n8.75\n\n\nlow\nI\n4\n15.63\n\n\nlow\nII\n1\n13.45\n\n\nlow\nII\n2\n14.18\n\n\nlow\nII\n3\n13.85\n\n\nlow\nII\n4\n19.24\n\n\nlow\nIII\n1\n12.86\n\n\nlow\nIII\n2\n15.43\n\n\nlow\nIII\n3\n15.29\n\n\nlow\nIII\n4\n16.44\n\n\nmid\nI\n1\n16.60\n\n\nmid\nI\n2\n13.38\n\n\nmid\nI\n3\n19.52\n\n\nmid\nI\n4\n14.16\n\n\nmid\nII\n1\n13.19\n\n\nmid\nII\n2\n16.21\n\n\nmid\nII\n3\n16.09\n\n\nmid\nII\n4\n14.67\n\n\nmid\nIII\n1\n14.97\n\n\nmid\nIII\n2\n15.11\n\n\nmid\nIII\n3\n15.09\n\n\nmid\nIII\n4\n14.99\n\n\nhigh\nI\n1\n15.95\n\n\nhigh\nI\n2\n16.28\n\n\nhigh\nI\n3\n17.47\n\n\nhigh\nI\n4\n18.16\n\n\nhigh\nII\n1\n17.01\n\n\nhigh\nII\n2\n17.24\n\n\nhigh\nII\n3\n23.31\n\n\nhigh\nII\n4\n20.22\n\n\nhigh\nIII\n1\n18.65\n\n\nhigh\nIII\n2\n22.56\n\n\nhigh\nIII\n3\n22.34\n\n\nhigh\nIII\n4\n18.21\n\n\n\n\n\n\nA.2.1 Explorative Datenanalyse (EDA)\n\nggplot(data_tbl, aes(trt, rsp, color = block)) +\n  geom_boxplot()\n\n\n\n\n\nstat_tbl <- data_tbl %>% \n  group_by(trt, block) %>% \n  summarise(mean = mean(rsp),\n            sd = sd(rsp),\n            se = sd/sqrt(n()))\n\nggplot(stat_tbl, aes(x = trt, y = mean, fill = block)) + \n    geom_bar(position = position_dodge(), stat = \"identity\") +\n    geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                  width = 0.2,\n                  position = position_dodge(.9))\n\n\n\n\n\nA.2.2 Lineares Modell\n\nfit_1 <- lm(rsp ~ trt + block, data = data_tbl)\n\n\nA.2.3 ANOVA\n\nfit_1 %>% anova\n\nAnalysis of Variance Table\n\nResponse: rsp\n          Df   Sum Sq Mean Sq  F value      Pr(>F)    \ntrt        2 147.4621 73.7310 14.36080 0.000038554 ***\nblock      2  20.7222 10.3611  2.01806     0.15001    \nResiduals 31 159.1598  5.1342                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nA.2.4 Gruppenvergleich mit dem multcomp Paket\nhttps://broom.tidymodels.org/reference/tidy.glht.html\n\nfit_1 %>% \n  glht(linfct = mcp(trt = \"Tukey\")) %>% \n  tidy %>% \n  select(contrast, estimate, adj.p.value) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 3 × 3\n  contrast   estimate adj.p.value\n  <chr>         <dbl>       <dbl>\n1 mid - low      1.13      0.451 \n2 high - low     4.74      0     \n3 high - mid     3.62      0.0013\n\n\n\nA.2.5 Gruppenvergleich mit der emmeans Paket\nhttps://broom.tidymodels.org/reference/tidy.emmGrid.html\n\nfit_1 %>% \n  emmeans(\"trt\") %>% \n  contrast(method = \"pairwise\") %>% \n  tidy %>% \n  select(contrast, estimate, adj.p.value) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 3 × 3\n  contrast   estimate adj.p.value\n  <chr>         <dbl>       <dbl>\n1 low - mid     -1.13      0.451 \n2 low - high    -4.74      0     \n3 mid - high    -3.62      0.0013"
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-boniturnoten",
    "href": "app-example-analysis.html#auswertung-von-boniturnoten",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.3 Auswertung von Boniturnoten",
    "text": "A.3 Auswertung von Boniturnoten\n\n\n\n\n\n\n\nvariety\nblock\nrating\n\n\n\nA\nI\n2\n\n\nA\nI\n3\n\n\nA\nI\n3\n\n\nA\nI\n4\n\n\nA\nI\n1\n\n\nA\nII\n3\n\n\nA\nII\n2\n\n\nA\nII\n2\n\n\nA\nII\n4\n\n\nA\nII\n4\n\n\nA\nIII\n2\n\n\nA\nIII\n2\n\n\nA\nIII\n3\n\n\nA\nIII\n1\n\n\nA\nIII\n2\n\n\nB\nI\n8\n\n\nB\nI\n9\n\n\nB\nI\n8\n\n\nB\nI\n9\n\n\nB\nI\n7\n\n\nB\nII\n7\n\n\nB\nII\n7\n\n\nB\nII\n8\n\n\nB\nII\n8\n\n\nB\nII\n7\n\n\nB\nIII\n8\n\n\nB\nIII\n9\n\n\nB\nIII\n7\n\n\nB\nIII\n9\n\n\nB\nIII\n8\n\n\nC\nI\n6\n\n\nC\nI\n5\n\n\nC\nI\n5\n\n\nC\nI\n6\n\n\nC\nI\n4\n\n\nC\nII\n4\n\n\nC\nII\n5\n\n\nC\nII\n3\n\n\nC\nII\n6\n\n\nC\nII\n4\n\n\nC\nIII\n7\n\n\nC\nIII\n6\n\n\nC\nIII\n4\n\n\nC\nIII\n6\n\n\nC\nIII\n4\n\n\nD\nI\n2\n\n\nD\nI\n4\n\n\nD\nI\n1\n\n\nD\nI\n2\n\n\nD\nI\n2\n\n\nD\nII\n2\n\n\nD\nII\n4\n\n\nD\nII\n4\n\n\nD\nII\n1\n\n\nD\nII\n3\n\n\nD\nIII\n3\n\n\nD\nIII\n4\n\n\nD\nIII\n2\n\n\nD\nIII\n1\n\n\nD\nIII\n3\n\n\nE\nI\n4\n\n\nE\nI\n4\n\n\nE\nI\n2\n\n\nE\nI\n7\n\n\nE\nI\n5\n\n\nE\nII\n4\n\n\nE\nII\n3\n\n\nE\nII\n4\n\n\nE\nII\n7\n\n\nE\nII\n7\n\n\nE\nIII\n5\n\n\nE\nIII\n5\n\n\nE\nIII\n4\n\n\nE\nIII\n6\n\n\nE\nIII\n6\n\n\n\n\n\n\nA.3.1 Explorative Datenanalyse (EDA)\n\nggplot(data_tbl, aes(variety, rating, color = block)) +\n  geom_boxplot() +\n  geom_dotplot(aes(fill = block), binaxis = \"y\", stackdir='center', \n               position=position_dodge(0.8))  \n\n\n\n\n\nggplot(data_tbl, aes(variety, rating, fill = block)) +\n  geom_dotplot(binaxis = \"y\", stackdir='center', \n               position=position_dodge(0.8)) +\n  stat_summary(fun = median, fun.min = median, fun.max = median,\n               geom = \"crossbar\", width = 0.5, \n               position=position_dodge(0.8)) \n\n\n\n\n\nA.3.2 Friedman Test\n\n#friedman.test(rating ~ variety | block, data = data_tbl)\n\ndata_tbl <- tibble(Block = 1:4,\n                   Sorte_1 = c(2,3,4,3),\n                   Sorte_2 = c(7,9,8,9),\n                   Sorte_3 = c(6,5,4,7),\n                   Sorte_4 = c(2,4,1,2),\n                   Sorte_5 = c(4,5,3,7)) %>%\n  gather(key, value, Sorte_1:Sorte_5)\n\nfriedman.test(value ~ key | Block, data = data_tbl)\n\n\n    Friedman rank sum test\n\ndata:  value and key and Block\nFriedman chi-squared = 13.5263, df = 4, p-value = 0.0089709"
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-infektionsstatus",
    "href": "app-example-analysis.html#auswertung-von-infektionsstatus",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.4 Auswertung von Infektionsstatus",
    "text": "A.4 Auswertung von Infektionsstatus"
  },
  {
    "objectID": "app-r-tutorial.html#genutzte-r-pakete-für-das-kapitel",
    "href": "app-r-tutorial.html#genutzte-r-pakete-für-das-kapitel",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.1 Genutzte R Pakete für das Kapitel",
    "text": "B.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, broom, broom.mixed, \n               multcomp, emmeans, performance, lme4, effectsize)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.\nR Package performance\nR Package effectsize"
  },
  {
    "objectID": "app-r-tutorial.html#keimung",
    "href": "app-r-tutorial.html#keimung",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.2 Keimung",
    "text": "B.2 Keimung\n\ngerm_tbl <- read_excel(\"data/germination_data.xlsx\")"
  },
  {
    "objectID": "app-r-tutorial.html#schweine",
    "href": "app-r-tutorial.html#schweine",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.3 Schweine",
    "text": "B.3 Schweine\n\npig_tbl <- read_excel(\"data/pig_feed_data.xlsx\")"
  },
  {
    "objectID": "app-r-tutorial.html#kohlenstoffnitrat",
    "href": "app-r-tutorial.html#kohlenstoffnitrat",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.4 Kohlenstoff/Nitrat",
    "text": "B.4 Kohlenstoff/Nitrat\n\ncarbon_tbl <- read_excel(\"data/carbon_data.xlsx\") %>% \n  mutate(c2n = c_o/n,\n         c_m2c_o = c_m/c_o)"
  },
  {
    "objectID": "app-r-tutorial.html#lichtintensität",
    "href": "app-r-tutorial.html#lichtintensität",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.5 Lichtintensität",
    "text": "B.5 Lichtintensität\n\nintensity_tbl <- read_excel(\"data/light_intensity_data.xlsx\") %>% \n  mutate(rack = as_factor(rack),\n         layer = as_factor(layer),\n         light_intensity = factor(light_intensity, \n                                  labels = c(\"low\", \"mid\", \"high\")))\n\n\n\n\n\nfit_1 <- lm(growth ~ light_intensity + rack + layer, data = intensity_tbl)\n\nfit_1 %>% anova %>% tidy\n\n# A tibble: 4 × 6\n  term               df  sumsq meansq statistic  p.value\n  <chr>           <int>  <dbl>  <dbl>     <dbl>    <dbl>\n1 light_intensity     2  433.   217.      3.87   0.0278 \n2 rack                2  628.   314.      5.61   0.00652\n3 layer               2   70.9   35.5     0.633  0.535  \n4 Residuals          47 2631.    56.0    NA     NA      \n\n\n\nfit_1 %>% glht(linfct = mcp(light_intensity = \"Tukey\")) %>% tidy\n\n# A tibble: 3 × 7\n  term            contrast   null.value estimate std.error statistic adj.p.value\n  <chr>           <chr>           <dbl>    <dbl>     <dbl>     <dbl>       <dbl>\n1 light_intensity mid - low           0    -2.88      2.49     -1.15      0.486 \n2 light_intensity high - low          0    -6.91      2.49     -2.77      0.0215\n3 light_intensity high - mid          0    -4.03      2.49     -1.61      0.249 \n\n\n\nmarginal <- emmeans(fit_1, \"light_intensity\")\ntidy(marginal) %>% \n  mutate_if(is.numeric, round, 2)\n\n# A tibble: 3 × 6\n  light_intensity estimate std.error    df statistic p.value\n  <chr>              <dbl>     <dbl> <dbl>     <dbl>   <dbl>\n1 low                 18.2      1.76    47     10.3        0\n2 mid                 15.3      1.76    47      8.69       0\n3 high                11.3      1.76    47      6.4        0\n\n\n\nmarginal %>% contrast(method = \"pairwise\") %>% tidy %>% \n  mutate_if(is.numeric, round, 2)\n\n# A tibble: 3 × 8\n  term        contrast null.value estimate std.error    df statistic adj.p.value\n  <chr>       <chr>         <dbl>    <dbl>     <dbl> <dbl>     <dbl>       <dbl>\n1 light_inte… low - m…          0     2.88      2.49    47      1.15        0.49\n2 light_inte… low - h…          0     6.91      2.49    47      2.77        0.02\n3 light_inte… mid - h…          0     4.03      2.49    47      1.61        0.25"
  },
  {
    "objectID": "app-r-tutorial.html#komplexes-weizenbeispiel",
    "href": "app-r-tutorial.html#komplexes-weizenbeispiel",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.6 Komplexes Weizenbeispiel",
    "text": "B.6 Komplexes Weizenbeispiel\nWir wollen uns nun ein kpmplexeres Datenbeispiel anschauen. In diesem Beispiel liegen zum einen die Daten in einem ungünstigen Wide-Format vor und müssen über gather() erst in das Long-Format gebracht werden. Zum anderen entstehen dadurch ungünstige Einträge in der key-Spalte, so dass wir hier nochmal einen regulären Ausdruck benötigen um den character Vektor umwandeln zu können.\nAls wäre dies nicht schon kompliziert genug, schauen wir uns nicht nur ein Outcome an, sondern in der Summe die Outcomes Weizenhöhe, Chlorophyllgehalt sowie Frisch- und Trockengewichte. Der Weizen wurde in vier Blöcken angezogen und zu verschiedenen Zeitpunkten gemessen. Hierdurch entsteht ein komplexer Versuchsaufbau.\n\nB.6.1 Weizenhöhe\nDie Höhe der Weizenpflanzen [cm] wurde in vier Blöcken an insgesamt neun Tagen gemessen. Die Datei corn_plant_height.csv beinhaltet die Daten des Versuchs. Für die folgende Auswertung nehmen wir an, das die Weizenhöhe normalverteilt ist. Wie beginnen mit einer exploratven Datenanalyse udn schauen uns die Daten einmal an.\n\nB.6.1.1 Exlorative Datenanalyse\n\nplant_tbl <- read_csv2(\"data/corn_plant_height.csv\") %>% \n  gather(key = \"day\", value = \"height\", \"1...3\":\"9...47\") %>% \n  mutate(day = str_replace(day, \"...\\\\d+\", \"\"),\n         day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\")))\n\nIn der csv-Datei sind die die Tage jeweils fünfmal mit einer 1 bis 9 in den Spalten abgebildet. Wir nutzen die Funktion read_csv2 um mit dem deutschen Format der csv-Datei umgehen zu können. Die Funktion read_csv2 erkennt das ; als Separator. Da R nicht mit gleichen Benennungen in den Spalten umgehen kann, setzt R hinter jeden Spaltennamen, der gleich ist drei Punkte und eine fortlaufende Zahl. Mit der Funktion gather() können wir die Spalten 1...3 bis 9...47 untereinanderkleben. Abschließend müssen wir noch den ...[Zahl]-Teil loswerden. Das machen wir über den regulären Ausdruck in der Funktion str_replace(). Reguläre Ausdrücke musst du nicht verstehen, sind aber sehr mächtige Werkzeuge im Umgang mit großen Datensätzen.\nSchauen wir uns nun einmal die Daten an. Unser Outcome (Y) ist height und auf X wollen wir das treatment. Das wollen wir die Boxplots noch nach dem Tag einfärben und jeweils ein Subplot für die vier Blöcke bauen.\n\nggplot(plant_tbl, aes(x = treatment, y = height, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Weizenhöhe [cm]\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\nAbbildung B.1— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung B.1 zeigt den entsprechenden Boxplot. Du siehst, dass du auf den ersten Blick nichts siehst. Bei einer so großen Datenmenge ist es selbst mit einem guten ggplot() schwer etwas zu erkennen. Hier müssen wir uns mehrere Fragen stellen…\n\n… wollen wir wirklich alle Blöcke getrennt auswerten?\n… wollen wir uns wirklich alle Tage anschauen? Oder geht es nicht eher um die Pflanzenhöhe am Ende des Versuches?\n… wollen wir wirklich alle treatment Stufen vergleichen?\n\n\nplant_tbl %>% \n  filter(block == \"I\") %>% \n  filter(day %in% c(6, 7, 8, 9)) %>% \n  ggplot(aes(x = treatment, y = height, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Weizenhöhe [cm]\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\nAbbildung B.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung B.2 zeigt einen Auschnitt in dem wir nur nach Block I und den Tagen 6 bis 9 gefiltert haben. In diesem Fall könnten wir auf den vollen Datensatz weitermachen oder vorab über filter() einen kleinern Datensatz bauen, der unsere Fragestellung bgut beantworten kann. Wir gehen jetzt den steinigeren Weg und analysieren den ganzen Datensatz - das muss nicht der bessere Weg sein!\n\nB.6.1.2 Lineares Modell mit lm()\n\nWir beginnen mit einer ANOVA und müssen dafür ein lineare Modell schätzen. Dafür nutzen wir erst die Funktion lm() und anschließend mit dem Ergebnis des linearen Modells die Funktion anova() um eine Varianzanalyse durchzuführen.\n\nfit_height <- lm(height ~ treatment + day + block + \n                   treatment:day + treatment:block, \n                 data = plant_tbl)\n\nfit_height %>% anova\n\nAnalysis of Variance Table\n\nResponse: height\n                  Df  Sum Sq Mean Sq    F value                 Pr(>F)    \ntreatment          7  2402.5  343.22  211.20218 < 0.000000000000000222 ***\nday                8 41280.2 5160.03 3175.28495 < 0.000000000000000222 ***\nblock              3    63.4   21.14   13.01124     0.0000000222375065 ***\ntreatment:day     56  1076.3   19.22   11.82650 < 0.000000000000000222 ***\ntreatment:block   21   162.2    7.72    4.75297     0.0000000000099287 ***\nResiduals       1344  2184.1    1.63                                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWir konzentrieren uns auf die Spalte Pr(>F) welche den p-Wert beinhaltet. Wir schauen welcher p-Wert kleiner ist als \\(\\alpha = 5\\% = 0.05\\). Alle p-Werte sind signifikant. Mindestens zwei treatment Level unterscheiden sich, mindestens zwei day Level unterschieden sich und mindestens zwei block Level unterscheiden sich. Abschließend ist auch der Interaktionsterm zwischen den Behandlungen und den Tagen sowie den Behandlungen und den Blöcken signifikant.\n\nfit_height %>% anova %>% eta_squared(partial = FALSE)\n\n# Effect Size for ANOVA (Type I)\n\nParameter       |     Eta2 |       95% CI\n-----------------------------------------\ntreatment       |     0.05 | [0.03, 1.00]\nday             |     0.88 | [0.87, 1.00]\nblock           | 1.34e-03 | [0.00, 1.00]\ntreatment:day   |     0.02 | [0.00, 1.00]\ntreatment:block | 3.44e-03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at (1).\n\n\nfit_height_lme <- lmer(height ~ treatment + block + (1|day), \n                       data = plant_tbl)\n\nfit_height_lme %>% summary\n\nfit_height_lme %>% \n  tidy(conf.int = TRUE, effects = \"fixed\")\n\nmodel_performance(fit_height_lme) \n\nr2(fit_height_lme)\n\nconf_tbl <- glht(fit_height_lme, linfct = mcp(treatment = \"Tukey\")) %>% \n  tidy(conf.int = TRUE) %>% \n  arrange(estimate) %>% \n  mutate(contrast = as_factor(contrast))\n\nggplot(conf_tbl, aes(x = contrast, y = estimate, \n                     ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"\", y = \"Mittelwertsdifferenz der Weizenhöhe [cm]\") +\n  coord_flip() +\n  theme_bw()\n\nB.6.2 Chlorophyllgehalt\n\nchlorophyl_tbl <- read_csv2(\"data/corn_chlorophyl.csv\") %>% \n  gather(key = \"day\", value = \"chlorophyl\", \"1...3\":\"3...62\") %>% \n  mutate(day = str_replace(day, \"...\\\\d+\", \"\"),\n         day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\"))) %>% \n  filter(chlorophyl >= 20 & chlorophyl <= 100)\n\n\nggplot(chlorophyl_tbl, aes(x = treatment, y = chlorophyl, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Chlorophyllgehalt\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\n\n\nB.6.3 Frisch- und Trockenmasse\n\nburn_tbl <- read_csv2(\"data/corn_burning.csv\") %>% \n  gather(key = \"day_outcome\", value = \"drymatter\", \"1_FM\":\"3_TMperc\") %>%\n  separate(day_outcome, c(\"day\", \"outcome\")) %>% \n  mutate(day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\")),\n         outcome = as_factor(outcome)) \n\n\nburn_tbl %>% \n  filter(outcome == \"FM\") %>% \n  ggplot(aes(x = treatment, y = drymatter, color = day)) +\n  geom_point() +\n  ##facet_wrap(~ block, scales = \"free_y\") +\n  labs(x = \"Behandlung\", y = \"Gewicht\", fill = \"Messtag\") +\n  theme_bw()"
  },
  {
    "objectID": "app-how-to-write.html",
    "href": "app-how-to-write.html",
    "title": "Appendix C — Writing principles",
    "section": "",
    "text": "Schreiben ist nicht einfach. Aber es folgt einem Schema. Schreiben ist anstrengend und dauert seine Zeit. Ein guter Text wird mehrfach revidiert, umgeschrieben und gelöscht, bis er zu einem guten Text geworden ist. Häufig vergehen mehrere Tage bis man eine Idee so auf das Blatt Papier gebracht hat, dass auch ein Dritter den Text lesen und verstehen kann.\n\n\n\n\n\n\nZentraler Gedanke\n\n\n\nDer erste Entwurf ist für einen selber, ab dem zweiten geht es um den Leser.\n\n\nEs geht also am Anfang erstmal darum, Text auf das weiße Blatt zu kriegen.\n\n\n\n\n\n\nOtto Kruse – Keine Angst vor dem leeren Blatt\n\n\n\nViele wissenschaftliche Themen kann man erst dann lösen, wenn man alle Aspekte explizit formuliert hat. Das Denken ist dafür insofern nicht genügend vorbereitet, als es immer nur kleine Ausschnitte fokussieren kann. Systematisch denken kann man nur, wenn man schreibt, also die Ergebnisse seines Denkens festhält und mit weiteren Aspekten in Beziehung setzt.\n\n\nDas ist die Idee vom Schreiben. Andere merken, wie weit du mit deinen Gedanken gekommen bist. Wir bringen komplexe Gedankengänge in die lineare Form des Textes."
  },
  {
    "objectID": "app-how-to-write.html#der-schreibprozess",
    "href": "app-how-to-write.html#der-schreibprozess",
    "title": "Appendix C — Writing principles",
    "section": "C.2 Der Schreibprozess",
    "text": "C.2 Der Schreibprozess\nDer Schreibprozess läuft nach Beginn in den nächsten Wochen und Monaten in mehreren Phasen ab. In jeder Phase ist es wichtig, sich ein gutes Umfeld für konzentriertes Arbeiten zu schaffen, gleichzeitig aber die Kommunikation mit den Betreuenden und anderen Mitschaffenden nicht abreißen zu lassen."
  },
  {
    "objectID": "app-how-to-write.html#zeitplan",
    "href": "app-how-to-write.html#zeitplan",
    "title": "Appendix C — Writing principles",
    "section": "C.3 Zeitplan",
    "text": "C.3 Zeitplan\nHier ist es wichtig was geschrieben werden soll. Eine Bachelor- und Masterarbeit hat einen klaren Zeitplan, der vorab feststehen muss. Bis wann müssen wie viele Wörter geschrieben sein, damit die Arbeit fertig werden kann. Beide Abschlussformen haben ja unterschiedliche Zeitrahmen. Und das ist wirklich wichtig! Wann sollte man fertig sein mit Programmieren, wie lange soll man sich Zeit für Vortragsvorbereitung nehmen, etc. Auch eine wissenschaftliche Veröffentlichung hat einen Zeitplan! Leider – das ist der Primat der Forschung – kann sich der Zeitplan immer wieder ändern, wenn Methoden nicht klappen oder neue Erkenntnisse gewonnen werden. Dennoch muss klar sein, dass in endlicher Zeit – meist ein Jahr – ein Paper eingereicht werden kann. Auf dieses Ziel sollten sich alle Einschwören. Sonst ist eine Promotion in endlicher Zeit nicht machbar."
  },
  {
    "objectID": "app-how-to-write.html#ideen-entwickeln",
    "href": "app-how-to-write.html#ideen-entwickeln",
    "title": "Appendix C — Writing principles",
    "section": "C.4 Ideen entwickeln",
    "text": "C.4 Ideen entwickeln\nMan sammelt Ideen zunächst in der Breite und fokussiert dann, was davon man aufschreiben will. Man liest andere wissenschaftliche Paper, lernt vielleicht noch Grundlagen und Methoden, und macht sich Notizen, was interessant sein könnte, und wo es steht. Natürlich kann man sich bei den Betreuern und Mitschaffenden Hilfe und Anregungen holen, wo man Input herbekommt. Holen heißt aber nicht, dass man gebracht bekommt.\n\n\n\n\n\n\nOCAR Prinzip\n\n\n\nFrage dich, was ist das Opening (der Hintergrund der Arbeit), die Challenge (was ist das Problem, was gelöst werden soll?), die Action (was wirst du tun um dieses Problem zu lösen?) und die Results (Was kam dabei raus oder soll rauskommen?)"
  },
  {
    "objectID": "app-how-to-write.html#strukturieren",
    "href": "app-how-to-write.html#strukturieren",
    "title": "Appendix C — Writing principles",
    "section": "C.5 Strukturieren",
    "text": "C.5 Strukturieren\nDas grobe Gerüst ist ja vorgegeben. Eine wissenschaftliche Arbeit folgt dem IMRaD Schema. Erst die Einleitung (Introduction), dann die Methoden (Methods), gefolgt von den Ergebnissen (Results) und der Diskussion (Discussion). Am Ende der Einleitung wird nochmal die Fragestellung benannt. Welche Frage soll in der Arbeit beantwortet werden? Dann fehlt noch die Zusammenfassung am Anfang (abstract) und der Schluss bzw. das Fazit (conclusion). So ist das vorgegebene Schema für die Arbeit, das soll mit Inhalt gefüllt werden. Klingt erstmal einfach und ist es auch. Mit Zwischenüberschriften in den einzelnen Abschnitten kann man sich eine grobe Ordnung vorgeben, was in welcher Reihenfolge aufgeschrieben werden soll. Die Struktur innerhalb von Methodenteilen ist zum Beispiel oft gleich, Beschreibung der Studie, Beschreibung der interessierenden Variablen und ihrer Erhebung, Beschreibung der Auswertungsmethodik. Das kommt aber aufs Thema an. Und unterhalb dieser kann man sich wieder Unter-zwischen-unterüberschriften machen. Es wird sowieso noch alles überarbeitet.\n\n\n\n\n\n\nGrobe Strukturierung nach IMRaD\n\n\n\n\nZusammenfassung\n\n\nEinleitung\n\nForschungsfrage\n\nMaterial und Methoden\nErgebnisse\nDiskussion\n\n\nLiteratur\n\n\n\nWenn es einen Flowchart gibt, so gibt dieser auch die Struktur vor. Ein Flowchart ist nicht final und ändert sich mit der Zeit! Mach den Flowchart am besten auf einem Blatt Papier. Da kannst du schneller was ergänzen.\n\n\n\n\n\n\nHinweis\n\n\n\nZeichne einen Flowchart, der aufzeigt was in der Arbeit passiert!"
  },
  {
    "objectID": "app-how-to-write.html#rohtexten",
    "href": "app-how-to-write.html#rohtexten",
    "title": "Appendix C — Writing principles",
    "section": "C.6 Rohtexten",
    "text": "C.6 Rohtexten\nDas kann wirklich sloppy sein, in Stichpunkten oder hingerotzt, aber hier soll man sich auch nicht an Details aufhalten, sondern dem Arbeits- und Denkfluss folgen. Gerne auch Denglisch. Lieber erst Text schreiben und dann korrigieren. Wenn das Englische Wort nicht einfällt, das deutsche Hinschreiben. Den Schreibprozess nicht durch im Internet suchen und dann mal was Anderes gucken unterbrechen. Gerade wenn die Arbeit selbst noch im Entstehen ist, schreibt man erst einmal auf, was man tut, was man gemacht, gelernt, oder gelesen hat. Diese Frage stellt sich meist nach den ersten paar Sätzen in einer wissenschaftlichen Arbeit. Worum geht es hier eigentlich? Es könnte alles so einfach sein. Das ist normal. Durch das Aufschreiben werden einem meist die Dinge klarer und uns wird bewusst, wo wir nochmal genauer einhaken müssen."
  },
  {
    "objectID": "app-how-to-write.html#reflektieren",
    "href": "app-how-to-write.html#reflektieren",
    "title": "Appendix C — Writing principles",
    "section": "C.7 Reflektieren",
    "text": "C.7 Reflektieren\nDie Grundideen sind jetzt schon mal auf dem Papier, jetzt muss man sich überlegen, wie daraus ein Text wird. Gut ist es, sich schon an dieser Stelle Feedback von Betreuern oder Kommilitonen zu holen. Das hilft auch, die eigene Perspektive auf den Text zu ändern und ihn aus mehreren Richtungen zu betrachten – was ist wichtig, was soll viel Platz einnehmen, was fehlt vielleicht noch?\n\n\n\n\n\n\nHinweis\n\n\n\nWas könnte die zentrale Abbildung in den Ergebnissen sein?\n\n\nEin guter Ansatz um einen Fokus zu haben!"
  },
  {
    "objectID": "app-how-to-write.html#jetzt-schreiben-wir-wie-geht-es-am-besten",
    "href": "app-how-to-write.html#jetzt-schreiben-wir-wie-geht-es-am-besten",
    "title": "Appendix C — Writing principles",
    "section": "C.8 Jetzt schreiben wir! Wie geht es am besten?",
    "text": "C.8 Jetzt schreiben wir! Wie geht es am besten?\nDafür geht gut die Hälfte der Schreibzeit drauf. Am wichtigsten sind Inhalt und Struktur, Korrektheit und Verständlichkeit dürfen aber auch nicht unterschätzt werden: Wir nutzen einfache englische Sprache. Das geschriebene Wort muss nicht schlau klingen, sondern der Inhalt muss schlau sein. Keine umständlichen, gekünstelten Verben verwenden, wenn es ein einfaches Verb auch tut. Wir machen es dem Leser einfach. Später wirst du in einem wissenschaftlichen Paper „we” schreiben, da man selten ein Paper alleine schreibt. Um das jetzt hier gleich am Anfang zu üben, schreibst du keine verschachtelten Passivkonstruktionen, sondern „I do/did something”. Das fühlt sich erst seltsam an, aber wir als Leser danken dir!\n\n\n\n\n\n\nSchlecht\n\n\n\nAfter the raw methylation data has been preprocessed, a student t test was used for the differential analysis.\n\n\n\n\n\n\n\n\nGut\n\n\n\nI used the student t test for the differential analysis after the preprocessing of the raw methylation data.\n\n\nWir nutzen auch keine Pronomen, wo man nicht weiß, was diese Pronomen aussagen sollen. Was ist „it” oder „they”?\n\n\n\n\n\n\nSchlecht\n\n\n\nThe dog and the cat walk into a house. It eats all the cookies.\n\n\n\n\n\n\n\n\nGut\n\n\n\nThe dog and the cat walk into a house. The cat eats all the cookies.\n\n\nWir führen alle Begriffe vorher ein, daher erklären wir diese Begriffe, bevor wir die Begriffe verwenden. Ja, mache Begriffe sind klar, aber welche das sind, ergibt sich manchmal erst auf Nachfrage bei uns und ist für einen Neuling in einem Fachbereich gar nicht zu wissen.\n\n\n\n\n\n\nSchlecht\n\n\n\nI analyzed the NGS data with an ANOVA after checking the residuals with a QQ-plot.\n\n\n\n\n\n\n\n\nGut\n\n\n\nI analyzed the next generation sequencing data (NGS) with an analysis of variance (ANOVA) after plotting the residuals of the model in a quantile-quantile plot (QQ-plot).\n\n\nIst dir der Begriff nicht klar, erkläre ihn. Später können wir immer noch kürzen. Erkenntnisgewinn durch schreiben ist das Ziel."
  },
  {
    "objectID": "app-how-to-write.html#wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz",
    "href": "app-how-to-write.html#wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz",
    "title": "Appendix C — Writing principles",
    "section": "C.9 Wer macht was? Die Frage des Lesers an jeden einzelnen Satz!",
    "text": "C.9 Wer macht was? Die Frage des Lesers an jeden einzelnen Satz!\nKomme in den ersten sieben Wörtern zum Punkt, wer was macht. Subjekt und Prädikat sollen nah beieinander sein und möglichst früh im Satz kommen. Wir schreiben kurze Sätze und vermeiden komplizierte Schachtelsätze.\n\n\n\n\n\n\nSchlecht\n\n\n\nThe differential analysis of whole genome genetic data - like methylation pattern or expression analysis - has a long history of different invented methods and I used different analysis methods to find the best method for the analysis of methylation data with repeated measurements.\n\n\n\n\n\n\n\n\nGut\n\n\n\n[1] A long history of different analysis methods like methylation pattern or expression analysis exists. [2] Hence, many scientist have invented different analysis methods of whole genome."
  },
  {
    "objectID": "app-how-to-write.html#löschen-von-text",
    "href": "app-how-to-write.html#löschen-von-text",
    "title": "Appendix C — Writing principles",
    "section": "C.10 Löschen von Text",
    "text": "C.10 Löschen von Text\nText löschen macht keine Freude. Es ist immer nervig Teile des Textes, den man so mühsam in die Maschine getippt hat, zu löschen. Lege dir eine neue Datei an, in der du alles was du löschen willst reinkopierst. Bei mir heißt die Datei dump.docx oder dump.R oder auch anders. Auf jeden Fall löschst du so keinen Text, sondern bewahrst ihn erstmal auf. Denk immer daran, es geht nicht darum nur viel Text zu produzieren!"
  },
  {
    "objectID": "app-how-to-write.html#zum-schluss-kommen",
    "href": "app-how-to-write.html#zum-schluss-kommen",
    "title": "Appendix C — Writing principles",
    "section": "C.11 Zum Schluss kommen",
    "text": "C.11 Zum Schluss kommen\nWie Anne und Jochen1 jetzt in diesem Augenblick musst du zum Schluss kommen. Kein Text ist perfekt, kein Gedankengang so klar niedergeschrieben, wie er sein könnte. Aber irgendwann muss gut sein. Lass das Perfekte nicht der Feind des Guten sein. Dieser Leitfaden ist good enough und somit muss es reichen. Viel Erfolg!1 Die beide zusammen die erste Version von diesem Text mal 2019 geschrieben haben. Tja, wie so die Zeit vergeht.\n\n\n\n\n\n\nErfahrungsbericht von ehemaligen Bachelorstudierenden\n\n\n\n\nkeine neuen (wichtigen) Begriffe verwenden, wenn sie nicht vorher eingeführt wurden\nwenn man einen Begriff nicht richtig versteht oder nicht richtig erklären kann, sollte man ihn nicht verwenden. Daher ist es sehr hilfreich sich gründlich in den Hintergrund des Themas einzulesen.\nman sollte mehr wissen über das Thema, als man eigentlich im Text erklärt (um auf Fragen vorbereitet zu sein)\nAchtgeben auf die Zeitformen\n“it”, “they” und weitere Pronomen vermeiden, d.h. immer klar machen worauf man sich bezieht\nwenn etwas komplizierter scheint, sollte man Beispiele benutzen oder es eventuell graphisch darstellen. Aber: ein Bild nicht verwenden, wenn es keinen inhaltlichen Wert hat! Bringt dieses Bild etwas zum Verständnis des Lesers bei?\nin der Diskussion kein neues “Fass aufmachen”\ndie Limitationen in der Diskussion im Fließtext “verstecken”\ndie eigene Arbeit nicht schlecht reden; “schlechte” Resultate sind auch Resultate\nkeine zu langen Sätze\nes sollte ein roter Faden in jedem Kapitel zu erkennen sein: Was ist das Ziel? Wie erreiche ich das? Was bringt mir diese Methode? Was sagen mir die Resultate (in Bezug auf mein Ziel)?\nund für die eigene Motivation: Es werden oft Schreibblockaden kommen, es wird oft frustrierend sein, weil vielleicht etwas umgeschmissen wird und man von vorne anfangen muss, etc., aber davon soll man sich nicht entmutigen lassen\nDer Text muss nicht gleich beim ersten Hinschreiben perfekt sein, sondern es hilft erstmal etwas drauflos zu schreiben um die Gedanken besser ordnen zu können\nähnlich beim Programmieren: hier hat es mir auch geholfen einfach erstmal anzufangen und Ideen aufzuschreiben, aus welchen sich kann das Programm aufbauen kann\nMan sollte nicht zögern so etwas wie deepl (deepl.com) zu benutzen, wenn man mal mit einer englischen Formulierung nicht weiterkommt\nMan kann vor Beginn eines Tages ein realistisches Tagesziel (oder alternativ ein Wochenziel) festlegen, dann hat man ein Zwischenziel vor Augen und ist zufrieden mit sich, wenn dieses erreicht ist"
  },
  {
    "objectID": "formula.html",
    "href": "formula.html",
    "title": "Appendix D — Formeln",
    "section": "",
    "text": "Diese Seite ist eine Sammelseite für Formeln und Ideen"
  },
  {
    "objectID": "formula.html#diagnostisches-testen",
    "href": "formula.html#diagnostisches-testen",
    "title": "Appendix D — Formeln",
    "section": "D.1 Diagnostisches Testen",
    "text": "D.1 Diagnostisches Testen\n\n\nTabelle D.1— Eine 2x2 Tabelle oder Vierfeldertafel\n\n\n\n\n\n\n\n\n\n\n\nInfected\n\n\n\n\n\n\nYes (1)\nNo (0)\n\n\n\nTest\n+ (1)\na\nb\n\\(\\mathbf{a+b}\\)\n\n\n\n- (0)\nc\nd\n\\(\\mathbf{c+d}\\)\n\n\n\n\n\\(\\mathbf{a+c}\\)\n\\(\\mathbf{b+d}\\)\n\\(\\mathbf{n}\\)\n\n\n\n\nDas ist ein Text Tabelle D.1"
  }
]