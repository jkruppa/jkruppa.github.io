```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, performance, parameters,
               latex2exp, see, patchwork, mfp, multcomp, emmeans, janitor, effectsize,
               broom, ggmosaic, tinytable, ggrepel, tidyplots, glue, ggtext, marginaleffects,
               mgcv, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- cb_pal
theme_marginal <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(face = "bold"),
          axis.text = element_text(size = 12),
          legend.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
set.seed(20250703)
modell_square_tbl <- tibble(x = rnorm(20, 5, 5),
                          y = 1.5 + 0.75 * -x^2 + rnorm(length(x), 0, 5))
modell_line_tbl <- tibble(x = rnorm(20, 2, 1),
                            y = 1.5 + 0.75 * x + rnorm(length(x), 0, 0.5))
set.seed(20250708)
enzyme_tbl <- tibble(x = rep(c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5), each = 10),
                     y = x^3 + -8*x^2 + 10*x + 10 + rnorm(length(x), 0, 10)) |> 
  group_by(x) |> 
  sample_n(size = sample(c(3:5), 1)) |> 
  ungroup() |> 
  mutate_if(is.numeric, round, 2)
enzyme_tbl |> 
  mutate(g1 = case_when(x < 2 ~ "niedrig",
                        x < 5 ~ "mittel",
                        x < 8 ~ "hoch")) |> 
  mutate(g2 = c(rep(c("Prokaryot", "Eukaryot"), times = c(8, 8)),
                rep(c("Prokaryot", "Eukaryot"), times = c(8, 7)),
                rep(c("Prokaryot", "Eukaryot"), times = c(5, 7)))) |> 
  set_names(c("ph", "activity", "grp", "type")) |> 
  writexl::write_xlsx("data/enzyme_kinetic.xlsx")
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-modeling-R.R")
source("images/R/stat-modeling-marginal.R")
```

# Marginal effect models {#sec-marginal}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-marginal.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Life is difficult." --- Morgan Scott Peck, The Road Less Traveled*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion (seit 07.2025)

Dieses Kapitel wird in den nächsten Wochen geschrieben und ist damit meine aktuelle Großbaustelle. Ich plane zum Beginn des SoSe 2026 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

Lange habe ich gebraucht um mich dazu durchzuringen das Kapitel zu den *Marginal effect models* (deu. *marginale Effektmodelle*, ungebräuchlich) zu schreiben. Ich werde hier bei dem englischen Begriff bleiben, den deutschen Begriff habe ich eher selten gehört und daher sind es für mich *Marginal effect models*. Insbesondere da der Begriff "marginal" auch sehr an gering oder minderwertig erinnert. Damit haben aber die *Marginal effect models* nicht im geringsten zu tun. Die Modelle sind sehr mächtig und können uns helfen wichtige Fragen an unsere Daten zu beantworten. Insbesondere die Dualität der beiden Pakete `{emmeans}` für experimentelle Daten und `{marginaleffects}` für beobachtete Daten ist spannend und möchte ich hier nochmal genauer betrachten. Neben diesen beiden Ecksteinen gibt es noch andere Pakete und ich werde auch hier einmal in die Pakete reinschauen.

Anfangen kann ich aber nicht ohne @heiss2022 mit seinem Blogpost [Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/) zu erwähnen. Vieles entlehnt sich direkt oder indirekt an seine Ausführungen. Wie immer habe ich etwas angepasst, wenn ich der Meinung war, dass es noch besser zu verstehen ist. Teilweise entfallten die *Marginal effect models* ihre wahre Kraft erst bei den nicht linearen Zusammenhängen und der Interpretation von *Generalized Additive Models* udn somit der nicht linearen Regression. Fangen wir also an *Marginal effect models* zu zerforschen und arbeiten uns dann voran.. Beginnen wollen wir aber mit einem allgemeinen Hintergrund bevor wir uns dann nochmal tiefer mit den *Marginal effect models* beschäftigen.

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use independent variable because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Jeder nennt in der Statistik sein Y und X wie er möchte. Da ich hier nicht nur von Y und X schreiben will, führe ich eben die Worte ein, die ich nutzen will. Damit sind die Worte dann auch richtig, da der Kontext definiert ist. Andere mögen es dann anders machen. Ich mache es eben dann so. Danke." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Testen. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren. Du kannst dann immer zu dem Kasten zurückgehen, wenn wir mal ein Wort nicht mehr ganz klar ist. Die fetten Begriffe sind die üblichen in den folgenden Kapiteln. Die anderen Worte werden immer mal wieder in der Literatur genutzt.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

## Allgemeiner Hintergrund

> *"Statistics is all about lines, and lines have slopes, or derivatives. These slopes represent the marginal changes in an outcome. As you move an independent/explanatory variable, what happens to the dependent/outcome variable?" --- @heiss2022*

Wenn wir von *Marginal effect models* sprechen, dann können wir uns im Prinzip zwei Aspekte anschauen. Wir können über die Steigung einer Funktion einer Geraden sprechen oder aber über die vorhergesagten $y$-Werte auf der Geraden für beliebige $x$-Werte. Damit sind wir dann bei den beiden Aspekten Steigung und Vorhersage. Wenn wir uns in der Welt der linearen Modelle bewegen, dann ist die Steigung eigentlich kein Problem und die Vorhersage auch nicht so komplex. Spannender wird das Zusammenspiel eines nichtlinearen Modells und eben den *Marginal effect models*. Hier kommt dann die eigentliche Kraft der *Marginal effect models* zu trage. In den folgenden beiden Abbildungen habe ich dir einmal eine nichtlinere Funktion dargestellt. Wir schauen uns hier den Zusammenhang zwischen der standardisierten Enzymeaktivität und dem standardisierten pH-Wert an. Wir haben die Enzymeaktivität zu festen pH-Werten wiederholt gemessen. Auf der linken Seite betrachten wir die Steigung der Geraden an drei Punkten und auf der rechten Seite sehen wir einmal die Vorhersage für drei pH-Werte auf der Geraden. Die Gerade folgt der Funktion $y = x^3 - 8x^2 + 10x + 10$ und ist mir somit für die Bestimmung der Steigung und der Vorhersage bekannt. Daher habe ich also die Möglichkeit die exakten Werte der Steigung und der Vorhersage zu bestimmen. Einen Luxus den wir selten mit echten Daten haben.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5.25
#| fig-width: 9.5
#| fig-cap: "Modellierung des nichtlinearen Zusammenhangs zwischen der standardisierten Enzymeaktivität und dem standardisierten pH-Wert. Der pH-Wert ist kontinuierlich. Die Funktionsgleichung ist bekannt. **(A)** Berechnung der Steigung (eng. *slope*) für ausgewählte pH Werte anhand der Modellierung. **(B)** Berechnete Vorhersagewerte (eng. *prediction*) der standardisierten Enzymeaktivität für ausgewählte pH-Werte anhand der Modellierung. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-01

p1_intro_00_1 + p2_intro_00_2 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Betrachten wir also einmal die Antworten, die die Steigung und die Vorhersage liefert. Dabei haben wir hier in diesem Fall ein kontinuierliches $X$ als Kovariate vorliegen und machen uns die Sachlage auch einfacher indem wir ein kontinuierliches $Y$ mit der standardisierten Enzymeaktivität vorliegen haben.

Welche Antwort liefert die Steigung?

:   *Wenn sich* $X$ *ändert, wie ändert sich dann* $Y$ *an dem Wert von* $X$*?* Hierbei muss sich $X$ nicht um eine Einheit verändern, wie wir es gerne im linearen Zusammenhang sagen, sondern wir wollen die Steigung direkt im Punkt von $(X;Y)$ haben.

Welche Antwort liefert die Vorhersage?

:   *Welche Werte für* $Y$ *sagt das Modell für* $X$ *vorraus?* Wir müssen hier die beobachteten Werte von $Y$, die in unserem Beispiel für einen pH-Wert wiederholt vorkommen, von dem einen vorhergesagten $Y$ Wert aus dem Modell für ein gegebenes $X$ unterscheiden.

Dann können wir auch schon die Steigung und die Vorhersage einmal interpretieren. In dem linken Tab findest du einmal die Interpretation der Steigung sowie die Ausgabe der Funktion `slopes()` aus dem R Paket `{marginaleffects}`. In dem rechten Tab dann die Ergebnisse der Vorhersage und die Ausgabe der Funktion `predictions()`. Mehr zu den beiden Funktionen dann weiter unten in der Anwendung. Ich berechne hier die Steigung und bestimme die vorhergesagten Werte für drei ausgewählte pH-Werte.

::: panel-tabset
## Interpretation Steigung

Wir können einmal die Steigung $(dx/dy)$ aus der ersten Ableitung der quadratischen Geradenfunktion für unsere ausgewählten pH-Werte bestimmen und dann entsprechend interpretieren.

| pH | Steigung | Interpretation |
|----|----|----|
| -1 | 29 | *Bei einem standardisierten pH-Wert von -1 steigt die Enzymeaktivität um 29U an.* |
| 2 | -10 | *Bei einem standardisierten pH-Wert von 2 sinkt die Enzymeaktivität um 10U.* |
| 6 | 22 | *Bei einem standardisierten pH-Wert von 6 steigt die Enzymeaktivität um 22U an.* |

: Interpretation der Steigung der Enzymeaktivität an drei ausgewählten pH-Werten. {#tbl-intro-inter-slope tbl-colwidths="\[15, 15, 70\]"}

Wir können uns dann die Steigung auch direkt mit der Funktion `slopes()` bestimmen lassen und erhalten dann die folgenden Informationen. Häufig haben wir ja nicht die Geradengleichung vorliegen. Hier haben wir dann auch die p-Werte sowie einen entsprechenden Fehler. Wir haben hier eine leichte Abweichung, da ich die obige Steigung durch die Ableitung der quadratischen Funktion erstellt habe und nicht aus einem Polynomialmodell entnommen habe.

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
slopes(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

## Interpretation Vorhersage

Auch hier können wir direkt durch das Einsetzen der pH-Werte in unsere quadratische Geradenfunktion die vorgesagten Enzymeaktivitäten für die ausgewählten pH-Werte bestimmen.

| pH | Vorhersage (y) | Interpretation |
|----|----|----|
| -1 | -9 | *Für einen standardisierten pH-Wert von -1 sagt die Funktion eine Enzymeaktivität von -9U vorher.* |
| 2 | 6 | *Für einen standardisierten pH-Wert von 2 sagt die Funktion eine Enzymeaktivität von 6U vorher.* |
| 6 | -2 | *Für einen standardisierten pH-Wert von 6 sagt die Funktion eine Enzymeaktivität von -2U vorher.* |

: Interpretation der Vorhersage der Enzymeaktivität an drei ausgewählten pH-Werten. {#tbl-intro-inter-vorhersage tbl-colwidths="\[15, 20, 65\]"}

Auch können wir die Steigung aus den Daten direkt mit der Funktion `predictions()` bestimmen. Häufig haben wir ja nicht die Geradengleichung vorliegen. Hier haben wir theoretisch noch eine riesige Auswahl an Funktionen in R, wir konzentrieren uns hier aber auf das R Paket `{marginaleffects}`. Wir haben auch hier eine leichte Abweichung, da ich die obigen Vorhersagen durch die quadratische Funktion bestimmt habe und nicht aus einem Polynomialmodell entnommen habe.

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
predictions(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```
:::

Wenn wir die Vorhersage betrachten dann können wir auch den Fall vorliegen haben, dass wir ein kategoriales $X$ mit Gruppen gemessen haben. In R wäre es dann ein Faktor und daher dann auch der Begriff des faktoriellen Designs, wenn es um das experimentelle Design geht. Wir hatten bis jetzt ein kontinuierlichen pH-Wert vorliegen. Zwar hatten wir auch Messgruppen, aber wir konnten von einem konitnuierlichen pH-Wert im Sinne der Modellierung ausgehen. Jetzt wollen wir uns einmal den Fall anschauen, dass wir auf eben wirkliche pH-Wertgruppen mit niedrigen, mittleren und hohen pH-Wertgruppen für die Enzymeaktivität vergleichen wollen. Ich schreibe hier schon gleiche von einem Vergleich, als erstes wollen wir aber die Mittelwerte pro Gruppe vorhersagen.

In der folgenden Abbildung siehst du auf der linken Seite einmal den einfaktoriellen Fall mit dem gruppierten pH-Wert als Gruppe. Auf der rechten Seite dann noch zusätzlich die beiden Gruppen der Prokaryoten sowie Eukaryoten. Wir sind jetzt an den Mittelwerten pro Gruppe interessiert und wir könnten diese Mittelwerte dann auch einfach berechnen. Dafür bräuchten wir dann erstmal kein Modell, wenn wir nur so ein simples Experiment vorliegen haben. Konkret bestimmen wir hier die *marginal means* aus einem Modell heraus.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Modellierung des Zusammenhangs zwischen der standardisierten Enzymeaktivität und den gruppierten pH-Werten nach niedrigen, mittleren und hohen pH-Werten. Der pH-Wert ist kategorial. **(A)** Einfaktorielle Vorhersage der Gruppenmittelwerte der Enzymeaktivität. **(B)** Zweifaktorielle Vorhersage der Gruppenmittelwerte der Enzymeaktivität aufgetrennt nach der Gruppe der Eukaryoten und Prokaryoten. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-04

p3_intro_00_3 + p4_intro_00_4 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))

```

Wir wollen jetzt für alle Gruppen die Mittelwerte vorhersagen. Nichts anderes macht dann auch die Funktion `predictions()`. Hier muss ich auch schon gleich einmal eine leichte Warnung aussprechen. So gut `{marginaleffects}` in der Bestimmung der Steigung und der Vorhersagen ist, um so viel besser ist das R Paket `{emmeans}` wenn es um die Auswertung von einem faktoriellen Design geht. Hier ist dann einfach `{emmeans}` besser in der Anwendung. Das hat auch Gründe im Algorithmus der beiden Pakete, dazu dann aber später mehr. Hier erstmal die Interpretation der beiden Vorhersagen für kategoriale $x$-Werte oder eben auch Faktoren in R genannt.

::: panel-tabset
## Vorhersage 1-faktoriell

Wir haben hier also in unserem einfaktoriellen Modell einmal die gruppierten pH-Werte in den Gruppen niedrig, mittel und hoch vorliegen. Wir wollen dann den Mittelwert für jede der Gruppen bestimmen.

| pH | Mittelwert | Interpretation |
|----|----|----|
| niedrig | 3.2 | *Für die Gruppe der niedrigen pH-Werte haben wir im Mittel eine Enzymeaktivität von 3.2U vorliegen.* |
| mittel | 2.59 | *Für die Gruppe der mittleren pH-Werte haben wir im Durchschnitt eine Enzymeaktivität von 2.59U vorliegen.* |
| hoch | -5.6 | *Für die Gruppe der hohen pH-Werte haben wir im Mittel eine Enzymeaktivität von -5.9U vorliegen.* |

: Interpretation der Vorhersage der Enzymeaktivität an drei ausgewählten pH-Werten. {#tbl-intro-inter-slope tbl-colwidths="\[15, 15, 70\]"}

Jetzt können wir uns auch mit der Funktion `predictions()` aus dem R Paket `{marginaleffects}` die Mittelwerte für die Gruppen vorhersagen lassen. Wir erhalten dann auch die entsprechenden Standardfehler und andere statistische Maßzahlen. Hier kriegen wir noch keinen Vergleich, hier wird nur getestet, ob der Mittelwert sich von der Null unterscheidet.

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx")  |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch"))) 
enzyme_fit <-  lm(activity ~ grp, data = enzyme_tbl)
predictions(enzyme_fit, by = c("grp"), vcov = "HAC")
```

## Vorhersage 2-faktoriell

Kommen wir nun zu der Vorhersage der Mittelwerte oder *Marginal means* in den gruppierten pH-Werten aufgeteilt nach den beiden Gruppen der Prokaryoten sowie Eukaryonten. Daher haben wir hier ein zweifaktorielles Design vorliegen. Wir wollen eben die Mittelwerte für alle Faktorkombinationen wissen.

| pH | Gruppe | Mittelwert | Interpretation |
|----|----|----|----|
| niedrig | Eukaryot | 14.21 | *Für die Gruppe der niedrigen pH-Werte der Eukaryoten haben wir im Mittel eine Enzymeaktivität von 14.21U vorliegen.* |
| niedrig | Prokaryot | -19.2 | *Für die Gruppe der niedrigen pH-Werte der Prokaryoten haben wir im Mittel eine Enzymeaktivität von -19.2U vorliegen.* |
| mittel | Eukaryot | -9.22 | *Für die Gruppe der mittleren pH-Werte der Eukaryoten haben wir im Mittel eine Enzymeaktivität von -9.22U vorliegen.* |
| mittel | Prokaryot | 2.59 | *Für die Gruppe der mittleren pH-Werte der Prokaryoten haben wir im Mittel eine Enzymeaktivität von 2.59U vorliegen.* |
| hoch | Eukaryot | 26.24 | *Für die Gruppe der hohen pH-Werte der Eukaryoten haben wir im Mittel eine Enzymeaktivität von 26.24U vorliegen.* |
| hoch | Prokaryot | -5.14 | *Für die Gruppe der hohen pH-Werte der Prokaryoten haben wir im Mittel eine Enzymeaktivität von -5.14U vorliegen.* |

: Interpretation der Vorhersage der Enzymeaktivität an drei ausgewählten pH-Werten in den Prokaryoten und Eukaryonten {#tbl-intro-inter-vorhersage tbl-colwidths="\[15, 15, 15, 55\]"}

Wenn wir dann die Funktion `predictions()` aus dem R Paket `{marginaleffects}` benutzen erhalten wir dann auch die *Marginal means* für alle Faktorkombinationen zurück. Hier sind die Werte die gleichen wir auch in der simplen Berechnung oben in der Abbildung, da unser Modell eben dann doch nur die beiden Faktoren enthält. Wir erhalten dann auch die Standardfehler und den p-Wert für den Test gegen einen Mittelwert von Null.

```{r}
#| message: false
#| echo: false
#| warning: false
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx") |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch"))) 
enzyme_fit <- lm(activity ~ grp * type, data = enzyme_tbl)
predictions(enzyme_fit, by = c("grp", "type"), vcov = "HAC")
```
:::

Soviel dann einmal zu dem allgemeinen Hintergrund. Die Idee der *Marginal effect models* ist es also dir die Steigung einer Funktion oder die vorhergesagten Werte einer Funktion wiederzugeben. Hier kannst du dann Funktion auch mit Modell erstetzen. Für den linearen Fall auf einem normalverteilten Messwert ist die Anwendung und der Erkenntnisgewinn der *Marginal effect models* begrenzt. Da reichen dann auch die Ausgaben der Standardfunktionen. Aber auch dort werden wir dann noch in den entsprechenden Kapiteln sehen, dass wir hier noch was rausholen können. Die *Marginal effect models* entwicklen dann ihre Stärke für nicht normalverteilte Messwerte sowie eben nicht lineare Zusammenhänge.

::: callout-tip
## Weitere Tutorien für die Marginal effects models

Wir oben schon erwähnt, kann dieses Kapitel nicht alle Themen der Marginal effects models abarbeiten. Daher präsentiere ich hier eine Liste von Literatur und Links, die mich für dieses Kapitel hier inspiriert haben. Nicht alles habe ich genutzt, aber vielleicht ist für dich was dabei.

-   Ohne den Blogpost [Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/) von @heiss2022 wäre dieses Kapitel nicht möglich gewesen.
-   Wie alles im Leben ist nichts ohne Kritik. [Is least squares means (lsmeans) statistical nonsense?](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents:~:text=found%20here%20and-,here,-.) ist dann auch eine gute Frage. Ich bin der Meinung nein und auch andere sind es, aber hier kannst du dann nochmal eine andere Meinung lesen.
:::

## Theoretischer Hintergrund

> *"What he says?" --- Asterix, Sieg über Caesar*

Soweit so gut. Wenn du verstanden hast, was die *Marginal effect models* können, dann kannst du auch bei den Daten und deren Auswertung weitermachen. Hier geht es dann etwas tiefer und ich gehe nochmal auf einzelne Aspekte etwas ausführlicher ein. So wollen wir nochmal verstehen, was eigentlich die Steigung nochmal war und wie wir die Steigung berechnen. Dann müssen wir nochmal über simple und multiple Modelle sprechen. Dann gehen wir nochmal auf die Vorhersage ein und ich gebe nochmal einen kurzen Überblick, was wir da eigentlich alles vorhersagen oder genauer was wie heißt. Dann besprechen wir nochmal die Unterschiede zwischen den Paketen `{marginaleffects}` und `{emmeans}`. Wie immer kann man den Teil hier auch überspringen, wenn es nur um die Anwendung geht.

#### Was ist die Steigung? {.unnumbered .unlisted}

Wenn wir mit dem Verstehen und Zerforschen der Steigung vorankommen wollen, dann können wir @heiss2022 und @heiss2024 mit der Veröffentlichung [Model to meaning --- How to Interpret Statistical Models With marginaleffects for R and Python](https://marginaleffects.com/) nicht ignorieren. Ich nutze jetzt eine etwas allgemeinere Erklärung der *Marginal effect models* und konzentriere mich erstmal auf ein normalverteilte Kovariate $c_1$ sowie ein normalverteiltes $y$ in einem simplen Modell mit einem $c_1$ und einem $y$ in der folgenden Form.

$$
y \sim \beta_0 + \beta_1 c_1
$$ mit

-   $\beta_0$, dem Koeffizienten des y-Achsenabschnitt oder Intercept der Geraden.
-   $\beta_1$, dem Koeffizienten der Steigung der Geraden

Daher haben wir hier in unserer Kovariate $c_1$ keine Gruppen vorliegen sondern einen klassischen Scatterplot mit Punkten als Beobachtungen. Wir können die *Marginal effect models* auch auf beliebige Faktoren wie eben Behandlungsgruppen sowie jedes beliebige $y$ anwenden, aber hier fangen wir einmal einfach an.

Welche Frage wollen wir mit *Marginal effect models* beantworten?

:   Wenn sich die Kovariate $c_1$ um einen Wert oder eine Einheit erhöht, um wieviele Einheiten verändert sich dann der Wert von $y$?

In der folgenden Abbildung siehst du einmal zwei Scatterplots. In dem linken Scatterplot haben wir einen linearen Zusammenhang zwischen unseren $c_1$-Werten der Kovariate und den $y$-Werten. Wir können sagen, dass wenn sich die Kovariate um einen Wert erhöht, dann erhöht sich auch $y$ um einen konstanten Wert. Dieser konstante Wert um den sich die $y$-Werte mit ansteigenden $c_1$ erhöhen, nennen wir auch die Steigung $\beta_1$. In einem linearen Zusammenhang ist die Frage damit mit der Steigung der Geraden eigentlich beantwortet. Steigt die Kovariate um einen Wert, dann steigt $y$ um den Wert der Steigung $\beta_1$ der Geraden. Diesen konstanten Zusammenhang haben wir aber nicht bei einem quadratischen Zusammenhang wie in der rechten Abbildung. Wir können hier nicht sagen, dass wenn sich die Kovariate um einen Wert erhöht, sich auch $y$ um einen konstanten Wert ändert. Hier hängt es von dem betrachteten $c_1$-Wert ab.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der kontinuierlichen Kovariate und kontinuierlichen Messwerten. In einem Modell wird die Abhängigkeit vom Messwert $y$ und der Kovariate $c_1$ modellieren. **(A)** Linearer Zusammenhang. **(B)** Quadratischer Zusammenhang. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-intro-05

p1_intro_00 + p2_intro_00 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Schauen wir mal in ein Zahlenbeispiel und lassen die Beobachtungen weg. Beginnen wir einmal mit dem linearen Zusammenhang der Funktion $f(x) = 2x-1$. Ich habe die Gerade einmal in der folgenden Abbildung eingezeichnet. Wenn uns jetzt die Steigung an jedem beliebigen Punkt von $c_1$ interessiert, dann bilden wir die erste Abbleitung $f'(x) = 2$. Erhöht sich also der Wert von der Kovariate um 1 dann steigt der Wert von $y$ um 2 an. Wir sehen aber auch, dass für jedes beliebige Punktepaar wir eine Steigung von 2 vorliegen haben.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Gerade des Modells für einen linearen Zusammenhang. In einem Modell wird die Abhängigkeit vom Messwert und der Kovariate modellieren. **(A)** Lineares Modell mit Gleichung. **(B)** Steigung an der Geraden für ausgewählte Punktepaare. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-intro-06

p1_intro_01 + p2_intro_01 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Spanndender wird die Sachlage in einem quadratischen Zusammenhang in der folgenden Abbildung. Oder allgemeiner gesprochen, wenn wir keinen linearen Zusammenhang vorliegen haben. Wir haben hier den Zusammenhgang $f(x) = -0.5x^2+5x$ vorliegen. Damit haben wir dann eine erste Ableitung von $f'(x) = x+5$. Wie du siehst, ändert sich auch die Steigung in Abhänigkeit von $x$. Wenn wir die Werte der Kovariaten links betrachten, dann liegt hier eher eine positive Steigung vor. Wenn wir nach rechts laufen, dann sehen wir immer stärkere negative Steigungen. Und hier kommen dann die *Marginal effect models* ins Spiel. Wir können allgemein gesprochen uns mit den *Marginal effect models* für jeden Wert der Kovariate die Steigung wiedergeben lassen.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Gerade des Modells für einen quadratischen Zusammenhang. In einem Modell wird die Abhängigkeit vom Messwert und der Kovariate modellieren. **(A)** Quadratisches Modell mit Gleichung. **(B)** Steigung an der Geraden für ausgewählte Punktepaare. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-intro-07


p1_intro_02 + p2_intro_02 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Aber Moment, denkst du jetzt, in dem linearen Zusammenhang ist es ja einfach mit der Steigung für jeden beliebigen Wert der Kovariate. Wir erhalten für jeden $c_1$-Wert genau die gleiche Steigung. Aber bei den nicht-linearen Zusammenhängen hat ja jeder Wert der Kovariate seine eigene Steigung. Wenn wir viele $c_1$-Werte gemessen haben, dann haben wir ja dutzende bis hunderte Steigungen durch ein *Marginal effect model* ermittelt. Das stimmt und damit kommen wir auch gleich zu dem nächsten Punkt, dem Aggregieren der Daten. Oder wie im folgenden Cartoon richtig dargestellt, müssen wir uns überlegen wie wir den den Durchschnitt der Steigungen berechnen.

!["Should I cut the red wire or the blue one!?" "WAIT! We're going to watch ALL the action movies from the '80s and '90s and then calculate the average!" Quelle: wumo.com](images/average.jpg){#fig-pretest-barplot-02 fig-align="center" width="100%"}

Wir haben uns in dem obigen Beispiel nur ein simples Modell mit einer Kovariate angeschaut. Jetzt kann es aber auch sein, dass deine $x$-Werte keine kontinuierlichen Messwerte wie das Gewicht oder die Zeit sind, sondern eben ein Gruppen sind. Also du hast verschiedene Düngestufen oder Behandlungsgruppen auf der $x$-Achse als Faktoren aufgetragen. Auch dann können wir eine lineare Regression rechnen, eine Linie durch die Punkte legen und anschließend ein *Marginal effect model* rechnen. Was ist also der Unterschied zwischen einer kontinuierlichen und einem kategoriellen Einflussvariablen? Oder wie uterscheiden sich nochmal Kovariaten von Faktoren?

#### Unterschied zwischen kontinuierlichen und kategoriale $x$-Werte {.unnumbered .unlisted}

Wir kennen verschiedene Namen für das Gleiche. So nennen wir dann ein kontinuierliches $x$ dann auch gerne eine stetige Variable oder intervalskaliert. Nichts destotrotz, wir haben ein $x$ was in kleinen, marignalen Schritten anwachsen kann. Hier kannst du eben an das Gewicht der Flöhe oder aber Zeiteinheiten sowie das Einkommen denken. Wir verändert sich das $y$, wenn wir die $x$-Werte erhöhen? Wir benennen daher auch die kontinuierliche Einflussvariablen als Kovariaten $c$.

Auf der anderen Seite haben wir dann kategoriale oder kategorielle $x$-Werte. Diese bezeichnen wir dann auch gerne diskret. Wenn wir die Werte von $x$ ändern, dann springen wir in eine neue Gruppe und es liegt hier eigentlich kein kleiner Schritt vor. Hier haben wir dann eben Düngestufen oder aber Behandlungsgruppen vorliegen. Hier fragen wir uns, wie ändert sich der Wert von $y$, wenn wir eine Gruppe in $x$ weiterspringen? Wir benennen dann kategoriale Einflussvariablen als Faktoren $f$.

In der folgenden Abbildung von @heiss2022 siehst du nochmal schön den Unterschied dargestellt. Wir haben bei der einer kategorialen Variable einen Schalter. Entweder ist der Schalter an oder eben aus. Im simpelsten Fall haben wir männliche oder eben weibliche Flöhe vorliegen. Das Geschlecht ist somit kategorial. Die Sprungweite oder das Gewicht von Flöhen ist eine kontinuierliche Variable. Wir haben einen Schieberegeler den wir ziemlich fein einstellen können. Mehr dazu im [Kapitel zu der simplen linearen Regression](#sec-modeling-simple-stat).

![Unterschied zwischen einer kategorialen Variable und einer kontinuierlichen Variable in einem statistischen Modell visualisiert als Schalter und Schieberegler. Übersetzt nach @heiss2022](images/marginal/slider-switch-annotated-trans.png){#fig-utest-intro-01 fig-align="center" width="100%"}

Wir können usn den Schieberegeler auch einmal mathematisch aufschreiben, Wir haben dann unseren Messwert auf der linken Seite und unsere erklärenden Variablen auf der rechten Seite. Unser $X$ kann dann entweder eine Kovariate oder eben ein Faktor sein.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der simplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ für die Steigung der Graden für eine Einflussvariable $x_1$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-07

p_simple_model
```

Als wäre das nicht kompliziert genug, schauen wir uns meistens dann nicht nur eine $x$ Variable in einem Modell an, die wir dann ändern, sondern eben mehrere. Dann kombinieren wir noch gerne kontinuierliche und kategoriale $x$-Werte in einem Modell miteinander und erhalten ein Mischboard. Wir können einiges an Schiebereglern und Schaltern in einem Modell betätigen und erhalten entsprechende andere $y$-Werte. Hier helfen dann auch *Marginal effect models* um mehr Erkenntnisse aus einem Modell zu erhalten. Mehr dazu im [Kapitel zu der multiplen linearen Regression](#sec-mult-reg-basic).

![Kombination verschiedener kategorialer Variablen und kontinuierlichen Variablen in einem statistischen Modell visualisiert als Mischboard. Übersetzt nach @heiss2022](images/marginal/mixer-board-annotated-trans.png){#fig-utest-intro-02 fig-align="center" width="100%"}

Wenn wir uns dann eine multiple lineare Regression anschauen, dann haben wir immernoch einen Messwert vorliegen. Wir haben aber jetzt mehr erklärende Variablen, die eben nur Kovariaten oder Faktoren sein können oder eben auch eine Mischung aus beidem. Dann haben wir kombinierte Modelle aus Kovariaten und Faktoren vorliegen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2.25
#| fig-width: 7
#| fig-cap: "Formelschreibweise der multiplen linearen Regression beinhaltend die Koeffizienten $\\beta_0$ für den y-Achsenabschnitt sowie $\\beta_1$ bis $\\beta_p$ für die partielle Steigung der Graden für jede Einflussvariable $x_1$ bis $x_p$. Die Residuen werden durch $\\epsilon$ abgebildet. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-04

p_mult_model 
```

Somit kommen wir dann hier mal zu einer Definition, wie wir dann die beiden Arten der möglichen $x$-Werte als kontinuierliche und kategoriale Werte sprachlich unterscheiden. Wir immer, je nach wissenschaftlichen Hintergrund können sich dann die Namen ändern und anders sein. Das ist dann eben so in der Statistik.

Marginal effect (deu. *marginaler Effekt*)

:   Ein marginaler Effekt beschreibt den statistischen Effekt für kontinuierliche erklärende Variablen damit auch die partielle Ableitung einer Variablen in einem Regressionsmodell oder eben den Effekt eines einzelnen Schiebereglers.

Conditional effect (deu. *bedingter Effekt*) oder Gruppenkontrast (eng. *group contrast*)

:   Ein bedingter Effekt beschreibt den statistischen Effekt für kategoriale erklärende Variablen damit auch den Unterschied in den Mittelwerten, wenn eine Bedingung eingeschaltet ist und wenn sie ausgeschaltet ist. Der Effekt eines einzelnen Schalters.

Als wäre das nicht schon kompliziert genug, variieren nicht nur die Einflussvariablen in der Anzahl und dem Typ. Wir haben auch je nach Messwert auch noch andere Eigenschaften unserer linken Seite. Je nach Messwert haben wir eine andere Verteilungsfamilie vorliegen und damit auch eine andere Interpretation unserer Einflussvariablen. In der folgenden Abbildung habe ich dir mal einen Auszuga aus der schreckliche netten Familie der Verteilungsfamilien mitgebracht. Wir sehen hier die Variationsmöglichkeiten in den Einflussvariablen wie auch in den Messwerten.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.7
#| fig-width: 7
#| fig-cap: "Erweiterte Darstellung der statistischen Modellierung. Die Messwerte $Y$ folgen einer Verteilung. Die Einflussvariablen liegen kontinuierlich als Kovariaten oder aber kategorial als Faktoren vor. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-09

p_lhs_rhs_detail
```

#### Unterschied `{marginaleffects}` und `{emmeans}` {.unnumbered .unlisted}

Wenn wir *Marginal effect models* rechnen wollen, dann können wir im Prinzip auf zwei große Pakete zurückgreifen. Einmal das [R Paket `{marginaleffects}`](https://marginaleffects.com/) sowie das [R Paket `{emmeans}`](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents). Das [R Paket `{modelbased}`](https://easystats.github.io/modelbased/index.html) setzt sich im Prinzip auf die beiden Pakete drauf und ist mehr oder minder ein Wrapper mit anderen Funktionsnamen. Das ist eigentlich eine gute Idee und ich zeige dann auch nochmal, wie sich das R Paket `{modelbased}` verhält. Kommen wir erstmal zu dem hauptsächlichen Unterschied zwischen unseren beiden Elefanten.

Wie unterscheiden sich `{emmeans}` und `{marginaleffects}`?

:   Das R Paket `{emmeans}` erstellt Durchschnittswerte der Daten und fügt diese Durchschnittswerte dann in Modelle ein. Das R Paket `{marginaleffects}` fügt alle Werte der Daten in ein Modell ein und erstellt dann Durchschnittswerte aus der Ausgabe des Modells. Am Ende ist es vermutlich dann auch wieder ein nur kleiner Unterschied, der was ausmachen kann. Aber da kommt es dann auf die wissenschaftliche Fragestellung an.

Dabei gibt es noch einen weiteren bedeutenden Unterschied zwischen den beiden Paketen, die sich dann direkt aus der Aggregierung der Daten ableitet. Die Frage ist ja, erst den Mittelwert bilden und dann Modellieren oder umgekehrt. Das R Paket `{emmeans}` hat als philosophischen Hintergrund experimentelle Daten als Basis. Das R Paket `{marginaleffects}` hingegen nimmt beobachtete Daten an. Hier möchte ich dann einmal die Vingette des R Pakets `{emmeans}` zitieren.

> *"To start off with, we should emphasize that the underpinnings of estimated marginal means – and much of what the `{emmeans}` package offers – relate more to experimental data than to observational data. In observational data, we sample from some population, and the goal of statistical analysis is to characterize that population in some way. In contrast, with experimental data, the experimenter controls the environment under which test runs are conducted, and in which responses are observed and recorded. Thus with experimentation, the population is an abstract entity consisting of potential outcomes of test runs made under conditions we enforce, rather than a physical entity that we observe without changing it." --- [R Paket `{emmeans}`](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#contents)*

Was will uns nun dieser Text sagen und was bedeutet der Unterschied zwischen experimentellen und beobachteten Daten?

-   Wir nutzen `{emmeans}`, wenn wir Gruppenvergleiche aus einem experimentellen, faktoriellen Design rechnen wollen. Solche faktorielle Designs sind in den Agrarwissenschaften sehr häufig.
-   Wir nutzen `{marginaleffects}`, wenn wir beobachtete Daten vorliegen haben. Dies ist sehr häufig bei zeitlichen Verläufen der Fall. Wenn wir also wissen wollen, wie ändert sich den Messwert über die Zeit?

Am Ende nutze ich dann in den Gruppebvergleichen immer noch `{emmeans}`, da das Paket einfach besser zu dem faktoriellen Design passt. Wenn wir uns aber mit Modellen beschäftigen, dann bevorzuge ich das R Paket `{marginaleffects}`. Oder um es etwas klarer zu sagen, sobald ich eine Kovariate in meinem Modell habe, dann wechsel ich das Paket und rechne alles in `{marginaleffecst}`. Damit haben wir alles zusammen, um uns jetzt einmal mit der Anwendung der *Marginal effect models* zu beschäftigen.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, gtsummary, marginaleffects, emmeans, scales,
               janitor, ggpmisc, conflicted)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::filter)
conflicts_prefer(ggplot2::annotate)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", 
            "#009E73", "#F0E442", "#F5C710", 
            "#0072B2", "#D55E00", "#CC79A7")
## 
nice_number <- label_number(style_negative = "minus", accuracy = 0.01)
nice_p <- label_pvalue(prefix = c("p < ", "p = ", "p > "))
find_intercept <- function(x1, y1, slope) {
  intercept <- slope * (-x1) + y1
  return(intercept)
}
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

#### Modellierung von Enzymen {.unnumbered .unlisted}

```{r}
enzyme_tbl <- read_excel("data/enzyme_kinetic.xlsx") |> 
  mutate(grp = factor(grp, levels = c("niedrig", "mittel", "hoch")))  
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-margin-table-01
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

enzyme_raw_tbl <- read_excel("data/enzyme_kinetic.xlsx") 

rbind(head(enzyme_raw_tbl, n = 3),
      rep("...", times = ncol(enzyme_raw_tbl)),
      tail(enzyme_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-margin-table-02
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

enzyme_raw_tbl |> 
  tabyl(ph) |> 
  mutate(percent = scales::percent(percent)) |> 
  kable(align = "c", "pipe")
```

$$
y = x^3 - 8x^2 + 10x + 10
$$

Funktion der Steigung als erste Ableitung nach

$$
y' = 3x^2 - 16x + 10
$$

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Scatterplot der *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-enzyme-01

p1_model_enzyme_01
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** gg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-enzyme-02

p1_model_enzyme_02 + p2_model_enzyme_02 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Modellierung von Flöhen {.unnumbered .unlisted}

```{r}
flea_model_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(feeding = as_factor(feeding),
         stage = as_factor(stage),
         bonitur = as.numeric(bonitur),
         infected = factor(infected, labels = c("healthy", "infected"))) |> 
  select(feeding, stage, jump_length, weight, hatched, count_leg,  bonitur, infected) 
```

Ein Satz zur Einheit

```{r}
flea_model_tbl <- flea_model_tbl |> 
  mutate(hatched = hatched/24/7)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac1cov-table
#| tbl-cap: "Daten für die einfaktorielle MANOVA mit der Sprungweite in [cm] und dem Gewicht der Flöhe in [mg] für drei Floharten."

flea_model_raw_tbl <- read_excel("data/fleas_model_data.xlsx") |> 
  mutate(bonitur = as.numeric(bonitur),
         infected = as.character(factor(infected, labels = c("healthy", "infected")))) |> 
  select(feeding, stage, jump_length, weight, count_leg, hatched, bonitur, infected) |> 
  mutate_if(is.numeric, round, 2)

rbind(head(flea_model_raw_tbl, n = 3),
      rep("...", times = ncol(flea_model_raw_tbl)),
      tail(flea_model_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10.5
#| fig-cap: "foo. **(A)** Kombinierte Darstellung in einem Scatterplot **(B)** Aufgeteilte Darstellung für beide Entwicklungsstadien. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-1

p1_model_flea + p2_model_flea + p3_model_flea +
  plot_layout(ncol = 3, widths = c(1.25, 1.25, 2.5)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-infected-model-fleas
#| tbl-cap: "Deskriptive Statistik des Infektionsstatus (0 = nein / 1 = ja) mit Flohschnupfen aufgeteilt nach den Faktoren und anderen Variablen."

flea_model_tbl |>
  select(infected, feeding, stage) |> 
  tbl_summary(
    by = infected,
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"
    ),
    digits = all_continuous() ~ 2,
    #label = count_color ~ "Anzahl Farben",
    missing_text = "(Missing)"
  )
```

## Visualisierung von Modellen

In dem folgenden Abschnitten wollen wir immer Modell in unsere Visualisierungen einzeichen. Nehmen wir einmal einen simplen Datensatz,d en wir uns einfach selber bauen und dann wollen wir dort eine Linie durchzeichnen. Dafür nehmen wri einmal zwanzig x-Werte und bauen uns dann die y-Werte nach $y = 1.5 + 0.75 \cdot x$ zusammen. Dann addieren wir noch einen Fehler aus einer Standardnormalverteilung hinzu. Wenn wir keinen Fehler hinzuaddieren würden, dann lägen die Punkte wie auf einer Perlenschnur aneinandergereit.

```{r}
set.seed(20250703)
modell_line_tbl <- tibble(x = rnorm(20, 2, 1),
                          y = 1.5 + 0.75 * x + rnorm(length(x), 0, 1))
```

Jetzt können wir einmal das Modell anpassen und schauen, ob wir die Koeffizienten des Modells wiederfinden. Dann wollen wir natürlich auch sehen, ob unser Modell durch die Punkte läuft. Also erstmal das Modell mit `lm()` gebaut. Dann schauen wir uns noch die Koeffizienten einmal mit an. Bei nur so wenigen Beobachtungen werden die Koeffizienten aus dem Modell nicht mit den voreingestellten übereinstimmen.

```{r}
model_fit <- lm(y ~ x, modell_line_tbl)
model_fit
```

In der folgenden Abbildung siehst du dann einmal den Scatterplot von unseren x-Werten und y-Werten. Wir wollen jetzt die Gerade, die wir im Modell geschätzt haben einmal durch die Punkte legen um zu schauen, ob das Modell auch die Punkte beschreibt. Dabei soll die Gerade durch die Mitte der Punkte laufen und die Punkte sollten auf beiden Seiten der Geraden gleichmäßig verteilt sein.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 7
#| fig-cap: "Scatterplot der x-Werte und y-Werte. Durch die Punkte soll die Gerade aus dem Modell gelegt werden. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-line-01

ggplot(modell_line_tbl, aes(x, y)) +
  theme_minimal() +
  geom_point()
```

Wir haben jetzt verschiedene Möglichkeiten die Koeffizienten und damit das Modell in den obigen Plot einzuzeichnen. Ich zeige dir hier einmal die häufigsten, die ich dann auch nutze. Erstmal die Anwendung direkt in `{ggplot}` und dann einmal noch in dem R Paket `{ggpmisc}`.

#### ...mit `{ggplot}` {.unnumbered .unlisted}

::: panel-tabset
## `geom_function()`

In der Funktion `geom_function()` müssen wir die Funktion angeben, die wir dann abbilden wollen. Wenn du verstehst, was die Koeffizienten in dem Modell bedeuten, dann kannst du natürlich die mathematische Funktion wie hier entsprechend ergänzen.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 7
#| fig-cap: "Scatterplot der x-Werte und y-Werte. Durch die Punkte läuft die Gerade mit den Koeffizienten aus dem Modell. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-line-02

ggplot(modell_line_tbl, aes(x, y)) +
  theme_minimal() +
  geom_point() +
  geom_function(fun = \(x) 1.9574 + 0.5534 * x, 
                color = "#CC79A7")
```

## `geom_line(aes(y = predict(model_fit)))`

Manchmal ist das Modell zu komplex, dass wir die mathematische Funktion einfach aufschreiben könnten. In dem Fall hilft die Funktion `geom_line()` die wir dann die vorhergesagten y-Werte mit der Funktion `predict()` aus dem Modell übergeben. Das funktioniert auch sehr gut.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 7
#| fig-cap: "Scatterplot der x-Werte und y-Werte. Durch die Punkte läuft die Gerade mit den vorhergesagten Werten aus dem Modell. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-line-03

ggplot(modell_line_tbl, aes(x, y)) +
  theme_minimal() +
  geom_point() +
  geom_line(aes(y = predict(model_fit)), 
                color = "#CC79A7")
```

## `geom_smooth()`

Abschließend können wir auch einfach so eine Gerade durch die Punkte legen indem wir die Funktion `geom_smooth()` als eine Art der Glättung nutzen. Aber hier muss ich sagen, dass uns dann die Geradengleichung fehlt. So mal zum gucken ist das wunderbar. Du kannst über die Option `formula` auch eine Funktion übergeben. Darüber hinaus erhalten wir dann noch einen Fehlerbalken des Standardfehlers, was in manchen Fällen nützlich ist. Wenn du die Geradengleichung brauchst, dann schaue einmal in dem Paket `{ggpmisc}` rein.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 7
#| fig-cap: "Scatterplot der x-Werte und y-Werte. Durch die Punkte läuft die Gerade aus einer Glättung. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-line-04

ggplot(modell_line_tbl, aes(x, y)) +
  theme_minimal() +
  geom_point() +
  geom_smooth(method = "lm", color = "#CC79A7") +
  geom_smooth(method = "lm", formula = y ~ I(x^4), 
              color = "#0072B2")
```
:::

#### ...mit `{ggpmisc}` {.unnumbered .unlisted}

Ich möchte hier nich zu sehr in die Tiefe von `{ggpmisc}` gehen, aber das Paket verbindet im Prinzip die Funktion `geom_smooth()` mit der Wiedergabe der Informationen zu den Regressionsgleichungen. Du findest bei StackOverflow einmal eine schöne Übersicht in [Add regression line equation and R\^2 on graph](https://stackoverflow.com/questions/7549694/add-regression-line-equation-and-r2-on-graph). Wenn du mehr willst, dann schaue dir einmal die Hilfeseite von `{ggpmisc}` mit [Fitted-Model-Based Annotations](https://cran.r-project.org/web/packages/ggpmisc/vignettes/model-based-annotations.html) näher an. Es geht echt eine Menge, von dem ich hier nur einmal den Klassiker zeige. Wir wollen einmal die Regressionsgleichung plus das Bestimmtheitsmaß einzeichnen. Das geht über drei Funktionen zusammen mit der Regressionsgeraden.

```{r}
#| message: false
#| echo: true
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 7
#| fig-cap: "Scatterplot der x-Werte und y-Werte. Durch die Punkte läuft die Gerade aus einer Glättung plus die Geradengleichung und das Bestimmtheitsmaß. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-line-05

ggplot(modell_line_tbl, aes(x, y)) +
  theme_minimal() +
  geom_point() +
  stat_poly_line(color = "#CC79A7") +
  stat_poly_eq(use_label("eq")) +
  stat_poly_eq(label.y = 0.9) 
```

## Datenraster

Was ist ein Datenraster (eng. *data grid*) eigentlich? Wir brauchen die Idee des Datenrasters um überhaupt die Vorhersagen, die Steigung und die kontrafaktischen Vergleiche zu verstehen. Im Prinzip beinhaltet das Datenraster die Information zu welchen Beobachtungen wir eine Vorhersage machen oder die Steigung berechnen wollen. Wenn wir nochmal kutz zu dem Enyzmebeispiel kommen, zu welchen pH-Werten möchtest du dann eine Steigung oder aber eine Vorhersage der Enzymetätigkeit haben? Beginnen wir mit einem einfachen Beispiel um zu verstehen was die einzelnen Datenraster aussagen wollen.

In Folgenden siehst du einmal einen kleinen Datensatz mit einer numerischen Variable, einer dichotomen Variable sowie einer Variable mit drei Kategorien. So ähnlich haben wir ja auch Datensätze in echt vorliegen.

```{r}
set.seed(20250709)
grid_tbl <-  tibble(numerisch = rnorm(n = 8),
                    dichotom = rbinom(n = 8, size = 1, prob = 0.5),
                    kategorial = sample(c("niedrig", "mittel", "hoch"), 
                                        size = 8, replace = TRUE))
```

#### Beobachtetes Raster (eng. *empirical grid*) {.unnumbered .unlisted}

```{r}
grid_tbl |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-01

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5), limits = c(-2, 8)) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5),
             color = "#D55E00", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Beobachtetes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

#### Interessantes Raster (eng. *interesting grid*) {.unnumbered .unlisted}

```{r}
datagrid(dichotom = c(0, 1), newdata = grid_tbl) |> tt()
```

```{r}
datagrid(numerisch = range, dichotom = mean, kategorial = unique, 
         newdata = grid_tbl) |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-02

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 1, 2, 3.5, 5.5, 7), limits = c(-2, 8)) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = c(0, 1, 2, 3.5, 5.5, 7),
             color = "#0072B2", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Interessantes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

#### Repräsentatives Raster (eng. *representative grid*) {.unnumbered .unlisted}

```{r}
datagrid(grid_type = "mean_or_mode", newdata = grid_tbl) |> tt()
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7.5
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-grid-03

a_line <- \(x) x^3 + -8*x^2 + 10*x + 10
mean_rep_grid <- mean(c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 7.5))

enzyme_tbl|> 
  ggplot(aes(ph, activity)) +
  theme_marginal() +
  geom_function(fun = a_line, linewidth = 1, color = "black", alpha = 0.5) +
  scale_x_continuous(breaks = mean_rep_grid, limits = c(-2, 8),
                     label = expression(bar(y)[pH])) +
  scale_y_continuous(breaks = c(-50, 0, 50, 100), limits = c(-55, 75)) +
  geom_vline(xintercept = mean_rep_grid,
             color = "#CC79A7", linetype = 21, size = 1) +
  geom_point() +
  labs(x = "Korrigierter pH-Wert", y = "Standardisierte Enzymaktivität",
       title = "Interessantes Raster") +
  theme(legend.position = "none") +
  theme(panel.grid.major.y = element_blank())
```

#### Balanciertes Raster (eng. *balanced grid*) {.unnumbered .unlisted}

```{r}
datagrid(grid_type = "balanced", newdata = grid_tbl) |> tt()
```

#### Kontrafaktisches Raster (eng. *counterfactual grid*) {.unnumbered .unlisted}

```{r}
cf_grid <- datagrid(
  dichotom = c(0, 1),
  grid_type = "counterfactual",
  newdata = grid_tbl[1:5,]
)
nrow(cf_grid )
```

::: panel-tabset
## Beobachtete Daten

```{r}
grid_tbl[1:5,] |> tt()
```

## Kontrafaktisches Raster

```{r}
cf_grid |> tt()
```
:::

## Steigung (eng. *slopes*)

> *"Let us introduce another concept that is likely to get very popular in the near future within the world of regressions. Derivatives." --- [`{modelbased}`](https://easystats.github.io/modelbased/articles/derivatives.html#effect-derivatives)*

Beginnen wir einmal mit der Steigung. Das heißt, wir haben hier zumindest ein einkovariates Modell vorliegen. Wir haben auf der x-Achse die Kovariate und dann kann es noch sein, dass wir zusätzlich einen Faktor als gruppierende Variable vorliegen haben. Wenn du mehr als einen Faktor vorliegen hast, dann wird die Sache schon sehr kompliziert. Die Idee ist ja, wie sich die Werte des Messwerts in Abhängigkeit der Kovariate ändern. Darüber hinaus macht die Betrachtung der Steigung erst so richtig Sinn, wenn wir uns mit nicht lineare Modellen beschäftigen. Ansonsten ist die Steigung ja über den ganzen Zahlenraum der Kovariate konstant. Mag auch von Interesse sein, aber die Stärke der *Marginal effect models* liegt dann doch eher in der Beschreibung der Steigung von nicht linearen Modellen. Fangen wir aber einmal mit den Grundlagen in einem einkovariaten Modell an.

### Einkovariates Modell

Im Folgenden schauen wir usn einmal die Modellierung der Flöhe an. Dort betrachten wir dann wie sich die Sprungweiten in Abhängigkeit von der Schlupfdauer verändert. Wir sidn hier wiedrum an der Steigung einer Tangente zu den Zeitpunkten der Schlupfzeiten interessiert. Hier sprechen wir dann auch von der Ableitung (eng. *derivative*). Die erste Ableitugn liefert uns ja die Steigung der Tangente an dem entsprechenden Punkt. Da wir hier nur ein einkovariates Modell vorliegen haben, müssen wir uns hier noch nicht mit komplexeren Abhängigkeiten rumschlagen.

#### Modellierung von Flöhen {.unnumbered .unlisted}

In der folgenden Abbildung siehst du einmal die Zusammenhänge von der Schlupfzeit und der Sprungweite. In der linken Abbildung ist einmal der lineare Zusammenhang dargestellt. Da wir hier eine Grade zeichnen, haben wir natürlich nur eine Steigung. Die Steigung ist immer $+10.5$ und damit nimmt die Sprungweite für jede Steigerung der Einheit in den Schlupfzeiten um $+10.5cm$ zu. Das ist etwas langweilig und in einem linearen Modell benötigen wir auch prinzipiell keine *Marginal effect models*. Wir können trotzdem eines rechnen und dann von den statistischen Maßzahlen eines *Marginal effect models* profitieren, aber die Stärke liegt dann eben in dem nicht linearen Modell auf der rechten Seite. Wir haben hier eine S-Kurve und damit auch verschiedene Steigungen entlang der Graden. Das sehen wir dann auch an der ersten Ablietung, die wiederum noch die Kovariate enthält und somit ist die Steigung abhängig von dem Wert der Kovariate der Schlupfzeit.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Scatterplot der Sprungweiten und Schlupfzeiten von Flöhen. **(A)** Linearer Zusammenhang mit Gradengleichung und der ersten Ableitung **(B)** Quadratischer Zusammenhang mit S-Kurve sowie Gradengleichung und erster Ableitung. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-2

p1_slope_flea <- ggplot(flea_model_tbl, aes(x = hatched, y = jump_length)) +
  theme_marginal() +
  geom_point2() +
  stat_smooth(method = "lm", formula = y ~ x, linewidth = 1, 
              color = cb_pal[2], se = FALSE) +
  geom_richtext(aes(x = 3.5, y = 113, 
                    label = "f(x) = 64.2 + 10.5x<br>f'(x) = 10.5")) +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]",
       title = "Linearer Zusammenhang") 

p2_slope_flea <- ggplot(flea_model_tbl, aes(x = hatched, y = jump_length)) +
  theme_marginal() +
  geom_point2() +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), linewidth = 1, 
              color = cb_pal[3], se = FALSE) +
  geom_richtext(aes(x = 3.5, y = 112, 
                    label = "f(x) = 125 - 53.8x + 18.9x² - 1.6x³<br>f'(x) = -53.8 + 37.8x - 4.8x²")) +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]",
       title = "Quadratischer Zusammenhang") 

p1_slope_flea + p2_slope_flea +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Schauen wir uns dann nochmal die Mathematik hinter den beiden Modellierungen an. Wir haben ja einmal den linearen Zusammenhang modelliert und eine Gradengleichung erhalten. Dann haben wir das Ganze auch einmal für den quadratischen Zusammenhang gemacht. Wir wollen jetzt einmal das Modell rechnen und dann noch die erste Ableitung bilden.

::: panel-tabset
## Linearer Zusammenhang ($y \sim x$)

Beginnen wir mit dem linearen Zusammenhang. In der folgenden Modellierung rechnen wir einmal ein lineares Modell und erhalten dann den Intercept sowie die Steigung für die Schlupfzeiten. Wir haben hier eine Steigung von $+10.5$ vorliegen. Für jede Woche mehr Schlupfzeit steigt die Sprungweite um $10.5cm$ an.

```{r}
model_ln <- lm(jump_length ~ hatched, data = flea_model_tbl)
tidy(model_ln)
```

Wir können dann den Zusammenhang auch nochmal mathematisch aufschrieben. Wir wolle einmal die Ableitung für die Kovariate bilden. Die erste Ableitung bildet sich dann wie folgt.

$$
\begin{aligned}
\operatorname{E}[y \mid x] &= \beta_0 + \beta_1 x \\[4pt]
\frac{\partial \operatorname{E}[y \mid x]}{\partial x} &= \beta_1
\end{aligned}
$$

Dann können wir das Ganze auch einmal durchführen. Wir haben ja die Zahlen für die Koeffizienten aus dem obigen Modell. Wir setzen also die Zahlen für den Intercept $\beta_0$ und die Steigung $\beta_1$ einmal ein und dann leiten wir nach der Schlupfzeit ab. Wir erhalten dann die Steigung von $+10.5cm$ wieder.

$$
\begin{aligned}
\operatorname{E}[\text{Sprungweite} \mid \text{Schlupfzeit}] &= 64.2 + 10.5 \times \text{Schlupfzeit} \\[6pt]
\frac{\partial \operatorname{E}[\text{Sprungweite} \mid \text{Schlupfzeit}]}{\partial\ \text{Schlupfzeit}} &= 10.5
\end{aligned}
$$

Das war jetzt kein großer Akt, aber wir sehen hier nochmal, wie die Idee ist. Wir hätten hier auch einfach die Koeffizienten aus dem Modell nehmen können, wie wir das auch ganz normal in der Interpretation eines linearen Modells machen. Spannender wird es in dem folgenden Tab, wenn wir eben keinen linearen Zuammenhang haben.

## Quadratischer Zusammenhang ($y \sim x + x^2 + x^3$)

Wenn wir eine quadratische Gleichung in R bauen, dann nutzen wir den Term `I()` um klar zu machen, dass wir jetzt einen quadratischen Term modellieren wollen. Prinzipiell könnten wir auch hier effizeinter die Funktion `poly()` nutzen, aber dann sehen wir nicht so gut die Koeffizienten und wir können auch nicht die Gradengleichung so einfach nachbauen. Mehr dazu dann im [Kapitel zur nicht linearen Regression](#sec-non-linear). Erstellen wir also einmal unser quadratisches Modell mit drei quadratischen Termen von $x^1$ bis $x^3$. Dann können wir die Koeffizienten einmal in unsere mathematische Formel einsetzen.

```{r}
model_sq <- lm(jump_length ~ hatched + I(hatched^2) + I(hatched^3),
               data = flea_model_tbl)
tidy(model_sq)
```

Auch hier ist die mathematische Formel etwas länger und wir erhalten dann auch eine quadratische erste Ableitung für die Steigung an verschiedenen Werten der Schlupfzeiten.

$$
\begin{aligned}
\operatorname{E}[y \mid x] &= \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3\\[4pt]
\frac{\partial \operatorname{E}[y \mid x]}{\partial x} &= \beta_1 + 2 \beta_2 x + 3 \beta_3 x^2
\end{aligned}
$$

Dann können wir die Koeffizienten aus dem Modell einmal in die Formel einsetzen und die erste Ableitung dann bilden. Hier sehen wir dann sehr schön, dass wir dann für verschiedende Schlupfzeiten immer andere Steigungen erhalten würden.

$$
\begin{aligned}
\operatorname{E}[\text{Sprungweite} \mid \text{Schlupfzeit}] = 125 &+ (-53.8 \times \text{Schlupfzeit})\\ 
&+ (18.9 \times \text{Schlupfzeit}^2)\\ 
&+ (-1.6 \times \text{Schlupfzeit}^3)
\end{aligned}
$$

$$
\begin{aligned}
\frac{\partial \operatorname{E}[\text{Sprungweite} \mid \text{Schlupfzeit}]}{\partial\ \text{Schlupfzeit}} = -53.8 &+ (2\times 18.9 \times \text{Schlupfzeit})\\ &+ (3 \times -1.6 \times \text{Schlupfzeit}^2)
\end{aligned}
$$

Wenn wir jetzt für jede Schlupfzeit dann immer die Steigung berechnen müssten, dann wäre das sehr aufwendig. Wir müssten ja erstmal das Modell rechnen, dann die mathematische Formel aufstellen. Danach könnten wir dann ja die erste Ableitung bilden. Je komplexer das Modell, desto aufwendiger wird es. Da kommen jetzt die *Marginal effect models* ins Spiel, die uns für sehr viele verschiedene Modelle die Steigungen wiedergeben können.
:::

Betrachten wir nochmal die erste Ableitung der quadratischen Funktion für die Sprungweiten aus den Schlupfzeiten. Ich habe hier einmal die Funktion aufgeschrieben und dann einmal drei Werte für die Schlupfzeiten gewählt. Wir erhalten dann die Steigungen an den drei Schlupfzeiten durch die Funktion wiedergegeben. Für das erste ist es etwas ungewohnt, aber wir schauen uns die Steigung gleich einmal an.

```{r}
jump_hatched_slope <- function(x) -53.8 + (2 * 18.9 * x) + (3 * -1.6 * x^2)
jump_hatched_slope(c(1.25, 3.5, 5.75))
```

In der folgenden Abbildung habe ich dir dan einmal für die drei Schlupfzeiten die Steigung mit der Tangente an den jeweiligen Punkten visualisiert. Wie du siehst haben die drei Punkte jeweils eine andere Steigung. Damit ist die Aussage auf die Sprungweite auch jeweils eine Andere, wenn wir uns verschiedene Schlupfzeiten anschauen. So haben wir zu geringen Schlupfzeiten eher einen Abfall der Sprungweiten und zu höhren Schlupzeiten eine Steigerung der Sprungweiten vorliegen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Scatterplot der Sprungweite und der Schlupfzeiten. Die angepasste Grade läuft durch die Punkte. An drei Schlupfzeiten ist die Steigung der Tangente angegeben. Die Steigung unterscheidet sich durch die S-Kurve an allen drei Punkten. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-3

tangents <- model_sq |> 
  augment(newdata = tibble(hatched = c(1.25, 3.5, 5.75))) |> 
  mutate(slope = jump_hatched_slope(hatched),
         intercept = find_intercept(hatched, .fitted, slope)) |> 
  mutate(nice_label = glue("Schlupfzeit: {hatched}<br>",
                           "Fitted Sprungweite: {nice_number(.fitted)}<br>",
                           "Steigung: **{nice_number(slope)}**"))

ggplot(flea_model_tbl, aes(x = hatched, y = jump_length)) +
  theme_marginal() +
  geom_point2() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), linewidth = 1.25, 
              se = FALSE, color = cb_pal[3], fullrange = TRUE) +
  geom_abline(data = tangents, aes(slope = slope, intercept = intercept), 
              linewidth = 1, color = c("#F0E442", "#E69F00", "#D55E00"), linetype = "21") +
  geom_point(data = tangents, aes(x = hatched, y = .fitted), 
             size = 4, shape = 18, color = c("#F0E442", "#E69F00", "#D55E00")) +
  geom_richtext(data = tangents, size = 3,
                aes(x = hatched, y = .fitted, label = nice_label), nudge_y = 25,
                fill = c("#F0E442", "#E69F00", "#D55E00"), alpha = 0.9) +
  scale_x_continuous(breaks = seq(0, 7, 1), limits = c(0, 7)) +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]") 

```

Jetzt ist es natürlich nicht immer möglich für jedes Modell die Gradengleichung zu erhalten. Auch wenn wir da mit [WolframAlpha](https://www.wolframalpha.com/) gute Möglichkeiten haben, Gleichungen abzuleiten oder aber zu bestimmen. Dennoch ist es für manche Modelle gar nicht so einfach möglich eien geschlossene ableitbare Gleichung zu erstellen. Oder es ist so komplex, dass es nicht erstrebenswert ist. Daher haben wir ja das R Paket `{marginaleffects}` welches uns für ein beliebiges Datenraster einmal die Steigung bestimmen lässt. Hier also einmal die Steigung für die drei Schlupzeiten.

```{r}
#| message: false
#| warning: false
model_sq |> 
  slopes(newdata = datagrid(hatched = c(1.25, 3.5, 5.75)),
         hypothesis = 0)
```

Das Ganze geht super einfach und wir erhalten auch noch die jeweiligen Fehler sowie einen statistischen Test wiedergegeben, ob sich die Steigung von Null unterscheidet. Wir können hier auch die Option `hypothesis =` ändern und auf einen anderen Grenzwert testen. Das ist sehr praktisch dazu dann noch die 95% Konfidenzintervalle.

Abschließend mag es ganz interessant sein, wie sich die Steigung über die ganze Kovariate verhält. Also in unserem Fall wie ändert sich die Steigung über die Schlupfzeit? Dafür haben wir dann die Funktion `plot_slopes()`, die uns dann mit einem Fehlerterm einmal angibt, wie sich die Steigung ändert. Das ist natürlich sehr angenehm, wenn wir ein komplexes Modell haben, was wir uns nicht so einfach darstellen können.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Steigung der Tangente über die Schlupfzeiten zusammen mit dem 95% Konfidenzintervall. Kurze und lange Schlupfzeiten führen zu einer negativen Steigung im bezug zu der Sprungweite. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-4

plot_slopes(model_sq, 
            variables = "hatched", 
            condition = "hatched") +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]") +
  theme_marginal()
```

#### Modellierung von Enzymen {.unnumbered .unlisted}

Nachdem wir uns einmal konzeptionell mit der Steigung und damit der Ableitung beschäftigt haben, kommen wir einmal zu einem etwas komplexeren beispiel mit unseren Enzym. Wir haben ja hier eine klare S-Kurve in der Enzymeaktivität vorliegen. Da wir ja das theoretische Modell kennen, können wir auch hier einfach die Ableitung bilden. In der Praxis kennen wir aber das theoretsiche Modell nicht sondern müssen eben die Grade mit einem Algorithmus anpassen. In den folgenden Tabs zeige ich dir dann einmal die Anpassung mit verschiedenen Algorithmen. Dazu habe ich dann auch immer mit dem R Paket `{marginaleffects}` an drei augewählten Werten des pH-Wertes die Steigung berechnet. Die Koeffizienten aller drei Modelle lassen sich nicht direkt einfach interpretieren. Die Steigung jedoch schon.

::: panel-tabset
## `gam()`

Die beste Möglichkeit eine Modellierung zu rechnen ist die Nutzung von *Generalized additive model* (abk. *GAM*), die sehr effizient komplexe Verläufe mit einer Graden versehen können. Der größte Nacvhteil ist, dass wir eigentlich mit der Ausgabe der Koeffizienten eines *Generalized additive model* wenig anfangen können. Jedenfalls was die direkte Interpretation angeht. Hier helfen dann die Steigungen an vordefinierten Punkten natürlich super weiter. oder aber wir berechnen die mittlere Steigung. Hier erstmal das *Generalized additive model* geschätzt. Wir müssen nur sagen, welche Variable mit `s()` nicht linear modelliert werden soll.

```{r}
#| message: false
#| warning: false
gam_fit <- gam(activity ~ s(ph), data = enzyme_tbl)
```

Dann können wir uns auch für drei standardisierte pH-Werte die Steigung wiedergeben lassen. Wir müssen hier also nicht schauen, wie das Modell aussieht oder aber was die Gradengleichung wäre. Alles macht dann die Funktion `slope()` für uns.

```{r}
slopes(gam_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

Manchmal wollen wir auch die durchschnittliche Steigung über alle Kovariatenwerte haben, dann können wir die Funktion `avg_slopes()` nutzen. Wenn wir eine sehr stark kurvige Grade haben, dann müssen wir überlegen, ob der Durchschnitt viel aussagt.

```{r}
avg_slopes(gam_fit)
```

Am Ende können wir uns dann einmal die beiden Modelle mit den jeweiligen Steigungen anschauen. Auf der linken Seite findest du das theoretische Modell mit dem die Daten generiert wurden und damit auch die wahren Steigungen an den pH-Werten. In der rechten Abbildung siehst du dann die Abweichung durch das *Generalized additive model*. So weit liegen die Werte aber gar nicht auseinander.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Vergleich der theoretischen und *Generalized additive model* Modellierung für die Enzymeaktivität. An drei pH-Werten wurde die Steigung der Tangenten der Graden bestimmt. **(A)** Theoretisches Modell mit den wahren Steigungen aus der Datengenierung. **(B)** Das angepasste *Generalized additive model* mit den entsprechenden Steigungen aus dem Modell. Die grauen Linien stellen die wahren Tangenten aus dem theoretischen Modell dar. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-02

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell", subtitle = "") +
  p1_slope_01 +
  labs(subtitle = "") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## `poly()`

Die polynomiale Regression bietet sich an, wenn wir eine effiziente Variante der `I()` Form haben wollen. Wir müssen ja sonst immer sehr lange Terme schreiben, da wir alle Hochzahlen in Form von `I()` ausformulieren müssen. Die Variante mit `poly()` erlaubt uns die Kovariate zu benennen die mit quadratischen Termen modelliert werden soll. Wir müssen nur angeben, wie viele Exponenten wir haben wollen. In diesem Fall wähle ich drei Exponenten aus und damit modellieren wir eben $x^1 + x^2 + x^3$ in dem Modell. Darüber hinaus ist die Funktion `poly()` auch sehr effizient.

```{r}
#| message: false
#| warning: false
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
```

Dann können wir uns auch für drei standardisierte pH-Werte die Steigung wiedergeben lassen. Wir müssen hier also nicht schauen, wie das Modell aussieht oder aber was die Gradengleichung wäre. Alles macht dann die Funktion `slope()` für uns.

```{r}
slopes(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

Manchmal wollen wir auch die durchschnittliche Steigung über alle Kovariatenwerte haben, dann können wir die Funktion `avg_slopes()` nutzen. Wenn wir eine sehr stark kurvige Grade haben, dann müssen wir überlegen, ob der Durchschnitt viel aussagt.

```{r}
avg_slopes(poly_fit)
```

Am Ende können wir uns dann einmal die beiden Modelle mit den jeweiligen Steigungen anschauen. Auf der linken Seite findest du das theoretische Modell mit dem die Daten generiert wurden und damit auch die wahren Steigungen an den pH-Werten. In der rechten Abbildung siehst du dann die Abweichung durch polynomiale Regression. So weit liegen die Werte aber gar nicht auseinander.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Vergleich der theoretischen und der polynomialen Modellierung für die Enzymeaktivität. An drei pH-Werten wurde die Steigung der Tangenten der Graden bestimmt. **(A)** Theoretisches Modell mit den wahren Steigungen aus der Datengenierung. **(B)** Das angepasste polynomiale Modell mit den entsprechenden Steigungen aus dem Modell. Die grauen Linien stellen die wahren Tangenten aus dem theoretischen Modell dar. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-01

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell", subtitle = "") +
  p1_slope_00  +
  labs(subtitle = "") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## `loess()`

Eine etwas ältere Alternative zu dem *Generalized additive model* ist die lokale lineare Kernregression (eng. *locally estimated scatterplot smoothing*, abk. *loess*) oder einfach Loessregression. Hier müssen wir gar nichts weiter angeben, sondern können einfach die Funktion aufrufen. Wir erhalten hier aber keine Informationen über die Streuung der Punkte um die Loessgrade, so dass wir gleich nicht alles mit `{marginaleffects}` machen können, was in den beiden anderen Modellierungen geht.

```{r}
#| message: false
#| warning: false
loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
```

Dann können wir uns auch für drei standardisierte pH-Werte die Steigung wiedergeben lassen. Wir müssen hier also nicht schauen, wie das Modell aussieht oder aber was die Gradengleichung wäre. Alles macht dann die Funktion `slope()` für uns.

```{r}
#| message: false
#| warning: false
slopes(loess_fit, newdata = datagrid(ph = c(-1, 2, 6)))
```

Manchmal wollen wir auch die durchschnittliche Steigung über alle Kovariatenwerte haben. Da wir hier ein Problem mit der Varianzmatrix haben, müssen wir uns den Durchschnitt einmal händisch berechnen. Das geht aber auch sehr fix und wir erhalten faktisch die gleichen Werte nur eben ohne Standardfehler und andere statistische Maßzahlen.

```{r}
#| message: false
#| warning: false
slopes(loess_fit) |> 
  summarise(avg_slope = mean(estimate))
```

Am Ende können wir uns dann einmal die beiden Modelle mit den jeweiligen Steigungen anschauen. Auf der linken Seite findest du das theoretische Modell mit dem die Daten generiert wurden und damit auch die wahren Steigungen an den pH-Werten. In der rechten Abbildung siehst du dann die Abweichung durch Loessregression. So weit liegen die Werte aber gar nicht auseinander. Ich würde hier aber nur die Loesregression nutzen, wenn es unbedingt sein muss. Die *Generalized additive models* sind mittlerweile einfach die bessere Alternative.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Vergleich der theoretischen und der Loess-Modellierung für die Enzymeaktivität. An drei pH-Werten wurde die Steigung der Tangenten der Graden bestimmt. **(A)** Theoretisches Modell mit den wahren Steigungen aus der Datengenierung. **(B)** Das angepasste Loess-Modellierung mit den entsprechenden Steigungen aus dem Modell. Die grauen Linien stellen die wahren Tangenten aus dem theoretischen Modell dar. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-slope-03

p1_intro_00_1 + 
  labs(title = "Theoretisches Modell", subtitle = "") +
  p1_slope_02  +
  labs(subtitle = "") +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

Damit haben wir den einfachen Fall mit einem einkovariaten Modell einmal bearbeitet. Häufig haben wir aber mehrere Kovariaten im Modell oder aber eine Kombination von einer Kovariate und einem grupppierenden Faktor. Dann können wir uns dennoch die Steigung berechnen lassen. Hier ist es vermutlich die Stärke von `{marginaleffects}`, dass wir hier dann einfach weiter machen können.

### Mehrkovariates Modell

Wir können natürlich auch den Fall vorliegen haben, dass wir dann zwei oder mehr Kovariaten in einem Modell haben. Ich habe hier einmal das lineare Modell mit zwei Kovariaten der Schlupfzeit und dem Gewicht der Flöhe angepasst. Wir haben jetzt gleich verschiedene Möglichkeiten uns die Steigung einmal wiedergeben zu lassen.

```{r}
model_ln <- lm(jump_length ~ hatched + weight, data = flea_model_tbl)
tidy(model_ln)
```

Hier können wir uns auch die gemittelte Steigung an den für die Schlupfzeiten und die Flohgewichte wiedergeben lassen. Hier kommt es dann darauf an, was du wissen willst. Die lineare Regression liefert ja faktisch die Steigung und so erhalten wir hier auch die gleichen Werte wieder.

```{r}
#| message: false
#| warning: false
model_ln |> 
  avg_slopes()
```

Spannender wird es dann bei nicht linearen Modellen, wo wir dann natürlich nicht die gleiche Steigung an jeder Kombination vorliegen haben. Auch hier muss ich dich nochmal auf die [Vingette zu den Steigungen (eng. *slopes*)](https://marginaleffects.com/chapters/slopes.html) des R Paketes `{marginaleffects}` für mehr verweisen. Meistens haben wir dann nicht ein mehrkovariates Modell vorliegen sondern wollen dann eine Kovariate nach einem Faktor gruppieren. Dazu kommen wir dann im nächsten Abschnitt.

### Kombiniertes Modell

Jetzt wollen wir ein kombiniertes Modell rechnen. Wir haben hier eigentlich das klassische Design einer ANCOVA vorliegen. Wir kombinieren eine Kovariate mit einem Faktor. Bei der ANCOVA lesen wir das meist andersherum, aber hier geht es ja primär darum, wie sich die Kovariate ändert. Wenn wir dann noch einen gruppierenden Faktor mit ins Modell nehmen, dann geht es darum, wie sich die Kovariate in den Gruppen des Faktors ändert. Dann können wir natürlich noch Werte für die Kovariate festlegen, die uns dann besonders interessieren. Wenn wir das Modell bauen, dann ist die Anordnung der Einflussvariablen wichtig. Erst kommt die gruppierende Variable, dann der Rest. Hier haben wir also das Modell der Sprungweite und die beiden Einflussvariablen des Entwicklungsstandes sowie dem Gewicht. Dabei wollen wir das Gewicht dann quadratisch modellieren, was hier schon der große Unterschied zur ANCOVA ist. In der ANCOVA ist alles linear.

```{r}
model_grp_sq <- lm(jump_length ~ stage * weight + I(weight^2),
                   data = flea_model_tbl)
tidy(model_grp_sq)
```

Wie immer ist komplexeres Modell schwierig an den Koeffizienten zu interpretieren. Deshalb schauen wir uns einmal in der folgenden Abbildung die Graden an. Wie wir sehen, ist der Zusammenhang zwischen dem Gewicht und der Sprungweite bei den juvenilen Flöhen eher linear, bei den adulten Flöhen dann eher quadratisch. Damit würden wir dann pro Gruppe auch eine andere Steigung über die Kovariate des Gewichts erwarten.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Scatterplot des Einflusses des Flohgewichts auf die Sprungweite aufgeteilt nach dem Entwicklungsstand in adult und juvenile Flöhe. Hier wurde ein quadratischer Zusammenhang modelliert, sodass die Steigung entlang der Grade über die Kovariate unterschiedlich ist. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-7

ggplot(flea_model_tbl, aes(x = weight, y = jump_length,
                           color = stage)) +
  theme_marginal() +
  geom_point() +
  labs(x = "Gewicht in [mg]", y = "Sprungweite in [cm]",
       color = "Eintwicklungsstand") +
  geom_line(aes(y = predict(model_grp_sq)), linewidth = 1.25) +
  ylim(NA, 175) +
  scale_color_okabeito() +
  theme(legend.position = "top")
```

In den beiden folgenden Tabs zeige ich dir einmal wie du die Steigung in den beiden Gruppen für da Gewicht mit dem R Paket `{marginaleffects}` und `slopes()` berechnest. Dann habe ich das auch nochmal Schritt für Schritt gemacht, damit du nochmal nachvollziehen kannst, wie sich die Steigungen in den Gruppen ergeben.

::: panel-tabset
## `slopes()`

Wir können uns die Steigung für die Kovariate `weight` einmal berechnen lassen. Wir wollen die Steigung aber über den Faktor `stage` mitteln. Wir mitteln hier immer, da wir eben nicht für jeden Wert des Gewichts und der Gruppe einen Wert erhalten.

```{r}
model_grp_sq |> 
  slopes(variables = "weight",
         by = "stage")
```

Wir wir sehen, ist die mittlere Steigung bei den juvenilen Flöhe sehr hoch, bei den adulten Flöhen eher niedrig. Hier müssen wir dann gleich nochmal in die Abbildung rein, da wir ja bei den adulten Flöhen eher einen quadratischen Zusammenhang vorliegen haben. Somit könnten sich auch Steigungen raus kürzen, wenn es erst runter und dann wieder rauf geht.

## Schritt-für-Schritt

Wir können die Steigungen auch erst für die Variable `weight` berechnen und dann erhalten wir alle Werte wiedergeben.

```{r}
mfx_grp_sq <- model_grp_sq |> 
  slopes(variables = "weight")
head(mfx_grp_sq)
```

Danach können wir dann die Steigungen nach dem Entwicklungsstand gruppieren und mitteln.

```{r}
mfx_grp_sq |> 
  group_by(stage) |> 
  summarize(stage_ame = mean(estimate))
```

Wir erhalten dann die gleichen Werte wie auch mit der Funktion `slopes()` aus dem vorherigen Tab nur eben ohne weitere statistische Maßzahlen.
:::

Dann ergänzen wir einmal die Steigungen in der folgenden Abbildung. Wir sehen hier sehr schön die Steigung bei den juvenilen Flöhen. Nehmen die juvenilen Flöhe zu, dann nimmt auch die Sprungweite sehr schnell an Wert zu. Anders sieht es bei den adulten Flöhen aus. Hier haben wir dann einen Abfall der Leistung mit einer Steigerung am Ende des Spektrums des Gewichts. Daher bietet sich hier insbesondere an, sich für repräsentative Werte einmal die Steigung wiedergeben zu lassen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "Scatterplot des Einflusses des Flohgewichts auf die Sprungweite aufgeteilt nach dem Entwicklungsstand in adult und juvenile Flöhe. Hier wurde ein quadratischer Zusammenhang modelliert, sodass die Steigung entlang der Grade über die Kovariate unterschiedlich ist. Die Tangenten mit den jeweiligen Steigungen an dem mittleren GEwicht wurden ergänzt. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-8

weight_sum <- flea_model_tbl |> 
  group_by(stage) |> 
  summarise(mean(weight))

pred <- predict(model_grp_sq, newdata = tibble(weight = 14.05, stage = "adult"))
pred <- predict(model_grp_sq, newdata = tibble(weight = 5.85, stage = "juvenile"))

ggplot(flea_model_tbl, aes(x = weight, y = jump_length,
                           color = stage)) +
  theme_marginal() +
  geom_point() +
  labs(x = "Gewicht in [mg]", y = "Sprungweite in [cm]",
       color = "Entwicklungsstand") +
  geom_abline(intercept = find_intercept(14.05, 85.48217, -0.192), slope = -0.192,
              linewidth = 0.5, color = cb_pal[8], linetype = "21") +
  geom_abline(intercept = find_intercept(5.85, 95.5206, 7.826), slope = 7.826,
              linewidth = 0.5, color = cb_pal[7], linetype = "21") +
  geom_line(aes(y = predict(model_grp_sq)), linewidth = 1.25,
            fullrange = TRUE) +
  annotate("point", x = 14.05, y = 85.48217, size = 4, shape = 18, 
           color = cb_pal[9]) +
  annotate("point", x = 5.85, y = 95.5206, size = 4, shape = 18, 
           color = cb_pal[9]) +
  geom_richtext(aes(x = 14.05, y = 100, label = "Steigung adult: -0.192"),
                site = 20, color = "black") +
  geom_richtext(aes(x = 5.85, y = 110, label = "Steigung juvenile: 7.826"),
                site = 20, color = "black") +
  scale_color_okabeito() +
  ylim(NA, 175) +
  theme(legend.position = "top")
```

Wenn wir uns jetzt an verschiedenen Flohgewichten die Steigung anschauen wollen, dann müssen wir auch definieren, welchen Entwicklungsstand wir betrachten wollen. Da wir jetzt mal über beide Stadien uns die Steigung anschauen wollen, sage ich hier einmal, dass ich über jedes Level des Entwicklungsstadium haben will. Hier kann ich dann `unique` nutzen, damit ich nicht alle Level eintippen muss.

```{r}
datagrid(model = model_grp_sq,
         weight = c(5, 10, 15, 20, 25),
         stage = unique)
```

Das Datenraster können wir dann einmal nutzen um uns dann an den jeweiligen Gewichten die Steigung für die beiden Entwicklungsstände wiedergeben zu lassen. Jetzt können wir noch entscheiden, ob wir dann einen statistischen Test rechnen wollen um die Steigungen zwischen den beiden Stadien zu vergleichen.

:::: panel-tabset
## Ohne Gruppenvergleich

Ohne Gruppenvergleich ist die Anwendung sehr simple. Wir nehmen das Modell und rechnen dann in der Funktion `slopes()` die Variable `weight` und rechnen für die Flohgewichte die Steigung an den Werten des Gewichts im Datenraster. Hier habe ich dann mal fünf Werte für das Gewicht gewählt. Dann wähle ich noch aus, dass ich nach dem Entwicklungsstand sortieren will.

```{r}
model_grp_sq |> 
  slopes(variables = "weight",
         newdata = datagrid(weight = c(5, 10, 15, 20, 25),
                            stage = unique)) |> 
  arrange(stage)
```

Wir hier sehr schön sehen, ist die Steigung der adulten Flöhe unterschiedlich. Wir haben hier eine andere Traktion je nachdem welches Gewicht wir uns anschauen. Adulte Flöhe springen bei geringen Gewicht schlechter als bei mittleren. Der Effekt steigt dann bei höherem Gewicht wieder an. Juvenile Flöhe haben einen konstanten Anstieg von ungefähr $+2cm$ mehr Sprungweite pro Einheit mehr an Gewicht.

## Mit Gruppenvergleich

Hier kommt der etwas nervigere Teil. Wir wollen jetzt auch die Steigungen innerhalb der beiden Entwicklungsstadien miteinander vergleichen. Je mehr Flohgewichte du jetzt mit in den Vergleich nimmst, desto schwieriger wird gleich das Lesen der Ausgabe. Deshalb würde ich dir empfehlen, die Vergleiche immer für *ein* Gewicht zu rechnen und dann die Vergleiche zu wiederholen. Dabei gehe ich davon aus, dass dich die Vergleich zwischen den Gewichten nicht interessieren. Das ist zwar etwas mühseliger, aber dann stabiler. Sonst weiß man immer nicht was genau der Koeffizient `b` jetzt sein soll. Hier also einmal der Vergleich der Steigungen in den beiden Entwicklungsstadien für zwei Gewichte. Dadurch haben wir jetzt vier Koeffizienten, die innerhalb von `{marginaleffects}` mit `b1` bis `b4` abkürzen. Ich habe das hier mal umständlicher rangeschrieben, damit du besser die Vergleiche verstehst.

```{r}
model_grp_sq |> 
  slopes(variables = "weight",
         newdata = datagrid(weight = c(5, 10),
                            stage = unique)) |> 
  as_tibble() |> 
  add_column(coefficient = str_c("b", 1:4), .before = 1) |> 
  select(coefficient, weight, stage, estimate, p.value, conf.low, conf.high)
```

Dann haben wir hier einmal alle Vergleiche für die jeweiligen Koeffizienten. Dabei steht dann `b1` für die adulten Flöhe mit einem Gewicht von 5mg, `b2` für die juvenilen Flöhe mit einem Gewicht von 5mg, `b3` für die adulten sowie `b4` für die juvenilen Flöhe mit jeweils einem Gewicht von 10mg. Dann können wir uns die folgenden Differenzen berechnen.

$$
\begin{aligned}
(b2) - (b1) &= 7.46 - (-4.04) = 11.50\\
(b3) - (b1) &= -1.92 - (-4.04) = 2.12\\
(b4) - (b1) &= 9.59 - (-4.04) = 13.63\\
(b3) - (b2) &= -1.92 - 7.46 = -9.38\\
(b4) - (b2) &= 9.59 - 7.46 = 2.13\\
(b4) - (b3) &= 9.59 - (-1.92) = 11.50\\
\end{aligned}
$$

In dieser Form kriegen wir dann auch die Vergleiche aus der Funktion `slopes()` wiedergeben. Nur das wir natürlich hier dann noch die Fehler sowie dann auch die p-Werte erhalten. Das anstrengende ist dann hier zu wissen, was hinter den Koeffizientenabkürzungen steht. Ich verstehe mittlerweile auch warum es so gemacht wird. Für mehrere Faktoren wird es dann wirklich sehr schwer allgemein über alle Modelle richtig die Koeffizienten zu bezeichnen. Auch können wir so recht einfach zwischen Differenzen `diffence` und Anteilen `ratio` wechseln. Aber so richtig befriedigend ist es nicht. Ich kann aber soweit damit leben.

```{r}
model_grp_sq |> 
  slopes(variables = "weight",
         newdata = datagrid(weight = c(5, 10),
                            stage = unique),
         hypothesis = difference ~ pairwise)
```

Sehen wir dann auch, wo die größten Unterschiede in den Steigungen sind. Signifikant sind dann am Ende keiner der Steigungen zwischen den beiden Gruppen. Wir sind zwar nah dran, aber es liegen alle p-Werte über den Signifikanzniveau von $\alpha$ gleich 5%. Dabei sind alle p-Werte hier unadjustiert für multiple Vergleiche. Wenn du das wollen würdest, dann musst du den Code wie folgt anpassen und noch die Funktion `hypotheses()` nutzen.

```{r}
model_grp_sq |> 
  slopes(variables = "weight",
         newdata = datagrid(weight = c(5, 10),
                            stage = unique)) |> 
  hypotheses(hypothesis = difference ~ pairwise,
             multcomp = "bonferroni")
```

Damit kommen wir hier auch zum Schluss. Wenn dich hier noch mehr interessiert, kannst du in den anderen Kapitel zum statistischen Modellieren noch Anwendungen finden. Auch ist in dem Kapitel zur nicht linearen Regression dann noch was enthalten. Am Ende ist der Gruppenvergleich von Steigungen dann aber doch irgendwie eine Nische.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Nachdem ich mich hier schon eine Zeit durch die Vergleiche von Steigungen innerhalb von Gruppen gequält habe, muss ich sagen, dass es nicht ideal ist. Hier kommst du um ein gites Divide-and-conquer nicht herum. Einfach die Kovariate zerstückeln und für jeden Wert einzeln die Vergleiche rechen. Sonst wird es mit den Koeffizienten super unübersichtlich." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::
::::

Nachdem wir uns hier etwas durchgearbeitet haben, bin ich noch auf einen Teil gestoßen, der eigentlich gut beschreibt, wie sich die beiden R Pakete `{marginaleffects}` und `{emmeans}` unterscheiden. Es geht im Prinzip darum, wie die Mittelwerte der Steigungen gebildet werden. Es gibt nämlich zwei Wege. Entweder berechnen wir erst alle Koeffizienten oder statistischen Parameter und mitteln dann darüber oder aber wir mitteln erst unsere Daten und berechnen dann auf den gemittelten Daten die Koeffizienten. Am Ende kommt sehr häufig das Gleiche heraus. Wie immer aber in der Statistik, ist es nicht in allen Fällen so. Zu merken ist hierbei, dass `{marginaleffects}` die Koeffizienten mittelt und `{emmeans}` auf den gemittelten Daten die Koeffizienten berechnet. Möge es von Interesse sein, ich fand es nett mal aufzuarbeiten.

::: callout-note
## Philosophien zur Mittelwertbildung

Die folgende Darstellung wurde stark von @heiss2022 inspiriert. Ich habe hier dann aber mal mein Beispiel genommen und entsprechend angepasst. Die Idee ist eigentlich simple. Entweder rechnen wir die Steigungen an jeden Punkt des Kovariate und mitteln dann die Steigung. Dann berechnen wir die *Average marginal effects (AME)*. Das ist mehr oder minder was das R Paket `{marginaleffects}` tut. Oder aber wir rechnen erst die mittleren Werte der Kovariaten aus und berechnen für diese Werte dann die Steigung. Damit haben wir dann die *Marginal effects at the mean (MEM)*. Das ist dann die Lösung im R Paket `{emmeans}`. Das erste soll für beobachtete Daten besser sein, das letztere dann für experimentelle Daten. Versuchen wir mal den Unterschied zu verstehen.

Dann berechnen wir nochmal das quadratische Modell mit unseren drei Koeffizienten für die Schlupfzeiten. Wir nutzen jetzt gleich mal das Modell um uns die beiden unterschiedlichen Arten der gemittelten Steigung berechnen zu lassen.

```{r}
model_sq <- lm(jump_length ~ hatched + I(hatched^2) + I(hatched^3),
               data = flea_model_tbl)
tidy(model_sq)
```

Wir interpretieren hier die Koeffizienten nicht weiter, da wir das Modell nur brauchen um die Steigungen entlang der Graden berechnen zu können.

#### Average marginal effects (AME) {.unnumbered .unlisted}

Beginnen wir einmal mit den *Average marginal effects (AME)* wobei wir dann die Steigung an allen Punkten der Kovariaten berechnen. Wie du in der folgenden Abbildung siehst, sind die Steigungen sehr unterschiedlich, da wir ja eine S-Kurve vorliegen haben. So geht die Steigung erst nach unten um dann abzuflachen und wieder anzusteigen. Am Ende haben wir dann wieder fast keine Steigung vorliegen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der Sprungweite und der Schlupfzeiten mit einer angepassten Graden. Für aufgewählte Werte der Schlupfzeit wurde die Steigung der Tangenten an der Graden berechnet. Die gemittelte Steigung über alle Steigungen wurde berechnet. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-5

tangents <- model_sq |> 
  augment(newdata = tibble(hatched = seq(1, 6, by = 0.5))) |> 
  mutate(slope = jump_hatched_slope(hatched),
         intercept = find_intercept(hatched, .fitted, slope)) |> 
  mutate(nice_label = glue("Schlupzeit: {hatched}<br>",
                           "Fitted Sprungweite: {nice_number(.fitted)}<br>",
                           "Steigung: **{nice_number(slope)}**"))

ggplot(flea_model_tbl, aes(x = hatched, y = jump_length)) +
  theme_marginal() +
  geom_point() +
  geom_abline(data = tangents, aes(slope = slope, intercept = intercept), 
              linewidth = 0.5, color = cb_pal[8], linetype = "21") +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), linewidth = 1.25, 
              se = FALSE, color = cb_pal[3], fullrange = TRUE) +
  geom_point(data = tangents, aes(x = hatched, y = .fitted), 
             size = 4, shape = 18, color = cb_pal[9]) +
  geom_richtext(aes(x = 3, y = 150, label = "Gemittelte Steigung: 5.71"),
                site = 20) +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]") 
```

Wir haben jetzt zwei Wege auf denen wir uns die gemittelte Steigung berechnen können. Entweder berechnen wir alle Steigungen und mitteln dann einmal über die Steigung. Oder wir nutzen dann die entsprechende Funktion. Im Folgenden habe ich einmal die Steigungen an allen Punkten der Kovariaten berechnet und zeige dir einmal über `head()` die ersten sechs Werte.

```{r}
mfx_sq <- slopes(model_sq)
head(mfx_sq)
```

Dann können wir einmal die Steigung mitteln. Wir nutzen dazu dann die Funktion `summarise()` und erhalten folgenden Wert.

```{r}
mfx_sq |> 
  summarize(avg_slope = mean(estimate))
```

Das Ganze können wir dann auch schneller über die Funktion `avg_slopes()` berechnen, da wir hier die gemittelten Steigungen direkt erhalten. Das ist dann eben ein Schritt weniger und geht etwas schneller. Dafür sind dann die `avg_*` Funktionen in `{marginaleffects}` gedacht.

```{r}
avg_slopes(model_sq)
```

Wir müssen dann mit dem Wert leben, da es hier kein richtig oder falsch gibt. Wenn wir die Steigungen berechnen und dann mitteln erhalten wir eben eine mittlere Steigung von $+5.71$ wieder.

#### Marginal effects at the mean (MEM) {.unnumbered .unlisted}

Etwas anders sieht es aus, wenn wir die Steigung nach `{emmeans}` oder aber dem *Marginal effects at the mean (MEM)* berechnen wollen. In der folgenden Abbildung siehst du einmal die Vorgehensweise. Wir berechnen die Steigung jetzt direkt am Mittelwert der Kovariate also hier eben der mittleren Schlupfzeit. An der mittleren Schlupfzeit berechnen wir dann die Steigung.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Scatterplot der Sprungweite und der Schlupfzeiten mit einer angepassten Graden. Für die mittlere Schlupfzeit von $2.77$ wurde die Steigung der Tangenten an der Graden berechnet. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-data-6

ggplot(flea_model_tbl, aes(x = hatched, y = jump_length)) +
  theme_marginal() +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), linewidth = 1.25, 
              se = FALSE, color = cb_pal[3], fullrange = TRUE) +
  geom_abline(intercept = find_intercept(2.772599, 86.52944, 13.7), slope = 13.7,
              linewidth = 0.5, color = cb_pal[8], linetype = "21") +
  annotate("point", x = 2.772599, y = 86.52944, size = 4, shape = 18, 
           color = cb_pal[9]) +
  geom_richtext(aes(x = 2.772599, y = 120, label = "Steigung am Mittelwert: 13.7"),
                  site = 20) +
  scale_x_continuous(breaks = c(2, 2.772599, 4, 6), labels = c(2, 2.77, 4, 6)) +
  labs(x = "Schlupfzeit in [week]", y = "Sprungweite in [cm]") 
```

Technisch gesehen brauchen wir jetzt also einmal den Mittelwert der Kovariaten. Dafür berechnen wir also einmal den Mittelwert der Schlupfzeit.

```{r}
avg_jump_hatched <- mean(flea_model_tbl$hatched)
avg_jump_hatched
```

Dann sagen wir einmal den Wert für die Sprungweite an dem Mittelwert voraus sowie den Wert der Sprungweite an dem Mittelwert der Kovariaten plus ganz wenig. Das ganz wenig ist dann hier $+0.001$ Wochen Schlupfzeit. Dann ahben wir die beiden Werte für die Sprungweiten. Da wir hier runden, sehen die Werte gleich aus.

```{r}
jump_hatched_fitted <- model_sq |> 
  augment(newdata = tibble(hatched = c(avg_jump_hatched, avg_jump_hatched + 0.001)))
jump_hatched_fitted
```

Dann wollen wir die Steigung mit $dy/dx$ berechnen. Daher brauchen wir einmal unser Delta der Sprungweiten sowie das Delta der Kovariaten. Dabei müssen wir unser Delta der Sprungweiten nochmal ausrechnen.

```{r}
delta_y <- (jump_hatched_fitted$.fitted[2] - jump_hatched_fitted$.fitted[1])
delta_x <- 0.001
```

Und dann können wir auch schon die Steigung berechnen. An der Stelle der mittleren Schlupfzeit ändert sich wie die Sprungweite?

```{r}
delta_y / delta_x
```

Wir haben aber auch die Möglichkeit, diesen Wert in `{marginaleffects}` zu berechnen indem wir die folgenden Option setzen. Wir rechnen hier eben die Steigung auf dem Mittelwert der Kovariaten.

```{r}
model_sq |> 
  avg_slopes(newdata = "mean")
```

Was besser ist kann ich nicht sagen. Es kommt drauf an. Wir erhalten natürlich andere Werte je nachdem was wir berechnen. Dazu dann bitte auch die Diskussion weiter oben zum Unterschied von `{mariginaleffects}` und `{emmeans}` beachten.
:::

Kommen wir nochmal zu einer praktischen Anwendung aus meiner Beratung. Häufig haben wir ja den Fall vorliegen, dass wir nicht so genau wissen, wo wir den nun die Steigung über eine Grade wirklich gebrauchen könnten. Wenn wir aber die Zeit als Kovariate vorliegen haben, können wir wirklich sagen, dass pro Stunde sich der Messwert in die eine oder andere Richtung bewegt hat. Diese Bewegung oder Traktion ist dann die Steigung. Wir wollen uns also einmal das Verhalten von vier Entenrassen anschauen. Die Frage war hier, ob sich die Enten über den Tag unterschiedlich im Bezug auf das Reingehen und Draußenbleiben unterscheiden.

::: callout-tip
## Anwendungsbeispiel: Zeitlicher Verlauf von Entenausflügen

In unserem Anwendungsbeispiel fragen wir uns, ob die vier Entenrassen *Abbacot ranger*, *Indian runner*, *Saxony duck* und *Silver Bantam* ein unterschiedliches Verhalten im Bezug auf das Reingehen und Draußenbleiben zeigen. Sind die vier Rassen also alle gleich gerne draußen oder drinnen? Dabei wollen wir uns aber auch die Veränderung über die Zeit anschauen. Dafür eignen sich dann die *Marginal effect models* besonders. Wir haben also dreißig Enten pro Rasse mit einer Videoanalyse aufgezeichnet und ausgewertet, wo jeweils wie viele der dreißig Enten waren. Dabei ging es hier gar nicht so sehr darum, wie viele Enten immer draußen oder drinnen waren, sondern wie eben die Änderung über die Zeit in den Rassen sich unterscheidet.

![Comic der vier Entenrassen in unserem Reingehen oder Draußenbleiben Experiment mit dreißig Enten je Rasse. Die Frage ist hier, ob sich das Verhalten der vier Entenrassen über die Zeit unterscheidet.](images/marginal/ducks.png){#fig-flea-yedi fig-align="center" width="80%"}

Wir müssen jetzt einmal unsere Daten einlesen und dafür sorgen, dasss auch alle vier Tabellenblätter berücksichtigt werden. Jede Entenrasse hat eben ihr eigenes Tabellenblatt und daher müssen wir eben die Daten etwas komplizierter Einlesen.

```{r}
path <- file.path("data/outside_ducks.xlsx")
duck_raw_tbl <- path |> 
  excel_sheets() |> 
  rlang::set_names() |> 
  map_dfr(read_excel, path = path)
```

Dann können wir Daten schon transformieren. Einen großen Teil verwenden wir darauf die Zeit in das entsprechende Format umzuwandeln. Wir wollen die Zeit in Blöcken von einer halben Stunde haben und nicht sekundengenau. Dann müssen wir noch die Zeit von einem Faktor in eine numerische Einflussvariable umwandeln. Am Ende sortieren und filtern wir dann noch etwas die Daten.

```{r}
duck_tbl <- duck_raw_tbl |> 
  mutate(time = as.POSIXct(time, format = "%H:%M:%S"),
         time_block = floor_date(time, unit = "30 minutes"),
         time_hour = hour(time) + minute(time)/60,
         timeblock_fct = as.factor(time_block)) |> 
  select(breed, time_block, timeblock_fct, outside) |>
  group_by(timeblock_fct, breed) |> 
  mutate(timeblock_num = as.numeric(timeblock_fct) - 1,
         breed = as_factor(breed)) |> 
  filter(timeblock_num %in% 0:24)
```

Dann rechnen wir unser *Generalized additive model* (abk. *GAM*) mit der Funktion `gam()` und setzten unsere nicht lineare Einflussvariable mit einem `s()` fest. Dann müssen wir noch sagen, dass die Zeit und Enten draußen eben dann noch von der Rasse `breed` abhängen. Dann erhalten wir auch für jede Rasse eine eigene Grade.

```{r}
model_full_sq <- gam(outside ~ breed + s(timeblock_num, by = breed),
                     data = duck_tbl)
```

In der folgenden Abbildung siehst du dann einmal den zeitlichen Verlauf der Enten. Wir sehen auf der y-Achse immer die Enten, die sich außerhalb vom Stall befinden. Je nach Rasse bewegen sich die Enten über die Zeit mehr oder minder stark in die Ställe oder eben wieder raus. Wir wollen dann gleich an drei Uhrzeiten einmal die Steigung bestimmen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Zeitlicher Verlauf der Enten außerhalb der Ställe und deren Rückkehr in die Ställe für die vier Entenrassen. Die Daten wurden für Zeitblöcke je 30 Minuten gemittelt. Die Grade stellt das angepasste *Generalized additive model* dar. An drei Uhrzeiten (0:00, 12:00 und 20:00) wird die Steigung der Graden bestimmt. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-app-ducks-01

duck_tbl |> 
  ggplot(aes(x = timeblock_num, y = outside,
             color = breed)) +
  theme_marginal() +
  geom_vline(xintercept = c(0, 12, 20)) +
  geom_line(aes(y = predict(model_full_sq))) +
  theme(legend.position = "top") +
  labs(x = "Uhrzeit", y = "Anzahl Enten draußen",
       color = "Rasse", 
       title = "Rausgehverhalten von verschiedenen Entenrassen") +
  scale_x_continuous(breaks = c(0, 4, 8, 12, 16, 20, 24)) +
  scale_y_continuous(breaks = c(0, 10, 20, 30)) +
  scale_color_okabeito()
```

Zuerst interessiert mich aber die Steigung über alle Zeitpunkte für jede Rasse. Wir rechnen also die mittlere Steigung der vier Entenrassen aus. Was sagt uns jetzt die mittlere Steigung aus? Wir sehen, dass alle Steigungen negativ sind. Daher haben alle Enten einen Drang nach drinnen zu gehen. Die Anzahl an Enten draußen vermindert sich also über den gemessenen Tag.

```{r}
model_full_sq |> 
  slopes(variables = "timeblock_num",
         by = "breed")
```

Und wie siehst es nun an drei ausgewählten Uhrzeiten aus? Hier haben wir dann natürlich nochmal alles aufgeteilt nach den vier Rassen und es wird schnell unübersichtlich. Vermutlich ist es besser hier einzelne Uhrzeiten nacheinander durchzugehen.

```{r}
model_full_sq |> 
  slopes(variables = "timeblock_num",
         newdata = datagrid(timeblock_num = c(0, 12, 20),
                            breed = unique))
```

Daher jetzt hier einmal der Vergleich der Steigungen für die Mittagszeit um 12:00 Uhr. Hier ist es dann wieder wichtig zu verstehen, was die Koeffizienten `b` in den paarweisen Vergleichen heißen sollen. Daher müssen wir den Vergleich einmal aufbrechen. Erstmal berechnen wir die Steigungen und dann im Anschuss den paarweisen Vergleich.

```{r}
clock_12_slopes_tbl <- model_full_sq |> 
  slopes(variables = "timeblock_num",
         newdata = datagrid(timeblock_num = c(12),
                            breed = unique))
clock_12_slopes_tbl
```

Jetzt wissen wir das `b1` für die Abacotenten steht, `b2` für die Indianenten, `b3` für die Silverenten sowie `b4` für die Saxonyenten. Daher können wir dann auch die folgenden Vergleiche verstehen. Sonst wäre das schwer möglich. Leider gibt es keine charmante Version die `b` Koeffizienten durch den entsprechenden Namen zu ersetzen.

```{r}
clock_12_slopes_tbl |> 
  hypotheses(hypothesis = difference~pairwise)
```

Am Ende können wir uns den Verlauf *der Steigungen* über die Zeit anschauen. Hier sehen wir sehr schön die Traktion über den Tag. Gegen Ende des Tages wollen dann alle Enten eher in den Stall. Sonst haben wir eher einen zyklischen Verlauf.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Verlauf der Steigungen über die Zeit aufgeteilt nach den vier Entenrassen. *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-app-ducks-02

plot_slopes(model_full_sq, 
            variables = "timeblock_num",  
            condition = c("timeblock_num", "breed")) +
  theme_marginal() +
  scale_color_okabeito() +
  scale_fill_okabeito() +
  theme(legend.position = "top") +
  labs(x = "Uhrzeit", y = "Steigung dy/dx",
       color = "Rasse", fill = "Rasse") +
  scale_x_continuous(breaks = c(0, 4, 8, 12, 16, 20, 24))
```

In diesem Beispiel siehst du ganz schön, wie wir dann die Steigung verwenden können um eine Aussage über die zeit zu treffen. Wenn du viele Faktoren wie die Rasse in dem Modell hast, bitte es sich an, die Vergleiche dann aufzusplitten damit du besser interpretieren kannst, was du da an Koeffizienten eigentlich vergleichst.
:::

Damit sind wir dann am Ende mit den Steigungen und kommen jetzt zu einem anderem Gebiet. Anstatt zu sagen, wie sich die Werte im Messwert an einer bestimmten Stelle der Einflussvariable verändern, können wir auch vorhersagen, wie der Wert des Messwertes für beliebige Einflussfaktoren nach dem Modell aussehen würde. Wir machen also eine klassische Vorhersage mit unserem statistischen Modell.

## Vorhersagen (eng. *predictions*)

### Kovariates Modell

#### Modellierung von Enzymen {.unnumbered .unlisted}

```{r}
#| message: false
#| warning: false

loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
```

```{r}
predictions(loess_fit)
```

```{r}
predictions(loess_fit, by = "ph")
```

::: panel-tabset
## `gam()`

```{r}
#| message: false
#| warning: false
gam_fit <- gam(activity ~ s(ph), data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false
gam_pred <- predictions(gam_fit, newdata = datagrid(ph = c(-1, 2, 6)))
gam_pred
```

## `poly()`

```{r}
#| message: false
#| warning: false
poly_fit <- lm(activity ~ poly(ph, 3), data = enzyme_tbl)
```

```{r}
poly_pred <- predictions(poly_fit, newdata = datagrid(ph = c(-1, 2, 6)))
poly_pred
```

## `loess()`

```{r}
#| message: false
#| warning: false
loess_fit <- loess(activity ~ ph, data = enzyme_tbl)
```

```{r}
loess_pred <- predictions(loess_fit, newdata = datagrid(ph = c(-1, 2, 6)))
loess_pred
```
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 9.5
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-01

p2_intro_00_2 + 
  labs(title = "Theoretisches Modell") +
  p1_predict_00 +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

### Faktorielles Modell

::: callout-warning
## Achtung, bitte beachten!

Ich persönlich finde die Implementierung des multiplen Testens in `{emmeans}` um Längen besser gelöst. Den Rest von `{marginaleffects}` dann eher nicht so. Daher würde ich dir hier davon abraten, deine Gruppenvergleiche mit `predictions()` zu rechnen. Es ist gut zu verstehen was die Funktion macht, aber `{emmeans}` hat den klaren Vorteil, dass wir das *Compact letter disply* berechnen können. Darüber hinaus finde ich die zweifaktorielle Analyse besser gelöst durch die beiden Zeichen Stern `*` und Strich `|` besser gelöst. In `{marginaleffects}` haben wir dann die Problematik mit den Hypothesen und Gruppennamen innerhalb der Ausgabe der Funktion `hypotheses()`. Hier nochmal die Alternativen in `{emmeans}`, die ich hier aber dann nicht ausführen lasse. Bitte schaue dann nochmal in das [Kapitel zu den Post-hoc Tests](#sec-posthoc) vorbei.

```{r}
#| eval: false
enzyme_1fac_fit |> 
  emmeans(~ grp, vcov = sandwich::vcovHAC) |> 
  contrast(method = "pairwise", adjust = "bonferroni")
```

```{r}
#| eval: false
enzyme_2fac_fit |> 
  emmeans(~ grp | type, vcov = sandwich::vcovHAC) |> 
  contrast(method = "pairwise", adjust = "bonferroni")
```
:::

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Manchmal schaue ich mir sehr lange Funktionen oder Pakete wie hier `{marginaleffects}` an und muss dann feststellen, dass für eien spezielle Orichideenanwendung dann doch ein anderes Paket besser ist. Ist nicht schlimm, dann musst du dir nicht die Arbeit machen. Für das faktorielle Experiment würde ich dann immer `{emmeans}` nehmen." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

Die Funktion `hypotheses()` ist mächtig.

*Marginal mean* nochmal erklären

::: panel-tabset
## Vorhersage 1-faktoriell

```{r}
enzyme_1fac_fit <-  lm(activity ~ grp, data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC")
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC",
            hypothesis = ~pairwise)  |> 
  hypotheses(multcomp = "bonferroni")
```

```{r}
#| message: false
#| warning: false
predictions(enzyme_1fac_fit, by = c("grp"), vcov = "HAC",
            hypothesis = ~pairwise) 
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-02

plot_predictions(enzyme_1fac_fit, by = c("grp")) +
  theme_minimal()
```

## Vorhersage 2-faktoriell

```{r}
enzyme_2fac_fit <- lm(activity ~ grp * type, data = enzyme_tbl)
```

```{r}
#| message: false
#| warning: false

predictions(enzyme_2fac_fit, by = c("grp", "type"), vcov = "HAC",
            hypothesis = ~pairwise | type, 
            newdata = "balanced") 
```

```{r}
#| message: false
#| warning: false

predictions(enzyme_2fac_fit, by = c("grp", "type"), vcov = "HAC",
            newdata = "balanced") |> 
  hypotheses(~pairwise | type, multcomp = "bonferroni")
```

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-03

plot_predictions(enzyme_2fac_fit, by = c("grp", "type")) +
  theme_minimal()
```
:::

:::: callout-note
## Vergleich `{marginaleffects}` und `{emmeans}`

```{r}
feeding_fit <-  lm(jump_length ~ feeding * stage, data = flea_model_tbl)
```

::: panel-tabset
## `{marginaleffects}`

```{r}
predictions(feeding_fit, by = c("stage", "feeding"), vcov = "HAC")
```

```{r}
predictions(feeding_fit, by = c("stage", "feeding"), vcov = "HAC",
            hypothesis = ~pairwise | stage)
```

```{r}
predictions(feeding_fit, by = c("stage", "feeding"), vcov = "HAC") |> 
  hypotheses(multcomp = "bonferroni")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "**(A)** Linearer Zusammenhang. **(B)** ggg *[Zum Vergrößern anklicken]*"
#| label: fig-marginal-model-predict-04

plot_predictions(feeding_fit, by = c("stage", "feeding")) +
  theme_minimal()
```

## `{emmeans}`

```{r}
feeding_fit |> 
  emmeans(~ feeding | stage, vcov = sandwich::vcovHAC)
```

```{r}
feeding_fit |> 
  emmeans(~ feeding | stage, vcov = sandwich::vcovHAC) |> 
  contrast(method = "pairwise", adjust = "bonferroni")
```
:::
::::

## Kontrafaktische Vergleiche (eng. *counterfactual*)

## Hypothesen- und Äquivalenztests

## Referenzen {.unnumbered}
