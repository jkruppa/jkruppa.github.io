[
  {
    "objectID": "stat-tests-preface.html",
    "href": "stat-tests-preface.html",
    "title": "Frequentistische Hypothesentests",
    "section": "",
    "text": "Das statistische Testen - eine Geschichte voller Missverständnisse. Wir wollen uns in diesem Kapitel mit den Grundlagen des frequentistischen Hypothesentestens beschäftigen. Wenn ich hier einen Unterschied mache, dann muss es ja auch noch ein anderes Hypothesentesten geben. Ja, das nennt man dann bayesianische Statistik und kommt eventuell mal später. Wir konzentrieren uns aber zuerst auf frequentistische Hypothesentesten was seit gut hundert Jahren genutzt wird. Ich werde hier textlich nur einen kurzen Einstieg liefern. Vielleicht wird es in den folgenden Jahren länger aber aktuell (Ende 2022) bleiben wir hier bei einem kurzen Einstieg.\nBeginnen wir mit der Logik der Forschung oder allgemeiner formuliert, als die Grundlage der Wissenschaft. Wir basieren all unsere Entscheidungen in der Wissenschaft auf dem Falsifikationsprinzip. Also bitte merken, wir können nur ablehnen (eng. reject).\nWir wollen hier auf keinen Fall die Leistungen von Altvorderen schmälern. Dennoch hatten Ronald Fischer (1890 - 1962), als der Begründer der Statistik, andere Vorraussetzungen als wir heutzutage. Als wichtigster Unterschied sei natürlich das Gerät genannt, an dem du gerade diese Zeilen liest: dem Computer. Selbst die Erstellung einfachster Abbildungen war sehr, sehr zeitaufwendig. Die Berechnung von Zahlen lohnte sich mehr, als die Zahlen zu visualisieren. Insbesondere wenn wir die Explorative Datenanalyse nach John Tukey (1915 - 2000) durchführen. Undenkbar zu den Zeiten von Ronald Fischer mehrere Abbildungen unterschiedlich nach Faktoren einzufärben und sich die Daten anzugucken.\nNeben dieser Begrenzung von moderner Rechenkapazität um 1900 gab es noch eine andere ungünstige Entwicklung. Stark vereinfacht formuliert entwickelte Ronald Fischer statistische Werkzeuge um abzuschätzen wir wahrscheinlich die Nullhypothese unter dem Auftreten der beobachteten Daten ist. Nun ist es aber so, dass wir ja auch eine Entscheidung treffen wollen. Nach der Logik der Forschung wollen wir ja eine Hypothese falsifizieren, in unserem Fall die Nullhypothese. Die Entscheidungsregeln, also die statistische Testtheorie, kommen nun von Jerzy Neyman (1894 - 1981) und Egon Pearson (1895 - 1980), beide als die Begründer der frequentistischen Hypothesentests.\nSchlussendlich gibt es noch eine andere Störmung in der Statistik, die auf den mathematischen Formeln von Thomas Bayes (1701 - 1761) basieren. In sich eine geschlossene Theorie, die auf der inversen Wahrscheinlichkeit basiert. Das klingt jetzt etwas schräg, aber eigentlich ist die bayesianische Statistik die Statistik, die die Fragen um die Alternativehypothese beantwortet. Der Grund warum die bayesianische Statistik nicht angewendet wurde, war der Bedarf an Rechenleistung. Die bayesiansiche Statistik lässt sich nicht händisch in endlicher Zeit lösen. Dieses technische Problem haben wir aber nicht mehr. Eigentlich könnten wir also die bayesiansiche Statistik verwenden. Wir wollen hier aber (noch) nicht auf die bayesianische Statistik eingehen, das werden wir später tun.\nWenn du allgemein Interesse hast an der Geschichte der Statistik dann sei auf Salsburg (2001) verwiesen. Ein sehr schönes Buch, was die geschichtlichen Zusammenhänge nochmal aufzeigt.\nKommen wir aber nun zu den wichtigeren Punkten. Das Kapitel ist sehr umfangreich und enthält viele Informationen, die wir teilweise später nochmal brauchen. Darüber hinaus müssen wir noch das Lernen und Verstehen von der Anwendung unterscheiden."
  },
  {
    "objectID": "stat-tests-preface.html#sec-hypothesen",
    "href": "stat-tests-preface.html#sec-hypothesen",
    "title": "Frequentistische Hypothesentests",
    "section": "Die Hypothesen",
    "text": "Die Hypothesen\n\n\nIm Anhang A findest du verschiedene Beispiele zu Auswertungen von Datenbeispielen.\nWir können auf allen Daten einen statistischen Test rechnen und erhalten statistische Maßzahlen wie eine Teststatistik oder einen p-Wert. Nur leider können wir mit diesen statistischen Maßzahlen nicht viel anfangen ohne die Hypothesen zu kennen. Jeder statistische Test testet eine Nullhypothese. Ob diese Hypothese dem Anwender nun bekannt ist oder nicht, ein statistischer Test testet eine Nullhypothese. Daher müssen wir uns immer klar sein, was die entsprechende Nullhypothese zu unserer Fragestellung ist. Wenn du hier stockst, ist das ganz normal. Eine Fragestellung mit einer statistischen Hypothese zu verbinden ist nicht immer so einfach gemacht.\n\n\n\n\n\n\nDie Nullhypothese \\(H_0\\) und die Alternativehypothese \\(H_A\\)\n\n\n\nDie Nullhypothese \\(H_0\\) nennen wir auch die Null oder Gleichheitshypothese. Die Nullhypothese sagt aus, dass zwei Gruppen gleich sind oder aber kein Effekt zu beobachten ist.\n\\[\nH_0: \\bar{y}_{1} = \\bar{y}_{2}\n\\]\nDie Alternativehypothese \\(H_A\\) oder \\(H_1\\) auch Alternative genannt nennen wir auch Unterschiedshypothese. Die Alternativehypothese besagt, dass ein Unterschied vorliegt oder aber ein Effekt vorhanden ist.\n\\[\nH_A: \\bar{y}_{1} \\neq \\bar{y}_{2}\n\\]\n\n\nAls Veranschaulichung nehmen wir das Beispiel aus Kapitel 5. Wir formulieren als erstes die Fragestellung. Eine Fragestellung endet mit einem Fragezeichen.\nLiegt ein Unterschied zwischen den Sprungweiten von Katzen und Hundeflöhen vor?\nWir können die Frage auch anders formulieren.\nSpringen Hunde und Katzenflöhe unterschiedlich weit?\nWichtig ist, dass wir eine primäre Fragestellung formulieren. Wir können auch mehrere Fargen an einen Datensatz haben. Das ist auch vollkommen normal. Nur hat jede Fragestellung ein eigenes Hypothesenpaar. Wir bleiben aber bei dem simplen Beispiel.\nWie sieht nun die statistische Hypothese in diesem Beispiel aus? Wir wollen uns die Sprungweite in [cm] anschauen. In diesem Fall wollen wir die mittlere Sprungweite der Hundeflöhe \\(\\bar{y}_{dog}\\) mit der mittleren Sprungweite der Katzenflöhe \\(\\bar{y}_{cat}\\) vergleichen. Es ergibt sich folgendes Hypothesenpaar.\n\\[\\begin{align*}\nH_0: \\bar{y}_{dog} &= \\bar{y}_{cat} \\\\  \nH_A: \\bar{y}_{dog} &\\neq \\bar{y}_{cat} \\\\   \n\\end{align*}\\]\nDas Falisifkationsprinzip - wir können nur Ablehnen - kommt hier zusammen mit der frequentistischen Statistik in der wir nur eine Wahrscheinlichkeitsaussage über das Auftreten der Daten \\(D\\) - unter der Annahme \\(H_0\\) gilt - treffen können.\nEs ist wichtig sich in Erinnerung zu rufen, dass wir nur und ausschließlich Aussagen über die Nullhypothese treffen werden. Das frequentistische Hypothesentesten kann nichts anders. Wir kriegen keine Aussage über die Alternativhypothese sondern nur eine Abschätzung der Wahrscheinlichkeit des Auftretens der Daten im durchgeführten Experiment, wenn die Nullhypothese wahr wäre."
  },
  {
    "objectID": "stat-tests-preface.html#die-testentscheidung",
    "href": "stat-tests-preface.html#die-testentscheidung",
    "title": "Frequentistische Hypothesentests",
    "section": "Die Testentscheidung…",
    "text": "Die Testentscheidung…\nIn den folgenden Kapiteln werden wir verschiedene statistische Tests kennenlernen. Alle statistischen Tests haben gemein, dass ein Test eine Teststatistik \\(T_{calc}\\) berechnet. Darüber hinaus liefert jeder Test auch einen p-Wert (eng. p-value). Manche statistischen Test geben auch ein 95% Konfidenzintervall wieder. Eine Testentscheidung gegen die Nullhypothese \\(H_0\\) kann mit jedem der drei statistischen Maßzahlen durchgeführt werden. Die Regel für die Entscheidung, ob die Nullhypothese \\(H_0\\) abgelehnt werden kann, ist nur jeweils anders. In Tabelle 1 sind die Entscheidungsregeln einmal zusammengefasst.\n\n\n\nTabelle 1— Zusammenfassung der statistischen Testentscheidung unter der Nutzung der Teststatistik, dem p-Wert und dem 95% Konfidenzintervall. Die Entscheidung nach der Teststatistik ist veraltet und dient nur dem konzeptionellen Verständnisses. In der Forschung angewandt wird der p-Wert und das 95% Konfidenzintervall. Im Fall des 95% Konfidenzintervalls müssen wir noch unterschieden, ob wir einen Mittelwertsunterschied \\(\\Delta_{A-B}\\) oder aber einen Anteilsunterschied \\(\\Delta_{A/B}\\) betrachten.\n\n\n\n\n\n\n\n\nTeststatistik\np-Wert\n95% Konfidenzintervall\n\n\n\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(\\boldsymbol{KI_{1-\\alpha}}\\)\n\n\nH\\(_0\\) ablehnen\n\\(T_{calc} \\geq T_{\\alpha = 5\\%}\\)\n\\(Pr(\\geq T_{calc}| H_0) \\leq \\alpha\\)\n\n\\(\\Delta_{A-B}\\): enthält nicht 0\n\n\n\nH\\(_0\\) ablehnen\n\n\n\n\\(\\Delta_{A/B}\\): enthält nicht 1\n\n\n\n\n\n\nWir wollen in den folgenden Abschnitten die jeweiligen Entscheidungsregeln eines statistisches Tests einmal durchgehen.\n\nDie Testentscheidung gegen die Nullhypothese anhand der Teststatistik in Kapitel 2.1\n\nDie Testentscheidung gegen die Nullhypothese anhand dem p-Wert in Kapitel 2.2\n\nDie Testentscheidung gegen die Nullhypothese anhand des 95% Konfidenzintervall in Kapitel 2.3\n\n\n\n\n\n\n\n\nStreng genommen gilt die Regel \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) nur für eine Auswahl an statistischen Tests siehe dazu auch Kapitel 2.1. Bei manchen statistischen Tests ist die Entscheidung gedreht. Hier lassen wir das aber mal so stehen…\n… anhand der Teststatistik\n\n\n\n\n\n\nPrinzip des statistischen Testens I - Die Teststatistik\n\n\n\nDu findest auf YouTube Prinzip des statistischen Testens I - Die Teststatistik als Video. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nWir wollen uns dem frequentistischen Hypothesentesten über die Idee der Teststatistik annähern. Im folgenden sehen wir die Formel für den t-Test. Den t-Test werden wir im Kapitel 15 uns nochmal detaillierter anschauen. Hier nutzen wir die vereinfachte Formel um das Konzept zu verstehen.\n\\[\nT_{calc}=\\cfrac{\\bar{y}_1-\\bar{y}_2}{s_{p} \\cdot \\sqrt{2/n_g}}\n\\]\nmit\n\n\n\\(\\bar{y}_1\\) dem Mittelwert für die erste Gruppe.\n\n\\(\\bar{y}_2\\) dem Mittelwert für die zweite Gruppe.\n\n\\(s_{p}\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{s_A + s_B}{2}\\).\n\n\\(n_g\\) der Gruppengröße der gruppen. Wir nehmen an beide Gruppen sind gleich groß.\n\nWir benötigen also zwei Mittelwerte \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\) und deren gepoolte Standardabweichung \\(s_p\\) sowie die Anzahl der Beobachtungen je Gruppe \\(n_g\\). Wenden wir die Formel des t-Tests einmal auf den folgenden Beispieldatensatz an. In ?tbl-dog-cat-small-delta ist eine Datenbeispiel gegeben.\n\n\n\n\nTabelle 2— Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.\n\nanimal\njump_length\n\n\n\ncat\n8.5\n\n\ncat\n9.9\n\n\ncat\n8.9\n\n\ncat\n9.4\n\n\ndog\n8.0\n\n\ndog\n7.2\n\n\ndog\n8.4\n\n\ndog\n7.5\n\n\n\n\n\n\nWir berechnen nun die Mittelwerte und die Standardabweichungen aus der obigen Datentabelle. Die Werte setzen wir dann in die Formel ein.\n\\[\nT_{calc}=\\cfrac{9.2 - 7.8}{\\cfrac{(0.6 + 0.5)}{2} \\cdot \\sqrt{2/4}} = 3.6\n\\]\nmit\n\n\n\\(\\bar{y}_{cat} = 9.2\\) dem Mittelwert für die Gruppe cat.\n\n\\(\\bar{y}_{dog} = 7.8\\) dem Mittelwert für die Gruppe dog.\n\n\\(s_p = 0.55\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{0.6 + 0.5}{2}\\).\n\n\\(n_g = 4\\) der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.\n\nWir haben nun die Teststatistik \\(T_{calc} = 3.6\\) berechnet. In der ganzen Rechnererei verliert man manchmal den Überblick. Erinnern wir uns, was wir eigentlich wollten. Die Frage war, ob sich die mittleren Sprungweiten der Hunde- und Katzenflöhe unterschieden. Wenn die \\(H_0\\) wahr wäre, dann wäre der Unterschied \\(\\Delta\\) der beiden Mittelwerte der Hunde- und Katzenflöhe gleich null. Oder nochmal in der Analogie der t-Test Formel, dann wäre im Zähler \\(\\Delta = \\bar{y}_{cat} - \\bar{y}_{dog} = 0\\). Wenn die Mittelwerte der Sprungweite [cm] der Hunde- und Katzenflöhe gleich wäre, dann wäre die berechnete Teststatistik \\(T_{calc} = 0\\), da im Zähler Null stehen würde. Die Differenz von zwei gleichen Zahlen ist Null.\nJe größer die berechnete Teststatistik \\(T_{calc}\\) wird, desto unwahrscheinlicher ist es, dass die beiden Mittelwerte per Zufall gleich sind. Wie groß muss nun die berechnete Teststatistik \\(T_{calc}\\) werden damit wir die Nullhypothese ablehnen können?\n\n\n\nAbbildung 1— Die t-Verteilung aller möglichen \\(T_{calc}\\) wenn die Nullhypothese wahr ist. Der Mittelwert der t-Verteilun ist \\(T=0\\). Wenn wir keinen Effekt erwarten würden dann wären die beiden Mittelwerte \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\) gleich groß. Die Differenz wäre 0. Je größer der \\(T_{calc}\\) wird desto weniger können wir davon ausgehen, dass die beiden Mittelwerte gleich sind. Liegt der \\(T_{calc}\\) über dem kritischen Wert von \\(T_{\\alpha = 5\\%}\\) dann wir die Nullhypothese abgelehnt.\n\n\n\nIn Abbildung 1 ist die Verteilung aller möglichen \\(T_{calc}\\) Werte unter der Annahme, dass die Nullhypothese wahr ist, dargestellt. Wir sehen, dass die t-Verteilung am höchsten bei \\(T_{calc} = 0\\) ist und niedrigeren Werte mit steigenden t-Werten annimmt. Wenn \\(T = 0\\) dann sind auch die Mittelwerte gleich. Je größer unsere berechnete Teststatistik \\(T_{calc}\\) wird, desto unwahrscheinlicher ist es, dass die Nullhypothese gilt. Die t-Verteilug ist so gebaut, dass die Fläche \\(A\\) unter der Kurve gleich \\(A=1\\) ist. Wir können nun den kritschen Wert \\(T_{\\alpha = 5\\%}\\) berechnen an dem rechts von dem Wert eine Fläche von 0.05 oder 5% liegt. Sommit liegt dann links von dem kritischen Wert die Fläche von 0.95 oder 95%. Den kritischen Wert \\(T_{\\alpha = 5\\%}\\) können wir statistischen Tabellen entnehmen. Oder wir berechnen den kritischen Wert direkt in R mit \\(T_{\\alpha = 5\\%} = 2.78\\).\nKommen wir zurück zu unserem Beispiel. Wir haben in unserem Datenbeispiel für den Vergleich von der Sprungweite in [cm] von Hunde- und Katzenflöhen eine Teststatistik von \\(T_{calc} = 3.6\\) berechnet. Der kritische Wert um die Nullhypothese abzulehnen liegt bei \\(T_{\\alpha = 5\\%} = 2.78\\). Wenn \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt. In unserem Fall ist \\(3.6 \\geq 2.78\\). Wir können die Nullhypothese ablehnen. Es gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen.\n\n\n\n\n\n\nEs gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen. Die Aussage ist statistisch falsch. Wir können im frequentistischen Hypothesentesten keine Aussage über die \\(H_A\\) treffen. Im Sinne der Anwendbarkeit soll es hier so stehen bleiben.\nNun ist es leider so, dass jeder statistische Test seine eigene Teststatistik \\(T\\) hat. Daher ist es etwas mühselig sich immer neue und andere kritische Werte für jeden Test zu merken. Es hat sich daher eingebürgert, sich nicht die Teststatistik für die Testentscheidung gegen die Nullhypothese zu nutzen sondern den p-Wert. Den p-Wert wollen wir uns in dem folgenden Abschnitt anschauen.\n\n\n\n\n\n\nEntscheidung mit der berechneten Teststatistik\n\n\n\nBei der Entscheidung mit der Teststatistik müssen wir zwei Fälle unterschieden.\n\nBei einem t-Test und einem \\(\\mathcal{X}^2\\)-Test gilt, wenn \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\nBei einem Wilcoxon-Mann-Whitney-Test gilt, wenn \\(T_{calc} < T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\n\nAchtung – Wir nutzen die Entscheidung mit der Teststatistik nur und ausschließlich in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik keine Verwendung mehr.\n\n\n… anhand dem p-Wert\n\n\n\n\n\n\nPrinzip des statistischen Testens II - Der p-Wert\n\n\n\nDu findest auf YouTube Prinzip des statistischen Testens II - Der p-Wert als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nIn dem vorherigen Abschnitt haben wir gelernt, wie wir zu einer Entscheidung gegen die Nullhypothese anhand der Teststatistik kommen. Wir haben einen kritischen Wert \\(T_{\\alpha = 5\\%}\\) definiert bei dem rechts von dem Wert 5% der Werte liegen. Anstatt nun den berechneten Wert \\(T_{calc}\\) mit dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) zu vergleichen, vergleichen wir jetzt die Flächen rechts von den jeweiligen Werten.\nWir schreiben \\(\\boldsymbol{Pr}\\) und meinen damit eine Wahrscheinlichkeit (eng. probability). Häufig wird auch nur das \\(P\\) verwendet, aber dann kommen wir wieder mit anderen Konzepten in die Quere.\nIn Abbildung 1 sind die Flächen auch eingetragen. Da die gesamte Fläche unter der t-Verteilung mit \\(A = 1\\) ist, können wir die Flächen auch als Wahrscheinlichkeiten lesen. Die Fläche rechts von der berechneten Teststatistik \\(T_{calc}\\) wird \\(Pr(T_{calc}|H_0)\\) oder \\(p\\)-Wert genannt. Die gesamte Fläche rechts von dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) wird \\(\\alpha\\) genannt und liegt bei 5%. Wir können also die Teststatistiken oder den p-Wert mit dem \\(\\alpha\\)-Niveau von 5% vergleichen.\n\n\nTabelle 3— Zusammenhang zwischen der Teststatistik \\(T\\) und der Fläche \\(A\\) rechts von der Teststatistik. Die Fläche rechts von der berechneten Teststatistik \\(T_{calc}\\) wird \\(Pr(T|H_0)\\) oder \\(p\\)-Wert genannt. Die Fläche rechts von dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) wird \\(\\alpha\\) genannt und liegt bei 5%.\n\nTeststatistik \\(T\\)\n\nFläche \\(A\\)\n\n\n\n\n\\(T_{calc}\\)\n\n\\(Pr(T_{calc}|H_0)\\) oder \\(p\\)-Wert\n\n\n\\(T_{\\alpha = 5\\%}\\)\n\\(\\alpha\\)\n\n\n\n\nDer p-Wert oder \\(Pr(T|H_0)\\) ist eine Wahrscheinlichkeit. Eine Wahrscheinlichkeit kann die Zahlen von 0 bis 1 annehmen. Dabei sind die Grenzen einfach zu definieren. Eine Wahrscheinlichkeit von \\(Pr(A) = 0\\) bedeutet, dass das Ereignis A nicht auftritt; eine Wahrscheinlichkeit von \\(Pr(A) = 1\\) bedeutet, dass das Ereignis A eintritt. Der Zahlenraum dazwischen stellt jeden von uns schon vor große Herausforderungen. Der Unterschied zwischen 40% und 60% für den Eintritt des Ereignisses A sind nicht so klar zu definieren, wie du auf den ersten Blick meinen magst.\nEin frequentistischer Hypothesentest beantwortet die Frage, mit welcher Wahrscheinlichkeit \\(Pr\\) die Teststatistik \\(T\\) aus dem Experiment mit den Daten \\(D\\) zu beobachten wären, wenn es keinen Effekt gäbe (\\(H_0\\) ist wahr).\nLikelihood heißt Plausibilität und Probability heißt Wahrscheinlichkeit.\nIm Englischen gibt es die Begrifflichkeiten einer Likelihood und einer Probability in der Statistik. Meist wird beides ins Deutsche ungenau mit Wahrscheinlichkeit übersetzt oder wir nutzen einfach Likelihood. Was aber auch nicht so recht weiterhilft. Es handelt sich hierbei aber um zwei unterschiedliche Konzepte. Deshalb Übersetzen wir Likelihood mit Plausibilität und Probability mit Wahrscheinlichkeit.\nIm Folgenden berechnen wir den \\(p\\)-Wert in R mit der Funktion t.test(). Mehr dazu im Kapitel 15, wo wir den t-Test und deren Anwendung im Detail besprechen.\n\n\n# A tibble: 1 × 2\n  statistic p.value\n      <dbl>   <dbl>\n1      2.81  0.0309\n\n\nWir sagen, dass wir ein signifikantes Ergebnis haben, wenn der \\(p\\)-Wert kleiner ist als die Signifikanzschwelle \\(\\alpha\\) von 5%.\nWir erhalten einen \\(p\\)-Wert von 0.031 und vergleichen diesen Wert zu einem \\(\\alpha\\) von 5%. Ist der \\(p\\)-Wert kleiner als der \\(\\alpha\\)-Wert von 5%, dann können wir die Nullhypothese ablehnen. Da 0.031 kleiner ist als 0.05 können wir die Nullhypothese und damit die Gleichheit der mittleren Sprungweiten in [cm] ablehnen. Wir sagen, dass wir ein signifikantes Ergebnis vorliegen haben.\n\n\n\n\n\n\nEntscheidung mit dem p-Wert\n\n\n\nWenn der p-Wert \\(\\leq \\alpha\\) dann wird die Nullhypothese (H\\(_0\\)) abgelehnt. Das Signifikanzniveau \\(\\alpha\\) wird als Kulturkonstante auf 5% oder 0.05 gesetzt. Die Nullhypothese (H\\(_0\\)) kann auch Gleichheitshypothese gesehen werden. Wenn die H\\(_0\\) gilt, liegt kein Unterschied zwischen z.B. den Behandlungen vor.\n\n\n… anhand des 95% Konfidenzintervall\nEin statistischer Test der eine Teststatistik \\(T\\) berechnet liefert auch immer einen \\(p\\)-Wert. Nicht alle statistischen Tests ermöglichen es ein 95% Konfidenzintervall zu berechnen. Abbildung 2 zeigt ein 95% konfidenzintervall.\n\n\nAbbildung 2— Ein 95% Konfidenzintervall. Der Punkt in der Mitte entspricht dem Unterschied oder Effekt \\(\\Delta\\).\n\n\nMit p-Werten haben wir Wahrscheinlichkeitsaussagen und damit über die Signifikanz. Damit haben wir noch keine Aussage über die Relevanz des beobachtenten Effekts.\nMit der Teststatistik \\(T\\) und dem damit verbundenen \\(p\\)-Wert haben wir uns Wahrscheinlichkeiten angeschaut und erhalten eine Wahrscheinlichkeitsaussage. Eine Wahrscheinlichkeitsaussage sagt aber nichts über den Effekt \\(\\Delta\\) aus. Also wie groß ist der mittlere Sprungunterschied zwischen Hunde- und Katzenflöhen. Eine nährere betrachtung von dem Effekt in der Statistik findest du in ?sec-effect.\nDie Idee von 95% Kondifenzintervallen ist es jetzt den Effekt mit der Wahrscheinlichkeitsaussage zusammenzubringen und beides in einer Visualisierung zu kombinieren. Im Folgenden sehen wir die vereinfachte Formel für das 95% Konfidenzintervall eines t-Tests.\n\\[\n\\left[\n(\\bar{y}_1-\\bar{y}_2) -\nT_{\\alpha = 5\\%} \\cdot \\frac {s_p}{\\sqrt{n}}; \\;\n(\\bar{y}_1-\\bar{y}_2) +\nT_{\\alpha = 5\\%} \\cdot \\frac {s_p}{\\sqrt{n}};\n\\right]\n\\]\nDie Formel ist ein wenig komplex, aber im Prinzip einfach. Der linke und der rechte Teil neben dem Semikolon sind fast gleich, bis auf das Plus- und Minuszeichen. Abbildung 3 visualisert die Formel einmal. Wir sehen Folgendes in der Formel und dann in der entsprechenden Abbildung:\n\n\n\\((\\bar{y}_{1}-\\bar{y}_{2})\\) ist der Effekt \\(\\Delta\\). In diesem Fall der Mittelwertsunterschied. Wir finden den Effekt als Punkt in der Mitte des Intervals.\n\n\\(T_{\\alpha = 5\\%} \\cdot \\frac {s}{\\sqrt{n}}\\) ist der Wert, der die Arme des Intervals bildet. Wir vereinfachen die Formel mit \\(s_p\\) für die gepoolte Standardabweichung und \\(n_g\\) für die Fallzahl der beiden Gruppen. Wir nehmen an das beide Gruppen die gleiche Fallzahl \\(n_1 = n_2\\) haben.\n\n\n\nAbbildung 3— Zusammenhang zwischen der vereinfachten Formel für das 95% Konfidenzintervall und der Visualisierung des 95% Konfidenzintervalls. Der Effektschätzer wird als Punkt in der Mitte des Intervalls dargestellt. Der Effektschäter \\(\\Delta\\) kann entweder ein Mittelwertsunterschied sein oder ein Anteilsunterschied. Bei einem Mittelwertsunterschied kann die Nullhypothese abgelehnt werden, wenn die 0 nicht im Konfidenzintervall ist; bei einem Anteilsunterschied wenn die 1 nicht im Konfidenzintervall ist. Die Arme werden länger oder kürzer je nachdem wie sich die statistischen Maßzahlen \\(s\\) und \\(n\\) verändern.\n\n\nDie Funktion factor() in R erlaubt es dir die Level eines Faktors zu sortieren und so festzulegen ob Level cat minus Level dog oder umgekehrt von R gerechnet wird.\nWir können eine biologische Relevanz definieren, dadurch das ein 95% Konfidenzintervall die Wahrscheinlichkeitsaussage über die Signifkanz, daher ob die Nullhypothese abgelehnt werden kann, mit dem Effekt zusammenbringt. Wo die Signifikanzschwelle klar definiert ist, hängt die Relevanzschwelle von der wissenschaftlichen Fragestellung und weiteren externen Faktoren ab. Die Signifikanzschwelle liegt bei 0, wenn wir Mittelwerte miteinander vergleichen und bei 1, wenn wir Anteile vergleichen. Abbildung 4 zeigt fünf 95% Konfidenzintervalle (a-e), die sich anhand der Signifikanz und Relevanz unterscheiden. Bei der Relevanz ist es wichtig zu wissen in welche Richtung der Effekt gehen soll. Erwarten wir einen positiven Effekt wenn wir die Differenz der beiden Gruppen bilden oder einen negativen Effekt?\n\n\nAbbildung 4— Verschiedene signifikante und relevante Konfidenzintervalle: (a) nicht signifikant und nicht relevant; (b) signifikant und nicht relevant; (c) signifikant und relevant; (d) signifikant und nicht relevant, der Effekt ist zu klein; (e) signifikant und potenziell relevant, Effekt zeigt in eine unerwartete Richtung gegeben der Relevanzschwelle.\n\n\nWir wollen uns nun einmal anschauen, wie sich ein 95% Konfidenzintervall berechnet. Wir nehmen dafür die vereinfachte Formel und setzen die berechneten statistischen Maßzahlen ein. In der Anwendung werden wir die Konfidenzintervalle nicht selber berechnen. Wenn ein statistisches Verfahren konfidenzintervalle berechnen kann, dann liefert die entsprechende Funktion in R das Konfidenzintervall.\nEs ergibt sich Folgende ausgefüllte, vereinfachte Formel für das 95% Konfidenzintervalls eines t-Tests für das Beispiel des Sprungweitenunterschieds [cm] zwischen Hunde- und Katzenflöhen.\n\n\n\n\n\n\nWir nutzen hier eine vereinfachte Formel für das Konfidenzintervall um das Konzept zu verstehen. Später berechnen wir das Konfidenzintervall in R.\n\\[\n\\left[\n(9.2-7.8) -\n2.78 \\cdot \\frac {0.55}{\\sqrt{4}}; \\;\n(9.2-7.8) +\n2.78 \\cdot \\frac {0.55}{\\sqrt{4}};\n\\right]\n\\]\nmit\n\n\n\\(\\bar{y}_{cat} = 9.2\\) dem Mittelwert für die Gruppe cat.\n\n\\(\\bar{y}_{dog} = 7.8\\) dem Mittelwert für die Gruppe dog.\n\n\\(T_{\\alpha = 5\\%} = 2.78\\) dem kritischen Wert.\n\n\\(s_p = 0.55\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{0.6 + 0.5}{2}\\).\n\n\\(n_g = 4\\) der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.\n\nLösen wir die Formel auf, so ergibt sich folgendes 95% Konfidenzintervall des Mittelwertsunterschiedes der Hunde- und Katzenflöhe.\n\\[[0.39; 2.20]\\]\nWir können sagen, dass mit 95% Wahrscheinlichkeit das Konfidenzintervall den wahren Effektunterschied \\(\\Delta\\) überdeckt. Oder etwas mehr in Prosa, dass wir eine Sprungweitenunterschied von 0.39 cm bis 2.20 cm zwischen Hunde- und Katzenflöhen erwarten würden.\nDie Entscheidung gegen die Nullhypothese bei einem Mittelwertsunterschied erfolgt bei einem 95% Konfidenzintervall danach ob die Null mit im Konfidenzintervall liegt oder nicht. In dem Interval \\([0.39; 2.20]\\) ist die Null nicht enthalten, also können wir die Nullhypothese ablehnen. Es ist mit einem Unterschied zwischen den mittleren Sprungweiten von Hunde- und Katzenflöhen auszugehen.\nIn unserem Beispiel, könnten wir die Relevanzschwelle für den mittleren Sprungweitenunterschied zwischen Hund- und Katzenflöhen auf 2 cm setzen. In dem Fall würden wir entscheiden, dass der mittlere Sprungweitenunterschied nicht relevant ist, da die 2 cm im Konfidenzintervall enthalten sind. Was wäre wenn wir die Relevanzschwelle auf 4 cm setzen? Dann wäre zwar die Relevanzschwelle nicht mehr im Konfidenzintervall, aber wir hätten Fall (d) in der Abbildung 4 vorliegen. Der Effekt ist einfach zu klein, dass der Effekt relevant sein könnte.\n\n\n\n\n\n\nEntscheidung mit dem 95% Konfidenzintervall\n\n\n\nBei der Entscheidung mit dem 95% Konfidenzinterval müssen wir zwei Fälle unterscheiden.\n\nEntweder schauen wir uns einen Mittelwertsunterschied (\\(\\Delta_{y_1-y_2}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 0 im 95% Konfidenzinterval ist.\nOder wir schauen uns einen Anteilsunterschied (\\(\\Delta_{y_1/y_2}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 1 im 95% Konfidenzinterval ist."
  },
  {
    "objectID": "stat-tests-preface.html#auswirkung-des-effektes-der-streuung-und-der-fallzahl",
    "href": "stat-tests-preface.html#auswirkung-des-effektes-der-streuung-und-der-fallzahl",
    "title": "Frequentistische Hypothesentests",
    "section": "Auswirkung des Effektes, der Streuung und der Fallzahl",
    "text": "Auswirkung des Effektes, der Streuung und der Fallzahl\nWir wollen einmal den Zusammenhang zwischen dem Effekt \\(\\Delta\\), der Streuung als Standardabweichung \\(s\\) und Fallzahl \\(n\\) uns näher anschauen. Wir können die Formel des t-Tests wie folgt vereinfachen.\n\\[\nT_{calc}=\\cfrac{\\bar{y}_1-\\bar{y}_1}{s_{p} \\cdot \\sqrt{2/n_g}}\n\\]\nFür die Betrachtung der Zusammenhänge wandeln wir \\(\\sqrt{2/n_g}\\) in \\(1/n\\) um. Dadurch wandert die Fallzahl \\(n\\) in den Zähler. Die Standardabweichung verallgemeinern wir zu \\(s\\) und damit allgemein zur Streuung. Abschließend betrachten wir \\(\\bar{y}_A-\\bar{y}_B\\) als den Effekt \\(\\Delta\\). Es ergibt sich folgende vereinfachte Formel.\n\\[\nT_{calc} = \\cfrac{\\Delta \\cdot n}{s}\n\\]\nWir können uns nun die Frage stellen, wie ändert sich die Teststatistik \\(T_{calc}\\) in Abhängigkeit vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\) in den Daten. Die Tabelle 4 zeigt die Zusammenhänge auf. Die Aussagen in der Tabelle lassen sich generalisieren. So bedeutet eine steigende Fallzahl meist mehr signifikante Ergebnisse. Eine stiegende Streuung reduziert die Signifikanz eines Vergleichs. Ein Ansteigen des Effektes führt zu mehr signifikanten Ergebnissen. Ebenso verschiebt eine Veränderung des Effekt das Konfidenzintervall, eine Erhöhung der Streuung macht das konfidenzintervall breiter, eine sinkende Streeung macht das konfidenzintervall schmaller. bei der Fallzahl verhält es sich umgekehrt. Eine Erhöhung der Fallzahl macht das Konfidenzintervall schmaller und eine sinkende Fallzahl das Konfidenzintervall breiter.\n\n\n\nTabelle 4— Zusammenhang von der Teststatistik \\(T_{calc}\\) und dem p-Wert \\(Pr(\\geq T_{calc}|H_0)\\) sowie dem \\(KI_{1-\\alpha}\\) in Abhängigkeit vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(KI_{1-\\alpha}\\)\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(KI_{1-\\alpha}\\)\n\n\n\n\\(\\Delta \\uparrow\\)\nsteigt\nsinkt\nverschoben\n\\(\\Delta \\downarrow\\)\nsinkt\nsteigt\nverschoben\n\n\n\\(s \\uparrow\\)\nsinkt\nsteigt\nbreiter\n\\(s \\downarrow\\)\nsteigt\nsinkt\nschmaller\n\n\n\\(n \\uparrow\\)\nsteigt\nsinkt\nschmaller\n\\(n \\downarrow\\)\nsinkt\nsteigt\nbreiter"
  },
  {
    "objectID": "stat-tests-preface.html#testtheorie",
    "href": "stat-tests-preface.html#testtheorie",
    "title": "Frequentistische Hypothesentests",
    "section": "Testtheorie",
    "text": "Testtheorie\n\n\n\n\n\n\nPrinzip der statistischen Testentscheidung - H\\(_0\\) und H\\(_A\\)\n\n\n\nDu findest auf YouTube Prinzip der statistischen Testentscheidung - \\(H_0\\) und \\(H_A\\) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nVielleicht ist die Idee der Testentscheidung besser mit der Analogie des Rauchmelders zu verstehen. Wir nehmen an, dass der Rauchmelder der statistische Test ist. Der Rauchmelder hängt an der Decke und soll entscheiden, ob es brennt oder nicht. Daher muss der Rauchmelder entscheiden, die Nullhypothese “kein Feuer” abzulehnen oder die Hypothese “kein Feuer” beizubehalten.\n\\[\n\\begin{align*}\nH_0&: \\mbox{kein Feuer im Haus} \\\\  \nH_A&: \\mbox{Feuer im Haus} \\\\   \n\\end{align*}\n\\]\nWir können jetzt den Rauchmelder einstellen, so dass der Rauchmelder bei einer Kerze losgeht oder erst bei einem Stubenbrand. Wie sensibel auf Rauch wollen wir den Rauchmelder einstellen? Soll der Rauchmelder sofort die Nullhypothese ablehnen? Wenn also nur eine Kerze brennt. Soll also der \\(\\alpha\\)-Fehler groß sein? Das wäre nicht sehr sinnvoll. Due Feuerwehr würde schon bei einer Kerze kommen oder wenn wir mal was anbrennen. Wir dürfen also den \\(\\alpha\\)-Fehler nicht zu groß einstellen.\nIntuitiv würde man meinen, ein sehr kleiner \\(\\alpha\\)-Fehler nun sinnvoll sei. Wenn wir aber den Rauchmelder sehr unsensibel einstellen, also der Rauchmelder erst bei sehr viel Rauch die Nullhypothese ablehnt, könnte das Haus schon unrettbar in Flammen stehen. Dieser Fehler, Haus steht in Flammen und der Rauchmelder geht nicht, wird als \\(\\beta\\)-Fehler bezeichnet. Wie du siehst hängen die beiden Fehler miteinander zusammen. Wichtig hierbei ist immmer, dass wir uns einen Zustand vorstellen, das Haus brent nicht (\\(H_0\\) ist wahr) oder das Haus brennt nicht (\\(H_A\\) ist wahr). An diesem Zustand entscheiden wir dann, wie hoch der Fehler jeweils sein soll diesen Zustand zu übersehen.\n\n\n\n\n\n\nDer \\(\\alpha\\)-Fehler und \\(\\beta\\)-Fehler als Rauchmelderanalogie\n\n\n\nHäufig verwirrt die etwas theoretische Herangehensweise an den \\(\\alpha\\)-Fehler und \\(\\beta\\)-Fehler. Wir versuchen hier nochmal die Analogie eines Rauchmelders und dem Feuer im Haus.\n\n\nAbbildung 5— Andere Art der Darstellung des \\(\\alpha\\)-Fehlers als Alarm without fire und dem \\(\\beta\\)-Fehler als Fire without alarm. Je nachdem wie empfindlich wir den Alarm des Rauchmelders (den statistischen Test) über das \\(\\alpha\\) einstellen, desto mehr Alarm bekommen wir ohne das ein Effekt vorhanden wäre. Drehen wir den Alarm zu niedrig, dann kriegen wir kein Feuer mehr angezeigt, den \\(\\beta\\)-Fehler.\n\n\n\n\n\\(\\boldsymbol{\\alpha}\\)-Fehler: Alarm without fire. Der statistische Test schlägt Alarm und wir sollen die \\(H_0\\) ablehnen, obwohl die \\(H_0\\) in Wahrheit gilt und kein Effekt vorhanden ist.\n\n\\(\\boldsymbol{\\beta}\\)-Fehler: Fire without alarm. Der statistische Test schlägt nicht an und wir sollen die \\(H_0\\) beibehalten, obwohl die \\(H_0\\) in Wahrheit nicht gilt und ein Effekt vorhanden ist.\n\n\n\nWie sieht nun die Lösung, erstmal für unseren Rauchmelder, aus? Wir müssen Grenzen für den \\(\\alpha\\) und \\(\\beta\\)-Fehler festlegen.\nWir setzen den \\(\\alpha\\)-Fehler auf 5%.\n\nWir setzen den \\(\\alpha\\)-Fehler auf 5%. Somit haben wir in 1 von 20 Fällen das Problem, dass uns der Rauchmelder angeht obwohl gar kein Feuer da ist. Wir lehnen die Nullhypothese ab, obwohl die Nullhypothese gilt.\n\nWir setzen den \\(\\beta\\)-Fehler auf 20%.\n\nAuf der anderen Seite setzen wir den \\(\\beta\\)-Fehler auf 20%. Damit brennt uns die Bude in 1 von 5 Fällen ab ohne das der Rauchmelder einen Pieps von sich gibt. Wir behalten die Nullhypothese bei, obwohl die Nullhypothese nicht gilt.\n\nNachdem wir uns die Testentscheidung mit der Analogie des Rauchmelders angesehen haben, wollen wir uns wieder der Statistik zuwenden. Betrachten wir das Problem nochmal von der theoretischen Seite mit den statistischen Fachbegriffen.\nSoweit haben wir es als gegeben angesehen, dass wir eine Testentscheidung durchführen. Entweder mit der Teststatistik, dem \\(p\\)-Wert oder dem 95% Konfidenzintervall. Immer wenn wir eine Entscheidung treffen, können wir auch immer eine falsche Entscheidung treffen. Wie wir wissen hängt die berechnete Teststatistik \\(T_{calc}\\) nicht nur vom Effekt \\(\\Delta\\) ab sondern auch von der Streuung \\(s\\) und der Fallzahl \\(n\\). Auch können wir den falschen Test wählen oder Fehler im Design des Experiments gemacht haben. Schlussendlich gibt es viele Dinge, die unsere simple mathematischen Formeln beeinflussen können, die wir nicht kennen. Ein frequentistischer Hypothesentest gibt immer nur eine Aussage über die Nullhypothese wieder. Also ob wir die Nullhypothese ablehnen können oder nicht.\nAbbildung 6 zeigt die theoretische Verteilung der Nullyhypothese und der Alternativehypothese. Wenn die beiden Verteilungen sehr nahe beieinander sind, wird es schwer für den statistischen Test die Hypothesen klar voneinander zu trennen. Die Verteilungen überlappen. Es gibt einen sehr kleinen Unterschied in den Sprungweiten zwischen Hunde- und Katzenflöhen.\n\n\n\nAbbildung 6— Darstellung der Null- und Alternativehypothese. Mit steigendem \\(T_{calc}\\) wird die Wahrscheinlichkeit für die \\(H_0\\) immer kleiner. Leider ist uns nichts über \\(H_A\\) und deren Lage bekannt. Sollte die \\(H_A\\) Verteilung zu weit nach links ragen, könnten wir die \\(H_0\\) beibehalten, obwohl die \\(H_A\\) gilt.\n\n\n\nAchtung In der Regression wird uns auch wieder das \\(\\beta\\) als Symbol begegnen. In der statistischen Testtheorie ist das \\(\\beta\\) ein Fehler; in der Regression ist das \\(\\beta\\) ein Koeffizient der Regression. Hier ist der Kontext wichtig.\nWir können daher bei statistischen Testen zwei Arten von Fehlern machen. Zum einen den \\(\\alpha\\) Fehler oder auch Type I Fehler genannt. Zum anderen den \\(\\beta\\) Fehler oder auch Type II Fehler genannt. Die Grundidee basiert darauf, dass wir eine Testentscheidung gegen die Nullhypothese machen. Diese Entscheidung kann richtig sein, da in Wirklichkeit die Nullhypothese gilt oder aber falsch sein, da in Wirklichkeit die Nullhypothese nicht gilt. In Abbildung 7 wird der Zusammenhang in einer 2x2 Tafel veranschaulicht.\n\n\n\nAbbildung 7— Zusammenhang zwischen der Testentscheidung gegen die \\(H_0\\) Hypothese sowie dem Beibehalten der \\(H_0\\) Hypothese und der unbekannten Wahrheit in der die \\(H_0\\) falsch sein kann oder die \\(H_0\\) wahr sein kann. Wir können mit unserer Testenstscheidung richtig liegen oder falsch. Mit welcher Wahrscheinlichkeit geben der \\(\\alpha\\) Fehler und \\(\\beta\\) Fehler wieder. Unten rechts ist der Zusammenhang zu der Abbildung 6 gezeigt.\n\n\n\n\n\nDie Diskussion über den \\(p\\)-Wert und dem Vergleich mit dem \\(\\alpha\\)-Fehler wird in der Statistik seit 2019 verstärkt diskutiert (Wasserstein, Schirm, und Lazar 2019). Das Nullritual wird schon lamge kritisiert (Gigerenzer, Krauss, und Vitouch 2004). Siehe dazu auch The American Statistician, Volume 73, Issue sup1 (2019).\nBeide Fehler sind Kulturkonstanten. Das heißt, dass sich diese Zahlen von 5% und 20% so ergeben haben. Es gibt keinen rationalen Grund diese Zahlen so zu nehmen. Man kann eigentlich sagen, dass die 5% und die 20% eher einem Zufall entsprungen sind, als einer tieferen Rationalen. Wir behalten diese beiden Zahlen bei aus den beiden schlechtesten Gründe überhaupt: i) es wurde schon immer so gemacht und ii) viele machen es so.\nEine weitere wichtige statistische Maßzahl im Kontext der Testtheorie ist die \\(Power\\) oder auch \\(1-\\beta\\). Die \\(Power\\) ist die Gegenwahrscheinlichkeit von dem \\(\\beta\\)-Fehler. In der Analogie des Rauchmelders wäre die \\(Power\\) daher Alarm with fire. Das heißt, wie wahrscheinlich ist es einen wahren Effekt - also einen Unterschied - mit dem statistischen Test auch zu finden. Oder anders herum, wenn wir wüssten, dass die Hunde- und Katzenflöhe unterschiedliche weit springen, mit welcher Wahrscheinlichkeit würde diesen Unterschied ein statistsicher Test auch finden? Mit eben der \\(Power\\), also gut 80%. Tabelle 5 zeigt die Abhängigkeit der \\(Power\\) vom Effekt \\(\\Delta\\), der Streuung \\(s\\) und der Fallzahl \\(n\\).\nDie \\(Power\\) ist eine Wahrscheinlichkeit und sagt nichts über die Relevanz des Effektes aus.\n\n\nTabelle 5— Abhängigkeit der \\(Power (1-\\beta)\\) vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\). Die \\(Power\\) ist eine Wahrscheinlichkeit und sagt nichts über die Relevanz des Effektes aus.\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{Power (1-\\beta)}\\)\n\n\\(\\boldsymbol{Power (1-\\beta)}\\)\n\n\n\n\\(\\Delta \\uparrow\\)\nsteigt\n\\(\\Delta \\downarrow\\)\nsinkt\n\n\n\\(s \\uparrow\\)\nsinkt\n\\(s \\downarrow\\)\nsteigt\n\n\n\\(n \\uparrow\\)\nsteigt\n\\(n \\downarrow\\)\nsinkt\n\n\n\n\nEinseitig oder zweiseitig?\nManchmal kommt die Frage auf, ob wir einseitig oder zweiseitig einen statistischen Test durchführen wollen. Beim Fall des zweiseitigen Testens verteilen wir den \\(\\alpha\\)-Fehler auf beide Seiten der Testverteilung mit jeweils \\(\\cfrac{\\alpha}{2}\\). In dem Fall des einseitigen Tests liegt der gesamte \\(\\alpha\\)-Fehler auf der rechten oder linken Seite der Testverteilung. In Abbildung 8 wird der Zusammenhang beispielhaft an der t-Verteilung gezeigt.\n\n\n\nAbbildung 8— Zusammenhang zwischen dem einseitigen und zweiseitigen Testen. Im Falle des zweiseitigen Testens teilen wir den \\(\\alpha\\)-Fehler auf beide Seiten der beispielhaften t-Verteilung auf. Im Falle des einseitigen Testen leigt der gesamte \\(\\alpha\\)-Fehler auf der rechten oder der linken Seite der t-Verteilung.\n\n\n\nIn der Anwendung testen wir immer zweiseitig.\nIn der Anwendung testen wir immer zweiseitig. Der Grund ist, dass das Vorzeichen von der Teststatik davon abhängt, welche der beiden Gruppen den größeren Mittelwert hat. Da wir die Mittelwerte vor der Auswertung nicht kennen, können wir auch nicht sagen in welche Richtung der Effekt und damit die Teststatistik laufen wird.\nEs gibt theoretisch Gründe, die für ein einseitiges Testen unter bestimmten Bedingungen sprechen, aber wir nutzen in der Anwendung nur das zweiseite Testen. Wir müssen dazu in R auch nichts weiter angeben. Ein durchgeführter statistischer Test in R testet automatisch immer zweiseitig.\n\n\n\n\n\n\nEinseitig oder zweiseitig im Spiegel der Regulierungsbehörden\n\n\n\nIn den allgemeinen Methoden des IQWiG, einer Regulierungsbehörde für klinische Studien, wird grundsätzlich das zweiseitige Testen empfohlen. Wenn einseitig getestet werden sollte, so soll das \\(\\alpha\\)-Niveau halbiert werden. Was wiederum das gleiche wäre wie zweiseitiges Testen - nur mit mehr Arbeit.\nZur besseren Vergleichbarkeit mit 2-seitigen statistischen Verfahren wird in einigen Guidelines für klinische Studien eine Halbierung des üblichen Signifikanzniveaus von 5 % auf 2,5 % gefordert. – Allgemeine Methoden Version 6.1 vom 24.01.2022, p. 180\n\n\nAdjustierung für multiple Vergleiche\nDas simultane Testen von mehreren Hypothesen führt zu einer \\(\\alpha\\)-Fehler Inflation\nIm Kapitel 21 werden wir mehrere multiple Gruppenvergleiche durchführen. Das heißt, wir wollen nicht nur die Sprungweite von Hunde- und Katzenflöhen miteinander vergleichen, sondern auch die Sprungweite von Hunde- und Fuchsflöhen sowie Katzen- und Fuchsflöhen. Wir würden also \\(k = 3\\) t-Tests für die Mittelwertsvergleiche rechnen.\nDieses mehrfache Testen führt aber zu einer Inflation des \\(\\alpha\\)-Fehlers oder auch Alphafehler-Kumulierung genannt. Daher ist die Wahrscheinlichkeit, dass mindestens eine Nullhypothese fälschlicherweise abgelehnt wird, nicht mehr durch das Signifikanzniveau \\(\\alpha\\) kontrolliert, sondern kann sehr groß werden.\nGehen wir von einer Situation mit \\(k\\) Null- und Alternativhypothesen aus. Wir rechnen also \\(k\\) statistische Tests und alle Nullhypothesen werden zum lokalen Niveau \\(\\alpha_{local} = 0.05\\) getestet. Im Weiteren nehmen wir an, dass tatsächlich alle Nullhypothesen gültig sind. Wir rechnen also \\(k\\) mal einen t-Test und machen jedes mal einen 5% Fehler Alarm zu geben, obwohl kein Effekt vorhanden ist.\nDie Wahrscheinlichkeit für einen einzelnen Test korrekterweise \\(H_0\\) abzulehnen ist \\((1 − \\alpha)\\). Da die \\(k\\) Tests unabhängig sind, ist die Wahrscheinlichkeit alle \\(k\\) Tests korrekterweise abzulehnen \\((1 − \\alpha)^k\\). Somit ist die Wahrscheinlichkeit, dass mindestens eine Nullhypothese fälschlicherweise abgelehnt wird \\(1-(1-\\alpha)^k\\). In der Tabelle 6 wird dieser Zusammenhang nochmal mit Zahlen für verschiedene \\(k\\) deutlich.\n\n\nTabelle 6— Inflation des \\(\\alpha\\)-Fehlers. Wenn 50 Hypothesen getestet werden, ist die Wahrscheinlichkeit mindestens eine falsche Testentscheidung zu treffen fast sicher.\n\nAnzahl Test \\(\\boldsymbol{k}\\)\n\n\\(\\boldsymbol{1-(1-\\alpha)^k}\\)\n\n\n\n1\n0.05\n\n\n2\n0.10\n\n\n10\n0.40\n\n\n50\n0.92\n\n\n\n\nAus Tabelle 7 können wir entnehmen, dass wenn 100 Hypothesen getestet werden, werden 5 Hypothesen im Schnitt fälschlicherweise abgelehnt. Die Tabelle 7 ist nochmal die Umkehrung der vorherigen Tabelle 6.\n\n\nTabelle 7— Inflation des \\(\\alpha\\)-Fehlers. Erwartete Anzahl fälschlich abgelehnter Nullhypothesen abhängig von der Anzahl der durchgeführten Tests\n\nAnzahl Test \\(\\boldsymbol{k}\\)\n\n\\(\\boldsymbol{\\alpha \\cdot k}\\)\n\n\n\n1\n0.05\n\n\n20\n1\n\n\n100\n5\n\n\n200\n10\n\n\n\n\nNachdem wir verstanden haben, dass wiederholtes statistisches Testen irgendwann immer ein signifikantes Ergebnis produziert, müssen wir für diese \\(\\alpha\\) Inflation unsere Ergebnisse adjustieren. Ich folgenden stelle ich verschiedene Adjustierungsverfahren vor.\nBonferroni Korrektur\nDie Bonferroni Korrektur ist die am weitesten verbreitete Methode zur \\(\\alpha\\) Adjustierung, da die Bonferroni Korrektur einfach durchzuführen ist. Damit die Wahrscheinlichkeit, dass mindestens eine Nullhypothese fälschlicherweise abgelehnt wird beim simultanen Testen von \\(k\\) Hypothesen durch das globale (und multiple) Signifikanzniveau \\(\\alpha = 5\\%\\) kontrolliert ist, werden die Einzelhypothesen zum lokalen Signifikanzniveau \\(\\alpha_{local} = \\tfrac{\\alpha_{5\\%}}{k}\\) getestet.\nDabei ist das Problem der Bonferroni Korrektur, dass die Korrektur sehr konservativ ist. Wir meinen damit, dass das tatsächliche globale (und multiple) \\(\\sum\\alpha_{local}\\) Niveau liegt deutlich unter \\(\\alpha_{5\\%}\\) und somit werden die Nullhypothesen zu oft beibehalten.\n\n\n\n\n\n\nAdjustierung des \\(\\boldsymbol{\\alpha}\\)-Fehlers\n\n\n\n\nDas globale \\(\\alpha\\)-Level wird durch die Anzahl \\(k\\) an durchgeführten statistischen Tests geteilt.\n\n\\(\\alpha_{local} = \\tfrac{\\alpha}{k}\\) für die Entscheidung \\(p < \\alpha_{local}\\)\n\n\n\n\n\n\n\n\n\n\nAdjustierung des \\(\\boldsymbol{p}\\)-Wertes\n\n\n\n\nDie p-Werte werden mit der Anzahl an durchgeführten statistischen Tests \\(k\\) multipliziert.\n\n\\(p_{adjust} = p_{raw} \\cdot k\\) mit \\(k\\) gleich Anzahl der Vergleiche.\nwenn \\(p_{adjust} > 1\\), wird \\(p_{adjust}\\) gleich 1 gesetzt, da \\(p_{adjust}\\) eine Wahrscheinlichkeitist.\n\n\n\nBenjamini–Hochberg\nWork in progress\nhttp://www.biostathandbook.com/multiplecomparisons.html"
  },
  {
    "objectID": "stat-tests-preface.html#referenzen",
    "href": "stat-tests-preface.html#referenzen",
    "title": "Frequentistische Hypothesentests",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nGigerenzer, Gerd, Stefan Krauss, und Oliver Vitouch. 2004. „The null ritual“. The Sage handbook of quantitative methodology for the social sciences, 391–408.\n\n\nSalsburg, David. 2001. The lady tasting tea: How statistics revolutionized science in the twentieth century. Macmillan.\n\n\nWasserstein, Ronald L, Allen L Schirm, und Nicole A Lazar. 2019. „Moving to a world beyond ‚p< 0.05‘“. The American Statistician. Taylor & Francis."
  }
]