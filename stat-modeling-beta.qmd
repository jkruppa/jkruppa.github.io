```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, patchwork)
```

# Beta Regression {#sec-beta}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-beta.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

link zu test auf anteile

wirkungsgrad?

Selten n

Im folgenden Kapitel

::: callout-note
## Moment, ich möchte nur zwei Wahrscheinlichkeiten $p_1$ und $p_2$ vergleichen!

Wenn du nur wissen willst, ob sich zwei Wahrscheinlichkeiten unterscheiden, dann musst du einmal in dem Kapitel [Vergleich zweier Anteile $p_1$ und $p_2$](#sec-chisquare-prop-test) nachschauen. Dort zeige ich dir wie du dann einen statistischen Test rechnen kannst um rauszufinden ob sich $0.5$ signifikant von $0.7$ unterscheidet. In diesem Kapitel schauen wir uns dann pro Faktor sehr viele Wahrscheinlichkeiten als Outcome an.
:::

Daher sieht unser Modell wie folgt aus. Wir haben ein $y$ und $p$-mal $x$. Wobei $p$ für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren ist unser $y$ normalverteilt. Das ist hier sehr wichtig, denn wir wollen ja eine multiple gaussian lineare Regression rechnen.

$$
y \sim x_1 + x_2 + ... + x_p 
$$

::: callout-tip
## Weitere Tutorien für die Beta Regression

Wie immer gibt es auch für die Frage nach dem Tutorium für die Beta Regression verschiedene Quellen. Ich kann noch folgende Informationen und Hilfen empfehlen.

-   [A guide to modeling proportions with Bayesian beta and zero-inflated beta regression models](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide) hilft besonders, wenn du tiefer in die Matrie einsteigen willst. Du erhälst bei dem Tutorium einen vollständigen Überblick über die Möglichkeiten. Weit mehr als ich hier mache.
-   Das Tutorium [Beta Regression for Percent and Proportion Data](https://rcompanion.org/handbook/J_02.html) leidet etwas unter dem Mangel an erklärenden Text. Hier wurde anscheinend erst der R Code generiert und der Text sollte folgen. Das schneit hier aber (noch) nicht der Fall zu sein. Als Überblick lohnt sich das Tutorium aber dennoch.
-   [What is the intuition behind beta distribution?](https://stats.stackexchange.com/questions/47771/what-is-the-intuition-behind-beta-distribution) erklärt nochmal was die Idee der Beta Regression eigentlich ist und was eine Betaverteilung eigentlich beschreibt.
-   Das R Paket `{betareg}` und die entsprechende Vignette [Beta Regression in R](https://cran.r-project.org/web/packages/betareg/vignettes/betareg.pdf) liefert wichtige Informationen über die Umsetzung der Beta Regression in R.
-   [Causal inference with beta regression](https://solomonkurz.netlify.app/blog/2023-06-25-causal-inference-with-beta-regression/) liefert eine sehr umfangreiche Überbick über die Beta Regression und das Testen mit der ANOVA. Dann aber auch nicht in dem klassischen Ansatz, den ich hier normalerweise rechne, sondern als bayesianische Variante.
-   Genauso betrachtet das Tutorium [Model Estimation by Example - Bayesian Beta Regression](https://m-clark.github.io/models-by-example/bayesian-beta-regression.html) auch die bayesianische Variante der Beta Regression, so dass du hier vermutlich eher weniger fündig wirst. Ich fand den Überblick aber gut und schön zu lesen -- vorallem war er auch nicht so lang.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom, betareg, car,
               see, performance, parameters, agridat, mfp,
               emmeans, multcomp, rcompanion, ggbeeswarm,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflicts_prefer(dplyr::summarise)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
            "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Wie immer schauen wir uns verschiedene Datensätze an, Visualisieren die Zusammenhänge und rechnen dann verschiedene Modelle, die passen könnten. Beginnen möchte ich mit einem Datensatz zu dem Jagederfolg in \[%\] von Schneefüchsen in verschiedenen Habitaten. Die Daten sind etwas gekürzt, wir haben nur den Jagederfolg und keine Informationen zu den Habitaten. Des Weiteren wollen wir schauen, ob der Jagderfolg der Eisfüche von der standardisierten Schneehöhe in \[cm\] abhängt. Wir haben hier mehr oder minder die Schneehöhe in dem Habit gemittelt. Der Eisfuchs jagt ja nicht immer an der perfekt gleichen Stelle, wo wir die Schneehöhe kennen.

```{r}
hunting_tbl <- read_excel("data/hunting_fox.xlsx") %>% 
  mutate(proportion = round(success/attempts, 2))
```

In der @tbl-beta-fox siehst du einen Auszug aus den Daten. Wir haben die Schneehöhe gemessen und geschaut von wie vielen Anläufen `attempts` eine Maus unter dem Schnee zu fangen erfolgreich war `success` oder eben ein Fehlschlag `fail`. Daraud haben wir dann die Erfolgsrate `proportion` berechnet. Wir haben einfach den Anteil der Erfolge eine Maus zu fangen an den gesamten Versuchen berechnet.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-beta-fox
#| tbl-cap: "Auszug aus dem Daten zu dem Jagderfolg in [%] von Eisfüchsen in abhängigkeit von der Schneehöhe in [cm]."

hunting_raw_tbl <- hunting_tbl %>% 
  mutate_all(as.character)
  

rbind(head(hunting_raw_tbl, 4),
      rep("...", times = ncol(hunting_raw_tbl)),
      tail(hunting_raw_tbl, 4)) %>% 
  kable(align = "c", "pipe")

```

Im Weiteren schauen wir uns einen Datensatz zu Brokkoli an. Wir wollen hier einmal schauen, ob wir das Zielgewicht von $500g$ erreichen. Wir sind aber daran interessiert die Rate von untergewichtigen Brokkoli möglichst klein zu halten. Deshalb schauen wir uns in dieser Auswertung den Anteil von Brokkoli unter der Zielmarke von $500g$ für zwei Düngezeitpunkte sowie drei Düngestufen an. Wir müssen hier jetzt die Daten etwas mehr aufbereiten, da wir mehr Informationen in den Daten haben als wir wirklich brauchen.

```{r}
#| message: false
broc_tbl <- read_excel("data/broccoli_weight.xlsx") %>% 
  filter(fert_time %in% c("early", "late")) %>% 
  mutate(fert_time = factor(fert_time, levels = c("early", "late")),
         fert_amount = as_factor(fert_amount),
         block = as_factor(block)) %>%
  select(fert_time, fert_amount, block, weight) %>% 
  filter(weight <= 500) %>% 
  mutate(proportion = round(weight/500, 2))
```

In der @tbl-beta-broc siehst du einmal den Auszug aus den Brokkolidaten. Wir wollen jetzt sehen, ob wir in den Behandlungsfaktoren einen Unterschied bezüglich der Anteile der untergewichtigen Brokkoliköpfe finden. Tendenziell wollen wir eine Kombination finden, die uns natürlich möglichst schwere Köpfe beschert.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-beta-broc
#| tbl-cap: "Auszug aus dem Daten zu den Zielgewichten von Brokkoli zu zwei Düngezeitpunkten und drei Düngestufen."

broc_raw_tbl <- broc_tbl %>% 
  mutate_all(as.character)
  
rbind(head(broc_raw_tbl, 4),
      rep("...", times = ncol(broc_raw_tbl)),
      tail(broc_raw_tbl, 4)) %>% 
  kable(align = "c", "pipe")

```

Abschließend schauen wir nochmal in das R Paket `{agridat}` und nehmen von dort den Datensatz `salmon.bunt` welcher eine Pilzinfektion von Weizenlinien beschreibt. Mehr dazu dann auf der Hilfeseite [Fungus infection in varieties of wheat](https://kwstat.github.io/agridat/reference/salmon.bunt.html) in der Vignette zum R Paket. Ich möchte später die Faktoren `gen` für die genetischen Linien und die Pilzarten `bunt` für die Anteile der Pilzinfektionen sortiert haben. Das mache ich dann einmal mit der Funktion `fct_reorder()` welche mir erlaubt einen Faktor nach einer anderen Variable zu sortieren. Wir haben zwei Wiederholungen `rep`, die auch so nicht helfen. Deshalb mittlere ich mit `summarise()` über die beiden Wiederholungen die Prozente der Pilzinfektionen des Weizen.

```{r}
#| message: false
#| warning: false
data(salmon.bunt)
fungi_tbl <- salmon.bunt %>% 
  as_tibble() %>% 
  select(gen, bunt, rep, percent = pct) %>% 
  mutate(gen = fct_reorder(gen, percent),
         bunt = fct_reorder(bunt, percent)) %>% 
  group_by(gen, bunt) %>% 
  summarise(percent = mean(percent)) 
```

In der @tbl-beta-fungi siehst du dann einmal den Auszug aus unseren Weizendaten mit einer Pilzinfektion. Wir haben 10 genetische Linien sowie 20 Pilzarten vorliegen. Daher ist der Datensatz ziemlich groß, was die Möglichkeiten der Faktorkombinationen angeht.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-beta-fungi
#| tbl-cap: "Auszug aus dem Daten zu den zehn Weizenlinien und den zwanzig Pilzarten. Es wurde der Anteil an infizierten Weizen [%] gemessen."

fungi_raw_tbl <- fungi_tbl %>% 
  ungroup() %>% 
  mutate_all(as.character) 
  
rbind(head(fungi_raw_tbl, 4),
      rep("...", times = ncol(fungi_raw_tbl)),
      tail(fungi_raw_tbl, 4)) %>% 
  kable(align = "c", "pipe")

```

Damit habe wir dann einige spannende Datensätze vorliegen, die wir nutzen können um die verschiedenen Aspekte der Beta Regression anzuschauen. Nicht immer muss es ja eine Beta Regression sein, wir haben auch die Möglichkeit unsere Fragestellung mit anderen Modellen eventuell anders oder gar besser zu beantworten.

## Visualisierung

Auch hier beginnen wir einmal mit der Visualisierung der Daten. Zuerst schauen wir uns einmal die Daten zu dem Jagderfolg der Eisfüchse in verschiedenen Habitaten in Abhängigkeit zu der Schneehöhe an. Wenn der Schnee zu hoch liegt, werden die Füchse weniger Jagderfolg haben. In der @fig-beta-fox-scatter sehen wir einmal den Jagerfolg von der Schneehöhe aufgetragen. Wir erkennen, dass wir zwar anfänglich eher einen linearen Zusammenhang haben könnten, aber bei höheren Schneedichten dann sehr schnell einen Abfall des Jagderfolges beobachten. Wir schauen uns dann gleich mal verschiedene Modelle an um eine Kurve durch die Punkte zu legen.

```{r}
#| warning: false
#| message: false
#| label: fig-beta-fox-scatter
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "Zusammenhang zwischen dem Jagederfolg von Eisfüchsen und der Schneehöhe in den jeweiligen beobachteten Habitaten."

hunting_tbl %>% 
  ggplot(aes(snow_height, proportion)) +
  theme_minimal() +
  geom_point() +
  labs(y = "Jagderfolg [%]", x = "Standardisierte Schneehöhe [cm]") +
  ylim(0, 1)
```

In der @fig-beta-broc sehen wir einmal die Verteilung unser untergewichtigen Brokkoli für die beiden Düngezeitpunkte und Düngemengen. Wir könnten annehmen, dass wir tendenziell bei einer höheren Düngemenge einen größeren Anteil an erreichtem Zielgewicht erhalten. Global betrachtet scheint es aber nicht so große Effekte zu geben. Wir schauen uns diese Beispiel dann einmal für den Gruppenvergleich an.

```{r}
#| warning: false
#| message: false
#| label: fig-beta-broc
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "Zusammenhang zwischen erreichten Zielgewicht von $500g$ bei Brokkoli [%] und der Düngermenge sowiw dem Düngezeitpunkt."

broc_tbl %>% 
  ggplot(aes(x = fert_amount, y = proportion, color = fert_time)) +
  theme_minimal() + 
  labs(y = "[%] erreichtes Zielgewicht", x = "Düngemenge [mg/l]",
       color = "Düngezeitpunkt") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  geom_beeswarm(dodge.width = 0.8) +
  theme(legend.position = "top") +
  scale_color_okabeito()
```

Abschließend schauen wir uns in der @fig-beta-fungi die Heatmap der genetischen Linien und der Art des Pilzes an. Ich habe die Heatmap so erstellt, dass eine viel Infektion rot dargestellt wird und wenig Infektion blau. Durch die Sortierung der Faktoren nach dem Infektionsgrad können wir sehr schön die Linien voneinander unterscheiden. Teilweise werden einige Linien von dem Pilz förmlich aufgefressen während andere Weizenlinien kaum befallen werden. Auch scheinen einige Arten des Pilzen mehr Weizenlinien befallen zu können als andere Pilzarten. So ist die Pilzart B189 extrem erfolgreich bei einer großen Anzahl an Linien. Die Art B1 hingegen kann mehr oder minder nur zwei Weizensorten befallen.

```{r}
#| warning: false
#| message: false
#| label: fig-beta-fungi
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
#| fig-cap: "Sortierte Heatmap der genetischen Linien und der Art des Pilzes. Farbig dargestellt sind die Anteile an infizierten Weizen in [%]. Nach dem Grad der Infektion wurden die Faktoren sortiert um eine bessere Übersicht zu erhalten."


fungi_tbl %>% 
  ggplot(aes(x = gen, y = bunt, fill = percent)) +
  theme_minimal() +
  geom_tile() +
  scale_fill_gradientn(colors = c("#375997", "gray", "firebrick"),
                       breaks = seq(0, 100, 10), 
                       limits = c(0, 100)) + 
  labs(y = "Art des Pilzes", x = "Genetische Linie des Weizens",
       fill = "[%] infiziert")

```

## Fit des Modells

Dann haben wir jetzt unsere Daten und wissen auch grob was in den Daten stecken könnte. Jetzt wollen wir einmal die verschieden Datensätze auswerten. Je nach Fragestellung können wir da verschiedene Modelle nutzen. Wie immer stelle ich auch Alternativen zu der Beta Regression vor. Wir schauen uns zum einen eine einfache Gaussian Regression an, die passt zwar nicht so richtig zu dem Outcome, aber unter bestimmten Voraussetzungen kann die Gaussian Regression Sinn machen. Wenn wir Erfolg/Misserfolg in unseren Daten als Outcome haben, dann können wir auch eine logistische Regression rechnen. Dementsprechend zeige ich die Anwendung auch einmal auf den Eisfuchsdaten, wo wir ja wissen wie oft ein Erfolg und ein Fehlschlag vorgekommen ist.

### ... mit der Gaussian Regression

Fangen wir also einmal mit der etwas groben Variante an. Wir rechnen einfach eine lineare Regression unter der Annahme das unser Outcome normalverteilt ist. Das stimmt zwar nur begrenzt für eine Wahrscheinlichkeit, die zwischen 0 und 1 liegt, aber rechnen können wir ja erstmal viel. Besonders wenn du Wahrscheinlichkeiten berechnet hast, die nicht sehr viele Nullen und Einsen beinhalten sondern mehr um die 0.5 streuen, dann kann deine Auswertung auch mit einer Gaussian Regression funktionieren. Wie immer kommt es dann auf den Einzelfall an, aber die Gaussian Regression liefert dann eben auch einen sehr gut zu verstehenden und interpretierenden Effektschätzer.

Wir wenden jetzt also einfach mal die Gaussian Regression mit der Funktion `lm()` auf unsere Daten zu dem Jagderfolg der Eisfüchse an. Wenn du dir nochmal die @fig-beta-fox-scatter anschaust, dann siehst du, dass wir nicht so viele Beobachtungen nah der Eins und der Null haben. Darüber hinaus ist eine wage Linearität zu erkennen. Oder anderherum, die Daten sehen jetzt nicht so schlimm aus, dass wir nicht eine Gerade durch die Punkte legen könnten.

```{r}
hunting_lm_fit <- lm(proportion ~ snow_height, data = hunting_tbl)
```

Dann schauen wir uns einmal die Koeffizienten des Modells einmal an. Wir haben einen `Intercept` von über Eins, was natürlich keinen Sinn ergibt. Wir können keinen Jagederfolg von über Eins bei einer Schneehöhe von Null haben. Hier sieht man schon, dass das Modell nicht so gut für die Randbereiche funktioniert. Dennoch haben wir einen Abfall durch die Steigung der Schneehöhe vorliegen. Wir erkennen, dass pro Zentimeter mehr Schnee der Jagderfolg um $0.02$ oder eben $2\%$ signifikant zurückgeht. Das ist ein Ergebnis mit dem wir leben könnten.

```{r}
#| message: false
#| warning: false
hunting_lm_fit %>% 
  model_parameters()
```

Schauen wir einmal wie das Bestimmtheitsmaß $R^2$ aussieht. Hier haben wir einen Wert von $0.758$ und damit können wir durch die Gerade gut $75\%$ der Varianz erklären. Das ist jetzt nicht der beste Werte und wir schauen uns am Ende nochmal in der @fig-beta-fox-predict wie die Gerade durch die Punkte läuft.

```{r}
hunting_lm_fit %>% r2()
```

Das einmal als sehr schneller und kurzer Einwurf der Gaussian Regression auf einem Outcome mit Prozenten. Es ist nicht ideal und weit weg von der Empfehlung. Aber wenn du einen statistischen Engel anfahren willst und mit der Interpretation kganz gut leben kannst, dann ist eine lineare Modellierung nicht so dramatisch. Achtung eben an den Rändern. Du erhälst eben auch schnell mal vorhergesagte Werte außerhalb von den Grenzen einer Wahrscheinlichkeit.

### ... mit dem R Paket `{betareg}`

```{r}
hunting_beta_fit <- betareg(proportion ~ snow_height | snow_height, data = hunting_tbl)
```

```{r}
#| message: false
#| warning: false
hunting_beta_fit %>% 
  model_parameters(exponentiate = TRUE)
```

$$
\mbox{Änderung in Odds %:}\; (OR-1) * 100
$$

$$
\mbox{Änderung in Odds %:}\; (0.94-1) * 100 = -6\%
$$

```{r}
hunting_beta_fit %>% r2()
```

```{r}
#| warning: false
#| message: false
#| label: fig-beta-fox-diagnostic
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Ausgabe ausgewählter Modelgüteplots der Funktion `check_model()`."
#| fig-subcap: 
#|   - "Alter nach Geschlecht"
#|   - "Körpergröße nach Geschlecht"
#|   - "test"
#|   - "test"
#| layout-nrow: 2

plot(hunting_beta_fit)
```

```{r}
hunting_beta_fit %>% Anova()
```

### ... mit einer logistischen Regression

```{r}
hunting_log_fit <- glm(cbind(hunting_tbl$success, hunting_tbl$fail) ~ snow_height, 
                       data = hunting_tbl, family = binomial(link="logit"))
```

```{r}
#| message: false
#| warning: false
hunting_log_fit %>% 
  model_parameters(exponentiate = TRUE)
```

Hier greifen wir auf das R Paket `{rcompanion}` zurück. Wir rechnen auch kein *echtes* Bestimmtheitsmaß $R^2$ aus, sondern den Vergleich zum Null-Modell.

```{r}
hunting_log_fit %>% 
  nagelkerke() %>% 
  pluck("Pseudo.R.squared.for.model.vs.null")
```

```{r}
hunting_log_fit %>% Anova()
```

```{r}
#| warning: false
#| message: false
#| label: fig-beta-fox-predict
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Ausgabe ausgewählter Modelgüteplots der Funktion `check_model()`."

hunting_tbl %>% 
  ggplot(aes(snow_height, proportion)) +
  theme_minimal() +
  geom_point() +
  geom_line(aes(y = predict(hunting_log_fit, type = "response"), color = "log")) +
  geom_line(aes(y = predict(hunting_lm_fit, type = "response"), color = "lm")) +
  geom_line(aes(y = predict(hunting_beta_fit, type = "response"), color = "betareg")) +
  scale_color_manual(name = "Modell", values = cb_pal[2:4])
```

::: callout-note
## Wo ist die mathematische Formel?

::: panel-tabset
## Mit `nls()`

```{r}
lm(log(proportion) ~ snow_height, hunting_tbl)
```

```{r}
nls(proportion ~ b0 - I(snow_height^b1), data = hunting_tbl, 
    start = c(b0 = exp(1.0324), b1 = -0.0354))
```

Dann können wir uns auch schon die Gleichung zusammenbauen.

$$
proportion = 3.196 - snow\_height^{0.248}
$$

## Mit `mfp()`

```{r}
mfp(proportion ~ fp(snow_height), data = hunting_tbl)
```

Dann erhalten wir folgende Gleichung.

$$
proportion = 0.9741 -2.4216 \cdot \left(\cfrac{snow\_height}{100}\right)^3
$$
:::

```{r}
nls_func <- \(x){3.196 - x^(0.248)}
mfp_func <- \(x){0.9741 - 2.4216 * (x/100)^3}
```

```{r}
#| warning: false
#| message: false
#| label: fig-beta-fox-predict-non
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Ausgabe ausgewählter Modelgüteplots der Funktion `check_model()`."

hunting_tbl %>% 
  ggplot(aes(snow_height, proportion)) +
  theme_minimal() +
  geom_point() +
  geom_function(fun = nls_func, aes(color = "nls"), linetype = 'dashed') +
  geom_function(fun = mfp_func, aes(color = "mfp"), linetype = 'dashed') +
  scale_color_manual(name = "Modell", values = cb_pal[2:3])
```
:::

## Gruppenvergleich {#sec-mult-comp-beta-reg}
