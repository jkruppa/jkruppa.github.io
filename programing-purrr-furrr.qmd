# Mit `purrr` und `furrr` {#sec-purrr-furrr}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"Until I realized, it is the struggle itself that is most important. We must strive to be more than we are, Lal. It does not matter that we will never reach our ultimate goal. The effort yields its own rewards."* --- Lieutenant Commander Data, Star Trek: The Next Generation, The Offspring

::: callout-caution
## Was soll das hier? Ziemlich wild alles...

Dieses Kapitel dient dazu *fortgeschrittene* Programmierung in R zu präsentieren. Teilweise nutze ich komplexeren Code bei der [Auswertung von den Beispielen](https://jkruppa.github.io/application/). Wenn dich also Programmieren interessiert, dann kannst du dir hier noch was anschauen. Das Kapitel ist eigentlich nie fertig, da ich sicherlich immer mal wieder was ergänzen werde.
:::

In diesem Kapitel geht es hauptsächlich um [Iterationen](https://r4ds.had.co.nz/iteration.html#iteration). Das heißt wir wollen immer das Gleiche auf verschiedene unterschiedliche Dinge anwenden. In unserem Fall ist das "Gleiche" eine Funktion `function(...){}` in R und das "Unterschiedliche" sind Einträge in einer Liste `lst()` oder einem Datensatz `tibble()`. Wir wollen also zum Beispiel auf verschiedenen Datensätzen mit fünf unterschiedlichen Outcomes immer wieder eine multiple lineare Regression rechnen. Anstatt also per Copy&Paste fünfmal den Code zu kopieren, wollen wir alle Datensätze in einer Liste speichern und die Liste dann in einem Schwung auswerten. Das geht natürlich nur eingeschränkt. Wir müssen ja noch beachten, dass jedes Outcome einer anderen Verteilung folgen könnte.

Wie wir die Daten in Gruppen zusammenfassen ist unterschiedlich möglich. Ich präsentiere hier zum einen die Funktion `split()`, die Daten in Listen aufteilt sowie die Funktion `nest()` die Daten in ein `tibble` zusammenfaltet. Beide Varianten haben so ihre Vor- und Nachteile. Wie immer kommt es dann auf die Anwendung an und was du machen willst.

Es lohnt sich hierbei die Listen bzw. die Datensätze, über die dann iteriert werden soll, so gleich wie irgendwie möglich zu bauen. Das heißt, dass wir die gleiche Anzahl an Spalten mit den gleichen Spaltennamen vorliegen haben wollen. Das erleichtert dann die spätere Anwendung mit `map()`.

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, rstatix, 
               janitor, purrr, furrr, see,
               readxl, tictoc, multcompView, 
               parameters, scales,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")

```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Die Daten

Als Datenbeispiel schauen wir uns einmal ein einfaktoriellen Datensatz an und suchen uns auch nur acht Zeilen und drei Outcomes raus. Wir könnten die Analyse auch über den vollen Datensatz rechnen, aber dann wird hier alles sehr voll. Es geht ja hier mehr um die Demonstration.

```{r}
#| message: false
#| warning: false
soil_tbl <- read_excel("data/soil_1fac_data.xlsx") %>% 
  mutate(variante = str_c(variante, "_", amount),
         variante = as_factor(variante),
         across(where(is.numeric), round, 2)) %>% 
  select(-amount) %>%
  extract(1:8, 1:4) %>% 
  pivot_longer(cols = fe:no3, 
               names_to = "outcome",
               values_to = "rsp") 
```

Als zweiten Datensatz nehmen wir noch eine zweifaktorilles Design mit einem Behandlungs- und einem Blockeffekt. Darüberhinaus haben wir dann noch verschiedene Outcomes und diese Outcomes dann auch an zwei Orten, einmal im Blatt und einmal im Stiel, gemessen. Das heißt, wir haben immer eine Outcome/Sample-Kombination vorliegen. Bei drei Outcomes und zwei Messorten macht das dann sechs Kombinationen auf denen wir dann immer unsere zweifaktoriellen Analysen rechnen wollen.

```{r}
spinach_tbl <- read_excel("data/spinach_metal_data.xlsx") %>% 
  mutate(trt = as_factor(trt),
         sample = as_factor(sample),
         block = as_factor(block)) %>% 
  pivot_longer(cols = fe:zn,
               names_to = "outcome",
               values_to = "rsp") %>% 
  mutate(outcome = as_factor(outcome))
```

## Daten aufteilen...

In R haben wir zwei Möglichkeiten für `map()` die Daten aufzuteilen. Klar, wir können die Aufteilung sicherlich auch mit anderen Funktionen machen, aber diese beiden Funktionen sind sehr nützlich.

### ... mit `split()`

Mit der Funktion `split()` können wir einen Datensatz nach *einer* Faktorspalte in eine Liste aufspalten. Die Liste ist dann auch gleich so benannt wie das Level es Faktors für das wir die Aufteilung gemacht haben. Die Benamung der Liste ist dann praktisch, wenn wir später wieder einen Datensatz aus den Ergebnissen bauen.

```{r}
soil_lst <- soil_tbl %>%
  split(.$outcome) 

soil_lst
```

### ... mit `nest()`

Wenn wir mehr als eine Gruppierungsspalte haben, dann können wir die Funktion `nest()` nutzen. In unserem Beispiel haben wir die Spalte `outcome` und `sample`. Für jede Kombination der beiden Spalte wollen wir dann jeweils ein Modell rechnen. Hier meine ich mit Modell eine lineare Regression und dann eine ANOVA. Als erstes müssen wir unsere Daten gruppieren und dann können wir die Daten nesten. Mit `unnest()` lässt sich dann die genestete Struktur wieder in einen normalen Datensatz zurückführen.

```{r}
spinach_nest_tbl <- spinach_tbl %>% 
  group_by(sample, outcome) %>% 
  nest() 

spinach_nest_tbl
```

## Mit `purrr` über Daten {#sec-purrr}

Das [R Paket purrr](https://purrr.tidyverse.org/) erlaubt es sehr effizient immer das Gleiche auf Listeneinträgen oder genereller auf Daten anzuwenden. Wir können uns dabei selber eine Funktion schreiben oder aber schon implementierte Funktionen anwenden. Gehen wir eimal alle Funktionen durch. Wir werden hier nicht alle zeigen, aber es ist gut einmal zu wissen, welche Funktionen es gibt.

::: column-margin
Schaue auch mal in das Cheat Sheet des R Paketes `purrr` rein: [Apply functions with purrr::cheat sheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_purrr.pdf)
:::

-   `map()` erlaubt über eine Liste von Datensätzen ein Funktion anzuwenden. Dabei können wir dann die einzelnen Listeneinträge über `.x` an die Funktionen weitergeben. Siehe hierzu auch [Basic map functions](https://dcl-prog.stanford.edu/purrr-basics.html).
-   `map2()` erlaubt es über zwei gleichlange Vektoren zu laufen. Wir können hier zwei Optionen in der Form `.x`, `.y` an die Funktion weitergeben. Siehe hierzu auch [Map with multiple inputs](https://dcl-prog.stanford.edu/purrr-parallel.html).
-   `pmap()` kann nun über eine Liste an Vektoren laufen und somit mehrere Inputoptionen verarbeiten. Damit ist `pmap()` die Generalisierung der `map()` Funktion. Siehe hierzu auch [Map with multiple inputs](https://dcl-prog.stanford.edu/purrr-parallel.html).
-   `walk()` ist ein *silent* `map()`. Damit können wir Daten in eine Datei schreiben, ohne ein Output wieder zubekommen.
-   `imap()` können wir nutzen, wenn wir den Index $i$ wieder haben wollen. Das heißt, wir wollen über einen Vektor laufen und brauchen dafür den Index. Hier hilft die `imap()` Familie.
-   `modify()`können wir anwenden, wenn wir nur Spalten modifizieren oder mutieren wollen. Wir haben einen Datensatz und wollen alle `character` Spalten in einen Faktor umwandeln. Siehe hierzu auch [Modify elements selectively](https://purrr.tidyverse.org/reference/modify.html).

Schauen wir uns die Anwendung von der Funktion `map()` auf eine Liste an. In folgenden Code entfernen wir einmal in *jedem* Listeneintrag die Spalte `outcome`. Dann lassen wir uns von *jedem* Listeneintrag die erste Zeile wiedergeben.

```{r}
soil_lst %>%
  map(select, -outcome) %>% 
  map(head, 1)
```

Wir können zum einen `map(head, 1)` schreiben oder aber den Listeneintrag als `.x` direkt in die Funktion weiterleiten. Dann schreiben wir `map(~head(.x, 1))` und müssen noch die Tilde `~` vor die Funktion setzen.

```{r}
soil_lst %>%
  map(~head(.x, 1))
```

Die richtige Stärke entwickelt dann `map()`, wenn wir mehrere Funktionen hineinander schalten. In unserem Fall rechnen wir einen Games-Howell Test und wollen uns dann das *compact letter display* wiedergeben lassen. Da wir am Ende dann einen Datensatz haben wollen, nutzen wir die Funktion `bind_rows()` um die Listeneinträge in einen Datensatz zusammen zukleben.

```{r}
soil_lst %>% 
  map(~games_howell_test(rsp ~ variante, data = .x)) %>% 
  map(~mutate(.x, contrast = str_c(.x$group1, "-", .x$group2))) %>% 
  map(pull, p.adj, contrast) %>% 
  map(~multcompLetters(.x)$Letters) %>% 
  bind_rows(.id = "outcome") 
```

Wir können auch auch auf genesteten Daten die Funktion `map()` anwenden. In diesem Fall belieben wir die ganze Zeit in einem `tibble`. Wir lagern unsere Ergebnisse sozusagen immer in einer Zelle und können auf diese Einträge dann immer wieder zugreifen. Einmal zu Demonstration rechnen wir sechs Mal ein lineares Modell mit der Funktion `lm()` und speichern das Ergebnis in der Spalte `model`. Wir haben jetzt dort jeweils `<lm>` stehen. Damit wissen wir auch, dass wir dort unser Modell drin haben. Wir können jetzt auf der Spalte `model` weiterechnen und uns neue Spalten mit Ergebnissen erschaffen.

```{r}
spinach_nest_tbl %>%
  mutate(model = map(data, ~lm(rsp ~ trt + block, data = .x)))
```

Im Folgenden rechnen wir ein lineares Modell, dann eine ANOVA und lassen uns das Ergebnis der ANOVA mit der Funktion `model_parameters()` aufhübschen. Wie du siehst, geben wie immer den Spaltennamen eine Funktion weiter. Dann wählen wir noch die Spalten, die wir dann unnesten wollen.

```{r}
spinach_nest_tbl %<>%
  mutate(model = map(data, ~lm(rsp ~ trt + block, data = .x))) %>% 
  mutate(anova = map(model, anova)) %>% 
  mutate(parameter = map(anova, model_parameters)) %>% 
  select(sample, outcome, parameter) 
```

Zum Abschluss nutzen wir die Funktion `unnest()` um uns die aufgehübschten Ergebnisse der ANOVA wiedergeben zu lassen. Dann will ich noch, dass die Namen alle klein geschrieben sind und auch sonst sauber sind. Dafür nutze ich dann die Funktion `clean_names()`. Abschließend filtere ich und runde ich noch die Ergebnisse. Am Ende will ich dann nur die Kombinationen aus `sample` und `outcome` haben sowie den $p$-Wert aus der ANOVA.

```{r}
spinach_nest_tbl %>%
  unnest(parameter) %>% 
  clean_names() %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  filter(parameter != "Residuals") %>% 
  select(sample, outcome, parameter, p)
```

Hier noch ein weiteres Beispiel für `split()`, `nest()` und `nest_by()` zum Ausprobieren und rumspielen. Wir wollen für hier einmal auf ganze vielen Behandlungen den Shapiro-Wilk-Tests für die Abweichung von der Normalverteilung rechnen. Dazu laden wir uns einmal die Daten `clove_germ_rate.xlsx`.

```{r}
clove_tbl <- read_excel("data/clove_germ_rate.xlsx") %>% 
  mutate(clove_strain = as_factor(clove_strain),
         germ_rate = as.numeric(germ_rate))
```

Wir rechnen einmal die Shapiro-Wilk-Tests über die Funktion `split()` und dann einer Liste.

```{r}
clove_tbl %>% 
  split(.$clove_strain) %>% 
  map(~shapiro.test(.x$germ_rate)) %>% 
  map(tidy) %>% 
  bind_rows(.id = "test") %>%
  select(test, p.value) %>% 
  mutate(decision = ifelse(p.value <= 0.05, "reject normal", "normal"),
         p.value = pvalue(p.value, accuracy = 0.001))

```

Dann das selbe nochmal mit der Funktion `nest_by()`, die jetzt Vektoren generiert.

```{r}
clove_tbl %>% 
  nest_by(clove_strain) %>% 
  mutate(shapiro = map(data, ~shapiro.test(.x)),
         clean = tidy(shapiro)) %>% 
  reframe(clean)
```

Und nochmal mit der Pipe von `group_by()` zu `nest()`. Die Funktion `nest()` hate auch eine `.by =`-Option, so dass wir auch den Schritt mit `group_by()` weglassen könnten.

```{r}
clove_tbl %>%
  group_by(clove_strain) %>% 
  nest() %>% 
  mutate(shapiro = map(data, ~shapiro.test(.x$germ_rate)),
         clean = map(shapiro, tidy)) %>% 
  unnest(clean)
```

## Mit `furrr` parallel über Daten {#sec-furrr}

Warum geht es den jetzt hier? Wenn du `purrr` und die Funktionen `map()` verstanden hast, dann geht natürlich alles auch in paralleler Berechnung. Die parallele Berechnung ist in dem [R Paket furrr](https://furrr.tidyverse.org/) implementiert. Das heißt wir müssen nur die Funktionsnamen ändern und schon rechnet sich alles in Parallel. Wir nutzen also nicht nur einen Kern von unseren Rechnern sondern eben alles was wir haben.

```{r}
no_cores <- availableCores() - 1
no_cores
```

Einmal das ganze in sequenzieller Programmierung. Also alles nacheinander gerechnet.

```{r}
plan(sequential)

tic()
nothingness <- future_map(c(2, 2, 2), ~Sys.sleep(.x))
toc()
```

Der folgende Code sollte ca. 2 Sekunden dauern, wenn der Code parallel läuft. Wir haben einen kleinen Overhead in `future_map()` durch das Senden von Daten an die einzelnen Kerne. Es gibt auch einmalige Zeitkosten für `plan(multisession)`, um die Kerne einzurichten.

```{r parallel-session}
#| cache: true

plan(multisession, workers = 3)

tic()
nothingness <- future_map(c(2, 2, 2), ~Sys.sleep(.x))
toc()
```

Wie du siehst, must du nur `future_` vor die `map()` Funktion ergänzen und schon kannst du parallel rechnen.

## progressr: An Introduction

Die Funktion `map()` hat die Option `.progress = TRUE` mit der du dir auch einen Fortschritt anzeigen lassen kannst. Also wie lange noch die Funktion braucht um über alle Listeneinträge zu rechnen. Wenn du es noch schöner haben willst, dann schaue dir einmal das R Paket [progressr: An Introduction](https://cran.r-project.org/web/packages/progressr/vignettes/progressr-intro.html) an.
