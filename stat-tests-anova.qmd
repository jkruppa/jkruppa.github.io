```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, plyr)
```

# Die ANOVA {#sec-anova}

[Historisch betrachtet ist die ANOVA, *das* statistische Verfahren was gut per Hand ohne Computer berechnet werden kann. Daher war die ANOVA von den 20zigern bis in die frühen 90ziger des letzten Jahrhunderts *das* statistische Verfahren der Wahl.]{.aside}

::: callout-tip
## Einführung in die ANOVA per Video

Du findest auf YouTube [Grundlagen in R](https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Die ANOVA (eng. *analysis of variance*) ist wichtig. Was für ein schöner Satz um anzufangen. Wir brauchen die ANOVA aus mehreren Gründen. Die Hochzeiten der ANOVA sind eigentlich vorbei, wir haben in der Statistik für viele Fälle mittlerweile besser Werkzeuge, aber als Allrounder ist die ANOVA immer noch nutzbar.

::: column-margin
Die tolle Webseite [Data Science for Agriculture in R](https://schmidtpaul.github.io/DSFAIR/index.html) liefert eine Vielzahl von experimentellen Designs sowie deren Auswertung. Neben anderen komplexeren Designs, auch diese einfacheren Designs, die jeder kennen sollte.

-   [Completely randomized design](https://schmidtpaul.github.io/DSFAIR/CRD_Mead1993.html), ist das Standarddesign für ein Feldexperiment.

-   [Randomized complete block design (RCBD) with 1 factor](https://schmidtpaul.github.io/DSFAIR/RCBD_ClewerScarisbrick2001.html), beschreibt ein Experiment mit Blöcken und einem Behandlungsfaktor.

-   [Randomized complete block design (RCBD) with 2 factors](https://schmidtpaul.github.io/DSFAIR/RCBD_2f_rice.html), beschreibt ein Experiment mit Blöcken und einem Behandlungsfaktor sowie einem weiteren Faktor.

-   [Latin square design](https://schmidtpaul.github.io/DSFAIR/latsquare_Bridges1989.html), ist ein etwas spezielleres Design, wird aber auch viel genutzt.

Wir gehen in einem späteren Kapitel nochmal auf die experimentellen Designs ein.
:::

Wofür brauchen wir die ANOVA?

1)  Wir brauchen die ANOVA um mehr als zwei Gruppen *gleichzeitig* miteinander zu vergleichen. Das heißt wir haben einen Faktor mit mehr als zwei Levels und wollen wissen, ob sich *mindestens* zwei Level bzw. Gruppen im mittelwert unterscheiden.
2)  Wir brauchen die ANOVA und deren Varianzzerlegung in der Züchtung. Hier speilt die ANOVA eine gewichtige Rolle bei der Abschätzung des genetischen Effekts. Wir werden aktuell (Stand Ende 2022) hierauf noch nicht tiefer eingehen.
3)  Wir nutzen die ANOVA in vielen Anwendunsggebieten als eine Arte Vortest um zu schauen, ob sich ein Effekt in den Daten verbirgt. Eigentlich stammt dieses Ritual aus ANOVA als Vortest und dann ein Posthoc Test noch aus der Zeit, wo wir keine moderen Rechner zu Verfügung hatten. Damals machte diese Reihenfolge noch Sinn. Wir werdend arüber aber später nochmal lesen.
4)  Experimentelle Designs sind darauf ausgelegt mit der ANOVA ausgewertet zu werden. Insbesondere in den Agrawissenschaften hat die ANOVA daher eine historische Bedeutung. Insbesondere durch die enge Verzahnung vom Experiment auf dem Feld und der eigentlichen Auswertung mit der ANOVA.

Wir sehen also, dass die ANOVA zum einen alt ist, aber auch heute noch viel verwendet wird. Daher werden wir in diesem *langem* Kapitel uns einmal mit der ANOVA ausgiebig beschäftigen. Fangen wir also an, dieses großartige Schwerzeitaschenmesser der Statistik besser zu verstehen.

::: callout-note
## Was macht die ANOVA?

Die *einfaktorielle* ANOVA vergleicht die Parameter mehrerer Normalverteilungen miteinander. Oder etwas anders formuliert, vergleicht die ANOVA die Mittlelwerte von mehreren Gruppen bzw. Behandlungen miteinander.

Die *zweifaktorielle* ANOVA vergleicht die Parameter mehrerer Normalverteilungen miteinander von zwei Faktoren. Oder etwas anders formuliert, vergleicht die ANOVA die Mittlelwerte von mehreren Gruppen bzw. Behandlungen miteinander. Dabei kann die *zweifaktorielle* ANOVA auch die Interaktion zwischen zwei Variablen abbilden.
:::

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Wir rechnen keine ANOVA in der Klausur *per Hand* sondern interpretieren die Ausgabe der R Funktionen einer einfaktoriellen oder zweifaktoriellen ANOVA. Auch hier gilt, überprüfe was du in der Vorlesung gehört hast!

Bitte schau dir unbedingt die Aufgaben in den [gesammelten Klausurfragen auf GitHub](https://github.com/jkruppa/teaching/tree/main/Klausur) an um eine Idee zu haben, welche Fragen zu der ANOVA drankommen.

Wenn kein $F_{\alpha = 5\%}$ in der Klausur gegeben ist, setzen wir $F_{\alpha = 5\%} = 3.55$.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
pacman::p_load(tidyverse, magrittr, broom, 
               readxl, effectsize, ggpubr)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Einfaktorielle ANOVA

Die einfaktorielle ANOVA ist die simpelste Form der ANOVA. Wir nutzen einen Faktor mit mehr als zwei Leveln. Im Rahmen der einfaktoriellen ANOVA wollen wir usn auch die ANOVA theoretisch einmal anschauen. Danach wie die einfaktorielle ANOVA in R genutzt wird. Ebenso wie wir die einfaktorielle ANOVA visualsieren. Abschließend müssen wir uns noch überlegen, ob es einen Effektschätzer für die einfaktorielle ANOVA gibt.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Die einfaktorielle ANOVA verlangt ein normalverteiltes $y$ sowie Varianzhomogenität über den Behandlungsfaktor $x$. Daher alle Level von $x$ sollen die gleiche Varianz haben.

Unsere Annahme an die Daten $D$ ist, dass das dein $y$ normalverteilt ist und das die Level vom $x$ homogen in den Varianzen sind. Später mehr dazu, wenn wir beides nicht vorliegen haben...
:::

### Daten für die einfaktorielle ANOVA

Wir wollen uns nun erstmal den einfachsten Fall anschauen mit einem simplen Datensatz. Wir nehmen ein normalverteiltes $y$ aus den Datensatz `flea_dog_cat_fox.csv` und einen Faktor mit mehr als zwei Leveln. Hätten wir nur zwei Level, dann können wir auch einen t-Test rechnen können.

Im Folgenden selektieren mit der Funktion `select()` die beiden Spalten `jump_length` als $y$ und die Spalte `animal` als $x$. Danach müssen wir noch die Variable `animal` in einen Faktor mit der Funktion `as_factor()` umwandeln.

```{r}
#| message: false

fac1_tbl <- read_csv2("data/flea_dog_cat_fox.csv") %>%
  select(animal, jump_length) %>% 
  mutate(animal = as_factor(animal))
```

Wir erhalten das Objekt `fac1_tbl` mit dem Datensatz in @tbl-data-anova-1 nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz für die einfaktorielle ANOVA mit einer normalverteilten Variable `jump_length` und einem Faktor mit drei Leveln der Variable `animal`.
#| label: tbl-data-anova-1

fac1_tbl %>% kable(align = "c", "pipe")
```

Wir bauen daher mit den beiden Variablen mit dem Objekt `fac1_tbl` folgendes Modell für später:

$$
jump\_length \sim animal
$$

Bevor wir jetzt das Modell verwenden, müssen wir uns nochmal überlegen, welchen Schluß wir eigentlich über die Nullhypothese machen. Wir immer können wir nur die Nullhypothese ablehnen. Daher überlegen wir uns im Folgenden wie die Nullhypothese in der einfaktoriellen ANOVA aussieht. Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

### Hypothesen für die einfaktorielle ANOVA

Die ANOVA betrachtet die Mittelwerte und nutzt die Varianzen um einen Unterschied nachzuweisen. Daher haben wir in der Nullhypothese als Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass die Mittelwerte jedes Levels des Faktors `animal` gleich sind.

```{=tex}
\begin{align*}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
\end{align*}
```
Die Alternative lautet, dass sich mindestens ein paarweiser Vergleich in den Mittelwerten unterschiedet. Hierbei ist das *mindestens ein Vergleich* wichtig. Es können sich alle Mittelwerte unterschieden oder eben nur ein paar. Wenn eine ANOVA die $H_0$ ablehnt, also ein signifikantes Ergebnis liefert, dann wissen wir nicht, welche Mittelwerte sich unterscheiden.

```{=tex}
\begin{align*}
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{align*}
```
Wir schauen uns jetzt einmal die ANOVA theoretisch an bevor wir uns mit der Anwendung der ANOVA in R beschäftigen.

### Einfaktoriellen ANOVA theoretisch

Kommen wir zurück zu den Daten in @tbl-data-anova-1. Wenn wir die ANOVA per Hand rechnen wollen, dann ist nicht das Long Format die beste Wahl sondern das Wide Format. Wir haben ein balanciertes Design vorliegen, dass heißt in jeder Level sind die gleiche Anzahl Beobachtungen. Wir schauen uns jeweils sieben Flöhe von jeder Tierart an. Für eine ANOVA ist aber ein balanciertes Design nicht notwendig, wir können auch mit ungleichen Gruppengrößen eine ANOVA rechnen.

[Statt einer einfaktoriellen ANOVA könnten wir auch gleich einen `pairwise.t.test()`rechnen. Historisch ebtrachtet ist die einfaktorielle ANOVA die Visualsierung des paarweisen t-Tests.]{.aside}

Eien einfaktorielle ANOVA macht eigentlich keinen großen Sinn, wenn wir anschließend sowieso paarweise Vergleich, wie in @sec-posthoc beschrieben, rechnen. Aus der Hisotrie stellte sich die Frage, ob es sich lohnt die ganze Arbeit für die paarweisen t-Tests per Hand zu rechnen. Daher wurde die ANOVA davorgeschaltet. War die ANOVA nicht signifikant, dann konnte man sich dann auch die Rechnerei für die paaweisen t-Tests sparen.

In @tbl-fac1-wide-01 sehen wir die Daten einmal als Wide Format dargestellt.

|  j  | dog  | cat | fox  |
|:---:|:----:|:---:|:----:|
|  1  | 5.7  | 3.2 | 7.7  |
|  2  | 8.9  | 2.2 | 8.1  |
|  3  | 11.8 | 5.4 | 9.1  |
|  4  | 8.2  | 4.1 | 9.7  |
|  5  | 5.6  | 4.3 | 10.6 |
|  6  | 9.1  | 7.9 | 8.6  |
|  7  | 7.6  | 6.1 | 10.3 |

: Wide Format der Beispieldaten `fac1_tbl` für die jeweils $j=7$ Beobachtungen für den Faktor `animal`. {#tbl-fac1-wide-01}

Wir können jetzt für jedes de Level den Mittelwert über all $j=7$ Beobachtungen berechnen.

```{=tex}
\begin{align*}
\bar{y}_{dog} &= 8.13 \\
\bar{y}_{cat} &= 4.74 \\
\bar{y}_{fox} &= 9.16 \\
\end{align*}
```
Wir tuen jetzt für einen Moment so, als gebe es den Faktor `animal` nicht in den Daten und schauen uns die Verteilung der einzelnen Beobachtungen in @fig-anova-exp-1-1 einmal an. Wir sehen das sich die Beobachtungen von ca. 2.2cm bis 11 cm streuen. Woher kommt nun diese Streuung bzw. Varianz? Was ist die Quelle der Varianz? In @fig-anova-exp-1-2 haben wir die Punkte einmal nach dem Faktor `animal` eingefärbt. Wir sehen, dass die blauen Beobachtungen eher weitere Sprunglängen haben als die grünen Beobachtungen. Wir gruppieren die Beobachtungen in @fig-anova-exp-1-3 nach dem Faktor `animal` und sehen, dass ein Teil der Varianz der Daten von dem Faktor `animal` ausgelöst wird.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Die Spungweite in [cm] in Abhängigkeit von dem Faktor `animal` dargestellt."
#| fig-subcap: 
#|   - "Die Sprungweite in [cm] ohne den Faktor `animal` betrachtet."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` eingefärbt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` eingefärbt und gruppiert."
#| layout-nrow: 1
#| column: page

ggplot(fac1_tbl, aes(x = as.factor(1), y = jump_length)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("")

ggplot(fac1_tbl, aes(x = as.factor(1), y = jump_length, fill = animal)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("")

ggplot(fac1_tbl, aes(x = animal, y = jump_length, color = animal)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("") 
```

Gehen wir einen Schritt weiter und zeichnen einmal das globale Mittel in die @fig-anova-exp-5-1 von $\bar{y}_{..} = 7.34$ und lassen die Beobachtungen gruppiert nach dem Faktor `animal`. Wir sehen, dass die Level des Faktors `animal` um das globale Mittel streuen. Was ja auch bei einem Mittelwert zu erwarten ist. Wir können jetzt in @fig-anova-exp-5-2 die lokalen Mittel für die einzelnen Level `dog`, `cat`und `fox` ergänzen. Und abschließend in @fig-anova-exp-5-3 die Abweichungen $\\beta_i$ zwischen dem globalen Mittel $\bar{y}_{..} = 7.34$ und den einzelnen lokalen Mittel berechnen. Die Summe der Abweichungen $\\beta_i$ ist $0.79 + (-2.6) + 1.81 \approx 0$. Das ist auch zu erwarten, den das globale Mittel muss ja per Definition als Mittelwert gleich großen Abstand "nach oben" wie "nach unten" haben.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-5
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Dotplot der Spungweite in [cm] in Abhängigkeit von dem Faktor `animal`."
#| fig-subcap: 
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und das globale Mittel $\\bar{y}_{..} = 7.34$ ergänzt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und die lokalen Mittel $\\bar{y}_{i.}$ für jedes Level ergänzt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und die Abweichungen $\\beta_i$ ergänzt."
#| layout-nrow: 1
#| column: page

stat <- ddply(fac1_tbl, "animal", summarize,
              mean = mean(jump_length, na.rm = TRUE),
              sd = round(sd(jump_length, na.rm = TRUE), 2))
grand_mean <- mean(fac1_tbl$jump_length, na.rm = TRUE)

ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(round(grand_mean, 2))) +
  ylab("") + xlab("")


ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  stat_summary(fun = mean, aes(ymin=..y.., ymax=..y..), 
               geom='errorbar', width = 0.5, color = "black", size = 1.25) +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(4.75, round(grand_mean, 2), 8.13, 9.16)) +
  ylab("") + xlab("")


ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  stat_summary(fun = mean, aes(ymin=..y.., ymax=..y..), 
               geom='errorbar', width = 0.5, color = "black", size = 1.25) +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  annotate("text", x = 1:3, y = 6.7, size = 5,
           label = round(stat$mean - grand_mean, 2)) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(4.75, round(grand_mean, 2), 8.13, 9.16)) +
  ylab("") + xlab("")

```

Wir tragen die Werte der lokalen Mittlwerte $\bar{y}_{i.}$ und deren Abweichungen $\beta_i$ vom globalen Mittelwert $\bar{y}_{..} = 7.34$ noch in die @tbl-fac1-wide-02 ein. Wir sehen in diesem Beispiel warum das Wide Format *besser* ist, wenn wir die lokalen Mittelwerte und die Abweichungen per Hand berechnen. Da wir in der Anwendung aber *nie* die ANOVA per Hand rechnen, liegen unsere Daten immer in R als Long Format vor.

|       j        |  dog   |  cat   |  fox   |
|:--------------:|:------:|:------:|:------:|
|       1        |  5.7   |  3.2   |  7.7   |
|       2        |  8.9   |  2.2   |  8.1   |
|       3        |  11.8  |  5.4   |  9.1   |
|       4        |  8.2   |  4.1   |  9.7   |
|       5        |  5.6   |  4.3   |  10.6  |
|       6        |  9.1   |  7.9   |  8.6   |
|       7        |  7.6   |  6.1   |  10.3  |
| $\bar{y}_{i.}$ | $8.13$ | $4.74$ | $9.16$ |
|   $\beta_i$    | $-2.6$ | $0.79$ | $1.81$ |

: Wide Format der Beispieldaten `fac1_tbl` für die jeweils $j=7$ Beobachtungen für den Faktor `animal`. Wir ergänzen die lokalen Mittlwerte $\bar{y}_{i.}$ und deren Abweichungen $\beta_i$ vom globalen Mittelwert $\bar{y}_{..} = 7.34$. {#tbl-fac1-wide-02}

Wie kriegen wir nun die ANOVA rechnerisch auf die Straße? Schauen wir uns dazu einmal die @fig-anova-exp-6 an. Auf der linken Seiten sehen wir vier Gruppen, die keinen Effekt haben. Die Gruppen liegen alle auf der gleichen Höhe. Es ist mit keinem Unterschied zwischen den Gruppen zu rechnen. Alle Gruppen*mittel* liegen auf dem globalen Mittel. Die Abweichungen der einzelnen Gruppen*mittel* zum globalen Mittel ist damit gleich null. Auf der rechten Seite sehen wir vier Gruppen mit einem Effekt. Die Gruppen unterscheiden sich in ihren Gruppen*mitteln*. Dadurch unterscheide sich aber auch die Gruppen*mittel* von dem globalen Mittel.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-6
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Darstellung von keinem Effekt und leichtem bis mittleren Effekt in einer einfaktoriellen ANOVA mit einem Faktor mit vier Leveln A - D."
#| fig-subcap: 
#|   - "Kein Effekt"
#|   - "Leichter bis mittlerer Effekt"
#| layout-nrow: 1
#| column: page

no_effect_df <- setNames(stack(tibble(A = rnorm(20, 20, 1),
                                     B = rnorm(20, 20, 1),
                                     C = rnorm(20, 20, 1),
                                     D = rnorm(20, 20, 1))),
                        c("values", "trt"))

ggplot(no_effect_df, aes(x = trt, y = values, fill = trt)) + geom_boxplot() +
  theme_bw() +
  ##scale_fill_manual(values = par$cbbPalette) +
  theme(legend.position="none") +
  ylab("") + xlab("")

light_effect_df <- setNames(stack(tibble(A = rnorm(20, 20, 3),
                                         B = rnorm(20, 25, 4),
                                         C = rnorm(20, 15, 4),
                                         D = rnorm(20, 35, 3))),
                            c("values", "trt"))

ggplot(light_effect_df, aes(x = trt, y = values, fill = trt)) + geom_boxplot() +
  theme_bw() +
  ##scale_fill_manual(values = par$cbbPalette) +
  theme(legend.position="none") +
  ylab("") + xlab("")

```

Wir können daher wie in @tbl-sum-anova-eff geschrieben die Funktionsweise der ANOVA zusammenfassen.

|                            |     |                                                                   |
|:--------------------------:|:---:|:-----------------------------------------------------------------:|
| All level means are equal. |  =  | The differences between level means and the total mean are small. |

: Zusammenfassung der ANOVA Funktionsweise. {#tbl-sum-anova-eff}

Nun kommen wir zum eigentlichen Schwenk und warum eigentlich die ANOVA meist etwas verwirrt. Wir wollen eine Aussage über die Mittelwerte machen. Die Nullhypothese lautet, dass alle Mittelwerte gleich sind. Wie wir in @tbl-sum-anova-eff sagen, heißt alle Mittelwerte gleich auch, dass die Abweichungen von den Gruppenmitteln zum globalen Mittel klein ist.

Wie weit die Gruppenmittel von dem globalen Mittel weg sind, dazu nutzt die ANOVA die Varianz. Die ANOVA vergleicht somit

-   die Varianz der einzelnen Mittelwerte der (Gruppen)Level zum globalen Mittel (eng. *variability between levels*)
-   und die Varianz der Beobachtungen zu den einzelnen Mittelwerten der Level (eng. *variability within one level*)

[Die *sum of squares* sind nichts anderes als die Varianz. Wir nennen das hier nur einmal anders...]{.aside}

Wir berechnen also wie die Beobachtungen jeweils um das globale Mittel streuen ($SS_{total}$), die einzelnen Beobachtungen um die einzelnen Gruppenmittel $SS_{error}$ und die Streuung der Gruppenmittel um das globale Mittel ($SS_{animal}$). Wir nennen die Streuung Abstandquadrate (eng. *sum of squares*) und damit sind die *Sum of Square* $(SS)$ nichts anderes als die Varianz. Die @tbl-sumsquares zeigt die Berechnung des Anteils jeder einzlenen Beobachtung an den jeweiligen *Sum of Squares*.

::: column-page
| animal (x) | jump_length (y) | $\boldsymbol{\bar{y}_{i.}}$ | SS$_{\boldsymbol{animal}}$ | SS$_{\boldsymbol{error}}$ | SS$_{\boldsymbol{total}}$ |
|:----------:|:---------------:|:---------------------------:|:--------------------------:|:-------------------------:|:-------------------------:|
|    dog     |      $5.7$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(5.7 - 8.13)^2 = 5.90$  |  $(5.7 - 7.34)^2 = 2.69$  |
|    dog     |      $8.9$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(8.9 - 8.13)^2 = 0.59$  |  $(8.9 - 7.34)^2 = 2.43$  |
|    dog     |     $11.8$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  | $(11.8 - 8.13)^2 = 13.47$ | $(11.8 - 7.34)^2 = 19.89$ |
|    dog     |      $8.2$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(8.2 - 8.13)^2 = 0.00$  |  $(8.2 - 7.34)^2 = 0.74$  |
|    dog     |      $5.6$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(5.6 - 8.13)^2 = 6.40$  |  $(5.6 - 7.34)^2 = 3.03$  |
|    dog     |      $9.1$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(9.1 - 8.13)^2 = 0.94$  |  $(9.1 - 7.34)^2 = 3.10$  |
|    dog     |      $7.6$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(7.6 - 8.13)^2 = 0.28$  |  $(7.6 - 7.34)^2 = 0.07$  |
|    cat     |      $3.2$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(3.2 - 4.74)^2 = 2.37$  | $(3.2 - 7.34)^2 = 17.14$  |
|    cat     |      $2.2$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(2.2 - 4.74)^2 = 6.45$  | $(2.2 - 7.34)^2 = 26.42$  |
|    cat     |      $5.4$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(5.4 - 4.74)^2 = 0.44$  |  $(5.4 - 7.34)^2 = 3.76$  |
|    cat     |      $4.1$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(4.1 - 4.74)^2 = 0.41$  | $(4.1 - 7.34)^2 = 10.50$  |
|    cat     |      $4.3$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(4.3 - 4.74)^2 = 0.19$  |  $(4.3 - 7.34)^2 = 9.24$  |
|    cat     |      $7.9$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(7.9 - 4.74)^2 = 9.99$  |  $(7.9 - 7.34)^2 = 0.31$  |
|    cat     |      $6.1$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(6.1 - 4.74)^2 = 1.85$  |  $(6.1 - 7.34)^2 = 1.54$  |
|    fox     |      $7.7$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(7.7 - 9.16)^2 = 2.13$  |  $(7.7 - 7.34)^2 = 0.13$  |
|    fox     |      $8.1$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(8.1 - 9.16)^2 = 1.12$  |  $(8.1 - 7.34)^2 = 0.58$  |
|    fox     |      $9.1$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(9.1 - 9.16)^2 = 0.00$  |  $(9.1 - 7.34)^2 = 3.10$  |
|    fox     |      $9.7$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(9.7 - 9.16)^2 = 0.29$  |  $(9.7 - 7.34)^2 = 5.57$  |
|    fox     |     $10.6$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  | $(10.6 - 9.16)^2 = 2.07$  | $(10.6 - 7.34)^2 = 10.63$ |
|    fox     |      $8.6$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(8.6 - 9.16)^2 = 0.31$  |  $(8.6 - 7.34)^2 = 1.59$  |
|    fox     |     $10.3$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  | $(10.3 - 9.16)^2 = 1.30$  | $(10.3 - 7.34)^2 = 8.76$  |
|            |                 |                             |          $74.68$           |          $56.53$          |         $131.21$          |

: Berechnung der $SS_{animal}$, $SS_{error}$ und $SS_{total}$ anhand der einzelnen gemessenen Werte $y$ für durch die jeweiligen Gruppenmittel $\bar{y}_{i.}$ und dem globalen Mittel $\bar{y}_{..}$ über alle Beobachtungen {#tbl-sumsquares}
:::

Die ANOVA wird deshalb auch Varianz*zerlegung* genannt, da die ANOVA versucht den Abstand der Beoabchtungen auf die Variablen im Modell zu zerlegen. Also wieviel der Streuung von den Beobachtungen kann von dem Faktor `animal` erklärt werden? Genau der Abstand von den Gruppenmitteln zu dem globalen Mittlelwert.

Du kannst dir das ungefähr als eine Reise von globalen Mittelwert zu der einzelnen Beobachtung vorstellen. Nehmen wir als Beispiel die kleinste Sprungweite eines Katzenflöhes von 2.2 cm und visualisieren wir uns die Reise wie in @fig-single-cat-anova zu sehen. Wie kommen wir jetzt *numerisch* vom globalen Mittel mit $7.34$ zu der Beobachtung? Wir können zum einen den direkten Abstand mit $2.2 - 7.34$ gleich $-5.14$ cm berechnen. Das wäre der *total* Abstand. Wie sieht es nun aus, wenn wir das Gruppenmittel mit beachten? In dem Fall gehen wir vom globalen Mittel zum Gruppenmittel `cat` mit $4.74 -7.34$ gleich $-2.6$ cm. Jetzt sind wir aber noch nicht bei der Beobachtung. Wir haben noch einen Rest von $2.2 - 4.74$ gleich $-2.54$ cm, die wir noch zurücklegen müssen. Das heißt, wir können einen Teil der Strecke mit dem Gruppenmittelwert erklären. Oder anders herum, wir können die Strecke vom globalen Mittelwert zu der Beobachtung in einen Teil für das Gruppenmittel und einen unerklärten Rest zerlegen.

![Visualisierung der Varianzzerlegung des Weges vom globalen Mittel zu der einzelnen Beoabchtung. Dargestellt sind die numerischen Abstände und *nicht* die Sum of Squares.](images/anova-pre-01.png){#fig-single-cat-anova fig-align="center" width="80%"}

Wir rechnen also eine ganze Menge an Abständen und quadrieren dann diese Absatände zu den Sum of Squares. Oder eben der Varianz. Dann fragen wir uns, ob der Faktor in unserem Modell einen Teil der Abstände erklären kann. Wir bauen uns dafür eine ANOVA Tabelle. @tbl-anova-fac1-theo zeigt eine theoretische, einfaktorielle ANOVA Tabelle. Wir berechnen zuerst die Abstände als $SS$. Nun ist es aber so, dass wenn wir in einer Gruppe viele Level und/oder Beoabchtungen haben, wir auch größere Sum of Squares bekommen. Wir müssen also die Sum of Squares in mittlere Abweichungsqudrate (eng. *mean squares*) mitteln. Abschließend können wir die F Statistik berechnen, indem wir die $MS$ des Faktors durch die $MS$ des Fehlers teilen. Das Verhältnis von erklärter Varianz vom Faktor zu dem unerklärten Rest.

::: column-page
| Varianzquelle |  df   |                             Sum of squares                             |               Mean squares               |           F$_{\boldsymbol{calc}}$            |
|:-------------:|:-----:|:----------------------------------------------------------------------:|:----------------------------------------:|:--------------------------------------------:|
|    animal     | $k-1$ |    $SS_{animal} = \sum_{i=1}^{k}n_i(\bar{y}_{i.} - \bar{y}_{..})^2$    | $MS_{animal} = \cfrac{SS_{animal}}{k-1}$ | $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$ |
|     error     | $n-k$ | $SS_{error} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{i.})^2$ |  $MS_{error} = \cfrac{SS_{error}}{N-k}$  |                                              |
|     total     | $n-1$ | $SS_{total} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{..})^2$ |                                          |                                              |

: Einfaktorielle ANOVA in der theoretischen Darstellung. Die sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac1-theo}
:::

Wir füllen jetzt die @tbl-anova-fac1-example einmal mit den Werten aus. Nachdem wir das getan haben oder aber die Tabelle in R ausgegeben bekommen haben, können wir die Zahlen interpretieren.

::: column-page
| Varianzquelle |   df   |    Sum of squares     |                Mean squares                |         F$_{\boldsymbol{calc}}$          |
|:-------------:|:------:|:---------------------:|:------------------------------------------:|:----------------------------------------:|
|    animal     | $3-1$  | $SS_{animal} = 74.68$ | $MS_{animal} = \cfrac{74.68}{3-1} = 37.34$ | $F_{calc} = \cfrac{37.34}{3.14} = 11.89$ |
|     error     | $21-3$ | $SS_{error} = 56.53$  |  $MS_{error} = \cfrac{56.53}{18} = 3.14$   |                                          |
|     total     | $21-1$ | $SS_{total} = 131.21$ |                                            |                                          |

: Einfaktorielle ANOVA mit den ausgefüllten Werten. Die $SS_{total}$ sind die Summe der $SS_{animal}$ und $SS_{error}$. Die $MS$ berechnen sich dan direkt aus den $SS$ und den Freiheitsgraden ($df$). Abschließend ergibt sich dann die F Statistik. {#tbl-anova-fac1-example}
:::

Zu erst ist die berechnete F Statistik $F_{calc}$ von Interesse. Wir haben hier eine $F_{calc}$ von 11.89. Wir vergleichen wieder die berechnete F Statistik mit einem kritsichen Wert. Der kritische F Wert $F_{\alpha = 5\%}$ lautet für die einfaktorielle ANOVA in diesem konkreten Beispiel mit $F_{\alpha = 5\%} = `r round(qf(p=.05, df1=2, df2=18, lower.tail=FALSE), 2)`$. Die Enstscheidungsregel nach der F Testatitik lautet, die $H_0$ abzulehnen, wenn $F_{calc} > F_{\alpha = 5\%}$.

Wir können also die Nullhypothese $H_0$ in unserem Beispiel ablehnen. Es liegt ein signifikanter Unterschied zwischen den Tiergruppen vor. Mindestens ein Mittelwertsunterschied in den Sprungweiten liegt vor.

::: callout-important
## Entscheidung mit der berechneten Teststatistik $F_{\boldsymbol{calc}}$

Bei der Entscheidung mit der berechneten Teststatistik $F_{calc}$ gilt, wenn $F_{calc} \geq F_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt.

**Achtung --** Wir nutzen die Entscheidung mit der Teststatistik *nur und ausschließlich* in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik *keine* Verwendung mehr.
:::

### Einfaktoriellen ANOVA in R

```{r}
fit_1 <-  lm(jump_length ~ animal, data = fac1_tbl) %>% 
  anova

fit_1

fit_1 %>% eta_squared
```

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-boxplot-anova-1

ggplot(fac1_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() +
  theme(legend.position = "none") 

```

## Zweifaktorielle ANOVA

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Die zweifaktorielle ANOVA verlangt ein normalverteiltes $y$ sowie Varianzhomogenität jeweils separat über beide Behandlungsfaktor $x_1$ und $x_2$. Daher alle Level von $x_1$ sollen die gleiche Varianz haben. Ebenso sollen alle Level von $x_2$ die gleiche Varianz haben.

Unsere Annahme an die Daten $D$ ist, dass das dein $y$ normalverteilt ist und das die Level vom $x_1$ und $x_2$ jewiels für sich homogen in den Varianzen sind. Später mehr dazu, wenn wir beides nicht vorliegen haben...
:::

### Daten für die zweifaktorielle ANOVA

```{r}
#| message: false

fac2_tbl <- read_csv2("data/flea_dog_cat_fox_site.csv") %>% 
  select(animal, site, jump_length) %>% 
  mutate(animal = as_factor(animal),
         site = as_factor(site))
```

```{r}
#| message: false
#| echo: false
#| tbl-cap: test caption
#| label: tbl-data-anova-2

fac2_tbl %>% kable(align = "c", "pipe")
```

### Hypothesen die zweifaktorielle ANOVA

Wir haben für jeden Faktor ein Hypothesenpaar.

Einmal für `animal`

```{=tex}
\begin{align*}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{align*}
```
Einmal für `site`

```{=tex}
\begin{align*}
H_0: &\; \bar{y}_{city} = \bar{y}_{smalltown} = \bar{y}_{village} = \bar{y}_{field}\\
H_A: &\; \bar{y}_{city} \ne \bar{y}_{smalltown}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{village} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{align*}
```
Einmal für die Interaktion `animal:site`

```{=tex}
\begin{align*}
H_0: &\; \mbox{keine Interaktion}\\
H_A: &\; \mbox{eine Interaktion zwischen animal und site}
\end{align*}
```
Decision rule: reject $H_0$ if $F > F_{df_A = k-1,\,df_E=N-k,\,1-\alpha}$

### Zweifaktoriellen ANOVA in R

#### Ohne Interaktionsterm

Beispieldaten sind in @fig-boxplot-anova-2 abgebildet.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-boxplot-anova-2

ggplot(fac2_tbl, aes(x = animal, y = jump_length, 
                     fill = site)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() 
```

```{r}
fit_2 <-  lm(jump_length ~ animal + site, data = fac2_tbl) %>% 
  anova

fit_2

fit_2 %>% tidy

fit_2 %>% eta_squared
```

::: column-page
| Varianzquelle |       df       | Sum of squares | Mean squares  |           F$_{\boldsymbol{calc}}$            |
|:-------------:|:--------------:|:--------------:|:-------------:|:--------------------------------------------:|
|    animal     |     $a-1$      | $SS_{animal}$  | $MS_{animal}$ | $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$ |
|     site      |     $b-1$      |  $SS_{site}$   |  $MS_{site}$  |  $F_{calc} = \cfrac{MS_{site}}{MS_{error}}$  |
|     error     | $n-(a-1)(b-1)$ |  $SS_{error}$  | $MS_{error}$  |                                              |
|     total     |     $n-1$      |  $SS_{total}$  |               |                                              |

: Zweifaktorielle Anova ohne Interaktionseffekt
:::

::: column-page
| Varianzquelle |        df        |     Sum of squares     |     Mean squares      |         F$_{\boldsymbol{calc}}$          |
|:-------------:|:----------------:|:----------------------:|:---------------------:|:----------------------------------------:|
|    animal     |      $3-1$       | $SS_{animal} = 180.03$ | $MS_{animal} = 90.02$ | $F_{calc} = \cfrac{90.02}{4.53} = 19.88$ |
|     site      |      $4-1$       |   $SS_{site} = 9.13$   |  $MS_{site} = 3.04$   |  $F_{calc} = \cfrac{3.04}{4.53} = 0.67$  |
|     error     | $120-(3-1)(4-1)$ | $SS_{error} = 516.17$  |  $MS_{error} = 4.53$  |                                          |
|     total     |     $120-1$      | $SS_{total} = 705.33$  |                       |                                          |

: Zweifaktorielle Anova ohne Interaktionseffekt
:::

#### Mit Interaktionssterm

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-interact-anova-1

ggplot(fac2_tbl, aes(x = animal, y = jump_length,
                     color = site, group = site)) +
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun = mean, geom = "line") +
  theme_bw()

```

```{r}
fit_3 <-  lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) %>% 
  anova

fit_3

fit_3 %>% tidy()

fit_3 %>% eta_squared
```

::: column-page
|    Varianzquelle     |      df      |      Sum of squares       |       Mean squares        |                 F$_{\boldsymbol{calc}}$                  |
|:--------------------:|:------------:|:-------------------------:|:-------------------------:|:--------------------------------------------------------:|
|        animal        |    $a-1$     |       $SS_{animal}$       |       $MS_{animal}$       |       $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$       |
|         site         |    $b-1$     |        $SS_{site}$        |        $MS_{site}$        |        $F_{calc} = \cfrac{MS_{site}}{MS_{error}}$        |
| animal $\times$ site | $(a-1)(b-1)$ | $SS_{animal \times site}$ | $MS_{animal \times site}$ | $F_{calc} = \cfrac{MS_{animal \times site}}{MS_{error}}$ |
|        error         |    $n-ab$    |       $SS_{error}$        |       $MS_{error}$        |                                                          |
|        total         |    $n-1$     |       $SS_{total}$        |                           |                                                          |

: Zweifaktorielle Anova mit Interaktionseffekt
:::

::: column-page
|    Varianzquelle     |         df          |           Sum of squares           |           Mean squares            |         F$_{\boldsymbol{calc}}$          |
|:--------------------:|:-------------------:|:----------------------------------:|:---------------------------------:|:----------------------------------------:|
|        animal        |        $3-1$        |       $SS_{animal} = 180.03$       |       $MS_{animal} = 90.02$       | $F_{calc} = \cfrac{90.02}{2.97} = 30.28$ |
|         site         |        $4-1$        |         $SS_{site} = 9.13$         |        $MS_{site} = 3.04$         |  $F_{calc} = \cfrac{3.04}{2.97} = 1.02$  |
| animal $\times$ site |    $(3-1)(4-1)$     | $SS_{animal \times site} = 195.12$ | $MS_{animal \times site} = 32.52$ | $F_{calc} = \cfrac{32.52}{2.97} = 10.94$ |
|        error         | $120 - (3 \cdot 4)$ |       $SS_{error} = 321.06$        |        $MS_{error} = 2.97$        |                                          |
|        total         |       $120-1$       |       $SS_{total} = 705.34$        |                                   |                                          |

: Zweifaktorielle Anova mit Interaktionseffekt
:::

## `ggpubr`

```{r}
#| message: false
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-ggpubr-1

p <- ggboxplot(fac2_tbl, x = "animal", y = "jump_length",
               color = "animal", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
               add = "jitter", shape = "animal")

my_comparisons <- list( c("cat", "dog"), c("dog", "fox"), c("cat", "fox") )
p + stat_compare_means(comparisons = my_comparisons) + 
  stat_compare_means(label.y = 27, method = "anova")                  


```

```{r}
#| message: false
#| warning: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-ggpubr-2
 
my_comparisons <- list( c("cat", "dog"), c("dog", "fox"), c("cat", "fox") )
         
ggviolin(fac2_tbl, x = "animal", y = "jump_length", fill = "animal",
         palette =c("#00AFBB", "#E7B800", "#FC4E07"),
         add = "boxplot", add.params = list(fill = "white"))+
  stat_compare_means(comparisons = my_comparisons, label = "p.signif") + 
  stat_compare_means(label.y = 27, method = "anova")                                      #
```
