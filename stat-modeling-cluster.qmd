```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra)
```

# Clusteranalysen {#sec-cluster-analysis}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

> *"Cluster together like stars!" --- Henry Miller*

In diesem Kapitel wollen wir uns mit der Clusteranalyse beschäftigen. Zuerst was verstehen wir unter einem Cluster? Ein Cluster ist ein Zusammenschluss von ähnlichen Beobachtungen. Nun stellt sich zuerst die Frage, was heißt ähnlich? Wir brauchen also Maßzahlen für die Ähnlichkeit zwischen zwei und mehreren Beobachtungen. Im Weiteren haben wir in erster Linie kein Outcome $y$. Wir nehmen alle Spalten $x$ aus unseren Daten und versuchen anhand der Spalten Gruppen über die Beobachtungen in den Zeilen zu bilden.

-   Die **hierarchisches Clustern** über Dendrogramme in @sec-clust-dendro
-   Das **k-NN** oder nächste Nachbarn Clustern in @sec-clust-knn
-   Die **Hauptkomponentenanalyse** in @sec-clust-pca
-   Die **Heatmaps** verbreitet in der genetischen Analys in @sec-clust-heat
-   Einmal das hierarchisches Clustern und k-NN über das R Paket `tidyclust` in @sec-clust-tidyclust

Teilweise haben wir Überlagerungen mit dem Kapitel @sec-outlier

Wie immer können wir nicht alles erschlagen. Daher hier die R Pakete, die du dir nochmal anschauen solltest.

-   Das R Paket `factoextra` [Factoextra R Package: Easy Multivariate Data Analyses and Elegant Visualization](http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization) um sich Faktoranalysen super anzuschauen und durchzuführen.
-   Das R Paket `dendextend` [Introduction to dendextend](https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html) um Dendrogramme wirklich schön zu zeichnen.
-   Das R Paket `pheatmap` [Making a heatmap in R with the pheatmap package](https://davetang.github.io/muse/pheatmap.html) um Heatmaps mit allem was das Herz begehrt zu bauen. Dann haben wir noch das R Paket [ComplexHeatmap](https://jokergoo.github.io/ComplexHeatmap-reference/book/index.html), was sich vom R Paket `pheatmap` inspirieren lies. Das geht dann aber hier zu weit, schauen da, wenn du wirklich Heatmaps brauchst.

Wir wollen uns die Clusteranalyse an zwei Spieldaten anschauen sowie einmal an den echten Daten zu den Gummibärchen. Eigentlich werden ja auch gerne Fragebögen mit der Clusteranalyse ausgewertet, aber hier muss ich nochmal warten bis ich ein gutes Beispiel in den Beratungen hatte. Dann ergänze ich ein Beispiel bei dem Skrippt zu den [Beispielhaften Auswertungen](https://jkruppa.github.io/application/).

https://www.datanovia.com/en/lessons/cluster-analysis-example-quick-start-r-code/ https://www.r-bloggers.com/2021/04/cluster-analysis-in-r/ https://www.datanovia.com/en/lessons/clustering-distance-measures/#data-preparation

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
set.seed(20230727)
pacman::p_load(tidyverse, magrittr, palmerpenguins, readxl,
               ggdendro, broom, cluster, factoextra,
               pheatmap, tidyclust, dlookr, janitor,
               dendextend, conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflicts_prefer(dlookr::transform)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Beginnen wir mit einem normierten Datensatz

```{r}
animals_tbl <- read_excel("data/cluster_animal.xlsx", sheet = 1) %>% 
  clean_names() %>% 
  mutate(across(where(is.numeric), \(x) x - 1))
```

Schauen

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-cluster-01
#| tbl-cap: "."

animals_tbl %>% 
  kable(align = "c", "pipe")
```

Als nächstes einen sehr schön hetrogenen Datensatz

[Clustering Creatures](https://rpubs.com/askieswe/clustering)

```{r}
creature_tbl <- read_excel("data/cluster_animal.xlsx", sheet = 2) %>% 
  clean_names() %>% 
  mutate(creature = tolower(creature))

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-cluster-02
#| tbl-cap: "."

creature_tbl %>% 
  kable(align = "c", "pipe")
```

Im Weiteren betrachten wir noch das Beispiel der Gummibärchendaten. Auch hier haben wir echte Daten vorliegen, so dass wir eventuell Ausreißer entdecken könnten. Da wir hier fehlende Werte in den Daten haben, entfernen wir alle fehlenden Werte mit der Funktion `na.omit()`. Damit löschen wir jede Zeile in den Daten, wo mindestens ein fehlender Wert auftritt. Da wir hier mittlerweile sehr viele Daten vorliegen haben, wollen wir das Problem auf die beiden Quellen *FU Berlin* und dem *Girls and Boys Day* eingrenzen.

```{r}
#| message: false

gummi_tbl <- read_excel("data/gummibears.xlsx")  %>%
  filter(module %in% c("FU Berlin", "Girls and Boys Day")) %>% 
  select(gender, age, height, semester, most_liked) %>% 
  mutate(gender = as_factor(gender),
         most_liked = as_factor(most_liked)) %>% 
  na.omit()
```

Auch

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-meta-sunflower
#| tbl-cap: "Daten zu den mit Mehltau infizierten Sonnenblumensamen nach der Behandlung mit MoldEx."

gummi_tbl %>% 
  head(7) %>% 
  kable(align = "lrr", "pipe")
```

Häufig

::: {.callout-caution collapse="true"}
## Weitere Datensätze fürs Clustern

Andere mögliche Datensätze für die Zukunft: `chorSub`, `flower`, `plantTraits`, `pluton`, `ruspini` und `agriculture`. Die Datensätze sind teilweise im R Paket `cluster` enthalten.

Im Weiteren noch die [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/index.html) mit dem Datensatz `penguins` aus dem R Paket `palmerpenguins`.
:::

## Daten preprocessing

Wir können die Daten so wir wie sie vorliegen haben in einem Clusteralgorithmus verwenden. Wir führen also keine Transformation der Daten durch, wir nutzen die Daten untransformiert. Dieses untransfomierte Verwenden der Daten führt aber meist dazu, dass Variablen nicht im gleichen Maße berücksichtigt werden. Es macht eben einen Unterschied, ob wir wie bei dem Alter sehr viele verschiedene Werte haben als beim Geschlecht. Es macht auch einen Unterschied, ob das Alter numerische Werte von 20 bis 60 haben kann und das Semester nur numerische Werte von 1 bis 10.

In dem @sec-eda-transform findest du die hier verwendeten Standardfunktionen in R aus dem Paket `dlookr` für die Normalisierung sowie Standardisierung mit der Funktion `transform()`. Wenn es komplexer wird, dann empfehle ich den Workflow, wie er im @sec-pre-processing für die Klassifikation von Daten vorgestellt wird.

### Normalisieren

Die Normalisierung von Variablen in ein Intervall von $[0;1]$. Es gehen natürlich auch andere Intervalle, aber das Intervall von 0 bis 1 ist wohl das häufigste Intervall was genutzt wird.

```{r}
norm_creature_tbl <- creature_tbl %>% 
  mutate(mass_grams = transform(mass_grams, "minmax"),
         heart_rate_bpm = transform(heart_rate_bpm, "minmax"),
         longevity_years = transform(longevity_years, "minmax")) 
norm_creature_tbl
```

Hier helfen natürlich auch die Funktionen von dem R Paket `dplyr` und der [Hilfsseite von `across()`](https://dplyr.tidyverse.org/reference/across.html) um mehrere Spalten schneller in `mutate` zu transformieren.

### Standardisieren

Die Standardisierung von Variablen zu einer $\mathcal{N(0,1)}$ Standardnormalverteilung

```{r}
scale_gummi_tbl <- gummi_tbl %>% 
  mutate(gender = as_factor(gender),
         age = transform(age, "zscore"),
         height = transform(height, "zscore"),
         semester = transform(semester, "zscore"),
         most_liked = as_factor(most_liked))
scale_gummi_tbl
```

Wie beim Normalisieren helfen hier natürlich auch die Funktionen von dem R Paket `dplyr` und der [Hilfsseite von `across()`](https://dplyr.tidyverse.org/reference/across.html) um mehrere Spalten schneller in `mutate` zu transformieren.

### Das `data.frame()` Problem

Leider ist es so, dass fast alle Pakete mit den Zeilennamen bzw. `row.names()` eines `data.frame()` arbeiten. Das hat den Grund, dass wir gut das Label in den Zeilennamen parken können, ohne das uns eine Spalte in den Auswertungen stört. Meistens ist das Label ja ein `character` und soll gar nicht in den Clusteralgorithmus mit rein. Deshalb müssen wir hier einmal unsere `tibble()` in einen `data.frame()` umwandeln. Die `tibble()` haben aus gutem Grund keine Zeilennamen, die Zeilennamen sind ein Ärgernis und Quelle von Fehlern und aus gutem Grund nicht in einem `tibble()` drin. Hier brauchen wir die Zeilennamen aber.

Wir bauen uns also einmal einen `data.frame()` für unseren Tierdatensatz und setzen die Tiernamen als Zeilennamen bzw. `row.names()`.

```{r}
animals_df <- animals_tbl %>% 
  na.omit() %>% 
  as.data.frame() %>% 
  set_rownames(.$animal) %>% 
  select(-animal)

```

Das Ganze machen wir dann auch noch einmal für die Kreaturendaten.

```{r}
norm_creature_df <- norm_creature_tbl %>% 
  as.data.frame() %>% 
  set_rownames(.$creature) %>% 
  select(-creature)
```

Wie eben gesagt, ist es teilweise echt nervig immer die `row.names()` mit zu nehmen und alles ein `data.frame()` zu nutzen. Insbesondere wenn die Daten sehr groß werden, kann kann es sehr ungünstig sein, alles in einem `data.frame()` zu lagern. Deshalb gibt es das Paket [tidyclust](https://tidyclust.tidymodels.org/index.html), welches ich am Ende nochmal vorstelle.

## Distanzmaße

Wir betrachten im Folgenden immer die Distanzen zwischen den Zeilen des Datensatzes. Das heißt, wir wollen immer die Distanzen zwischen den Beobachtungen berechnen. Wie nah oder fern sind sich zwei Beobachtungen gegeben den Spalten? Wir schauen uns einmal zwei sehr intuitive Distanzmaße mit der euklidischen sowie der manhattan Distanz an.

Euklidische Distanz

:   $$
    d_E(p,q) = \sqrt{(p-q)^2}
    $$

Manhattan Distanz

:   $$
    d_M(p,q) = \lvert p-q \rvert
    $$

-   `dist()` als Standardfunktion: Akzeptiert nur numerische Daten als Eingabe, das zu verwendende Abstandsmaß muss eines der Folgenden sein: `euclidean`, `maximum`, `manhattan`, `canberra`, `binary` oder `minkowski`. Die Hilfeseite `?dist()` liefert mehr Informationen über die Distanzmaße.
-   `get_dist()` aus dem R Paket `factoextra`: Akzeptiert nur numerische Daten als Eingabe. Im Vergleich zur Standardfunktion dist() unterstützt sie korrelationsbasierte Abstandsmaße einschließlich der Methoden `pearson`, `kendall` und `spearman`.
-   `daisy()` aus dem R Paket `cluster`: Kann mit anderen Variablentypen umgehen als numerisch. Also auch mit Kategorien und Faktoren. In diesem Fall wird automatisch der Gower-Koeffizient als Metrik verwendet. Er ist eines der beliebtesten Näherungsmaße für gemischte Datentypen. Weitere Einzelheiten findest du auf der Hilfeseite der Funktion `?daisy`.

Durch die Standardisierung werden die Abstandsmaße - Euklidisch, Manhattan, Korrelation - ähnlicher, als sie es bei nicht transformierten Daten wären.

Die Funktion `fviz_dist()` aus dem R Paket `factorextra` erlaubt hier die Distanzmatrix zu visualisieren.

## Algorithmen fürs Clustern

### Hierarchische Clusteranalyse oder Dendrogramme {#sec-clust-dendro}

Es gibt vier gängige Ansätze für die Cluster-Cluster-Distanzierung, auch *Linkage* genannt:

-   *single linkage*: Der Abstand zwischen zwei Clustern ist der Abstand zwischen den beiden nächstgelegenen Beobachtungen.
-   *average linkage*: Der Abstand zwischen zwei Clustern ist der Durchschnitt aller Abstände zwischen den Beobachtungen in einem Cluster und den Beobachtungen im anderen Cluster.
-   *complete linkage*: Der Abstand zwischen zwei Clustern ist der Abstand zwischen den beiden am weitesten entfernten Beobachtungen.
-   *centroid method*: Der Abstand zwischen zwei Clustern ist der Abstand zwischen ihren Zentroiden (geometrisches Mittel oder Median).
-   *Ward-Methode*: Der Abstand zwischen zwei Clustern ist proportional zur Zunahme der Fehlerquadratsumme (ESS), die sich aus der Verbindung der beiden Cluster ergeben würde. Die ESS wird als Summe der quadrierten Abstände zwischen den Beobachtungen in einem Cluster und dem Schwerpunkt des Clusters berechnet.

```{r}
#| message: false
#| warning: false
h_clust_animal <- animals_df  %>% 
  dist(., method = "euclidean") %>% 
  hclust(., method = "ward.D")
```

```{r}
#| message: false
#| warning: false
grp_animal <- cutree(h_clust_animal , k=3)
grp_animal
```

Wir nehmen jetzt mal die normalisierten Kreaturen

```{r}
#| message: false
#| warning: false
h_clust_creature <- norm_creature_df %>% 
  dist(., method = "euclidean") %>% 
  hclust(., method = "ward.D")
```

```{r}
#| message: false
#| warning: false
grp_creature <- cutree(h_clust_creature , k=3)
grp_creature
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| label: fig-cluster-01
#| fig-cap: "dst."
#| fig-subcap: 
#|   - "Verteilung der beobachteten Werte."
#|   - "Verteilung der theoretischen Werte."
#| layout-nrow: 1
#| column: page

ggdendrogram(h_clust_animal)
ggdendrogram(h_clust_creature)
```

[Introduction to dendextend](https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html)

[Hierarchical cluster analysis on famous data sets - enhanced with the dendextend package](https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html)

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:  fig-cluster-04
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "dst."
#| fig-subcap: 
#|   - "within cluster sums of squares"
#|   - "gap statistics."
#| layout-nrow: 1
#| column: page

fviz_dend(h_clust_animal, cex = 0.5, k = 4, palette = "jco") 
fviz_dend(h_clust_creature, cex = 0.5, k = 4, palette = "jco") 

```

### k-means Clusteranalyse {#sec-clust-knn}

[K-means Cluster Analysis](https://uc-r.github.io/kmeans_clustering)

Siehe auch `pam()` aus dem R Paket `cluster`.

```{r}
knn_animal <- animals_df %>% 
  kmeans(centers = 4)
```

```{r}
knn_creature <- norm_creature_df %>% 
  kmeans(centers = 4)
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:  fig-cluster-03
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "dst."
#| fig-subcap: 
#|   - "within cluster sums of squares"
#|   - "gap statistics."
#| layout-nrow: 1
#| column: page

fviz_cluster(knn_animal, data = animals_df, palette = "jco") +
  theme_bw() +
  scale_x_continuous(expand = expansion(add = c(0.5, 0.5))) +
  scale_y_continuous(expand = expansion(add = c(0.5, 0.5))) 

fviz_cluster(knn_creature, data = norm_creature_df, palette = "jco") +
  theme_bw() +
  scale_x_continuous(expand = expansion(add = c(0.5, 1))) +
  scale_y_continuous(expand = expansion(add = c(0.5, 0.5))) 


```

Was ist das optimale $k$ für die Anzahl an Gruppen?

```{r}
#| echo: true
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| label: fig-cluster-02
#| fig-cap: "dst."
#| fig-subcap: 
#|   - "within cluster sums of squares"
#|   - "gap statistics."
#| layout-nrow: 1
#| column: page


animals_df %>% 
  fviz_nbclust(kmeans, method = "wss")

norm_creature_df %>% 
  fviz_nbclust(kmeans, method = "gap_stat")
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:  fig-cluster-05
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "."
ggplot(creature_tbl, aes(longevity_years, heart_rate_bpm, label = creature)) + 
  theme_bw() +
  geom_label(aes(fill = as_factor(knn_creature$cluster)), colour = "white", 
             fontface = "bold", size=2) +
  scale_fill_discrete(name = "Cluster") 
```

Um das Ergebnis der Gruppenfindung zu beurteilen, eignet sich ein Silhouettenplot. Ein Silhouettenplot zeigt für jede Beobachtung i die Silhouettenbreite $s_i$, welche definiert ist als normierte Differenz der kleinsten Distanz zu den Beobachtungen außerhalb der eigenen Gruppe und dem Mittelwert der Distanzen innerhalb einer Gruppe. Die Silhouettenbreite $s_i$ kann jeden Wert im Intervall \[-1, 1\] annehmen und wird folgendermaßen interpretiert.

-   $s_i = 1$ Die Beobachtung ist dem "richtigen" Cluster zugeordnet.
-   $s_i = 0$ Die Beobachtung hätte ebenso gut einer anderen Gruppe zugeordnet werden können.
-   $s_i = -1$ Die Beobachtung ist schlecht zugeordnet.

Es kann darüber hinaus die durchschnittliche Silhouettenbreite über alle Beobachtungen berechnet werden, womit sich die Gruppenbildung als Ganzes beurteilen lässt. Die durchschnittliche Silhouettenbreite wird analog interpretiert.

Was ist mit tidyclust::silhouette?

```{r}
silhouette_creature_tbl <- cluster::silhouette(knn_creature$cluster, 
                                      dist(norm_creature_df, "canberra")) %>% 
  as_tibble() %>% 
  mutate(creature = row.names(norm_creature_df),
         cluster = as_factor(cluster))
```

```{r}
silhouette_animals_tbl <- cluster::silhouette(knn_animal$cluster, 
                                      dist(animals_df, "canberra")) %>% 
  as_tibble() %>% 
  mutate(animal = row.names(animals_df),
         cluster = as_factor(cluster))
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:  fig-cluster-08
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "dst."
#| fig-subcap: 
#|   - "within cluster sums of squares"
#|   - "gap statistics."
#| layout-nrow: 1
#| column: page

ggplot(silhouette_creature_tbl, aes(x = creature, y = sil_width, fill = cluster)) +
  theme_bw() +
  geom_bar(stat = "identity", width = 0.5) + 
  coord_flip() + 
  labs(x = "")

ggplot(silhouette_animals_tbl, aes(x = animal, y = sil_width, fill = cluster)) +
  theme_bw() +
  geom_bar(stat = "identity", width = 0.5) + 
  coord_flip() + 
  labs(x = "")
```

```{r}
silhouette_creature_tbl %>% 
  summarise(mean(sil_width),
            sd(sil_width))
```

```{r}
silhouette_animals_tbl %>% 
  summarise(mean(sil_width),
            sd(sil_width))
```

### Heatmap {#sec-clust-heat}

Das R Paket `pheatmap` [Making a heatmap in R with the pheatmap package](https://davetang.github.io/muse/pheatmap.html) um Heatmaps

[Heatmap in R: Static and Interactive Visualization](https://www.datanovia.com/en/lessons/heatmap-in-r-static-and-interactive-visualization/)

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:  fig-cluster-09
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "."

pheatmap(animals_df, cutree_cols = 4)
```

Wir schauen uns im Folgenden das Beispiel von [Hierarchical cluster analysis on famous data sets](https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html#heatmap-1) nochmal an.

Nach den Zeilen

```{r}
dend_r <- animals_df %>% dist(method = "man") %>% hclust(method = "ward.D") %>% as.dendrogram %>% ladderize %>%
    color_branches(k=4)
```

Nach den Spalten

```{r}
dend_c <- t(animals_df) %>% dist(method = "man") %>% hclust(method = "com") %>% as.dendrogram %>% ladderize%>%
    color_branches(k=3)
```

```{r}
# some_col_func <- function(n) rev(colorspace::heat_hcl(n, c = c(80, 30), l = c(30, 90), power = c(1/5, 1.5)))
# some_col_func <- colorspace::diverge_hcl
# some_col_func <- colorspace::sequential_hcl
 some_col_func <- function(n) (colorspace::diverge_hcl(n, h = c(246, 40), c = 96, l = c(65, 90)))

```

```{r}
gplots::heatmap.2(as.matrix(animals_df), 
          main = "Attributes of Animals",
          srtCol = 35,
          Rowv = dend_r,
          Colv = dend_c,
          trace="row", hline = NA, tracecol = "darkgrey",         
          margins =c(6, 5),      
          key.xlab = "no / yes",
          denscol = "grey",
          density.info = "density",
          col = gplots::bluered(100)
         )
```

Das R Paket `heatmaps` [Tutorial heatmaps](https://bioconductor.org/packages/release/bioc/vignettes/heatmaps/inst/doc/heatmaps.html) liefert nochmal Beispiele mit genetischen Datensätzen.

[ComplexHeatmap](https://jokergoo.github.io/ComplexHeatmap-reference/book/index.html), was sich vom R Paket `pheatmap` inspirieren lies. Das geht dann aber hier zu weit, schauen da, wenn du wirklich Heatmaps brauchst.

### Hauptkomponentenanalyse {#sec-clust-pca}

Teilweise haben wir Überlagerungen mit dem Kapitel @sec-outlier

## Datenanalyse mit `tidyclust` {#sec-clust-tidyclust}

Wie du schon oben gesehen hast, ist es teilweise echt nervig immer die `row.names()` mit zu nehmen oder alles ein `data.frame()` zu nutzen. Insbesondere wenn die Daten sehr groß werden, kann kann es sehr ungünstig sein, alles in einem `data.frame()` zu lagern. Deshalb gibt es das Paket [tidyclust](https://tidyclust.tidymodels.org/index.html), was ich hier nochmal vorstellen möchte. Die Visualisierungen von oben können alle genutzt werden. Der Vorteil ist eben, dass wir hier in der `tidy`-Welt sind und uns auch die `recipes()` aus dem Klassifikationskapiteln zu nutze machen können. Da ist dann das Normalisierieren und andere Vorbereitungsschritte der Daten viel einfacher. Damit wir auch mal die Datenanalyse mit einem großen Datensatz sehen, nutze ich hier einmal den Datensatz der Gummibärchendaten. Im Folgenden analysieren wir also die Gummibärchendaten einmal mit dem R Paket `tidyclust`.

### Hierarchical Clustering

::: column-margin
[tidyclust Hilfeseite für das Hierarchical Clustering](https://tidyclust.tidymodels.org/articles/hier_clust.html)
:::

```{r}
hc_spec <- hier_clust(num_clusters = 3,
                       linkage_method = "average")
```

```{r}
hc_fit <- hc_spec %>%
  fit(~ gender + age + height + semester + most_liked,
      data = gummi_tbl)
```

Wenn es zu lang wird dann auch `fit(~ .)`

```{r}
#| echo: true
#| message: false
#| warning: false
#| label:   fig-cluster-11
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "."

ggdendrogram(hc_fit$fit, rotate = FALSE, size = 2) +
  theme_bw()
```

```{r}
hc_summary <- hc_fit %>% extract_fit_summary()

hc_summary %>% 
  pluck("cluster_assignments")
```

### k-means Clustering

::: column-margin
[tidyclust Hilfeseite für das k-means Clustering](https://tidyclust.tidymodels.org/articles/k_means.html)
:::

```{r}
kmeans_spec <- k_means(num_clusters = 3)

kmeans_spec
```

```{r}
kmeans_spec_lloyd <- k_means(num_clusters = 3) %>%
  parsnip::set_engine("stats", algorithm = "Lloyd")
```

```{r}
kmeans_fit <- kmeans_spec %>%
  fit(~ age + height + semester,
      data = gummi_tbl)
```

```{r}
kmeans_fit$fit
```

```{r}
kmeans_fit %>%
  extract_cluster_assignment()
```

```{r}
kmeans_summary <- kmeans_fit %>%
  extract_fit_summary()
```

```{r}
tibble(
  orig_labels = kmeans_summary$orig_labels,
  standard_labels = kmeans_summary$cluster_assignments
)
```

```{r}
kmeans_fit %>%
  extract_centroids()
```

```{r}
kmeans_fit %>%
  tidyclust::silhouette_avg(select(gummi_tbl, age, height, semester))
```

## Referenzen {.unnumbered}
