```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Der Effektschätzer {#sec-effect}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

::: column-margin
Eine wunderbare Übersicht über den Begriff *Effektschätzer* liefert das englische Buch [Doing Meta-Analysis with R: A Hands-On Guide](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html).
:::

Der Effektschätzer. Ein seltsames Kapitel, denn ich tue mich sehr schwer, dieses Kapitel irgendwo in die Linearität dieses Buches hier einzuordnen. Deshalb ist dieses Kapitel eigentlich immer an der falschen Stelle. Entweder hast du schon die statistischen Tests gelesen und du wüsstest gerne was die Effektschätzer sind *oder* du suchst hier nochmal die Beschreibung der Effektschätzer zum Beispiel aus der multiple Regression heraus. Also steht jetzt dieses Kapitel hier im Raum und du musst schauen, was du wirklich brauchst. Oder ob du dieses Kapitel erst überspringst und dann später nochmal hier liest.

[Der Effektschätzer wird auch gerne Theta $\boldsymbol{\theta}$ genannt. Da wir dann aber später noch mit anderen Konzepten in die Quere kommen, nutze ich das etwas intuitivere Delta $\boldsymbol{\Delta}$.]{.aside}

Wenn wir einen der vielen Effektschätzer berechnen wollen, dann nutzen wir dafür die Effektschätzer aus dem [R Paket effectsize](https://easystats.github.io/effectsize/index.html). Das R Paket `effectsize` liefert Effektschätzer für fast alle statistischen Gelegenheiten. Wir werden hier wie immer nur den groben Überblick abdecken. Vermutlich wird das Kapitel dann noch Anwachsen. Streng genommen gehört das @sec-test-diag zu den diagnostischen Tests auf einer 2x2 Kreuztabelle auch irgendwie zu Effektschätzern. Wenn du Spezifität und Sensitivität suchst bist du in dem Kapitel zu diagnostischen Tests richtig.

Wir unterscheiden hier erstmal grob in zwei Arten von Effektschätzern:

1)  Effektschätzer, die einen **Mittelwertsunterschied** beschreiben.
2)  Effektschätzer, die einen **Anteilsunterschied** beschreiben.

Daneben gibt es wie noch die Korrelation wie in @sec-lin-reg-corr beschrieben. Die Korrelation wollen wir aber in diesem Kapitel nicht vorgreifen bzw. wiederholen.

::: callout-tip
## Effektschätzer

Wenn wir uns einen Unterschied eines **Mittelwerts** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn der Mittlwertsunterschied $\Delta$ zwischen der Gruppe $A$ und der Gruppe $B$ gleich 0 ist. Die Nullhypothese gilt. Beide Gruppen $A$ und $B$ haben den gleichen Mittelwert.

$$
\Delta_{A-B} = A - B = 0
$$

Wenn wir uns einen Unterschied eines **Anteils** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn der Anteilsunterschied $\Delta$ zwischen der Gruppe $A$ und der Gruppe $B$ gleich 1 ist. Die Nullhypothese gilt. Beide Gruppen $A$ und $B$ haben den gleichen Anteil.

$$
\Delta_{A/B} = \cfrac{A}{B} = 1
$$

Dieses Wissen brauchen wir um die Signifikanzschwelle bei einem 95% Konfidenzintervall richtig zu setzen und interpretieren zu können. Siehe dazu auch nochmal das @sec-ki.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, see, effectsize)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Unterschied zweier Mittelwerte

Wir berechnen zwei Mittelwerte $\bar{y}_1$ und $\bar{y}_2$. Wenn wir wissen wollen wie groß der Effekt zwischen den beiden Mittelwerten ist, dann bilden wir die Differenz. Wir berechnen das $\Delta_{y_1-y_2}$ für $y_1$ und $y_2$ indem wir die beiden Mittelwerte voneinander abziehen.

$$
\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2
$$

[Warum schreiben wir hier vermutlich? Ein statistischer Test ist eine Funktion von $\Delta$, $s$ und $n$. Wir können auch mit kleinem $\Delta$ die Nullhypothese ablehnen, wenn $s$ und $n$ eine passende Teststatistik generieren. Siehe dazu auch das @sec-delta-n-s.]{.aside}

Wenn es keinen Unterschied zwischen den beiden Mittelwerten $\bar{y}_1$ und $\bar{y}_2$ gibt, dann ist die Differenz $\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2$ gleich 0. Wir sagen, die Nullhypothese *vermutlich* gilt, wenn die Differenz klein ist. Was wir besser annehmen können ist, dass die Relevanz klein ist. Effekt mit einem geringen Mittelwertsunterschied sind meistens nicht relevant. Aber diese Einschätzung hängt stark von der Fragestellung ab.

$$
H_0: \Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2 = 0
$$

In @tbl-dog-cat-small-delta ist nochmal ein sehr simples Datenbeispiel gegeben an dem wir den Zusammenhang nochmal nachvollziehen wollen.

```{r}
#| echo: false
#| label: tbl-dog-cat-small-delta
#| tbl-cap: Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.
data_tbl <- tibble(animal = gl(2, 4, labels = c("cat", "dog")),
                   jump_length = c(8.0, 7.9, 8.3, 9.1, 8.0, 7.8, 9.2, 7.7)) 

data_tbl %>% 
  kable(align = "c", "pipe")

mean_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean_animal = round(mean(jump_length), 1),
            var_animal = round(var(jump_length), 1))

mean_cat <- mean_tbl$mean_animal[1]
mean_dog <- mean_tbl$mean_animal[2]

```

Nehmen wir an, wir berechnen für die Sprungweite \[cm\] der Hundeflöhe einen Mittelwert von $\bar{y}_{dog} = `r mean_dog`$ und für die Sprungweite \[cm\] der Katzenflöhe einen Mittelwert von $\bar{y}_{cat} =`r mean_cat`$. Wie große ist nun der Effekt? Oder anders gesprochen, welchen Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu sein? Was ist also der Effekt von `animal`? Wir rechnen $\bar{y}_{dog} - \bar{y}_{cat} = 8.2 - 8.3 = -0.1$. Zum einen wissen wir jetzt "die Richtung". Da wir ein Minus vor dem Mittelwertsunterschied haben, müssen die Katzenflöhe weiter springen als die Hundeflöhe, nämlich 0.1 cm. Dennoch ist der Effekt sehr klein.

### Cohen's d

Da der Mittlwertsunterschied *alleine* nnur eine eingeschränkte Aussage über den Effekt erlaubt, gibt es noch Effektschätzer, die den Mittelwertsunterschied $\Delta_{y_1-y_2}$ mit der Streuung $s^2$ sowie der Fallzahl zusammenbringt. Der bekannteste Effektschätzer für einen Mittelwertsunterschied bei großer Fallzahl mit mehr als 20 Beobachtungen ist Cohen's d. Wir können Cohen's d wie folgt berechnen.

$$
|d| = \cfrac{\bar{y}_1-\bar{y}_2}{\sqrt{\cfrac{s_1^2+s_2^2}{2}}}
$$

Wenn wir die berechneten Mittelwerte und die Varianz der beiden Gruppen in die Formel einsetzten ergibt sich ein absolutes Cohen's d von 0.24 für den Gruppenvergleich.

$$
|d| = \cfrac{8.2 - 8.3}{\sqrt{(0.5^2+0.3^2) /2}} = \cfrac{-0.1}{0.41} = \lvert-0.24\rvert
$$

::: column-margin
Mehr Informationen zu Cohen's d gibt es auf der Hilfeseite von `effectsize`: [Interpret standardized differences](https://easystats.github.io/effectsize/reference/interpret_cohens_d.html)
:::

Was denn nun Cohen's d *exakt* aussagt, kann niemand sagen. Aber wir haben einen Wust an möglichen Grenzen. Hier soll die Grenzen von Cohen (1988) einmal angegeben werden. Cohen (1988) hat in seiner Arbeit folgende Grenzen in @tbl-cohen-d für die Interpretation von $d$ vorgeschlagen.

|     Cohen's d      | Interpretation des Effekts |
|:------------------:|:--------------------------:|
|     $d < 0.2$      |         Sehr klein         |
| $0.2 \leq d < 0.5$ |           Klein            |
| $0.5 \leq d < 0.8$ |           Mittel           |
|    $d \geq 0.8$    |           Stark            |

: Interpretation der Effektstärke nach Cohen (1988). {#tbl-cohen-d}

Wir können auch über die Funktion `cohens_d()` Cohen's d einfach in R berechnen. Die Funktion `cohens_d()` akzeptiert die Formelschreibweise. Die 95% Konfidenzintervalle sind mit Vorsicht zu interpretieren. Denn die Nullhypothese ist hier nicht so klar formuliert. Wir lassen also die 95% Konfidenzintervalle erstmal hier so stehen.

```{r}
cohens_d(jump_length ~ animal, data = data_tbl, pooled_sd = TRUE)
```

Dankenswerterweise gibt es noch die Funktion `interpret_cohens_d`, die es uns erlaubt auszusuchen nach welche Literturquelle wir den Wert von Cohen's d interpretieren wollen.

```{r}
interpret_cohens_d(0.24, rules = "cohen1988")
```

### Hedges' g

Soweit haben wir uns mit sehr großen Fallzahlen beschäftigt. Cohen's d ist dafür auch sehr gut geeigent und wenn wir mehr als 20 Beobachtungen haben, können wir Cohen's d auch gut anwenden. Wenn wir weniger Fallzahl vorliegen haben, dann können wir Hedges' g nutzen. Hedges' g bietet eine Verzerrungskorrektur für kleine Stichprobengrößen ($N < 20$) sowie die Möglichkeit auch für *unbalanzierte* Gruppengrößen einen Effektschätzeer zu berechnen. Die Formel sieht mit dem Korrekturterm recht mächtig aus.

$$
g = \cfrac{\bar{y}_1 - \bar{y}_2}{s^*} \cdot \left(\cfrac{N-3}{N-2.25}\right) \cdot \sqrt{\cfrac{N-2}{N}}
$$

mit

$$
s^* = \sqrt{\cfrac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}
$$

Wir können aber einfach die Mittelwerte und die Varianzen aus unserem beispiel einsetzen. Da unsere beiden Gruppen gleich groß sind $n_1 = n_2$ und damit ein balanziertes Design vorliegt, sind Cohen's d und Hedges' g numerisch gleich. Wir können dann noch für die geringe Fallzahl korrigieren und erhalten ein händisches $g = 0.18$.

$$
g = \cfrac{8.2 - 8.3}{0.41} \cdot \left(\cfrac{8-3}{8-2.25}\right) \cdot \sqrt{\cfrac{8-2}{8}} = \lvert-0.24\rvert \cdot 0.87 \cdot 0.87 \approx 0.18
$$

mit

$$
s^* = \sqrt{\cfrac{(4-1)\cdot0.5^2 + (4-1)\cdot0.3^2}{4+4-2}} = \sqrt{\cfrac{0.75 + 0.27}{6}} = 0.41
$$

In R gibt es die Funktion `hedges_g()` die usn erlaubt in der formelschreibweise direkt Hedges' g zu berechnen. Wir sehen hier eine Abweichung von unserer händischen Rechnung. Das ist aber in soweit nicht ungewöhnlich, da es noch eine Menge Varianten der Anpassung für die geringe Fallzahl gibt. In der Anwendung nutzen wir die Funktion aus dem Paket `effectsize` wie hier durchgeführt.

```{r}
hedges_g(jump_length ~ animal, data = data_tbl, pooled_sd = TRUE)
```

Auch für Hedges' g gibt es die Möglichkeit sich über die Funktion `interpret_hedges_g()` den Wert von $g=0.21$ interpretieren zu lassen.

```{r}
interpret_hedges_g(0.21, rules = "sawilowsky2009")
```

[Die Hilfeseite zu dem Paket `effectsize`](https://easystats.github.io/effectsize/reference/interpret_cohens_d.html) bietet eine Liste an möglichen Referenzen für die Wahl der Interpretation der Effektstärke.

## Unterschied zweier Anteile

[Eine Wahrscheinlichkeit und eine Change sind nicht das Gleiche. Mehr in diesem Abschnitt.]{.aside}

Neben den Unterschied zweier Mittelwerte ist auch häufig das Interesse an dem Unterschied zwischen zwei Wahrscheinlichkeiten oder auch Anteilen. Ebenso kann die Chance berechnet werden. Hier tritt häufig Verwirrung auf, daher hier zuerst ein Beispiel.

|           |             |                   |                   |
|:---------:|:-----------:|:-----------------:|:-----------------:|
|           |             |   **Infected**    |                   |
|           |             |     *Yes (1)*     |     *No (0)*      |
| **Group** | *Treatment* | $23_{\;\Large a}$ | $10_{\;\Large b}$ |
|           |  *Control*  | $18_{\;\Large c}$ | $14_{\;\Large d}$ |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei nach einer Behandlung mit *FleaEx* für die Berechnung von Effektschätzern eines Anteils. {#tbl-2x2-ratio-delta}

Aus der @tbl-2x2-ratio-delta können wir entnehmen, dass 23 behandelte Hunde mit Flöhen infiziert sind und 10 Hunde keine Infektion aufweisen. Bei den Hunden aus der Kontrolle haben wir 18 infizierte und 14 gesunde Tiere beobachtet.

Wir können nun zwei Arten von Anteilen berechnen. Das bekanntere ist die Frequenz oder Wahrscheinlichkeit oder Risk Ratio (RR). Das andere ist das Chancenverhältnis oder Odds Ratio (OR). Beide kommen in der Statistik vor und sind unterschiedlich zu interpretieren.

Um die die Odds Ratio und die Risk Ratios auch in R berechnen zu können müssen wir einmal die 2x2 Kreuzabelle in R nachbauen. Wir nutzen dafür die Funktion `matrix()` und müssen schauen, dass die Zaheln in der 2x2 Kreuztabelle in R dann auch so sind, wie in der Datentabelle.

```{r}
cross_mat <- matrix(c(23, 10, 18, 14),
  nrow = 2, byrow = TRUE,
  dimnames = list(
    Group = c("Treatment", "Control"),
    Infected = c("Yes", "No")
  )
)

cross_mat
```

### Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)

$$
Pr(\mbox{dog}|\mbox{infected}) = \cfrac{a}{a+c} = \cfrac{23}{23+10} \approx 0.67
$$

$$
Pr(\mbox{cat}|\mbox{infected}) = \cfrac{b}{b+d} = \cfrac{18}{18+14} \approx 0.56
$$

$$
\Delta_{y_1/y_2} = RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} =  \cfrac{0.67}{0.56} \approx 1.2 
$$

```{r}
oddsratio(cross_mat)
```

### Chancenverhältnis oder Odds Ratio (OR)

$$
Odds(\mbox{dog}|\mbox{infected}) = a:b = 23:10 = \cfrac{23}{10} = 2.3
$$

$$
Odds(\mbox{cat}|\mbox{infected}) = c:d = 18:14 = \cfrac{18}{14} \approx 1.29 
$$

$$
\Delta_{y_1/y_2} = OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = \cfrac{a \cdot d}{b \cdot c} = \cfrac{2.30}{1.29} \approx 1.78
$$

```{r}
riskratio(cross_mat)
```

Wann liegt nun kein Effekt bei einem Anteil wie dem RR oder OR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe. Dies gilt sowohl fürdas RR als auch das OR.

$$
H_0: RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} = 1
$$

$$
H_0: OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = 1
$$

::: callout-important
## Stärke eines Effektes

Du musst immer den Effekt, hier den Mittelwertsunterschied, im Kontext der Fragestellung bzw. des Outcomes $y$ bewerten. Der numerische Unterschied von 0,1cm kann in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein Unterschied von 0,1cm sehr viel sein. Oder aber sehr wenig, wenn wir uns das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage, ob ein Unterschied von 6% viel oder wenig ist...
:::
