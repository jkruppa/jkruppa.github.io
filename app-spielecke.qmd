```{r echo = FALSE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, performance, parameters,
               latex2exp, see, patchwork, mfp, multcomp, emmeans, janitor, effectsize,
               conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cb_pal <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
            "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- cb_pal
```

# Spielecke {#sec-spielecke}

*Letzte Änderung am `r format(fs::file_info("app-spielecke.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Denn, um es endlich auf einmal herauszusagen, der Mensch spielt nur, wo er in voller Bedeutung des Worts Mensch ist, und er ist nur da ganz Mensch, wo er spielt." --- Friedrich Schiller*

Dieses Kapitel ist *meine Spielecke*, wo ich Ideen und sonst so Zeug sammele, was mir über den Weg läuft und ich noch nicht so richtig weiter im Skript eingeordnet habe. Deshalb hat das hier auch keine Struktur, da mir die Gedanken eben auch noch wirr durch den Kopf geistern.

::: callout-tip
## Anwendungsbeispiel: Klinische Studien und das weibliche Geschlecht

In dem Buch [Eve: How the Female Body Drove 200 Million Years of Human Evolution](https://www.penguinrandomhouse.com/books/227568/eve-by-cat-bohannon/) von @miksanek2023eve
:::

## Delete me {.unnumbered}

```{r}
flea_dog_cat_tbl <- read_excel("data/flea_dog_cat.xlsx") |> 
  mutate(animal = as_factor(animal))
```

## Histogramm {.unnumbered}

Wozu nutzen wir das Histogramm? Wir brauchen das Histogramm um die Verteilung der Messwerte $y$ abzuschätzen. Daher wie sind unsere Sprungweiten, Anzahlen oder Gewichte unserer Hunde- und Katzenflöhe verteilt. Zuerst brauchen wir aber viele Beobachtungen. Wir brauchen für ein anständiges Histogramm, wo du auch was erkennen kannst, mindestens 20 Beobachtung *pro Gruppe*. Hier ist das *pro Gruppe* sehr wichtig. Zwar haben wir auch in unseren Hunde- und Katzenflohdaten vierzehn Beobachtungen, aber nur sieben pro Gruppe! Da können wir dann mit einem Histogramm nicht viel erkennen und dann nutzen wir den Boxplot für die Abschätzung der Verteilung. Häufig irritiert bei einem Histogramm auch, dass wir auf der x-Achse die Werte der y-Achse darstellen und dann auf der y-Achse des Histogramms die Anzahlen zählen. Aber dazu dann gleich mehr in den folgenden Tabs zur theoretischen Betrachtung, einem Beispiel und der Umsetzung in `{ggplot}`. Ein Hisogramm nutzen wir eigentlich in einer laufenden Analyse als ein statistisches Tool und berichten es eher selten.

::: panel-tabset
## Theoretisch

Für die Erstellung eines Histogramm müssen wir unterscheiden, ob wir als Outcome etwas zählbares vorliegen haben. Also ob unser Outcome Kategorien hat. Wir zählen die Anzahl an Haaren eines Flohbeins oder aber die Noten von Schülern. Wir können aber auch andere Kategorien vorliegen haben, aber es müssen schon ein paar sein. Mit ein paar meine ich dann mehr als fünf Kategorien. Ein Notenspiegel macht ja auch nur Sinn, da wir da gut zehn Notenschritte drin haben. Im Folgenden siehst du einmal eine Abbildung mit den Kategorien A bis I. Jetzt zählen wir wie oft kommt A vor, wie oft kommt B vor und so weiter. Die Anzahlen tragen wir dann als Balken ein. Dann haben wir die *absoluten* Anzahlen gezählt. Wenn wir aber Histogramme mit unterschiedlichen Beobachtungen vergleichen wollen, dann macht es mehr Sinn sich die *relativen* Häufigkeiten anzuschauen. In unserem Fall haben wir achtzehn Beobachtungen vorliegen, also bedeutet eine Beobachtung $1/18 = 0.055$ relativen Anteil.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-hist-drawn-01
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Histogramm von achtzehn Flöhen für einen kategorialen Endpunkt der Kategorien A bis I. Auf der linken Seite sind die absoluten Anzahlen dargestellt und auf der rechten Seite die entsprechenden relativen Häufigkeiten. *[Zum Vergrößern anklicken]*"


tibble(x = 0:10, y = c(0, 1, 3, 5, 4, 2, 2, 1, 0.5, 0, 0)) |> 
  ggplot(aes(x, y)) +
  theme_minimal() +
  ylim(0, NA) +
  xlim(0, NA) +
  geom_rect(aes(xmin = 0.55, xmax = 1.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 1.55, xmax = 2.45, ymin = 0, ymax = 3), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 2.55, xmax = 3.45, ymin = 0, ymax = 5), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 3.55, xmax = 4.45, ymin = 0, ymax = 4), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 4.55, xmax = 5.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 5.55, xmax = 6.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 6.55, xmax = 7.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  #geom_vline(xintercept = c(0, 10)) +
  geom_hline(yintercept = c(0, 1, 2, 3, 4, 5), color = "gray50") +
  scale_y_continuous(name = "Absolute Anzahl",
                     sec.axis = sec_axis(~ ., name = "Relative Häufigkeit",
                                         breaks = c(0, 1, 2, 3, 4, 5), 
                                         labels = c("0%", "5.5%", "11.1%", "16.6%", "22%.2", "27.7%")),
                     limits = c(0, NA)) +
  scale_x_continuous(name = "", breaks = 1:9, limits = c(0, NA),
                     labels = LETTERS[1:9]) +
  ggtitle("Kategorial")  +
  theme(legend.position = "none",
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  annotate("label", x = 6.2, y = 2.5, label = "2 Beobachtungen\nder Kategorie E",
           size = 5, color = "#009E73", hjust = "left") +
  geom_curve(x = 6.1, y = 2.5, xend = 5, yend = 2.1, linewidth = 0.5,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = 0.3, alpha = 0.3, color = "#009E73") 

```

Wenn wir keine Kategorien vorliegen haben, dann müssen wir uns für unser Outcome welche Überlegen. Das heißt wir nutzen das so genannte *bining* (deu. *eindosen*, ungebräuchlich). Wenn du das Gewicht von Flöhen misst, dann hast du Kommazahlen und damit kontinuierliche Daten vorliegen. Damit unterscheiden sich alle deine Messwerte vermutlich. Deshalb fasst du "gleiche" Werte zusammen. Meistens machen wir das, indem wir Beobachtungen in zwischen zwei Zahlen als eine Kategorie zählen. Wie da die Grenzen liegen, ist immer unterschiedlich und hängt von der Fragestellung ab.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-hist-drawn-02
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Histogramm von achtzehn Flöhen für einen kontinuierlichen Endpunkt. Ein Balken entspricht immer einem Zahlenraum entsprechend der x-Achse. Auf der linken Seite sind die absoluten Anzahlen dargestellt und auf der rechten Seite die entsprechenden relativen Häufigkeiten. *[Zum Vergrößern anklicken]*"


tibble(x = 0:10, y = c(0, 1, 3, 5, 4, 2, 2, 1, 0.5, 0, 0)) |> 
  ggplot(aes(x, y)) +
  theme_minimal() +
  ylim(0, NA) +
  xlim(0, NA) +
  geom_rect(aes(xmin = 0.55, xmax = 1.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 1.55, xmax = 2.45, ymin = 0, ymax = 3), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 2.55, xmax = 3.45, ymin = 0, ymax = 5), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 3.55, xmax = 4.45, ymin = 0, ymax = 4), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 4.55, xmax = 5.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 5.55, xmax = 6.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 6.55, xmax = 7.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_hline(yintercept = c(0, 1, 2, 3, 4, 5), color = "gray50") +
  scale_y_continuous(name = "Absolute Anzahl",
                     sec.axis = sec_axis(~ ., name = "Relative Häufigkeit",
                                         breaks = c(0, 1, 2, 3, 4, 5), 
                                         labels = c("0%", "5.5%", "11.1%", "16.6%", "22%.2", "27.7%")),
                     limits = c(0, NA)) +
  scale_x_continuous(name = "", breaks = 1:9, 
                     limits = c(0, NA), 
                     labels = c("(1,2]", "(2,3]", "(3,4]", "(4,5]", "(5,6]",
                                "(6,7]", "(7,8]", "(8,9]", "(9,10]")) +
  ggtitle("Kontinuierlich") +
  theme(legend.position = "none",
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  annotate("label", x = 6.2, y = 2.5, label = "2 Beobachtungen\nzwischen >5 und \u22646",
           size = 5, color = "#009E73", hjust = "left") +
  geom_curve(x = 6.1, y = 2.5, xend = 5, yend = 2.1, linewidth = 0.5,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = 0.3, alpha = 0.3, color = "#009E73") 

```

## Händisch

Betrachten wir einmal die Erstellung eine Histogramms für einen Endpunkt mit Kategorien. Dafür habe ich mir einmal die Boniturnoten für achtzehn Hundeflöhe in der folgenden Tabelle ausgedacht. Wir brauchen eben mehr Daten als wir in den ursprünglichen Hunde- und Katzenflohdaten vorliegen haben. Jetzt wollen wir uns einmal die Verteilung der Boniturnoten anschauen.

```{r}
#| echo: false
#| label: tbl-hist-cat-flea-grade
#| tbl-cap: "Die Boniturnote von achtzehn Hundeflöhen."

c(1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6, 6, 7) |> sample() |>  
  matrix(nrow = 1) |> 
  kable()
```

In der folgenden Abbildung siehst du einmal die Verteilung der achtzehn Boniturnoten der Hundeflöhe dargestellt. Wir sehen sofort, dass wir am meisten die Note 3 vergeben haben. Wir haben nämlich fünfmal die Note 3 an unseren Flöhen festgestellt. Die Boniturnote 5 haben wir dann an zwei Flöhen erhoben. Da wir achtzehn Flöhe haben, entspricht jede Anzahl dann $5.5%$ auf der relativen Skala.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-hist-drawn-04
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Histogramm von achtzehn Flöhen für die Boniturnoten als kategorialen Endpunkt. *[Zum Vergrößern anklicken]*"


tibble(x = 0:10, y = c(0, 1, 3, 5, 4, 2, 2, 1, 0.5, 0, 0)) |> 
  ggplot(aes(x, y)) +
  theme_minimal() +
  ylim(0, NA) +
  xlim(0, NA) +
  geom_rect(aes(xmin = 0.55, xmax = 1.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 1.55, xmax = 2.45, ymin = 0, ymax = 3), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 2.55, xmax = 3.45, ymin = 0, ymax = 5), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 3.55, xmax = 4.45, ymin = 0, ymax = 4), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 4.55, xmax = 5.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 5.55, xmax = 6.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 6.55, xmax = 7.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  #geom_vline(xintercept = c(0, 10)) +
  geom_hline(yintercept = c(0, 1, 2, 3, 4, 5), color = "gray50") +
  scale_y_continuous(name = "Absolute Anzahl",
                     sec.axis = sec_axis(~ ., name = "Relative Häufigkeit",
                                         breaks = c(0, 1, 2, 3, 4, 5), 
                                         labels = c("0%", "5.5%", "11.1%", "16.6%", "22%.2", "27.7%")),
                     limits = c(0, NA)) +
  scale_x_continuous(name = "Boniturnote", breaks = 1:9, limits = c(0, NA),
                     labels = 1:9) +
  ggtitle("Kategorial")  +
  theme(legend.position = "none",
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  annotate("label", x = 6.2, y = 2.5, label = "2 Beobachtungen\nder Boniturnote 5",
           size = 5, color = "#009E73", hjust = "left") +
  geom_curve(x = 6.1, y = 2.5, xend = 5, yend = 2.1, linewidth = 0.5,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = 0.3, alpha = 0.3, color = "#009E73") 

```

Schauen wir uns im zweiten Beispiel einmal das Gewicht von achtzehn Hundeflöhen an. Hier siehst du, dass wir Kommazahlen also kontinuierliche Daten vorliegen haben. Keine der Zahlen ist doppelt, so dass wir hier dann keine Balken hochzählen können. Damit wir das aber können, bilden wir Zahlenräume in denen wir die Gewichte zusammenfassen.

```{r}
#| echo: false
#| label: tbl-hist-cont-flea-weight
#| tbl-cap: "Das Gewicht in [mg] von achtzehn Hundeflöhen."

c(0.7, 1.7, 2.0, 2.1, 2.7, 2.8, 3.0, 3.1, 3.3,
  3.8, 4.0, 4.1, 4.3, 4.9, 5.2, 5.9, 6.1, 7.4) |> 
  sample() |> 
  matrix(nrow = 1) |> 
  kable()
```

In der folgenden Abbildung siehst du einmal die Zusammenfassung unserer Flohgewichte in die Zahlenräume der Größe $1mg$. Gewichte, die in den Bereich $x \pm 0.5$ fallen, werden dann in einem Balken zusammengefasst. Wir haben zum Beispiel in dem Bereich mit $x = 2$ und somit $2 \pm 0.5$ dann die drei Werte 1.7, 2.0 und 2.1 vorliegen. Wir zeichnen einen Balken der Höhe drei. Ebenso haben wir in dem Bereich $5.5 < x \leq 6.5$ zwei Beobachtungen vorliegen. Wir zeichnen hier einen Balken der Höhe zwei. Die Entscheidung wie weit der Zahlenraum zum zusammenfassen reichen soll, ist meist ein Ausprobieren. Das ist natürlich bei der händischen Erstellung problematisch.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-hist-drawn-03
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "Histogramm von achtzehn Flöhen für das Gewicht als kontinuierlichen Endpunkt. *[Zum Vergrößern anklicken]*"


tibble(x = 0:10, y = c(0, 1, 3, 5, 4, 2, 2, 1, 0.5, 0, 0)) |> 
  ggplot(aes(x, y)) +
  theme_minimal() +
  ylim(0, NA) +
  xlim(0, NA) +
  geom_rect(aes(xmin = 0.55, xmax = 1.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 1.55, xmax = 2.45, ymin = 0, ymax = 3), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 2.55, xmax = 3.45, ymin = 0, ymax = 5), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 3.55, xmax = 4.45, ymin = 0, ymax = 4), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 4.55, xmax = 5.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 5.55, xmax = 6.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 6.55, xmax = 7.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_vline(xintercept = c(0.7, 1.7, 2.0, 2.1, 2.7, 2.8, 3.0, 3.1, 3.3,
                            3.8, 4.0, 4.1, 4.3, 4.9, 5.2, 5.9, 6.1, 7.4),
             color = "#D55E00") +
  geom_hline(yintercept = c(0, 1, 2, 3, 4, 5), color = "gray50") +
  scale_y_continuous(name = "Absolute Anzahl",
                     sec.axis = sec_axis(~ ., name = "Relative Häufigkeit",
                                         breaks = c(0, 1, 2, 3, 4, 5), 
                                         labels = c("0%", "5.5%", "11.1%", "16.6%", "22%.2", "27.7%")),
                     limits = c(0, NA)) +
  scale_x_continuous(name = "Gewicht [mg]", breaks = c(0.7, 1.7, 2.0, 2.1, 2.7, 2.8, 3.0, 3.1, 3.3,
                            3.8, 4.0, 4.1, 4.3, 4.9, 5.2, 5.9, 6.1, 7.4), 
                     limits = c(0, NA),
                     guide = guide_axis(n.dodge=3)) +
  ggtitle("Kontinuierlich") +
  theme(legend.position = "none",
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  annotate("label", x = 6.2, y = 2.5, label = "2 Flöhe zwischen\n>5.5mg und \u22646.5mg",
           size = 5, color = "#009E73", hjust = "left") +
  geom_curve(x = 6.1, y = 2.5, xend = 5, yend = 2.1, linewidth = 0.5,
             arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
             curvature = 0.3, alpha = 0.3, color = "#009E73") 

```

## `{ggplot}`

Für die Erstellung eines Histogramms mit `{ggplot}` nutzen wir unsere Spieldaten aus dem Tab zur händischen Erstellung eines Histogramms. Nun schauen wir uns jetzt einmal achtzehn Hundflöhe an und bestimmen die Boniturnote, dargestellt in der Spalte `grade`. Darüber hinaus bestimmen wir auch noch das mittlere Gewicht der Flöhe auf dem jeweiligen Hund, dargestellt in der Spalte `weight`.

```{r}
#| echo: true
#| message: false
flea_hist_tbl <- tibble(grade = c(1, 2, 2, 2, 3, 3, 3, 3, 3, 
                                  4, 4, 4, 4, 5, 5, 6, 6, 7),
                        weight = c(0.7, 1.7, 2.0, 2.1, 2.7, 
                                   2.8, 3.0, 3.1, 3.3, 3.8, 
                                   4.0, 4.1, 4.3, 4.9, 5.2, 
                                   5.9, 6.1, 7.4))
```

In `{ggplot}` können wir ein Histogramm mit der Funktion `geom_histogram()` erstellen. Dabei ist es dann immer etwas verwirrend, dass wir unser Outcome als $y$ dann auf der x-Achse darstellen. Wir können die Option `binwidth` nutzen, um zu entscheiden, wie viele Noten in einem Balken zusammengefasst werden sollen. Sinnvoll ist natürlich hier eine `binwidth` von 1, da wir pro Balken eine Boniturnote zählen wollen.

```{r}
#| echo: true
#| message: false
#| label: fig-hist-flea-count
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Histogramm der Boniturnoten von achtzehn Hundeflöhen. *[Zum Vergrößern anklicken]*"

ggplot(data = flea_hist_tbl, aes(x = grade)) +
  geom_histogram(binwidth = 1, fill = "gray", color = "black") +
  theme_minimal() +
  labs(x = "Boniturnote", y = "Anzahl") 
```

Anders sieht es für kontinuierliche Variablen mit Kommazahlen aus. Schauen wir uns das Gewicht der Flöhe an, so sehen wir, dass es sehr viele Zahlen gibt, die nur einmal vorkommen. Hier können wir dann mit `binwidth` den Bereich einstellen, in denen die Zahlen fallen sollen. Auch hier ist es immer ein Gefummel, wenn wir zu wenige Beobachtungen vorliegen haben. Die beste Bandbreite für die Balken zu finden, ist immer ein Ausprobieren.

```{r}
#| echo: true
#| message: false
#| label: fig-hist-flea-1
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Histogramm des Gewichts von achtzehn Hundeflöhen. *[Zum Vergrößern anklicken]*"

ggplot(data = flea_hist_tbl, aes(x = weight)) +
  geom_histogram(binwidth = 1, fill = "gray", color = "black") +
  theme_minimal() +
  labs(x = "Gewicht [mg]", y = "Anzahl") 
```
:::

### Density Plot

Eine weitere Möglichkeit sich eine Verteilung anzuschauen, ist die Daten nicht als Balkendiagramm sondern als Densityplot - also Dichteverteilung - anzusehen. Im Prinzip verwandeln wir die Balken in eine Kurve. Damit würden wir im Prinzip unterschiedliche Balkenhöhen ausgleichen und eine "glattere" Darstellung erreichen. Wir wir aber gleich sehen werden, benötigen wir dazu eine Menge an Beobachtungen und auch dann ist das Ergebnis eventuell nicht gut zu interpretieren. Eine händsiche Darstellung ist nicht möglich, wir machen Dichteverteilungen nur in R aber nicht selber auf einem Blattpapier.

::: panel-tabset
## Theoretisch

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-density-drawn-01
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"


tibble(x = 0:10, y = c(0.1, 1, 3, 5, 4, 2, 2, 1, 0.5, 0.1, 0.1)) |> 
  ggplot(aes(x, y)) +
  theme_minimal() +
  ylim(0, NA) +
  xlim(0, NA) +
  geom_rect(aes(xmin = 0.55, xmax = 1.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 1.55, xmax = 2.45, ymin = 0, ymax = 3), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 2.55, xmax = 3.45, ymin = 0, ymax = 5), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 3.55, xmax = 4.45, ymin = 0, ymax = 4), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 4.55, xmax = 5.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 5.55, xmax = 6.45, ymin = 0, ymax = 2), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_rect(aes(xmin = 6.55, xmax = 7.45, ymin = 0, ymax = 1), fill = "gray80",
            color = "black", linewidth = 0.5) +
  geom_vline(xintercept = c(0)) +
  geom_hline(yintercept = 0) +
  scale_y_continuous(name = "Dichte",
                     limits = c(0, NA)) +
  scale_x_continuous(name = "", breaks = 0:9, limits = c(0, NA)) +
  stat_smooth(aes(x, y), method = "lm",
              formula = y ~ poly(x, 5), se = FALSE, geom = "area", alpha = 0.3,
              fill = "#CC79A7", color = "#CC79A7") +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 

```

## `{ggplot}`

```{r }
#| echo: true
#| message: false
#| label: fig-dens-flea-1
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Densityplot der Boniturnote und des Gewichts von achtzehn Hundeflöhen. **(A)** Boniturnote **(B)** Gewicht. *[Zum Vergrößern anklicken]*"


p1 <- ggplot(data = flea_hist_tbl, aes(x = grade)) +
  geom_density(fill = "#CC79A7", color = "#CC79A7", alpha = 0.3) +
  theme_minimal() +
  labs(x = "Boniturnote", y = "Dichte")

p2 <- ggplot(data = flea_hist_tbl, aes(x = weight)) +
  geom_density(fill = "#CC79A7", color = "#CC79A7", alpha = 0.3) +
  theme_minimal() +
  labs(x = "Gewicht [mg]", y = "Dichte") 

p1 + p2 + 
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A')
```
:::

@fig-dens-flea-1 zeigt auf der linken Seite erneut die Abbildung des Histogramms als Balkendiagramm für die Anzahl der Flöhe auf den 39 Hunden. Auf der rechten Seite die entsprechenden gleichen Daten als Denistyplot. Klar ist die Wellenbewegung des Densityplots zu erkennen. Hier liegen zu wenige Beobachtungen und Kategorien auf der x-Achse vor, so dass der Densityplot nicht zu empfehlen ist.

::: {.callout-note appearance="simple" collapse="true"}
## Generieren eines Avatars

Wir wollen uns in der Vorlesung einen Avatar generieren, der uns begleitet und das ein oder andere Abenteuer mit Daten zu erleben hat. Dann können wir uns noch ein Bild vom Avatar machen mit dem [Avataaars Generator](https://getavataaars.com). Wir beantworten gemeinsam folgende Fragen über den Avatar $X$ in der Vorlesung.

-   Nenne einen Namen für $X$!
-   Nenne ein Alter für $X$!
-   Benenne woher $X$ kommt!
-   Benenne womit $X$ innerlich zu kämpfen hat?
-   Benenne ein Vorbild von $X$! Wenn bewundert $X$?
-   Benenne ein biographisches Ereignis im Leben von $X$!
-   Wie würden Freund:innen $X$ beschreiben?
-   Warum studiert $X$?
-   Wo möchte $X$ im Leben hin?
-   Wovor hat $X$ Angst?
-   Wer oder was hat $X$ besonders geprägt und warum?
-   Benenne einen Beziehungsstatus für $X$!
-   Benenne ein Lieblingstier von $X$!
:::

## Offene Ideen & Wartungsarbeiten {.unnumbered}

> *"The days can be easy if the years are consistent. You can write a book or get in shape or code a piece of software in 30 minutes per day. But the key is you can't miss a bunch of days." --- James Clear*

Was tippe ich gerade zur Zeit und welche Baustellen sind hier im Buch gerade offen? Im Folgenden einmal eine lose Liste an Themen und Fragmenten, die ich noch integrieren möchte. Die dargestellte Reihenfolge ist nicht die Reihenfolge in der ich an den Texten arbeite. Auch schaffe ich meistens nichts alles in ein paar Tagen. Daher handelt es sich nur um einen groben Überblick und eine Rückversicherung für mich, was ich noch offen habe. Teilweise ziemlich lange...

-   [Permutationstest & Bootstraping mit Bootstraping ergänzen.](#sec-permut)
-   [Modellieren in R als Einstiegskapitel erstellen](#sec-modeling-R) und dabei die Überarbeitung der statistischen Modellierungskapitel und Abbildungen ergänzen
-   [Räumliche Daten](#sec-spatial-data)
-   [Metaanalysen](#sec-meta)
-   Das R Paket `{infer}` passend ergänzen
-   [Marginal Models und `{emmeans}` mit mehr Theorie](#sec-posthoc)
-   Maximum Likelihood als Methode ergänzen
-   [Ideen zu Frauen in der Statistik erarbeiten](#sec-programming-preface)
-   Handzeichnungen in theoretische Statistik durch `{ggplot}` ersetzen.

Folgende allgemeine Wartungs- und Qualitätsarbeiten müssen noch durchgeführt werden. Da diese immer etwas nervig sind, dauert es meistens noch länger, bis ich hier fertig werde.

i)  Zitate zu den Kapiteln ergänzen und sinnvoll anpassen.
ii) Zitate und Quellen für wissenschaftliche Veröffentlichungen ergänzen.
iii) Rechtschreibung und Grammatik systematisch überprüfen.
iv) `{patchwork}` also Ersatz für `column: page`
v)  Global Abbildungen ohne sichtbaren Code aufhübschen.

## Links {.unnumbered}

[R Library Contrast Coding Systems for categorical variables](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

[An Introduction to emojifont package](https://cran.r-project.org/web/packages/emojifont/vignettes/emojifont.html)

[Emoji Unicode Tables](https://apps.timwhitlock.info/emoji/tables/unicode)

[emo(ji)](https://github.com/hadley/emo)

[AnAge Database of Animal Ageing and Longevity](https://genomics.senescence.info/species/index.html)

```{r}
#| warning: false
#| message: false
anage_tbl <- read_delim("data/anage_data.txt", delim = "\t")
```

```{r}
#| warning: false
#| message: false
die_risk_tbl <- tibble(age = c(25, 60, 80, 100, 108),
                       risk = c(0.1, 1, 6, 16, 50))

fit_nls <- nls(risk ~ b0 + I(b1^(age)), data = die_risk_tbl, 
           start = c(b0 = 1, b1 = 1))

hand_func <- \(x) {-5 + 1.037^(x * 0.97)}


ggplot(die_risk_tbl, aes(age, risk)) +
  theme_minimal() +
  geom_point() +
  geom_line(aes(y = predict(fit_nls)), size = 1, color = "#CC79A7") +
  geom_function(fun = hand_func, color = "#009E73", size = 1,
                xlim = c(25, 110)) 

```

Area under the curve larger than 1?

Why We Die: And How We Live: The New Science of Ageing and Longevity

[Here's Waldo: Computing the optimal search strategy for finding Waldo](https://randalolson.com/2015/02/03/heres-waldo-computing-the-optimal-search-strategy-for-finding-waldo/)

[Waldbrände und Dürren: Wie Korkeichen in Portugal den Klimawandel stoppen sollen](https://www.spiegel.de/ausland/waldbraende-und-duerren-wie-korkeichen-in-portugal-den-klimawandel-stoppen-sollen-a-db859f6d-2300-4b43-874c-ae239b76bd43)

[Stock assessment models overstate sustainability of the world’s fisheries](https://www.science.org/doi/10.1126/science.adl6282) and [Modelling seasonal data with GAMs](https://fromthebottomoftheheap.net/2014/05/09/modelling-seasonal-data-with-gam/)

[Karnickelsterben nun auch in Bremen](https://taz.de/Das-Ende-der-Plage/!6027222/)

[Jagd in Niedersachsen](https://www.ml.niedersachsen.de/startseite/themen/wald_holz_jagd/jagd_in_niedersachsen/jagd-in-niedersachsen-5138.html)

[Ein Kind meiner Zeit](https://www.republik.ch/2024/06/19/ein-kind-meiner-zeit) [Galenus von Pergamon - Leben und Werk](https://robl.de/galen/galen.htm)

[I Will Fucking Piledrive You If You Mention AI Again](https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/)

[Plötzlich sah ich den entscheidenden Graphen](https://www.zeit.de/2024/27/klimaforschung-ozean-klimawandel-umwelt-nachhaltigkeit)

> Amoc sind riesige Wasserzirkulationen im Ozean, zu denen auch der Golfstrom gehört. Sie sorgen dafür, dass wir in Europa mildes Klima haben. Wenn dieses System zusammenbricht, würde es in den Niederlanden oder Deutschland etwa zehn bis zwanzig Grad kälter werden.

[Atmospheric Response to a Collapse of the North Atlantic](https://gmao.gsfc.nasa.gov/gmaoftp/corbe/AMOC/orbe245_revision1.pdf)

[Atlantic meridional overturning circulation](https://en.wikipedia.org/wiki/Atlantic_meridional_overturning_circulation)

[The 2,500-Year-Old History of Adults Blaming the Younger Generation](https://historyhustle.com/2500-years-of-people-complaining-about-the-younger-generation/)

## Paper Ideen {.unnumbered}

Beide Paper dann mit den jeweiligen FAOSTAT Suchen verbinden.

[Food and agriculture data](https://www.fao.org/faostat/en/#home)

Mit dem [R Paket `{FAOSTAT}`](https://cran.r-hub.io/web/packages/FAOSTAT/) und der Vignette [FAOSTAT: Download Data from the FAOSTAT Database](https://cran.r-hub.io/web/packages/FAOSTAT/vignettes/FAOSTAT.pdf)

Tierpaper

-   [Arginine Nutrition in Neonatal Pigs](https://www.sciencedirect.com/science/article/pii/S0022316623031279)
-   [Fiber effects in nutrition and gut health in pigs](https://link.springer.com/article/10.1186/2049-1891-5-15)
-   [Phosphorus nutrition of growing pigs](https://www.sciencedirect.com/science/article/pii/S2405654522000373)
-   [Implications of sorghum in broiler chicken nutrition](https://www.sciencedirect.com/science/article/pii/S0377840110000209)
-   [Proposed bursa of fabricius weight to body weight ratio standard in commercial broilers](https://www.sciencedirect.com/science/article/pii/S0032579119322448)
-   [Growth, efficiency, and yield of commercial broilers from 1957, 1978, and 2005](https://www.sciencedirect.com/science/article/pii/S0032579119385505)

Pflanzenpaper

-   [Hoverfly pollination enhances yield and fruit quality in mango under protected cultivation](https://www.sciencedirect.com/science/article/pii/S0304423822004411)
-   [Plant Growth, Yield, and Fruit Size Improvements in ‘Alicia’ Papaya Multiplied by Grafting](https://www.mdpi.com/2223-7747/12/5/1189)
-   [Growth, yield, plant quality and nutrition of basil (Ocimum basilicum L.) under soilless agricultural systems](https://www.sciencedirect.com/science/article/pii/S0570178316300288)
-   [Growing Hardier Crops for Better Health: Salinity Tolerance and the Nutritional Value of Broccoli](https://pubs.acs.org/doi/full/10.1021/jf802994p)
-   [Influence of Light Intensity and Spectrum on Duckweed Growth and Proteins in a Small-Scale, Re-Circulating Indoor Vertical Farm](https://www.mdpi.com/2223-7747/11/8/1010)

## Zitate {.unnumbered}

Copycat

> *"" ---*

------------------------------------------------------------------------

> *"The 'C' students run the world" --- [Harry Truman](https://www.stormrake.com/blogs/post/the-world-is-run-by-c-students)*

> *"Nobody belongs anywhere, nobody exists on purpose, everybody's going to die." --- [Rick and Morty](https://www.youtube.com/watch?v=E_qvy82U4RE)*

> *"To celebrate the noun do the verb." --- [Ryan Holiyday](https://www.youtube.com/shorts/zvJozTZo18o)*

> *"The formulation of a problem is often more essential than its solution, which may be merely a matter of mathematical or experimental skill. To raise new questions, new possibilities, to regard old problems from a new angle requires creative imagination and marks real advances in science" --- Albert Einstein*

> *"The whole world is a very narrow bridge and the main thing is to have no fear at all." --- [Kol Ha'Olam Kulo](https://jwa.org/media/lyrics-to-kol-haolam-kulo)*

> *"Frei ist, wer missfallen kann." --- Annette Oschmann in [Mädchen stärken](https://www.annette-oschmann.de/maedchen-staerken/)*

> *"The graveyard is full of 'irreplaceable' and important people." --- Charles De Gaulle [and others](https://quoteinvestigator.com/2011/11/21/graveyards-full/)*

> *"20 years from now, the only people who will remember that you worked late are your kids." --- David Clarke on [r/antiwork](https://www.reddit.com/r/antiwork/comments/12uz90c/psa_20_years_from_now_the_only_people_who_will/?rdt=47059)*

> *"You have to finish things — that's what you learn from, you learn by finishing things." --- Neil Gaiman in Advice to Aspiring Writers*

> *"I never once failed at making a light bulb. I just found out 99 ways not to make one." --- Thomas A. Edison*

> *"Leben heißt leiden, überleben heißt, im Leiden einen Sinn finden." --- Friedrich Nietzsche*

> *"Wachstum ist nicht alles, das ist wahr. Aber ohne Wachstum ist alles nichts." --- Angela Merkel*

> *"Competition is for losers!" --- Peter Thiel*

> *"Das Pferd frisst keinen Gurkensalat" --- Philipp Reis erster 1981 telefonisch übertragende Satz*

> *"One glance at a book and you hear the voice of another person perhaps someone dead for thousands of years. Across the millennia the author is speaking clearly and silently inside your head, directly to YOU." --- Carl Sagan*

> *"If you feel safe in the area that you're working in, you're not working in the right area. Always go a little further into the water than you feel you're capable of being in. Go a little bit out of your depth, and when you don't feel that your feet are quite touching the bottom, you're just about in the right place to do something exciting." -- David Bowie*

> *"(1) Alles was es schon gab, als Du geboren wurdest, ist normal und gewöhnlich. Diese Dinge werden als natürlich wahrgenommen und halten die Welt am Laufen. (2) Alles was zwischen Deinem 16ten und 36ten Lebensjahr erfunden wird ist neu, aufregend und revoltionär. Und vermutlich kannst Du in dem Bereich sogar Karriere machen. (3) Alles was nach dem 36ten Lebensjahr erfunden wird ist gegen die natürliche Ordnung der Dinge." --- Douglas Adams, Per Anhalter durch die Galaxis*

> *"Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it." --- Brian Kernighan, professor at Princeton University.*

> *"The three stages of career development are: 1. I want to be in the meeting; 2. I want to run the meeting; 3. I want to avoid meetings." --- Jay Ferro*

> *"Freude ist ein Akt des Trotzes. Mit Freude gewinnen wir, auch wenn wir verlieren. Gut gelebt zu haben ist alles was uns bleibt, denn sterben müssen wir alle." --- Jaghatai Khan, The Lost and the Damned*

> *"Freude ist ein Akt des Trotzes. Durch sie gewinnen wir, auch wenn wir verlieren. Denn sterben müssen wir alle und ein schönes Leben ist alles was uns bleibt." --- Jaghatai Khan, The Lost and the Damned*

> *"\[Alice Munro\] habe sich, erzählte sie einmal, die Sätze ihrer Erzählungen jeweils beim Kartoffelschälen ausgedacht und diese, während die Kartoffeln kochten, zwischendurch im Wohnzimmer notiert." --- [Alice Munro & Die Kunst des Nebenbeischreibens](https://www.zeit.de/kultur/literatur/2024-05/alice-munro-schriftstellerin-nobelpreis-nachruf)*

> *"Gott würfelt nicht!" --- Albert Einstein*

## Korrelation {.unnumbered}

[How does Polychoric Correlation Work? (aka Ordinal-to-Ordinal correlation)](https://www.r-bloggers.com/2021/02/how-does-polychoric-correlation-work-aka-ordinal-to-ordinal-correlation/)

[An Alternative to the Correlation Coefficient That Works For Numeric and Categorical Variables](https://rviews.rstudio.com/2021/04/15/an-alternative-to-the-correlation-coefficient-that-works-for-numeric-and-categorical-variables/)

## Pakete, die ich mal anschauen will... {.unnumbered}

[R Paket `{ggdist}`](https://mjskay.github.io/ggdist/index.html)

Das R Paket `{visibly}` auf [An Introduction to Visibly](https://m-clark.github.io/visibly/articles/intro.html)

[R Paket `{innsight}`](https://github.com/bips-hb/innsight)

[`{snakecase}`](https://tazinho.github.io/snakecase/)

[`{visdat}`](https://docs.ropensci.org/visdat/)

[Make an R Cheat Sheet](https://biol355.github.io/midterm/midterm.html)

[`{vroom}`](https://vroom.r-lib.org/)

[`{gt}`](https://github.com/rstudio/gt)

## Learning text {.unnumbered}

Wachsamkeit und Konzentration kann ein Mensch nur für 90 Minuten halten. Selbst dann ist Aufmerksamkeit ein Flackern von höherer und niedrigerer Intensität. Danach muss der Mensch 1-2 Stunden lang wirklich ruhen, bevor er wieder sehr hart arbeiten & lernen kann.

Folgende Dinge, die innerhalb von 4 Stunden nach diesen 90-minütigen Lerneinheiten durchgeführt werden, beschleunigen das Lernen.

-   Kurzes Nickerchen
-   Nichtschlafende tiefe Ruhe (NSDR)
-   Yoga Nidra
-   Formen der Meditation, die nicht viel fokussierte Konzentration erfordern,

Folgende Dinge helfen während der Lernphase das Lernen zu verstärken und zu festigen. Der Hippocampus wiederholt während dieser Zeit die Informationen mit 20-facher Geschwindigkeit und beschleunigt das Lernen und das Behalten der neu gelernten Informationen.

-   Mache ab und zu 10 Sekunden Pause vom Lernen, in denen du absolut nichts tust
-   Mache den Kopf frei (Lückeneffekt/Mikropausen),
-   Inkrementelles Lernen. Du kannst das Lernen in kleine, konzentrierte Einheiten aufteilen.
-   Stelle dir einen Timer für 3 Minuten ein, schalte das Telefon aus und verbringe die 3 Minuten damit, eine Sache intensiv zu lernen, auch wenn es sich anfühlt, als würde es aktuell nichts bringen.
-   Wenn du das wiederholt tust, können diese kleinen Schritte des Lernens zu einer übergroßen Menge des Lernens insgesamt führen.

[How to Learn Anything You Want \| Andrew Huberman](https://youtu.be/8oyA-ctqq3g)

## Weitere Datenquellen {.unnumbered}

[Food and agriculture data](https://www.fao.org/faostat/en/#home)

Mit dem [R Paket `{FAOSTAT}`](https://cran.r-hub.io/web/packages/FAOSTAT/) und der Vignette [FAOSTAT: Download Data from the FAOSTAT Database](https://cran.r-hub.io/web/packages/FAOSTAT/vignettes/FAOSTAT.pdf)

```{r}
#| eval: false


```

Mit dem [R Paket `{owidR}`](https://cran.r-project.org/web/packages/owidR/index.html) haben wir auch eine Möglichkeit direkt auf die Datenbank von [Our World in Data](https://ourworldindata.org/) zuzugreifen.

```{r}
#| eval: false

library(owidR)
foo <- owid_search("annual") 
owid("annual-co2-emissions-by-region")
owid(foo[3])
```

Eine wunderbare Sammlung von Datensätzen aus dem Bereich der Agarwissenschaften liefert das R Paket `{agridat}`. Über die Hilfeseite [agridat: Agricultural Datasets](https://cran.r-project.org/web/packages/agridat/index.html) findest du dann einmal einen gesamten Überblick und auch die Informationen über einige ausgewählte Datensätze aus Dutzenden von Datensätzen. Alle Datensätze der wichtigen Bücher zu dem experimentellen Designs sind dort eigentlich enthalten und einmal kuratiert.

Hier noch der Link zu [agridat - Datensätze mit Abbildungen in `{desplot}`](https://kwstat.github.io/agridat/reference/index.html). Du musst dann auf die jeweiligen Datensätze in der Liste klicken und dann kommst du zu dem Datensatz mit mehr Details sowie meistens auch einer Abbildung in `desplot`.

## Marginal effects {.unnumbered}

[Marginal Effects Zoo](https://marginaleffects.com)

[R Paket `{marginaleffects}`](https://marginaleffects.com)

[Marginal and conditional effects for GLMMs with `{marginaleffects}`](https://www.andrewheiss.com/blog/2022/11/29/conditional-marginal-marginaleffects/)

[Marginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are](https://www.andrewheiss.com/blog/2022/05/20/marginalia/#what-about-marginal-things-in-statistics)

## Latent Class Analysis {.unnumbered}

Wie immer gibt es eine Reihe von Tutorien auf denen dieser Abschnitt aufbaut. Zum einen wirf einfach mal einen Blick in das Tutorium [Latent Class Analysis Using R](https://pop.princeton.edu/events/2020/latent-class-analysis-using-r). Eine leider etwas veraltete Übersicht über mögliche R Pakete liefert [Ways to do Latent Class Analysis in R](https://maksimrudnev.com/2016/12/28/latent-class-analysis-in-r/). Ich habe da immer mal quer geschaut und mich dann für die Pakete hier entschieden. Es gibt sicherlich noch andere Möglichkeiten eine *latent class analysis* zu rechnen.

Wenn du mehr über *latent class analysis* erfahren möchtest, dann kann ich dir nur das [LCA Frequently Asked Questions (FAQ)](https://www.john-uebersax.com/stat/faq.htm) empfehlen. Das FAQ ist sehr umfangreich und beschäftigt sich mit allen wichtigen Punkten. Wir wollen uns ja mit dem R Paket `poLCA` beschäftigen. Hier gibt es zwei Tutorien. Einmal gibt es das Tutorium [Example for a latent class analysis with the poLCA-package in R](https://statistics.ohlsen-web.de/latent-class-analysis-polca/) und das Tutroium [Latent Class Analysis](https://rpubs.com/eogawac/poLCA). Und natürlich die Litertur von @linzer2011polca mit der entsprechenden Veröffentlichung [poLCA: An R Package for Polytomous Variable Latent Class Analysis](https://www.sscnet.ucla.edu/polisci/faculty/lewis/pdf/poLCA-JSS-final.pdf)

Grundsätzlich basiert die *latent class analysis* nicht auf Distanzen sondern versucht über eine Modellierung der Klassenzugehörigkeitswahrscheinlichkeit getrennte Gruppen zu bilden. Wir wollen also $k$ Klassen haben und im idealen Fall können wir durch unsere Variablen in dem Datensatz jeweils mit einer 100% Wahrscheinlichkeit einer der drei Klassen zuordnen. Was dann diese $k$ Klassen aussagen, müssen wir dann selber anhand der zugewiesenen Variablen aus unseren Daten interpretieren.

```{r}
#| eval: false
pacman::p_load(tidyverse, magrittr, janitor, conflicted)

animals_tbl <- read_excel("data/cluster_animal.xlsx", sheet = 1) |> 
  clean_names() 
```

```{r}
#| eval: false
pacman::p_load(poLCA)

poLCA(cbind(warm_blooded, fly, vertebrate, threatened, live_in_groups) ~ 1,
      nclass = 3,
      data = animals_tbl,
      nrep = 1,
      na.rm = FALSE,
      graphs = TRUE,
      maxiter = 100000
)

```

Hier hängen wir dann an der Interpretation. Da müssen wir nochmal tiefer schauen.

## Structural Equation Modeling {.unnumbered}

@van2023best [tidySEM](https://cjvanlissa.github.io/tidySEM/index.html)

[Structural Equation Modeling](https://bookdown.org/bean_jerry/using_r_for_social_work_research/structural-equation-modeling.html)

[Introduction to structural equation modeling (sem) in r with lavaan](https://stats.oarc.ucla.edu/r/seminars/rsem/)

[Intro to structural equation modeling](https://rpubs.com/Agrele/SEM)

Schöne Diagramme [Structural Equation Models](https://advstats.psychstat.org/book/sem/index.php)

## Links & Quellen {.unnumbered}

[Large language models, explained with a minimum of math and jargon](https://www.understandingai.org/p/large-language-models-explained-with)

Data Science

-   Real World Data @liu2022real
-   Warum **Data** Science @hariri2019uncertainty
-   Paradigmenwechsel?

## Referenzen {.unnumbered}
