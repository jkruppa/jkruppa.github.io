[
  {
    "objectID": "stat-modeling-multinom.html",
    "href": "stat-modeling-multinom.html",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "",
    "text": "Version vom November 07, 2022 um 09:06:53"
  },
  {
    "objectID": "stat-modeling-multinom.html#annahmen-an-die-daten",
    "href": "stat-modeling-multinom.html#annahmen-an-die-daten",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.1 Annahmen an die Daten",
    "text": "42.1 Annahmen an die Daten\nUnser gemessenes Outcome \\(y\\) folgt einer Multinomialverteilung.\nIm folgenden Kapitel zu der multinomialen / ordinalen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDaher sieht unser Modell wie folgt aus. Wir haben ein \\(y\\) und \\(p\\)-mal \\(x\\). Wobei \\(p\\) für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser \\(y\\) einer Multinomialverteilung. Damit finden wir im Outcome im Falle der multinomialen logistischen linearen Regression ungeordnete Kategorien und im Falle der ordinalen logistischen linearen Regression geordnete Kategorien.\n\\[\ny \\sim x_1 + x_2 + ... + x_p\n\\]\nWir können in dem Modell auch Faktoren \\(f\\) haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in Kapitel 31 nochmal nachlesen."
  },
  {
    "objectID": "stat-modeling-multinom.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-multinom.html#genutzte-r-pakete-für-das-kapitel",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.2 Genutzte R Pakete für das Kapitel",
    "text": "42.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, gtsummary,\n               ordinal, janitor, MASS, nnet)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"extract\", \"magrittr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-multinom.html#daten",
    "href": "stat-modeling-multinom.html#daten",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.3 Daten",
    "text": "42.3 Daten\nIm Folgenden wollen wir uns die Daten von den infirzierten Ferkeln nocheinmal anschauen.\n\npig_tbl <- read_excel(\"data/infected_pigs.xlsx\") %>%\n  mutate(frailty_ord = ordered(frailty, levels = c(\"robust\", \"pre-frail\", \"frail\")),\n         frailty_fac = as_factor(frailty)) %>% \n  select(-infected)\n\n\n\n\n\nTabelle 42.1— Auszug aus dem Daten zu den kranken Ferkeln.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nlocation\nactivity\ncrp\nfrailty\nbloodpressure\nweight\ncreatinin\nfrailty_ord\nfrailty_fac\n\n\n\n61\nmale\nnortheast\n15.31\n22.38\nrobust\n49.88\n16.94\n3.07\nrobust\nrobust\n\n\n53\nmale\nnorthwest\n13.01\n18.64\nrobust\n58.2\n17.95\n4.88\nrobust\nrobust\n\n\n66\nfemale\nnortheast\n11.31\n18.76\nrobust\n56.8\n19.02\n3.98\nrobust\nrobust\n\n\n59\nfemale\nnorth\n13.33\n19.37\nrobust\n56.47\n18.98\n5.18\nrobust\nrobust\n\n\n63\nmale\nnorthwest\n14.71\n21.57\nrobust\n59.85\n16.57\n6.71\nrobust\nrobust\n\n\n55\nmale\nnorthwest\n15.81\n21.45\nrobust\n58.1\n18.22\n5.43\nrobust\nrobust\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n54\nfemale\nnorth\n11.82\n21.5\nrobust\n57.05\n17.95\n6.16\nrobust\nrobust\n\n\n56\nmale\nwest\n13.91\n20.8\npre-frail\n50.84\n18.02\n6.52\npre-frail\npre-frail\n\n\n57\nmale\nnorthwest\n12.49\n21.95\nrobust\n55.51\n17.73\n3.94\nrobust\nrobust\n\n\n61\nmale\nnorthwest\n15.26\n23.1\nrobust\n58.5\n18.23\n2.73\nrobust\nrobust\n\n\n59\nfemale\nnorth\n13.13\n20.23\npre-frail\n57.33\n17.21\n5.42\npre-frail\npre-frail\n\n\n63\nfemale\nnorth\n10.01\n19.89\nrobust\n55.85\n17.76\n6.18\nrobust\nrobust"
  },
  {
    "objectID": "stat-modeling-multinom.html#sec-ordinal",
    "href": "stat-modeling-multinom.html#sec-ordinal",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.4 Ordinale logistische Regression",
    "text": "42.4 Ordinale logistische Regression\n\n\nIch verweise gerne hier auf das tolle Tutorium Ordinal Logistic Regression | R Data Analysis Examples. Hier erfährst du noch mehr über die Analyse der ordinalen logistischen Regression.\n\nologit_fit <- polr(frailty_ord ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n                   data = pig_tbl)\n\n\nologit_fit %>% summary\n\nCall:\npolr(formula = frailty_ord ~ age + sex + location + activity + \n    crp + bloodpressure + weight + creatinin, data = pig_tbl)\n\nCoefficients:\n                       Value Std. Error  t value\nage                0.0051994   0.021710  0.23950\nsexmale            0.5002016   0.282143  1.77287\nlocationnortheast -0.3153773   0.279274 -1.12928\nlocationnorthwest -0.4695787   0.251658 -1.86594\nlocationwest      -0.0466411   0.273814 -0.17034\nactivity          -0.1302999   0.074089 -1.75870\ncrp               -0.1331070   0.068569 -1.94122\nbloodpressure      0.0161814   0.030828  0.52490\nweight             0.0473460   0.070801  0.66872\ncreatinin         -0.0229332   0.070972 -0.32313\n\nIntercepts:\n                 Value    Std. Error t value \nrobust|pre-frail -2.11884  3.07073   -0.69001\npre-frail|frail  -0.36253  3.06945   -0.11811\n\nResidual Deviance: 776.35998 \nAIC: 800.35998 \n\n\n\nologit_fit %>% confint %>% exp\n\n                       2.5 %    97.5 %\nage               0.96330723 1.0489840\nsexmale           0.95165838 2.8812061\nlocationnortheast 0.42003125 1.2576050\nlocationnorthwest 0.38070890 1.0223181\nlocationwest      0.55662496 1.6307907\nactivity          0.75844827 1.0145338\ncrp               0.76458653 1.0007596\nbloodpressure     0.95673898 1.0798234\nweight            0.91252472 1.2050083\ncreatinin         0.84984003 1.1229968\n\n\n\ncoef_df <- summary(ologit_fit) %>% coef\np_n <- pnorm(abs(coef_df[, \"t value\"]), lower.tail = FALSE) * 2\np_t <- pt(abs(coef_df[, \"t value\"]), df = 3, lower.tail = FALSE) * 2\n\n\ncbind(coef_df,\n      p_n = round(p_n, 3),\n      p_t = round(p_t, 3))\n\n                          Value  Std. Error     t value   p_n   p_t\nage                0.0051993515 0.021709539  0.23949617 0.811 0.826\nsexmale            0.5002015508 0.282142671  1.77286743 0.076 0.174\nlocationnortheast -0.3153772915 0.279274106 -1.12927509 0.259 0.341\nlocationnorthwest -0.4695786718 0.251658467 -1.86593631 0.062 0.159\nlocationwest      -0.0466410914 0.273814157 -0.17033850 0.865 0.876\nactivity          -0.1302998865 0.074088627 -1.75870295 0.079 0.177\ncrp               -0.1331070476 0.068568880 -1.94121659 0.052 0.148\nbloodpressure      0.0161814264 0.030827768  0.52489775 0.600 0.636\nweight             0.0473459616 0.070800950  0.66871930 0.504 0.552\ncreatinin         -0.0229331628 0.070972437 -0.32312774 0.747 0.768\nrobust|pre-frail  -2.1188439172 3.070730313 -0.69001303 0.490 0.540\npre-frail|frail   -0.3625280557 3.069446386 -0.11810861 0.906 0.913\n\n\n\nologit_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 12 × 7\n   term              estimate std.error statistic conf.low conf.high coef.type  \n   <chr>                <dbl>     <dbl>     <dbl>    <dbl>     <dbl> <chr>      \n 1 age                  1.01     0.0217     0.239    0.963      1.05 coefficient\n 2 sexmale              1.65     0.282      1.77     0.952      2.88 coefficient\n 3 locationnortheast    0.730    0.279     -1.13     0.420      1.26 coefficient\n 4 locationnorthwest    0.625    0.252     -1.87     0.381      1.02 coefficient\n 5 locationwest         0.954    0.274     -0.170    0.557      1.63 coefficient\n 6 activity             0.878    0.0741    -1.76     0.758      1.01 coefficient\n 7 crp                  0.875    0.0686    -1.94     0.765      1.00 coefficient\n 8 bloodpressure        1.02     0.0308     0.525    0.957      1.08 coefficient\n 9 weight               1.05     0.0708     0.669    0.913      1.21 coefficient\n10 creatinin            0.977    0.0710    -0.323    0.850      1.12 coefficient\n11 robust|pre-frail     0.120    3.07      -0.690   NA         NA    scale      \n12 pre-frail|frail      0.696    3.07      -0.118   NA         NA    scale      \n\n\n\nologit_fit %>% \n  model_parameters() \n\n# alpha\n\nParameter        | Log-Odds |   SE |        95% CI | t(400) |     p\n-------------------------------------------------------------------\nrobust|pre-frail |    -2.12 | 3.07 | [-8.16, 3.92] |  -0.69 | 0.491\npre-frail|frail  |    -0.36 | 3.07 | [-6.40, 5.67] |  -0.12 | 0.906\n\n# beta\n\nParameter            | Log-Odds |   SE |        95% CI | t(400) |     p\n-----------------------------------------------------------------------\nage                  | 5.20e-03 | 0.02 | [-0.04, 0.05] |   0.24 | 0.811\nsex [male]           |     0.50 | 0.28 | [-0.05, 1.06] |   1.77 | 0.077\nlocation [northeast] |    -0.32 | 0.28 | [-0.87, 0.23] |  -1.13 | 0.259\nlocation [northwest] |    -0.47 | 0.25 | [-0.97, 0.02] |  -1.87 | 0.063\nlocation [west]      |    -0.05 | 0.27 | [-0.59, 0.49] |  -0.17 | 0.865\nactivity             |    -0.13 | 0.07 | [-0.28, 0.01] |  -1.76 | 0.079\ncrp                  |    -0.13 | 0.07 | [-0.27, 0.00] |  -1.94 | 0.053\nbloodpressure        |     0.02 | 0.03 | [-0.04, 0.08] |   0.52 | 0.600\nweight               |     0.05 | 0.07 | [-0.09, 0.19] |   0.67 | 0.504\ncreatinin            |    -0.02 | 0.07 | [-0.16, 0.12] |  -0.32 | 0.747\n\n\nTabelle 42.2\n\nologit_fit %>% \n  tbl_regression(exponentiate = TRUE) %>% \n  as_flex_table()\n\n\n\n\n\n\nTabelle 42.2—  . \n\nCharacteristic\nOR1\n95% CI1\n\n\n\nage\n1.01\n0.96, 1.05\n\n\nsex\n\n\n\n\nfemale\n—\n—\n\n\nmale\n1.65\n0.95, 2.88\n\n\nlocation\n\n\n\n\nnorth\n—\n—\n\n\nnortheast\n0.73\n0.42, 1.26\n\n\nnorthwest\n0.63\n0.38, 1.02\n\n\nwest\n0.95\n0.56, 1.63\n\n\nactivity\n0.88\n0.76, 1.01\n\n\ncrp\n0.88\n0.76, 1.00\n\n\nbloodpressure\n1.02\n0.96, 1.08\n\n\nweight\n1.05\n0.91, 1.21\n\n\ncreatinin\n0.98\n0.85, 1.12\n\n\n1OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "stat-modeling-multinom.html#sec-multinom",
    "href": "stat-modeling-multinom.html#sec-multinom",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.5 Multinomiale logistische Regression",
    "text": "42.5 Multinomiale logistische Regression\n\n\nIch verweise gerne hier auf das tolle Tutorium Multinomial Logistic Regression | R Data Analysis Examples. Hier erfährst du noch mehr über die Analyse der multinominale logistischen Regression.\n\npig_tbl <- pig_tbl %>% \n  mutate(frailty_fac = relevel(frailty_fac, ref = \"robust\"))\n\n\nmultinom_fit <- multinom(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n                         data = pig_tbl)\n\n# weights:  36 (22 variable)\ninitial  value 452.628263 \niter  10 value 390.759179\niter  20 value 381.245185\niter  30 value 380.697891\nfinal  value 380.689300 \nconverged\n\n\n\nmultinom_fit %>% summary\n\nCall:\nmultinom(formula = frailty_fac ~ age + sex + location + activity + \n    crp + bloodpressure + weight + creatinin, data = pig_tbl)\n\nCoefficients:\n          (Intercept)          age    sexmale locationnortheast\npre-frail  0.17654446  0.038506729 0.44925294       -0.41996317\nfrail      3.43418548 -0.033003064 0.68636582       -0.30022746\n          locationnorthwest locationwest     activity          crp\npre-frail       -0.43820881 -0.057193261 -0.191776610 -0.079704735\nfrail           -0.63013878 -0.073415754 -0.090520213 -0.229375206\n          bloodpressure      weight    creatinin\npre-frail  -0.016647061 0.083133822  0.094937138\nfrail       0.058258849 0.012490455 -0.178314707\n\nStd. Errors:\n          (Intercept)         age    sexmale locationnortheast\npre-frail   3.5091063 0.025151746 0.31842764        0.32492320\nfrail       4.8352868 0.035066534 0.46442174        0.43539077\n          locationnorthwest locationwest    activity        crp bloodpressure\npre-frail        0.29000544   0.31989471 0.084862909 0.07938138   0.035364171\nfrail            0.41839015   0.43146491 0.120871533 0.10977972   0.049574040\n               weight  creatinin\npre-frail 0.080012561 0.08225239\nfrail     0.112812864 0.11711736\n\nResidual Deviance: 761.3786 \nAIC: 805.3786 \n\n\n\nmultinom_fit %>% confint %>%  exp\n\n, , pre-frail\n\n                         2.5 %        97.5 %\n(Intercept)       0.0012294634 1157.78780258\nage               0.9892682131    1.09177329\nsexmale           0.8395797922    2.92519061\nlocationnortheast 0.3475659166    1.24218832\nlocationnorthwest 0.3654561294    1.13904639\nlocationwest      0.5045060880    1.76789372\nactivity          0.6989997769    0.97487272\ncrp               0.7903421060    1.07883301\nbloodpressure     0.9176313368    1.05407694\nweight            0.9289615622    1.27119266\ncreatinin         0.9358738525    1.29194503\n\n, , frail\n\n                         2.5 %          97.5 %\n(Intercept)       0.0023748938 404810.16418681\nage               0.9032714078      1.03637192\nsexmale           0.7994078154      4.93629822\nlocationnortheast 0.3155059693      1.73867402\nlocationnorthwest 0.2345307873      1.20911761\nlocationwest      0.3988892623      2.16460940\nactivity          0.7207780217      1.15764022\ncrp               0.6411194437      0.98588959\nbloodpressure     0.9618425758      1.16815103\nweight            0.8117046826      1.26313864\ncreatinin         0.6650716365      1.05256612\n\n\n\nz_mat <- summary(multinom_fit)$coefficients/summary(multinom_fit)$standard.errors\np_n <- (1 - pnorm(abs(z_mat), 0, 1)) * 2\np_n\n\n          (Intercept)        age    sexmale locationnortheast locationnorthwest\npre-frail  0.95987505 0.12577524 0.15828949        0.19618411        0.13077915\nfrail      0.47755899 0.34662514 0.13943631        0.49047180        0.13204066\n          locationwest    activity         crp bloodpressure     weight\npre-frail   0.85810435 0.023831174 0.315343219    0.63783185 0.29880026\nfrail       0.86488853 0.453919866 0.036670533    0.23991925 0.91183969\n           creatinin\npre-frail 0.24841106\nfrail     0.12787632\n\n\n\nmultinom_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 22 × 8\n   y.level   term        estimate std.error statistic p.value conf.low conf.high\n   <chr>     <chr>          <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 pre-frail (Intercept)    1.19     3.51      0.0503  0.960   0.00123  1158.   \n 2 pre-frail age            1.04     0.0252    1.53    0.126   0.989       1.09 \n 3 pre-frail sexmale        1.57     0.318     1.41    0.158   0.840       2.93 \n 4 pre-frail locationno…    0.657    0.325    -1.29    0.196   0.348       1.24 \n 5 pre-frail locationno…    0.645    0.290    -1.51    0.131   0.365       1.14 \n 6 pre-frail locationwe…    0.944    0.320    -0.179   0.858   0.505       1.77 \n 7 pre-frail activity       0.825    0.0849   -2.26    0.0238  0.699       0.975\n 8 pre-frail crp            0.923    0.0794   -1.00    0.315   0.790       1.08 \n 9 pre-frail bloodpress…    0.983    0.0354   -0.471   0.638   0.918       1.05 \n10 pre-frail weight         1.09     0.0800    1.04    0.299   0.929       1.27 \n# … with 12 more rows\n\n\n\nmultinom_fit %>% model_parameters()\n\n# Response level: pre-frail\n\nParameter            | Log-Odds |   SE |         95% CI | t(390) |     p\n------------------------------------------------------------------------\n(Intercept)          |     0.18 | 3.51 | [-6.72,  7.08] |   0.05 | 0.960\nage                  |     0.04 | 0.03 | [-0.01,  0.09] |   1.53 | 0.127\nsex [male]           |     0.45 | 0.32 | [-0.18,  1.08] |   1.41 | 0.159\nlocation [northeast] |    -0.42 | 0.32 | [-1.06,  0.22] |  -1.29 | 0.197\nlocation [northwest] |    -0.44 | 0.29 | [-1.01,  0.13] |  -1.51 | 0.132\nlocation [west]      |    -0.06 | 0.32 | [-0.69,  0.57] |  -0.18 | 0.858\nactivity             |    -0.19 | 0.08 | [-0.36, -0.02] |  -2.26 | 0.024\ncrp                  |    -0.08 | 0.08 | [-0.24,  0.08] |  -1.00 | 0.316\nbloodpressure        |    -0.02 | 0.04 | [-0.09,  0.05] |  -0.47 | 0.638\nweight               |     0.08 | 0.08 | [-0.07,  0.24] |   1.04 | 0.299\ncreatinin            |     0.09 | 0.08 | [-0.07,  0.26] |   1.15 | 0.249\n\n# Response level: frail\n\nParameter            | Log-Odds |   SE |         95% CI | t(390) |     p\n------------------------------------------------------------------------\n(Intercept)          |     3.43 | 4.84 | [-6.07, 12.94] |   0.71 | 0.478\nage                  |    -0.03 | 0.04 | [-0.10,  0.04] |  -0.94 | 0.347\nsex [male]           |     0.69 | 0.46 | [-0.23,  1.60] |   1.48 | 0.140\nlocation [northeast] |    -0.30 | 0.44 | [-1.16,  0.56] |  -0.69 | 0.491\nlocation [northwest] |    -0.63 | 0.42 | [-1.45,  0.19] |  -1.51 | 0.133\nlocation [west]      |    -0.07 | 0.43 | [-0.92,  0.77] |  -0.17 | 0.865\nactivity             |    -0.09 | 0.12 | [-0.33,  0.15] |  -0.75 | 0.454\ncrp                  |    -0.23 | 0.11 | [-0.45, -0.01] |  -2.09 | 0.037\nbloodpressure        |     0.06 | 0.05 | [-0.04,  0.16] |   1.18 | 0.241\nweight               |     0.01 | 0.11 | [-0.21,  0.23] |   0.11 | 0.912\ncreatinin            |    -0.18 | 0.12 | [-0.41,  0.05] |  -1.52 | 0.129\n\n\nTabelle 42.3\n\nmultinom_fit %>% \n  tbl_regression(exponentiate = TRUE) %>% \n  as_flex_table()\n\n\n\n\n\n\nTabelle 42.3—  . \n\nOutcome\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\npre-frail\nage\n1.04\n0.99, 1.09\n0.13\n\n\n\nsex\n\n\n\n\n\n\nfemale\n—\n—\n\n\n\n\nmale\n1.57\n0.84, 2.93\n0.2\n\n\n\nlocation\n\n\n\n\n\n\nnorth\n—\n—\n\n\n\n\nnortheast\n0.66\n0.35, 1.24\n0.2\n\n\n\nnorthwest\n0.65\n0.37, 1.14\n0.13\n\n\n\nwest\n0.94\n0.50, 1.77\n0.9\n\n\n\nactivity\n0.83\n0.70, 0.97\n0.024\n\n\n\ncrp\n0.92\n0.79, 1.08\n0.3\n\n\n\nbloodpressure\n0.98\n0.92, 1.05\n0.6\n\n\n\nweight\n1.09\n0.93, 1.27\n0.3\n\n\n\ncreatinin\n1.10\n0.94, 1.29\n0.2\n\n\nfrail\nage\n0.97\n0.90, 1.04\n0.3\n\n\n\nsex\n\n\n\n\n\n\nfemale\n—\n—\n\n\n\n\nmale\n1.99\n0.80, 4.94\n0.14\n\n\n\nlocation\n\n\n\n\n\n\nnorth\n—\n—\n\n\n\n\nnortheast\n0.74\n0.32, 1.74\n0.5\n\n\n\nnorthwest\n0.53\n0.23, 1.21\n0.13\n\n\n\nwest\n0.93\n0.40, 2.16\n0.9\n\n\n\nactivity\n0.91\n0.72, 1.16\n0.5\n\n\n\ncrp\n0.80\n0.64, 0.99\n0.037\n\n\n\nbloodpressure\n1.06\n0.96, 1.17\n0.2\n\n\n\nweight\n1.01\n0.81, 1.26\n>0.9\n\n\n\ncreatinin\n0.84\n0.67, 1.05\n0.13\n\n\n1OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "stat-modeling-multinom.html#logistische-regression",
    "href": "stat-modeling-multinom.html#logistische-regression",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.6 Logistische Regression",
    "text": "42.6 Logistische Regression\n\npig_tbl$frailty %>% tabyl\n\n         .   n    percent\n     frail  53 0.12864078\n pre-frail 133 0.32281553\n    robust 226 0.54854369\n\n\n\npig_lst <- list(robust_prefrail = filter(pig_tbl, frailty_fac %in% c(\"robust\", \"pre-frail\")),\n                robust_frail = filter(pig_tbl, frailty_fac %in% c(\"robust\", \"frail\")),\n                prefrail_frail = filter(pig_tbl, frailty_fac %in% c(\"pre-frail\", \"frail\")))\n\n\npig_lst %>% \n  map(~glm(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n           data = .x, family = binomial)) %>% \n  map(model_parameters, exponentiate = TRUE) %>% \n  map(extract, -1, )\n\n$robust_prefrail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       1.04 | 0.03 | [0.99, 1.09] |  1.52 | 0.127\nsex [male]           |       1.58 | 0.51 | [0.85, 3.00] |  1.44 | 0.151\nlocation [northeast] |       0.66 | 0.22 | [0.35, 1.25] | -1.26 | 0.209\nlocation [northwest] |       0.65 | 0.19 | [0.36, 1.14] | -1.51 | 0.132\nlocation [west]      |       0.96 | 0.31 | [0.51, 1.80] | -0.13 | 0.895\nactivity             |       0.83 | 0.07 | [0.70, 0.98] | -2.19 | 0.028\ncrp                  |       0.93 | 0.07 | [0.79, 1.08] | -0.95 | 0.342\nbloodpressure        |       0.98 | 0.03 | [0.92, 1.06] | -0.44 | 0.657\nweight               |       1.09 | 0.09 | [0.93, 1.28] |  1.05 | 0.295\ncreatinin            |       1.11 | 0.09 | [0.94, 1.31] |  1.23 | 0.220\n\n$robust_frail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       0.96 | 0.03 | [0.89, 1.03] | -1.09 | 0.275\nsex [male]           |       1.93 | 0.87 | [0.81, 4.76] |  1.46 | 0.144\nlocation [northeast] |       0.80 | 0.35 | [0.33, 1.87] | -0.52 | 0.603\nlocation [northwest] |       0.52 | 0.22 | [0.22, 1.17] | -1.57 | 0.116\nlocation [west]      |       0.95 | 0.41 | [0.40, 2.21] | -0.13 | 0.900\nactivity             |       0.95 | 0.11 | [0.75, 1.19] | -0.47 | 0.638\ncrp                  |       0.78 | 0.09 | [0.63, 0.97] | -2.17 | 0.030\nbloodpressure        |       1.06 | 0.05 | [0.96, 1.17] |  1.22 | 0.223\nweight               |       1.00 | 0.11 | [0.81, 1.24] | -0.01 | 0.992\ncreatinin            |       0.82 | 0.10 | [0.65, 1.04] | -1.64 | 0.100\n\n$prefrail_frail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       0.94 | 0.03 | [0.88, 1.01] | -1.61 | 0.108\nsex [male]           |       1.29 | 0.69 | [0.46, 3.73] |  0.48 | 0.632\nlocation [northeast] |       0.96 | 0.46 | [0.37, 2.44] | -0.08 | 0.938\nlocation [northwest] |       0.81 | 0.38 | [0.32, 2.02] | -0.44 | 0.660\nlocation [west]      |       0.92 | 0.43 | [0.36, 2.30] | -0.17 | 0.866\nactivity             |       1.05 | 0.14 | [0.81, 1.37] |  0.39 | 0.695\ncrp                  |       0.87 | 0.10 | [0.69, 1.09] | -1.18 | 0.240\nbloodpressure        |       1.08 | 0.06 | [0.96, 1.21] |  1.34 | 0.182\nweight               |       0.95 | 0.12 | [0.74, 1.21] | -0.42 | 0.673\ncreatinin            |       0.79 | 0.10 | [0.61, 1.00] | -1.87 | 0.061"
  },
  {
    "objectID": "stat-modeling-poisson.html",
    "href": "stat-modeling-poisson.html",
    "title": "43  Poisson Regression",
    "section": "",
    "text": "Version vom November 07, 2022 um 09:17:41\nIn diesem Kapitel wollen wir eine Poisson Regression rechnen. Wir müssen uns hier wieder überlegen, was ist eigentlich unser Outcome \\(y\\) und was sind unsere Einflussvariablen \\(x\\). Die Poisson Regression ist je nach Hintergurnd des Anwenders eher selten. In der Ökologie, wo gerne mal gezaählt wird, wie oft etwas vorkommt, ist die Poisson Regression häufig vertreten. Sonst fristet die Poisson Regresson eher ein unbekanntes Dasein.\nEin häufig unterschätzter Vorteil der Poisson Regression ist, dass wir auch auch \\(0/1\\) Daten eine Poisson Regression rechnen können. Moment, wirst du jetzt vielleicht denken, das machen wir doch mit der logistsichen Regression. Ja, das stimmt, aber wir können auf Zahlen viel rechnen. Wenn wir auf ein \\(0/1\\) Outcome eine Poisson Regression rechnen, dann kriegen wir nicht Odds Ratios \\(OR\\) als Effektschätzer sondern Risk Ratios \\(RR\\). Wir erhalten also keine Chancen sondern Wahrscheinlichkeiten. Unter der Annahme, dass das Modell auch konvergiert und wir sinnvolle Zahlen erhalten.\nEin weiteres Problem sind die zu vielen Nullen in dem Outcome \\(y\\). Daherher wir zählen über die Maßen viel Nichts. Wir nennen diesen Fall zero inflation und beschreiben damit die zu vielen Nullen in den Daten. Hier muss dann noch speziell modelliert werden. Eine Poisson Regression hat schon so seine speziellen Tücken."
  },
  {
    "objectID": "stat-modeling-poisson.html#annahmen-an-die-daten",
    "href": "stat-modeling-poisson.html#annahmen-an-die-daten",
    "title": "43  Poisson Regression",
    "section": "\n43.1 Annahmen an die Daten",
    "text": "43.1 Annahmen an die Daten\nUnser gemessenes Outcome \\(y\\) folgt einer Poissonverteilung.\nIm folgenden Kapitel zu der multiplen Poisson linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDaher sieht unser Modell wie folgt aus. Wir haben ein \\(y\\) und \\(p\\)-mal \\(x\\). Wobei \\(p\\) für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser \\(y\\) einer Poissonverteilung. Das ist hier sehr wichtig, denn wir wollen ja eine multiple Poisson lineare Regression rechnen.\n\\[\ny \\sim x_1 + x_2 + ... + x_p\n\\]\nWir können in dem Modell auch Faktoren \\(f\\) haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in Kapitel 31 nochmal nachlesen."
  },
  {
    "objectID": "stat-modeling-poisson.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-poisson.html#genutzte-r-pakete-für-das-kapitel",
    "title": "43  Poisson Regression",
    "section": "\n43.2 Genutzte R Pakete für das Kapitel",
    "text": "43.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, MASS, pscl, see,\n               scales)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-poisson.html#daten",
    "href": "stat-modeling-poisson.html#daten",
    "title": "43  Poisson Regression",
    "section": "\n43.3 Daten",
    "text": "43.3 Daten\nIm folgenden schauen wir uns ein Datenbeispiel mit Hechten an. Es handelt sich um langnasige Hechte in nordamerikanischen Flüssen. Wir haben uns insgesamt \\(n = 68\\) Flüsse einmal angesehen und dort die Anzahl an Hechten gezählt. Im Weiteren haben wir dann noch andere Flussparameter erhoben und fragen uns nun, welche dieser Parameter einen Einfluss auf die Anzahl an Hechten in den Flussarmen haben. In Kapitel 10.2 findest du nochmal mehr Informationen zu den Daten. Wir entfernen hier die Informationen zu den Flüssen, die brauchen wir in dieser Analyse nicht.\n\n\nDie Daten zu den langnasigen Hechten stammt von Salvatore S. Mangiafico - An R Companion for the Handbook of Biological Statistics.\n\nlongnose_tbl <- read_csv2(\"data/longnose.csv\") %>% \n  select(-stream)\n\n\n\n\n\nTabelle 43.1— Auszug aus dem Daten zu den langnasigen Hechten.\n\nlongnose\narea\ndo2\nmaxdepth\nno3\nso4\ntemp\n\n\n\n13\n2528\n9.6\n80\n2.28\n16.75\n15.3\n\n\n12\n3333\n8.5\n83\n5.34\n7.74\n19.4\n\n\n54\n19611\n8.3\n96\n0.99\n10.92\n19.5\n\n\n19\n3570\n9.2\n56\n5.44\n16.53\n17\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n26\n1450\n7.9\n60\n2.96\n8.84\n18.6\n\n\n20\n4106\n10\n96\n2.62\n5.45\n15.4\n\n\n38\n10274\n9.3\n90\n5.45\n24.76\n15\n\n\n19\n510\n6.7\n82\n5.25\n14.19\n26.5\n\n\n\n\n\n\nIm Folgenden werden wir die Daten nur für das Fitten eines Modells verwenden. In den anderen oben genannten Kapiteln nutzen wir die Daten dann anders. In Abbildung 43.1 sehen wir nochmal die Verteilung der Anzahl der Hechte in den Flüssen.\n\nggplot(longnose_tbl, aes(longnose)) +\n  theme_bw() +\n  geom_histogram()\n\n\n\nAbbildung 43.1— Histogramm der Verteilung der Hechte in den beobachteten Flüssen."
  },
  {
    "objectID": "stat-modeling-poisson.html#fit-des-modells",
    "href": "stat-modeling-poisson.html#fit-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.4 Fit des Modells",
    "text": "43.4 Fit des Modells\nIn diesem Abschnitt wollen wir verschiedene Modelle für Zähldaten schätzen. Die Poissonverteilung hat keinen eignen Parameter für die Streung wie die Normalverteilung. Die Poissonverteilung ist mit \\(\\mathcal{Pois}(\\lambda)\\) definiert und hat somit die Eigenschaft das die Varianz eins zu eins mit dem Mittelwert \\(\\lambda\\) der Poissonverteilung ansteigt. Es kann aber sein, dass wir in den Daten nicht diesen ein zu eins Zusammenhang von Mittelwert und Varianz vrliegen haben. Häufig ist die Varianz viel größer und steigt schneller an. Wenn die Varianz in Wirklichkeit sehr viel größer ist, dann würden wir die Varianz in unseren Modell unterschätzen.\n\nEin klassisches Poissonmodell glm(..., familiy = poisson) mit der Annahme keiner Overdisperison.\nEin Quasi-Poissonmodell glm(..., family = quasipoisson) mit der Möglichkeit der Berücksichtigung einer Overdispersion.\nEin negative Binomialmodell glm.nb(...) ebenfalls mit der Berücksichtigung einer Overdispersion.\n\nBeginnen wollen wir aber mit einer klassischen Poissonregression ohne die Annahme von einer Overdispersion in den Daten. Wir nutzen dafür die Funktion glm() und spezifizieren die Verteilungsfamilie als poisson. Wir nehmen wieder alle Variablen in das Modell auf der rechten Seite des ~. Auf der linken Seite des ~ kommt dann unser Outcome longnose was die Anzahl an Hechten erhält.\nHier gibt es nur die Kurzfassung der link-Funktion. Dormann (2013) liefert hierzu in Kapitel 7.1.3 nochmal ein Einführung in das Thema.\nWir müssen für die Possionregression noch beachten, dass die Zähldaten von \\(0\\) bis \\(+\\infty\\) laufen. Damit wir normalverteilte Residuen erhalten und einen lineren Zusammenhang, werden wir das Modell auf dem \\(\\log\\)-scale fitten. Das heißt, wir werden den Zusammenhang von \\(y\\) und \\(x\\) logarithmieren. Wichtig ist hierbei der Zusammenhang. Wir transformieren nicht einfach \\(y\\) und lassen den Rest unberührt. Das führt dazu, dass wir am Ende die Koeffizienten der Poissonregression exponieren müssen. Das können die gängigen Funktionen, wir müssen das Exponieren aber aktiv durchführen. Deshalb hier schon mal erwähnt.\n\npoisson_fit <- glm(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                    longnose_tbl, family = poisson)\n\nWir schauen uns die Ausgabe des Modells einmal mit der summary() Funktion an, da wir hier einmal händisch schauen wollen, ob eine Overdispersion vorliegt. Sonst könnten wir auch die Funktion model_parameters() nehmen. Die nutzen wir später für die Interpretation des Modells, hier wollen wir erstmal sehen, ob alles geklappt hat.\n\npoisson_fit %>% summary\n\n\nCall:\nglm(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, family = poisson, data = longnose_tbl)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-9.2343  -4.0856  -1.6619   1.7709  14.3616  \n\nCoefficients:\n                 Estimate    Std. Error z value              Pr(>|z|)    \n(Intercept) -1.5643879535  0.2818029375 -5.5514         0.00000002835 ***\narea         0.0000384263  0.0000020794 18.4796 < 0.00000000000000022 ***\ndo2          0.2258789585  0.0212563866 10.6264 < 0.00000000000000022 ***\nmaxdepth     0.0115493150  0.0006687680 17.2695 < 0.00000000000000022 ***\nno3          0.1813114263  0.0106815488 16.9743 < 0.00000000000000022 ***\nso4         -0.0068097229  0.0036222591 -1.8800               0.06011 .  \ntemp         0.0785448817  0.0065300439 12.0282 < 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2766.88  on 67  degrees of freedom\nResidual deviance: 1590.04  on 61  degrees of freedom\nAIC: 1936.86\n\nNumber of Fisher Scoring iterations: 5\n\n\nWir schauen in die Summary-Ausgabe des Poissonmodells und sehen, dass dort steht, dass Dispersion parameter for poisson family taken to be 1. Wir modellieren also einen eins zu eins Zusammenhang von Mittelwert und Varianz. Wenn dieser Zusammenhang nicht in unseren Daten existiert, dann haben wir eine Overdispersion vorliegen.\nWir können die Overdispersion mit abschätzen indem wir die Residual deviance durch die Freiheitsgrade der Residual deviance teilen. Daher erhalten wir eine Overdispersion von \\(\\cfrac{1590.04}{61} \\approx 26.1\\). Damit haben wir eine eindeutige Overdispersion vorliegen. Damit steigt die Varianz in einem Verhältnis von ca. 1 zu 26. Wir können auch die Funktion check_overdispersion() aus dem R Paket performance nutzen um die Overdispersion zu berechnen. Die Funktion kann das schneller und ist auch in der Abfolge einer Analyse besser geeignet.\n\npoisson_fit %>% check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =   29.403\n  Pearson's Chi-Squared = 1793.599\n                p-value =  < 0.001\n\n\nOverdispersion detected.\n\n\nWenn wir Overdispersion vorliegen haben und damit die Varianz zu niedrig schätzen, dann erhalten wir viel mehr signifikante Ergebnisse als es in den Daten zu erwarten wäre. Schauen wir uns nochmal die Parameter der Poissonverteilung und die \\(p\\)-Werte einmal an.\n\npoisson_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |         95% CI |     z |      p\n--------------------------------------------------------------------\n(Intercept) |     -1.56 |     0.28 | [-2.12, -1.01] | -5.55 | < .001\narea        |  3.84e-05 | 2.08e-06 | [ 0.00,  0.00] | 18.48 | < .001\ndo2         |      0.23 |     0.02 | [ 0.18,  0.27] | 10.63 | < .001\nmaxdepth    |      0.01 | 6.69e-04 | [ 0.01,  0.01] | 17.27 | < .001\nno3         |      0.18 |     0.01 | [ 0.16,  0.20] | 16.97 | < .001\nso4         | -6.81e-03 | 3.62e-03 | [-0.01,  0.00] | -1.88 | 0.060 \ntemp        |      0.08 | 6.53e-03 | [ 0.07,  0.09] | 12.03 | < .001\n\n\nIn der Spalte p finden wir die \\(p\\)-Werte für alle Variablen. Wir sehen, dass fast alle Variablen signifikant sind und das wir eine sehr niedrige Varianz in der Spalte SE sehen. Das heißt unser geschätzer Fehler ist sehr gering. Das ahnten wir ja schon, immerhin haben wir eine Overdisperson vorliegen. Das Modell ist somit falsch. Wir müssen uns ein neues Modell suchen, was Overdispersion berückscihtigen und modellieren kann.\nDie Quasi-Poisson Verteilung hat einen zusätzlichen, unabhänigen Parameter um die Varianz der Verteilung zu schätzen. Daher können wir die Overdispersion mit einer Quasi-Poisson Verteilung berückscihtigen. Wir können eine Quasi-Poisson Verteilung auch mit der Funktion glm() schätzen nur müssen wir als Verteilungsfamilie quasipoisson angeben.\n\nquasipoisson_fit <- glm(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                        data = longnose_tbl, family = quasipoisson)\n\nNach dem Modellti können wir nochmal in der summary() Funktion schauen, ob wir die Overdispersion richtig berücksichtigt haben.\n\nquasipoisson_fit %>% summary\n\n\nCall:\nglm(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, family = quasipoisson, data = longnose_tbl)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-9.2343  -4.0856  -1.6619   1.7709  14.3616  \n\nCoefficients:\n                Estimate   Std. Error t value Pr(>|t|)   \n(Intercept) -1.564387953  1.528071553 -1.0238 0.309989   \narea         0.000038426  0.000011275  3.4080 0.001164 **\ndo2          0.225878959  0.115262389  1.9597 0.054605 . \nmaxdepth     0.011549315  0.003626383  3.1848 0.002282 **\nno3          0.181311426  0.057920513  3.1303 0.002679 **\nso4         -0.006809723  0.019641637 -0.3467 0.730011   \ntemp         0.078544882  0.035409050  2.2182 0.030273 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 29.403319)\n\n    Null deviance: 2766.88  on 67  degrees of freedom\nResidual deviance: 1590.04  on 61  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\n\nAn der Zeile Dispersion parameter for quasipoisson family taken to be 29.403319 in der Summary-Ausgabe sehen wir, dass das Modell der Quasi-Possion Verteilung die Overdispersion korrekt berücksichtigt hat. Wir können uns nun einmal die Modellparameter anschauen. Die Interpretation machen wir am Ende des Kapitels.\n\nquasipoisson_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |        95% CI | t(61) |      p\n-------------------------------------------------------------------\n(Intercept) |     -1.56 |     1.53 | [-4.57, 1.41] | -1.02 | 0.306 \narea        |  3.84e-05 | 1.13e-05 | [ 0.00, 0.00] |  3.41 | < .001\ndo2         |      0.23 |     0.12 | [ 0.00, 0.45] |  1.96 | 0.050 \nmaxdepth    |      0.01 | 3.63e-03 | [ 0.00, 0.02] |  3.18 | 0.001 \nno3         |      0.18 |     0.06 | [ 0.07, 0.29] |  3.13 | 0.002 \nso4         | -6.81e-03 |     0.02 | [-0.05, 0.03] | -0.35 | 0.729 \ntemp        |      0.08 |     0.04 | [ 0.01, 0.15] |  2.22 | 0.027 \n\n\nJetzt sieht unser Modell und die \\(p\\)-Werte zusammen mit dem Standardfehler SE schon sehr viel besser aus. Wir können also diesem Modell erstmal von der Seite der Overdispersion vertrauen.\nAm Ende wollen wir nochmal das Modell mit der negativen Binomialverteilung rechnen. Die negativen Binomialverteilung erlaubt auch eine Unabhängigkeit von dem Mittelwert zu der Varianz. Wir können hier auch für die Overdispersion adjustieren. Wir rechnen die negativen Binomialregression mit der Funktion glm.nb() aus dem R Paket MASS. Wir müssen keine Verteilungsfamilie angeben, die Funktion glm.nb() kann nur die negative Binomialverteilung modellieren.\n\nnegativebinomial_fit <- glm.nb(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                               data = longnose_tbl)\n\nAuch hier schauen wir mit der Funktion summary() einmal, ob die Overdisprsion richtig geschätzt wurde oder ob hier auch eine Unterschätzung des Zusammenhangs des Mittelwerts und der Varianz vorliegt.\n\nnegativebinomial_fit %>% summary()\n\n\nCall:\nglm.nb(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, data = longnose_tbl, init.theta = 1.666933879, link = log)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.46010  -0.98759  -0.44256   0.48249   2.27756  \n\nCoefficients:\n                Estimate   Std. Error z value  Pr(>|z|)    \n(Intercept) -2.945664673  1.305427827 -2.2565 0.0240409 *  \narea         0.000046513  0.000013002  3.5774 0.0003470 ***\ndo2          0.341916152  0.105012333  3.2560 0.0011301 ** \nmaxdepth     0.009537603  0.003465417  2.7522 0.0059192 ** \nno3          0.207240064  0.056268918  3.6830 0.0002305 ***\nso4         -0.002157482  0.015165776 -0.1423 0.8868747    \ntemp         0.094595849  0.033149947  2.8536 0.0043230 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6669) family taken to be 1)\n\n    Null deviance: 127.6700  on 67  degrees of freedom\nResidual deviance:  73.6483  on 61  degrees of freedom\nAIC: 610.175\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.667 \n          Std. Err.:  0.289 \n\n 2 x log-likelihood:  -594.175 \n\n\nAuch hier sehen wir, dass die Overdispersion mit dem Parameter \\(\\theta\\) berücksichtigt wird. Wir können die Zahl \\(1.67\\) nicht direkt mit der Overdispersion aus einer Poissonregression verglechen, aber wir sehen dass das Verhältnis von Residual deviance zu den Freiheitsgraden mit \\(\\cfrac{73.65}{61} \\approx 1.20\\) fast bei 1:1 liegt. Wir könnten also auch eine negative Binomialverteilung für das Modellieren nutzen.\n\nnegativebinomial_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |         95% CI |     z |      p\n--------------------------------------------------------------------\n(Intercept) |     -2.95 |     1.31 | [-5.85, -0.10] | -2.26 | 0.024 \narea        |  4.65e-05 | 1.30e-05 | [ 0.00,  0.00] |  3.58 | < .001\ndo2         |      0.34 |     0.11 | [ 0.11,  0.58] |  3.26 | 0.001 \nmaxdepth    |  9.54e-03 | 3.47e-03 | [ 0.00,  0.02] |  2.75 | 0.006 \nno3         |      0.21 |     0.06 | [ 0.10,  0.32] |  3.68 | < .001\nso4         | -2.16e-03 |     0.02 | [-0.03,  0.03] | -0.14 | 0.887 \ntemp        |      0.09 |     0.03 | [ 0.03,  0.16] |  2.85 | 0.004 \n\n\n\n\nWie immer gibt es reichtlich Tipps & Tricks welches Modell du nun nehmen solltest. How to deal with overdispersion in Poisson regression: quasi-likelihood, negative binomial GLM, or subject-level random effect? und das Tutorial Modeling Count Data. Auch ich mus immer wieder schauen, was am besten konkret in der Anwendung passen könnte und würde.\nWelches Modell nun das beste Modell ist, ist schwer zu sagen. Wenn du Overdisperion vorliegen hast, dann ist natürlich nur das Quasi-Poissonmodell oder das negative Binomialmodell möglich. Welche der beiden dann das bessere ist, hängt wieder von der Fragestellung ab. Allgemein gesprochen ist das Quasi-Poissonmodell besser wenn dich die Zusammenhänge von \\(y\\) zu \\(x\\) am meisten interessieren. Und das ist in unserem Fall hier die Sachlage. Daher gehen wir mit den Quasi-Poissonmdell dann weiter."
  },
  {
    "objectID": "stat-modeling-poisson.html#performance-des-modells",
    "href": "stat-modeling-poisson.html#performance-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.5 Performance des Modells",
    "text": "43.5 Performance des Modells\nIn diesem kurzen Abschnitt wollen wir uns einmal anschauen, ob das Modell neben der Overdispersion auch sonst aus statistischer Sicht in Ordnung ist. Wir wollen ja mit dem Modell aus dem Fit quasipoisson_fit weitermachen. Also schauen wir uns einmal das pseudo-\\(R^2\\) für die Poissonregression an. Da wir es mit einem GLM zu tun haben, ist das \\(R^2\\) mit vorsicht zu genießen. In einer Gaussianregression können wir das \\(R^2\\) als Anteil der erklärten Varianz durch das Modell interpretieren. Im Falle von GLM’s müssen wir hier vorsichtiger sein. In GLM’s gibt es ja keine Varianz sondern eine Deviance.\n\nr2_efron(quasipoisson_fit)\n\n[1] 0.3257711\n\n\nMit einem pseudo-\\(R^2\\) von \\(0.33\\) erklären wir ca. 33% der Varianz in der Anzahl der Hechte. Das ist zwar keine super gute Zahl, aber dafür, dass wir nur eine handvoll von Parametern erfasst haben, ist es dann auch wieder nicht so schlecht. Die Anzahl an Hechten wird sicherlich an ganz vielen Parametern hängen, wir konnten immerhin einige wichtige Stellschrauben vermutlich finden.\nIn Abbildung 43.2 schauen wir uns nochmal die Daten in den Modelgüteplots an. Wir sehen vorallem, dass wir vielelicht doch einen Ausreißer mit der Beobachtung 17 vorliegen haben. Auch ist der Fit nicht so super, wie wir an dem QQ-Plot sehen. Die Beobachtungen fallen in dem QQ-Plot nicht alle auf eine Linie. Auch sehen wir dieses Muster in dem Residualplot. Hiererwarten wir eine gerade blaue Linie und auch hier haben wir eventuell Ausreißer mit in den Daten.\n\ncheck_model(quasipoisson_fit, colors = cbbPalette[6:8], \n            check = c(\"qq\", \"outliers\", \"pp_check\", \"homogeneity\")) \n\n\n\nAbbildung 43.2— Ausgabe ausgewählter Modelgüteplots der Funktion check_model()."
  },
  {
    "objectID": "stat-modeling-poisson.html#interpretation-des-modells",
    "href": "stat-modeling-poisson.html#interpretation-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.6 Interpretation des Modells",
    "text": "43.6 Interpretation des Modells\nUm die Effektschätzer einer Poissonregression oder aber einer Quasipoisson-Regression interpretieren zu können müssen wir uns einmal einen Beispieldatensatz mit bekannten Effekten zwischen den Gruppen bauen. Im Folgenden bauen wir uns einen Datensatz mit zwei Gruppen. Einmal einer Kontrollgruppe mit einer mittleren Anzahl an \\(15\\) und einer Behandlungsgruppe mit einer um \\(\\beta_1 = 10\\) höheren Anzahl. Wir haben also in der Kontrolle im Mittel eine Anzahl von \\(15\\) und in der Behandlungsgruppe eine mittlere Anzahl von \\(25\\).\n\nsample_size <- 10000\nlongnose_small_tbl <- tibble(grp = rep(c(0, 1), each = sample_size),\n                             count = 15 + 10 * grp + rnorm(2 * sample_size, 0, 1)) %>%\n  mutate(count = round(count),\n         grp = factor(grp, labels = c(\"ctrl\", \"trt\")))\n\nIn Tabelle 43.2 sehen wir nochmal die Daten als Ausschnitt dargestellt.\n\n\n\n\nTabelle 43.2— How much is the fish? Der Datensatz über \\(n = 1000\\) Beobachtungen an dem wir überlegen wollen wie wir die Effektschätzer einer Poissonregression zu interpretieren haben.\n\ngrp\ncount\n\n\n\nctrl\n18\n\n\nctrl\n14\n\n\nctrl\n16\n\n\nctrl\n14\n\n\n…\n…\n\n\ntrt\n26\n\n\ntrt\n25\n\n\ntrt\n26\n\n\ntrt\n25\n\n\n\n\n\n\nDa sich die Tabelle schlecht liest hier nochmal der Boxplot in Abbildung 43.3. Wir sehen den Grupenunterschied von \\(10\\) sowie die unterschiedlichen mittleren Anzahlen für die Kontrolle und die Behandlung.\n\nggplot(longnose_small_tbl, aes(x = grp, y = count, fill = grp)) +\n  theme_bw() +\n  geom_boxplot() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() \n\n\n\nAbbildung 43.3— How much is the fish? Der Boxplot über \\(n = 1000\\) Beobachtungen an dem wir überlegen wollen wie wir die Effektschätzer einer Poissonregression zu interpretieren haben.\n\n\n\n\nJetzt fitten wir einmal das simple Poissonmodell mit der Anzahl als Outcome und der Gruppe mit den zwei Leveln als \\(x\\). Wir pipen dann das Ergebnis des Fittes gleich in die Funktion model_parameters() weiter um die Ergebnisse des Modellierens zu erhalten.\n\nglm(count ~ grp, data = longnose_small_tbl, family = poisson) %>%\n  model_parameters(exponentiate = TRUE)\n\nParameter   |   IRR |       SE |         95% CI |       z |      p\n------------------------------------------------------------------\n(Intercept) | 15.00 |     0.04 | [14.92, 15.07] | 1048.70 | < .001\ngrp [trt]   |  1.67 | 5.44e-03 | [ 1.66,  1.68] |  156.41 | < .001\n\n\nAls erstes fällt auf, dass wir die Ausgabe des Modells exponieren müssen. Um einen linearen Zusamenhang hinzukriegen bedient sich die Poissonregression den Trick, das der Zusammenhang zwischen dem \\(y\\) und dem \\(x\\) transformiert wird. Wir rechnen unsere Regression nicht auf den echten Daten sondern auf dem \\(\\log\\)-scale. Daher müssen wir die Koeffizienten der Poissonregression wieder zurücktransfomieren, wenn wir die Koeffizienten interpretieren wollen. Das können wir mit der Option exponentiate = TRUE durchführen.\nGut soweit, aber was heißen den jetzt die Zahlen? Wir haben einen Intercept von \\(14.99\\) das entspricht der mittleren Anzahl in der Kontrollgruppe. Und was sagt jetzt die \\(1.67\\) vom Level trt des Faktors grp? Wenn wir \\(14.99 \\cdot 1.67\\) rechnen, dann erhalten wir als Ergebnis \\(25.03\\), also die mittlere Anzahl in der Behandlungsgruppe. Was sagt uns das jetzt aus? Wir erhalten aus der Poissonregression eine Wahrscheinlichkeit oder aber ein Risk Ratio. Wir können sagen, dass die Anzahl in der Behandlungsgruppe \\(1.67\\)-mal so groß ist wie in der Kontrollgruppe.\nSchauen wir uns nochmal das volle Modell an und interpretieren die Effekte der einzelnen Variablen.\n\nquasipoisson_fit %>% \n  model_parameters(exponentiate = TRUE) \n\nParameter   |  IRR |       SE |       95% CI | t(61) |      p\n-------------------------------------------------------------\n(Intercept) | 0.21 |     0.32 | [0.01, 4.11] | -1.02 | 0.306 \narea        | 1.00 | 1.13e-05 | [1.00, 1.00] |  3.41 | < .001\ndo2         | 1.25 |     0.14 | [1.00, 1.57] |  1.96 | 0.050 \nmaxdepth    | 1.01 | 3.67e-03 | [1.00, 1.02] |  3.18 | 0.001 \nno3         | 1.20 |     0.07 | [1.07, 1.34] |  3.13 | 0.002 \nso4         | 0.99 |     0.02 | [0.95, 1.03] | -0.35 | 0.729 \ntemp        | 1.08 |     0.04 | [1.01, 1.16] |  2.22 | 0.027 \n\n\nSo schön auch die Funktion model_parameters() ist, so haben wir aber hier das Problem, dass wir den Effekt von area nicht mehr richtig sehen. Wir kriegen hier eine zu starke Rundung auf zwei Nachkommastellen. Wir nutzen jetzt mal die Funktion tidy() um hier Abhilfe zu leisten. Ich muss hier noch die Spalte estimate mit num(..., digits = 5) anpassen, damit du in der Ausgabe auf der Webseite auch die Nachkommastellen siehst.\n\nquasipoisson_fit %>% \n  tidy(exponentiate = TRUE, digits = 5) %>% \n  select(term, estimate, p.value) %>% \n  mutate(p.value = pvalue(p.value),\n         estimate = num(estimate, digits = 5))\n\n# A tibble: 7 × 3\n  term         estimate p.value\n  <chr>       <num:.5!> <chr>  \n1 (Intercept)   0.20922 0.310  \n2 area          1.00004 0.001  \n3 do2           1.25342 0.055  \n4 maxdepth      1.01162 0.002  \n5 no3           1.19879 0.003  \n6 so4           0.99321 0.730  \n7 temp          1.08171 0.030  \n\n\nSchauen wir uns die Effekte der Poissonregression einmal an und versuchen die Ergebnisse zu interpretieren. Dabei ist wichtig sich zu erinnern, dass kein Effekt eine 1 bedeutet. Wir schauen hier auf einen Faktor. Wenn wir eine Anzahl mal Faktor 1 nehmen, dann ändert sich nichts an der Anzahl.\n\n\n(Intercept) beschreibt den Intercept der Poissonregression. Wenn wir mehr als eine simple Regression vorliegen haben, wie in diesem Fall, dann ist der Intercept schwer zu interpretieren. Wir konzentrieren uns auf die Effekte der anderen Variablen.\n\narea, beschreibt den Effekt der Fläche. Steigt die Fläche um ein Quadratmeter an, so erhöht sich die Anzahl an Fischen um den \\(1.00001\\). Daher würde man hier eher sagen, erhöht sich die Fläche um jeweils 1000qm so erhöht sich die Anzahl an Fischen um den Faktor \\(1.1\\). Dann haben wir auch einen besser zu interpretierenden Effektschätzer. Die Signifikanz bleibt hier davon unbetroffen.\n\ndo2, beschreibt den Partzialdruck des Sauerstoffs. Steigt dieser um eine Einheit an, so sehen wie eine Erhöhung der Anzahl an Fischen um den Faktor \\(1.25\\). Der Effekt ist gerade nicht signifikant.\n\nmaxdepth, beschreibt die maximale Tiefe. Je tiefer ein Fluß, desto mehr Hechte werden wir beobachten. Der Effekt von \\(1.01\\) pro Meter Tiefe ist signifikant.\n\nno3, beschreibt den Anteil an Nitrat in den Flüssen. Je mehr Nitrat desto signifiant mehr Hechte werden wir beobachten. Hier steigt der Faktor auch um \\(1.20\\).\n\nso4, beschreibt den Schwefelgehalt und mit steigenden Schwefelgehalt nimmt die Anzahl an Fischen leicht ab. Der Effekt ist aber überhauot nicht signifikant.\n\ntemp, beschreibt die Temperatur der Flüsse. Mit steigender Tempertaur erwarten wir mehr Hechte zu beobachten. Der Effekt von \\(1.08\\) Fischen pro Grad Erhöhung ist signifikant.\n\nWas nehmen wir aus der Poissonregression zu den langnasigen Hechten mit? Zum einen haben die Fläche, die Tiefe und der Nitratgehalt einen signifikanten Einfluss auf die Anzahl an Hechten. Auch führt eine höhere Temperatur zu mehr gefundenen Hechten. Die erhöhte Temperatur steht etwas im Widerspuch zu dem Sauerstoffpartizaldruck. Denn je höher die Temperatur desto weniger Sauerstoff wird in dem Wasser gelöst sein. Auch scheint die Oberfläche mit der Tiefe korreliert. Allgemein scheinen Hechte große Flüße zu mögen. Hier bietet sich also noch eine Variablenselektion oder eine Untersuchung auf Ausreißer an um solche Effekte nochmal gesondert zu betrachten."
  },
  {
    "objectID": "stat-modeling-poisson.html#zeroinflation",
    "href": "stat-modeling-poisson.html#zeroinflation",
    "title": "43  Poisson Regression",
    "section": "\n43.7 Zeroinflation",
    "text": "43.7 Zeroinflation"
  },
  {
    "objectID": "stat-modeling-poisson.html#referenzen",
    "href": "stat-modeling-poisson.html#referenzen",
    "title": "43  Poisson Regression",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer."
  }
]