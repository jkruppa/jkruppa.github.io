```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Spielecke {#sec-spielecke}

*Letzte Änderung am `r format(fs::file_info("app-spielecke.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Denn, um es endlich auf einmal herauszusagen, der Mensch spielt nur, wo er in voller Bedeutung des Worts Mensch ist, und er ist nur da ganz Mensch, wo er spielt." --- Friedrich Schiller*

Das ist hier meine Spielecke, wo ich Ideen und sonst so Zeug sammele, was mir über den Weg läuft und ich noch nicht so richtig weiter im Skript eingeordnet habe. Deshalb hat das hier auch keine Struktur, da mir die Gedanken eben auch noch wirr durch den Kopf geistern.

------------------------------------------------------------------------

![](images/caution.png){fig-align="center" width="50%"}

::: callout-tip
## Offene Themen, über die ich sinnieren muss

-   Latent Class Analysis (seit September 2023)
-   Structural Equation Modeling (seit September 2023)
-   Discrete Time Survival Analysis (seit September 2023)
:::

------------------------------------------------------------------------

## Violinplot

```{r}
#| message: false

gummi_tbl <- read_excel("data/gummibears.xlsx")  %>%
  select(gender, height, age) %>% 
  mutate(gender = factor(gender, labels = c("männlich", "weiblich"))) %>% 
  na.omit()

```

## R Paket `{modelbased}`

[R Paket `{modelbased}`](https://easystats.github.io/modelbased/)

## FAO Stat

[Food and agriculture data](https://www.fao.org/faostat/en/#home)

[FAOSTAT: Download Data from the FAOSTAT Database](https://cran.r-hub.io/web/packages/FAOSTAT/vignettes/FAOSTAT.pdf)

Mit dem R Paket `{owidR}` haben wir auch eine Möglichkeit direkt auf die Datenbank von Our World in Data zuzugreifen.

```{r}
#| eval: false
foo <- owid_search("annual") 
owid("annual-co2-emissions-by-region")
owid(foo[3])
```

### Mixed dumb

```{r}
#| message: false
#| echo: true
#| eval: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Scatterplot der Körperlängen zusammen mit den 95% Konfidenzintervall und dem *compact letter display*.
#| label: fig-cld-lmer

ggplot() +
  theme_bw() +
  geom_point(data = dragons_tbl, aes(x = body_length_cat, y = test_score)) +
  geom_text(data = res_lmer_cld, 
            aes(x = body_length_cat , y = estimate, label = .group),
            position = position_nudge(x = 0.2), color = "red") +
  geom_errorbar(data = res_lmer_cld,
                aes(ymin = conf.low, ymax = conf.high, x = body_length_cat),
                color = "red", width = 0.1,
                position = position_nudge(x = 0.1)) +
  geom_point(data = res_lmer_cld, 
             aes(x = body_length_cat , y = estimate),
             position = position_nudge(x = 0.1), color = "red") +
  scale_color_okabeito() +
  labs(x = "Körperlänge in Kategorien", y = "Testscore", 
       caption = "Schwarze Punkte stellen Rohdaten dar.
       Rote Punkte und Fehlerbalken stellen bereinigte Mittelwerte mit 95% Konfidenzgrenzen pro Behandlung dar.
       Mittelwerte, mit einem gemeinsamen Buchstaben, sind nicht signifikant unterschiedlich.")

```

```{r}
#| eval: false
gen_school <- defData(varname = "n_classes", dist = "nonrandom", formula = 3,
    id = "id_school")
gen_school <- defData(gen_school, varname = "s0", dist = "normal", formula = 0, variance = 3)
```

```{r}
#| eval: false
set.seed(282721)

dt_school <- genData(9, gen_school)
dt_school <- trtAssign(dt_school, n = 3, grpName = "trt")

dt_school
```

text

```{r}
#| eval: false
gen_class <- defDataAdd(varname = "n_students", dist = "nonrandom", formula = 5)
gen_class <- defDataAdd(gen_class, varname = "c0", dist = "normal", formula = 0, variance = 2)
```

```{r}
#| eval: false
dt_class <- genCluster(dt_school, "id_school", numIndsVar = "n_classes", level1ID = "id_class")
dt_class <- addColumns(gen_class, dt_class)

dt_class %<>% 
  add_column(trt_new = rep(1:3, 9))

head(dt_class)
```

text

```{r}
#| eval: false
gen_student <- defDataAdd(varname = "test", dist = "normal",
                          formula = "50 + s0 + c0 + 8 * trt", variance = 2)
dt_student <- genCluster(dt_class, cLevelVar = "id_class", numIndsVar = "n_students",
    level1ID = "id_child")

dt_student <- addColumns(gen_student, dt_student) %>% 
  mutate(id_class = as_factor(id_class),
         id_school = as_factor(id_school),
         trt = as_factor(trt),
         trt_new = as_factor(trt_new))
```

```{r}
#| eval: false
n_s <- 9
s_tbl <- tibble(s_id = 1:n_s,
                s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3)) %>% 
  expand_grid(c_per_s = 1:3)

foo <- tibble(s_id = 1:n_s,
       s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3),
             t_eff = rep(c(10, -10, 30), 3)) %>% 
  expand_grid(c_per_s = 1:3) %>% 
  mutate(c_id = 1:27,
         c_0 = rnorm(27, 0, 5)) %>% 
  expand_grid(reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + t_eff + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

foo %>% 
  ggplot(aes(trt, test, fill = s_id, group = c_id)) +
  theme_bw() +
  geom_boxplot() 

lmer_fit <- lmer(test ~ trt + (1|s_id) + (1|c_id), data = foo) 

lmer_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

```

```{r}
#| eval: false
expand_grid(tibble(s_id = 1:n_s,
                   s_0 = rnorm(n_s, 0, 2)),
            tibble(trt = 1:3,
                   trt_eff = c(10, -5, 20))) 



final_data <- s_tbl %>% 
  mutate(c_id = 1:27,
         c_0 = rnorm(27, 0, 5)) %>% 
  expand_grid(reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + 10 * trt + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

final_data %>% 
  ggplot(aes(trt, test, fill = s_id, group = c_id)) +
  theme_bw() +
  geom_boxplot() 
```

```{r}
#| eval: false
n_s <- 9
s_tbl <- tibble(s_id = 1:n_s,
                s_0 = rnorm(n_s, 0, 2)) %>% 
  add_column(trt = rep(1:3, 3)) 

c_tbl <- tibble(c_id = 1:3,
                c_0 = rnorm(3, 0, 5))


final_data <- s_tbl %>% 
  expand_grid(c_tbl,
              reps = 1:20) %>% 
  mutate(test = 50 + s_0 + c_0 + 8 * trt + rnorm(n(), 0, 2),
         s_id = as_factor(s_id),
         c_id = as_factor(c_id),
         trt = as_factor(trt))

final_data %>% 
  ggplot(aes(trt, test, fill = c_id)) +
  theme_bw() +
  geom_boxplot() +
  facet_wrap(~s_id)

```

```{r}
#| eval: false
dt_student %>% 
  ggplot(aes(id_class, test, fill = id_school, linetype = trt, color = trt)) +
  theme_bw() +
  geom_boxplot()


dt_student %>% 
  ggplot(aes(trt, test, fill = id_school, group = id_class)) +
  theme_bw() +
  geom_boxplot()
```

### Latent Class Analysis {.unnumbered}

Wie immer gibt es eine Reihe von Tutorien auf denen dieser Abschnitt aufbaut. Zum einen wirf einfach mal einen Blick in das Tutorium [Latent Class Analysis Using R](https://pop.princeton.edu/events/2020/latent-class-analysis-using-r). Eine leider etwas veraltete Übersicht über mögliche R Pakete liefert [Ways to do Latent Class Analysis in R](https://maksimrudnev.com/2016/12/28/latent-class-analysis-in-r/). Ich habe da immer mal quer geschaut und mich dann für die Pakete hier entschieden. Es gibt sicherlich noch andere Möglichkeiten eine *latent class analysis* zu rechnen.

Wenn du mehr über *latent class analysis* erfahren möchtest, dann kann ich dir nur das [LCA Frequently Asked Questions (FAQ)](https://www.john-uebersax.com/stat/faq.htm) empfehlen. Das FAQ ist sehr umfangreich und beschäftigt sich mit allen wichtigen Punkten. Wir wollen uns ja mit dem R Paket `poLCA` beschäftigen. Hier gibt es zwei Tutorien. Einmal gibt es das Tutorium [Example for a latent class analysis with the poLCA-package in R](https://statistics.ohlsen-web.de/latent-class-analysis-polca/) und das Tutroium [Latent Class Analysis](https://rpubs.com/eogawac/poLCA). Und natürlich die Litertur von @linzer2011polca mit der entsprechenden Veröffentlichung [poLCA: An R Package for Polytomous Variable Latent Class Analysis](https://www.sscnet.ucla.edu/polisci/faculty/lewis/pdf/poLCA-JSS-final.pdf)

Grundsätzlich basiert die *latent class analysis* nicht auf Distanzen sondern versucht über eine Modellierung der Klassenzugehörigkeitswahrscheinlichkeit getrennte Gruppen zu bilden. Wir wollen also $k$ Klassen haben und im idealen Fall können wir durch unsere Variablen in dem Datensatz jeweils mit einer 100% Wahrscheinlichkeit einer der drei Klassen zuordnen. Was dann diese $k$ Klassen aussagen, müssen wir dann selber anhand der zugewiesenen Variablen aus unseren Daten interpretieren.

```{r}
#| eval: false
pacman::p_load(tidyverse, magrittr, janitor, conflicted)

animals_tbl <- read_excel("data/cluster_animal.xlsx", sheet = 1) %>% 
  clean_names() 
```

```{r}
#| eval: false
pacman::p_load(poLCA)

poLCA(cbind(warm_blooded, fly, vertebrate, threatened, live_in_groups) ~ 1,
      nclass = 3,
      data = animals_tbl,
      nrep = 1,
      na.rm = FALSE,
      graphs = TRUE,
      maxiter = 100000
)

```

Hier hängen wir dann an der Interpretation. Da müssen wir nochmal tiefer schauen.

### Structural Equation Modeling {.unnumbered}

@van2023best [tidySEM](https://cjvanlissa.github.io/tidySEM/index.html)

[Structural Equation Modeling](https://bookdown.org/bean_jerry/using_r_for_social_work_research/structural-equation-modeling.html)

[Introduction to structural equation modeling (sem) in r with lavaan](https://stats.oarc.ucla.edu/r/seminars/rsem/)

[Intro to structural equation modeling](https://rpubs.com/Agrele/SEM)

Schöne Diagramme [Structural Equation Models](https://advstats.psychstat.org/book/sem/index.php)

### Autoregressive model {.unnumbered}

$$
AR = 
\begin{pmatrix}
 1 & \rho & \rho^2 & \rho^3 & \cdots & \rho^{n-1} \\
 \rho & 1 & \rho & \rho^2 & \cdots & \rho^{n-2} \\
 \rho & \rho^2 & 1 & \rho & \cdots & \rho^{n-3} \\
 \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
 \rho^{n-1} & \rho^{n-2} & \rho^{n-3} & \rho^{n-4} & \cdots & 1 \\
\end{pmatrix}
$$

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-time-ar-1
#| fig-align: center
#| fig-height: 6
#| fig-width: 8
#| fig-cap: "AR(0); AR(1) mit AR-Parameter 0.3; AR(1) mit AR-Parameter 0.9; AR(2) mit AR-Parameter 0.3 und 0.3; und AR(2) mit AR-Parameter 0.9 und -0.8."

set.seed(202318080)

plot_tbl <- map(lst(0.01, 0.3, 0.9, c(0.3, 0.3), c(0.2, 0.7)), \(x) {
  arima.sim(model = list(ar = x), n = 100) %>% 
    as_tibble() 
}) %>% 
  bind_cols() %>% 
  set_names(c("AR(0) 0", "AR(1) 0.3", "AR(1) 0.9", "AR(2) 0.3; 0.3", "AR(2) 0.9; -0.8")) %>% 
  mutate(index = 1:100) %>% 
  pivot_longer(cols = matches("AR"),
               values_to = "value",
               names_to = "key") %>% 
  mutate(key = as_factor(key))

ggplot(plot_tbl, aes(index, value, fill = key)) +
  theme_bw() +
  facet_wrap(~ key, nrow = 5, strip.position="right") + 
  geom_line() +
  geom_hline(yintercept = 0) +
  geom_ribbon(aes(ymin = ifelse(value <= 0, value, 0), 
                  ymax = ifelse(value >= 0, value, 0)), 
              alpha=0.5) +
  ylim(-5, 5) +
  labs(x = "", y = "") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        legend.position = "none", 
        strip.text = element_text(size = 10))

```

## Zitate {.unnumbered}

> *"One glance at a book and you hear the voice of another person perhaps someone dead for thousands of years. Across the millennia the author is speaking clearly and silently inside your head, directly to YOU." --- Carl Sagan*

> *"Zu tun, worauf man Lust hat, und nicht, was man muss -- das ist eines der ältesten und wichtigsten Ziele der Menschheit. Wir arbeiten hart daran, das zu verdrängen." --- Die Not des Müßiggangs, Magazin Brand Eins*

> *"If you feel safe in the area that you're working in, you're not working in the right area. Always go a little further into the water than you feel you're capable of being in. Go a little bit out of your depth, and when you don't feel that your feet are quite touching the bottom, you're just about in the right place to do something exciting." -- David Bowie*

> *"All models are approximations. Essentially, all models are wrong, but some are useful. However, the approximate nature of the model must always be borne in mind." --- George E. P. Box*

> *"Curiosity is the beginning of knowledge. Action is the beginning of change." --- James Clear*

> *"(1) Alles was es schon gab, als Du geboren wurdest, ist normal und gewöhnlich. Diese Dinge werden als natürlich wahrgenommen und halten die Welt am Laufen. (2) Alles was zwischen Deinem 16ten und 36ten Lebensjahr erfunden wird ist neu, aufregend und revoltionär. Und vermutlich kannst Du in dem Bereich sogar Karriere machen. (3) Alles was nach dem 36ten Lebensjahr erfunden wird ist gegen die natürliche Ordnung der Dinge." --- Douglas Adams, Per Anhalter durch die Galaxis*

> *"Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it." --- Brian Kernighan, professor at Princeton University.*

> *"The three stages of career development are: 1. I want to be in the meeting; 2. I want to run the meeting; 3. I want to avoid meetings." --- Jay Ferro*

## Links {.unnumbered}

[Analyzing reactor water level measurements in the Fukushima Daiichi 1 accident](https://www.sciencedirect.com/science/article/pii/S0149197023001427)

[sjPlot - Data Visualization for Statistics in Social Science](https://strengejacke.github.io/sjPlot/)

[The wages dataset](https://search.r-project.org/CRAN/refmans/QRegVCM/html/wages.html)

[Äther](https://de.wikipedia.org/wiki/%C3%84ther_(Physik))

## Steinbruch unsortierter Ideen {.unnumbered}

[Mathematical Tables Project](https://en.wikipedia.org/wiki/Mathematical_Tables_Project)

[10 Oldest Computers in The World](https://www.oldest.org/technology/computers/)

[The 2,500-Year-Old History of Adults Blaming the Younger Generation](https://historyhustle.com/2500-years-of-people-complaining-about-the-younger-generation/)

[Women And Children First: Technology And Moral Panic](https://www.wsj.com/articles/BL-TEB-2814)

Calvinismus

Sparen und Mutterbild

-   Bias (Survival Bias)

https://en.wikipedia.org/wiki/Bias

Survival Bias

https://de.wikipedia.org/wiki/Survivorship_Bias

[Biasarten](https://www.iqwig.de/sonstiges/glossar/biasarten.html)

Big Bang Theorie

https://stats.stackexchange.com/questions/555855/why-is-a-regression-coefficient-covariance-variance

https://denninginstitute.com/modules/dau/stat/regression/linregsn/nreg_6_frm.html#:\~:text=The%20Regression%20coefficient%20is%20defined,independent%20variable%2C%20x%20or%20y.

https://wiki.pathmind.com/eigenvector

https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues

Data Science

-   Real World Data @liu2022real
-   Warum **Data** Science @hariri2019uncertainty
-   Paradigmenwechsel?

Deutsches Sprichwort: Deutsch mit jemanden Reden; Verstehe nur Spanisch

Von den Daten zu Erkenntnis und zurück.

Wahrscheinlichkeitsbegriff sollte dann doch irgendwie bei Bayes mit rein...

> *"Gott würfelt nicht!" --- Albert Einstein*

-   [Frequentistischer Wahrscheinlichkeitsbegriff](https://de.wikipedia.org/wiki/Frequentistischer_Wahrscheinlichkeitsbegriff)
-   [Bayessche Wahrscheinlichkeitsbegriff](https://de.wikipedia.org/wiki/Bayesscher_Wahrscheinlichkeitsbegriff)

## Und heute? {.unnumbered}

Wie sieht es denn heute aus? Haben wir dort auch sehr viele Frauen, die sich in der Programmierung vortun? Leider nein. In der @fig-eda-preface-r-01 sehen wir den dramatischen Rückgang an Frauen in der Informatik und den Computerwissenschaften. Eigentlich bin ich ja hier schon zu spät dran mit meiner Lehre der Informatik und Programmierung, der größte Rückgang an Frauen wird schon in den früheren Jahren verursacht als ich junge Frauen unterrichte. Aber dennoch möchte ich hier natürlich dem Trend entgegenwirken. Nichtstun ist ja in so einem Fall auch keine wirkliche Option.

```{r}
#| warning: false
#| echo: false
#| message: false
#| label: fig-eda-preface-r-01
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Im Jahr 1995 waren 37 % der Informatiker Frauen. Heute sind es nur noch 24 %. Der Prozentsatz wird weiter sinken, wenn wir nichts tun. Wir wissen, dass der größte Rückgang von Mädchen in der Informatik im Alter zwischen 13 und 17 Jahren stattfindet. Quelle: [Girls who code](https://girlswhocode.com/about-us)"

data_tbl <- tibble(year = c(1995, 2017, 2022),
                   percent = c(0.34, 0.24, 0.22))

ggplot(data_tbl, aes(year, percent, label = scales::percent(percent))) +
  theme_minimal() +
  geom_line() +
  geom_ribbon(aes(ymin = 0.1, ymax = percent), fill = "#F0E442", alpha=0.7, position = "identity") +
  geom_label() + 
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = c(1995, 2017, 2022)) +
  labs(y = "% of women in Computer Science", x = "")

```

Was sind den die Gründe für das [Gap in der Informatik und der Computerwissenschaften](https://en.wikipedia.org/wiki/Gender_disparity_in_computing)? Hier gibt es ntürlich nicht den einen Grund, aber ich fand einen der Gründe besonders spannend.

Auch unterrichte ich weniger Informatik als [Computational statistics](https://en.wikipedia.org/wiki/Computational_statistics) oder eben aktuell Data Science - die Wisenschaft der Daten. Eigentlich gibt es nur noch Computational statistics,

[Admiral Grace Murray Hopper: When Women Were Computers](https://www.nationalww2museum.org/war/articles/grace-hopper-woman-computer)

[Girls who code](https://girlswhocode.com/)

## Referenzen {.unnumbered}
