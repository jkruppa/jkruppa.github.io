[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bio Data Science",
    "section": "",
    "text": "Auf den folgenden Seiten wirst du eine Menge über Statistik oder Data Science lernen. Du musst dafür nicht eine meiner Veranstaltungen besuchen. Gerne kannst du hier und dort einmal schauen, ob etwas für dich dabei ist. Das Skript wird fortlaufend von mir ergänzt. Neben dem Skript gibt es auch noch die erklärenden YouTube Videos. Ich freue mich, dass du Lust hast hier etwas zu lernen… oder aber du musst – da bald eine Klausur ansteht. Wie auch immer – schau dich einfach mal um. Im Anhang findest du auch einen kleinen Leitfaden für das Schreiben einer Abschlussarbeit. Vielleicht hilft dir die Anleitung ja beim Schreiben.\n\n\n\n\n\n\nGesammelte Klausurfragen Bio Data Science\n\n\n\n\n\nDu findest die gesammelten Klausurfragen auf GitHub. Die Klausurfragen zu den einzelnen Vorlesungen in einem Modul werden in den entsprechenden Übungen besprochen. Bitte komme in die Übungen.\n\n\n\n\n\nDu liest hier gerade das Skript für meine Vorlesungen an der Hochschule Osnabrück an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL). Wie immer Leben kannst du auf verschiedene Arten und Weisen den Stoff, den ich vermitteln will, lernen. Daher gibt es noch zwei andere Möglichkeiten. Zum einen Lernen auf YouTube, mit meinen Lernvideos oder du schaust dir das Material auf GitHub an. Auf GitHub habe ich auch Informationen, die du vielleicht brauchen kannst. Ebenso findest du im Kapitel 2 noch andere Literaturempfehlungen.\n\n\n\n\n\n\n\nWenn du möchtest kannst du auf YouTube unter https://www.youtube.com/c/JochenKruppa noch einige Lehrvideos als Ergänzung schauen. In den Videos wiederhole ich Inhalte und du kannst auf Pause drücken um nochmal Programmierschritte nachverfolgen zu können.\n\n\n\n\n\n\n\n\nAlle Materialien von mir findest du immer auf GitHub unter https://github.com/jkruppa/teaching. Selbst wenn du nicht mehr in einem meiner Kurse bist, kannst du so auf die Lehrinhalte immer nochmal zugreifen und die aktuellen Versionen haben. Auf GitHub liegt auch immer eine semesteraktuelle Version der gesammelten Klausurfragen für meine Module.\n\n\n\n\nWie erreichst du mich? Am einfachsten über die gute, alte E-Mail. Bitte bachte, dass gerade kurz vor den Prüfungen ich mehr E-Mails kriege. Leider kann es dann einen Tick dauern.\n\n\n\n\n\nEinfach an j.kruppa@hs-osnabrueck.de schreiben. Du findest hier auch eine kurze Formulierungshilfe. Einfach auf den Ausklapppfeil klicken.\nBitte gib immer in deiner E-Mail dein Modul - was du belegst - mit an. Pro Semester unterrichte ich immer drei sehr ähnlich klingende Module. Daher schau nochmal hier in der Liste, wenn du unsicher bist.\n\n\n\n\n\n\nE-Mailvorlage mit beispielhafter Anrede\n\n\n\n\n\nHallo Herr Kruppa,\n… ich belege gerade Ihr Modul Modulname und hätte eine Bitte/Frage/Anregung…\n… ich benötige Hilfe bei der Planung/Auswertung meiner Bachelorarbeit…\nMit freundlichen Grüßen\nM. Muster"
  },
  {
    "objectID": "organisation.html",
    "href": "organisation.html",
    "title": "1  Organisation",
    "section": "",
    "text": "Den Teil kannst du hier überspringen, wenn es dich nicht so richtig interessiert, was ich alles an Vorlesungen anbiete. Wenn es dir um statistische Inhalte geht, dann gehe einfach weiter in das nächste Kapitel."
  },
  {
    "objectID": "organisation.html#statistische-beratung",
    "href": "organisation.html#statistische-beratung",
    "title": "1  Organisation",
    "section": "1.1 Statistische Beratung",
    "text": "1.1 Statistische Beratung\nIch biete auch Termine für die statistische Beratung von Abschlussarbeiten sowie Projekten an. Dafür musst du mir einfach nur eine E-Mail schreiben und dann erhälst du einen Termin innerhalb der nächsten zwei Wochen.\nDie Beratung ist grundsätzlich anonym und vertraulich. Wenn du willst kannst du gerne noch dein:e Betreuer:in mitbringen. Das ist aber keine Voraussetzung oder Notwendigkeit."
  },
  {
    "objectID": "organisation.html#sec-r-tutorium",
    "href": "organisation.html#sec-r-tutorium",
    "title": "1  Organisation",
    "section": "1.2 R Tutorium",
    "text": "1.2 R Tutorium\nIm Rahmen der statistischen Beratung bieten wir auch ein R Tutorium für alle Mitglieder:innen der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) an. Die aktuellen Termine findest du in Tabelle 1.1.\nIm R Tutorium besprechen wir aktuelle Themen der Teilnehmer:innen. Meist sind dies aktuelle Fragen zu den BAchelorarbeiten. Auch wenn du kein dringendes Problem hats, kannst du gerne kommen und dir die Fragestellungen anhören. Bitte beachte folgende Hinweise zu den Terminen.\n\n\n\n\n\n\nHinweise zu dem R Tutorium\n\n\n\nDas R Tutorium findet nicht im Prüfungszeitraum der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) statt.\nDas R Tutorium findet nicht im Februar und März statt.\nDas R Tutorium findet nicht im August und September statt.\n\n\n\n\nTabelle 1.1— Aktuelle Termine des R Tutoriums im Semester\n\n\nTermin\nUhrzeit\nRaum\nAnmerkung\n\n\n\n\nnächste\nTermine\nab\nOktober 2022"
  },
  {
    "objectID": "organisation.html#sec-vorlesungen-hs",
    "href": "organisation.html#sec-vorlesungen-hs",
    "title": "1  Organisation",
    "section": "1.3 Vorlesungen an der Hochschule Osnabrück",
    "text": "1.3 Vorlesungen an der Hochschule Osnabrück\nVon mir angebotene Vorlesungen werden an der Hochschule Osnabrück an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) in ILIAS verwaltet. Alle notwendigen Informationen und Materialien sind auf ILIAS unter https://lms.hs-osnabrueck.de/ zu finden. Wenn du in dem Kurs nicht angemeldet bist, dann kontaktiere mich bitte per Mail. Auch die Kommunikation erfolgt von meiner Seite aus über ILIAS.\nAuf ILIAS findest du alle aktuellen Kursinformationen und erhälst auch die Mails, wenn Änderungen im Kursablauf stattfinden.\nWenn du nicht in der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL) studierst oder aber in einem Studiengang, der meine Module nicht anbietet, steht es dir natürlich frei, sich in meine Vorlesungen zu setzten. Du findest in Tabelle 1.2 eine Übersicht der angebotenen Module und auch die inhaltliche Ordnung nach Lernstufe. Bitte informiere dich in deinem Studierendensekretariat über die Modalitäten zur Prüfungsteilnahme.\nEine inhaltliche Übersicht findet sich auf dem Google Spreadsheet. Die Planung ist aktuell (Stand Sommer 2022) noch nicht abgeschlossen. Im Zweifel einfach bei mir einmal per Mail anfragen.\n\n\n\nTabelle 1.2— Angebotene Statistik Module an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL). Die Stufe gibt das Lernniveau an.\n\n\nStufe\nLandwirtschaft; Angewandte Pflanzenbiologie – Gartenbau, Pflanzentechnologie\nWirtschafts- ingenieurwesen Agrar / Lebensmittel\nBioverfahrenstechnik in Agrar- und Lebensmittelwirtschaft\nAngewandte Nutztier- und Pflanzenwissenschaften\n\n\n\n\n1\nMathematik und Statistik\nStatistik\nAngewandte Statistik für Bioverfahrenstechnik\n\n\n\n2\nAngewandte Statistik und Versuchswesen\nAngewandte Statistik und Versuchswesen\n\n\n\n\n3\nSpezielle Statistik und Versuchswesen\n\n\nBiostatistik"
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "2  Literatur",
    "section": "",
    "text": "Was ist gute Literatur? Immer schwer zu beurteilen. Im folgenden liste ich einige Literaturquellen auf. Zum einen basiert eine Menge von dem R Code auf Wickham (2016) zum Anderen möchtest du dich vielleicht nochmal rechts oder links weiter bilden. Du musst aber nicht um die Klausur bestehen zu können. Siehe es eher als ein Angebot.\nNeben diesem Modul musst du vermutlich noch andere Module belegen. Deshalb hier eine Auswahl Literatur, die dir helfen mag. Zum einen ist die Literatur anders geschrieben und zum anderen sind dort andere Imhalte."
  },
  {
    "objectID": "literature.html#parametrische-statistik",
    "href": "literature.html#parametrische-statistik",
    "title": "2  Literatur",
    "section": "2.1 Parametrische Statistik",
    "text": "2.1 Parametrische Statistik\n\n\n\n\n\nDormann (2013) liefert ein tolles deutsches Buch für die Vertiefung in die Statistik. Insbesondere wenn du wissenschaftlich Arbeiten willst weit über die Bachelorarbeit hinaus. Dormann baut in seinem Buch eine hervorragende Grundlage auf. Das Buch ist an der Hochschule Osnabrück kostenlos über den Link zu erhalten."
  },
  {
    "objectID": "literature.html#r-for-data-science",
    "href": "literature.html#r-for-data-science",
    "title": "2  Literatur",
    "section": "2.2 R for Data Science",
    "text": "2.2 R for Data Science\n\n\n\n\n\nWickham (2016) ist die Grundlage für die R Programmierung. Das Material von Wickahm findet sich kostenlos online unter https://r4ds.had.co.nz/ und https://www.tidyverse.org/. Wir werden uns hauptsächlich mit R wie es Wickham lehrt beschäftigen. Somit ist Wickham unsere Grundlage für R."
  },
  {
    "objectID": "literature.html#practical-statistics-for-data-scientists",
    "href": "literature.html#practical-statistics-for-data-scientists",
    "title": "2  Literatur",
    "section": "2.3 Practical Statistics for Data Scientists",
    "text": "2.3 Practical Statistics for Data Scientists\n\n\n\n\n\nBruce (2020) schreibt ein Buch für den Anwender. Ohne Vorkenntnisse ist das Buch vermutlich etwas schwer zu lesen. Dafür bietet das Buch aber nach einem Statistikkurs sehr gute Anknüpfungspunkte Richtung maschinelles Lernen und somit der Klassifikation. Das Buch ist auch hier in der englischen Version und hier in der deutschen Version zu erhalten. Beide Links benötigen den Zugang über die Hochschule Osnabrück."
  },
  {
    "objectID": "literature.html#data-science-for-agriculture-in-r",
    "href": "literature.html#data-science-for-agriculture-in-r",
    "title": "2  Literatur",
    "section": "2.4 Data Science for Agriculture in R",
    "text": "2.4 Data Science for Agriculture in R\n\n\n\n\n\nSchmidt liefert auf der Webseite https://schmidtpaul.github.io/DSFAIR/index.html eine tolle Sammlung an experimentellen Designs bzw. Versuchsanlagen samt der Auswertung in R. Ohne Vorkenntnisse schwer zu verstehen. Sollte aber nach einem Kurs Statistik dann möglich sein. Gerne hier auch mich fragen, dann können wir gemeinsam das passende Design raussuchen und besprechen."
  },
  {
    "objectID": "literature.html#odds-ends",
    "href": "literature.html#odds-ends",
    "title": "2  Literatur",
    "section": "2.5 Odds & Ends",
    "text": "2.5 Odds & Ends\n\n\n\n\n\nAm Ende dann noch eine Mathebuch von Weisberg zu finden unter https://jonathanweisberg.org/vip/. Eigentlich eher ein Buch über Wahrscheinlichkeiten und wenn ein Buch am Ende stehen muss, dann ist es dieses Buch. Ich finde es sehr spannend zu lesen, aber das ist dann vermutlich special intrest."
  },
  {
    "objectID": "literature.html#referenzen",
    "href": "literature.html#referenzen",
    "title": "2  Literatur",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nBruce, Peter, Andrew Bruce, und Peter Gedeck. 2020. Practical statistics for data scientists: 50+ essential concepts using R and Python. O’Reilly Media.\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer.\n\n\nWickham, Hadley, und Garrett Grolemund. 2016. R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "\n3  Einführung\n",
    "section": "",
    "text": "In diesem Kapitel nenne ich die wichtigsten Lernziele, die nach dem Lesen des Skriptes von dir erreicht worden sein sollten. Je nach besuchten Kurs kann natürlich nicht alles geschafft worden sein. So sehe diese Übersicht als Einführung für das was später kommt. Wenn du die Beispiele hir verstehst, dann hast du eine gute und solide Grundlage in Statistik und Bio Data Science."
  },
  {
    "objectID": "preface.html#ein-wort-der-warnung",
    "href": "preface.html#ein-wort-der-warnung",
    "title": "\n3  Einführung\n",
    "section": "Ein Wort der Warnung…",
    "text": "Ein Wort der Warnung…\nWenn du dieses Bild eines niedergeschlagenen Engels der Statistik siehst…\n\n\n\n\n… dann bedeutet der niedergeschlagene Engel der Statistik:\n\nWir opfern Genauigkeit für Anwendbarkeit. Ja, manchmal ist es eben statstisch nicht richtig was hier steht, aber aus Gründen der Anwendung fahren wir mal über den Engel drüber. Schade.\nWir sind hier Anfänger und Anwender. Später kannst du noch tiefer ins Detail gehen. Hier wollen wir die Grundlagen lernen. Das hat dann einen Preis an Richtigkeit.\nWir wollen fertig werden. Durch geschicktes Manövrieren können wir an einen Punkt kommen, wo kein statistischer Test mehr passt. Das wollen wir nicht. Deshalb zahlen wir hier auch einen Preis. Passt aber.\n\nDeshalb konzentrieren wir uns auf einige wichtige Lernziele, die wir jetzt einmal nacheinander durchgehen."
  },
  {
    "objectID": "preface.html#lernziel-1-eine-explorative-datananalyse-durchführen",
    "href": "preface.html#lernziel-1-eine-explorative-datananalyse-durchführen",
    "title": "\n3  Einführung\n",
    "section": "\n3.1 Lernziel 1: Eine explorative Datananalyse durchführen",
    "text": "3.1 Lernziel 1: Eine explorative Datananalyse durchführen\nGleich zu Beginn R Code zu zeigen und eine entsprechende Abbildung ist vielleicht ungewöhnlich, aber wir wollen zu dieser Abbildung 3.1 hin. In Abbildung 3.1 siehst du einen Boxplot. Und wie wir aus den Daten flea_dog_cat.xlsx einen Boxplot erstellen, das soll uns in den nächsten Kapitel beschäftigen. Dafür müssen wir nämlich eine Menge in dem Codeblock verstehen und dann auch Anwenden können. Und natürlich lernen was eigentlich ein Boxplot ist und was in einem Boxplot eigentlich dargestellt ist.\nData\n\n\n\n\nAbbildung 3.1— Boxplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nHier ist der Codeblock der in R die Abbildung 3.1 erstellt.\n\n## Einlesen von Daten aus Excel\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n## Umformen der <chr> Spalte in einen Factor <fct>\ndata_tbl <- data_tbl %>% \n  mutate(animal = as_factor(animal))\n\n## Auswählen der wichtigen Spalten für den Boxplot\ndata_tbl <- data_tbl %>% \n  select(animal, jump_length) \n\n## Generieren des Boxplots in ggplot()\nggplot(data_tbl, aes(x = animal, y = jump_length, \n                     fill = animal)) +\n  geom_boxplot() +\n  geom_jitter() +\n  labs(x = \"Tierart\", y = \"Sprungweite in [cm]\", \n       fill = \"Tierart\") +\n  scale_x_discrete(labels = c(\"Hund\", \"Katze\")) +\n  theme_bw()\n\nWir müssen nun folgende Dinge lernen um den Codeblock zu verstehen:\n\nWir müssen das Datenbeispiel verstehen. Was sind das eigentlich für Daten, die wir da abbilden? Was sind überhaupt Daten im Sinne der Statistik bzw. für R.\nWir müssen den R Code verstehen. Von einzelnen wichtigen Opertatoren wie -> und %\\>% zu dem den Unterschieden von Worten und Objekten.\nWie kriegen wir Daten aus Excel in R hinein? Wir können die Daten ja nicht einfach in R eintragen sondern haben die Daten ja meist in einer (Excel) Datei wie flea_dog_cat.xlsx.\nWas ist eigentlich ein Boxplot und welche statistsichen Maßzahlen werden hier eigentlich abgebildet?\nWie funktioniert eigentlich die Funktioen ggplot() mit der wir den Boxplot erstellt haben?\n\nAll diese Fragen und weitere Fragen, die sich diesen Fragen anschließen, wollen wir uns in den nächsten Kapitel anschauen. Leider kann ich hier nur linear schreiben. Deshalb musst du eventuell mal ein Kapitel wiederholen oder etwas quer lesen. Du kanst dir ja auch nicht immer alles auf einmal merken."
  },
  {
    "objectID": "preface.html#lernziel-2-rstudio-und-r",
    "href": "preface.html#lernziel-2-rstudio-und-r",
    "title": "\n3  Einführung\n",
    "section": "\n3.2 Lernziel 2: RStudio und R",
    "text": "3.2 Lernziel 2: RStudio und R\nUm Data Science durchführen zu können musst du etwas Programmieren können. Wir programmieren in R und nutzen die Software um Abbildungen zu erstellen und Analysen zu rechnen.\nWir arbeiten in R und nutzen dafür das RStudio. Führe einfach folgende Schritte aus um erst R zu installieren und dann das RStudio.\n\nR installieren unter https://cran.rstudio.com/\n\nRStudio installieren unter https://www.rstudio.com/products/rstudio/download/#download\n\n\nBitte die Reihenfolge beachten. Beide Schritte kannst du dir auch nochmals im Video anschauen oder aber du kommst in das R Tutorium was regelmäßig an der Hochschule Osnabrück von mir angeboten wird. Die Termine findest du im Kapitel 1.2.\n\n\n\n\n\n\nWas ist eigentlich RStudio und woher kriege ich das?\n\n\n\nDu findest auf YouTube Einführung in R - Teil 01 - Installation von RStudio und R als Video. Ich gehe in dem Video einmal alle wichtigen Schritte durch und so kannst du dir Rstudio und R installieren."
  },
  {
    "objectID": "preface.html#lernziel-3-statistische-versuche-verstehen",
    "href": "preface.html#lernziel-3-statistische-versuche-verstehen",
    "title": "\n3  Einführung\n",
    "section": "\n3.3 Lernziel 3: Statistische Versuche verstehen",
    "text": "3.3 Lernziel 3: Statistische Versuche verstehen\nWie funktioniert ein statistischer Versuch? Ich könnte auch wissenschaftliches Experiment schreiben, aber ein wissenschaftliches Experiment ist sehr abstrakt. Wir wollen ja einen Versuch durchführen und danach - ja was eigentlich? Was wollen wir nach dem Versuch haben? Meistens eine neue Erkenntnis. Um diese Erkenntnis zu validieren oder aber abzusichern nutzen wir Statistik. Dazu musst du noch wissen, dass wir eine spezielle Form der Statistik nutzen: die frequentistische Statistik.\nEine biologische Wiederholung beinhaltet ein neues Tier, Pflanze oder Mensch. Eine technische Wiederholung ist die gleiche Messung an dem gleichen Tier, Pflanze oder Mensch.\nWir nennen das Outcome auch Endpunkt, Response oder kurz \\(y\\).\nDie frequentistische Statistik basiert - wie der Name andeutet - auf Wiederholungen in einem Versuch. Daher der Name frequentistisch. Also eine Frequenz von Beobachtungen. Ist ein wenig gewollt, aber daran gewöhnen wir uns schon mal. Konkret, ein Experiment welches wir frequentistisch Auswerten wollen besteht immer aus biologischen Wiederholungen. Wir müssen also ein Experiment planen in dem wir wiederholt ein Outcome an vielen Tieren, Pflanzen oder Menschen messen. Auf das Outcome gehen wir noch später ein. Im Weiteren konzentrieren wir uns hier auf die parametrische Statistik. Die parametrische Statistik beschäftigt sich mit Parametern von Verteilungen. Ein schwieriger Satz. Schauen wir uns einmal eine Verteilung an.\n\n3.3.1 Possionverteilung\nAbbildung 3.2 zeigt eine Poissonverteilung. Eine Poissonverteilung beschreibt Zähldaten. Mehr zu der Poissonverteilung findest du im Kapitel 23. Wir zählen bei 39 Hunden wiviele Flöhe jeder Hund jeweils hatte. Danach zeichnen wir uns einen Dotplot der die Verteilung der Anzahl Flöhe auf den Hunden wiederspiegelt.\n\n\n\n\nAbbildung 3.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nParameter sind Zahlen, die eine Verteilungskurve beschreiben.\nEine Verteilung hat Parameter. Parameter sind die Eigenschaften einer Verteilung, die notwendig sind um eine Verteilung vollständig zu beschreiben.\nIm Falle der Possionverteilung brauchen wir nur einen Paramter für den höchsten Punkt der Kurve. Wir nennen diesen Punkt Lambda (\\(\\lambda\\)). Die Ausbreitung der Kurve ist eine Funktion von \\(\\lambda\\) und steigt mit \\(\\lambda\\) an.\n\n3.3.2 Normalverteilung\nAbbildung 3.3 zeigt eine Normalverteilung. Mehr zu der Poissonverteilung findest du im Kapitel 22. Hier haben wir das Flohgewicht von den Flöhen von 24 Hunden gemessen, die mit Flöhen befallen waren. Wir sehen, dass sich eine Glockenkurve bildet oder zumindestens etwas ähnliches. Wir können annehmen, dass das Gewicht approximativ normalverteilt ist.\nWir nutzen das Wort approximativ wenn wir sagen wollen, dass ein Outcome näherungsweise normalverteilt ist.\n\n\n\n\nAbbildung 3.3— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nIm Falle der Normalverteilung brauchen wir einen Paramter für den höchsten Punkt der Kurve, sowie einen Parameter für die Ausbreitung, also wie weit geht die Kurve nach links und nach rechts. Der Mittelwert \\(\\bar{y}\\) beschriebt den höchsten Punkt einer Normalverteilung. Die Standardabweichung \\(s_y\\) beschreibt die Ausbreitung einer Normalverteilung.\n\n\n\n\n\n\nWie gehen wir nun vor, wenn wir ein Experiment durchführen wollen?\n\n\n\n\nWir müssen auf jeden Fall wiederholt ein Outcome an verschiedenen Tieren, Pflanzen oder Menschen messen.\nWir überlegen uns aus welcher Verteilungsfamilie unser Outcome stammt, damit wir dann die entsprechende Verfahren zur Analyse nehmen können."
  },
  {
    "objectID": "preface.html#lernziel-4-falsifikationsprinzip",
    "href": "preface.html#lernziel-4-falsifikationsprinzip",
    "title": "\n3  Einführung\n",
    "section": "\n3.4 Lernziel 4: Falsifikationsprinzip",
    "text": "3.4 Lernziel 4: Falsifikationsprinzip\n\n\n\n\n\n\nGrundlagen der Wissenschaft und Falsifikationsprinzip\n\n\n\nDu findest auf YouTube Grundlagen der Wissenschaft und Falsifikationsprinzip als Video Reihe.\n\n\nWenn wir ein Experiment durchführen dann erheben wir einmalig Daten \\(D_1\\). Wir könnten das Experiment wiederholen und erneut Daten \\(D_2\\) erheben. Wir können das Experiment \\(j\\)-mal wiederholen und haben dann Daten von \\(D_1,..., D_j\\). Dennoch werden wir nie alle Daten erheben können, die mit einem Experiment verbunden sind.\nStrukturgleichkeit erreichen wir durch Randomisierung.\nNehmen wir das Beispiel, dass wir die Sprungweite von Hunde- und Katzenflöhen vergleichen wollen. Wir können nicht alle Hunde- und Katzenflöhe messen. Wir können nur eine Stichprobe an Daten \\(D_1\\) erheben. Über diese Daten \\(D_1\\) können wir dann später durch statistische Algorithmen eine Aussage treffen. Wichtig ist hier sich zu merken, dass wir eine Grundgesamtheit haben aus der wir eine Stichprobe ziehen. Wir müssen darauf achten, dass die Stichprobe repräsentativ ist und damit strukturgleich zur Grundgesamtheit ist. Die Strukturgleichkeit erreichen wir durch Randomisierung. Wir veranschaulichen diesen Zusammenhang in Abbildung 3.4. Ein Rückschluß von der Stichprobe ist nur möglich, wenn die Stichprobe die Grundgesamtheit repräsentiert. Auch eine Randomisierung mag dieses Ziel nicht immer erreichen. Im Beispiel der Hundeflöhe könnte wir eine Art an Flöhen übersehen und diese Flohart nicht mit in die Stichprobe aufnehmen. Ein Rückschluß auf diese Flohart wäre dann mit unserem Experiment nicht möglich.\n\n\nAbbildung 3.4— Abbildung über die Grundgesamtheit und die Stichprobe(n) \\(D_1\\) bis \\(D_j\\). Durch Randomisierung wird Sturkturgleichheit erreicht, die dann einen Rückschluß von der Stichprobe auf die Grundgesamtheit erlaubt. Jede Stichprobe ist anders und nicht jede Randomisierung ist erfolgreich was die Strukturgleicheit betrifft.\n\n\nTabelle 3.1 zeigt nochmal die Zusammenfassung von der Grundgesamtheit un der Stichprobe im Vergleich. Wichtig ist zu merken, dass wir mit unserem kleinen Experiment Daten \\(D\\) generieren mit denen wir einen Rückschluß und somit eine Verallgemeinerung erreichen wollen.\n\n\nTabelle 3.1— Vergleich von Grundgesamtheit und Stichprobe.\n\n\n\n\n\nGrundgesamtheit\nStichprobe\n\n\n\n… \\(n\\) ist riesig bis unfassbar.\n… \\(n\\) von \\(D\\) ist klein.\n\n\n… der Mittelwert wird mit \\(\\mu_y\\) beschrieben.\n… der Mittelwert wird mit \\(\\bar{y}\\) beschrieben.\n\n\n… die Varianz wird mit \\(\\sigma^2\\) beschrieben.\n… die Varianz wird mit \\(s^2\\) beschrieben.\n\n\n… die Standardabweichung wird mit \\(\\sigma\\) beschrieben.\n… die Standardabweichung wird mit \\(s\\) beschrieben."
  },
  {
    "objectID": "example-preface.html",
    "href": "example-preface.html",
    "title": "Datenbeispiele",
    "section": "",
    "text": "Wir brauchen am Anfang erstmal ein simples Beispiel. Konkrete Zahlen mit denen wir arbeiten können und Grundlagen aufbauen können. Was liegt da näher als sich einmal am Kopf zu kratzen und zu fragen, was juckt den da? Genau! Flöhe. Wir schauen uns einmal Flöhe auf Hunden und Katzen an. Daran können wir viel über Zahlen und Buchstaben in der Statistik und dann im Programmieren lernen."
  },
  {
    "objectID": "example-preface.html#von-flöhen-und-hunden",
    "href": "example-preface.html#von-flöhen-und-hunden",
    "title": "Datenbeispiele",
    "section": "Von Flöhen und Hunden",
    "text": "Von Flöhen und Hunden\nIn unserem ersten Beispiel in Kapitel 4 geht es darum einmal ein Gefühl für Daten zu kriegen. Also was sind diese Zahlen und Buchstaben eigentlich? Wie sind Daten aufgebaut und wie musst du Daten bauen, so dass wir auch mit den Daten arbeiten können? Wir schauen uns dafür einmal Flöhe auf Hunden an und fragen uns welche Typen von Zahlen können wir erheben?"
  },
  {
    "objectID": "example-preface.html#von-flöhen-hunden-und-katzen",
    "href": "example-preface.html#von-flöhen-hunden-und-katzen",
    "title": "Datenbeispiele",
    "section": "Von Flöhen, Hunden und Katzen",
    "text": "Von Flöhen, Hunden und Katzen\nIn unserem zweiten Beispiel in Kapitel 5 erweitern wir unserer erstes Beispiel aus Kapitel 4 um die Katzen. Das heist, dass eigentlich alles gleich bleibt. Wir schauen usn zusätlich noch als zweite Gruppe die Katzen an. Nun können wir die Frage stellen, unterscheiden sich Flöhe auf Hunden und Katzen gegeben von gemessenen Eigenschaften?"
  },
  {
    "objectID": "example-preface.html#von-flöhen-auf-tieren",
    "href": "example-preface.html#von-flöhen-auf-tieren",
    "title": "Datenbeispiele",
    "section": "Von Flöhen auf Tieren",
    "text": "Von Flöhen auf Tieren\nIn unserem dritten Beispiel in Kapitel 6 erweitern wir das Beispiel um den Fuchs mit einem weiteren Tier. Dadurch haben wir nicht mehr einen Faktor mit zwei Leveln vorliegen sondern einen mit drei Leveln. Die Fragestrellung erweitert sich jetzt auf einen multiplen Gruppenvergleich. Wir vergleichen nicht mehr nur noch zwei Gruppen miteinander sondern drei."
  },
  {
    "objectID": "example-preface.html#von-flöhen-auf-tieren-in-habitaten",
    "href": "example-preface.html#von-flöhen-auf-tieren-in-habitaten",
    "title": "Datenbeispiele",
    "section": "Von Flöhen auf Tieren in Habitaten",
    "text": "Von Flöhen auf Tieren in Habitaten\nIn unserem vierten Beispiel in Kapitel 7 schauen wir uns zusätzlich zu dem dritten Beispiel in Kapitel 6 noch verschiedene Habitate (eng. site) an. Wir haben nämlich die Hunde-, Katzen-, und Fuchsflöhe nicht nur an einem Ort sondern an verschiedenen Orten gesammelt und gemessen. Wir haben einen zweiten Faktor vorliegen."
  },
  {
    "objectID": "example-fleas-dogs.html",
    "href": "example-fleas-dogs.html",
    "title": "4  Von Flöhen und Hunden",
    "section": "",
    "text": "In unserem ersten Beispiel wollen wir uns verschiedene Daten \\(D\\) von Hunden und Hundeflöhen anschauen. Unter anderem sind dies die Sprungweite, die Anzahl an Flöhen, die Boniturnoten auf einer Hundemesse sowie der Infektionsstatus. Hier nochmal detailiert, was wir uns im folgenden im Kapitel einmal anschauen wollen.\n\nSprungweite in [cm] von verschiedenen Flöhen \\[\nY_{jump} = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}.\n\\]\nAnzahl an Flöhen auf verschiedenen Hunden \\[\n  Y_{count} = \\{18, 22, 17, 12, 23, 18, 21\\}.\n  \\]\nBoniturnoten [1 = schlechteste bis 9 = beste Note] von verschiedenen Hunden \\[\n  Y_{grade} = \\{8, 8, 6, 8, 7, 7, 9\\}.\n  \\]\nInfektionstatus [0 = gesund, 1 = infiziert] mit Flöhen von verschiedenen Hunden \\[\n  Y_{infected} = \\{0, 1, 1, 0, 1, 0, 0\\}.\n  \\]\n\nJe nachdem was wir messen, nimmt \\(Y\\) andere Zahlenräume an. Wir sagen, \\(Y\\) folgt einer Verteilung. Die Sprungweite ist normalverteilt, die Anzahl an Flöhen folgt einer Poisson Verteilung, die Boniturnoten sind multinominal/ordinal bzw. kategorial verteilt. Der Infektionsstatus ist binomial verteilt. Wir werden uns später die Verteilungen anschauen und visualisieren. Das können wir hier aber noch nicht. Wichtig ist, dass du schon mal gehört hast, dass \\(Y\\) unterschiedlich verteilt ist, je nachdem welche Dinge wir messen.\nTabelle 4.1 zeigt dir die Darstellung der Daten von oben in einer einzigen Tabelle. Bitte bachte, dass genau eine Zeile für eine Beobachutng, in diesem Fall einem Hund, vorgesehen ist.\n\n\n\n\nTabelle 4.1— Sprunglängen [cm] für Hundeflöhe. Die Tabelle ist im Long-Format dargestellt.\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n8\n1\n\n\ndog\n11.8\n17\n6\n1\n\n\ndog\n8.2\n12\n8\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\n\n\n\n\n\n\n\n\n\n\nDatei für von Flöhen und Hunden\n\n\n\nDu findest die Datei flea_dog.xlsx auf GitHub jkruppa.github.io/data/ als Excel oder auch als CSV."
  },
  {
    "objectID": "example-fleas-dogs-cats.html",
    "href": "example-fleas-dogs-cats.html",
    "title": "5  Von Flöhen, Hunden und Katzen",
    "section": "",
    "text": "Wir wollen jetzt das Beispiel von den Hunden und Flöhen um eine Spezies erweitern. Wir nehmen noch die Katzen mit dazu und fragen uns, wie sieht es mit der Sprungfähigkeit von Katzen und Hundeflöhen aus? Konzentrieren wir uns hier einmal auf die Sprungweite. Wir können wie in dem Beispiel 4 die Sprungweiten [cm] wieder aufschreiben:\n\\[\nY_{jump} = \\{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\\}.\n\\]\nWenn wir jetzt die Sprungweiten der Hundeflöhe mit den Katzenflöhen vergleichen wollen haben wir ein Problem. Beide Zahlenvektoren heißen gleich, nämlich \\(Y_{jump}\\). Wir könnten jeweils in die Indizes noch \\(dog\\) und \\(cat\\) schreiben als \\(Y_{jump,\\, dog}\\) und \\(Y_{jump,\\, cat}\\) und erhalten folgende Vektoren.\n\\[\nY_{jump,\\, dog} = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}\n\\]\n\\[\nY_{jump,\\, cat} = \\{3.2, 2.2, 5.4, 4.1, 4.3, 7.9, 6.1\\}\n\\]\nDadurch werden die Indizes immer länger und unübersichticher. Auch das \\(Y\\) einfach \\(Y_{dog}\\) oder \\(Y_{cat}\\) zu nennen ist keine Lösung - wir wollen uns vielleicht später nicht nur die Sprungweite vergleichen, sondern vielleicht auch die Anzahl an Flöhen oder den Infektionsstatus. Dann ständen wir wieder vor dem Problem die \\(Y\\) für die verschiedenen Outcomes zu unterscheiden. Daher erstellen wir uns die Tabelle 5.1. Wir haben jetzte eine Datentabelle.\n\n\n\n\nTabelle 5.1— Sprunglängen [cm] für Hunde- und Katzenflöhe. Die Tabelle ist im Wide-Format dargestellt.\n\ndog\ncat\n\n\n\n5.7\n3.2\n\n\n8.9\n2.2\n\n\n11.8\n5.4\n\n\n8.2\n4.1\n\n\n5.6\n4.3\n\n\n9.1\n7.9\n\n\n7.6\n6.1\n\n\n\n\n\n\nIntuitiv ist die Tabelle 5.1 übersichtlich und beinhaltet die Informationen die wir wollten. Dennoch haben wir das Probem, das wir in dieser Tabelle 5.1 nicht noch weitere Outcomes angeben können. Wir können die Anzahl an Flöhen auf den Hunde und Katzen nicht darstellen. Als Lösung ändern wir die Tabelle 5.1 in das Long-Format. Dargestellt in Tabelle 5.2. Jede Beobachtung belegt nun eine Zeile. Dies ist sehr wichtig im Kopf zu behalten, wenn du eigene Daten in z.B. Excel eingibts.\n\n\n\n\nTabelle 5.2— Tabelle der Sprunglängen [cm], Anzahl an Flöhen, Boniturnote sowie der Infektionsstatus von Hunde- und Katzenflöhe. Die Tabelle ist im Long-Format dargestellt.\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n8\n1\n\n\ndog\n11.8\n17\n6\n1\n\n\ndog\n8.2\n12\n8\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n7\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n6\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n5\n0\n\n\n\n\n\n\n\n\n\n\n\n\nDatei für von Flöhen, Hunden und Katzen\n\n\n\nDu findest die Datei flea_dog_cat.xlsx auf GitHub jkruppa.github.io/data/ als Excel oder auch als CSV."
  },
  {
    "objectID": "example-fleas-dogs-cats-foxes.html",
    "href": "example-fleas-dogs-cats-foxes.html",
    "title": "6  Von Flöhen auf Tieren",
    "section": "",
    "text": "Wir wollen jetzt das Beispiel von den Hunde- und Katzenflöhen um eine weitere Spezies erweitern. Wir nehmen noch die Füchse mit dazu und fragen uns, wie sieht es mit der Sprungfähigkeit von Hunde-, Katzen- und Fuchsflöhen aus?\n\n\n\n\nTabelle 6.1— Sprunglängen [cm] für Hunde-, Katzen- und Fuchsflöhe.\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n8\n1\n\n\ndog\n11.8\n17\n6\n1\n\n\ndog\n8.2\n12\n8\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n7\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n6\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n5\n0\n\n\nfox\n12.1\n21\n5\n1\n\n\nfox\n13.2\n25\n4\n1\n\n\nfox\n14.1\n31\n4\n1\n\n\nfox\n9.7\n12\n5\n1\n\n\nfox\n10.6\n28\n4\n0\n\n\nfox\n11.5\n18\n4\n1\n\n\nfox\n10.8\n19\n3\n0\n\n\n\n\n\n\n\n\n\n\n\n\nDatei für von Flöhen auf Tieren\n\n\n\nDu findest die Datei flea_dog_cat_fox.xlsx auf GitHub jkruppa.github.io/data/ als Excel oder auch als CSV."
  },
  {
    "objectID": "example-fleas-dogs-cats-foxes-site.html",
    "href": "example-fleas-dogs-cats-foxes-site.html",
    "title": "7  Von Flöhen auf Tieren in Habitaten",
    "section": "",
    "text": "Wir schauen uns in diesem Beispiel wiederum drei Tierarten an: Hunde, Katzen und Füchse. Auf diesen Tierarten messen wir die Sprunglänge von jeweils zehn Tieren. Im Vergleich zu dem vorherigen Beispiel erweitern wir die Daten um eine Spalte site in der wir vier verschiedene Messorte protokollieren. Es ergibt sich folgende Tabelle 7.1 und die dazugehörige Abbildung 7.1.\n\n\n\n\n\n\n\nTabelle 7.1— Sprunglängen [cm] für Hunde-, Katzen- und Fuchsflöhe in verschiedenen Habitaten.\n\nanimal\nsite\nrep\njump_length\n\n\n\ncat\ncity\n1\n12.04\n\n\ncat\ncity\n2\n11.98\n\n\ncat\ncity\n3\n16.10\n\n\ncat\ncity\n4\n13.42\n\n\ncat\ncity\n5\n12.37\n\n\ncat\ncity\n6\n16.36\n\n\ncat\ncity\n7\n14.91\n\n\ncat\ncity\n8\n11.17\n\n\ncat\ncity\n9\n12.38\n\n\ncat\ncity\n10\n15.06\n\n\ncat\nsmalltown\n1\n15.24\n\n\ncat\nsmalltown\n2\n13.36\n\n\ncat\nsmalltown\n3\n15.08\n\n\ncat\nsmalltown\n4\n12.83\n\n\ncat\nsmalltown\n5\n14.68\n\n\ncat\nsmalltown\n6\n10.73\n\n\ncat\nsmalltown\n7\n13.35\n\n\ncat\nsmalltown\n8\n14.54\n\n\ncat\nsmalltown\n9\n12.99\n\n\ncat\nsmalltown\n10\n14.51\n\n\ncat\nvillage\n1\n17.59\n\n\ncat\nvillage\n2\n11.24\n\n\ncat\nvillage\n3\n12.44\n\n\ncat\nvillage\n4\n13.63\n\n\ncat\nvillage\n5\n14.92\n\n\ncat\nvillage\n6\n17.43\n\n\ncat\nvillage\n7\n18.30\n\n\ncat\nvillage\n8\n16.35\n\n\ncat\nvillage\n9\n16.34\n\n\ncat\nvillage\n10\n14.23\n\n\ncat\nfield\n1\n13.70\n\n\ncat\nfield\n2\n15.13\n\n\ncat\nfield\n3\n17.99\n\n\ncat\nfield\n4\n14.60\n\n\ncat\nfield\n5\n16.16\n\n\ncat\nfield\n6\n14.26\n\n\ncat\nfield\n7\n15.39\n\n\ncat\nfield\n8\n16.85\n\n\ncat\nfield\n9\n19.02\n\n\ncat\nfield\n10\n18.76\n\n\ndog\ncity\n1\n19.35\n\n\ndog\ncity\n2\n17.10\n\n\ndog\ncity\n3\n19.85\n\n\ndog\ncity\n4\n15.33\n\n\ndog\ncity\n5\n15.15\n\n\ndog\ncity\n6\n19.57\n\n\ndog\ncity\n7\n15.44\n\n\ndog\ncity\n8\n16.09\n\n\ndog\ncity\n9\n15.91\n\n\ndog\ncity\n10\n13.01\n\n\ndog\nsmalltown\n1\n17.72\n\n\ndog\nsmalltown\n2\n17.11\n\n\ndog\nsmalltown\n3\n17.57\n\n\ndog\nsmalltown\n4\n17.12\n\n\ndog\nsmalltown\n5\n16.02\n\n\ndog\nsmalltown\n6\n22.61\n\n\ndog\nsmalltown\n7\n16.49\n\n\ndog\nsmalltown\n8\n18.64\n\n\ndog\nsmalltown\n9\n17.21\n\n\ndog\nsmalltown\n10\n19.90\n\n\ndog\nvillage\n1\n16.60\n\n\ndog\nvillage\n2\n15.28\n\n\ndog\nvillage\n3\n16.91\n\n\ndog\nvillage\n4\n15.08\n\n\ndog\nvillage\n5\n18.56\n\n\ndog\nvillage\n6\n16.34\n\n\ndog\nvillage\n7\n17.61\n\n\ndog\nvillage\n8\n14.80\n\n\ndog\nvillage\n9\n17.52\n\n\ndog\nvillage\n10\n16.93\n\n\ndog\nfield\n1\n15.78\n\n\ndog\nfield\n2\n17.02\n\n\ndog\nfield\n3\n15.41\n\n\ndog\nfield\n4\n15.61\n\n\ndog\nfield\n5\n19.87\n\n\ndog\nfield\n6\n19.24\n\n\ndog\nfield\n7\n17.65\n\n\ndog\nfield\n8\n18.83\n\n\ndog\nfield\n9\n17.60\n\n\ndog\nfield\n10\n14.67\n\n\nfox\ncity\n1\n19.50\n\n\nfox\ncity\n2\n18.49\n\n\nfox\ncity\n3\n19.78\n\n\nfox\ncity\n4\n19.45\n\n\nfox\ncity\n5\n21.56\n\n\nfox\ncity\n6\n21.37\n\n\nfox\ncity\n7\n18.64\n\n\nfox\ncity\n8\n20.08\n\n\nfox\ncity\n9\n21.62\n\n\nfox\ncity\n10\n20.68\n\n\nfox\nsmalltown\n1\n19.81\n\n\nfox\nsmalltown\n2\n17.78\n\n\nfox\nsmalltown\n3\n19.65\n\n\nfox\nsmalltown\n4\n16.38\n\n\nfox\nsmalltown\n5\n17.46\n\n\nfox\nsmalltown\n6\n17.02\n\n\nfox\nsmalltown\n7\n19.38\n\n\nfox\nsmalltown\n8\n15.89\n\n\nfox\nsmalltown\n9\n17.15\n\n\nfox\nsmalltown\n10\n17.43\n\n\nfox\nvillage\n1\n15.32\n\n\nfox\nvillage\n2\n17.59\n\n\nfox\nvillage\n3\n15.70\n\n\nfox\nvillage\n4\n18.58\n\n\nfox\nvillage\n5\n16.85\n\n\nfox\nvillage\n6\n18.25\n\n\nfox\nvillage\n7\n18.75\n\n\nfox\nvillage\n8\n16.96\n\n\nfox\nvillage\n9\n13.38\n\n\nfox\nvillage\n10\n18.38\n\n\nfox\nfield\n1\n16.85\n\n\nfox\nfield\n2\n13.55\n\n\nfox\nfield\n3\n13.89\n\n\nfox\nfield\n4\n15.67\n\n\nfox\nfield\n5\n16.38\n\n\nfox\nfield\n6\n14.59\n\n\nfox\nfield\n7\n14.03\n\n\nfox\nfield\n8\n13.63\n\n\nfox\nfield\n9\n14.09\n\n\nfox\nfield\n10\n15.52\n\n\n\n\n\n\nÜber die explorative Datenanalyse erfährst du mehr im Kapitel 15\nDie Datentabelle ist in dieser Form schon fast nicht mehr überschaubar. Daher hilft hier die explorative Datenanalyse weiter. Wir schauen uns daher die Daten einmal als einen Boxplot in Abbildung 7.1 an. Wir sehen hier, dass wir drei Tierarten an vier Orten die Sprungweite in [cm] gemessen haben.\n\n\n\n\nAbbildung 7.1— Boxplot der Sprungweiten [cm] für Hunde-, Katzen- und Fuchsflöhe in verschiedenen Habitaten.\n\n\n\n\n\n\n\n\n\n\nDatei für von Flöhen auf Tieren in Habitaten\n\n\n\nDu findest die Datei flea_dog_cat_fox_site.xlsx auf GitHub jkruppa.github.io/data/ als Excel oder auch als CSV."
  },
  {
    "objectID": "example-outro.html",
    "href": "example-outro.html",
    "title": "8  Zusammenfassung",
    "section": "",
    "text": "Nun haben wir Tabelle 5.2 mit Daten zu verschiedenen Oucomes, wie Sprungweite [cm], Anzahl an Flöhen auf Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus.\nDie Tabelle 5.2 ist zwar nicht groß aber auch nicht wirklich klein. In den nächsten Kapitel wollen wir uns damit beschäftigen, die Zahlen in der Tabelle sinnvoll zusammenzufassen.\nTeilweise benötigen wir die Beispiele in unterschiedlichen Kontexten. Je nachdem kannst du hier nochmal zurück schauen. Du findest die alle Dateien auf GitHub unter jkruppa.github.io/data/ als Excel oder auch als CSV. Oder aber auf ILIAS, wenn du gerade eine Vorlesung bei mir an der Hochschule Osnabrück besuchst."
  },
  {
    "objectID": "programing-preface.html",
    "href": "programing-preface.html",
    "title": "Programmieren in R",
    "section": "",
    "text": "Im vorherigen Kapitel zu den Beispielen haben wir die Datentabelle Tabelle 5.2 mit den Hunde- und Katzenflöhen erschaffen. Bevor wir uns weiter mit statistischen Kennzahlen beschäftigen, wollen wir uns einmal die Realisierung der Tabelle Tabelle 5.2 mit den Hunde- und Katzenflöhen in R anschauen. Dabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu können. Wir wollen später R nutzen um die explorative Datenanalyse anzuwenden. Über die explorative Datenanalyse lernen wir in späteren Kapiteln mehr.\n\n\n\n\n\n\nEinführung in R per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "programing-letters-numbers.html",
    "href": "programing-letters-numbers.html",
    "title": "9  Von Buchstaben und Zahlen",
    "section": "",
    "text": "Im Kapitel 5 haben wir uns folgende Daten in Tabelle 9.1 angeschaut. Bevor wir uns weiter mit statistischen Kennzahlen beschäftigen, wollen wir uns einmal die Realisierung der Tabelle Tabelle 9.1 in R anschauen. Das heist, wie ist eine Tabelle in R aufgebaut und was sehen wir da eigentlich?\nDabei wollen wir auch Eigenschaften von Zahlen und Buchstaben lernen, die notwendig sind um mit einem Programm wie R kommunizieren zu können. Nun haben wir Tabelle Tabelle 9.1 mit Daten zu verschiedenen Oucomes, wie Sprungweite [cm], Anzahl an Flöhen auf Hunden und Katzen, die Boniturnoten oder aber den Infektionsstatus. Die Tabelle Tabelle 9.1 ist zwar nicht groß aber auch nicht wirklich klein. Wir wollen uns nun damit beschäftigen, die Zahlen sinnvoll in R darzustellen. Wir wollen mit der Darstellung einer Datentabelle in R beginnen, einem tibble()."
  },
  {
    "objectID": "programing-letters-numbers.html#daten-in-r-sind-tibble",
    "href": "programing-letters-numbers.html#daten-in-r-sind-tibble",
    "title": "9  Von Buchstaben und Zahlen",
    "section": "\n9.1 Daten in R sind tibble()\n",
    "text": "9.1 Daten in R sind tibble()\n\nIm folgenden sehen wir die Datentabelle Tabelle 9.1 in R als tibble dargestellt. Was ist nun ein tibble? Ein tibble ist zu aller erst ein Speicher für Daten in R. Das heist wir haben Spalten und Zeilen. Jede Spalte repräsentiert eine Messung oder Variable und die Zeilen jeweils eine Beobachtung.\n\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <int> <dbl> <lgl>   \n 1 dog            5.7         18     8 FALSE   \n 2 dog            8.9         22     8 TRUE    \n 3 dog           11.8         17     6 TRUE    \n 4 dog            8.2         12     8 FALSE   \n 5 dog            5.6         23     7 TRUE    \n 6 dog            9.1         18     7 FALSE   \n 7 dog            7.6         21     9 FALSE   \n 8 cat            3.2         12     7 TRUE    \n 9 cat            2.2         13     5 FALSE   \n10 cat            5.4         11     7 FALSE   \n11 cat            4.1         12     6 FALSE   \n12 cat            4.3         16     6 TRUE    \n13 cat            7.9          9     6 FALSE   \n14 cat            6.1          7     5 FALSE   \n\n\nAls erstes erfahren wir, dass wir einen A tibble: 14 x 5 vorliegen haben. Das heist, wir haben 14 Zeile und 5 Spalten. In einem tibble wird immer in der ersten Zeile angezeigt wieviele Beobachtungen wir in dem Datensatz haben. Wenn das tibble zu groß wird, werden wir nicht mehr das ganze tibble sehen sondern nur noch einen Ausschnitt. Im Weiteren hat jede Spalte noch eine Eigenschaft unter dem Spaltennamen:\n\n\n<chr> bedeutet character. Wir haben also hier Worte vorliegen.\n\n<dbl> bedeutet double. Ein double ist eine Zahl mit Kommastellen.\n\n<int> bedeutet integer. Ein integer ist eine ganze Zahl ohne Kommastellen.\n\n<lgl> bedeutet logical oder boolean. Hier gibt es nur die Ausprägung wahr oder falsch. Somit TRUE oder FALSE. Statt den Worten TRUE oder FALSE kann hier auch 0 oder 1 stehen.\n\n<str> bedeutet string der aus verschiedenen character besteht kann, getrennt durch Leerzeichen.\n\n\n\n\n\n\n\nZahlen, Buchstaben, Skalenniveau - Was ist das eigentlich?\n\n\n\nDu findest auf YouTube Einführung in R - Teil 06 - Zahlen, Buchstaben, Skalenniveau - Was ist das eigentlich? als Video. Hier erkläre ich den Zusammenhang nochmal in einem Video."
  },
  {
    "objectID": "programing-letters-numbers.html#faktoren-als-wörter-zu-zahlen",
    "href": "programing-letters-numbers.html#faktoren-als-wörter-zu-zahlen",
    "title": "9  Von Buchstaben und Zahlen",
    "section": "\n9.2 Faktoren als Wörter zu Zahlen",
    "text": "9.2 Faktoren als Wörter zu Zahlen\nEin Faktor ist eine Variable mit mehrern Faktorstufen oder Leveln. Für uns sieht der Faktor wie ein Wort aus, hinter jedem Wort steht aber eine Zahl mit der gerechnet werden kann.\nEin Computer und somit auch eine Programmsprache wie R kann keine Buchstaben verrechnen. Ein Programm kann nur mit Zahlen rechnen. Wir haben aber in der Datentabelle Tabelle 9.1 in der Spalte animal Buchstaben stehen. Da wir hier einen Kompromiss eingehen müssen führen wir Faktoren ein. Ein Faktor kombiniert Buchstaben mit Zahlen. Wir als Anwender sehen die Buchstaben, die Wörter bilden. Intern steht aber jedes Wort für eine Zahl, so dass R mit den Zahlen rechnen kann. Klingt ein wenig kryptisch, aber wir schauen uns einen factor einmal an.\n\ndata_tbl$animal[1:8]\n\n[1] \"dog\" \"dog\" \"dog\" \"dog\" \"dog\" \"dog\" \"dog\" \"cat\"\n\n\nWas haben wir gemacht? Als erstes haben wir die Spalte animal aus dem Datensatz data_tbl mit dem Dollarzeichen $ herausgezogen. Mit dem $ Zeichen können wir uns eine einzelne Spalte aus dem Datensatz data_tbl rausziehen. Du kannst dir das $ wie einen Kleiderbügel und das data_tbl als einen Schrank für Kleiderbügel verstellen. An dem Kleiderbügel hängen dann die einzelnen Zahlen und Worte. Wir nehmen aber nicht den ganzen Vektor sondern nur die Zahlen 1 bis 8, dargestellt durch [1:8]. Die Gänsefüße \" um dog zeigen uns, dass wir hier Wörter oder charactervorliegen haben. Schauen wir auf das Ergebnis, so erhalten wir sieben Mal dog und einmal cat. Insgesamt die ersten acht Einträge der Datentabelle. Wir wollen diesen Vektor uns nun einmal als Faktor anschauen. Wir nutzen die Funktion as_factor(). Über Funktionen kannst du im Kapitel 10.3 mehr erfahren.\n\nas.factor(data_tbl$animal[1:8])\n\n[1] dog dog dog dog dog dog dog cat\nLevels: cat dog\n\n\nIm direkten vergleich verschwinden die Gänsefüße \" um dog und zeigen usn, dass wir hier keine character mehr vorliegen haben. Darüber hinaus sehen wir auch, dass die der Faktor jetzt Levels hat. Exakt zwei Stück. Jeweils einen für dog und einen für cat. Wir werden später Faktoren benötigen, wenn wir zum Beispiel eine einfaktorielle ANOVA rechnen. Hier siehst du schon den Begriff Faktor wieder.\n\n\nWir brauchen später zum Modellieren einen Datensatz, der meist aus einer Outcome-Spalte, einer Faktor-Spalte mit der Behandlung und einer Faktor-Spalte mit dem Block oder Cluster besteht.\n\\[\n{\\small Outcome \\sim Behandlung + Block}\n\\]"
  },
  {
    "objectID": "programing-letters-numbers.html#von-wörtern-und-objekten",
    "href": "programing-letters-numbers.html#von-wörtern-und-objekten",
    "title": "9  Von Buchstaben und Zahlen",
    "section": "\n9.3 Von Wörtern und Objekten",
    "text": "9.3 Von Wörtern und Objekten\nDas mag etwas verwirrend sein, denn es gibt in R Wörter string <str> oder character <chr>. Wörter sind was anderes als Objekte. Streng genommen sind beides Wörter, aber in Objekten werden Dinge gespeichert wohin gegen das Wort einfach ein Wort ist. Deshalb kennezeichnen wir Wörter auch mit Gänsefüßchen als win \"wort\" und zeigen damit, dass es sich hier um einen String handelt.\nWir tippen \"animal\" in R und erhalten \"animal\" als Wort zurück. Das sehen wir auch an dem Ausdruck mit den Gänsefüßchen.\n\n\"animal\"\n\n[1] \"animal\"\n\n\nÜber den Zuweisungspfeil <- kannst du im Kapitel 10.4 mehr erfahren.\nWir tippen animal ohne die Anführungszeichen in R und erhalten den Inhalt von animal ausgegeben. Dafür müssen wir aber das Objekt animal erst einmal über den Zuweisungspfeil <-erschaffen.\n\nanimal <- c(\"dog\", \"cat\", \"fox\")\nanimal\n\n[1] \"dog\" \"cat\" \"fox\"\n\n\nSollte es das Objekt animal nicht geben, also nicht über den Zuweisungspfeil <- erschaffen worden, dann wird eine Fehlermeldung von R ausgegeben:\nFehler in eval(expr, envir, enclos) : Objekt 'animal' nicht gefunden"
  },
  {
    "objectID": "programing-letters-numbers.html#zusammenfassung",
    "href": "programing-letters-numbers.html#zusammenfassung",
    "title": "9  Von Buchstaben und Zahlen",
    "section": "\n9.4 Zusammenfassung",
    "text": "9.4 Zusammenfassung\nVariablennamen meint hier immer den Namen der Spalte im Datensatz bzw. tibble\nTabelle 9.2 zeigt eine Übersicht wie einzelne Variablennamen und deren zugehörigen Beispielen sowie den Namen in R, der Informatik allgemein, als Skalenneivau und welcher Verteilungsfamilie die Variable angehören würde. Leider ist es so, dass wieder gleiche Dinge unterschiedliche benannt werden. Aber an dieses doppelte Benennen können wir uns in der Statistik schonmal gewöhnen.\n\n\n\nTabelle 9.2— Zusammenfassung und Übersicht von Variablennamen und deren Bennung in R, in der Informatik allgemein, als Skalenniveau und die dazugehörige Verteilungsfamilie.\n\n\n\n\n\n\n\n\n\nVariablenname\nBeispiel\nR\nInfomatik\nSkalenniveau\nVerteilungsfamilie\n\n\n\nweight\n12.3, 12.4, 5.4, 21.3, 13.4\nnumeric\ndouble\ncontinuous\nGaussian\n\n\ncount\n5, 0, 12, 23, 1, 4, 21\ninteger\ninteger\ncontinuous\nPoisson\n\n\ndosis\nlow, mid, high\nordered\n\ncategorical / discrete / ordinal\nOrdinal\n\n\nfield\nmainz, berlin, kiel\nfactor\n\ncategorical / discrete\nMultinomial\n\n\ncancer\n0, 1\nfactor\n\ndichotomous / binary / nominal\nBinomial\n\n\ntreatment\n“placebo”, “aspirin”\ncharacter\ncharacter/string\ndichotomous / binary / nominal\nBinomial\n\n\nbirth\n2001-12-02, 2005-05-23\ndate"
  },
  {
    "objectID": "programing-basics.html",
    "href": "programing-basics.html",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "",
    "text": "Es ist immer schwierig, wann die Grundlagen von R einmal gelehrt werden sollte. Wenn du nichts von Programmierung bis jetzt gehört hast, dann mag es keinen Sinn ergeben mit Operatoren, wie dem Zuweisungspfeil <- und der Pipe %>% zu beginnen. Wir brauchen aber für die Programmierung folgende zentrale Konzepte."
  },
  {
    "objectID": "programing-basics.html#sec-R-packages",
    "href": "programing-basics.html#sec-R-packages",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.1 Pakete und library()\n",
    "text": "10.1 Pakete und library()\n\nAls Vanilla beschreibt man in der Informatikerwelt ein Programm, was keine zusätzlichen Pakete geladen hat. Also die reinst Form ohne zusätzlichen Geschmack.\nIn der Vanilla-Variante hat R sehr wenige Funktionen. Ohne zusätzliche Pakete ist R mehr ein sehr potenter Taschenrechner. Leider mit der Funktionalität aus den 90’zigern, was die Programmierumgebung und die Funktionen angeht. Das wollen wir aber nicht. Wir wollen auf den aktuellen Stand der Technik und auch Sprache programmieren. Daher nutzen wir zusätzliche R Pakete.\n\n\nAbbildung 10.1— Auf den Reiter Packages klicken und dann Install. In der deutschen version vom RStudio mögen die Begriffe leicht anders sein.\n\n\nIn Abbildung 10.1 wird gezeigt wie du ein zusätzliches Paket installieren kannst. Hierbei ist nochmal wichtig den semantischen Unterschied zu wissen. Es gibt das Paket tidyverse was wir viel nutzen. Wir isnatllieren einmalig Pakete der Funktion install.packages() oder eben wie in Abbildung 10.1 gezeigt. Wir nutzen die Funktion library() um ein Paket in R zu laden. Ja, es müsste anders heisen, tut es aber nicht.\n\n## Das Paket tidyverse installieren - einmalig\ninstall.packages(tidyverse)\n\n## Das Paket tidyverse laden - jedes Mal\nlibrary(tidyverse)\n\nNun muss man sich immer merken, ob das Paket schon installiert ist oder man schreibt relativ viele library() untereinander. Das passiert schnell, wenn du viele Pakete laden willst. Dafür erlaubt dir das Paket pacman eine Vereinfachung. Die Funktion p_load() installiert Pakete, wenn die Pakete nicht installiert sind. Sollten die Pakete installiert sein, so werden die Pakete geladen. Du musst nur einmal install.packages(pacman) ausführen um das Paket pacman zu installieren.\n\npacman::p_load(tidyverse, magrittr, readxl)\n\nSchlussendlich gibt es noch die Möglichkeit sich alles nochmal bei YouTube anzuschauen.\n\n\n\n\n\n\nUnterschied von Packages und Libraries in R\n\n\n\nDu findest auf YouTube Einführung in R - Teil 03 - Unterschied Packages und Libraries in R als Video. Hier erkläre ich nochmal den Ablauf zwischen Installieren eines Paketes und dem Laden eines Paketes."
  },
  {
    "objectID": "programing-basics.html#sec-R-vector",
    "href": "programing-basics.html#sec-R-vector",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.2 Einen Vektor bauen c()\n",
    "text": "10.2 Einen Vektor bauen c()\n\nWir können mit der Funktion c() Zahlen und Wörter zu einem Vektor kombinieren.\n\nc(\"dog\", \"dog\", \"cat\", \"cat\", \"fox\", \"fox\")\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\"\n\n\nHier werden die Wörter “dog”, “cat” und “fox” miteinader in einen Vektor kombiniert. Wir erinnern uns an das $ Zeichen, was uns erlaubt eine Variable als Vektor aus einem tibble()herauszuziehen."
  },
  {
    "objectID": "programing-basics.html#sec-R-function",
    "href": "programing-basics.html#sec-R-function",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.3 Funktionen",
    "text": "10.3 Funktionen\nWir haben schon einige Funktion nebenbei in R kennengelernt. Zum einen as.factor() um einen Faktor zu erstellen oder aus dem Kapitel 10.1, wo wir die Funktion install.packages() nutzen um ein Paket zu installieren oder aber die Funktion library() um ein Paket in R zu laden.\nFunktionen sehen aus wie Wörter. Haben aber keine Gänsefüßchen und beinhalten auch keine Daten oder Vektoren. Funktionen können mit Daten und Vektoren rechnen und geben das Berechnete dann wieder. Nehmen wir als Beispiel die Funktion mean(), die den Mittelwert von einer Reihe Zahlen berechnet.\n\ny <- c(1.2, 3.4, 2.1, 6, 4.3)\nmean(y)\n\n[1] 3.4\n\n\nWir sehen, dass wir mit der Funktion c() die Zahlen \\(1.2, 3.4, 2.1, 6, 4.3\\) zusammenkleben. Danach speichern wir die Zahlen in den Objekt y als einen Vektor ab. Wir müssen ynicht erst erschaffen, das Erschaffen und Speichern passiert in R in einem Schritt. Wir stecken nun den Vektor y in die Funktion mean() und erhalten den Mittelwert von \\(3.4\\) der Zahlen wiedergegeben.\nEigentlich müssen in der Programmierung Objekte erst deklariert werden und somit erschaffen. Erst dann können Objekte initalisiert und somit befüllt bzw. etwas zugewiesen werden."
  },
  {
    "objectID": "programing-basics.html#sec-R-pfeil",
    "href": "programing-basics.html#sec-R-pfeil",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.4 Zuweisungspfeil <-\n",
    "text": "10.4 Zuweisungspfeil <-\n\nMit dem Zuweisungspfeil speichern wir Dinge in Objekte in R. Das heist wir speichern damit intern in R Datensätze und viele andere Sachen, die wir dan später wieder verwenden wollen. Schauen wir uns das einmal im Beispiel an. Schrieben wir nur den Vektor c() mit Hunden und Katzen darin, so erscheint eine Ausgabe in R.\n\nc(\"dog\", \"dog\", \"cat\", \"cat\", \"fox\", \"fox\")\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\"\n\n\nSchreiben wir den gleichen Vektor und nutzen den Zuweisungspfeil, dann wird der Vektor in dem Objekt animal gespeichert.\n\nanimal <- c(\"dog\", \"dog\", \"cat\", \"cat\", \"fox\", \"fox\")\n\nWie kommen wir jetzt an die Sachen, die in animal drin sind? Wir können einfach animal in R schreiben und dann wird uns der Inhalt von animal ausgegeben.\n\nanimal\n\n[1] \"dog\" \"dog\" \"cat\" \"cat\" \"fox\" \"fox\"\n\n\nDer Zuweisungspfeil <- ist zentral für die Nutzung von R.\nWir nutzen den Zuweisungspfeil <- ist zentral für die Nutzung von R. Wir brauchen den Zuweisungspfeil <- um Objekte in R zu erschaffen und Ergebnisse intern abzuspeichern. Zusammen mit Funktionen nutzen wir nur noch die Pipe %>% öfter."
  },
  {
    "objectID": "programing-basics.html#sec-R-pipe",
    "href": "programing-basics.html#sec-R-pipe",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.5 Pipe %>%\n",
    "text": "10.5 Pipe %>%\n\n\n\n\n\n\n\nZahlen, Buchstaben, Skalenniveau - Was ist das eigentlich?\n\n\n\nDu findest auf YouTube Einführung in R - Teil 11 - Pipes in R als Video. Hier erkläre ich den Zusammenhang nochmal in einem Video.\n\n\nIm Weiteren nutzen wir den Pipe Operator dargestellt als %\\>%. Du kannst dir den Pipe Operator als eine Art Röhre vorstellen in dem die Daten verändert werden und dann an die nächste Funktion weitergeleitet werden. Im folgenden siehst du viele Funktionen, die aneinander über Objekte miteinander verbunden werden. Im Kapitel 12 erfährst du mehr über die Funktionen select()und filter().\n\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\nanimal_1_tbl <- select(data_tbl, animal, jump_length)\nanimal_2_tbl <- filter(animal_1_tbl, jump_length >= 4)\nsort(animal_2_tbl$jump_length)\n\n [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8\n\ndata_tbl %>% \n  select(animal, jump_length) %>% \n  filter(jump_length >= 4) %>% \n  pull(jump_length) %>% \n  sort\n\n [1]  4.1  4.3  5.4  5.6  5.7  6.1  7.6  7.9  8.2  8.9  9.1 11.8\n\n\nIm unteren Beispiel siehst du die Nutzung des Pipe Operators %>%. Das Ergebnis ist das gleiche, aber der Code ist einfacher zu lesen. Wir nehmen den Datensatz data_tbl leiten den Datensatz in den Funktion select() und wählen die Spalten animal sowie jump_length. Dann filtern wir noch nach jump_lengthgrößer als 4 cm. Dann ziehen wir uns mit der Funktion pull() die Spalte jump_length aus dem Datensatz. Den Vektor leiten wir dann weiter in die Funktion sort() und erhalten die sortierten Sprunglängen zurück."
  },
  {
    "objectID": "programing-basics.html#sec-R-help",
    "href": "programing-basics.html#sec-R-help",
    "title": "10  Operatoren, Funktionen und Pakete",
    "section": "\n10.6 Hilfe mit ?\n",
    "text": "10.6 Hilfe mit ?\n\nDas Fragezeichen ? vor einem Funktionsnamen erlaubt die Hilfeseite zu öffnen. Die Hilfsseiten findest du auch in einem der Reiter im RStudio.\n\n\nAbbildung 10.2— Neben den Paketen in R findet sich auch der Reiter Help, wo du Hilfe für die einzelnen Funktionen findets.."
  },
  {
    "objectID": "programing-import.html",
    "href": "programing-import.html",
    "title": "\n11  Daten einlesen\n",
    "section": "",
    "text": "Die Daten aus unserem Experiment müssen rein in R. Das heißt, wir haben meist unsere Daten in einer Exceldatei vorliegen und wollen diese Daten nun in R einlesen.\nGängige Fehler beim Einlesen von Dateien in R sind folgende Probelem. Wir wollen diese Probeleme nacheinander einmal durchgehen. Aber keine Sorge, das Einlesen von Daten in R ist immer am Anfang etwas frickelig. Du kannst gerne in das R Tutorium (siehe Kapitel 1.2 für Raum und Zeiten) kommen, dann können wir dir da beim Einlesen der Daten helfen."
  },
  {
    "objectID": "programing-import.html#genutzte-r-pakete-für-das-kapitel",
    "href": "programing-import.html#genutzte-r-pakete-für-das-kapitel",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.1 Genutzte R Pakete für das Kapitel",
    "text": "11.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, janitor)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "programing-import.html#sec-format",
    "href": "programing-import.html#sec-format",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.2 Dateiformat",
    "text": "11.2 Dateiformat\n\n\nDas Buch Cookbook for R stellt auch Beispiele für die Funktion gather() zu Verfügung für die Umwandlung von Wide zu Long Format: Converting data between wide and long format\nWir unterschieden bei Datenformaten zwischen den Wide Format und dem Long Format. Meistens gibst du die Daten intuitv im Wide Format in Excel ein. Das ist in Excel auch übersichtlicher. R und später die Funktion ggplot() zur Visualisierung der Daten kann aber nur mit dem Long Format arbeiten. Wir können aber mit der Funktion gather() das Wide Format in das Long Format umwandeln.\n\n11.2.1 Wide Format\nIn Tabelle 11.1 sehen wir eine typische Datentabelle in einem Wide Format. Die Spalten egeben jeweils die Tierart wieder und die Einträge in den Spalten sind die Sprungweiten in [cm].\n\n\nTabelle 11.1— Eine Datentabelle mit Sprungweiten in [cm] von Hunde- und Katzenflöhen im Wide Format.\n\ndog\ncat\n\n\n\n5.2\n10.1\n\n\n4.9\n9.4\n\n\n12.1\n11.8\n\n\n8.2\n6.7\n\n\n5.6\n8.2\n\n\n9.1\n9.1\n\n\n7.4\n7.1\n\n\n\n\nWir können diese Datentablle auch in R erstellen und uns als tibble() wiedergeben lassen.\n\njump_wide_tbl <- tibble(dog = c(5.2, 4.9, 12.1, 8.2, 5.6, 9.1, 7.4),\n                        cat = c(10.1, 9.4, 11.8, 6.7, 8.2, 9.1, 7.1))\njump_wide_tbl\n\n# A tibble: 7 × 2\n    dog   cat\n  <dbl> <dbl>\n1   5.2  10.1\n2   4.9   9.4\n3  12.1  11.8\n4   8.2   6.7\n5   5.6   8.2\n6   9.1   9.1\n7   7.4   7.1\n\n\nWenn du schon Daten hast, dann macht es eventuell mehr Sinn eine neue Exceldatei anzulegen in der du dann die Daten in das Long Format kopierst.\nWir können aber mit einem Wide-Format nicht mit ggplot() die Daten aus der Tabelle 11.1 visualisieren. Deshalb müssen wir entweder das Wide Format in das Long Format umwandeln oder die Daten gleich in Excel im Long Format erstellen.\n\n11.2.2 Long Format\nWenn du Daten erstellst ist es wichtig, dass du die Daten in Excel im Long-Format erstellst. Dabei muss eine Beobachtung eine Zeile sein. Du siehst in Abbildung 11.1 ein Beispiel für eine Tabelle in Excel, die dem Long Format folgt.\n\n\nAbbildung 11.1— Beispiel für eine Exceldatentabelle in Long Format.\n\n\nIm Folgenden sehen wir einmal wie die Funktion gather() das tibble() in Wide Format in ein tibble() in Long Format umwandelt. Wir müssen dafür noch die Spalte benennen mit der Option key = in die die Namen der Spalten aus dem Wide Format geschrieben werden sowie den Spaltennamen für die eigentlichen Messwerte mit der Option value =.\n\njump_tbl <- tibble(dog = c(5.2, 4.9, 12.1, 8.2, 5.6, 9.1, 7.4),\n                   cat = c(10.1, 9.4, 11.8, 6.7, 8.2, 9.1, 7.1)) %>%\n  gather(key = \"animal\", value = \"jump_length\")\njump_tbl\n\n# A tibble: 14 × 2\n   animal jump_length\n   <chr>        <dbl>\n 1 dog            5.2\n 2 dog            4.9\n 3 dog           12.1\n 4 dog            8.2\n 5 dog            5.6\n 6 dog            9.1\n 7 dog            7.4\n 8 cat           10.1\n 9 cat            9.4\n10 cat           11.8\n11 cat            6.7\n12 cat            8.2\n13 cat            9.1\n14 cat            7.1\n\n\nWir sehen, dass ein Long Format viel mehr Paltz benötigt. Das ist aber in R kein Problem. Wir sehen die Daten kaum sondern nutzen Funktionen wie ggplot() um die Daten zu visualisieren. Wichtig ist, dass du die Daten in Excel sauber abgelegt hast.\nIm Folgenden schauen wir uns noch komplexere Daten in Tabelle 11.2 an. Das Datenbeispiel ist im Wide Format mit einem Behandlungsfaktor treatment einem Clusterfaktor block sowie mehreren Messwiederholungen zu unterschiedichen Zeitpunkten t_1 bis t_6 angelegt.\n\n\n\n\nTabelle 11.2— Komplexeres Datenbeispiel im Wide Format mit einem Behandlungsfaktor treatment einem Clusterfaktor block sowie mehreren Messwiederholungen zu unterschiedichen Zeitpunkten t_1 bis t_6.\n\ntreatment\nblock\nt_1\nt_2\nt_3\nt_4\nt_5\nt_6\n\n\n\nA\n1\n15.71\n12.80\n14.44\n15.14\n17.14\n20.84\n\n\nA\n2\n15.64\n17.15\n17.98\n16.90\n17.75\n14.97\n\n\nA\n3\n15.93\n17.94\n15.37\n16.96\n17.12\n14.97\n\n\nA\n4\n15.54\n15.73\n18.12\n17.10\n16.82\n15.59\n\n\nB\n1\n14.63\n15.87\n14.86\n18.18\n17.77\n20.41\n\n\nB\n2\n16.46\n14.23\n19.97\n19.55\n16.83\n21.96\n\n\nB\n3\n18.36\n12.41\n18.65\n16.53\n19.87\n19.95\n\n\nB\n4\n12.73\n15.44\n18.86\n13.96\n17.85\n15.48\n\n\nC\n1\n16.03\n16.45\n15.38\n13.57\n18.13\n18.70\n\n\nC\n2\n17.12\n14.96\n17.61\n14.35\n17.37\n19.27\n\n\nC\n3\n14.35\n16.93\n18.72\n18.69\n20.86\n20.85\n\n\nC\n4\n15.67\n11.47\n20.38\n18.89\n20.57\n16.05\n\n\nD\n1\n12.97\n13.02\n16.26\n16.80\n18.91\n20.29\n\n\nD\n2\n15.12\n14.15\n14.20\n17.11\n16.36\n18.64\n\n\nD\n3\n14.73\n14.91\n18.64\n14.96\n11.33\n19.13\n\n\nD\n4\n17.85\n16.59\n14.57\n19.69\n18.93\n18.80\n\n\n\n\n\n\nIm Folgenden Codeblock sehen wir, wie die Funktion gather() die Daten in Tabelle Tabelle 11.2 in ein Long Format umwandelt. Die Funktion fasst die Messwiederholungen der Spalten t_1 bis t_6 zusammen, in dem die Werte alle in der Spalte drymatter untereinander geklebt werden. Die Spalten treatment und block werden dann sechs Mal wiederholt untereinander geklebt.\n\ndata_tbl %>% \n  gather(key = \"time_point\", value = \"drymatter\", t_1:t_6) %>% \n  arrange(treatment, block)\n\n# A tibble: 96 × 4\n   treatment block time_point drymatter\n   <fct>     <int> <chr>          <dbl>\n 1 A             1 t_1             15.7\n 2 A             1 t_2             12.8\n 3 A             1 t_3             14.4\n 4 A             1 t_4             15.1\n 5 A             1 t_5             17.1\n 6 A             1 t_6             20.8\n 7 A             2 t_1             15.6\n 8 A             2 t_2             17.2\n 9 A             2 t_3             18.0\n10 A             2 t_4             16.9\n# … with 86 more rows"
  },
  {
    "objectID": "programing-import.html#importieren-mit-rstudio",
    "href": "programing-import.html#importieren-mit-rstudio",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.3 Importieren mit RStudio",
    "text": "11.3 Importieren mit RStudio\nWir können das RStudio nutzen um Daten mit Point-and-Klick rein zuladen und dann den Code wieder in den Editor kopieren. Im Prinzip ist dieser Weg der einfachste um einmal zu sehen, wie ein pfad funktioniert und der Code lautet. Später benötigt man diese ‘Krücke’ nicht mehr. Wir nutzen dann direkt den Pfad zu der Datei. Abbildung 11.2 zeigt einen Ausschnitt, wo wir im RStudio die Import Dataset Funktionalität finden.\n\n\nAbbildung 11.2— Auf den Reiter Einviroment klicken und dann Import Dataset. In der deutschen version vom RStudio mögen die Begriffe leicht anders sein.\n\n\n\n\n\n\n\n\nImportieren mit RStudio als Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 21.0 - Daten importieren mit RStudio - Point and Klick als Video. Point and Klick ist als Video einfacher nachzuvollziehen als Screenshots in einem Fließtext."
  },
  {
    "objectID": "programing-import.html#sec-pfad",
    "href": "programing-import.html#sec-pfad",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.4 Importieren per Pfad",
    "text": "11.4 Importieren per Pfad\nIn Abbildung 11.3 können wir sehen wie wir den Pfad zu unserer Excel Datei flea_dog_cat.xlsx finden. Natürlich kannst du den Pfad auch anders herausfinden bzw. aus dem Explorer oder Finder kopieren.\n\n\nAbbildung 11.3— Durch den Rechts-Klick auf die Eigenschaften einer Datei kann man sich den Pfad zur Datei anzeigen lassen. Achtung! Unter Windows muss der Slash \\ noch in den Backslash / gedreht werden.\n\n\nNachdem wir den Pfad gefunden haben, können wir den Pfad in die Funktion read_excel() kopieren und die Datei in das Objekt data_tbl einlesen. Ja, es wird nichts in der R Console ausgegeben, da sich die Daten jetzt in dem Object data_tbl befinden.\n\n## Ganzer Pfad zur Datei flea_dog_cat.xlsx\ndata_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n\n\n\n\n\n\nUnterschied zwischen \\ in Windows und / in R\n\n\n\nAchte einmal auf den Slash im Pfad in R und einem im Pfsd in Windows. Einmal ist es der Slash \\ im Dateipfad und einmal der Backslash /. Das ist sehr ärgerlich, aber dieses Problem geht zurück in die 80’ziger. Bill hat entschieden für sein Windows / zu nutzen und Steve (und Unix) eben /. Und mit dieser Entscheidung müssen wir jetzt leben…"
  },
  {
    "objectID": "programing-import.html#sec-umlaute",
    "href": "programing-import.html#sec-umlaute",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.5 Auf ein englisches Wort in Dateien",
    "text": "11.5 Auf ein englisches Wort in Dateien\nEin großes Problem in Datein sind Umlaute (ä,ö,ü) oder aber andere (Sonder)zeichen (ß, ?, oder #). Als dies sollte vermieden werden. Eine gute Datei für R beinhaltet nur ganze Wörter, Zahlen oder aber leere Felder. Ein leeres Feld ist ein fehlender Wert. Abbildung 11.4 zeigt eine gute Exceldatentablle. Wir schreiben jump_length mit Unterstrich um den Namen besser zu lesen zu können. Sonst ist auch alles in Englisch geschrieben. Wir vermeiden durch die neglische Schreibweise aus versehen einen Umlaut oder anderweitig problematische Zeichen zu verwenden. Später können wir alles noch für Abbildungen anpassen.\n\n\nAbbildung 11.4— Beispiel für eine gute (Excel)Datentabelle. Keine Umlaute sind vorhanden und die Spaltennamen haben keine Leerzeichen oder Sonderzeichen."
  },
  {
    "objectID": "programing-import.html#sec-spalten",
    "href": "programing-import.html#sec-spalten",
    "title": "\n11  Daten einlesen\n",
    "section": "\n11.6 Spaltennamen in der (Excel)-Datei",
    "text": "11.6 Spaltennamen in der (Excel)-Datei\nDie Funktion clean_names() aus dem R Paket janitor erlaubt es die Spaltennamen einer eingelesenen Datei in eine für R gute Form zu bringen.\n\nKeine Leerzeichen in den Spaltennamen.\nAlle Spaltennamen sind klein geschrieben.\n\n\ndata_tbl %>% \n  clean_names()\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            5.7         18     8        0\n 2 dog            8.9         22     8        1\n 3 dog           11.8         17     6        1\n 4 dog            8.2         12     8        0\n 5 dog            5.6         23     7        1\n 6 dog            9.1         18     7        0\n 7 dog            7.6         21     9        0\n 8 cat            3.2         12     7        1\n 9 cat            2.2         13     5        0\n10 cat            5.4         11     7        0\n11 cat            4.1         12     6        0\n12 cat            4.3         16     6        1\n13 cat            7.9          9     6        0\n14 cat            6.1          7     5        0"
  },
  {
    "objectID": "programing-dplyr.html",
    "href": "programing-dplyr.html",
    "title": "12  Daten bearbeiten",
    "section": "",
    "text": "Wir haben in dem vorherigen Kapitel Daten eingelesen. Jetzt wollen wir die Daten aufräumen (eng. tidy). Es ist notwendig, dass wir die Daten so aufarbeiten, dass R damit umgehen kann. Insbesondere das Erstellen von Faktoren ist wichtig, wenn die Spalte ein Faktor ist. R muss wissen was für Eigenschaften eine Spalte hat. Sonst funktionieren spätere Anwendungen in R nicht richtig oder geben einen Fehler wieder.\nEs gibt zwei Möglichkeiten wie du mit deinen Daten umgehst:\nIm Folgenden wollen wir den Datensatz data_tbl in R bearbeiten. Das heißt wir wollen Spalten auswählen mit select() oder Zeilen auswählen mit filter(). Schlussendlich wollen wir auch die Eigenschaften von Spalten mit der Funktion mutate ändern. Wir laden also den Datensatz flea_dog_cat.xlsx einmal in R.\nEs ergibt sich folgende Tabelle 12.1, die wir schon aus vorherigen Kapiteln kennen."
  },
  {
    "objectID": "programing-dplyr.html#genutzte-r-pakete-für-das-kapitel",
    "href": "programing-dplyr.html#genutzte-r-pakete-für-das-kapitel",
    "title": "12  Daten bearbeiten",
    "section": "\n12.1 Genutzte R Pakete für das Kapitel",
    "text": "12.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, readxl, magrittr, janitor)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "programing-dplyr.html#spalten-wählen-mit-select",
    "href": "programing-dplyr.html#spalten-wählen-mit-select",
    "title": "12  Daten bearbeiten",
    "section": "\n12.2 Spalten wählen mit select()\n",
    "text": "12.2 Spalten wählen mit select()\n\n\n\n\n\n\n\nYouTube - Spalten auswählen mit select()\n\n\n\nDu findest auf YouTube Einführung in R - Teil 12 - Spalten auswählen mit select() als Video zum nochmal anschauen.\n\n\nWir nutzen die Funktion select()um Spalten zu wählen.\nDer Datensatz, den wir im Experiment erschaffen, ist meist riesig. Jetzt könnten wir natürlich eine Exceltabelle mit unterschiedlichen Sheets bzw. Reitern erstellen oder aber die Spalten die wir brauchen in R selektieren. Wir nutzen die Funktion select()um Spalten zu wählen. Im folgenden Codeblock wählen wir die Spalten animal, jump_length und flea_count.\n\ndata_tbl %>% \n  select(animal, jump_length, flea_count)\n\n# A tibble: 21 × 3\n   animal jump_length flea_count\n   <chr>        <dbl>      <dbl>\n 1 dog            5.7         18\n 2 dog            8.9         22\n 3 dog           11.8         17\n 4 dog            8.2         12\n 5 dog            5.6         23\n 6 dog            9.1         18\n 7 dog            7.6         21\n 8 cat            3.2         12\n 9 cat            2.2         13\n10 cat            5.4         11\n# … with 11 more rows\n\n\nWir können die Spalten beim selektieren auch umbenennen und in eine andere Reihenfolge bringen.\n\ndata_tbl %>% \n  select(Sprungweite = jump_length, flea_count, animal)\n\n# A tibble: 21 × 3\n   Sprungweite flea_count animal\n         <dbl>      <dbl> <chr> \n 1         5.7         18 dog   \n 2         8.9         22 dog   \n 3        11.8         17 dog   \n 4         8.2         12 dog   \n 5         5.6         23 dog   \n 6         9.1         18 dog   \n 7         7.6         21 dog   \n 8         3.2         12 cat   \n 9         2.2         13 cat   \n10         5.4         11 cat   \n# … with 11 more rows\n\n\nDu findest auf der englischen Hilfeseite für select() noch weitere Beispiele für die Nutzung."
  },
  {
    "objectID": "programing-dplyr.html#zeilen-wählen-mit-filter",
    "href": "programing-dplyr.html#zeilen-wählen-mit-filter",
    "title": "12  Daten bearbeiten",
    "section": "\n12.3 Zeilen wählen mit filter()\n",
    "text": "12.3 Zeilen wählen mit filter()\n\n\n\n\n\n\n\nYouTube - Zeilen auswählen mit filter()\n\n\n\nDu findest auf YouTube Einführung in R - Teil 13 - Zeilen auswählen mit filter() als Video zum nochmal anschauen.\n\n\nWir nutzen die Funktion filter() um Zeilen nach Kriterien zu wählen.\nWährend wir die Auswahl an Spalten gut und gerne auch in Excel durchführen können, so ist dies bei der Auswahl der Zeilen nicht so einfach. Wir können in R hier auf die Funktion filter() zurückgreifen. Wir nutzen die Funktion filter() um Zeilen nach Kriterien zu wählen.\nIm folgenden Codeblock wählen wir die Zeilen aus in denen die Worte dog und fox stehen. Wir nutzen dazu den Operator %in% um auszudrücken, dass wir alle Einträge in der Spalte animal wollen die in dem Vektor c(\"dog\", \"fox\") beschrieben sind.\n\ndata_tbl %>% \n  filter(animal %in% c(\"dog\", \"fox\"))\n\n# A tibble: 14 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            5.7         18     8        0\n 2 dog            8.9         22     8        1\n 3 dog           11.8         17     6        1\n 4 dog            8.2         12     8        0\n 5 dog            5.6         23     7        1\n 6 dog            9.1         18     7        0\n 7 dog            7.6         21     9        0\n 8 fox           12.1         21     5        1\n 9 fox           13.2         25     4        1\n10 fox           14.1         31     4        1\n11 fox            9.7         12     5        1\n12 fox           10.6         28     4        0\n13 fox           11.5         18     4        1\n14 fox           10.8         19     3        0\n\n\nEs stehen dir Folgende logische Operatoren zu Verfügung wie in Tabelle 12.2 gezeigt. Am Anfang ist es immer etwas schwer sich in den logischen Operatoren zurechtzufinden. Daher kann ich dir nur den Tipp geben einmal die Operatoren selber auszuprobieren und zu schauen, was du da so rausfilterst.\n\n\nTabelle 12.2— Logische Opertairen und R und deren Beschreibung\n\n\n\n\n\nLogischer Operator\nBeschreibung\n\n\n\n<\nkleiner als (eng. less than)\n\n\n<=\nkleiner als oder gleich (eng. less than or equal to)\n\n\n>\ngrößer als (eng. greater than)\n\n\n>=\ngrößer als oder gleich (eng. greater than or equal to)\n\n\n==\nexact gleich (eng. exactly equal to)\n\n\n!=\nnicht gleich (eng. not equal to)\n\n\n!x\nnicht (eng. not x)\n\n\nx | y\noder (eng. x or y)\n\n\nx & y\nund (eng. x and y)\n\n\n\n\nHier ein paar Beispiele. Probiere gerne auch mal Operatoren selber aus. Im folgenden Codeblock wollen wir nur die Zeilen haben, die eine Anzahl an Flöhen größer von 15 haben.\n\ndata_tbl %>% \n  filter(flea_count > 15)\n\n# A tibble: 13 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            5.7         18     8        0\n 2 dog            8.9         22     8        1\n 3 dog           11.8         17     6        1\n 4 dog            5.6         23     7        1\n 5 dog            9.1         18     7        0\n 6 dog            7.6         21     9        0\n 7 cat            4.3         16     6        1\n 8 fox           12.1         21     5        1\n 9 fox           13.2         25     4        1\n10 fox           14.1         31     4        1\n11 fox           10.6         28     4        0\n12 fox           11.5         18     4        1\n13 fox           10.8         19     3        0\n\n\nWir wollen nur die infizierten Tiere haben.\n\ndata_tbl %>% \n  filter(infected == TRUE)\n\n# A tibble: 10 × 5\n   animal jump_length flea_count grade infected\n   <chr>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            8.9         22     8        1\n 2 dog           11.8         17     6        1\n 3 dog            5.6         23     7        1\n 4 cat            3.2         12     7        1\n 5 cat            4.3         16     6        1\n 6 fox           12.1         21     5        1\n 7 fox           13.2         25     4        1\n 8 fox           14.1         31     4        1\n 9 fox            9.7         12     5        1\n10 fox           11.5         18     4        1\n\n\nWir wollen nur die infizierten Tiere haben UND die Tiere mit einer Flohanzahl größer als 20.\n\ndata_tbl %>% \n  filter(infected == TRUE & flea_count > 20)\n\n# A tibble: 5 × 5\n  animal jump_length flea_count grade infected\n  <chr>        <dbl>      <dbl> <dbl>    <dbl>\n1 dog            8.9         22     8        1\n2 dog            5.6         23     7        1\n3 fox           12.1         21     5        1\n4 fox           13.2         25     4        1\n5 fox           14.1         31     4        1\n\n\nDu findest auf der englischen Hilfeseite für filter() noch weitere Beispiele für die Nutzung."
  },
  {
    "objectID": "programing-dplyr.html#spalten-ändern-mit-mutate",
    "href": "programing-dplyr.html#spalten-ändern-mit-mutate",
    "title": "12  Daten bearbeiten",
    "section": "\n12.4 Spalten ändern mit mutate()\n",
    "text": "12.4 Spalten ändern mit mutate()\n\n\n\n\n\n\n\nYouTube - Eigenschaften von Variablen ändern mit mutate()\n\n\n\nDu findest auf YouTube Einführung in R - Teil 14 - Eigenschaften von Variablen ändern mit mutate() als Video zum nochmal anschauen.\n\n\n\n\nWir nutzen die Funktion mutate() um die Eigenschaften von Spalten daher Variablen zu ändern.\nDie Reihenfolge der Funktionen ist wichtig um unliebsame Effekte zu vermeiden.\n\nErst wählen wir die Spalten mit select()\n\nDann filtern wir die Zeilen mit filter()\n\nAbschließend ändern wir die Eigenschaften der Spalten mit mutate()\n\n\nNachdem wir die Spalten mit select() udn eventuell die Zeieln mit filter() gewählt haben. müssen wir jetzt noch die Eigenschaften der Spalten ändern. Das Ändern müssen wir nicht immer tun, aber häufig müssen wir noch einen Faktor erschaffen. Wir nutzen noch die Funktion pull() um uns die Spalte animal aus dem Datensatz zu ziehen. Nur so sehen wir die vollen Eigenschaften des Faktors. Später nutzen wir pull seltener und nur um zu kontrollieren, was wir gemacht haben.\nIm folgenden Codeblock verwandeln wir die Variable animal in einen Faktor durch die Funktion as_factor. Wir sehen, dass die Level des Faktoes so sortiert sind, wie das Auftreten in der Spalte animal.\n\ndata_tbl %>% \n  mutate(animal = as_factor(animal)) %>% \n  pull(animal)\n\n [1] dog dog dog dog dog dog dog cat cat cat cat cat cat cat fox fox fox fox fox\n[20] fox fox\nLevels: dog cat fox\n\n\nWollen wir die Sortierung der Level ändern, können wir die Funktion factor() nutzen. Wir ändern die Sortierung des Faktors zu fox, dog und cat.\n\ndata_tbl %>% \n  mutate(animal = factor(animal, levels = c(\"fox\", \"dog\", \"cat\"))) %>% \n  pull(animal)\n\n [1] dog dog dog dog dog dog dog cat cat cat cat cat cat cat fox fox fox fox fox\n[20] fox fox\nLevels: fox dog cat\n\n\nWir können auch die Namen (eng. labels) der Level ändern. Hier musst du nur aufpassen wie du die alten Labels überschreibst. Wenn ich gleichzeitig die Level und die Labels ändere komme ich häufig durcheinander. Da muss du eventuell nochmal schauen, ob auch alles so geklappt hat wie du wolltest.\n\ndata_tbl %>% \n  mutate(animal = factor(animal, labels = c(\"Hund\", \"Katze\", \"Fuchs\"))) %>% \n  pull(animal)\n\n [1] Katze Katze Katze Katze Katze Katze Katze Hund  Hund  Hund  Hund  Hund \n[13] Hund  Hund  Fuchs Fuchs Fuchs Fuchs Fuchs Fuchs Fuchs\nLevels: Hund Katze Fuchs\n\n\nDu findest auf der englischen Hilfeseite für mutate() noch weitere Beispiele für die Nutzung. Insbesondere die Nutzung von mutate() über mehrere Spalten gleichzeitig erlaubt sehr effiezientes Programmieren. Aber das ist für den Anfang etwas viel.\n\n\n\n\n\n\nDie Funktionen select(), filter() und mutate() in R\n\n\n\nBitte schaue dir auch die Hilfeseiten der Funktionen an. In diesem Skript kann ich nicht alle Funktionalitäten der Funktionen zeigen. Oder du kommst in das R Tutorium welches ich anbiete und fragst dort nach den Möglichkeiten Daten in R zu verändern."
  },
  {
    "objectID": "programing-dplyr.html#gruppieren-mit-group_by",
    "href": "programing-dplyr.html#gruppieren-mit-group_by",
    "title": "12  Daten bearbeiten",
    "section": "\n12.5 Gruppieren mit group_by()\n",
    "text": "12.5 Gruppieren mit group_by()\n\nSobald wir einen Faktor erschaffen haben, können wir die Daten in R auch nach dem Faktor gruppieren. Das heißt wir nutzen die Funktion group_by() um R mitzuteilen, dass nun folgende Funktionen getrennt für die einzelen Gruppen erfolgen sollen. Im folgenden Codeblock siehst du die Anwendung.\n\ndata_tbl %>% \n  mutate(animal = as_factor(animal)) %>% \n  group_by(animal)\n\n# A tibble: 21 × 5\n# Groups:   animal [3]\n   animal jump_length flea_count grade infected\n   <fct>        <dbl>      <dbl> <dbl>    <dbl>\n 1 dog            5.7         18     8        0\n 2 dog            8.9         22     8        1\n 3 dog           11.8         17     6        1\n 4 dog            8.2         12     8        0\n 5 dog            5.6         23     7        1\n 6 dog            9.1         18     7        0\n 7 dog            7.6         21     9        0\n 8 cat            3.2         12     7        1\n 9 cat            2.2         13     5        0\n10 cat            5.4         11     7        0\n# … with 11 more rows\n\n\nAuf den ersten Blick ändert sich nicht viel. Es entsteht aber die Zeile # Groups: animal [3]. Wir wissen nun, dass wir nach der Variable animal mit drei Gruppen die Datentabelle gruppiert haben. Die Anwendung siehst du in Kapitel 14.10 bei der Berechung von deskriptiven Maßzahlen."
  },
  {
    "objectID": "programing-dplyr.html#mehr-informationen-durch-glimpse-und-str",
    "href": "programing-dplyr.html#mehr-informationen-durch-glimpse-und-str",
    "title": "12  Daten bearbeiten",
    "section": "\n12.6 Mehr Informationen durch glimpse() und str()\n",
    "text": "12.6 Mehr Informationen durch glimpse() und str()\n\nAm Ende noch zwei Funktionen zur Kontrolle, was wir hier eigentlich gerade tun. Mit der Funktion glimpse() können wir uns einen Einblick in die Daten geben lassen. Wir sehen dann nochmal kurz und knapp wieviel Zeieln und Spalten wir haben und welche Inhalte in den Spalten stehen. Die gleichen Informationen erhalten wir auch durch die Funktion str(). Die Funktion str()geht aber noch einen Schritt weiter und nennt uns auch Informationen zu dem Objekt. Daher wir wissen jetzt, dass es sich beim dem Objekt data_tbl um ein tibble() handelt.\n\nglimpse(data_tbl)\n\nRows: 21\nColumns: 5\n$ animal      <chr> \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"cat\", \"c…\n$ jump_length <dbl> 5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6, 3.2, 2.2, 5.4, 4.1, 4.…\n$ flea_count  <dbl> 18, 22, 17, 12, 23, 18, 21, 12, 13, 11, 12, 16, 9, 7, 21, …\n$ grade       <dbl> 8, 8, 6, 8, 7, 7, 9, 7, 5, 7, 6, 6, 6, 5, 5, 4, 4, 5, 4, 4…\n$ infected    <dbl> 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1…\n\nstr(data_tbl)\n\ntibble [21 × 5] (S3: tbl_df/tbl/data.frame)\n $ animal     : chr [1:21] \"dog\" \"dog\" \"dog\" \"dog\" ...\n $ jump_length: num [1:21] 5.7 8.9 11.8 8.2 5.6 9.1 7.6 3.2 2.2 5.4 ...\n $ flea_count : num [1:21] 18 22 17 12 23 18 21 12 13 11 ...\n $ grade      : num [1:21] 8 8 6 8 7 7 9 7 5 7 ...\n $ infected   : num [1:21] 0 1 1 0 1 0 0 1 0 0 ..."
  },
  {
    "objectID": "programing-outro.html",
    "href": "programing-outro.html",
    "title": "\n13  Zusammenfassung\n",
    "section": "",
    "text": "Soweit haben wir einmal die Grundlagen in der R Programmierung gelegt. Wir könne Daten einlesen und diese Daten dann auch Manipulieren. Das musst du nicht in R tun, du kannst dafür euch Excel nutzen. Nur muss dir klar sein, dasss du um die Funktion mutate()nicht drum herum kommst. Du musst die Funktion mutate()nutzen um Faktoren zu erschaffen. Faktoren brauchen wir in den folgenden Kapiteln sehr oft.\n\n\n\n\n\n\nWas war der Sinn der Reise?\n\n\n\nWir haben uns jetzt die Grundlagen in R einmal soweit angeschaut, dass wir Funktionen und Pakete in den folgenden Kapiteln nutzen können."
  },
  {
    "objectID": "eda-preface.html",
    "href": "eda-preface.html",
    "title": "Explorative Datenanalyse",
    "section": "",
    "text": "Wir kürzen die explorative Datenanalyse häufig als EDA ab.\nWir haben die Daten jetzt in R Eingelesen und im Zweifel noch angepasst. Nun wollen wir usn die Daten einmal angucken. Nicht in dem Sinne, dass wir auf die Datentabelle schauen. Sondern wir wollen die Daten visualisieren. Wir erstellen Abbildungen von den Daten und versuchen so mehr über die Daten zu erfahren. Sehen wir Zusammenhänge zwischen verschiedenen Variablen bzw. Spalten? Wir führen eine explorative Datenanalyse durch. Über die exploratibve Datenanalyse wollen wir uns in diesem Kapitel einmal Gedanken machen.\n\n\n\n\n\n\nEinführung in R per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Du musst die Grundlagen in R verstanden haben, damit du dem R Code folgen kannst."
  },
  {
    "objectID": "eda-descriptive.html",
    "href": "eda-descriptive.html",
    "title": "14  Deskriptive Statistik",
    "section": "",
    "text": "Eigentlich schätzen wir die Parameter einer Verteilung. Aber das kommt nochmal später genauer, wenn wir wissen was Verteilungen sind.\nWir nutzen die deskriptive Statistik um Zahlen zusammenzufassen. Das heißt wir haben einen Datensatz vorliegen wie den Datensatz flea_dog_cat.xlsx. Wir wollen jetzt den großen Datensatz in wenige Zahlen wiedergeben. Warum wenige Zahlen? Wenn wir das Ergebnis präsentieren wollen, dann müssen es wenige Zahlen sein, die den Datensatz gut zusammenfassen. Daher ist es wichtig zu wissen, dass wir dutzende bis hunderte Zahlen durch meist eine oder zwei Zahlen beschreiben wollen. Wir brauchen die statistischen Maßzahlen aus diesem Kapitel später um teilweise noch extrem größere Datensätze darstellen zu können. Ebenso werden wir die Maßzahlen aus diesem Kapitel dafür verwenden statistische Tests und Modelle zu rechnen.\nBeginnen wir aber mit einem einfachen Beispiel und dem Datensatz flea_dog_cat.xlsx. In Tabelle 14.1 sehen wir nochmal den Datensatz. Wir wollen uns jetzt aber erstmal nur die Spalte jump_length für die Hunde anschauen.\nNehmen wir nun als Beispiel die Sprungweiten in [cm] von Hundeflöhen. Wir messen sieben Sprungweiten von sieben Hundeflöhen und messen dabei folgende Werte in [cm]: 5.7, 8.9, 11.8, 8.2, 5.6, 9.1 und 7.6. Wir schreiben nun y als einen Vektor in der Form\n\\[\ny = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}.\n\\]\nIn R würde der Vektor wie etwas anders aussehen.\nWir wollen nun die Zahlen in \\(y\\) beschrieben und durch wenige andere Zahlen zusammenfassen. Einige der statistischen Maßzahlen sind dir vermutlich schon bekannt, andere eher neu."
  },
  {
    "objectID": "eda-descriptive.html#mittelwert",
    "href": "eda-descriptive.html#mittelwert",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.1 Mittelwert",
    "text": "14.1 Mittelwert\nDer Mittelwert einer Zahlenreihe beschreibt den Schwerpunkt der Zahlen. Der Mittelwert wird auch als Lageparameter benannt.  Wir schreiben den Mittelwert mit einem Strich über den Vektor, der die Zahlen enthält. Im folgenden ist die Formel für den Mittelwert der Sprungweite in [cm] der Hunde gezeigt. Der Mittelwert ist in dem Sinne eine künstliche Zahl, da der Mittlwert häufig nicht in den beobachteten Zahlen vorkommt.Der Mittelwert und der Median sind zwei Lageparameter einer Verteilung. Beide beschreiben die Stelle, wo die Verteilungskurve am höchsten ist.\n\n\n\n\n\n\nWir werden immer mal wieder Formeln vereinfachen. Zum Beispiel nur \\(\\sum\\) schreiben anstatt \\(\\sum_i^n\\), wenn wir einen Vektor aufsummieren und uns die Indizes sparen…\n\\[\n\\bar{y} = \\sum_{i=1}^{n}\\cfrac{x_i}{n} =\n\\cfrac{5.7 + 8.9 + 11.8 + 8.2 + 5.6 + 9.1 + 7.6}{7} =\n8.13\n\\]\nIm Durchschnitt oder im Mittel springen Hundeflöhe 8.13 cm weit.\nIn der Abbildung 14.1 wollen wir die Formel nochmal visualisieren. Vielleicht fällt dir dann der Zusammenhang von dem Index \\(i\\) und der gesamten Fallzahl \\(n\\) leichter.\n\n\nAbbildung 14.1— Zusamenhang zwischen \\(y\\) sowie dem Index \\(i\\) in der Formel für den Mittelwert.\n\n\nIn R können wir den Mittelwert einfach mit der Funktion mean() berechnen. Wir wollen dann den Mittelwert noch auf die zweite Kommastelle runden. Das machen wir dann mit der Funktion round().\n\ny %>% mean %>% round(2)\n\n[1] 8.13\n\n\nWir erhalten das gleiche Ergebnis wie oben in unserer händischen Rechnung. Die Hundeflöhe springen im Mittel 8.13 cm weit.\nDer Mittelwert ist eine bedeutende Maßzahl der Normalverteilung. Daher merken wir uns hier schon mal, dass wir den Mittelwert brauchen werden. Auch wenn wir darüber nachdenken ob sich zwei Gruppen unterscheiden, so nutzen wir hierzu den Mitelwert. Unterscheiden sich die mittleren Sprungweiten in [cm] von Hunde- und Katzenflöhen?"
  },
  {
    "objectID": "eda-descriptive.html#spannweite",
    "href": "eda-descriptive.html#spannweite",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.2 Spannweite",
    "text": "14.2 Spannweite\nDie Spannweite erlaubt uns zu überprüfen was die kleinste Zahl und die größte Zahl ist. Also uns das Minimum und das Maximum einer Zahlenreihe anzuschauen. Auf den ersten Blick mag das nicht so sinnig sein, aber wenn wir uns hunderte von Beobachtungen anschauen, wollen wir wissen, ob wir nicht einen Fehler bei Eintragen der Daten gemacht haben. Wir wissen eigentlich, dass z.B keine negativen Zuwachsraten auftreten können.\nDie Spannweite dient dazu in einem Datensatz zu übersprüfen ob die Spalte, oder auch Variable genannt, den richtigen Zahlenraum aufweist. Das machen wir durch die Funktion range().\n\\[\ny_{range} = y_{max} - y_{min} = 12.1 - 4.9 = 7.2\n\\] Die Hundeflöhe springen in einer Spannweite von 7.2 cm. Das kommt einem normal vor. Die Spannweite ist nicht übertrieben groß. Der minimale Wert ist 4.9 und der maximale Wert it 12.1 und somit sind beide Zahlen in Ordnung. Keine der beiden Zahlen ist übertrieben groß oder gar negativ.\nIn R können wir die Spannweite mit range() wie folgt berechnen. Wir erhalten den minmialen udn maximalen Wert.\n\nrange(y) \n\n[1]  5.6 11.8\n\n\nWir merken uns, dass die Spannweite eine Maßzahl für die Validität der Daten ist. Hat das Experiment geklappt oder kamen da nur komische Zahlen bei raus, die wir so in der Realität nicht erwarten würden. Zum Beispiel negative Sprungweiten, weil wir einmalauf das Minuszeichen gekommen sind."
  },
  {
    "objectID": "eda-descriptive.html#varianz",
    "href": "eda-descriptive.html#varianz",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.3 Varianz",
    "text": "14.3 Varianz\nBis jetzt können wirmit dem Mittelwert \\(\\bar{y}\\) die Lage oder den Mittelpunkt unserer Zahlenreihe beschreiben. Uns fehlt damit aber die Information über die Streuung der Zahlen. Sind die Zahlen alle eher gleich oder sehr verschieden? Liegen die Zahlen daher alle bei dem Mittelwert oder sind die Zahlen weit um den Mittelwert gestreut.\nDie Streuung der Zahlen um den Mittelwert beschreibt die Varianz oder auch \\(s^2\\). Wir berechnen die Varianz indem wir von jeder Zahl den Mittelwert aller Zahlen abziehen und dann das Ergebnis quadrieren. Das machen wir für alle Zahlen und addieren dann die Summe auf. Wir erhalten die Quadratsumme von \\(y\\).\nAbweichungsquadrate sind ein wichtiges Konzept in der Statistik. Wenn wir wissen wollen, wie groß eine Abweichung von einer Zahl zu einer anderen ist, dann nutzen wir immer das Quadrat der Abweichung und bilden die Quadratsumme..\n\\[\ns^2 = \\sum_{i=1}^n\\cfrac{(y_i - \\bar{y})^2}{n-1} = \\cfrac{(5.7 -\n8.13)^2 + ... + (7.6 - 8.13)^2}{7-1} = 4.6\n\\]\nDie Varianz berschreibt also die Streuung der Zahlen im Quadrat um den Mittelwert. Das heißt in unserem Beispiel, dass die Sprungweite eine Varianz von 4.6 cm\\(^2\\) hat. Wir können Quadratzentimeter schlecht interpretieren. Deshalb führen wir gleich die Wuzel der Varianz ein: die Standardabweichung.\nIn R lässt sich die Varianz einfach durch die Funktion var() berechnen.\n\ny %>% var %>% round(2) \n\n[1] 4.6\n\n\nWir benötigen die Varianz häufig nur als Zwischenschritt um die Standardabweichung zu berechnen. Das Konzept der Abweichungsquadrate benötigen wir aber in der Varianzanalyse (ANOVA) und für die Beschreibung einer Normalverteilung."
  },
  {
    "objectID": "eda-descriptive.html#standardabweichung",
    "href": "eda-descriptive.html#standardabweichung",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.4 Standardabweichung",
    "text": "14.4 Standardabweichung\nDie Standardabweichugn ist die Wurzel der Varianz. Wo die Varianz die Abweichung der Sprungweite in [cm\\(^2\\)] beschreibt, beschreibt die Standardabweichung die Streung der Sprungweite in [cm].\n\\[\ns = \\sqrt{s^2} = \\sqrt{4.6} = 2.14\n\\] Wir schreiben immer den Mittelwert plusminus die Standardabweichung. Also immer \\(\\bar{y} \\pm s\\).\nWir können also schreiben, dass die Flöhe im Mittel 8.13 \\(\\pm\\) 2.14cm weit springen. Somit haben wir die Lage und die Streuung der Zahlenreihe \\(y\\) der Sprungweite in [cm] mit zwei Zahlen beschrieben.\nIn R können wir die Standardabweichung einfach mit der Funktion sd() berechnen.\n\ny %>% sd %>% round(2) \n\n[1] 2.14"
  },
  {
    "objectID": "eda-descriptive.html#mittelwert-und-varianz---eine-herleitung",
    "href": "eda-descriptive.html#mittelwert-und-varianz---eine-herleitung",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.5 Mittelwert und Varianz - eine Herleitung",
    "text": "14.5 Mittelwert und Varianz - eine Herleitung\nWas ist der Mitelwert und die Varianz genau? Schauen wir uns das einmal in Abbildung 14.2 an. Die graue Linie oder Grade beschreibt den Mittelwert der fünf Beobachtungen. Die fünf Beobachtungen sind als blaue Punkt dargestellt. Auf der x-Achse ist nur der Index des Punktes. Das heißt \\(y_1\\) ist der erste Punkte, das der Index \\(i\\) gleich 1 ist.\n\n\nAbbildung 14.2— Die graue Linie beschreibt den Mittelwert der genau so durch die blauen Punkte geht, dass die Abstände der Punkte oberhalb und unterhalb zu Null aufaddieren. Die Linie liegt in der Mitte der Punkte. Die quadrierten Abstände sind die Varainz der blauen Punkte. Auf der x-Achse ist der Index des Punktes eingetragen.\n\n\nWenn wir die Summe der Abweichungen von \\(y_1\\) bis \\(y_5\\) zu dem Mittelwert bilden, so wird diese Summe 0 sein. Der Mittelwert liegt genau in der Mitte der Punkte. In unserem Beispiel ist der Mittelwert \\(\\bar{y} = 5.8\\). Wi können jetzt die Abstände wie in der folgenden Tabelle berechnen.\n\n\n\n\n\n\n\n\n\n\nIndex \\(i\\)\n\ny\n\\(\\boldsymbol{\\epsilon}\\)\n\\(\\boldsymbol{y_i - \\bar{y}}\\)\nWert\n\n\n\n1\n5.7\n\\(\\epsilon_1\\)\n\\(y_1 - \\bar{y}\\)\n\\(5.7 - 8.13 = -2.43\\)\n\n\n2\n8.9\n\\(\\epsilon_2\\)\n\\(y_2 - \\bar{y}\\)\n\\(8.9 - 8.13 = 0.77\\)\n\n\n3\n11.8\n\\(\\epsilon_3\\)\n\\(y_3 - \\bar{y}\\)\n\\(11.8 - 8.13 = 3.67\\)\n\n\n4\n8.2\n\\(\\epsilon_4\\)\n\\(y_4 - \\bar{y}\\)\n\\(8.2 - 8.13 = 0.07\\)\n\n\n5\n5.6\n\\(\\epsilon_5\\)\n\\(y_5 - \\bar{y}\\)\n\\(5.6 - 8.13 = -2.53\\)\n\n\n6\n9.1\n\\(\\epsilon_4\\)\n\\(y_4 - \\bar{y}\\)\n\\(9.1 - 8.13 = 0.97\\)\n\n\n7\n7.6\n\\(\\epsilon_5\\)\n\\(y_5 - \\bar{y}\\)\n\\(7.6 - 8.13 = -0.53\\)\n\n\n\n\n\n\n\nWir nennen die Abstände \\(y_i - \\bar{y}\\) nach dem griechischen Buchstaben Epsilon \\(\\epsilon\\). Das \\(\\epsilon\\) soll an das \\(e\\) von Error erinnern. So meint dann Error eben auch Abweichung. Ja, es gibt hier viele Worte für das gleiche Konzept.\nWir berechnen einen Mittelwert von den Epsilons mit \\(\\bar{\\epsilon} = 0\\). Ein Mittelwert nahe Null bzw. von Null wundert uns nicht. Wir haben die Gerade ja so gebaut, das nach oben und unten die gleichen Abstände sind. Die Varianz \\(s^2\\) der \\(y\\) ist \\(s_y^2 = 4.599\\) und die Varianz von \\(\\epsilon\\) ist \\(s_{\\epsilon}^2 = 4.599\\). In beiden Fällen ist die Zahl gleich. Wir können uns merken, dass die Epsilons einen Mittelwert von 0 haben und eine Varianz von \\(s_y^2\\).\nWir schreiben auch, dass die Residuen genannt \\(\\epsilon\\) normalverteilt sind mit \\(\\mathcal{N}(0, s_y^2)\\).\n\n\n\nlm(val_vec ~ 1)\n\n\nCall:\nlm(formula = val_vec ~ 1)\n\nCoefficients:\n(Intercept)  \n     8.1286"
  },
  {
    "objectID": "eda-descriptive.html#standardfehler-oder-standard-error-se",
    "href": "eda-descriptive.html#standardfehler-oder-standard-error-se",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.6 Standardfehler oder Standard Error (SE)",
    "text": "14.6 Standardfehler oder Standard Error (SE)\nWenn wir den Mittelwert der Sprungweiten berichten dann gehört die Standardabweichung der Sprungweiten mit als beschreibendes Maß dazu. Wir berichten keinen Mittelwert ohne Standardabweichung.\nNun ist es aber so, dass der Mittelwert und die Standardabweichung von der Fallzahl abhängen. Je mehr Fallzahl bzw. Beoabchtungen wir haben, desto genauer wird der Mittelwert sein. Oder anders ausgedrückt \\(\\bar{y}\\) wird sich \\(\\mu_y\\) annähern. Das gleiche gilt auch für die Standardabweichung \\(s_y\\), die sich \\(\\sigma_y\\) mit steigender Fallzahl annähert.\nAus diesem Grund brauchen wir noch einen Fehler bzw. eine Maßzahl für die Streuung, die unabhängig von der Fallzahl ist. Wir skalieren also die Standardabweichung mit der Fallzahl indem wir die Standardbweichung durch die Wurzel der Fallzahl teilen.\n\\[\nSE = \\cfrac{s}{\\sqrt{n}} = \\cfrac{2.14}{2.65} = 0.81\n\\]\nWir müssten ein Paket in R laden um den Standardfehler zu berechnen. Das Laden von zusätzlichen Paketen wollen wir hier aber vermeiden; wir können den Standardfehler auch einfach selber berechnen.\n\nse <- sd(y)/sqrt(length(y))\nse %>% round(2)\n\n[1] 0.81\n\n\nWir erhalten einen Standardfehler von 0.81. Diese Zahl ist in dem Sinne nicht zu interpretieren, da wir hier nur Experimente losgelöst von deren Fallzahl miteinander vergleichen können. Auf der anderen Seite können wir ohne die berichtete Fallzahl nicht vom Standardfehler auf die Standardabweichung schließen.\nWir berichten den Standardfehler immer zusammen mit der Fallzahl, so dass die Standardabweichung berechnet werden kann.\nWir benötigen den Standardfehler eigentlich nicht zum Berichten von Ergebnissen. Der Standardfehler ist nicht als Zahl interpretierbar und somit eine reine statistische Größe. Tabelle 14.2 zeigt die Zusammenfassung und den Vergleich von Standardabweichung und Standardfehler.\n\n\nTabelle 14.2— Zusammenfassung und Vergleich von Standardabweichung und Standardfehler\n\n\n\n\n\nStandardabweichung\nStandardfehler\n\n\n\n… ist eine Aussage über die Streuung der erhobenen Werte einer Stichprobe.\n… ist eine Aussage über die Genauigkeit des Mittelwertes einer Stichprobe.\n\n\n… hängt von der biologischen Variabilität ab.\n… abhängig von der Messgenauigkeit\n\n\n… ist ein beschreibendes Maß.\n… ist ein statistisches Maß.\n\n\n… ist nur wenig durch die Größe der Stichprobe beineinflussbar.\n… steht im direkten Verhältnis zur Größe der Stichprobe.\n\n\n\n\n\n\nDer Standardfehler oder Standard Error (SE) oder Standard Error of the Mean (SEM) wird uns wieder beim statistischen Testen und dem t-Test begegnen.\n\\[\nT_{calc} = \\cfrac{\\bar{y_1} - \\bar{y_2}}{s_p \\cdot \\sqrt{\\tfrac{2}{n}}} \\approx \\cfrac{\\bar{y_1} - \\bar{y_2}}{SEM}\n\\]\nDer Nenner beim t-Test kann als Standardfehler gesehen werden. Wir benötigen den Standardfehler also im Kontext des statistischen Testen als eine statististische Maßzahl.\n\n\n\n\n\n\nStandardfehler wird in der Metaanalyse genutzt\n\n\n\nDer Standardfehler ist bedeutend in der Metaanalyse. Also dem gemeinsamen Auswerten von mehreren klinischen Studien. Du kannst im Buch Doing Meta-Analysis with R: A Hands-On Guide mehr darüber erfahren. Wir nutzen keine Metaanalysen in den Grundlagenveranstaltungen."
  },
  {
    "objectID": "eda-descriptive.html#median",
    "href": "eda-descriptive.html#median",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.7 Median",
    "text": "14.7 Median\nWir wollen uns jetzt noch eine andere Art der Zusammenfassung von Zahlen anschauen. Anstatt mit den Zahlen zu rechnen, sortieren wir jetzt die Zahlen aus dem Vektor \\(y = \\{5.7, 8.9, 11.8, 8.2, 5.6, 9.1, 7.6\\}\\) nach dem Rang. Wir rechnen dann mit den Rängen. Die kleinste Zahl kriegt den kleinsten Rang. Wir können R nutzen über due Funktion sort() um den Vektor \\(y\\) zu sortieren.\n\ny %>% sort()\n\n[1]  5.6  5.7  7.6  8.2  8.9  9.1 11.8\n\n\nDer Median \\(\\tilde{y}\\) ist die mittlere Zahl eines Zahlenvektors. Wir haben hier sieben Zahlen, also ist der Median die vierte Zahl. Wir müssen hier aber zwischen einr ungeraden Anzahl und einer geraden Anzahl unterscheiden.\n\n\nUngerade Anzahl von Zahlen, der Median ist die mittlere Zahl des Vektors \\(y\\): \\[\n5.6,  5.7,  7.6,  \\underbrace{8.2,}_{Median}  8.9,  9.1, 11.8\n\\]\n\n\nIn R können wir den Median einfach mit der Funktion median()berechnen.\n\nmedian(y) \n\n[1] 8.2\n\n\n\n\nGerade Anzahl von Zahlen, der Median ist der Mittelwert der beiden mittleren Zahlen des Vektors \\(y\\): \\[\n5.6,  5.7,  7.6,  \\underbrace{8.2, 8.9,}_{Median = \\tfrac{8.2+8.9}{2}=8.55} 9.1, 11.8, \\color{blue}{13.1}\n\\]\n\n\nIn R können wir den Median wieder einfach mit der Funktion median()berechnen. Wir müssen nur die Zahl 13.1 zu dem Vektor y mit der Funktion c() hinzufügen.\n\nc(y, 13.1) %>% median() \n\n[1] 8.55\n\n\nWenn der Mittelwert stark von dem Median abweicht, deutet dies auf eine schiefe Verteilung oder aber Ausreißer in den Daten hin. Wir müssen dann in der explorativen Datenanalyse der Sachlage nachgehen\nDer Median ist eine Alternative zu dem Mitelwert. Insbesondere in Fällen, wo es sehr große Zahlen gibt, die den Mittelwert in der Aussage verzerren, kann der Median sinnvoll sein.\n\n\n\n\n\n\nMedian versus Mittelwert\n\n\n\nZur Veranschaulichung des Unterschiedes zwischen Median und Mittelwert nehmen wir die Mietpreise in New York. Der mittlere Mietpreis für eine 2-Zimmerwohnung in Manhattan liegt bei 5000$ pro Monat. In den mittleren Mietpreis gehen aber auch die Mieten der Billionaires’ Row mit ein. Der mediane Mietpreis liegt bei 4000$. Die hohen Mieten ziehen den Mittelwert nach rechts."
  },
  {
    "objectID": "eda-descriptive.html#quantile-und-quartile",
    "href": "eda-descriptive.html#quantile-und-quartile",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.8 Quantile und Quartile",
    "text": "14.8 Quantile und Quartile\nBei dem Mittelwert beschreibt die Standardabweichung die Streuung der Daten um den Mitelwert. Bei dem Median sind dies die Quartile. Die Quartile beschreiben die Streuung der Daten um den Median. Um die Quartile bestimmen zu können, teilen wir die Daten in 100 Quantile. Du kannst dir Quantile wie Prozente vorstellen. Wir schneiden die Daten also in 100 Scheiben. Das geht natürlich erst wirklich, wenn wir hundert Zahlen haben. Deshalb hilft man sich mit Quartilen - von Quarta, ein Viertel - aus. Tabelle 14.3 zeigt den Zusammenhang.\n\n\nTabelle 14.3— Zusammenfassung und Vergleich von Quantilen, Quartilen und Median\n\nQuantile\nQuartile\nMedian\n\n\n\n25% Quantile\n1\\(^{st}\\) Quartile\n\n\n\n50% Quantile\n2\\(^{nd}\\) Quartile\nMedian\n\n\n75% Quantile\n3\\(^{rd}\\) Quartile\n\n\n\n\n\nWir bestimmen die Quartile wie den Median. Wir müssen unterscheiden, ob wir eine ungerade Anzahl an Zahlen oder eine gerade Anzahl an Zahlen vorliegen haben.\n\nUngerade Anzahl von Zahlen, das 1\\(^{st}\\) Quartile ist die mittlere Zahl des unteren Mittels und das 3\\(^{rd}\\) Quartile ist die mittlere Zahl des oberen Mittels des Vektors \\(y\\): \\[\n5.6,  \\underbrace{5.7,}_{1st\\ Quartile}  7.6,  8.2,  8.9,  \\underbrace{9.1,}_{3rd\\ Quartile} 11.8\n\\]\nGerade Anzahl von Zahlen, das 1\\(^{st}\\) Quartile ist der Mittelwert der beiden mittleren Zahl des unteren Mittels und das 3\\(^{rd}\\) Quartile ist der Mitelwert der beiden mittleren Zahlen des oberen Mittels des Vektors \\(y\\): \\[\n5.6,  \\underbrace{5.7, 7.6,}_{1st\\ Quartile = \\tfrac{5.7+7.6}{2}=6.65}    8.2,  8.9,  \\underbrace{9.1, 11.8}_{3rd\\ Quartile = \\tfrac{9.1+11.8}{2}=10.45} \\color{blue}{13.1}\n\\]\n\nDas 95% Quantile und das 97.25% Quantile werden wir später nochmal im statistischen Testen brauchen. Auch hier ist die Idee, dass wir die Daten in hundert Teile schneiden und uns dann die extremen Zahlen anschauen.\nIn R können wir den Median einfach mit der Funktion quantile() berechnen. Wir berechnen hier das 25% Quantile also das 1\\(^{st}\\) Quartile sowie das 50% Quantile also den Median und das 75% Quantile also das 3\\(^{rd}\\) Quartile.\n\ny %>% quantile(probs = c(0.25, 0.5, 0.75)) %>% round(2)\n\n 25%  50%  75% \n6.65 8.20 9.00 \n\nc(y, 13.1) %>% quantile(probs = c(0.25, 0.5, 0.75)) %>% round(2) \n\n 25%  50%  75% \n7.12 8.55 9.77 \n\n\nWarum unterscheiden sich die händisch berechneten Quartile von den Quartilen aus R? Es gibt verschiedene Arten der Berechnung. In der Klausur nutzen wir die Art und Weise wie die händische Berechnung hier beschrieben ist. Später in der Anwendung nehmen wir die Werte, die R ausgibt. Die Abweichungen sind so maginal, dass wir diese Abweichungen in der praktischen Anwendung ignorieren wollen."
  },
  {
    "objectID": "eda-descriptive.html#interquartilesabstand-iqr",
    "href": "eda-descriptive.html#interquartilesabstand-iqr",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.9 Interquartilesabstand (IQR)",
    "text": "14.9 Interquartilesabstand (IQR)\nDer Interquartilesabstand (IQR) beschreibt den Abstand zwischen dem 1\\(^{st}\\) Quartile und dem 3\\(^{rd}\\) Quartile. Daher ist der Interquartilesabstand (IQR) ähnlich der Spannweite zwischen dem maximalen und minimalen Wert. Wir benötigen das Interquartilesabstand (IQR) in der explorativen Datenanalyse wenn wir einen Boxplot erstellen wollen.\n\\[\nIQR = 3^{rd}\\,\\mbox{Quartile} - 1^{st}\\,\\mbox{Quartile} = 9.1 - 5.7 = 3.4\n\\]"
  },
  {
    "objectID": "eda-descriptive.html#sec-desc-group-by",
    "href": "eda-descriptive.html#sec-desc-group-by",
    "title": "14  Deskriptive Statistik",
    "section": "\n14.10 Zusammenfassen von Daten per Faktor",
    "text": "14.10 Zusammenfassen von Daten per Faktor\nGut und soll ich jetzt für jeden Faktorlevel überall den Mittelwert mit mean() berechnen? Geht das nicht einfacher? Ja, geht es. Im folgenden siehst du, wie du den verschiedene deskriptive Maßzahlen in einem Rutsch berechnen kannst.\n\ndata_tbl %>%\n  mutate(animal = as_factor(animal)) %>%\n  group_by(animal) %>%\n  summarise(mean = mean(jump_length),\n            sd = sd(jump_length),\n            median = median(jump_length),\n            quantiles = quantile(jump_length, \n                                 probs = c(0.25, 0.5, 0.75))) %>% \n  mutate(across(where(is.numeric), round, 2))\n\n# A tibble: 6 × 5\n# Groups:   animal [2]\n  animal  mean    sd median quantiles\n  <fct>  <dbl> <dbl>  <dbl>     <dbl>\n1 dog     8.13  2.14    8.2      6.65\n2 dog     8.13  2.14    8.2      8.2 \n3 dog     8.13  2.14    8.2      9   \n4 cat     4.74  1.9     4.3      3.65\n5 cat     4.74  1.9     4.3      4.3 \n6 cat     4.74  1.9     4.3      5.75"
  },
  {
    "objectID": "eda-ggplot.html",
    "href": "eda-ggplot.html",
    "title": "15  Visualisierung von Daten",
    "section": "",
    "text": "Ein wichtiger Teil in der Analyse von Daten ist die Visualisierung. Wir glauben keine Auswertung eines mathematischen Algorithmus, wenn wir nicht die Bestätigung in einer Abbildung sehen. Daher ist die Visualisierung die Grundlage für ein fundiertes, wissenschaftliches Arbeiten. In diesem Kapitel stelle ich dir verschiedene Abbilungen vor, die uns helfen werden zu Verstehen ob es einen Zusammenhang zwischen Y und X gibt. Wir haben ein \\(y\\) vorliegen, was wir auf die y-Achse eines Graphen legen und daneben dann mehrere Variablen bzw. Spalten die wir \\(x\\) nennen. Eine der Variablen legen wir auf die x-Achse des Graphen. Nach den anderen \\(x\\) färben wir die Abbildung ein."
  },
  {
    "objectID": "eda-ggplot.html#genutzte-r-pakete-für-das-kapitel",
    "href": "eda-ggplot.html#genutzte-r-pakete-für-das-kapitel",
    "title": "15  Visualisierung von Daten",
    "section": "\n15.1 Genutzte R Pakete für das Kapitel",
    "text": "15.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, ggmosaic, janitor)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "eda-ggplot.html#grundlagen-in-ggplot",
    "href": "eda-ggplot.html#grundlagen-in-ggplot",
    "title": "15  Visualisierung von Daten",
    "section": "\n15.2 Grundlagen in ggplot()",
    "text": "15.2 Grundlagen in ggplot()\nIm Gegensatz zu dem Pipe-Operator %>% nutzt ggplot den Operator + um die verschiedenen ggplot Funktionen (geom_) miteinander zu verbinden.\nWir nutzen in R das R Paket ggplot2 um unsere Daten zu visualisieren. Die zentrale Idee von ggplot2 ist, dass wir uns eine Abbildung wie ein Sandwich bauen. Zuerst legen wir eine Scheibe Brot hin und legen uns dann Scheibe für Scheibe weitere Schichten übereinander. Oder die Idee eines Bildes, wo wir erst die Leinwand definieren und dann Farbschicht über Farbschicht auftragen. Das Konzept von ggplot2ist schlecht zu beschreiben deshalb habe ich auch noch zwei Videos hierfür gemacht. Um den Prozess von ggplot2 zu visualisieren…\n\n\n\n\n\n\nGrundlagen von ggplot() im Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 16.0 - Trockenübung ggplot2 simpel und einfach erklärt als Video.\nSowie auch auf YouTube Einführung in R - Teil 16.1 - Abbildungen mit ggplot in R erstellen. Idee und Konzept von ggplot als Video. Also alles nochmal als Video - vielleicht einfacher nachzuvollziehen als in einem Fließtext.\n\n\nDie Funktion ggplot() ist die zentrale Funktion, die die Leinwand erschafft auf der wir dann verschiedene Schichten aufbringen werden. Diese Schichten heißen geom. Es gibt nicht nur ein geom sondern mehrere. Zum Beispiel das geom_boxplot für die Erstellung von Boxplots, das geom_histogram für die Erstellung von Histogrammen. Die Auswahl ist riesig. Die einzelnen Schichten werden dann über den Operator + miteinander verbunden. Soviel erstmal zur Trockenübung. Schauen wir uns das ganze einmal an einem Beispiel an.\n\n15.2.1 Datenbeispiel\nWir importieren den Datensatz flea_cat_dog.xlsx und wollen einzelne Variablen visualisieren. Wir kennen den Datensatz schon aus dem Kapitel 5. Dennoch nochmal hier der Datensatz in Tabelle 15.1.\n\nflea_dog_cat_tbl <- read_excel(\"data/flea_dog_cat.xlsx\") %>% \n  mutate(animal = as_factor(animal))\n\nSpaltennamen sind in Englisch und haben keine Leerzeichen. Die Funktion clean_names() aus dem R Paket janitor ist hier eine Hilfe.\nIm folgenden ist es wichtig, dass du dir die Spaltennamen merkst. Wir können nur die exakten, wortwörtlichen Spaltennamen verwenden. Sonst erhalten wir einen Fehler. Deshalb haben wir auch keine Leerzeichen in den Spaltennamen.\n\n\n\n\nTabelle 15.1— Beispieldatensatz für Eigenschaften von Flöhen von zwei Tierarten.\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n8\n1\n\n\ndog\n11.8\n17\n6\n1\n\n\ndog\n8.2\n12\n8\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n7\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n6\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n5\n0\n\n\n\n\n\n\n\n15.2.2 Erste Abbildung in ggplot()\nDer folgende R Code erstellt die Leinwand in der Abbildung 15.1 für die folgende, zusätzliches Schichten (geom).\n\nggplot(data = flea_dog_cat_tbl, \n       aes(x = animal , y = jump_length))\n\nWir schauen uns einmal den Code im Detail an.\n\n\nggplot ruft die Funktion auf. Die Funktion ist dafür da den Plot zu zeichnen.\n\ndata = flea_dog_cat_tbl bennent den Datensatz aus dem der Plot gebaut werden soll.\n\naes()ist die Abkürzung für aesthetics und beschreibt, was auf die x-Achse soll, was auf die y-Achse soll sowie ob es noch andere Faktoren in den Daten gibt.\n\n\nx braucht den Spaltennamen für die Variable auf der x-Achse.\n\ny braucht den Spaltennamen für die Variable auf der y-Achse.\n\n\n\nFaktoren meint hier andere Gruppenvariablen. Variablen sind ein anderes Wort für Spalten. Also Variablen die wir mit as_factorerschaffen haben.\n\n\n\n\nAbbildung 15.1— Leere ggplot() Leinwand mit den Spalten animal und jump_length aus dem Datensatz flea_dog_cat_tbl.\n\n\n\n\nWir sehen, dass wir nichts sehen in Abbildung 15.1. Der Grund ist, dass wir noch kein geom hinzugefügt haben. Das geom beschreibt nun wie die Zahlen in der Datentabelle flea_dog_cat_tbl visualisiert werden sollen."
  },
  {
    "objectID": "eda-ggplot.html#häufig-verwendete-abbildungen",
    "href": "eda-ggplot.html#häufig-verwendete-abbildungen",
    "title": "15  Visualisierung von Daten",
    "section": "\n15.3 Häufig verwendete Abbildungen",
    "text": "15.3 Häufig verwendete Abbildungen\nIn diesem Kapitel wollen wir durch die häufigsten und wichtigsten Abbildungen in der explorativen Datenanalyse durchghen. Das wären im folgenden diese Abbildungen:\n\n\nHistogramm in Kapitel 15.3.1 für mehr als 20 Beobachtungen (pro Gruppe). Wir nutzen ein Histogramm um die Verteilung einer Variable zu visualisieren.\n\nBoxplot in Kapitel 15.3.3 für 5 bis 20 Beobachtungen (pro Gruppe). Ebenso wie bei einem Histogramm, geht es bei einem Boxplot auch um die Verteilung der einer Variable.\n\nDotplot in Kapitel 15.3.4 für 3 bis 5 Beobachtungen (pro Gruppe). Hier geht es weniger um die Verteilung der Variable, sondern darum die wenigen Beobachtungen zu visualisieren.\n\nScatterplot in Kapitel 15.3.5 für zwei kontinuierliche Variablen. Auch xy-Plot genannt. Die Abbildung, die dir bekannt sein müsste. Wir zeichnen hier eine Grade durch eine Punktewolke.\n\nMosaicplot in Kapitel 15.3.6 für zwei diskrete Variablen. Eine etwas seltene Abbildung, wenn wir Variablen abbilden wollen, die diskret sind bzw. aus Kategorien bestehen.\n\nKonkret ist eine Variable gleich einer Spalte in einem Datensatz.\n\n\n\n\n\n\nHistogramm, Boxplot, Scatterplot und Mosaicplot im Video\n\n\n\nDu findest auf YouTube Einführung in R - Teil 16.2 - Histogramm, Boxplot, Scatterplot und Mosaicplot mit ggplot in R als Video. Weitere Videos werden dann noch folgen und ergänzt.\n\n\n\n15.3.1 Histogramm\nWir nutzen für die Erstellung eines Histogramms den Datensatz dog_fleas_hist.csv. Wir brauchen für ein anständiges Histogramm, wo du auch was erkennen kannst, mindestens 20 Beobachtung. Am besten mehr noch mhr Beobachtungen. Deshalb schauen wir uns jetzt einmal 39 Hunde an und zählen wieviele Flöhe die Hunde jeweils haben, dargestellt in der Spalteflea_count. Darüber hinaus bestimmen wir auch noch das mittlere Gewicht der Flöhe auf dem jeweiligen Hund, dargestellt in der Spalte flea_weight.\n\ndog_fleas_hist_tbl <- read_csv(\"data/dog_fleas_hist.csv\")\n\n\n\n\n\nTabelle 15.2— Beispieldatensatz für die Anzahl an Flöhen auf 39 Hunden. Gezählt wurde die Anzahl an Flöhen flea_count und das gemittelte Gewicht der Flöhe flea_weight.\n\nflea_count\nflea_weight\n\n\n\n0\n0.00\n\n\n1\n7.43\n\n\n4\n21.04\n\n\n2\n20.07\n\n\n1\n21.90\n\n\n0\n0.00\n\n\n2\n24.96\n\n\n1\n27.08\n\n\n5\n16.58\n\n\n1\n19.92\n\n\n0\n0.00\n\n\n0\n0.00\n\n\n2\n24.63\n\n\n4\n21.64\n\n\n3\n20.97\n\n\n1\n23.15\n\n\n0\n0.00\n\n\n3\n14.91\n\n\n1\n19.39\n\n\n2\n17.66\n\n\n1\n19.15\n\n\n1\n25.10\n\n\n2\n26.38\n\n\n2\n19.33\n\n\n2\n13.29\n\n\n1\n17.81\n\n\n0\n0.00\n\n\n2\n23.56\n\n\n1\n18.64\n\n\n1\n15.64\n\n\n3\n19.88\n\n\n1\n18.40\n\n\n1\n25.17\n\n\n0\n0.00\n\n\n0\n0.00\n\n\n\n\n\n\nTabelle 15.2 zeigt den Datensatz dog_fleas_hist.csv. Wir wollen jetzt die Variable flea_count und flea_weight jeweils abbilden. Wir beginnen mit der diskreten Variable flea_count. Im Gegensatz zu der Variable flea_weight haben wir bei der Anzahl gleiche Zahlen vorliegen, die wir dann zusammen darstellen können. Abbildung 15.2 zeigt die Darstellung der Tabelle. Auf der x-Achse ist die Anzahl an Flöhen dargestellt. Auf der y-Achse die Anzahl der jeweiligen Anzahl an Flöhen. Das klingt jetzt etwas schief, aber schauen wir uns die Abbilung näher an.\n\n\n\n\nAbbildung 15.2— Die Anzahl von Flöhen auf 39 Hunden. Jeder Punkt entspricht einem Hund und der entsprechenden Anzahl an Flöhen auf dem Hund.\n\n\n\n\nWir sehen in Abbildung 15.2 dasacht Hunde keine Flöhe hatten - also eine Anzahl an Flöhen von 0. Auf der anderen Seite hatten zwei Hunde vier Flöhe und ein Hund hatte sogar fünf Flöhe. Wir sehen also die Verteilung der Anzahl an Flöhen über alle unsere 39 Hundebeobachtungen.\nWir schauen uns aber die Verteilung der Anzahl an Flöhen meist nicht in der Form von gestapelten Punkten an, sondern in der Form eines Histogramms also einem Balkendiagramm. Abbildung 15.3 zeigt das Histogramm für die Anzahl der Flöhe.\n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_count)) +\n  geom_histogram(binwidth = 1, fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Anzahl Flöhe\", y = \"Anzahl\") \n\n\n\nAbbildung 15.3— Histogramm der Anzahl von Flöhen auf 39 Hunden.\n\n\n\n\nWas sehen wir in der Abbildung 15.3? Anstatt von gestapelten Punkten sehen wir jetzt Balken, die die jeweilige Anzahl an Flöhen zusammenfassen. Der Unterschied ist bei einer diskreten Variable wie der Anzahl (eng. count) relativ gering.\nAnders sieht es für kontenuierliche Variablen mit Kommazahlen aus. Schauen wir uns das Gewicht der Flöhe an, so sehen wir, dass es sehr viele Zahlen gibt, die nur einmal vorkomen. Abbildung 15.4 zeigt das Histogramm für das Geicht der Flöhe.\n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_weight)) +\n  geom_histogram(binwidth = 1, fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Gewicht [mg]\", y = \"Anzahl\") \n\n\n\nAbbildung 15.4— Histogramm des Gewichts von Flöhen auf 39 Hunden.\n\n\n\n\nWie entsteht nun ein Hisotgramm für konetnierliche Zahlen? Schauen wir uns dafür einmal ein kleineres Datenbeispiel an, in dem wir nur Flöhe mit einem Gewicht größer als 11 und kleiner als 19 wäheln. Wir nutzen dazu die Funktion filter(flea_weight > 11 & flea_weight < 19). Wir erhalten folgende Zahlen und das entsprechende Histogramm.\n\n\n[1] 13.29 14.91 15.64 16.58 17.66 17.81 18.40 18.64\n\n\n\n\nAbbildung 15.5— Zusammenhang zwischen den einzelnen Beobachtungen und der Höhe der einzelnen Balken am Beispiel von acht Hunden.\n\n\n\n\nAbbildung 15.5 zeigt das Histogramm der reduzierten Daten. Die roten vertikalen Linien zeigen die Position der einzelnen Flohgewichte auf der x-Achse. Die blauen Hilfslinien machen nochmal klarer, wie hoch die einzelnen Balken sind sowie welche Beobachtungen auf der x-Achse in den jeweiligen Balken mit eingehen. Wir sehen, dass wir einen Hund mit Flöhen haben, die zwischen 12.5 und 13.5 wiegen - der entsprechende Balken erhält die Anzahl von eins. Auf der anderen Seite sehen wir, dass es drei Hunde mit Flöhen, die zwischen 17.5 und 18.5 wiegen. Daher wächst der Balken auf eine Anzahl von drei.\nWir können mit der Option binwidth in dem geom_histogram() einstellen, wie breit auf der x-Achse die jeweiligen Balken sein sollen. Hier empfiehlt es sich verschiedene Zahlen für binwidthauszuprobieren.\n\n15.3.2 Density Plot\nEine weitere Möglichkeit sich eine Verteilung anzuschauen, ist die Daten nicht als Balkendiagramm sondern als Densityplot - also Dichteverteilung - anzusehen. Im Prinzip verwandeln wir die Balken in eine Kurve. Damit würden wir im Prinzip unterschiedliche Balkenhöhen ausgleichen udn eine “glattere” Darstellung erreichen. Wir wir aber gleich sehen werden, benötigen wir dazu eine Menge an Beoabchtungen und auch dann ist das Ergebnis eventuell nicht gut zu interpretieren.\n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_count)) +\n  geom_histogram(binwidth = 1, fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Anzahl Flöhe\", y = \"Anzahl\")\n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_count)) +\n  geom_density(fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Anzahl Flöhe\", y = \"Häufigkeit\") \n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n(b) Densityplot\n\n\n\n\nAbbildung 15.6— Zusammenhang von Histogramm und Densityplot an der Anzahl der Flöhe auf 39 Hunden.\n\n\n\nAbbildung 15.6 zeigt auf der linken Seite erneut die Abbildung des Histogramms als Balkendiagramm für die Anzahl der Flöhe auf den 39 Hunden. Auf der rechten Seite die entsprechenden gleichen Daten als Denistyplot. Klar ist die Wellenbewegung des Densityplots zu erkennen. Hier leigen zu wenige Beobachtungen und Kategorien auf der x-Achse vor, so dass der Densityplot nicht zu empfehlen ist.\n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_weight)) +\n  geom_histogram(binwidth = 1, fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Gewicht [mg]\", y = \"Anzahl\") \n\nggplot(data = dog_fleas_hist_tbl, aes(x = flea_weight)) +\n  geom_density(fill = \"gray\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Gewicht [mg]\", y = \"Häufigkeit\") \n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n(b) Densityplot\n\n\n\n\nAbbildung 15.7— Zusammenhang von Histogramm und Densityplot am Gewicht der Flöhe auf 39 Hunden.\n\n\n\nAbbildung 15.7 zeigt auf der linken Seite erneut die Abbildung des Histogramms als Balkendiagramm für das Gewicht der Flöhe auf den 39 Hunden. Insbesondere bei dieser Abbildung erkennst du die Nachteile des Densityplot. Dadurch das es einen Peak von acht Hunden mit einem Flohgewicht von 0 gibt, zeigt der Densityplot eine seltsame Wellenform. Es emppfielt sich daher die Daten zuerst als Histogramm zu betrachten.\n\n15.3.3 Boxplot\nIn Kapitel 14 haben wir den Median und die Quartile kennengelernt. Mit dem Boxplot können wir den Median und die Quartile visualisieren. In Abbildung 15.8 sehen wir einen Boxplot, der den Median und die Quartile visualisiert. Die Box wird aus dem IQR gebildet. Der Median wird als Strich in der Box gezeigt. Die Schnurrhaare (eng. Whiskers) sind das 1.5 fache des IQR. Punkte die außerhalb der Schnurrhaare liegen werden als einzelne Punkte dargestellt. Diese einzelnen Punkte werden auch als Ausreißer (eng. Outlier) bezeichnet.\n\n\n\nAbbildung 15.8— Ein Boxplot der die statistischen Maßzahlen Median und Quartile visualisiert. Die Box wird aus dem IQR gebildet. Der Median wird als Strich in der Box gezeigt. Die Schnurrhaare sind das 1.5 fache des IQR. Punkte die außerhalb der Schnurrhaare liegen werden als einzele Punkte dargestellt.\n\n\n\nIn Abbildung 15.9 sehen wir den Zusammenhang zwischen einem Histogramm, Densityplot und dem Boxplot. Der Median \\(\\tilde{y}\\) im Boxplot zeigt die höchste Stelle des Densityplots an. Durch einen Boxplot kann die Verteilung der entsprechenden Zahlen abgeschätzt werden.\n\n\nAbbildung 15.9— Der Zusammenhang von Histogram, Densityplot und Boxplot.\n\n\nDie “liegende” Darstellung des Boxplots dient nur der Veranschaulichung und dem Verständnis des Zusammenhangs von Histogramm und Boxplot. In der Abbildung 15.10 sehen wir drei Boxplots für einen Faktor mit drei Leveln. Jedes Level wird duch einen Boxplot dargestellt. Zum Beispiel eine Düngerbehandlung mit drei Konzentrationen. Auf der x-Achse würden wir die Behandelung finden und auf der y-Achse das Trockengewicht in [kg/ha].\n\n\nAbbildung 15.10— Typische Darstellung von drei Gruppen jeweils dargestellt durch einen Boxplot. Boxplots werden in der Anwendung stehtend dargestellt. Insbesondere wenn die Boxplots mehrere Gruppen repräsentieren.\n\n\nWie erstellen wir nun einen Boxplot in R? Zuerst laden wir die Daten mit der Funktion read_excel() in R, wenn du die Daten als .xlsx Datei vorliegen hast. Im XX kannst du nochmal das Importieren von Daten wiederholen.\n\nflea_dog_cat_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n\n\n\n\nAbbildung 15.11— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nIn Abbildung 15.11 ist der Boxplot für die Daten aus der Datei flea_dog_cat.xlsx dargestellt. Auf der x-Achse finden wir die Tierart als cat und dog. Auf der y-Achse ist die Sprungweite in [cm] dargestellt.\nWir erkennen auf einen Blick, dass die Sprungweite von den Hundeflöhen weiter ist als die Sprungweite der Katzenflöhe. Im Weiteren können wir abschätzen, dass die Streuung etwa gleich groß ist. Die Boxen sind in etwa gleich groß und die Whiskers in etwa gleich lang.\n\nggplot(data = flea_dog_cat_tbl, aes(x = animal, y = jump_length,\n                                    fill = animal)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.25, shape = 1) +\n  theme_bw() +\n  labs(x = \"Tierart\", y = \"Sprungweite [cm]\") \n\n\n\nAbbildung 15.12— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nWir neigen dazu die Boxplots überzuinterpretieren, wenn die Anzahl der Beobachtungen klein ist. Deshalb können wir mit dem geom_jitter() noch die Beobachtungen zu den Boxplot ergänzen, dargestellt in Abbildung 15.12. Die Funktion geom_jitter() streut die Punkte zufällig, so dass keine Punkte übereinanderliegen. Wir haben hier die Streuuweite durch die Option width = 0.25 etwas eingeschränkt. Darüber hinaus habe wir das Aussehen der Punkte mit shape = 1 geändert, so dass wir die Jitter-Punkte von den potenziellen Ausreißer-Punkten unterscheiden können. Du kannst auch andere Zahlen hinter shape eintragen um verschiedene Punktesymbole durchzuprobieren. Eine Übersicht an shapes findest du auch hier unter Cookbook for R > Graphs > Shapes and line types.\n\n15.3.4 Dotplot\nWenn wir weniger als fünf Beobachtungen haben, dann ist meist ein Boxplot verzerrend. Wir sehen eine Box und glauben, dass wir viele Datenpunkte vorliegen haben. Bei 3 bis 7 Beobachtungen je Gruppe bietet sich der Dotplot als eine Lösung an. Wir stellen hier alle Beobachtungen als einzelne Punkte dar.\nWie erstellen wir nun einen Dotplot in R? Zuerst laden wir die Daten mit der Funktion read_excel() in R, wenn du die Daten als .xlsx Datei vorliegen hast. Im XX kannst du nochmal das Importieren von Daten wiederholen.\n\nflea_dog_cat_tbl <- read_excel(\"data/flea_dog_cat.xlsx\")\n\n\nggplot(data = flea_dog_cat_tbl, aes(x = animal, y = grade,\n                                    fill = animal)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\") +\n  theme_bw() +\n  labs(x = \"Tierart\", y = \"Boniturnote [1-9]\") \n\n\n\nAbbildung 15.13— Der Dotplot für die Anzahl der Flöhe für die beiden Tierarten Hund und Katze.\n\n\n\n\nIn Abbildung 15.13 sehen wir den Dotplot aus der Datei flea_dog_cat.xlsx. Auf der x-Achse sind die Level des Faktors animal dargestellt und auf der y-Achse die Notenbewertung grade der einzelnen Hunde und Katzen. Die Funktion geom_dotplot() erschafft das Layer für die Dots bzw. Punkte. Wir müssen in der Funktion noch zwei Dinge angeben, damit der Plot so aussieht, dass wir den Dotplot gut interpretieren können. Zum einen müssen wir die Option binaxis = y wählen, damit die Punkte horizontal geordent werden. Zum anderen wollen wir auch, dass die Punkte zentriert sind und nutzen dafür die Option stackdir = center.\n\nggplot(data = flea_dog_cat_tbl, aes(x = animal, y = grade,\n                            fill = animal)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\") +\n  stat_summary(fun = median, fun.min = median, fun.max = median,\n               geom = \"crossbar\", width = 0.5) +\n  theme_bw() +\n  labs(x = \"Tierart\", y = \"Boniturnote [1-9]\") \n\n\n\nAbbildung 15.14— Der Dotplot für die Anzahl der Flöhe für die beiden Tierarten Hund und Katze. Die schwarze Linie stelt den Median für die beiden Tierarten dar.\n\n\n\n\nNun macht es wenig Sinn bei sehr wenigen Beobachtungen noch statistische Maßzahlen mit in den Plot zu zeichnen. Sonst hätten wir auch gleich einen Boxplot als Visualisierung der Daten wählen können. In Abbildung 15.14 sehen wir die Ergänzung des Medians. Hier müssen wir etwas mehr angeben, aber immerhin haben wir so eine Idee, wo die “meisten” Beobachtungen wären. Aber auch hier ist Vorsicht geboten. Wir haben sehr wenige Beobachtungen, so dass eine Beobachtung mehr oder weniger große Auswirkungen auf den Median und die Interpretation hat.\n\n15.3.5 Scatterplot\nDer Scatterplot wird auch xy-Plot genannt. Wir stellen in einem Scatterplot zwei kontenuierliche Variablen dar. Dann wollen wir eine Linie durch die Punkte legen. Im Prinzip fragen wir uns, wie hänge die Werte auf der y-Achse von den Werten auf der x-Achse ab? Wenn sich also die Werte auf der x-Achse erhöhen, wie verhalten sich dann die Werte auf der y-Achse?\n\nggplot(data = flea_dog_cat_tbl, aes(x = flea_count, y = jump_length)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Anzahl der Flöhe\", y = \"Sprungweite in [cm]\") \n\n\n\nAbbildung 15.15— Zusammenhang zwischen der Sprungweite in [cm] und der Anzahl an Flöhen auf den 39 Hunden. Jeder Punkt stellt einen Hund dar.\n\n\n\n\nAbbildung 15.15 zeigt den Scatterplot für die Spalte flea_count auf der x-Achse und jump_length auf der y-Achse. Mit der Funktion geom_point() können wir die Punktepaare für jede Beobachtung zeichnen. In unserem Fall zeichnen wir mit der Funktion stat_smooth() noch die entsprechende Grade durch die Punkte. Es handelt sich hierbei um eine Regression. Du kannst im Kapitel XX mehr darüber erfahren.\n\n15.3.6 Mosaic Plot\nWenn wir zwei Spalten visualisieren wollen, die aus zwei Faktoren bestehen mit jeweils zwei Leveln, dann nutzen wir den Mosaic Plot. Wir nutzen den Datensatz flea_dog_cat.xlsx mit vierzehn Beobachtungen. Schauen wir uns einmal die 2x2 Kreuztabelle der beiden Spalten animal and infected an.\n\nflea_dog_cat_tbl %>%\n  mutate(animal = factor(animal, levels = c(\"dog\", \"cat\"))) %>% \n  tabyl(animal, infected) \n\n animal 0 1\n    dog 4 3\n    cat 5 2\n\n\nWir sehen in der Tabelle, dass wir mehr uninfizierte Tiere (n = 9) als infizierte Tiere haben (n = 5). Die Aufteilung zwischen den beiden Tierarten ist nahezu gleich. Im folgenden wollen wir diese Tabelle durch einen Mosaic Plot einmal visualisieren.\n\nggplot(data = flea_dog_cat_tbl) +\n  geom_mosaic(aes(x = product(animal, infected), fill = animal)) \n\n\n\nAbbildung 15.16— Visualisierung einer 2x2 Tabelle als Mosaic Plot. Die unterschiedlich großen Flächen geben die Verhältnisse wieder.\n\n\n\n\nAbbildung 15.16 zeigt den Mosaic Plot für die Variable animal and infected. Die untrschiedlich großen Flächen bilden die Verhältnisse der 2x2 Tabelle ab. So sehen wir, dass es mehr uninfizierte Tiere als infizierte Tiere gibt. Am meisten gibt es uninfizierte Katzen. Am wenigstens treten infizierte Katzen auf.\n\n15.3.7 Überschriften, Achsen und Legenden\nWenn du mehr machen willst, also die Überschriften anpassen oder aber die Achsenbeschriftung ändern, dann gibt es hier global Hilfe im ggplot Manual. Die Webseite R Cookbook hat auch spezielle Hilfe für ggplot().\n\nÜberschriften von Abbildungen\nAchsenbeschriftung\nLegende\nFarben\n\nIm Kapitel 1.2 findest du Informationen zum R Tutorium, wann und wo es stattfindet.\nIn Abbildung 15.17 siehst du eine Abbildung mit Titel und veränderten Beschriftungen. Die Möglichkeiten sind nahezu unbegrenzt und sprengen auch hier den Rahmen. Im Zweifel im R Tutorium vorbeischauen oder aber in der Vorlesung fragen.\n\nggplot(data = flea_dog_cat_tbl, aes(x = animal, y = jump_length,\n                                    fill = animal)) +\n  geom_boxplot() +\n  labs(title = \"Frischgewicht in Abhängigkeit von der Behandlung\",\n       x = \"Behandlung\", y = \"Frischgewicht in kg/ha\") +\n  scale_x_discrete(labels = c(\"Katze\", \"Hund\")) +\n  scale_fill_discrete(name = \"Behandlung\", labels = c(\"Katze\", \"Hund\")) +\n  theme_bw() \n\n\n\nAbbildung 15.17— Beispielhafte Abbildung mit Titel und geänderter Achsenbeschrittung"
  },
  {
    "objectID": "stat-tests-preface.html",
    "href": "stat-tests-preface.html",
    "title": "Frequentistische Hypothesentests",
    "section": "",
    "text": "Das statistische Testen - eine Geschichte voller Missverständnisse. Wir wollen uns in diesem Kapitel mit den Grundlagen des frequentistischen Hypothesentestens beschäftigen. Wenn ich hier einen Unterschied mache, dann muss es ja auch noch ein anderes Hypothesentesten geben. Ja, das nennt man dann bayesianische Statistik und kommt eventuell mal später. Wir konzentrieren uns aber zuerst auf frequentistische Hypothesentesten was seit gut hundert Jahren genutzt wird. Ich werde hier textlich nur einen kurzen Einstieg liefern. Vielleicht wird es in den folgenden Jahren länger aber aktuell (Ende 2022) bleiben wir hier bei einem kurzen Einstieg.\nBeginnen wir mit der Logik der Forschung oder allgemeiner formuliert, als die Grundlage der Wissenschaft. Wir basieren all unsere Entscheidungen in der Wissenschaft auf dem Falsifikationsprinzip. Also bitte merken, wir können nur ablehnen (eng. reject).\nWir wollen hier auf keinen Fall die Leistungen von Altvorderen schmälern. Dennoch hatten Ronald Fischer (1890 - 1962), als der Begründer der Statistik, andere Vorraussetzungen als wir heutzutage. Als wichtigster Unterschied sei natürlich das Gerät genannt, an dem du gerade diese Zeilen liest: dem Computer. Selbst die Erstellung einfachster Abbildungen war sehr, sehr zeitaufwendig. Die Berechnung von Zahlen lohnte sich mehr, als die Zahlen zu visualisieren. Insbesondere wenn wir die Explorative Datenanalyse nach John Tukey (1915 - 2000) durchführen. Undenkbar zu den Zeiten von Ronald Fischer mehrere Abbildungen unterschiedlich nach Faktoren einzufärben und sich die Daten anzugucken.\nNeben dieser Begrenzung von moderner Rechenkapazität um 1900 gab es noch eine andere ungünstige Entwicklung. Stark vereinfacht formuliert entwickelte Ronald Fischer statistische Werkzeuge um abzuschätzen wir wahrscheinlich die Nullhypothese unter dem Auftreten der beobachteten Daten ist. Nun ist es aber so, dass wir ja auch eine Entscheidung treffen wollen. Nach der Logik der Forschung wollen wir ja eine Hypothese falsifizieren, in unserem Fall die Nullhypothese. Die Entscheidungsregeln, also die statistische Testtheorie, kommen nun von Jerzy Neyman (1894 - 1981) und Egon Pearson (1895 - 1980), beide als die Begründer der frequentistischen Hypothesentests.\nSchlussendlich gibt es noch eine andere Störmung in der Statistik, die auf den mathematischen Formeln von Thomas Bayes (1701 - 1761) basieren. In sich eine geschlossene Theorie, die auf der inversen Wahrscheinlichkeit basiert. Das klingt jetzt etwas schräg, aber eigentlich ist die bayesianische Statistik die Statistik, die die Fragen um die Alternativehypothese beantwortet. Der Grund warum die bayesianische Statistik nicht angewendet wurde, war der Bedarf an Rechenleistung. Die bayesiansiche Statistik lässt sich nicht händisch in endlicher Zeit lösen. Dieses technische Problem haben wir aber nicht mehr. Eigentlich könnten wir also die bayesiansiche Statistik verwenden. Wir wollen hier aber (noch) nicht auf die bayesianische Statistik eingehen, das werden wir später tun.\nWenn du allgemein Interesse hast an der Geschichte der Statistik dann sei auf Salsburg (2001) verwiesen. Ein sehr schönes Buch, was die geschichtlichen Zusammenhänge nochmal aufzeigt.\nKommen wir aber nun zu den wichtigeren Punkten. Das Kapitel ist sehr umfangreich und enthält viele Informationen, die wir teilweise später nochmal brauchen. Darüber hinaus müssen wir noch das Lernen und Verstehen von der Anwendung unterscheiden."
  },
  {
    "objectID": "stat-tests-preface.html#sec-hypothesen",
    "href": "stat-tests-preface.html#sec-hypothesen",
    "title": "Frequentistische Hypothesentests",
    "section": "Die Hypothesen",
    "text": "Die Hypothesen\n\n\nIm Anhang A findest du verschiedene Beispiele zu Auswertungen von Datenbeispielen.\nWir können auf allen Daten einen statistischen Test rechnen und erhalten statistische Maßzahlen wie eine Teststatistik oder einen p-Wert. Nur leider können wir mit diesen statistischen Maßzahlen nicht viel anfangen ohne die Hypothesen zu kennen. Jeder statistische Test testet eine Nullhypothese. Ob diese Hypothese dem Anwender nun bekannt ist oder nicht, ein statistischer Test testet eine Nullhypothese. Daher müssen wir uns immer klar sein, was die entsprechende Nullhypothese zu unserer Fragestellung ist. Wenn du hier stockst, ist das ganz normal. Eine Fragestellung mit einer statistischen Hypothese zu verbinden ist nicht immer so einfach gemacht.\n\n\n\n\n\n\nDie Nullhypothese \\(H_0\\) und die Alternativehypothese \\(H_A\\)\n\n\n\nDie Nullhypothese \\(H_0\\) nennen wir auch die Null oder Gleichheitshypothese. Die Nullhypothese sagt aus, dass zwei Gruppen gleich sind oder aber kein Effekt zu beobachten ist.\n\\[\nH_0: \\bar{y}_{1} = \\bar{y}_{2}\n\\]\nDie Alternativehypothese \\(H_A\\) oder \\(H_1\\) auch Alternative genannt nennen wir auch Unterschiedshypothese. Die Alternativehypothese besagt, dass ein Unterschied vorliegt oder aber ein Effekt vorhanden ist.\n\\[\nH_A: \\bar{y}_{1} \\neq \\bar{y}_{2}\n\\]\n\n\nAls Veranschaulichung nehmen wir das Beispiel aus Kapitel 5. Wir formulieren als erstes die Fragestellung. Eine Fragestellung endet mit einem Fragezeichen.\nLiegt ein Unterschied zwischen den Sprungweiten von Katzen und Hundeflöhen vor?\nWir können die Frage auch anders formulieren.\nSpringen Hunde und Katzenflöhe unterschiedlich weit?\nWichtig ist, dass wir eine primäre Fragestellung formulieren. Wir können auch mehrere Fargen an einen Datensatz haben. Das ist auch vollkommen normal. Nur hat jede Fragestellung ein eigenes Hypothesenpaar. Wir bleiben aber bei dem simplen Beispiel.\nWie sieht nun die statistische Hypothese in diesem Beispiel aus? Wir wollen uns die Sprungweite in [cm] anschauen. In diesem Fall wollen wir die mittlere Sprungweite der Hundeflöhe \\(\\bar{y}_{dog}\\) mit der mittleren Sprungweite der Katzenflöhe \\(\\bar{y}_{cat}\\) vergleichen. Es ergibt sich folgendes Hypothesenpaar.\n\\[\\begin{align*}\nH_0: \\bar{y}_{dog} &= \\bar{y}_{cat} \\\\  \nH_A: \\bar{y}_{dog} &\\neq \\bar{y}_{cat} \\\\   \n\\end{align*}\\]\nDas Falisifkationsprinzip - wir können nur Ablehnen - kommt hier zusammen mit der frequentistischen Statistik in der wir nur eine Wahrscheinlichkeitsaussage über das Auftreten der Daten \\(D\\) - unter der Annahme \\(H_0\\) gilt - treffen können.\nEs ist wichtig sich in Erinnerung zu rufen, dass wir nur und ausschließlich Aussagen über die Nullhypothese treffen werden. Das frequentistische Hypothesentesten kann nichts anders. Wir kriegen keine Aussage über die Alternativhypothese sondern nur eine Abschätzung der Wahrscheinlichkeit des Auftretens der Daten im durchgeführten Experiment, wenn die Nullhypothese wahr wäre."
  },
  {
    "objectID": "stat-tests-preface.html#die-testentscheidung",
    "href": "stat-tests-preface.html#die-testentscheidung",
    "title": "Frequentistische Hypothesentests",
    "section": "Die Testentscheidung…",
    "text": "Die Testentscheidung…\nIn den folgenden Kapiteln werden wir verschiedene statistische Tests kennenlernen. Alle statistischen Tests haben gemein, dass ein Test eine Teststatistik \\(T_{calc}\\) berechnet. Darüber hinaus liefert jeder Test auch einen p-Wert (eng. p-value). Manche statistischen Test geben auch ein 95% Konfidenzintervall wieder. Eine Testentscheidung gegen die Nullhypothese \\(H_0\\) kann mit jedem der drei statistischen Maßzahlen durchgeführt werden. Die Regel für die Entscheidung, ob die Nullhypothese \\(H_0\\) abgelehnt werden kann, ist nur jeweils anders. In Tabelle 1 sind die Entscheidungsregeln einmal zusammengefasst.\n\n\n\nTabelle 1— Zusammenfassung der statistischen Testentscheidung unter der Nutzung der Teststatistik, dem p-Wert und dem 95% Konfidenzintervall. Die Entscheidung nach der Teststatistik ist veraltet und dient nur dem konzeptionellen Verständnisses. In der Forschung angewandt wird der p-Wert und das 95% Konfidenzintervall. Im Fall des 95% Konfidenzintervalls müssen wir noch unterschieden, ob wir einen Mittelwertsunterschied \\(\\Delta_{A-B}\\) oder aber einen Anteilsunterschied \\(\\Delta_{A/B}\\) betrachten.\n\n\n\n\n\n\n\n\nTeststatistik\np-Wert\n95% Konfidenzintervall\n\n\n\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(\\boldsymbol{KI_{1-\\alpha}}\\)\n\n\nH\\(_0\\) ablehnen\n\\(T_{calc} \\geq T_{\\alpha = 5\\%}\\)\n\\(Pr(\\geq T_{calc}| H_0) \\leq \\alpha\\)\n\n\\(\\Delta_{A-B}\\): enthält nicht 0\n\n\n\nH\\(_0\\) ablehnen\n\n\n\n\\(\\Delta_{A/B}\\): enthält nicht 1\n\n\n\n\n\n\nWir wollen in den folgenden Abschnitten die jeweiligen Entscheidungsregeln eines statistisches Tests einmal durchgehen.\n\nDie Testentscheidung gegen die Nullhypothese anhand der Teststatistik in Kapitel 2.1\n\nDie Testentscheidung gegen die Nullhypothese anhand dem p-Wert in Kapitel 2.2\n\nDie Testentscheidung gegen die Nullhypothese anhand des 95% Konfidenzintervall in Kapitel 2.3\n\n\n\n\n\n\n\n\nStreng genommen gilt die Regel \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) nur für eine Auswahl an statistischen Tests siehe dazu auch Kapitel 2.1. Bei manchen statistischen Tests ist die Entscheidung gedreht. Hier lassen wir das aber mal so stehen…\n… anhand der Teststatistik\n\n\n\n\n\n\nPrinzip des statistischen Testens I - Die Teststatistik\n\n\n\nDu findest auf YouTube Prinzip des statistischen Testens I - Die Teststatistik als Video. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nWir wollen uns dem frequentistischen Hypothesentesten über die Idee der Teststatistik annähern. Im folgenden sehen wir die Formel für den t-Test. Den t-Test werden wir im Kapitel 16 uns nochmal detaillierter anschauen. Hier nutzen wir die vereinfachte Formel um das Konzept zu verstehen.\n\\[\nT_{calc}=\\cfrac{\\bar{y}_1-\\bar{y}_2}{s_{p} \\cdot \\sqrt{2/n_g}}\n\\]\nmit\n\n\n\\(\\bar{y}_1\\) dem Mittelwert für die erste Gruppe.\n\n\\(\\bar{y}_2\\) dem Mittelwert für die zweite Gruppe.\n\n\\(s_{p}\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{s_A + s_B}{2}\\).\n\n\\(n_g\\) der Gruppengröße der gruppen. Wir nehmen an beide Gruppen sind gleich groß.\n\nWir benötigen also zwei Mittelwerte \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\) und deren gepoolte Standardabweichung \\(s_p\\) sowie die Anzahl der Beobachtungen je Gruppe \\(n_g\\). Wenden wir die Formel des t-Tests einmal auf den folgenden Beispieldatensatz an. In ?tbl-dog-cat-small-delta ist eine Datenbeispiel gegeben.\n\n\n\n\nTabelle 2— Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.\n\nanimal\njump_length\n\n\n\ncat\n8.5\n\n\ncat\n9.9\n\n\ncat\n8.9\n\n\ncat\n9.4\n\n\ndog\n8.0\n\n\ndog\n7.2\n\n\ndog\n8.4\n\n\ndog\n7.5\n\n\n\n\n\n\nWir berechnen nun die Mittelwerte und die Standardabweichungen aus der obigen Datentabelle. Die Werte setzen wir dann in die Formel ein.\n\\[\nT_{calc}=\\cfrac{9.2 - 7.8}{\\cfrac{(0.6 + 0.5)}{2} \\cdot \\sqrt{2/4}} = 3.6\n\\]\nmit\n\n\n\\(\\bar{y}_{cat} = 9.2\\) dem Mittelwert für die Gruppe cat.\n\n\\(\\bar{y}_{dog} = 7.8\\) dem Mittelwert für die Gruppe dog.\n\n\\(s_p = 0.55\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{0.6 + 0.5}{2}\\).\n\n\\(n_g = 4\\) der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.\n\nWir haben nun die Teststatistik \\(T_{calc} = 3.6\\) berechnet. In der ganzen Rechnererei verliert man manchmal den Überblick. Erinnern wir uns, was wir eigentlich wollten. Die Frage war, ob sich die mittleren Sprungweiten der Hunde- und Katzenflöhe unterschieden. Wenn die \\(H_0\\) wahr wäre, dann wäre der Unterschied \\(\\Delta\\) der beiden Mittelwerte der Hunde- und Katzenflöhe gleich null. Oder nochmal in der Analogie der t-Test Formel, dann wäre im Zähler \\(\\Delta = \\bar{y}_{cat} - \\bar{y}_{dog} = 0\\). Wenn die Mittelwerte der Sprungweite [cm] der Hunde- und Katzenflöhe gleich wäre, dann wäre die berechnete Teststatistik \\(T_{calc} = 0\\), da im Zähler Null stehen würde. Die Differenz von zwei gleichen Zahlen ist Null.\nJe größer die berechnete Teststatistik \\(T_{calc}\\) wird, desto unwahrscheinlicher ist es, dass die beiden Mittelwerte per Zufall gleich sind. Wie groß muss nun die berechnete Teststatistik \\(T_{calc}\\) werden damit wir die Nullhypothese ablehnen können?\n\n\n\nAbbildung 1— Die t-Verteilung aller möglichen \\(T_{calc}\\) wenn die Nullhypothese wahr ist. Der Mittelwert der t-Verteilun ist \\(T=0\\). Wenn wir keinen Effekt erwarten würden dann wären die beiden Mittelwerte \\(\\bar{y}_1\\) und \\(\\bar{y}_2\\) gleich groß. Die Differenz wäre 0. Je größer der \\(T_{calc}\\) wird desto weniger können wir davon ausgehen, dass die beiden Mittelwerte gleich sind. Liegt der \\(T_{calc}\\) über dem kritischen Wert von \\(T_{\\alpha = 5\\%}\\) dann wir die Nullhypothese abgelehnt.\n\n\n\nIn Abbildung 1 ist die Verteilung aller möglichen \\(T_{calc}\\) Werte unter der Annahme, dass die Nullhypothese wahr ist, dargestellt. Wir sehen, dass die t-Verteilung am höchsten bei \\(T_{calc} = 0\\) ist und niedrigeren Werte mit steigenden t-Werten annimmt. Wenn \\(T = 0\\) dann sind auch die Mittelwerte gleich. Je größer unsere berechnete Teststatistik \\(T_{calc}\\) wird, desto unwahrscheinlicher ist es, dass die Nullhypothese gilt. Die t-Verteilug ist so gebaut, dass die Fläche \\(A\\) unter der Kurve gleich \\(A=1\\) ist. Wir können nun den kritschen Wert \\(T_{\\alpha = 5\\%}\\) berechnen an dem rechts von dem Wert eine Fläche von 0.05 oder 5% liegt. Sommit liegt dann links von dem kritischen Wert die Fläche von 0.95 oder 95%. Den kritischen Wert \\(T_{\\alpha = 5\\%}\\) können wir statistischen Tabellen entnehmen. Oder wir berechnen den kritischen Wert direkt in R mit \\(T_{\\alpha = 5\\%} = 2.78\\).\nKommen wir zurück zu unserem Beispiel. Wir haben in unserem Datenbeispiel für den Vergleich von der Sprungweite in [cm] von Hunde- und Katzenflöhen eine Teststatistik von \\(T_{calc} = 3.6\\) berechnet. Der kritische Wert um die Nullhypothese abzulehnen liegt bei \\(T_{\\alpha = 5\\%} = 2.78\\). Wenn \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt. In unserem Fall ist \\(3.6 \\geq 2.78\\). Wir können die Nullhypothese ablehnen. Es gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen.\n\n\n\n\n\n\nEs gibt einen Unterschied zwischen der mittleren Sprungweite von Hunde- und Katzenflöhen. Die Aussage ist statistisch falsch. Wir können im frequentistischen Hypothesentesten keine Aussage über die \\(H_A\\) treffen. Im Sinne der Anwendbarkeit soll es hier so stehen bleiben.\nNun ist es leider so, dass jeder statistische Test seine eigene Teststatistik \\(T\\) hat. Daher ist es etwas mühselig sich immer neue und andere kritische Werte für jeden Test zu merken. Es hat sich daher eingebürgert, sich nicht die Teststatistik für die Testentscheidung gegen die Nullhypothese zu nutzen sondern den p-Wert. Den p-Wert wollen wir uns in dem folgenden Abschnitt anschauen.\n\n\n\n\n\n\nEntscheidung mit der berechneten Teststatistik\n\n\n\nBei der Entscheidung mit der Teststatistik müssen wir zwei Fälle unterschieden.\n\nBei einem t-Test und einem \\(\\mathcal{X}^2\\)-Test gilt, wenn \\(T_{calc} \\geq T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\nBei einem Wilcoxon-Mann-Whitney-Test gilt, wenn \\(T_{calc} < T_{\\alpha = 5\\%}\\) wird die Nullhypothese (H\\(_0\\)) abgelehnt.\n\nAchtung – Wir nutzen die Entscheidung mit der Teststatistik nur und ausschließlich in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik keine Verwendung mehr.\n\n\n… anhand dem p-Wert\n\n\n\n\n\n\nPrinzip des statistischen Testens II - Der p-Wert\n\n\n\nDu findest auf YouTube Prinzip des statistischen Testens II - Der p-Wert als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nIn dem vorherigen Abschnitt haben wir gelernt, wie wir zu einer Entscheidung gegen die Nullhypothese anhand der Teststatistik kommen. Wir haben einen kritischen Wert \\(T_{\\alpha = 5\\%}\\) definiert bei dem rechts von dem Wert 5% der Werte liegen. Anstatt nun den berechneten Wert \\(T_{calc}\\) mit dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) zu vergleichen, vergleichen wir jetzt die Flächen rechts von den jeweiligen Werten.\nWir schreiben \\(\\boldsymbol{Pr}\\) und meinen damit eine Wahrscheinlichkeit (eng. probability). Häufig wird auch nur das \\(P\\) verwendet, aber dann kommen wir wieder mit anderen Konzepten in die Quere.\nIn Abbildung 1 sind die Flächen auch eingetragen. Da die gesamte Fläche unter der t-Verteilung mit \\(A = 1\\) ist, können wir die Flächen auch als Wahrscheinlichkeiten lesen. Die Fläche rechts von der berechneten Teststatistik \\(T_{calc}\\) wird \\(Pr(T_{calc}|H_0)\\) oder \\(p\\)-Wert genannt. Die gesamte Fläche rechts von dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) wird \\(\\alpha\\) genannt und liegt bei 5%. Wir können also die Teststatistiken oder den p-Wert mit dem \\(\\alpha\\)-Niveau von 5% vergleichen.\n\n\nTabelle 3— Zusammenhang zwischen der Teststatistik \\(T\\) und der Fläche \\(A\\) rechts von der Teststatistik. Die Fläche rechts von der berechneten Teststatistik \\(T_{calc}\\) wird \\(Pr(T|H_0)\\) oder \\(p\\)-Wert genannt. Die Fläche rechts von dem kritischen Wert \\(T_{\\alpha = 5\\%}\\) wird \\(\\alpha\\) genannt und liegt bei 5%.\n\nTeststatistik \\(T\\)\n\nFläche \\(A\\)\n\n\n\n\n\\(T_{calc}\\)\n\n\\(Pr(T_{calc}|H_0)\\) oder \\(p\\)-Wert\n\n\n\\(T_{\\alpha = 5\\%}\\)\n\\(\\alpha\\)\n\n\n\n\nDer p-Wert oder \\(Pr(T|H_0)\\) ist eine Wahrscheinlichkeit. Eine Wahrscheinlichkeit kann die Zahlen von 0 bis 1 annehmen. Dabei sind die Grenzen einfach zu definieren. Eine Wahrscheinlichkeit von \\(Pr(A) = 0\\) bedeutet, dass das Ereignis A nicht auftritt; eine Wahrscheinlichkeit von \\(Pr(A) = 1\\) bedeutet, dass das Ereignis A eintritt. Der Zahlenraum dazwischen stellt jeden von uns schon vor große Herausforderungen. Der Unterschied zwischen 40% und 60% für den Eintritt des Ereignisses A sind nicht so klar zu definieren, wie du auf den ersten Blick meinen magst.\nEin frequentistischer Hypothesentest beantwortet die Frage, mit welcher Wahrscheinlichkeit \\(Pr\\) die Teststatistik \\(T\\) aus dem Experiment mit den Daten \\(D\\) zu beobachten wären, wenn es keinen Effekt gäbe (\\(H_0\\) ist wahr).\nLikelihood heißt Plausibilität und Probability heißt Wahrscheinlichkeit.\nIm Englischen gibt es die Begrifflichkeiten einer Likelihood und einer Probability in der Statistik. Meist wird beides ins Deutsche ungenau mit Wahrscheinlichkeit übersetzt oder wir nutzen einfach Likelihood. Was aber auch nicht so recht weiterhilft. Es handelt sich hierbei aber um zwei unterschiedliche Konzepte. Deshalb Übersetzen wir Likelihood mit Plausibilität und Probability mit Wahrscheinlichkeit.\nIm Folgenden berechnen wir den \\(p\\)-Wert in R mit der Funktion t.test(). Mehr dazu im Kapitel 16, wo wir den t-Test und deren Anwendung im Detail besprechen.\n\n\n# A tibble: 1 × 2\n  statistic p.value\n      <dbl>   <dbl>\n1      2.81  0.0309\n\n\nWir sagen, dass wir ein signifikantes Ergebnis haben, wenn der \\(p\\)-Wert kleiner ist als die Signifikanzschwelle \\(\\alpha\\) von 5%.\nWir erhalten einen \\(p\\)-Wert von 0.031 und vergleichen diesen Wert zu einem \\(\\alpha\\) von 5%. Ist der \\(p\\)-Wert kleiner als der \\(\\alpha\\)-Wert von 5%, dann können wir die Nullhypothese ablehnen. Da 0.031 kleiner ist als 0.05 können wir die Nullhypothese und damit die Gleichheit der mittleren Sprungweiten in [cm] ablehnen. Wir sagen, dass wir ein signifikantes Ergebnis vorliegen haben.\n\n\n\n\n\n\nEntscheidung mit dem p-Wert\n\n\n\nWenn der p-Wert \\(\\leq \\alpha\\) dann wird die Nullhypothese (H\\(_0\\)) abgelehnt. Das Signifikanzniveau \\(\\alpha\\) wird als Kulturkonstante auf 5% oder 0.05 gesetzt. Die Nullhypothese (H\\(_0\\)) kann auch Gleichheitshypothese gesehen werden. Wenn die H\\(_0\\) gilt, liegt kein Unterschied zwischen z.B. den Behandlungen vor.\n\n\n… anhand des 95% Konfidenzintervall\nEin statistischer Test der eine Teststatistik \\(T\\) berechnet liefert auch immer einen \\(p\\)-Wert. Nicht alle statistischen Tests ermöglichen es ein 95% Konfidenzintervall zu berechnen. Abbildung 2 zeigt ein 95% konfidenzintervall.\n\n\nAbbildung 2— Ein 95% Konfidenzintervall. Der Punkt in der Mitte entspricht dem Unterschied oder Effekt \\(\\Delta\\).\n\n\nMit p-Werten haben wir Wahrscheinlichkeitsaussagen und damit über die Signifikanz. Damit haben wir noch keine Aussage über die Relevanz des beobachtenten Effekts.\nMit der Teststatistik \\(T\\) und dem damit verbundenen \\(p\\)-Wert haben wir uns Wahrscheinlichkeiten angeschaut und erhalten eine Wahrscheinlichkeitsaussage. Eine Wahrscheinlichkeitsaussage sagt aber nichts über den Effekt \\(\\Delta\\) aus. Also wie groß ist der mittlere Sprungunterschied zwischen Hunde- und Katzenflöhen. Eine nährere betrachtung von dem Effekt in der Statistik findest du in ?sec-effect.\nDie Idee von 95% Kondifenzintervallen ist es jetzt den Effekt mit der Wahrscheinlichkeitsaussage zusammenzubringen und beides in einer Visualisierung zu kombinieren. Im Folgenden sehen wir die vereinfachte Formel für das 95% Konfidenzintervall eines t-Tests.\n\\[\n\\left[\n(\\bar{y}_1-\\bar{y}_2) -\nT_{\\alpha = 5\\%} \\cdot \\frac {s_p}{\\sqrt{n}}; \\;\n(\\bar{y}_1-\\bar{y}_2) +\nT_{\\alpha = 5\\%} \\cdot \\frac {s_p}{\\sqrt{n}};\n\\right]\n\\]\nDie Formel ist ein wenig komplex, aber im Prinzip einfach. Der linke und der rechte Teil neben dem Semikolon sind fast gleich, bis auf das Plus- und Minuszeichen. Abbildung 3 visualisert die Formel einmal. Wir sehen Folgendes in der Formel und dann in der entsprechenden Abbildung:\n\n\n\\((\\bar{y}_{1}-\\bar{y}_{2})\\) ist der Effekt \\(\\Delta\\). In diesem Fall der Mittelwertsunterschied. Wir finden den Effekt als Punkt in der Mitte des Intervals.\n\n\\(T_{\\alpha = 5\\%} \\cdot \\frac {s}{\\sqrt{n}}\\) ist der Wert, der die Arme des Intervals bildet. Wir vereinfachen die Formel mit \\(s_p\\) für die gepoolte Standardabweichung und \\(n_g\\) für die Fallzahl der beiden Gruppen. Wir nehmen an das beide Gruppen die gleiche Fallzahl \\(n_1 = n_2\\) haben.\n\n\n\nAbbildung 3— Zusammenhang zwischen der vereinfachten Formel für das 95% Konfidenzintervall und der Visualisierung des 95% Konfidenzintervalls. Der Effektschätzer wird als Punkt in der Mitte des Intervalls dargestellt. Der Effektschäter \\(\\Delta\\) kann entweder ein Mittelwertsunterschied sein oder ein Anteilsunterschied. Bei einem Mittelwertsunterschied kann die Nullhypothese abgelehnt werden, wenn die 0 nicht im Konfidenzintervall ist; bei einem Anteilsunterschied wenn die 1 nicht im Konfidenzintervall ist. Die Arme werden länger oder kürzer je nachdem wie sich die statistischen Maßzahlen \\(s\\) und \\(n\\) verändern.\n\n\nDie Funktion factor() in R erlaubt es dir die Level eines Faktors zu sortieren und so festzulegen ob Level cat minus Level dog oder umgekehrt von R gerechnet wird.\nWir können eine biologische Relevanz definieren, dadurch das ein 95% Konfidenzintervall die Wahrscheinlichkeitsaussage über die Signifkanz, daher ob die Nullhypothese abgelehnt werden kann, mit dem Effekt zusammenbringt. Wo die Signifikanzschwelle klar definiert ist, hängt die Relevanzschwelle von der wissenschaftlichen Fragestellung und weiteren externen Faktoren ab. Die Signifikanzschwelle liegt bei 0, wenn wir Mittelwerte miteinander vergleichen und bei 1, wenn wir Anteile vergleichen. Abbildung 4 zeigt fünf 95% Konfidenzintervalle (a-e), die sich anhand der Signifikanz und Relevanz unterscheiden. Bei der Relevanz ist es wichtig zu wissen in welche Richtung der Effekt gehen soll. Erwarten wir einen positiven Effekt wenn wir die Differenz der beiden Gruppen bilden oder einen negativen Effekt?\n\n\nAbbildung 4— Verschiedene signifikante und relevante Konfidenzintervalle: (a) nicht signifikant und nicht relevant; (b) signifikant und nicht relevant; (c) signifikant und relevant; (d) signifikant und nicht relevant, der Effekt ist zu klein; (e) signifikant und potenziell relevant, Effekt zeigt in eine unerwartete Richtung gegeben der Relevanzschwelle.\n\n\nWir wollen uns nun einmal anschauen, wie sich ein 95% Konfidenzintervall berechnet. Wir nehmen dafür die vereinfachte Formel und setzen die berechneten statistischen Maßzahlen ein. In der Anwendung werden wir die Konfidenzintervalle nicht selber berechnen. Wenn ein statistisches Verfahren konfidenzintervalle berechnen kann, dann liefert die entsprechende Funktion in R das Konfidenzintervall.\nEs ergibt sich Folgende ausgefüllte, vereinfachte Formel für das 95% Konfidenzintervalls eines t-Tests für das Beispiel des Sprungweitenunterschieds [cm] zwischen Hunde- und Katzenflöhen.\n\n\n\n\n\n\nWir nutzen hier eine vereinfachte Formel für das Konfidenzintervall um das Konzept zu verstehen. Später berechnen wir das Konfidenzintervall in R.\n\\[\n\\left[\n(9.2-7.8) -\n2.78 \\cdot \\frac {0.55}{\\sqrt{4}}; \\;\n(9.2-7.8) +\n2.78 \\cdot \\frac {0.55}{\\sqrt{4}};\n\\right]\n\\]\nmit\n\n\n\\(\\bar{y}_{cat} = 9.2\\) dem Mittelwert für die Gruppe cat.\n\n\\(\\bar{y}_{dog} = 7.8\\) dem Mittelwert für die Gruppe dog.\n\n\\(T_{\\alpha = 5\\%} = 2.78\\) dem kritischen Wert.\n\n\\(s_p = 0.55\\) der gepoolten Standardabweichung mit \\(s_p = \\tfrac{0.6 + 0.5}{2}\\).\n\n\\(n_g = 4\\) der Gruppengröße der Gruppe A und B. Wir nehmen an beide Gruppen sind gleich groß.\n\nLösen wir die Formel auf, so ergibt sich folgendes 95% Konfidenzintervall des Mittelwertsunterschiedes der Hunde- und Katzenflöhe.\n\\[[0.39; 2.20]\\]\nWir können sagen, dass mit 95% Wahrscheinlichkeit das Konfidenzintervall den wahren Effektunterschied \\(\\Delta\\) überdeckt. Oder etwas mehr in Prosa, dass wir eine Sprungweitenunterschied von 0.39 cm bis 2.20 cm zwischen Hunde- und Katzenflöhen erwarten würden.\nDie Entscheidung gegen die Nullhypothese bei einem Mittelwertsunterschied erfolgt bei einem 95% Konfidenzintervall danach ob die Null mit im Konfidenzintervall liegt oder nicht. In dem Interval \\([0.39; 2.20]\\) ist die Null nicht enthalten, also können wir die Nullhypothese ablehnen. Es ist mit einem Unterschied zwischen den mittleren Sprungweiten von Hunde- und Katzenflöhen auszugehen.\nIn unserem Beispiel, könnten wir die Relevanzschwelle für den mittleren Sprungweitenunterschied zwischen Hund- und Katzenflöhen auf 2 cm setzen. In dem Fall würden wir entscheiden, dass der mittlere Sprungweitenunterschied nicht relevant ist, da die 2 cm im Konfidenzintervall enthalten sind. Was wäre wenn wir die Relevanzschwelle auf 4 cm setzen? Dann wäre zwar die Relevanzschwelle nicht mehr im Konfidenzintervall, aber wir hätten Fall (d) in der Abbildung 4 vorliegen. Der Effekt ist einfach zu klein, dass der Effekt relevant sein könnte.\n\n\n\n\n\n\nEntscheidung mit dem 95% Konfidenzintervall\n\n\n\nBei der Entscheidung mit dem 95% Konfidenzinterval müssen wir zwei Fälle unterscheiden.\n\nEntweder schauen wir uns einen Mittelwertsunterschied (\\(\\Delta_{y_1-y_2}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 0 im 95% Konfidenzinterval ist.\nOder wir schauen uns einen Anteilsunterschied (\\(\\Delta_{y_1/y_2}\\)) an, dann können wir die Nullhypothese (H\\(_0\\)) nicht ablehnen, wenn die 1 im 95% Konfidenzinterval ist."
  },
  {
    "objectID": "stat-tests-preface.html#auswirkung-des-effektes-der-streuung-und-der-fallzahl",
    "href": "stat-tests-preface.html#auswirkung-des-effektes-der-streuung-und-der-fallzahl",
    "title": "Frequentistische Hypothesentests",
    "section": "Auswirkung des Effektes, der Streuung und der Fallzahl",
    "text": "Auswirkung des Effektes, der Streuung und der Fallzahl\nWir wollen einmal den Zusammenhang zwischen dem Effekt \\(\\Delta\\), der Streuung als Standardabweichung \\(s\\) und Fallzahl \\(n\\) uns näher anschauen. Wir können die Formel des t-Tests wie folgt vereinfachen.\n\\[\nT_{calc}=\\cfrac{\\bar{y}_1-\\bar{y}_1}{s_{p} \\cdot \\sqrt{2/n_g}}\n\\]\nFür die Betrachtung der Zusammenhänge wandeln wir \\(\\sqrt{2/n_g}\\) in \\(1/n\\) um. Dadurch wandert die Fallzahl \\(n\\) in den Zähler. Die Standardabweichung verallgemeinern wir zu \\(s\\) und damit allgemein zur Streuung. Abschließend betrachten wir \\(\\bar{y}_A-\\bar{y}_B\\) als den Effekt \\(\\Delta\\). Es ergibt sich folgende vereinfachte Formel.\n\\[\nT_{calc} = \\cfrac{\\Delta \\cdot n}{s}\n\\]\nWir können uns nun die Frage stellen, wie ändert sich die Teststatistik \\(T_{calc}\\) in Abhängigkeit vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\) in den Daten. Die Tabelle 4 zeigt die Zusammenhänge auf. Die Aussagen in der Tabelle lassen sich generalisieren. So bedeutet eine steigende Fallzahl meist mehr signifikante Ergebnisse. Eine stiegende Streuung reduziert die Signifikanz eines Vergleichs. Ein Ansteigen des Effektes führt zu mehr signifikanten Ergebnissen. Ebenso verschiebt eine Veränderung des Effekt das Konfidenzintervall, eine Erhöhung der Streuung macht das konfidenzintervall breiter, eine sinkende Streeung macht das konfidenzintervall schmaller. bei der Fallzahl verhält es sich umgekehrt. Eine Erhöhung der Fallzahl macht das Konfidenzintervall schmaller und eine sinkende Fallzahl das Konfidenzintervall breiter.\n\n\n\nTabelle 4— Zusammenhang von der Teststatistik \\(T_{calc}\\) und dem p-Wert \\(Pr(\\geq T_{calc}|H_0)\\) sowie dem \\(KI_{1-\\alpha}\\) in Abhängigkeit vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(KI_{1-\\alpha}\\)\n\n\\(\\boldsymbol{T_{calc}}\\)\n\\(\\boldsymbol{Pr(\\geq T_{calc}|H_0)}\\)\n\\(KI_{1-\\alpha}\\)\n\n\n\n\\(\\Delta \\uparrow\\)\nsteigt\nsinkt\nverschoben\n\\(\\Delta \\downarrow\\)\nsinkt\nsteigt\nverschoben\n\n\n\\(s \\uparrow\\)\nsinkt\nsteigt\nbreiter\n\\(s \\downarrow\\)\nsteigt\nsinkt\nschmaller\n\n\n\\(n \\uparrow\\)\nsteigt\nsinkt\nschmaller\n\\(n \\downarrow\\)\nsinkt\nsteigt\nbreiter"
  },
  {
    "objectID": "stat-tests-preface.html#testtheorie",
    "href": "stat-tests-preface.html#testtheorie",
    "title": "Frequentistische Hypothesentests",
    "section": "Testtheorie",
    "text": "Testtheorie\n\n\n\n\n\n\nPrinzip der statistischen Testentscheidung - H\\(_0\\) und H\\(_A\\)\n\n\n\nDu findest auf YouTube Prinzip der statistischen Testentscheidung - \\(H_0\\) und \\(H_A\\) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nVielleicht ist die Idee der Testentscheidung besser mit der Analogie des Rauchmelders zu verstehen. Wir nehmen an, dass der Rauchmelder der statistische Test ist. Der Rauchmelder hängt an der Decke und soll entscheiden, ob es brennt oder nicht. Daher muss der Rauchmelder entscheiden, die Nullhypothese “kein Feuer” abzulehnen oder die Hypothese “kein Feuer” beizubehalten.\n\\[\\begin{align*}\nH_0&: \\mbox{kein Feuer im Haus} \\\\  \nH_A&: \\mbox{Feuer im Haus} \\\\   \n\\end{align*}\\]\nWir können jetzt den Rauchmelder einstellen, so dass der Rauchmelder bei einer Kerze losgeht oder erst bei einem Stubenbrand. Wie sensibel auf Rauch wollen wir den Rauchmelder einstellen? Soll der Rauchmelder sofort die Nullhypothese ablehnen? Wenn also nur eine Kerze brennt. Soll also der \\(\\alpha\\)-Fehler groß sein? Das wäre nicht sehr sinnvoll. Due Feuerwehr würde schon bei einer Kerze kommen oder wenn wir mal was anbrennen. Wir dürfen also den \\(\\alpha\\)-Fehler nicht zu groß einstellen.\nIntuitiv würde man meinen, ein sehr kleiner \\(\\alpha\\)-Fehler nun sinnvoll sei. Wenn wir aber den Rauchmelder sehr unsensibel einstellen, also der Rauchmelder erst bei sehr viel Rauch die Nullhypothese ablehnt, könnte das Haus schon unrettbar in Flammen stehen. Dieser Fehler, Haus steht in Flammen und der Rauchmelder geht nicht, wird als \\(\\beta\\)-Fehler bezeichnet. Wie du siehst hängen die beiden Fehler miteinander zusammen. Wichtig hierbei ist immmer, dass wir uns einen Zustand vorstellen, das Haus brent nicht (\\(H_0\\) ist wahr) oder das Haus brennt nicht (\\(H_A\\) ist wahr). An diesem Zustand entscheiden wir dann, wie hoch der Fehler jeweils sein soll diesen Zustand zu übersehen.\n\n\n\n\n\n\nDer \\(\\alpha\\)-Fehler und \\(\\beta\\)-Fehler als Rauchmelderanalogie\n\n\n\nHäufig verwirrt die etwas theoretische Herangehensweise an den \\(\\alpha\\)-Fehler und \\(\\beta\\)-Fehler. Wir versuchen hier nochmal die Analogie eines Rauchmelders und dem Feuer im Haus.\n\n\nAbbildung 5— Andere Art der Darstellung des \\(\\alpha\\)-Fehlers als Alarm without fire und dem \\(\\beta\\)-Fehler als Fire without alarm. Je nachdem wie empfindlich wir den Alarm des Rauchmelders (den statistischen Test) über das \\(\\alpha\\) einstellen, desto mehr Alarm bekommen wir ohne das ein Effekt vorhanden wäre. Drehen wir den Alarm zu niedrig, dann kriegen wir kein Feuer mehr angezeigt, den \\(\\beta\\)-Fehler.\n\n\n\n\n\\(\\boldsymbol{\\alpha}\\)-Fehler: Alarm without fire. Der statistische Test schlägt Alarm und wir sollen die \\(H_0\\) ablehnen, obwohl die \\(H_0\\) in Wahrheit gilt und kein Effekt vorhanden ist.\n\n\\(\\boldsymbol{\\beta}\\)-Fehler: Fire without alarm. Der statistische Test schlägt nicht an und wir sollen die \\(H_0\\) beibehalten, obwohl die \\(H_0\\) in Wahrheit nicht gilt und ein Effekt vorhanden ist.\n\n\n\nWie sieht nun die Lösung, erstmal für unseren Rauchmelder, aus? Wir müssen Grenzen für den \\(\\alpha\\) und \\(\\beta\\)-Fehler festlegen.\nWir setzen den \\(\\alpha\\)-Fehler auf 5%.\n\nWir setzen den \\(\\alpha\\)-Fehler auf 5%. Somit haben wir in 1 von 20 Fällen das Problem, dass uns der Rauchmelder angeht obwohl gar kein Feuer da ist. Wir lehnen die Nullhypothese ab, obwohl die Nullhypothese gilt.\n\nWir setzen den \\(\\beta\\)-Fehler auf 20%.\n\nAuf der anderen Seite setzen wir den \\(\\beta\\)-Fehler auf 20%. Damit brennt uns die Bude in 1 von 5 Fällen ab ohne das der Rauchmelder einen Pieps von sich gibt. Wir behalten die Nullhypothese bei, obwohl die Nullhypothese nicht gilt.\n\nNachdem wir uns die Testentscheidung mit der Analogie des Rauchmelders angesehen haben, wollen wir uns wieder der Statistik zuwenden. Betrachten wir das Problem nochmal von der theoretischen Seite mit den statistischen Fachbegriffen.\nSoweit haben wir es als gegeben angesehen, dass wir eine Testentscheidung durchführen. Entweder mit der Teststatistik, dem \\(p\\)-Wert oder dem 95% Konfidenzintervall. Immer wenn wir eine Entscheidung treffen, können wir auch immer eine falsche Entscheidung treffen. Wie wir wissen hängt die berechnete Teststatistik \\(T_{calc}\\) nicht nur vom Effekt \\(\\Delta\\) ab sondern auch von der Streuung \\(s\\) und der Fallzahl \\(n\\). Auch können wir den falschen Test wählen oder Fehler im Design des Experiments gemacht haben. Schlussendlich gibt es viele Dinge, die unsere simple mathematischen Formeln beeinflussen können, die wir nicht kennen. Ein frequentistischer Hypothesentest gibt immer nur eine Aussage über die Nullhypothese wieder. Also ob wir die Nullhypothese ablehnen können oder nicht.\nAbbildung 6 zeigt die theoretische Verteilung der Nullyhypothese und der Alternativehypothese. Wenn die beiden Verteilungen sehr nahe beieinander sind, wird es schwer für den statistischen Test die Hypothesen klar voneinander zu trennen. Die Verteilungen überlappen. Es gibt einen sehr kleinen Unterschied in den Sprungweiten zwischen Hunde- und Katzenflöhen.\n\n\n\nAbbildung 6— Darstellung der Null- und Alternativehypothese. Mit steigendem \\(T_{calc}\\) wird die Wahrscheinlichkeit für die \\(H_0\\) immer kleiner. Leider ist uns nichts über \\(H_A\\) und deren Lage bekannt. Sollte die \\(H_A\\) Verteilung zu weit nach links ragen, könnten wir die \\(H_0\\) beibehalten, obwohl die \\(H_A\\) gilt.\n\n\n\nAchtung In der Regression wird uns auch wieder das \\(\\beta\\) als Symbol begegnen. In der statistischen Testtheorie ist das \\(\\beta\\) ein Fehler; in der Regression ist das \\(\\beta\\) ein Koeffizient der Regression. Hier ist der Kontext wichtig.\nWir können daher bei statistischen Testen zwei Arten von Fehlern machen. Zum einen den \\(\\alpha\\) Fehler oder auch Type I Fehler genannt. Zum anderen den \\(\\beta\\) Fehler oder auch Type II Fehler genannt. Die Grundidee basiert darauf, dass wir eine Testentscheidung gegen die Nullhypothese machen. Diese Entscheidung kann richtig sein, da in Wirklichkeit die Nullhypothese gilt oder aber falsch sein, da in Wirklichkeit die Nullhypothese nicht gilt. In Abbildung 7 wird der Zusammenhang in einer 2x2 Tafel veranschaulicht.\n\n\n\nAbbildung 7— Zusammenhang zwischen der Testentscheidung gegen die \\(H_0\\) Hypothese sowie dem Beibehalten der \\(H_0\\) Hypothese und der unbekannten Wahrheit in der die \\(H_0\\) falsch sein kann oder die \\(H_0\\) wahr sein kann. Wir können mit unserer Testenstscheidung richtig liegen oder falsch. Mit welcher Wahrscheinlichkeit geben der \\(\\alpha\\) Fehler und \\(\\beta\\) Fehler wieder. Unten rechts ist der Zusammenhang zu der Abbildung 6 gezeigt.\n\n\n\n\n\nDie Diskussion über den \\(p\\)-Wert und dem Vergleich mit dem \\(\\alpha\\)-Fehler wird in der Statistik seit 2019 verstärkt diskutiert (Wasserstein, Schirm, und Lazar 2019). Das Nullritual wird schon lamge kritisiert (Gigerenzer, Krauss, und Vitouch 2004). Siehe dazu auch The American Statistician, Volume 73, Issue sup1 (2019).\nBeide Fehler sind Kulturkonstanten. Das heißt, dass sich diese Zahlen von 5% und 20% so ergeben haben. Es gibt keinen rationalen Grund diese Zahlen so zu nehmen. Man kann eigentlich sagen, dass die 5% und die 20% eher einem Zufall entsprungen sind, als einer tieferen Rationalen. Wir behalten diese beiden Zahlen bei aus den beiden schlechtesten Gründe überhaupt: i) es wurde schon immer so gemacht und ii) viele machen es so.\nEine weitere wichtige statistische Maßzahl im Kontext der Testtheorie ist die \\(Power\\) oder auch \\(1-\\beta\\). Die \\(Power\\) ist die Gegenwahrscheinlichkeit von dem \\(\\beta\\)-Fehler. In der Analogie des Rauchmelders wäre die \\(Power\\) daher Alarm with fire. Das heißt, wie wahrscheinlich ist es einen wahren Effekt - also einen Unterschied - mit dem statistischen Test auch zu finden. Oder anders herum, wenn wir wüssten, dass die Hunde- und Katzenflöhe unterschiedliche weit springen, mit welcher Wahrscheinlichkeit würde diesen Unterschied ein statistsicher Test auch finden? Mit eben der \\(Power\\), also gut 80%. Tabelle 5 zeigt die Abhängigkeit der \\(Power\\) vom Effekt \\(\\Delta\\), der Streuung \\(s\\) und der Fallzahl \\(n\\).\nDie \\(Power\\) ist eine Wahrscheinlichkeit und sagt nichts über die Relevanz des Effektes aus.\n\n\nTabelle 5— Abhängigkeit der \\(Power (1-\\beta)\\) vom Effekt \\(\\Delta\\), der Fallzahl \\(n\\) und der Streuung \\(s\\). Die \\(Power\\) ist eine Wahrscheinlichkeit und sagt nichts über die Relevanz des Effektes aus.\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{Power (1-\\beta)}\\)\n\n\\(\\boldsymbol{Power (1-\\beta)}\\)\n\n\n\n\\(\\Delta \\uparrow\\)\nsteigt\n\\(\\Delta \\downarrow\\)\nsinkt\n\n\n\\(s \\uparrow\\)\nsinkt\n\\(s \\downarrow\\)\nsteigt\n\n\n\\(n \\uparrow\\)\nsteigt\n\\(n \\downarrow\\)\nsinkt\n\n\n\n\nEinseitig oder zweiseitig?\nManchmal kommt die Frage auf, ob wir einseitig oder zweiseitig einen statistischen Test durchführen wollen. Beim Fall des zweiseitigen Testens verteilen wir den \\(\\alpha\\)-Fehler auf beide Seiten der Testverteilung mit jeweils \\(\\cfrac{\\alpha}{2}\\). In dem Fall des einseitigen Tests liegt der gesamte \\(\\alpha\\)-Fehler auf der rechten oder linken Seite der Testverteilung. In Abbildung 8 wird der Zusammenhang beispielhaft an der t-Verteilung gezeigt.\n\n\n\nAbbildung 8— Zusammenhang zwischen dem einseitigen und zweiseitigen Testen. Im Falle des zweiseitigen Testens teilen wir den \\(\\alpha\\)-Fehler auf beide Seiten der beispielhaften t-Verteilung auf. Im Falle des einseitigen Testen leigt der gesamte \\(\\alpha\\)-Fehler auf der rechten oder der linken Seite der t-Verteilung.\n\n\n\nIn der Anwendung testen wir immer zweiseitig.\nIn der Anwendung testen wir immer zweiseitig. Der Grund ist, dass das Vorzeichen von der Teststatik davon abhängt, welche der beiden Gruppen den größeren Mittelwert hat. Da wir die Mittelwerte vor der Auswertung nicht kennen, können wir auch nicht sagen in welche Richtung der Effekt und damit die Teststatistik laufen wird.\nEs gibt theoretisch Gründe, die für ein einseitiges Testen unter bestimmten Bedingungen sprechen, aber wir nutzen in der Anwendung nur das zweiseite Testen. Wir müssen dazu in R auch nichts weiter angeben. Ein durchgeführter statistischer Test in R testet automatisch immer zweiseitig.\n\n\n\n\n\n\nEinseitig oder zweiseitig im Spiegel der Regulierungsbehörden\n\n\n\nIn den allgemeinen Methoden des IQWiG, einer Regulierungsbehörde für klinische Studien, wird grundsätzlich das zweiseitige Testen empfohlen. Wenn einseitig getestet werden sollte, so soll das \\(\\alpha\\)-Niveau halbiert werden. Was wiederum das gleiche wäre wie zweiseitiges Testen - nur mit mehr Arbeit.\nZur besseren Vergleichbarkeit mit 2-seitigen statistischen Verfahren wird in einigen Guidelines für klinische Studien eine Halbierung des üblichen Signifikanzniveaus von 5 % auf 2,5 % gefordert. – Allgemeine Methoden Version 6.1 vom 24.01.2022, p. 180\n\n\nAdjustierung des \\(\\alpha\\)-Fehlers\nWork in progress…"
  },
  {
    "objectID": "stat-tests-preface.html#referenzen",
    "href": "stat-tests-preface.html#referenzen",
    "title": "Frequentistische Hypothesentests",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nGigerenzer, Gerd, Stefan Krauss, und Oliver Vitouch. 2004. „The null ritual“. The Sage handbook of quantitative methodology for the social sciences, 391–408.\n\n\nSalsburg, David. 2001. The lady tasting tea: How statistics revolutionized science in the twentieth century. Macmillan.\n\n\nWasserstein, Ronald L, Allen L Schirm, und Nicole A Lazar. 2019. „Moving to a world beyond ‚p< 0.05‘“. The American Statistician. Taylor & Francis."
  },
  {
    "objectID": "stat-tests-ttest.html",
    "href": "stat-tests-ttest.html",
    "title": "16  Der t-Test",
    "section": "",
    "text": "Wir benötigen für den t-Test ein normalverteiltes \\(y\\) und einen Faktor mit zwei Leveln als \\(x\\). Wir nehmen daher mit select()die Spalte jump_length und animal.\nBeispieldaten sind in Tabelle 16.1 abgebildet."
  },
  {
    "objectID": "stat-tests-ttest.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-tests-ttest.html#genutzte-r-pakete-für-das-kapitel",
    "title": "16  Der t-Test",
    "section": "\n16.1 Genutzte R Pakete für das Kapitel",
    "text": "16.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, broom, readxl)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-tests-ttest.html#hypothesenpaar",
    "href": "stat-tests-ttest.html#hypothesenpaar",
    "title": "16  Der t-Test",
    "section": "\n16.2 Hypothesenpaar",
    "text": "16.2 Hypothesenpaar\n\\[\\begin{align*}\nH_0: \\bar{y}_{dog} &= \\bar{y}_{cat} \\\\  \nH_A: \\bar{y}_{dog} &\\neq \\bar{y}_{cat} \\\\   \n\\end{align*}\\]\n\n\n\n\nAbbildung 16.1— Boxplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nDas ist das Beispiel Abbildung 16.1\n\n\n\n\nAbbildung 16.2— Dotplot der Sprungweiten [cm] von Hunden und Katzen.\n\n\n\n\nDas ist das Beispiel Abbildung 16.2"
  },
  {
    "objectID": "stat-tests-ttest.html#die-wichtigkeit-des-t-tests",
    "href": "stat-tests-ttest.html#die-wichtigkeit-des-t-tests",
    "title": "16  Der t-Test",
    "section": "\n16.7 Die Wichtigkeit des t-Tests",
    "text": "16.7 Die Wichtigkeit des t-Tests\n\\[\n\\text{Teststatistik} = \\cfrac{\\text{Signal}}{\\text{Noise}}\n\\]"
  },
  {
    "objectID": "stat-tests-ttest.html#student-t-test",
    "href": "stat-tests-ttest.html#student-t-test",
    "title": "16  Der t-Test",
    "section": "\n16.3 Student t-Test",
    "text": "16.3 Student t-Test\n\nsum_tbl <- data_tbl %>% \n  group_by(animal) %>% \n  summarise(mean = round(mean(jump_length), 2), \n            sd = round(sd(jump_length), 2)) \n\nsd_pool <- (sum_tbl$sd[1] + sum_tbl$sd[2])/2\nt_student <- round((sum_tbl$mean[1] - sum_tbl$mean[2])/(sd_pool * sqrt(2/7)), 2)\n\n\\[\nT_{calc} = \\cfrac{\\bar{y}_1-\\bar{y}_2}{s_{pooled} \\cdot \\sqrt{\\cfrac{2}{n_{group}}}}\n\\]\nFoo\n\n\n\n\n\n\nEigentlich wäre hier folgende Formel richtig…\n\\[\ns_{pooled} = \\sqrt{\\frac{1}{2} (s^2_{y_1} + s^2_{y_2})}\n\\] …aber auch hier erwischen wir einen Statistikengel um es etwas einfacher zu machen.\n\\[\ns_{pooled} = \\cfrac{s_{y_1} + s_{y_2}}{2}\n\\]\n\\[\ns_{pooled} = \\cfrac{2.14 + 1.9}{2} = 2.02\n\\]\n\\[\nT_{calc} = \\cfrac{8.13- 4.74}{2.02 \\cdot \\sqrt{\\cfrac{2}{7}}} = 3.14\n\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  jump_length by animal\nt = 3.12528, df = 12, p-value = 0.0087684\nalternative hypothesis: true difference in means between group dog and group cat is not equal to 0\n95 percent confidence interval:\n 1.0253394 5.7460892\nsample estimates:\nmean in group dog mean in group cat \n        8.1285714         4.7428571 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = TRUE) %>% \n  tidy() \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>\n1     3.39      8.13      4.74      3.13 0.00877        12     1.03      5.75\n# … with 2 more variables: method <chr>, alternative <chr>"
  },
  {
    "objectID": "stat-tests-ttest.html#welch-t-test",
    "href": "stat-tests-ttest.html#welch-t-test",
    "title": "16  Der t-Test",
    "section": "\n16.4 Welch t-Test",
    "text": "16.4 Welch t-Test\n\\[\nT_{calc} = \\cfrac{\\bar{y_1} - \\bar{y_2}}{\\sqrt{\\cfrac{s^2_{y_1}}{n} + \\cfrac{s^2_{y_2}}{m}}}\n\\]\nHier muss man noch bedenken, dass die Freiheitsgrade anders berechnte werden Die Freiheitsgrade werden mit11 \\[df = \\cfrac{\\left(\\cfrac{s^2_{y_1}}{n} +\n\\cfrac{s^2_{y_2}}{m}\\right)^2}{\\cfrac{\\left(\\cfrac{s^2_{y_1}}{n}\\right)^2}{n-1} + \\cfrac{\\left(\\cfrac{s^2_{y_2}}{m}\\right)^2}{m-1}}\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  jump_length by animal\nt = 3.12528, df = 11.8307, p-value = 0.008906\nalternative hypothesis: true difference in means between group dog and group cat is not equal to 0\n95 percent confidence interval:\n 1.0215869 5.7498416\nsample estimates:\nmean in group dog mean in group cat \n        8.1285714         4.7428571 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, var.equal = FALSE) %>% \n  tidy() \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl>\n1     3.39      8.13      4.74      3.13 0.00891      11.8     1.02      5.75\n# … with 2 more variables: method <chr>, alternative <chr>"
  },
  {
    "objectID": "stat-tests-ttest.html#verbundener-t-test-paired-t-test",
    "href": "stat-tests-ttest.html#verbundener-t-test-paired-t-test",
    "title": "16  Der t-Test",
    "section": "\n16.5 Verbundener t-Test (Paired t-Test)",
    "text": "16.5 Verbundener t-Test (Paired t-Test)\n\\[\nT_{calc} = \\sqrt{n}\\cfrac{\\bar{d}}{s_d}\n\\]\n\nt.test(jump_length ~ animal, \n       data = data_tbl, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  jump_length by animal\nt = 3.76033, df = 6, p-value = 0.0093949\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.1825691 5.5888595\nsample estimates:\nmean difference \n      3.3857143 \n\n\n\nt.test(jump_length ~ animal, \n       data = data_tbl, paired = TRUE) %>% \n  tidy() \n\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr>      <chr>      \n1     3.39      3.76 0.00939         6     1.18      5.59 Paired t-… two.sided"
  },
  {
    "objectID": "stat-tests-ttest.html#freiheitsgrade-im-t-test",
    "href": "stat-tests-ttest.html#freiheitsgrade-im-t-test",
    "title": "16  Der t-Test",
    "section": "\n16.6 Freiheitsgrade im t-Test",
    "text": "16.6 Freiheitsgrade im t-Test\n\n\nAbbildung 16.3— kjk"
  },
  {
    "objectID": "stat-tests-ttest.html#der-t-test-in-der-regression",
    "href": "stat-tests-ttest.html#der-t-test-in-der-regression",
    "title": "16  Der t-Test",
    "section": "\n16.8 Der t-Test in der Regression",
    "text": "16.8 Der t-Test in der Regression\n\nlm(jump_length ~ animal, \n       data = data_tbl) %>% \n  tidy() \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic     p.value\n  <chr>          <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)     8.13     0.766     10.6  0.000000188\n2 animalcat      -3.39     1.08      -3.13 0.00877"
  },
  {
    "objectID": "stat-tests-anova.html#einfaktorielle-anova",
    "href": "stat-tests-anova.html#einfaktorielle-anova",
    "title": "17  Die ANOVA",
    "section": "\n17.1 Einfaktorielle ANOVA",
    "text": "17.1 Einfaktorielle ANOVA\n\n\n\n\nTabelle 17.1— test caption\n\nanimal\njump_length\nflea_count\ngrade\ninfected\n\n\n\ndog\n5.7\n18\n8\n0\n\n\ndog\n8.9\n22\n8\n1\n\n\ndog\n11.8\n17\n6\n1\n\n\ndog\n8.2\n12\n8\n0\n\n\ndog\n5.6\n23\n7\n1\n\n\ndog\n9.1\n18\n7\n0\n\n\ndog\n7.6\n21\n9\n0\n\n\ncat\n3.2\n12\n7\n1\n\n\ncat\n2.2\n13\n5\n0\n\n\ncat\n5.4\n11\n7\n0\n\n\ncat\n4.1\n12\n6\n0\n\n\ncat\n4.3\n16\n6\n1\n\n\ncat\n7.9\n9\n6\n0\n\n\ncat\n6.1\n7\n5\n0\n\n\nfox\n12.1\n21\n5\n1\n\n\nfox\n13.2\n25\n4\n1\n\n\nfox\n14.1\n31\n4\n1\n\n\nfox\n9.7\n12\n5\n1\n\n\nfox\n10.6\n28\n4\n0\n\n\nfox\n11.5\n18\n4\n1\n\n\nfox\n10.8\n19\n3\n0\n\n\n\n\n\n\nBeispieldaten sind in Tabelle 17.1 abgebildet.\n\n\n\n\nAbbildung 17.1— Boxplot der Sprungweiten [cm] von Hunden und Katzen."
  },
  {
    "objectID": "stat-tests-anova.html#zweifaktorielle-anova",
    "href": "stat-tests-anova.html#zweifaktorielle-anova",
    "title": "17  Die ANOVA",
    "section": "\n17.2 Zweifaktorielle ANOVA",
    "text": "17.2 Zweifaktorielle ANOVA\n\n\n\nBeispieldaten sind in ?fig-data-anova-2 abgebildet.\n\n\n\n\nAbbildung 17.2— Boxplot der Sprungweiten [cm] von Hunden und Katzen."
  },
  {
    "objectID": "stat-tests-utest.html",
    "href": "stat-tests-utest.html",
    "title": "\n18  Der Wilcoxon-Mann-Whitney-Test\n",
    "section": "",
    "text": "Was macht der Wilcoxon-Mann-Whitney-Test?\n\n\n\nDer Wilcoxon-Mann-Whitney-Test vergleicht die Mediane zweier beliebiger Verteilungen miteinander.\n\n\n\n\n\n\n\n\nEinführung in den Wilcoxon-Mann-Whitney-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-kruskal.html",
    "href": "stat-tests-kruskal.html",
    "title": "\n19  Der Kruskal-Wallis-Test\n",
    "section": "",
    "text": "Was macht der Kruskal-Wallis-Test?\n\n\n\nDer Kruskal-Wallis-Test vergleicht die Mediane mehrerer beliebiger Verteilungen miteinander.\n\n\n\n\n\n\n\n\nEinführung in den Kruskal-Wallis-Test per Video\n\n\n\nDu findest auf YouTube Grundlagen in R als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher."
  },
  {
    "objectID": "stat-tests-chi-test.html",
    "href": "stat-tests-chi-test.html",
    "title": "\n20  \\(\\mathcal{X}^2\\)-Test\n",
    "section": "",
    "text": "Einführung in den \\(\\mathcal{X}^2\\)-Test per Video\n\n\n\nDu findest auf YouTube Der Chi-Quadrat-Test erklärt als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\n\n\nTabelle 20.1— Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils.\n\n\n\n\n\n\n\n\n\n\n\nInfected\n\n\n\n\n\n\nYes (1)\nNo (0)\n\n\n\nAnimal\nDog\n\\(23_{\\;\\Large a}\\)\n\\(10_{\\;\\Large b}\\)\n\\(\\mathbf{a+b = 33}\\)\n\n\n\nCat\n\\(18_{\\;\\Large c}\\)\n\\(14_{\\;\\Large d}\\)\n\\(\\mathbf{c+d = 32}\\)\n\n\n\n\n\\(\\mathbf{a+c = 41}\\)\n\\(\\mathbf{b+d = 24}\\)\n\\(n = 65\\)\n\n\n\n\nText Tabelle 20.1\n\n\nTabelle 20.2— Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei Hunden und Katzen für die Berechnung von Effektschätzern eines Anteils.\n\n\n\n\n\n\n\n\n\n\n\nInfected\n\n\n\n\n\n\nYes (1)\nNo (0)\n\n\n\nAnimal\nDog\n\\(\\cfrac{41 \\cdot 33}{65} = 20.82\\)\n\\(\\cfrac{24 \\cdot 33}{65} = 12.18\\)\n\\(\\mathbf{33}\\)\n\n\n\nCat\n\\(\\cfrac{41 \\cdot 32}{65} = 20.18\\)\n\\(\\cfrac{24 \\cdot 32}{65} = 11.82\\)\n\\(\\mathbf{32}\\)\n\n\n\n\n\\(\\mathbf{41}\\)\n\\(\\mathbf{24}\\)\n\\(n = 65\\)\n\n\n\n\nText Tabelle 20.2\n\\[\n\\chi^2 = \\cfrac{(O - E)^2}{E}\n\\]\n\\[\\begin{align*}\n\\chi^2 &= \\cfrac{(23 - 20.82)^2}{20.82} + \\cfrac{(10 - 12.18)^2}{12.18} + \\\\\n&\\phantom{=}\\;\\; \\cfrac{(18 - 20.18)^2}{20.18} + \\cfrac{(14 - 11.82)^2}{11.82} = 1.25\n\\end{align*}\\]\nTest\n\nmat <- matrix(c(23, 10, 18, 14), byrow = TRUE, nrow = 2)\nchisq.test(mat, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  mat\nX-squared = 1.26134, df = 1, p-value = 0.2614\n\n\n\\(\\chi^2_{\\alpha=5\\%} = 3.84\\)"
  },
  {
    "objectID": "distributions-preface.html",
    "href": "distributions-preface.html",
    "title": "Verteilungen",
    "section": "",
    "text": "https://rstudio-pubs-static.s3.amazonaws.com/100906_8e3a32dd11c14b839468db756cee7400.html"
  },
  {
    "objectID": "distributions-preface.html#normalverteilung",
    "href": "distributions-preface.html#normalverteilung",
    "title": "Verteilungen",
    "section": "Normalverteilung",
    "text": "Normalverteilung\nKapitel 22"
  },
  {
    "objectID": "distributions-preface.html#poissonverteilung",
    "href": "distributions-preface.html#poissonverteilung",
    "title": "Verteilungen",
    "section": "Poissonverteilung",
    "text": "Poissonverteilung\nKapitel 23\nHundeffloh Beispiel in groß!!! Dormann (2013) Hurlbert (1984)\n\n\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer.\n\n\nHurlbert, Stuart H. 1984. „Pseudoreplication and the design of ecological field experiments“. Ecological monographs 54 (2): 187–211."
  },
  {
    "objectID": "distributions-normal.html",
    "href": "distributions-normal.html",
    "title": "22  Die Normalverteilung",
    "section": "",
    "text": "Abbildung 22.1— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung 22.1\n\n\n\n\nAbbildung 22.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung 22.2"
  },
  {
    "objectID": "distributions-poisson.html",
    "href": "distributions-poisson.html",
    "title": "23  Die Poissonverteilung",
    "section": "",
    "text": "An 39 Hunden wurde die Anzahl an Flöhen gezählt."
  },
  {
    "objectID": "statistical-modeling-preface.html#das-regressionskreuz",
    "href": "statistical-modeling-preface.html#das-regressionskreuz",
    "title": "Statistisches Modellieren",
    "section": "Das Regressionskreuz",
    "text": "Das Regressionskreuz\n\n\n\nAbbildung 1— Das Regressionskreuz"
  },
  {
    "objectID": "statistical-modeling-preface.html#kausales-modell",
    "href": "statistical-modeling-preface.html#kausales-modell",
    "title": "Statistisches Modellieren",
    "section": "Kausales Modell",
    "text": "Kausales Modell"
  },
  {
    "objectID": "statistical-modeling-preface.html#prädiktives-modell",
    "href": "statistical-modeling-preface.html#prädiktives-modell",
    "title": "Statistisches Modellieren",
    "section": "Prädiktives Modell",
    "text": "Prädiktives Modell"
  },
  {
    "objectID": "app-example-analysis.html#genutzte-r-pakete-für-das-kapitel",
    "href": "app-example-analysis.html#genutzte-r-pakete-für-das-kapitel",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.1 Genutzte R Pakete für das Kapitel",
    "text": "A.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, \n               broom, multcomp, emmeans, \n               conflicted)\n\n## resolve some conflicts with same function naming\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-gewichten",
    "href": "app-example-analysis.html#auswertung-von-gewichten",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.2 Auswertung von Gewichten",
    "text": "A.2 Auswertung von Gewichten\n\n\n\n\n\n\n\ntrt\nblock\nrep\nrsp\n\n\n\nlow\nI\n1\n13.07\n\n\nlow\nI\n2\n13.46\n\n\nlow\nI\n3\n10.13\n\n\nlow\nI\n4\n13.67\n\n\nlow\nII\n1\n13.92\n\n\nlow\nII\n2\n11.43\n\n\nlow\nII\n3\n15.31\n\n\nlow\nII\n4\n13.46\n\n\nlow\nIII\n1\n12.49\n\n\nlow\nIII\n2\n18.02\n\n\nlow\nIII\n3\n15.06\n\n\nlow\nIII\n4\n15.69\n\n\nmid\nI\n1\n14.85\n\n\nmid\nI\n2\n9.86\n\n\nmid\nI\n3\n12.85\n\n\nmid\nI\n4\n13.12\n\n\nmid\nII\n1\n17.07\n\n\nmid\nII\n2\n16.47\n\n\nmid\nII\n3\n12.70\n\n\nmid\nII\n4\n16.02\n\n\nmid\nIII\n1\n17.29\n\n\nmid\nIII\n2\n14.04\n\n\nmid\nIII\n3\n16.01\n\n\nmid\nIII\n4\n16.99\n\n\nhigh\nI\n1\n19.14\n\n\nhigh\nI\n2\n18.13\n\n\nhigh\nI\n3\n16.54\n\n\nhigh\nI\n4\n18.22\n\n\nhigh\nII\n1\n18.78\n\n\nhigh\nII\n2\n19.14\n\n\nhigh\nII\n3\n19.29\n\n\nhigh\nII\n4\n18.12\n\n\nhigh\nIII\n1\n17.60\n\n\nhigh\nIII\n2\n17.38\n\n\nhigh\nIII\n3\n21.93\n\n\nhigh\nIII\n4\n24.51\n\n\n\n\n\n\nA.2.1 Explorative Datenanalyse (EDA)\n\nggplot(data_tbl, aes(trt, rsp, color = block)) +\n  geom_boxplot()\n\n\n\n\n\nstat_tbl <- data_tbl %>% \n  group_by(trt, block) %>% \n  summarise(mean = mean(rsp),\n            sd = sd(rsp),\n            se = sd/sqrt(n()))\n\nggplot(stat_tbl, aes(x = trt, y = mean, fill = block)) + \n    geom_bar(position = position_dodge(), stat = \"identity\") +\n    geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                  width = 0.2,\n                  position = position_dodge(.9))\n\n\n\n\n\nA.2.2 Lineares Modell\n\nfit_1 <- lm(rsp ~ trt + block, data = data_tbl)\n\n\nA.2.3 ANOVA\n\nfit_1 %>% anova\n\nAnalysis of Variance Table\n\nResponse: rsp\n          Df   Sum Sq Mean Sq F value        Pr(>F)    \ntrt        2 187.9493 93.9747 26.8736 0.00000016989 ***\nblock      2  48.2658 24.1329  6.9012     0.0033185 ** \nResiduals 31 108.4042  3.4969                          \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nA.2.4 Gruppenvergleich mit dem multcomp Paket\nhttps://broom.tidymodels.org/reference/tidy.glht.html\n\nfit_1 %>% \n  glht(linfct = mcp(trt = \"Tukey\")) %>% \n  tidy %>% \n  select(contrast, estimate, adj.p.value) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 3 × 3\n  contrast   estimate adj.p.value\n  <chr>         <dbl>       <dbl>\n1 mid - low     0.964       0.426\n2 high - low    5.26        0    \n3 high - mid    4.29        0    \n\n\n\nA.2.5 Gruppenvergleich mit der emmeans Paket\nhttps://broom.tidymodels.org/reference/tidy.emmGrid.html\n\nfit_1 %>% \n  emmeans(\"trt\") %>% \n  contrast(method = \"pairwise\") %>% \n  tidy %>% \n  select(contrast, estimate, adj.p.value) %>% \n  mutate(across(where(is.numeric), round, 4))\n\n# A tibble: 3 × 3\n  contrast   estimate adj.p.value\n  <chr>         <dbl>       <dbl>\n1 low - mid    -0.964       0.426\n2 low - high   -5.26        0    \n3 mid - high   -4.29        0"
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-boniturnoten",
    "href": "app-example-analysis.html#auswertung-von-boniturnoten",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.3 Auswertung von Boniturnoten",
    "text": "A.3 Auswertung von Boniturnoten\n\n\n\n\n\n\n\nvariety\nblock\nrating\n\n\n\nA\nI\n2\n\n\nA\nI\n3\n\n\nA\nI\n3\n\n\nA\nI\n4\n\n\nA\nI\n1\n\n\nA\nII\n3\n\n\nA\nII\n2\n\n\nA\nII\n2\n\n\nA\nII\n4\n\n\nA\nII\n4\n\n\nA\nIII\n2\n\n\nA\nIII\n2\n\n\nA\nIII\n3\n\n\nA\nIII\n1\n\n\nA\nIII\n2\n\n\nB\nI\n8\n\n\nB\nI\n9\n\n\nB\nI\n8\n\n\nB\nI\n9\n\n\nB\nI\n7\n\n\nB\nII\n7\n\n\nB\nII\n7\n\n\nB\nII\n8\n\n\nB\nII\n8\n\n\nB\nII\n7\n\n\nB\nIII\n8\n\n\nB\nIII\n9\n\n\nB\nIII\n7\n\n\nB\nIII\n9\n\n\nB\nIII\n8\n\n\nC\nI\n6\n\n\nC\nI\n5\n\n\nC\nI\n5\n\n\nC\nI\n6\n\n\nC\nI\n4\n\n\nC\nII\n4\n\n\nC\nII\n5\n\n\nC\nII\n3\n\n\nC\nII\n6\n\n\nC\nII\n4\n\n\nC\nIII\n7\n\n\nC\nIII\n6\n\n\nC\nIII\n4\n\n\nC\nIII\n6\n\n\nC\nIII\n4\n\n\nD\nI\n2\n\n\nD\nI\n4\n\n\nD\nI\n1\n\n\nD\nI\n2\n\n\nD\nI\n2\n\n\nD\nII\n2\n\n\nD\nII\n4\n\n\nD\nII\n4\n\n\nD\nII\n1\n\n\nD\nII\n3\n\n\nD\nIII\n3\n\n\nD\nIII\n4\n\n\nD\nIII\n2\n\n\nD\nIII\n1\n\n\nD\nIII\n3\n\n\nE\nI\n4\n\n\nE\nI\n4\n\n\nE\nI\n2\n\n\nE\nI\n7\n\n\nE\nI\n5\n\n\nE\nII\n4\n\n\nE\nII\n3\n\n\nE\nII\n4\n\n\nE\nII\n7\n\n\nE\nII\n7\n\n\nE\nIII\n5\n\n\nE\nIII\n5\n\n\nE\nIII\n4\n\n\nE\nIII\n6\n\n\nE\nIII\n6\n\n\n\n\n\n\nA.3.1 Explorative Datenanalyse (EDA)\n\nggplot(data_tbl, aes(variety, rating, color = block)) +\n  geom_boxplot() +\n  geom_dotplot(aes(fill = block), binaxis = \"y\", stackdir='center', \n               position=position_dodge(0.8))  \n\n\n\n\n\nggplot(data_tbl, aes(variety, rating, fill = block)) +\n  geom_dotplot(binaxis = \"y\", stackdir='center', \n               position=position_dodge(0.8)) +\n  stat_summary(fun = median, fun.min = median, fun.max = median,\n               geom = \"crossbar\", width = 0.5, \n               position=position_dodge(0.8)) \n\n\n\n\n\nA.3.2 Friedman Test\n\n#friedman.test(rating ~ variety | block, data = data_tbl)\n\ndata_tbl <- tibble(Block = 1:4,\n                   Sorte_1 = c(2,3,4,3),\n                   Sorte_2 = c(7,9,8,9),\n                   Sorte_3 = c(6,5,4,7),\n                   Sorte_4 = c(2,4,1,2),\n                   Sorte_5 = c(4,5,3,7)) %>%\n  gather(key, value, Sorte_1:Sorte_5)\n\nfriedman.test(value ~ key | Block, data = data_tbl)\n\n\n    Friedman rank sum test\n\ndata:  value and key and Block\nFriedman chi-squared = 13.5263, df = 4, p-value = 0.0089709"
  },
  {
    "objectID": "app-example-analysis.html#auswertung-von-infektionsstatus",
    "href": "app-example-analysis.html#auswertung-von-infektionsstatus",
    "title": "Appendix A — Beispielhafte Auswertungen",
    "section": "\nA.4 Auswertung von Infektionsstatus",
    "text": "A.4 Auswertung von Infektionsstatus"
  },
  {
    "objectID": "app-r-tutorial.html#genutzte-r-pakete-für-das-kapitel",
    "href": "app-r-tutorial.html#genutzte-r-pakete-für-das-kapitel",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.1 Genutzte R Pakete für das Kapitel",
    "text": "B.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, broom, broom.mixed, \n               multcomp, emmeans, performance, lme4, effectsize)\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.\nR Package performance\nR Package effectsize"
  },
  {
    "objectID": "app-r-tutorial.html#keimung",
    "href": "app-r-tutorial.html#keimung",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.2 Keimung",
    "text": "B.2 Keimung\n\ngerm_tbl <- read_excel(\"data/germination_data.xlsx\")"
  },
  {
    "objectID": "app-r-tutorial.html#schweine",
    "href": "app-r-tutorial.html#schweine",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.3 Schweine",
    "text": "B.3 Schweine\n\npig_tbl <- read_excel(\"data/pig_feed_data.xlsx\")"
  },
  {
    "objectID": "app-r-tutorial.html#kohlenstoffnitrat",
    "href": "app-r-tutorial.html#kohlenstoffnitrat",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.4 Kohlenstoff/Nitrat",
    "text": "B.4 Kohlenstoff/Nitrat\n\ncarbon_tbl <- read_excel(\"data/carbon_data.xlsx\") %>% \n  mutate(c2n = c_o/n,\n         c_m2c_o = c_m/c_o)"
  },
  {
    "objectID": "app-r-tutorial.html#lichtintensität",
    "href": "app-r-tutorial.html#lichtintensität",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.5 Lichtintensität",
    "text": "B.5 Lichtintensität\n\nintensity_tbl <- read_excel(\"data/light_intensity_data.xlsx\") %>% \n  mutate(rack = as_factor(rack),\n         layer = as_factor(layer),\n         light_intensity = factor(light_intensity, \n                                  labels = c(\"low\", \"mid\", \"high\")))\n\n\n\n\n\nfit_1 <- lm(growth ~ light_intensity + rack + layer, data = intensity_tbl)\n\nfit_1 %>% anova %>% tidy\n\n# A tibble: 4 × 6\n  term               df  sumsq meansq statistic  p.value\n  <chr>           <int>  <dbl>  <dbl>     <dbl>    <dbl>\n1 light_intensity     2  433.   217.      3.87   0.0278 \n2 rack                2  628.   314.      5.61   0.00652\n3 layer               2   70.9   35.5     0.633  0.535  \n4 Residuals          47 2631.    56.0    NA     NA      \n\n\n\nfit_1 %>% glht(linfct = mcp(light_intensity = \"Tukey\")) %>% tidy\n\n# A tibble: 3 × 7\n  term            contrast   null.value estimate std.error statistic adj.p.value\n  <chr>           <chr>           <dbl>    <dbl>     <dbl>     <dbl>       <dbl>\n1 light_intensity mid - low           0    -2.88      2.49     -1.15      0.486 \n2 light_intensity high - low          0    -6.91      2.49     -2.77      0.0215\n3 light_intensity high - mid          0    -4.03      2.49     -1.61      0.249 \n\n\n\nmarginal <- emmeans(fit_1, \"light_intensity\")\ntidy(marginal) %>% \n  mutate_if(is.numeric, round, 2)\n\n# A tibble: 3 × 6\n  light_intensity estimate std.error    df statistic p.value\n  <chr>              <dbl>     <dbl> <dbl>     <dbl>   <dbl>\n1 low                 18.2      1.76    47     10.3        0\n2 mid                 15.3      1.76    47      8.69       0\n3 high                11.3      1.76    47      6.4        0\n\n\n\nmarginal %>% contrast(method = \"pairwise\") %>% tidy %>% \n  mutate_if(is.numeric, round, 2)\n\n# A tibble: 3 × 8\n  term        contrast null.value estimate std.error    df statistic adj.p.value\n  <chr>       <chr>         <dbl>    <dbl>     <dbl> <dbl>     <dbl>       <dbl>\n1 light_inte… low - m…          0     2.88      2.49    47      1.15        0.49\n2 light_inte… low - h…          0     6.91      2.49    47      2.77        0.02\n3 light_inte… mid - h…          0     4.03      2.49    47      1.61        0.25"
  },
  {
    "objectID": "app-r-tutorial.html#komplexes-weizenbeispiel",
    "href": "app-r-tutorial.html#komplexes-weizenbeispiel",
    "title": "Appendix B — Tutorium in R",
    "section": "\nB.6 Komplexes Weizenbeispiel",
    "text": "B.6 Komplexes Weizenbeispiel\nWir wollen uns nun ein kpmplexeres Datenbeispiel anschauen. In diesem Beispiel liegen zum einen die Daten in einem ungünstigen Wide-Format vor und müssen über gather() erst in das Long-Format gebracht werden. Zum anderen entstehen dadurch ungünstige Einträge in der key-Spalte, so dass wir hier nochmal einen regulären Ausdruck benötigen um den character Vektor umwandeln zu können.\nAls wäre dies nicht schon kompliziert genug, schauen wir uns nicht nur ein Outcome an, sondern in der Summe die Outcomes Weizenhöhe, Chlorophyllgehalt sowie Frisch- und Trockengewichte. Der Weizen wurde in vier Blöcken angezogen und zu verschiedenen Zeitpunkten gemessen. Hierdurch entsteht ein komplexer Versuchsaufbau.\n\nB.6.1 Weizenhöhe\nDie Höhe der Weizenpflanzen [cm] wurde in vier Blöcken an insgesamt neun Tagen gemessen. Die Datei corn_plant_height.csv beinhaltet die Daten des Versuchs. Für die folgende Auswertung nehmen wir an, das die Weizenhöhe normalverteilt ist. Wie beginnen mit einer exploratven Datenanalyse udn schauen uns die Daten einmal an.\n\nB.6.1.1 Exlorative Datenanalyse\n\nplant_tbl <- read_csv2(\"data/corn_plant_height.csv\") %>% \n  gather(key = \"day\", value = \"height\", \"1...3\":\"9...47\") %>% \n  mutate(day = str_replace(day, \"...\\\\d+\", \"\"),\n         day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\")))\n\nIn der csv-Datei sind die die Tage jeweils fünfmal mit einer 1 bis 9 in den Spalten abgebildet. Wir nutzen die Funktion read_csv2 um mit dem deutschen Format der csv-Datei umgehen zu können. Die Funktion read_csv2 erkennt das ; als Separator. Da R nicht mit gleichen Benennungen in den Spalten umgehen kann, setzt R hinter jeden Spaltennamen, der gleich ist drei Punkte und eine fortlaufende Zahl. Mit der Funktion gather() können wir die Spalten 1...3 bis 9...47 untereinanderkleben. Abschließend müssen wir noch den ...[Zahl]-Teil loswerden. Das machen wir über den regulären Ausdruck in der Funktion str_replace(). Reguläre Ausdrücke musst du nicht verstehen, sind aber sehr mächtige Werkzeuge im Umgang mit großen Datensätzen.\nSchauen wir uns nun einmal die Daten an. Unser Outcome (Y) ist height und auf X wollen wir das treatment. Das wollen wir die Boxplots noch nach dem Tag einfärben und jeweils ein Subplot für die vier Blöcke bauen.\n\nggplot(plant_tbl, aes(x = treatment, y = height, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Weizenhöhe [cm]\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\nAbbildung B.1— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung B.1 zeigt den entsprechenden Boxplot. Du siehst, dass du auf den ersten Blick nichts siehst. Bei einer so großen Datenmenge ist es selbst mit einem guten ggplot() schwer etwas zu erkennen. Hier müssen wir uns mehrere Fragen stellen…\n\n… wollen wir wirklich alle Blöcke getrennt auswerten?\n… wollen wir uns wirklich alle Tage anschauen? Oder geht es nicht eher um die Pflanzenhöhe am Ende des Versuches?\n… wollen wir wirklich alle treatment Stufen vergleichen?\n\n\nplant_tbl %>% \n  filter(block == \"I\") %>% \n  filter(day %in% c(6, 7, 8, 9)) %>% \n  ggplot(aes(x = treatment, y = height, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Weizenhöhe [cm]\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\nAbbildung B.2— An 39 Hunden wurde die Anzahl an Flöhen gezählt.\n\n\n\n\nAbbildung B.2 zeigt einen Auschnitt in dem wir nur nach Block I und den Tagen 6 bis 9 gefiltert haben. In diesem Fall könnten wir auf den vollen Datensatz weitermachen oder vorab über filter() einen kleinern Datensatz bauen, der unsere Fragestellung bgut beantworten kann. Wir gehen jetzt den steinigeren Weg und analysieren den ganzen Datensatz - das muss nicht der bessere Weg sein!\n\nB.6.1.2 Lineares Modell mit lm()\n\nWir beginnen mit einer ANOVA und müssen dafür ein lineare Modell schätzen. Dafür nutzen wir erst die Funktion lm() und anschließend mit dem Ergebnis des linearen Modells die Funktion anova() um eine Varianzanalyse durchzuführen.\n\nfit_height <- lm(height ~ treatment + day + block + \n                   treatment:day + treatment:block, \n                 data = plant_tbl)\n\nfit_height %>% anova\n\nAnalysis of Variance Table\n\nResponse: height\n                  Df  Sum Sq Mean Sq    F value                 Pr(>F)    \ntreatment          7  2402.5  343.22  211.20218 < 0.000000000000000222 ***\nday                8 41280.2 5160.03 3175.28495 < 0.000000000000000222 ***\nblock              3    63.4   21.14   13.01124     0.0000000222375065 ***\ntreatment:day     56  1076.3   19.22   11.82650 < 0.000000000000000222 ***\ntreatment:block   21   162.2    7.72    4.75297     0.0000000000099287 ***\nResiduals       1344  2184.1    1.63                                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWir konzentrieren uns auf die Spalte Pr(>F) welche den p-Wert beinhaltet. Wir schauen welcher p-Wert kleiner ist als \\(\\alpha = 5\\% = 0.05\\). Alle p-Werte sind signifikant. Mindestens zwei treatment Level unterscheiden sich, mindestens zwei day Level unterschieden sich und mindestens zwei block Level unterscheiden sich. Abschließend ist auch der Interaktionsterm zwischen den Behandlungen und den Tagen sowie den Behandlungen und den Blöcken signifikant.\n\nfit_height %>% anova %>% eta_squared(partial = FALSE)\n\n# Effect Size for ANOVA (Type I)\n\nParameter       |     Eta2 |       95% CI\n-----------------------------------------\ntreatment       |     0.05 | [0.03, 1.00]\nday             |     0.88 | [0.87, 1.00]\nblock           | 1.34e-03 | [0.00, 1.00]\ntreatment:day   |     0.02 | [0.00, 1.00]\ntreatment:block | 3.44e-03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at (1).\n\n\nfit_height_lme <- lmer(height ~ treatment + block + (1|day), \n                       data = plant_tbl)\n\nfit_height_lme %>% summary\n\nfit_height_lme %>% \n  tidy(conf.int = TRUE, effects = \"fixed\")\n\nmodel_performance(fit_height_lme) \n\nr2(fit_height_lme)\n\nconf_tbl <- glht(fit_height_lme, linfct = mcp(treatment = \"Tukey\")) %>% \n  tidy(conf.int = TRUE) %>% \n  arrange(estimate) %>% \n  mutate(contrast = as_factor(contrast))\n\nggplot(conf_tbl, aes(x = contrast, y = estimate, \n                     ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"\", y = \"Mittelwertsdifferenz der Weizenhöhe [cm]\") +\n  coord_flip() +\n  theme_bw()\n\nB.6.2 Chlorophyllgehalt\n\nchlorophyl_tbl <- read_csv2(\"data/corn_chlorophyl.csv\") %>% \n  gather(key = \"day\", value = \"chlorophyl\", \"1...3\":\"3...62\") %>% \n  mutate(day = str_replace(day, \"...\\\\d+\", \"\"),\n         day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\"))) %>% \n  filter(chlorophyl >= 20 & chlorophyl <= 100)\n\n\nggplot(chlorophyl_tbl, aes(x = treatment, y = chlorophyl, fill = day)) +\n  geom_boxplot() +\n  facet_wrap(~ block) +\n  labs(x = \"Behandlung\", y = \"Chlorophyllgehalt\", fill = \"Messtag\") +\n  theme_bw()\n\n\n\n\n\nB.6.3 Frisch- und Trockenmasse\n\nburn_tbl <- read_csv2(\"data/corn_burning.csv\") %>% \n  gather(key = \"day_outcome\", value = \"drymatter\", \"1_FM\":\"3_TMperc\") %>%\n  separate(day_outcome, c(\"day\", \"outcome\")) %>% \n  mutate(day = as_factor(day),\n         treatment = as_factor(treatment),\n         block = factor(block, labels = c(\"I\", \"II\", \"III\", \"IV\")),\n         outcome = as_factor(outcome)) \n\n\nburn_tbl %>% \n  filter(outcome == \"FM\") %>% \n  ggplot(aes(x = treatment, y = drymatter, color = day)) +\n  geom_point() +\n  ##facet_wrap(~ block, scales = \"free_y\") +\n  labs(x = \"Behandlung\", y = \"Gewicht\", fill = \"Messtag\") +\n  theme_bw()"
  },
  {
    "objectID": "app-how-to-write.html",
    "href": "app-how-to-write.html",
    "title": "Appendix C — Writing principles",
    "section": "",
    "text": "Schreiben ist nicht einfach. Aber es folgt einem Schema. Schreiben ist anstrengend und dauert seine Zeit. Ein guter Text wird mehrfach revidiert, umgeschrieben und gelöscht, bis er zu einem guten Text geworden ist. Häufig vergehen mehrere Tage bis man eine Idee so auf das Blatt Papier gebracht hat, dass auch ein Dritter den Text lesen und verstehen kann.\n\n\n\n\n\n\nZentraler Gedanke\n\n\n\nDer erste Entwurf ist für einen selber, ab dem zweiten geht es um den Leser.\n\n\nEs geht also am Anfang erstmal darum, Text auf das weiße Blatt zu kriegen.\n\n\n\n\n\n\nOtto Kruse – Keine Angst vor dem leeren Blatt\n\n\n\nViele wissenschaftliche Themen kann man erst dann lösen, wenn man alle Aspekte explizit formuliert hat. Das Denken ist dafür insofern nicht genügend vorbereitet, als es immer nur kleine Ausschnitte fokussieren kann. Systematisch denken kann man nur, wenn man schreibt, also die Ergebnisse seines Denkens festhält und mit weiteren Aspekten in Beziehung setzt.\n\n\nDas ist die Idee vom Schreiben. Andere merken, wie weit du mit deinen Gedanken gekommen bist. Wir bringen komplexe Gedankengänge in die lineare Form des Textes."
  },
  {
    "objectID": "app-how-to-write.html#der-schreibprozess",
    "href": "app-how-to-write.html#der-schreibprozess",
    "title": "Appendix C — Writing principles",
    "section": "C.2 Der Schreibprozess",
    "text": "C.2 Der Schreibprozess\nDer Schreibprozess läuft nach Beginn in den nächsten Wochen und Monaten in mehreren Phasen ab. In jeder Phase ist es wichtig, sich ein gutes Umfeld für konzentriertes Arbeiten zu schaffen, gleichzeitig aber die Kommunikation mit den Betreuenden und anderen Mitschaffenden nicht abreißen zu lassen."
  },
  {
    "objectID": "app-how-to-write.html#zeitplan",
    "href": "app-how-to-write.html#zeitplan",
    "title": "Appendix C — Writing principles",
    "section": "C.3 Zeitplan",
    "text": "C.3 Zeitplan\nHier ist es wichtig was geschrieben werden soll. Eine Bachelor- und Masterarbeit hat einen klaren Zeitplan, der vorab feststehen muss. Bis wann müssen wie viele Wörter geschrieben sein, damit die Arbeit fertig werden kann. Beide Abschlussformen haben ja unterschiedliche Zeitrahmen. Und das ist wirklich wichtig! Wann sollte man fertig sein mit Programmieren, wie lange soll man sich Zeit für Vortragsvorbereitung nehmen, etc. Auch eine wissenschaftliche Veröffentlichung hat einen Zeitplan! Leider – das ist der Primat der Forschung – kann sich der Zeitplan immer wieder ändern, wenn Methoden nicht klappen oder neue Erkenntnisse gewonnen werden. Dennoch muss klar sein, dass in endlicher Zeit – meist ein Jahr – ein Paper eingereicht werden kann. Auf dieses Ziel sollten sich alle Einschwören. Sonst ist eine Promotion in endlicher Zeit nicht machbar."
  },
  {
    "objectID": "app-how-to-write.html#ideen-entwickeln",
    "href": "app-how-to-write.html#ideen-entwickeln",
    "title": "Appendix C — Writing principles",
    "section": "C.4 Ideen entwickeln",
    "text": "C.4 Ideen entwickeln\nMan sammelt Ideen zunächst in der Breite und fokussiert dann, was davon man aufschreiben will. Man liest andere wissenschaftliche Paper, lernt vielleicht noch Grundlagen und Methoden, und macht sich Notizen, was interessant sein könnte, und wo es steht. Natürlich kann man sich bei den Betreuern und Mitschaffenden Hilfe und Anregungen holen, wo man Input herbekommt. Holen heißt aber nicht, dass man gebracht bekommt.\n\n\n\n\n\n\nOCAR Prinzip\n\n\n\nFrage dich, was ist das Opening (der Hintergrund der Arbeit), die Challenge (was ist das Problem, was gelöst werden soll?), die Action (was wirst du tun um dieses Problem zu lösen?) und die Results (Was kam dabei raus oder soll rauskommen?)"
  },
  {
    "objectID": "app-how-to-write.html#strukturieren",
    "href": "app-how-to-write.html#strukturieren",
    "title": "Appendix C — Writing principles",
    "section": "C.5 Strukturieren",
    "text": "C.5 Strukturieren\nDas grobe Gerüst ist ja vorgegeben. Eine wissenschaftliche Arbeit folgt dem IMRaD Schema. Erst die Einleitung (Introduction), dann die Methoden (Methods), gefolgt von den Ergebnissen (Results) und der Diskussion (Discussion). Am Ende der Einleitung wird nochmal die Fragestellung benannt. Welche Frage soll in der Arbeit beantwortet werden? Dann fehlt noch die Zusammenfassung am Anfang (abstract) und der Schluss bzw. das Fazit (conclusion). So ist das vorgegebene Schema für die Arbeit, das soll mit Inhalt gefüllt werden. Klingt erstmal einfach und ist es auch. Mit Zwischenüberschriften in den einzelnen Abschnitten kann man sich eine grobe Ordnung vorgeben, was in welcher Reihenfolge aufgeschrieben werden soll. Die Struktur innerhalb von Methodenteilen ist zum Beispiel oft gleich, Beschreibung der Studie, Beschreibung der interessierenden Variablen und ihrer Erhebung, Beschreibung der Auswertungsmethodik. Das kommt aber aufs Thema an. Und unterhalb dieser kann man sich wieder Unter-zwischen-unterüberschriften machen. Es wird sowieso noch alles überarbeitet.\n\n\n\n\n\n\nGrobe Strukturierung nach IMRaD\n\n\n\n\nZusammenfassung\n\n\nEinleitung\n\nForschungsfrage\n\nMaterial und Methoden\nErgebnisse\nDiskussion\n\n\nLiteratur\n\n\n\nWenn es einen Flowchart gibt, so gibt dieser auch die Struktur vor. Ein Flowchart ist nicht final und ändert sich mit der Zeit! Mach den Flowchart am besten auf einem Blatt Papier. Da kannst du schneller was ergänzen.\n\n\n\n\n\n\nHinweis\n\n\n\nZeichne einen Flowchart, der aufzeigt was in der Arbeit passiert!"
  },
  {
    "objectID": "app-how-to-write.html#rohtexten",
    "href": "app-how-to-write.html#rohtexten",
    "title": "Appendix C — Writing principles",
    "section": "C.6 Rohtexten",
    "text": "C.6 Rohtexten\nDas kann wirklich sloppy sein, in Stichpunkten oder hingerotzt, aber hier soll man sich auch nicht an Details aufhalten, sondern dem Arbeits- und Denkfluss folgen. Gerne auch Denglisch. Lieber erst Text schreiben und dann korrigieren. Wenn das Englische Wort nicht einfällt, das deutsche Hinschreiben. Den Schreibprozess nicht durch im Internet suchen und dann mal was Anderes gucken unterbrechen. Gerade wenn die Arbeit selbst noch im Entstehen ist, schreibt man erst einmal auf, was man tut, was man gemacht, gelernt, oder gelesen hat. Diese Frage stellt sich meist nach den ersten paar Sätzen in einer wissenschaftlichen Arbeit. Worum geht es hier eigentlich? Es könnte alles so einfach sein. Das ist normal. Durch das Aufschreiben werden einem meist die Dinge klarer und uns wird bewusst, wo wir nochmal genauer einhaken müssen."
  },
  {
    "objectID": "app-how-to-write.html#reflektieren",
    "href": "app-how-to-write.html#reflektieren",
    "title": "Appendix C — Writing principles",
    "section": "C.7 Reflektieren",
    "text": "C.7 Reflektieren\nDie Grundideen sind jetzt schon mal auf dem Papier, jetzt muss man sich überlegen, wie daraus ein Text wird. Gut ist es, sich schon an dieser Stelle Feedback von Betreuern oder Kommilitonen zu holen. Das hilft auch, die eigene Perspektive auf den Text zu ändern und ihn aus mehreren Richtungen zu betrachten – was ist wichtig, was soll viel Platz einnehmen, was fehlt vielleicht noch?\n\n\n\n\n\n\nHinweis\n\n\n\nWas könnte die zentrale Abbildung in den Ergebnissen sein?\n\n\nEin guter Ansatz um einen Fokus zu haben!"
  },
  {
    "objectID": "app-how-to-write.html#jetzt-schreiben-wir-wie-geht-es-am-besten",
    "href": "app-how-to-write.html#jetzt-schreiben-wir-wie-geht-es-am-besten",
    "title": "Appendix C — Writing principles",
    "section": "C.8 Jetzt schreiben wir! Wie geht es am besten?",
    "text": "C.8 Jetzt schreiben wir! Wie geht es am besten?\nDafür geht gut die Hälfte der Schreibzeit drauf. Am wichtigsten sind Inhalt und Struktur, Korrektheit und Verständlichkeit dürfen aber auch nicht unterschätzt werden: Wir nutzen einfache englische Sprache. Das geschriebene Wort muss nicht schlau klingen, sondern der Inhalt muss schlau sein. Keine umständlichen, gekünstelten Verben verwenden, wenn es ein einfaches Verb auch tut. Wir machen es dem Leser einfach. Später wirst du in einem wissenschaftlichen Paper „we” schreiben, da man selten ein Paper alleine schreibt. Um das jetzt hier gleich am Anfang zu üben, schreibst du keine verschachtelten Passivkonstruktionen, sondern „I do/did something”. Das fühlt sich erst seltsam an, aber wir als Leser danken dir!\n\n\n\n\n\n\nSchlecht\n\n\n\nAfter the raw methylation data has been preprocessed, a student t test was used for the differential analysis.\n\n\n\n\n\n\n\n\nGut\n\n\n\nI used the student t test for the differential analysis after the preprocessing of the raw methylation data.\n\n\nWir nutzen auch keine Pronomen, wo man nicht weiß, was diese Pronomen aussagen sollen. Was ist „it” oder „they”?\n\n\n\n\n\n\nSchlecht\n\n\n\nThe dog and the cat walk into a house. It eats all the cookies.\n\n\n\n\n\n\n\n\nGut\n\n\n\nThe dog and the cat walk into a house. The cat eats all the cookies.\n\n\nWir führen alle Begriffe vorher ein, daher erklären wir diese Begriffe, bevor wir die Begriffe verwenden. Ja, mache Begriffe sind klar, aber welche das sind, ergibt sich manchmal erst auf Nachfrage bei uns und ist für einen Neuling in einem Fachbereich gar nicht zu wissen.\n\n\n\n\n\n\nSchlecht\n\n\n\nI analyzed the NGS data with an ANOVA after checking the residuals with a QQ-plot.\n\n\n\n\n\n\n\n\nGut\n\n\n\nI analyzed the next generation sequencing data (NGS) with an analysis of variance (ANOVA) after plotting the residuals of the model in a quantile-quantile plot (QQ-plot).\n\n\nIst dir der Begriff nicht klar, erkläre ihn. Später können wir immer noch kürzen. Erkenntnisgewinn durch schreiben ist das Ziel."
  },
  {
    "objectID": "app-how-to-write.html#wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz",
    "href": "app-how-to-write.html#wer-macht-was-die-frage-des-lesers-an-jeden-einzelnen-satz",
    "title": "Appendix C — Writing principles",
    "section": "C.9 Wer macht was? Die Frage des Lesers an jeden einzelnen Satz!",
    "text": "C.9 Wer macht was? Die Frage des Lesers an jeden einzelnen Satz!\nKomme in den ersten sieben Wörtern zum Punkt, wer was macht. Subjekt und Prädikat sollen nah beieinander sein und möglichst früh im Satz kommen. Wir schreiben kurze Sätze und vermeiden komplizierte Schachtelsätze.\n\n\n\n\n\n\nSchlecht\n\n\n\nThe differential analysis of whole genome genetic data - like methylation pattern or expression analysis - has a long history of different invented methods and I used different analysis methods to find the best method for the analysis of methylation data with repeated measurements.\n\n\n\n\n\n\n\n\nGut\n\n\n\n[1] A long history of different analysis methods like methylation pattern or expression analysis exists. [2] Hence, many scientist have invented different analysis methods of whole genome."
  },
  {
    "objectID": "app-how-to-write.html#löschen-von-text",
    "href": "app-how-to-write.html#löschen-von-text",
    "title": "Appendix C — Writing principles",
    "section": "C.10 Löschen von Text",
    "text": "C.10 Löschen von Text\nText löschen macht keine Freude. Es ist immer nervig Teile des Textes, den man so mühsam in die Maschine getippt hat, zu löschen. Lege dir eine neue Datei an, in der du alles was du löschen willst reinkopierst. Bei mir heißt die Datei dump.docx oder dump.R oder auch anders. Auf jeden Fall löschst du so keinen Text, sondern bewahrst ihn erstmal auf. Denk immer daran, es geht nicht darum nur viel Text zu produzieren!"
  },
  {
    "objectID": "app-how-to-write.html#zum-schluss-kommen",
    "href": "app-how-to-write.html#zum-schluss-kommen",
    "title": "Appendix C — Writing principles",
    "section": "C.11 Zum Schluss kommen",
    "text": "C.11 Zum Schluss kommen\nWie Anne und Jochen1 jetzt in diesem Augenblick musst du zum Schluss kommen. Kein Text ist perfekt, kein Gedankengang so klar niedergeschrieben, wie er sein könnte. Aber irgendwann muss gut sein. Lass das Perfekte nicht der Feind des Guten sein. Dieser Leitfaden ist good enough und somit muss es reichen. Viel Erfolg!1 Die beide zusammen die erste Version von diesem Text mal 2019 geschrieben haben. Tja, wie so die Zeit vergeht.\n\n\n\n\n\n\nErfahrungsbericht von ehemaligen Bachelorstudierenden\n\n\n\n\nkeine neuen (wichtigen) Begriffe verwenden, wenn sie nicht vorher eingeführt wurden\nwenn man einen Begriff nicht richtig versteht oder nicht richtig erklären kann, sollte man ihn nicht verwenden. Daher ist es sehr hilfreich sich gründlich in den Hintergrund des Themas einzulesen.\nman sollte mehr wissen über das Thema, als man eigentlich im Text erklärt (um auf Fragen vorbereitet zu sein)\nAchtgeben auf die Zeitformen\n“it”, “they” und weitere Pronomen vermeiden, d.h. immer klar machen worauf man sich bezieht\nwenn etwas komplizierter scheint, sollte man Beispiele benutzen oder es eventuell graphisch darstellen. Aber: ein Bild nicht verwenden, wenn es keinen inhaltlichen Wert hat! Bringt dieses Bild etwas zum Verständnis des Lesers bei?\nin der Diskussion kein neues “Fass aufmachen”\ndie Limitationen in der Diskussion im Fließtext “verstecken”\ndie eigene Arbeit nicht schlecht reden; “schlechte” Resultate sind auch Resultate\nkeine zu langen Sätze\nes sollte ein roter Faden in jedem Kapitel zu erkennen sein: Was ist das Ziel? Wie erreiche ich das? Was bringt mir diese Methode? Was sagen mir die Resultate (in Bezug auf mein Ziel)?\nund für die eigene Motivation: Es werden oft Schreibblockaden kommen, es wird oft frustrierend sein, weil vielleicht etwas umgeschmissen wird und man von vorne anfangen muss, etc., aber davon soll man sich nicht entmutigen lassen\nDer Text muss nicht gleich beim ersten Hinschreiben perfekt sein, sondern es hilft erstmal etwas drauflos zu schreiben um die Gedanken besser ordnen zu können\nähnlich beim Programmieren: hier hat es mir auch geholfen einfach erstmal anzufangen und Ideen aufzuschreiben, aus welchen sich kann das Programm aufbauen kann\nMan sollte nicht zögern so etwas wie deepl (deepl.com) zu benutzen, wenn man mal mit einer englischen Formulierung nicht weiterkommt\nMan kann vor Beginn eines Tages ein realistisches Tagesziel (oder alternativ ein Wochenziel) festlegen, dann hat man ein Zwischenziel vor Augen und ist zufrieden mit sich, wenn dieses erreicht ist"
  }
]