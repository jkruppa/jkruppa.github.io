[
  {
    "objectID": "stat-modeling-multinom.html",
    "href": "stat-modeling-multinom.html",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:48:22"
  },
  {
    "objectID": "stat-modeling-multinom.html#annahmen-an-die-daten",
    "href": "stat-modeling-multinom.html#annahmen-an-die-daten",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.1 Annahmen an die Daten",
    "text": "42.1 Annahmen an die Daten\nUnser gemessenes Outcome \\(y\\) folgt einer Multinomialverteilung.\nIm folgenden Kapitel zu der multinomialen / ordinalen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDaher sieht unser Modell wie folgt aus. Wir haben ein \\(y\\) und \\(p\\)-mal \\(x\\). Wobei \\(p\\) für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser \\(y\\) einer Multinomialverteilung. Damit finden wir im Outcome im Falle der multinomialen logistischen linearen Regression ungeordnete Kategorien und im Falle der ordinalen logistischen linearen Regression geordnete Kategorien.\n\\[\ny \\sim x_1 + x_2 + ... + x_p\n\\]\nWir können in dem Modell auch Faktoren \\(f\\) haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in Kapitel 31 nochmal nachlesen."
  },
  {
    "objectID": "stat-modeling-multinom.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-multinom.html#genutzte-r-pakete-für-das-kapitel",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.2 Genutzte R Pakete für das Kapitel",
    "text": "42.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, gtsummary,\n               ordinal, janitor, MASS, nnet, flextable)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"extract\", \"magrittr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-multinom.html#daten",
    "href": "stat-modeling-multinom.html#daten",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.3 Daten",
    "text": "42.3 Daten\nIm Folgenden wollen wir uns die Daten von den infirzierten Ferkeln nocheinmal anschauen.\n\npig_tbl <- read_excel(\"data/infected_pigs.xlsx\") %>%\n  mutate(frailty_ord = ordered(frailty, levels = c(\"robust\", \"pre-frail\", \"frail\")),\n         frailty_fac = as_factor(frailty)) %>% \n  select(-infected)\n\n\n\n\n\nTabelle 42.1— Auszug aus dem Daten zu den kranken Ferkeln.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nlocation\nactivity\ncrp\nfrailty\nbloodpressure\nweight\ncreatinin\nfrailty_ord\nfrailty_fac\n\n\n\n61\nmale\nnortheast\n15.31\n22.38\nrobust\n49.88\n16.94\n3.07\nrobust\nrobust\n\n\n53\nmale\nnorthwest\n13.01\n18.64\nrobust\n58.2\n17.95\n4.88\nrobust\nrobust\n\n\n66\nfemale\nnortheast\n11.31\n18.76\nrobust\n56.8\n19.02\n3.98\nrobust\nrobust\n\n\n59\nfemale\nnorth\n13.33\n19.37\nrobust\n56.47\n18.98\n5.18\nrobust\nrobust\n\n\n63\nmale\nnorthwest\n14.71\n21.57\nrobust\n59.85\n16.57\n6.71\nrobust\nrobust\n\n\n55\nmale\nnorthwest\n15.81\n21.45\nrobust\n58.1\n18.22\n5.43\nrobust\nrobust\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n54\nfemale\nnorth\n11.82\n21.5\nrobust\n57.05\n17.95\n6.16\nrobust\nrobust\n\n\n56\nmale\nwest\n13.91\n20.8\npre-frail\n50.84\n18.02\n6.52\npre-frail\npre-frail\n\n\n57\nmale\nnorthwest\n12.49\n21.95\nrobust\n55.51\n17.73\n3.94\nrobust\nrobust\n\n\n61\nmale\nnorthwest\n15.26\n23.1\nrobust\n58.5\n18.23\n2.73\nrobust\nrobust\n\n\n59\nfemale\nnorth\n13.13\n20.23\npre-frail\n57.33\n17.21\n5.42\npre-frail\npre-frail\n\n\n63\nfemale\nnorth\n10.01\n19.89\nrobust\n55.85\n17.76\n6.18\nrobust\nrobust"
  },
  {
    "objectID": "stat-modeling-multinom.html#sec-ordinal",
    "href": "stat-modeling-multinom.html#sec-ordinal",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.4 Ordinale logistische Regression",
    "text": "42.4 Ordinale logistische Regression\n\n\nIch verweise gerne hier auf das tolle Tutorium Ordinal Logistic Regression | R Data Analysis Examples. Hier erfährst du noch mehr über die Analyse der ordinalen logistischen Regression.\n\nologit_fit <- polr(frailty_ord ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n                   data = pig_tbl)\n\n\nologit_fit %>% summary\n\nCall:\npolr(formula = frailty_ord ~ age + sex + location + activity + \n    crp + bloodpressure + weight + creatinin, data = pig_tbl)\n\nCoefficients:\n                      Value Std. Error t value\nage                0.005199    0.02171  0.2395\nsexmale            0.500202    0.28214  1.7729\nlocationnortheast -0.315377    0.27927 -1.1293\nlocationnorthwest -0.469579    0.25166 -1.8659\nlocationwest      -0.046641    0.27381 -0.1703\nactivity          -0.130300    0.07409 -1.7587\ncrp               -0.133107    0.06857 -1.9412\nbloodpressure      0.016181    0.03083  0.5249\nweight             0.047346    0.07080  0.6687\ncreatinin         -0.022933    0.07097 -0.3231\n\nIntercepts:\n                 Value   Std. Error t value\nrobust|pre-frail -2.1188  3.0707    -0.6900\npre-frail|frail  -0.3625  3.0694    -0.1181\n\nResidual Deviance: 776.36 \nAIC: 800.36 \n\n\n\nologit_fit %>% confint %>% exp\n\n                      2.5 %   97.5 %\nage               0.9633072 1.048984\nsexmale           0.9516584 2.881206\nlocationnortheast 0.4200312 1.257605\nlocationnorthwest 0.3807089 1.022318\nlocationwest      0.5566250 1.630791\nactivity          0.7584483 1.014534\ncrp               0.7645865 1.000760\nbloodpressure     0.9567390 1.079823\nweight            0.9125247 1.205008\ncreatinin         0.8498400 1.122997\n\n\n\ncoef_df <- summary(ologit_fit) %>% coef\np_n <- pnorm(abs(coef_df[, \"t value\"]), lower.tail = FALSE) * 2\np_t <- pt(abs(coef_df[, \"t value\"]), df = 3, lower.tail = FALSE) * 2\n\n\ncbind(coef_df,\n      p_n = round(p_n, 3),\n      p_t = round(p_t, 3))\n\n                         Value Std. Error    t value   p_n   p_t\nage                0.005199352 0.02170954  0.2394962 0.811 0.826\nsexmale            0.500201551 0.28214267  1.7728674 0.076 0.174\nlocationnortheast -0.315377291 0.27927411 -1.1292751 0.259 0.341\nlocationnorthwest -0.469578672 0.25165847 -1.8659363 0.062 0.159\nlocationwest      -0.046641091 0.27381416 -0.1703385 0.865 0.876\nactivity          -0.130299886 0.07408863 -1.7587030 0.079 0.177\ncrp               -0.133107048 0.06856888 -1.9412166 0.052 0.148\nbloodpressure      0.016181426 0.03082777  0.5248978 0.600 0.636\nweight             0.047345962 0.07080095  0.6687193 0.504 0.552\ncreatinin         -0.022933163 0.07097244 -0.3231277 0.747 0.768\nrobust|pre-frail  -2.118843917 3.07073031 -0.6900130 0.490 0.540\npre-frail|frail   -0.362528056 3.06944639 -0.1181086 0.906 0.913\n\n\n\nologit_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 12 x 7\n   term              estimate std.error statistic conf.low conf.high coef.type  \n   <chr>                <dbl>     <dbl>     <dbl>    <dbl>     <dbl> <chr>      \n 1 age                  1.01     0.0217     0.239    0.963      1.05 coefficient\n 2 sexmale              1.65     0.282      1.77     0.952      2.88 coefficient\n 3 locationnortheast    0.730    0.279     -1.13     0.420      1.26 coefficient\n 4 locationnorthwest    0.625    0.252     -1.87     0.381      1.02 coefficient\n 5 locationwest         0.954    0.274     -0.170    0.557      1.63 coefficient\n 6 activity             0.878    0.0741    -1.76     0.758      1.01 coefficient\n 7 crp                  0.875    0.0686    -1.94     0.765      1.00 coefficient\n 8 bloodpressure        1.02     0.0308     0.525    0.957      1.08 coefficient\n 9 weight               1.05     0.0708     0.669    0.913      1.21 coefficient\n10 creatinin            0.977    0.0710    -0.323    0.850      1.12 coefficient\n11 robust|pre-frail     0.120    3.07      -0.690   NA         NA    scale      \n12 pre-frail|frail      0.696    3.07      -0.118   NA         NA    scale      \n\n\n\nologit_fit %>% \n  model_parameters() \n\n# alpha\n\nParameter        | Log-Odds |   SE |        95% CI | t(400) |     p\n-------------------------------------------------------------------\nrobust|pre-frail |    -2.12 | 3.07 | [-8.16, 3.92] |  -0.69 | 0.491\npre-frail|frail  |    -0.36 | 3.07 | [-6.40, 5.67] |  -0.12 | 0.906\n\n# beta\n\nParameter            | Log-Odds |   SE |        95% CI | t(400) |     p\n-----------------------------------------------------------------------\nage                  | 5.20e-03 | 0.02 | [-0.04, 0.05] |   0.24 | 0.811\nsex [male]           |     0.50 | 0.28 | [-0.05, 1.06] |   1.77 | 0.077\nlocation [northeast] |    -0.32 | 0.28 | [-0.87, 0.23] |  -1.13 | 0.259\nlocation [northwest] |    -0.47 | 0.25 | [-0.97, 0.02] |  -1.87 | 0.063\nlocation [west]      |    -0.05 | 0.27 | [-0.59, 0.49] |  -0.17 | 0.865\nactivity             |    -0.13 | 0.07 | [-0.28, 0.01] |  -1.76 | 0.079\ncrp                  |    -0.13 | 0.07 | [-0.27, 0.00] |  -1.94 | 0.053\nbloodpressure        |     0.02 | 0.03 | [-0.04, 0.08] |   0.52 | 0.600\nweight               |     0.05 | 0.07 | [-0.09, 0.19] |   0.67 | 0.504\ncreatinin            |    -0.02 | 0.07 | [-0.16, 0.12] |  -0.32 | 0.747\n\n\nTabelle 42.2\n\nologit_fit %>% \n  tbl_regression(exponentiate = TRUE) %>% \n  as_flex_table()\n\n\n\n\n\n\nTabelle 42.2—  . \n\nCharacteristic\nOR1\n95% CI1\n\n\n\nage\n1.01\n0.96, 1.05\n\n\nsex\n\n\n\n\nfemale\n—\n—\n\n\nmale\n1.65\n0.95, 2.88\n\n\nlocation\n\n\n\n\nnorth\n—\n—\n\n\nnortheast\n0.73\n0.42, 1.26\n\n\nnorthwest\n0.63\n0.38, 1.02\n\n\nwest\n0.95\n0.56, 1.63\n\n\nactivity\n0.88\n0.76, 1.01\n\n\ncrp\n0.88\n0.76, 1.00\n\n\nbloodpressure\n1.02\n0.96, 1.08\n\n\nweight\n1.05\n0.91, 1.21\n\n\ncreatinin\n0.98\n0.85, 1.12\n\n\n1OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "stat-modeling-multinom.html#sec-multinom",
    "href": "stat-modeling-multinom.html#sec-multinom",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.5 Multinomiale logistische Regression",
    "text": "42.5 Multinomiale logistische Regression\n\n\nIch verweise gerne hier auf das tolle Tutorium Multinomial Logistic Regression | R Data Analysis Examples. Hier erfährst du noch mehr über die Analyse der multinominale logistischen Regression.\n\npig_tbl <- pig_tbl %>% \n  mutate(frailty_fac = relevel(frailty_fac, ref = \"robust\"))\n\n\nmultinom_fit <- multinom(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n                         data = pig_tbl)\n\n# weights:  36 (22 variable)\ninitial  value 452.628263 \niter  10 value 390.759179\niter  20 value 381.245185\niter  30 value 380.697891\nfinal  value 380.689300 \nconverged\n\n\n\nmultinom_fit %>% summary\n\nCall:\nmultinom(formula = frailty_fac ~ age + sex + location + activity + \n    crp + bloodpressure + weight + creatinin, data = pig_tbl)\n\nCoefficients:\n          (Intercept)         age   sexmale locationnortheast locationnorthwest\npre-frail   0.1765445  0.03850673 0.4492529        -0.4199632        -0.4382088\nfrail       3.4341855 -0.03300306 0.6863658        -0.3002275        -0.6301388\n          locationwest    activity         crp bloodpressure     weight\npre-frail  -0.05719326 -0.19177661 -0.07970474   -0.01664706 0.08313382\nfrail      -0.07341575 -0.09052021 -0.22937521    0.05825885 0.01249045\n            creatinin\npre-frail  0.09493714\nfrail     -0.17831471\n\nStd. Errors:\n          (Intercept)        age   sexmale locationnortheast locationnorthwest\npre-frail    3.509106 0.02515175 0.3184276         0.3249232         0.2900054\nfrail        4.835287 0.03506653 0.4644217         0.4353908         0.4183902\n          locationwest   activity        crp bloodpressure     weight\npre-frail    0.3198947 0.08486291 0.07938138    0.03536417 0.08001256\nfrail        0.4314649 0.12087153 0.10977972    0.04957404 0.11281286\n           creatinin\npre-frail 0.08225239\nfrail     0.11711736\n\nResidual Deviance: 761.3786 \nAIC: 805.3786 \n\n\n\nmultinom_fit %>% confint %>%  exp\n\n, , pre-frail\n\n                        2.5 %       97.5 %\n(Intercept)       0.001229463 1157.7878026\nage               0.989268213    1.0917733\nsexmale           0.839579792    2.9251906\nlocationnortheast 0.347565917    1.2421883\nlocationnorthwest 0.365456129    1.1390464\nlocationwest      0.504506088    1.7678937\nactivity          0.698999777    0.9748727\ncrp               0.790342106    1.0788330\nbloodpressure     0.917631337    1.0540769\nweight            0.928961562    1.2711927\ncreatinin         0.935873852    1.2919450\n\n, , frail\n\n                        2.5 %       97.5 %\n(Intercept)       0.002374894 4.048102e+05\nage               0.903271408 1.036372e+00\nsexmale           0.799407815 4.936298e+00\nlocationnortheast 0.315505969 1.738674e+00\nlocationnorthwest 0.234530787 1.209118e+00\nlocationwest      0.398889262 2.164609e+00\nactivity          0.720778022 1.157640e+00\ncrp               0.641119444 9.858896e-01\nbloodpressure     0.961842576 1.168151e+00\nweight            0.811704683 1.263139e+00\ncreatinin         0.665071636 1.052566e+00\n\n\n\nz_mat <- summary(multinom_fit)$coefficients/summary(multinom_fit)$standard.errors\np_n <- (1 - pnorm(abs(z_mat), 0, 1)) * 2\np_n\n\n          (Intercept)       age   sexmale locationnortheast locationnorthwest\npre-frail   0.9598751 0.1257752 0.1582895         0.1961841         0.1307792\nfrail       0.4775590 0.3466251 0.1394363         0.4904718         0.1320407\n          locationwest   activity        crp bloodpressure    weight creatinin\npre-frail    0.8581044 0.02383117 0.31534322     0.6378318 0.2988003 0.2484111\nfrail        0.8648885 0.45391987 0.03667053     0.2399193 0.9118397 0.1278763\n\n\n\nmultinom_fit %>% tidy(conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 22 x 8\n   y.level   term        estimate std.error statistic p.value conf.low conf.high\n   <chr>     <chr>          <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 pre-frail (Intercept)    1.19     3.51      0.0503  0.960   0.00123  1158.   \n 2 pre-frail age            1.04     0.0252    1.53    0.126   0.989       1.09 \n 3 pre-frail sexmale        1.57     0.318     1.41    0.158   0.840       2.93 \n 4 pre-frail locationno~    0.657    0.325    -1.29    0.196   0.348       1.24 \n 5 pre-frail locationno~    0.645    0.290    -1.51    0.131   0.365       1.14 \n 6 pre-frail locationwe~    0.944    0.320    -0.179   0.858   0.505       1.77 \n 7 pre-frail activity       0.825    0.0849   -2.26    0.0238  0.699       0.975\n 8 pre-frail crp            0.923    0.0794   -1.00    0.315   0.790       1.08 \n 9 pre-frail bloodpress~    0.983    0.0354   -0.471   0.638   0.918       1.05 \n10 pre-frail weight         1.09     0.0800    1.04    0.299   0.929       1.27 \n# ... with 12 more rows\n\n\n\nmultinom_fit %>% model_parameters()\n\n# Response level: pre-frail\n\nParameter            | Log-Odds |   SE |         95% CI | t(390) |     p\n------------------------------------------------------------------------\n(Intercept)          |     0.18 | 3.51 | [-6.72,  7.08] |   0.05 | 0.960\nage                  |     0.04 | 0.03 | [-0.01,  0.09] |   1.53 | 0.127\nsex [male]           |     0.45 | 0.32 | [-0.18,  1.08] |   1.41 | 0.159\nlocation [northeast] |    -0.42 | 0.32 | [-1.06,  0.22] |  -1.29 | 0.197\nlocation [northwest] |    -0.44 | 0.29 | [-1.01,  0.13] |  -1.51 | 0.132\nlocation [west]      |    -0.06 | 0.32 | [-0.69,  0.57] |  -0.18 | 0.858\nactivity             |    -0.19 | 0.08 | [-0.36, -0.02] |  -2.26 | 0.024\ncrp                  |    -0.08 | 0.08 | [-0.24,  0.08] |  -1.00 | 0.316\nbloodpressure        |    -0.02 | 0.04 | [-0.09,  0.05] |  -0.47 | 0.638\nweight               |     0.08 | 0.08 | [-0.07,  0.24] |   1.04 | 0.299\ncreatinin            |     0.09 | 0.08 | [-0.07,  0.26] |   1.15 | 0.249\n\n# Response level: frail\n\nParameter            | Log-Odds |   SE |         95% CI | t(390) |     p\n------------------------------------------------------------------------\n(Intercept)          |     3.43 | 4.84 | [-6.07, 12.94] |   0.71 | 0.478\nage                  |    -0.03 | 0.04 | [-0.10,  0.04] |  -0.94 | 0.347\nsex [male]           |     0.69 | 0.46 | [-0.23,  1.60] |   1.48 | 0.140\nlocation [northeast] |    -0.30 | 0.44 | [-1.16,  0.56] |  -0.69 | 0.491\nlocation [northwest] |    -0.63 | 0.42 | [-1.45,  0.19] |  -1.51 | 0.133\nlocation [west]      |    -0.07 | 0.43 | [-0.92,  0.77] |  -0.17 | 0.865\nactivity             |    -0.09 | 0.12 | [-0.33,  0.15] |  -0.75 | 0.454\ncrp                  |    -0.23 | 0.11 | [-0.45, -0.01] |  -2.09 | 0.037\nbloodpressure        |     0.06 | 0.05 | [-0.04,  0.16] |   1.18 | 0.241\nweight               |     0.01 | 0.11 | [-0.21,  0.23] |   0.11 | 0.912\ncreatinin            |    -0.18 | 0.12 | [-0.41,  0.05] |  -1.52 | 0.129\n\n\nTabelle 42.3\n\nmultinom_fit %>% \n  tbl_regression(exponentiate = TRUE) %>% \n  as_flex_table()\n\n\n\n\n\n\nTabelle 42.3—  . \n\nOutcome\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\npre-frail\nage\n1.04\n0.99, 1.09\n0.13\n\n\n\nsex\n\n\n\n\n\n\nfemale\n—\n—\n\n\n\n\nmale\n1.57\n0.84, 2.93\n0.2\n\n\n\nlocation\n\n\n\n\n\n\nnorth\n—\n—\n\n\n\n\nnortheast\n0.66\n0.35, 1.24\n0.2\n\n\n\nnorthwest\n0.65\n0.37, 1.14\n0.13\n\n\n\nwest\n0.94\n0.50, 1.77\n0.9\n\n\n\nactivity\n0.83\n0.70, 0.97\n0.024\n\n\n\ncrp\n0.92\n0.79, 1.08\n0.3\n\n\n\nbloodpressure\n0.98\n0.92, 1.05\n0.6\n\n\n\nweight\n1.09\n0.93, 1.27\n0.3\n\n\n\ncreatinin\n1.10\n0.94, 1.29\n0.2\n\n\nfrail\nage\n0.97\n0.90, 1.04\n0.3\n\n\n\nsex\n\n\n\n\n\n\nfemale\n—\n—\n\n\n\n\nmale\n1.99\n0.80, 4.94\n0.14\n\n\n\nlocation\n\n\n\n\n\n\nnorth\n—\n—\n\n\n\n\nnortheast\n0.74\n0.32, 1.74\n0.5\n\n\n\nnorthwest\n0.53\n0.23, 1.21\n0.13\n\n\n\nwest\n0.93\n0.40, 2.16\n0.9\n\n\n\nactivity\n0.91\n0.72, 1.16\n0.5\n\n\n\ncrp\n0.80\n0.64, 0.99\n0.037\n\n\n\nbloodpressure\n1.06\n0.96, 1.17\n0.2\n\n\n\nweight\n1.01\n0.81, 1.26\n>0.9\n\n\n\ncreatinin\n0.84\n0.67, 1.05\n0.13\n\n\n1OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "stat-modeling-multinom.html#logistische-regression",
    "href": "stat-modeling-multinom.html#logistische-regression",
    "title": "42  Multinomiale / Ordinale logistische Regression",
    "section": "\n42.6 Logistische Regression",
    "text": "42.6 Logistische Regression\n\npig_tbl$frailty %>% tabyl\n\n         .   n   percent\n     frail  53 0.1286408\n pre-frail 133 0.3228155\n    robust 226 0.5485437\n\n\n\npig_lst <- list(robust_prefrail = filter(pig_tbl, frailty_fac %in% c(\"robust\", \"pre-frail\")),\n                robust_frail = filter(pig_tbl, frailty_fac %in% c(\"robust\", \"frail\")),\n                prefrail_frail = filter(pig_tbl, frailty_fac %in% c(\"pre-frail\", \"frail\")))\n\n\npig_lst %>% \n  map(~glm(frailty_fac ~ age + sex + location + activity + crp + bloodpressure + weight + creatinin, \n           data = .x, family = binomial)) %>% \n  map(model_parameters, exponentiate = TRUE) %>% \n  map(extract, -1, )\n\n$robust_prefrail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       1.04 | 0.03 | [0.99, 1.09] |  1.52 | 0.127\nsex [male]           |       1.58 | 0.51 | [0.85, 3.00] |  1.44 | 0.151\nlocation [northeast] |       0.66 | 0.22 | [0.35, 1.25] | -1.26 | 0.209\nlocation [northwest] |       0.65 | 0.19 | [0.36, 1.14] | -1.51 | 0.132\nlocation [west]      |       0.96 | 0.31 | [0.51, 1.80] | -0.13 | 0.895\nactivity             |       0.83 | 0.07 | [0.70, 0.98] | -2.19 | 0.028\ncrp                  |       0.93 | 0.07 | [0.79, 1.08] | -0.95 | 0.342\nbloodpressure        |       0.98 | 0.03 | [0.92, 1.06] | -0.44 | 0.657\nweight               |       1.09 | 0.09 | [0.93, 1.28] |  1.05 | 0.295\ncreatinin            |       1.11 | 0.09 | [0.94, 1.31] |  1.23 | 0.220\n\n$robust_frail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       0.96 | 0.03 | [0.89, 1.03] | -1.09 | 0.275\nsex [male]           |       1.93 | 0.87 | [0.81, 4.76] |  1.46 | 0.144\nlocation [northeast] |       0.80 | 0.35 | [0.33, 1.87] | -0.52 | 0.603\nlocation [northwest] |       0.52 | 0.22 | [0.22, 1.17] | -1.57 | 0.116\nlocation [west]      |       0.95 | 0.41 | [0.40, 2.21] | -0.13 | 0.900\nactivity             |       0.95 | 0.11 | [0.75, 1.19] | -0.47 | 0.638\ncrp                  |       0.78 | 0.09 | [0.63, 0.97] | -2.17 | 0.030\nbloodpressure        |       1.06 | 0.05 | [0.96, 1.17] |  1.22 | 0.223\nweight               |       1.00 | 0.11 | [0.81, 1.24] | -0.01 | 0.992\ncreatinin            |       0.82 | 0.10 | [0.65, 1.04] | -1.64 | 0.100\n\n$prefrail_frail\nParameter            | Odds Ratio |   SE |       95% CI |     z |     p\n-----------------------------------------------------------------------\nage                  |       0.94 | 0.03 | [0.88, 1.01] | -1.61 | 0.108\nsex [male]           |       1.29 | 0.69 | [0.46, 3.73] |  0.48 | 0.632\nlocation [northeast] |       0.96 | 0.46 | [0.37, 2.44] | -0.08 | 0.938\nlocation [northwest] |       0.81 | 0.38 | [0.32, 2.02] | -0.44 | 0.660\nlocation [west]      |       0.92 | 0.43 | [0.36, 2.30] | -0.17 | 0.866\nactivity             |       1.05 | 0.14 | [0.81, 1.37] |  0.39 | 0.695\ncrp                  |       0.87 | 0.10 | [0.69, 1.09] | -1.18 | 0.240\nbloodpressure        |       1.08 | 0.06 | [0.96, 1.21] |  1.34 | 0.182\nweight               |       0.95 | 0.12 | [0.74, 1.21] | -0.42 | 0.673\ncreatinin            |       0.79 | 0.10 | [0.61, 1.00] | -1.87 | 0.061"
  },
  {
    "objectID": "stat-modeling-poisson.html",
    "href": "stat-modeling-poisson.html",
    "title": "43  Poisson Regression",
    "section": "",
    "text": "Version vom November 07, 2022 um 09:19:50\nIn diesem Kapitel wollen wir eine Poisson Regression rechnen. Wir müssen uns hier wieder überlegen, was ist eigentlich unser Outcome \\(y\\) und was sind unsere Einflussvariablen \\(x\\). Die Poisson Regression ist je nach Hintergurnd des Anwenders eher selten. In der Ökologie, wo gerne mal gezaählt wird, wie oft etwas vorkommt, ist die Poisson Regression häufig vertreten. Sonst fristet die Poisson Regresson eher ein unbekanntes Dasein.\nEin häufig unterschätzter Vorteil der Poisson Regression ist, dass wir auch auch \\(0/1\\) Daten eine Poisson Regression rechnen können. Moment, wirst du jetzt vielleicht denken, das machen wir doch mit der logistsichen Regression. Ja, das stimmt, aber wir können auf Zahlen viel rechnen. Wenn wir auf ein \\(0/1\\) Outcome eine Poisson Regression rechnen, dann kriegen wir nicht Odds Ratios \\(OR\\) als Effektschätzer sondern Risk Ratios \\(RR\\). Wir erhalten also keine Chancen sondern Wahrscheinlichkeiten. Unter der Annahme, dass das Modell auch konvergiert und wir sinnvolle Zahlen erhalten.\nEin weiteres Problem sind die zu vielen Nullen in dem Outcome \\(y\\). Daherher wir zählen über die Maßen viel Nichts. Wir nennen diesen Fall zero inflation und beschreiben damit die zu vielen Nullen in den Daten. Hier muss dann noch speziell modelliert werden. Eine Poisson Regression hat schon so seine speziellen Tücken."
  },
  {
    "objectID": "stat-modeling-poisson.html#annahmen-an-die-daten",
    "href": "stat-modeling-poisson.html#annahmen-an-die-daten",
    "title": "43  Poisson Regression",
    "section": "\n43.1 Annahmen an die Daten",
    "text": "43.1 Annahmen an die Daten\nUnser gemessenes Outcome \\(y\\) folgt einer Poissonverteilung.\nIm folgenden Kapitel zu der multiplen Poisson linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDaher sieht unser Modell wie folgt aus. Wir haben ein \\(y\\) und \\(p\\)-mal \\(x\\). Wobei \\(p\\) für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser \\(y\\) einer Poissonverteilung. Das ist hier sehr wichtig, denn wir wollen ja eine multiple Poisson lineare Regression rechnen.\n\\[\ny \\sim x_1 + x_2 + ... + x_p\n\\]\nWir können in dem Modell auch Faktoren \\(f\\) haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in Kapitel 31 nochmal nachlesen."
  },
  {
    "objectID": "stat-modeling-poisson.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-poisson.html#genutzte-r-pakete-für-das-kapitel",
    "title": "43  Poisson Regression",
    "section": "\n43.2 Genutzte R Pakete für das Kapitel",
    "text": "43.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, MASS, pscl, see,\n               scales)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-poisson.html#daten",
    "href": "stat-modeling-poisson.html#daten",
    "title": "43  Poisson Regression",
    "section": "\n43.3 Daten",
    "text": "43.3 Daten\nIm folgenden schauen wir uns ein Datenbeispiel mit Hechten an. Es handelt sich um langnasige Hechte in nordamerikanischen Flüssen. Wir haben uns insgesamt \\(n = 68\\) Flüsse einmal angesehen und dort die Anzahl an Hechten gezählt. Im Weiteren haben wir dann noch andere Flussparameter erhoben und fragen uns nun, welche dieser Parameter einen Einfluss auf die Anzahl an Hechten in den Flussarmen haben. In Kapitel 10.2 findest du nochmal mehr Informationen zu den Daten. Wir entfernen hier die Informationen zu den Flüssen, die brauchen wir in dieser Analyse nicht.\n\n\nDie Daten zu den langnasigen Hechten stammt von Salvatore S. Mangiafico - An R Companion for the Handbook of Biological Statistics.\n\nlongnose_tbl <- read_csv2(\"data/longnose.csv\") %>% \n  select(-stream)\n\n\n\n\n\nTabelle 43.1— Auszug aus dem Daten zu den langnasigen Hechten.\n\nlongnose\narea\ndo2\nmaxdepth\nno3\nso4\ntemp\n\n\n\n13\n2528\n9.6\n80\n2.28\n16.75\n15.3\n\n\n12\n3333\n8.5\n83\n5.34\n7.74\n19.4\n\n\n54\n19611\n8.3\n96\n0.99\n10.92\n19.5\n\n\n19\n3570\n9.2\n56\n5.44\n16.53\n17\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n26\n1450\n7.9\n60\n2.96\n8.84\n18.6\n\n\n20\n4106\n10\n96\n2.62\n5.45\n15.4\n\n\n38\n10274\n9.3\n90\n5.45\n24.76\n15\n\n\n19\n510\n6.7\n82\n5.25\n14.19\n26.5\n\n\n\n\n\n\nIm Folgenden werden wir die Daten nur für das Fitten eines Modells verwenden. In den anderen oben genannten Kapiteln nutzen wir die Daten dann anders. In Abbildung 43.1 sehen wir nochmal die Verteilung der Anzahl der Hechte in den Flüssen.\n\nggplot(longnose_tbl, aes(longnose)) +\n  theme_bw() +\n  geom_histogram()\n\n\n\nAbbildung 43.1— Histogramm der Verteilung der Hechte in den beobachteten Flüssen."
  },
  {
    "objectID": "stat-modeling-poisson.html#fit-des-modells",
    "href": "stat-modeling-poisson.html#fit-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.4 Fit des Modells",
    "text": "43.4 Fit des Modells\nIn diesem Abschnitt wollen wir verschiedene Modelle für Zähldaten schätzen. Die Poissonverteilung hat keinen eignen Parameter für die Streung wie die Normalverteilung. Die Poissonverteilung ist mit \\(\\mathcal{Pois}(\\lambda)\\) definiert und hat somit die Eigenschaft das die Varianz eins zu eins mit dem Mittelwert \\(\\lambda\\) der Poissonverteilung ansteigt. Es kann aber sein, dass wir in den Daten nicht diesen ein zu eins Zusammenhang von Mittelwert und Varianz vrliegen haben. Häufig ist die Varianz viel größer und steigt schneller an. Wenn die Varianz in Wirklichkeit sehr viel größer ist, dann würden wir die Varianz in unseren Modell unterschätzen.\n\nEin klassisches Poissonmodell glm(..., familiy = poisson) mit der Annahme keiner Overdisperison.\nEin Quasi-Poissonmodell glm(..., family = quasipoisson) mit der Möglichkeit der Berücksichtigung einer Overdispersion.\nEin negative Binomialmodell glm.nb(...) ebenfalls mit der Berücksichtigung einer Overdispersion.\n\nBeginnen wollen wir aber mit einer klassischen Poissonregression ohne die Annahme von einer Overdispersion in den Daten. Wir nutzen dafür die Funktion glm() und spezifizieren die Verteilungsfamilie als poisson. Wir nehmen wieder alle Variablen in das Modell auf der rechten Seite des ~. Auf der linken Seite des ~ kommt dann unser Outcome longnose was die Anzahl an Hechten erhält.\nHier gibt es nur die Kurzfassung der link-Funktion. Dormann (2013) liefert hierzu in Kapitel 7.1.3 nochmal ein Einführung in das Thema.\nWir müssen für die Possionregression noch beachten, dass die Zähldaten von \\(0\\) bis \\(+\\infty\\) laufen. Damit wir normalverteilte Residuen erhalten und einen lineren Zusammenhang, werden wir das Modell auf dem \\(\\log\\)-scale fitten. Das heißt, wir werden den Zusammenhang von \\(y\\) und \\(x\\) logarithmieren. Wichtig ist hierbei der Zusammenhang. Wir transformieren nicht einfach \\(y\\) und lassen den Rest unberührt. Das führt dazu, dass wir am Ende die Koeffizienten der Poissonregression exponieren müssen. Das können die gängigen Funktionen, wir müssen das Exponieren aber aktiv durchführen. Deshalb hier schon mal erwähnt.\n\npoisson_fit <- glm(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                    longnose_tbl, family = poisson)\n\nWir schauen uns die Ausgabe des Modells einmal mit der summary() Funktion an, da wir hier einmal händisch schauen wollen, ob eine Overdispersion vorliegt. Sonst könnten wir auch die Funktion model_parameters() nehmen. Die nutzen wir später für die Interpretation des Modells, hier wollen wir erstmal sehen, ob alles geklappt hat.\n\npoisson_fit %>% summary\n\n\nCall:\nglm(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, family = poisson, data = longnose_tbl)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-9.2343  -4.0856  -1.6619   1.7709  14.3616  \n\nCoefficients:\n                 Estimate    Std. Error z value              Pr(>|z|)    \n(Intercept) -1.5643879535  0.2818029375 -5.5514         0.00000002835 ***\narea         0.0000384263  0.0000020794 18.4796 < 0.00000000000000022 ***\ndo2          0.2258789585  0.0212563866 10.6264 < 0.00000000000000022 ***\nmaxdepth     0.0115493150  0.0006687680 17.2695 < 0.00000000000000022 ***\nno3          0.1813114263  0.0106815488 16.9743 < 0.00000000000000022 ***\nso4         -0.0068097229  0.0036222591 -1.8800               0.06011 .  \ntemp         0.0785448817  0.0065300439 12.0282 < 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2766.88  on 67  degrees of freedom\nResidual deviance: 1590.04  on 61  degrees of freedom\nAIC: 1936.86\n\nNumber of Fisher Scoring iterations: 5\n\n\nWir schauen in die Summary-Ausgabe des Poissonmodells und sehen, dass dort steht, dass Dispersion parameter for poisson family taken to be 1. Wir modellieren also einen eins zu eins Zusammenhang von Mittelwert und Varianz. Wenn dieser Zusammenhang nicht in unseren Daten existiert, dann haben wir eine Overdispersion vorliegen.\nWir können die Overdispersion mit abschätzen indem wir die Residual deviance durch die Freiheitsgrade der Residual deviance teilen. Daher erhalten wir eine Overdispersion von \\(\\cfrac{1590.04}{61} \\approx 26.1\\). Damit haben wir eine eindeutige Overdispersion vorliegen. Damit steigt die Varianz in einem Verhältnis von ca. 1 zu 26. Wir können auch die Funktion check_overdispersion() aus dem R Paket performance nutzen um die Overdispersion zu berechnen. Die Funktion kann das schneller und ist auch in der Abfolge einer Analyse besser geeignet.\n\npoisson_fit %>% check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =   29.403\n  Pearson's Chi-Squared = 1793.599\n                p-value =  < 0.001\n\n\nOverdispersion detected.\n\n\nWenn wir Overdispersion vorliegen haben und damit die Varianz zu niedrig schätzen, dann erhalten wir viel mehr signifikante Ergebnisse als es in den Daten zu erwarten wäre. Schauen wir uns nochmal die Parameter der Poissonverteilung und die \\(p\\)-Werte einmal an.\n\npoisson_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |         95% CI |     z |      p\n--------------------------------------------------------------------\n(Intercept) |     -1.56 |     0.28 | [-2.12, -1.01] | -5.55 | < .001\narea        |  3.84e-05 | 2.08e-06 | [ 0.00,  0.00] | 18.48 | < .001\ndo2         |      0.23 |     0.02 | [ 0.18,  0.27] | 10.63 | < .001\nmaxdepth    |      0.01 | 6.69e-04 | [ 0.01,  0.01] | 17.27 | < .001\nno3         |      0.18 |     0.01 | [ 0.16,  0.20] | 16.97 | < .001\nso4         | -6.81e-03 | 3.62e-03 | [-0.01,  0.00] | -1.88 | 0.060 \ntemp        |      0.08 | 6.53e-03 | [ 0.07,  0.09] | 12.03 | < .001\n\n\nIn der Spalte p finden wir die \\(p\\)-Werte für alle Variablen. Wir sehen, dass fast alle Variablen signifikant sind und das wir eine sehr niedrige Varianz in der Spalte SE sehen. Das heißt unser geschätzer Fehler ist sehr gering. Das ahnten wir ja schon, immerhin haben wir eine Overdisperson vorliegen. Das Modell ist somit falsch. Wir müssen uns ein neues Modell suchen, was Overdispersion berückscihtigen und modellieren kann.\nDie Quasi-Poisson Verteilung hat einen zusätzlichen, unabhänigen Parameter um die Varianz der Verteilung zu schätzen. Daher können wir die Overdispersion mit einer Quasi-Poisson Verteilung berückscihtigen. Wir können eine Quasi-Poisson Verteilung auch mit der Funktion glm() schätzen nur müssen wir als Verteilungsfamilie quasipoisson angeben.\n\nquasipoisson_fit <- glm(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                        data = longnose_tbl, family = quasipoisson)\n\nNach dem Modellti können wir nochmal in der summary() Funktion schauen, ob wir die Overdispersion richtig berücksichtigt haben.\n\nquasipoisson_fit %>% summary\n\n\nCall:\nglm(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, family = quasipoisson, data = longnose_tbl)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-9.2343  -4.0856  -1.6619   1.7709  14.3616  \n\nCoefficients:\n                Estimate   Std. Error t value Pr(>|t|)   \n(Intercept) -1.564387953  1.528071553 -1.0238 0.309989   \narea         0.000038426  0.000011275  3.4080 0.001164 **\ndo2          0.225878959  0.115262389  1.9597 0.054605 . \nmaxdepth     0.011549315  0.003626383  3.1848 0.002282 **\nno3          0.181311426  0.057920513  3.1303 0.002679 **\nso4         -0.006809723  0.019641637 -0.3467 0.730011   \ntemp         0.078544882  0.035409050  2.2182 0.030273 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 29.403319)\n\n    Null deviance: 2766.88  on 67  degrees of freedom\nResidual deviance: 1590.04  on 61  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\n\nAn der Zeile Dispersion parameter for quasipoisson family taken to be 29.403319 in der Summary-Ausgabe sehen wir, dass das Modell der Quasi-Possion Verteilung die Overdispersion korrekt berücksichtigt hat. Wir können uns nun einmal die Modellparameter anschauen. Die Interpretation machen wir am Ende des Kapitels.\n\nquasipoisson_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |        95% CI | t(61) |      p\n-------------------------------------------------------------------\n(Intercept) |     -1.56 |     1.53 | [-4.57, 1.41] | -1.02 | 0.306 \narea        |  3.84e-05 | 1.13e-05 | [ 0.00, 0.00] |  3.41 | < .001\ndo2         |      0.23 |     0.12 | [ 0.00, 0.45] |  1.96 | 0.050 \nmaxdepth    |      0.01 | 3.63e-03 | [ 0.00, 0.02] |  3.18 | 0.001 \nno3         |      0.18 |     0.06 | [ 0.07, 0.29] |  3.13 | 0.002 \nso4         | -6.81e-03 |     0.02 | [-0.05, 0.03] | -0.35 | 0.729 \ntemp        |      0.08 |     0.04 | [ 0.01, 0.15] |  2.22 | 0.027 \n\n\nJetzt sieht unser Modell und die \\(p\\)-Werte zusammen mit dem Standardfehler SE schon sehr viel besser aus. Wir können also diesem Modell erstmal von der Seite der Overdispersion vertrauen.\nAm Ende wollen wir nochmal das Modell mit der negativen Binomialverteilung rechnen. Die negativen Binomialverteilung erlaubt auch eine Unabhängigkeit von dem Mittelwert zu der Varianz. Wir können hier auch für die Overdispersion adjustieren. Wir rechnen die negativen Binomialregression mit der Funktion glm.nb() aus dem R Paket MASS. Wir müssen keine Verteilungsfamilie angeben, die Funktion glm.nb() kann nur die negative Binomialverteilung modellieren.\n\nnegativebinomial_fit <- glm.nb(longnose ~ area + do2 + maxdepth + no3 + so4 + temp,\n                               data = longnose_tbl)\n\nAuch hier schauen wir mit der Funktion summary() einmal, ob die Overdisprsion richtig geschätzt wurde oder ob hier auch eine Unterschätzung des Zusammenhangs des Mittelwerts und der Varianz vorliegt.\n\nnegativebinomial_fit %>% summary()\n\n\nCall:\nglm.nb(formula = longnose ~ area + do2 + maxdepth + no3 + so4 + \n    temp, data = longnose_tbl, init.theta = 1.666933879, link = log)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.46010  -0.98759  -0.44256   0.48249   2.27756  \n\nCoefficients:\n                Estimate   Std. Error z value  Pr(>|z|)    \n(Intercept) -2.945664673  1.305427827 -2.2565 0.0240409 *  \narea         0.000046513  0.000013002  3.5774 0.0003470 ***\ndo2          0.341916152  0.105012333  3.2560 0.0011301 ** \nmaxdepth     0.009537603  0.003465417  2.7522 0.0059192 ** \nno3          0.207240064  0.056268918  3.6830 0.0002305 ***\nso4         -0.002157482  0.015165776 -0.1423 0.8868747    \ntemp         0.094595849  0.033149947  2.8536 0.0043230 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6669) family taken to be 1)\n\n    Null deviance: 127.6700  on 67  degrees of freedom\nResidual deviance:  73.6483  on 61  degrees of freedom\nAIC: 610.175\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.667 \n          Std. Err.:  0.289 \n\n 2 x log-likelihood:  -594.175 \n\n\nAuch hier sehen wir, dass die Overdispersion mit dem Parameter \\(\\theta\\) berücksichtigt wird. Wir können die Zahl \\(1.67\\) nicht direkt mit der Overdispersion aus einer Poissonregression verglechen, aber wir sehen dass das Verhältnis von Residual deviance zu den Freiheitsgraden mit \\(\\cfrac{73.65}{61} \\approx 1.20\\) fast bei 1:1 liegt. Wir könnten also auch eine negative Binomialverteilung für das Modellieren nutzen.\n\nnegativebinomial_fit %>% model_parameters()\n\nParameter   |  Log-Mean |       SE |         95% CI |     z |      p\n--------------------------------------------------------------------\n(Intercept) |     -2.95 |     1.31 | [-5.85, -0.10] | -2.26 | 0.024 \narea        |  4.65e-05 | 1.30e-05 | [ 0.00,  0.00] |  3.58 | < .001\ndo2         |      0.34 |     0.11 | [ 0.11,  0.58] |  3.26 | 0.001 \nmaxdepth    |  9.54e-03 | 3.47e-03 | [ 0.00,  0.02] |  2.75 | 0.006 \nno3         |      0.21 |     0.06 | [ 0.10,  0.32] |  3.68 | < .001\nso4         | -2.16e-03 |     0.02 | [-0.03,  0.03] | -0.14 | 0.887 \ntemp        |      0.09 |     0.03 | [ 0.03,  0.16] |  2.85 | 0.004 \n\n\n\n\nWie immer gibt es reichtlich Tipps & Tricks welches Modell du nun nehmen solltest. How to deal with overdispersion in Poisson regression: quasi-likelihood, negative binomial GLM, or subject-level random effect? und das Tutorial Modeling Count Data. Auch ich mus immer wieder schauen, was am besten konkret in der Anwendung passen könnte und würde.\nWelches Modell nun das beste Modell ist, ist schwer zu sagen. Wenn du Overdisperion vorliegen hast, dann ist natürlich nur das Quasi-Poissonmodell oder das negative Binomialmodell möglich. Welche der beiden dann das bessere ist, hängt wieder von der Fragestellung ab. Allgemein gesprochen ist das Quasi-Poissonmodell besser wenn dich die Zusammenhänge von \\(y\\) zu \\(x\\) am meisten interessieren. Und das ist in unserem Fall hier die Sachlage. Daher gehen wir mit den Quasi-Poissonmdell dann weiter."
  },
  {
    "objectID": "stat-modeling-poisson.html#performance-des-modells",
    "href": "stat-modeling-poisson.html#performance-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.5 Performance des Modells",
    "text": "43.5 Performance des Modells\nIn diesem kurzen Abschnitt wollen wir uns einmal anschauen, ob das Modell neben der Overdispersion auch sonst aus statistischer Sicht in Ordnung ist. Wir wollen ja mit dem Modell aus dem Fit quasipoisson_fit weitermachen. Also schauen wir uns einmal das pseudo-\\(R^2\\) für die Poissonregression an. Da wir es mit einem GLM zu tun haben, ist das \\(R^2\\) mit vorsicht zu genießen. In einer Gaussianregression können wir das \\(R^2\\) als Anteil der erklärten Varianz durch das Modell interpretieren. Im Falle von GLM’s müssen wir hier vorsichtiger sein. In GLM’s gibt es ja keine Varianz sondern eine Deviance.\n\nr2_efron(quasipoisson_fit)\n\n[1] 0.3257711\n\n\nMit einem pseudo-\\(R^2\\) von \\(0.33\\) erklären wir ca. 33% der Varianz in der Anzahl der Hechte. Das ist zwar keine super gute Zahl, aber dafür, dass wir nur eine handvoll von Parametern erfasst haben, ist es dann auch wieder nicht so schlecht. Die Anzahl an Hechten wird sicherlich an ganz vielen Parametern hängen, wir konnten immerhin einige wichtige Stellschrauben vermutlich finden.\nIn Abbildung 43.2 schauen wir uns nochmal die Daten in den Modelgüteplots an. Wir sehen vorallem, dass wir vielelicht doch einen Ausreißer mit der Beobachtung 17 vorliegen haben. Auch ist der Fit nicht so super, wie wir an dem QQ-Plot sehen. Die Beobachtungen fallen in dem QQ-Plot nicht alle auf eine Linie. Auch sehen wir dieses Muster in dem Residualplot. Hiererwarten wir eine gerade blaue Linie und auch hier haben wir eventuell Ausreißer mit in den Daten.\n\ncheck_model(quasipoisson_fit, colors = cbbPalette[6:8], \n            check = c(\"qq\", \"outliers\", \"pp_check\", \"homogeneity\")) \n\n\n\nAbbildung 43.2— Ausgabe ausgewählter Modelgüteplots der Funktion check_model()."
  },
  {
    "objectID": "stat-modeling-poisson.html#interpretation-des-modells",
    "href": "stat-modeling-poisson.html#interpretation-des-modells",
    "title": "43  Poisson Regression",
    "section": "\n43.6 Interpretation des Modells",
    "text": "43.6 Interpretation des Modells\nUm die Effektschätzer einer Poissonregression oder aber einer Quasipoisson-Regression interpretieren zu können müssen wir uns einmal einen Beispieldatensatz mit bekannten Effekten zwischen den Gruppen bauen. Im Folgenden bauen wir uns einen Datensatz mit zwei Gruppen. Einmal einer Kontrollgruppe mit einer mittleren Anzahl an \\(15\\) und einer Behandlungsgruppe mit einer um \\(\\beta_1 = 10\\) höheren Anzahl. Wir haben also in der Kontrolle im Mittel eine Anzahl von \\(15\\) und in der Behandlungsgruppe eine mittlere Anzahl von \\(25\\).\n\nsample_size <- 10000\nlongnose_small_tbl <- tibble(grp = rep(c(0, 1), each = sample_size),\n                             count = 15 + 10 * grp + rnorm(2 * sample_size, 0, 1)) %>%\n  mutate(count = round(count),\n         grp = factor(grp, labels = c(\"ctrl\", \"trt\")))\n\nIn Tabelle 43.2 sehen wir nochmal die Daten als Ausschnitt dargestellt.\n\n\n\n\nTabelle 43.2— How much is the fish? Der Datensatz über \\(n = 1000\\) Beobachtungen an dem wir überlegen wollen wie wir die Effektschätzer einer Poissonregression zu interpretieren haben.\n\ngrp\ncount\n\n\n\nctrl\n14\n\n\nctrl\n16\n\n\nctrl\n14\n\n\nctrl\n14\n\n\n…\n…\n\n\ntrt\n26\n\n\ntrt\n23\n\n\ntrt\n24\n\n\ntrt\n26\n\n\n\n\n\n\nDa sich die Tabelle schlecht liest hier nochmal der Boxplot in Abbildung 43.3. Wir sehen den Grupenunterschied von \\(10\\) sowie die unterschiedlichen mittleren Anzahlen für die Kontrolle und die Behandlung.\n\nggplot(longnose_small_tbl, aes(x = grp, y = count, fill = grp)) +\n  theme_bw() +\n  geom_boxplot() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() \n\n\n\nAbbildung 43.3— How much is the fish? Der Boxplot über \\(n = 1000\\) Beobachtungen an dem wir überlegen wollen wie wir die Effektschätzer einer Poissonregression zu interpretieren haben.\n\n\n\n\nJetzt fitten wir einmal das simple Poissonmodell mit der Anzahl als Outcome und der Gruppe mit den zwei Leveln als \\(x\\). Wir pipen dann das Ergebnis des Fittes gleich in die Funktion model_parameters() weiter um die Ergebnisse des Modellierens zu erhalten.\n\nglm(count ~ grp, data = longnose_small_tbl, family = poisson) %>%\n  model_parameters(exponentiate = TRUE)\n\nParameter   |   IRR |       SE |         95% CI |       z |      p\n------------------------------------------------------------------\n(Intercept) | 15.00 |     0.04 | [14.93, 15.08] | 1049.11 | < .001\ngrp [trt]   |  1.66 | 5.44e-03 | [ 1.65,  1.68] |  156.07 | < .001\n\n\nAls erstes fällt auf, dass wir die Ausgabe des Modells exponieren müssen. Um einen linearen Zusamenhang hinzukriegen bedient sich die Poissonregression den Trick, das der Zusammenhang zwischen dem \\(y\\) und dem \\(x\\) transformiert wird. Wir rechnen unsere Regression nicht auf den echten Daten sondern auf dem \\(\\log\\)-scale. Daher müssen wir die Koeffizienten der Poissonregression wieder zurücktransfomieren, wenn wir die Koeffizienten interpretieren wollen. Das können wir mit der Option exponentiate = TRUE durchführen.\nGut soweit, aber was heißen den jetzt die Zahlen? Wir haben einen Intercept von \\(14.99\\) das entspricht der mittleren Anzahl in der Kontrollgruppe. Und was sagt jetzt die \\(1.67\\) vom Level trt des Faktors grp? Wenn wir \\(14.99 \\cdot 1.67\\) rechnen, dann erhalten wir als Ergebnis \\(25.03\\), also die mittlere Anzahl in der Behandlungsgruppe. Was sagt uns das jetzt aus? Wir erhalten aus der Poissonregression eine Wahrscheinlichkeit oder aber ein Risk Ratio. Wir können sagen, dass die Anzahl in der Behandlungsgruppe \\(1.67\\)-mal so groß ist wie in der Kontrollgruppe.\nSchauen wir uns nochmal das volle Modell an und interpretieren die Effekte der einzelnen Variablen.\n\nquasipoisson_fit %>% \n  model_parameters(exponentiate = TRUE) \n\nParameter   |  IRR |       SE |       95% CI | t(61) |      p\n-------------------------------------------------------------\n(Intercept) | 0.21 |     0.32 | [0.01, 4.11] | -1.02 | 0.306 \narea        | 1.00 | 1.13e-05 | [1.00, 1.00] |  3.41 | < .001\ndo2         | 1.25 |     0.14 | [1.00, 1.57] |  1.96 | 0.050 \nmaxdepth    | 1.01 | 3.67e-03 | [1.00, 1.02] |  3.18 | 0.001 \nno3         | 1.20 |     0.07 | [1.07, 1.34] |  3.13 | 0.002 \nso4         | 0.99 |     0.02 | [0.95, 1.03] | -0.35 | 0.729 \ntemp        | 1.08 |     0.04 | [1.01, 1.16] |  2.22 | 0.027 \n\n\nSo schön auch die Funktion model_parameters() ist, so haben wir aber hier das Problem, dass wir den Effekt von area nicht mehr richtig sehen. Wir kriegen hier eine zu starke Rundung auf zwei Nachkommastellen. Wir nutzen jetzt mal die Funktion tidy() um hier Abhilfe zu leisten. Ich muss hier noch die Spalte estimate mit num(..., digits = 5) anpassen, damit du in der Ausgabe auf der Webseite auch die Nachkommastellen siehst.\n\nquasipoisson_fit %>% \n  tidy(exponentiate = TRUE, digits = 5) %>% \n  select(term, estimate, p.value) %>% \n  mutate(p.value = pvalue(p.value),\n         estimate = num(estimate, digits = 5))\n\n# A tibble: 7 × 3\n  term         estimate p.value\n  <chr>       <num:.5!> <chr>  \n1 (Intercept)   0.20922 0.310  \n2 area          1.00004 0.001  \n3 do2           1.25342 0.055  \n4 maxdepth      1.01162 0.002  \n5 no3           1.19879 0.003  \n6 so4           0.99321 0.730  \n7 temp          1.08171 0.030  \n\n\nSchauen wir uns die Effekte der Poissonregression einmal an und versuchen die Ergebnisse zu interpretieren. Dabei ist wichtig sich zu erinnern, dass kein Effekt eine 1 bedeutet. Wir schauen hier auf einen Faktor. Wenn wir eine Anzahl mal Faktor 1 nehmen, dann ändert sich nichts an der Anzahl.\n\n\n(Intercept) beschreibt den Intercept der Poissonregression. Wenn wir mehr als eine simple Regression vorliegen haben, wie in diesem Fall, dann ist der Intercept schwer zu interpretieren. Wir konzentrieren uns auf die Effekte der anderen Variablen.\n\narea, beschreibt den Effekt der Fläche. Steigt die Fläche um ein Quadratmeter an, so erhöht sich die Anzahl an Fischen um den \\(1.00001\\). Daher würde man hier eher sagen, erhöht sich die Fläche um jeweils 1000qm so erhöht sich die Anzahl an Fischen um den Faktor \\(1.1\\). Dann haben wir auch einen besser zu interpretierenden Effektschätzer. Die Signifikanz bleibt hier davon unbetroffen.\n\ndo2, beschreibt den Partzialdruck des Sauerstoffs. Steigt dieser um eine Einheit an, so sehen wie eine Erhöhung der Anzahl an Fischen um den Faktor \\(1.25\\). Der Effekt ist gerade nicht signifikant.\n\nmaxdepth, beschreibt die maximale Tiefe. Je tiefer ein Fluß, desto mehr Hechte werden wir beobachten. Der Effekt von \\(1.01\\) pro Meter Tiefe ist signifikant.\n\nno3, beschreibt den Anteil an Nitrat in den Flüssen. Je mehr Nitrat desto signifiant mehr Hechte werden wir beobachten. Hier steigt der Faktor auch um \\(1.20\\).\n\nso4, beschreibt den Schwefelgehalt und mit steigenden Schwefelgehalt nimmt die Anzahl an Fischen leicht ab. Der Effekt ist aber überhauot nicht signifikant.\n\ntemp, beschreibt die Temperatur der Flüsse. Mit steigender Tempertaur erwarten wir mehr Hechte zu beobachten. Der Effekt von \\(1.08\\) Fischen pro Grad Erhöhung ist signifikant.\n\nWas nehmen wir aus der Poissonregression zu den langnasigen Hechten mit? Zum einen haben die Fläche, die Tiefe und der Nitratgehalt einen signifikanten Einfluss auf die Anzahl an Hechten. Auch führt eine höhere Temperatur zu mehr gefundenen Hechten. Die erhöhte Temperatur steht etwas im Widerspuch zu dem Sauerstoffpartizaldruck. Denn je höher die Temperatur desto weniger Sauerstoff wird in dem Wasser gelöst sein. Auch scheint die Oberfläche mit der Tiefe korreliert. Allgemein scheinen Hechte große Flüße zu mögen. Hier bietet sich also noch eine Variablenselektion oder eine Untersuchung auf Ausreißer an um solche Effekte nochmal gesondert zu betrachten."
  },
  {
    "objectID": "stat-modeling-poisson.html#zeroinflation",
    "href": "stat-modeling-poisson.html#zeroinflation",
    "title": "43  Poisson Regression",
    "section": "\n43.7 Zeroinflation",
    "text": "43.7 Zeroinflation"
  },
  {
    "objectID": "stat-modeling-poisson.html#referenzen",
    "href": "stat-modeling-poisson.html#referenzen",
    "title": "43  Poisson Regression",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer."
  },
  {
    "objectID": "stat-modeling-mixed.html",
    "href": "stat-modeling-mixed.html",
    "title": "44  Lineare gemischte Modelle",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:48:52"
  },
  {
    "objectID": "stat-modeling-mixed.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-mixed.html#genutzte-r-pakete-für-das-kapitel",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.2 Genutzte R Pakete für das Kapitel",
    "text": "44.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom, see,\n               multcomp, emmeans, lme4, broom.mixed,\n               parameters, ggridges, scales, performance)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-mixed.html#daten",
    "href": "stat-modeling-mixed.html#daten",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.3 Daten",
    "text": "44.3 Daten\nIn diesem fiktiven Datenbeispiel wollen wir uns die Testscores eines Intelligentest bei \\(N = 480\\) Drachen anschauen. Wir sind dafür an acht Berge gefahren und haben die dortigen Drachen an den drei Flanken des Berges getestet. Daher hat der Faktor mountain_range acht Level mit Bavarian, Ligurian, Emmental, Central, Maritime, Southern, Julian, und Sarntal. Die drei Flanken des Berges bilden wir im Faktor site mit den Leveln north, east und south ab. In Abbildung 44.1 sehen wir eine Skizze für drei Berge mit den jeweiligen Flanken, wo gemessen wurde.\n\n\nAbbildung 44.1— Beispiel für drei der acht Berge mit Bavarian, Central und Julian. Auf jeden der acht Berge wurden an drei Seiten north, east und south die Testscores der dort lebenden Drachen erhoben.\n\n\nDie Daten liegen in dem Datensatz dragons.csv ab. Wir müssen aber noch einen Faktor body_length_cat bilden in dem wir die body_length der einzelnen Drachen in Kategorien umwandeln. Wir wollen später noch Gruppenvergleiche rechnen und brauchen daher einen Faktor mit Leveln. Daher nutzen wir die Funktion case_when() um einen Faktor mit fünf Größenkategorien zu bilden. Danach müssen wir wie immer noch die character Spalten in die entsprechenden Faktoren umwandeln.\n\ndragons_tbl <- read.csv2(\"data/dragons.csv\") %>% \n  mutate(body_length_cat = \n           case_when(body_length < 170 ~ \"tiny\",\n                     body_length >= 170 & body_length < 180 ~ \"small\",\n                     body_length >= 180 & body_length < 200 ~ \"medium\",\n                     body_length >= 200 & body_length < 220 ~ \"large\",\n                     body_length >= 220 ~ \"gigantic\"),\n         body_length_cat = as_factor(body_length_cat),\n         mountain_range = as_factor(mountain_range),\n         site = factor(site, labels = c(\"north\", \"east\", \"south\"))) %>% \n  select(test_score, body_length, body_length_cat, everything())\n\nEs ergibt sich dann der Datensatz wie in Tabelle 44.1 gezeigt. Wir belassen die Körperlänge der Drachen in der kontinuierlichen Form nochmal mit in den Daten.\n\n\n\n\nTabelle 44.1— Datensatz der Testscores für die Drachen auf verschiedenen Bergen und dort an verschiedenen Flanken der Berge.\n\n\n\n\n\n\n\n\n\n\ntest_score\nbody_length\nbody_length_cat\nmountain_range\nsite\n\n\n\n1\n16.15\n165.55\ntiny\nBavarian\nnorth\n\n\n2\n33.89\n167.56\ntiny\nBavarian\nnorth\n\n\n3\n6.04\n165.88\ntiny\nBavarian\nnorth\n\n\n4\n18.84\n167.69\ntiny\nBavarian\nnorth\n\n\n5\n…\n…\n…\n…\n…\n\n\n477\n59.37\n213.58\nlarge\nSarntal\nsouth\n\n\n478\n68.75\n207.63\nlarge\nSarntal\nsouth\n\n\n479\n74.89\n198.25\nmedium\nSarntal\nsouth\n\n\n480\n65.95\n208.06\nlarge\nSarntal\nsouth\n\n\n\n\n\n\nBevor wir mit dem Modellieren beginnen, wollen wir erstmal visuell überprüfen, ob unser Outcome \\(y\\) mit dem Testscore auch normalverteilt ist. Wir benötigen für das klaissche lineare gemischte Modell ein normalverteiltes Outcome \\(y\\). In Abbildung 44.2 sehen wir das Histogramm der Verteilung des Testscores für alle \\(N = 480\\) Drachen.\n\nggplot(dragons_tbl, aes(test_score)) +\n  geom_histogram() +\n  theme_bw() \n\n\n\nAbbildung 44.2— Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.\n\n\n\n\nWir können in der Abbildung 44.3 auch nochmal schauen, ob die Annahme der annährenden Normalverteilung für unseren Testscore auch für jedes Level unseres Faktors der Körperlängen gegeben ist. Wir sehen auch hier, dass der Testscore einer Normalverteilung über alle Kategorien der Körperlänge folgt.\n\nggplot(dragons_tbl, aes(y = body_length_cat, x = test_score, fill = body_length_cat)) +\n  theme_bw() +\n  stat_density_ridges() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() \n\n\n\nAbbildung 44.3— Histogramm des Testscores aufgeteilt nach Kategorie der Körpergröße zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores für alle Kategorien der Körpergröße.\n\n\n\n\nNatürlich können wir uns hier noch weitere Abbildungen erstellen, aber hier soll es erstmal reichen. Wir sehen, dass der Testscore einer Normalverteilung folgt und dass die Varianzen vermutlich homogen sind, da die Histogramme ungefähr gleich breit sind. Ja, ein wenig unterscheiden sich die Verteilungen, aber so gravierend ist es erstmal nicht."
  },
  {
    "objectID": "stat-modeling-mixed.html#modellierung",
    "href": "stat-modeling-mixed.html#modellierung",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.4 Modellierung",
    "text": "44.4 Modellierung\nIm Folgenden wollen wir uns verschiedene statistische Modelle anschauen um uns dem linearen gemischten Modell einmal anzunähern. Dabei beginnen wir mit einem simplen Gaussian lineare Modell mit einem Faktor \\(f_1\\):\n\\[\ny \\sim f_1\n\\]\nWir haben also nur einen Faktor in unserem Modell vorliegen und ignorieren die restlichen in den Daten vorhandenen Variablen.\nAls zweites Modell betrachten wir eine multiples Gaussian lineares Modell mit einem Faktor \\(f_1\\) und einem Blockfaktor \\(b_1\\):\n\\[\ny \\sim f_1 + b_1\n\\]\nJetzt erweitern wir das Modell nochmal um einen Block oder auch Clustereffekt. Das heißt, wir haben alle Beobachtungen nicht auf einem Feld oder in einem Stall durchgeführt, sondern an mehreren Orten.\nDer eigentliche Bruch kommt jetzt. Wie wollen wir den Effekt des Blocks betrachten? Hier entscheidet sich, ob wir den Block als festen Effekt (eng. fixed effect) oder als zufälligen Effekt (eng. random effect) ausweisen wollen. Zuerst ist dies eine Modellierungsentscheidung. Wir müssen uns also zwischen zwei Modellen entscheiden. Daher können wir auch beide Arten bauen und dann Modelle vergleichen. Machen wir dann auch am Ende des Kapitels.\n\n\nDie Idee hinter dem Modell mit festen Effekten ist, dass die beobachteten Effektgrößen von Block zu Block variieren können, was aber nur auf den Stichprobenfehler \\(\\epsilon\\) zurückzuführen ist. In Wirklichkeit sind die wahren Effektgrößen alle gleich: Sie sind fix. (siehe auch The Fixed-Effect Model)\n\nDas Modell der zufälligen Effekte geht davon aus, dass es nicht nur eine wahre Effektgröße gibt, sondern eine Verteilung der wahren Effektgrößen. Das Ziel des Modells mit zufälligen Effekten ist es daher nicht, die eine wahre Effektgröße aller Studien zu schätzen, sondern den Mittelwert der Verteilung der wahren Effekte. (siehe auch The Random-Effect Model)\n\nLineare gemischte Modelle schätzen die subjektspezifischen Auswirkungen (eng. subject-specific). Betrachten wir dabei die folgenden zwei Szenarien nach Allison (2009):\n\n\nSzenario 1: Du bist ein Arzt. Du möchtest wissen, um wie viel ein Cholesterinmedikament die Wahrscheinlichkeit eines Herzinfarkts bei deinem Patienten senkt.\n\nSzenario 2: Du bist ein staatlicher Gesundheitsbeamter. Du möchtest wissen, wie sich die Zahl der Menschen, die an einem Herzinfarkt sterben, verändern würde, wenn alle Menschen in der Risikogruppe das Cholesterinmedikament einnehmen würden.\n\nIm ersten Szenario wollen wir die subjektspezifischen (eng. subject-specific) Chancen wissen. Im zweiten Fall sind wir an der Vorhersage für die gesamte Bevölkerung interessiert. Lineare gemischte Modelle können uns Schätzungen für das erste, aber nicht für das zweite Szenario liefern.\nDaher kommt jetzt als drittes Model ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor \\(f_1\\) und einem zufälligen Blockfaktor \\(z_1\\):\n\\[\ny \\sim f_1 + 1|z_1\n\\]\nWir schreiben in R den Term für da zufällige Modell in der Form \\(z_0|z_1\\). Meist setzen wir den Intercept \\(z_0\\) für den zufälligen Effekt auf 1.\nAbschießend schauen wir uns noch ein multiples Gaussian lineares gemischtes Modell mit einem festen Faktor \\(f_1\\) und einem zufälligen Blockfaktor \\(z_2\\) genested in einem einem zufälligen Blockfaktor \\(z_1\\):\n\\[\ny \\sim f_1 + 1|z_1/z_2\n\\]\nWir sagen nested, wenn wir meinen, dass ein Faktor in einen anderen Faktor verschränkt ist. Die Klassen einer Schule sind in der Schule genested.\nDas heißt, dass der zufällige Blockfaktor \\(z_2\\) in den zufälligen Blockfaktor \\(z_1\\) genested ist. Das heist, die Faktorlevel des Blockfaktors \\(z_2\\) finden sich jeweils nur in jeweils einem der Faktorlevel des Blocks \\(z_1\\). Das klingt jetzt etwas schräg, also einmal ein Beispiel. Wir haben eine Schule, dann sind die Schulklassen dieser Schule in der Schule genested. Es gibt diese spezifischen Klassen mit den Schülern schlichtweg nicht in anderen Schulen.\nBevor wir jetzt mit dem Modellieren beginnen, müssen wir noch kurz in einem QQ-Plot schauen, ob unser Ourcome testscore auch ungefähr normalverteilt ist. Abbildung 44.4 zeigt den QQ-Plot des Testscores. Wir sehen, dass der Hauptteil der Beobachtungen auf der Geraden liegt und wir nehmen daher an, dass der Testscore zumindest approximativ normalverteilt ist. Wir können also mit einem gaussian linearen gemischten Modell weitermachen.\n\nggplot(dragons_tbl, aes(sample = test_score)) +\n  stat_qq() + stat_qq_line(color = \"red\") +\n  theme_bw() +\n  scale_color_okabeito()\n\n\n\nAbbildung 44.4— QQ-Plot zu Überprüfung, ob der Testscore einer Normalverteilung folgt. Die Punkte liegen ungefähr auf der Geraden als Winkelhalbierende, so dass wi eine Normalverteilung des Testscores annehmen können.\n\n\n\n\nSchauen wir uns nun als erstes das Modell lm_simple_fit einmal an. Wir bauen das Modell nur mit der Faktorvariable body_length_cat. Wir erhalten dann gleich die Ausgabe des Modells über die Funktion model_parameters() in einer aufgearbeiteten Form.\n\nlm_simple_fit <- lm(test_score ~ body_length_cat, data = dragons_tbl)\n\nlm_simple_fit %>% model_parameters()\n\nParameter                  | Coefficient |   SE |         95% CI | t(475) |      p\n----------------------------------------------------------------------------------\n(Intercept)                |       24.61 | 4.33 | [16.10, 33.12] |   5.68 | < .001\nbody length cat [small]    |        2.63 | 5.39 | [-7.96, 13.21] |   0.49 | 0.626 \nbody length cat [medium]   |       24.89 | 4.68 | [15.70, 34.07] |   5.32 | < .001\nbody length cat [large]    |       32.50 | 4.55 | [23.56, 41.43] |   7.15 | < .001\nbody length cat [gigantic] |       29.32 | 5.20 | [19.10, 39.54] |   5.64 | < .001\n\n\nDer Intercept beinhaltet den Mittelwert für die Drachen des Levels [tiny]. Die jeweiligen Koeffizienten dann die Abweichung von den Drachen des Levels [tiny]. Daher sind Drachen des Levels [small] ungefähr um \\(2.63\\) Einheiten intelligenter. Wir sehen dann an dem \\(p\\)-Wert, ob sich die Koeffizienten signifikant von 0 unterscheiden. In Abbildung 44.5 sehen wir nochmal die Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße. Wir erkennen, dass die kleineren Drachen tendenziell dümmer sind als die großen Drachen. Wir sehen zwei Plateaus.\n\nggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = body_length_cat)) +\n  theme_bw() +\n  geom_boxplot() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() \n\n\n\nAbbildung 44.5— Boxplots der einzelnen Testscores aufgeteilt nach der Körpergröße.\n\n\n\n\nNun haben wir aber nicht nur die Körpergrößen gemessen sondern auch auf welchem Berg wir die jeweiligen Drachen gefunden haben. Nun könnte es sein, dass der Berg einen viel größeren Einfluss auf die Inteliegenz hat als die Drachenkörpergröße. Wir könnten einen Confoundereffekt durch die Berge vorliegen haben. Ergänzen wir also das Modell um den Faktor mountain_range und erhalten das Modell lm_mountain_fit.\n\nlm_mountain_fit <- lm(test_score ~ body_length_cat + mountain_range, data = dragons_tbl)\nlm_mountain_fit %>% model_parameters()\n\nParameter                  | Coefficient |   SE |         95% CI | t(468) |      p\n----------------------------------------------------------------------------------\n(Intercept)                |       20.93 | 3.34 | [14.36, 27.49] |   6.27 | < .001\nbody length cat [small]    |        1.67 | 3.89 | [-5.98,  9.32] |   0.43 | 0.668 \nbody length cat [medium]   |        3.55 | 3.72 | [-3.76, 10.85] |   0.95 | 0.341 \nbody length cat [large]    |        3.59 | 4.30 | [-4.86, 12.03] |   0.83 | 0.405 \nbody length cat [gigantic] |        0.08 | 4.85 | [-9.45,  9.60] |   0.02 | 0.988 \nmountain range [Ligurian]  |       17.33 | 3.58 | [10.28, 24.37] |   4.83 | < .001\nmountain range [Emmental]  |       15.91 | 3.63 | [ 8.79, 23.04] |   4.39 | < .001\nmountain range [Central]   |       35.62 | 3.69 | [28.36, 42.88] |   9.64 | < .001\nmountain range [Maritime]  |       48.75 | 3.24 | [42.39, 55.11] |  15.06 | < .001\nmountain range [Southern]  |        8.47 | 2.74 | [ 3.08, 13.85] |   3.09 | 0.002 \nmountain range [Julian]    |       45.74 | 3.86 | [38.15, 53.33] |  11.85 | < .001\nmountain range [Sarntal]   |       41.03 | 3.30 | [34.54, 47.53] |  12.42 | < .001\n\n\nWie wir sehen, werden nun die Körpergrößen der Drachen nicht mehr als signifikant ausgegeben. Die Effekte der Körpergröße auf den Testscore sind auch viel kleiner geworden, wenn wir die mountain_range mit in das Modell nehmen. Anscheinend hat der Berg auf dem wir den Drachen getroffen haben einen viel größeren Einfluss auf die Intelligenz als die Körpergröße. Wir können uns den Zusammenhang zwischen dem Testscore und dem Berg auch in der Abbildung 44.6 einmal anschauen.\nEigentlich würden wir erwarten, dass es keinen Effekt der Berge auf den Testscore der Drachen gibt. Es müsste eigentlich egal sein, wo wir einen Drachen befragen, wenn wir nur an der Körpergröße und dem Testscore interessiert sind. Wir sehen jedoch in der Abbildung 44.6 einen klaren Unterschied zwischen den Bergen im Bezug auf den Testscore.\n\nggplot(dragons_tbl, aes(mountain_range, test_score, fill = mountain_range)) +\n  geom_boxplot() +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito()\n\n\n\nAbbildung 44.6— Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung.\n\n\n\n\nIn der Abbildung 44.7 sehen wir den Zusammenhang von Testscore und der Körpergröße sowie den Bergen auf denen das Interview stattgefunden hat. so langsam dämmert uns warum wir hier einen Effekt der Körperlänge zu dem Testscore sehen. Die kleineren Drache sind alle nur auf bestimmten Bergen zu finden! Betrachten wir die Berge mit in dem Modell, dann hat die Körpergröße keinen Einfluß mehr.\n\nggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +\n  geom_boxplot(position = position_dodge(preserve = \"single\")) +\n  theme_bw() +\n  scale_fill_okabeito() +\n  labs(fill = \"Mountain\")\n\n\n\nAbbildung 44.7— Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße.\n\n\n\n\nDer Zusammenhang wird vielleicht in Abbildung 44.8 nochmal klarer. Hier schauen wir uns den Zusamenhang wieder für die Körperlänge getrennt für die Berge an. Nur zeichnen wir jetzt jeden einzelnen Berg in ein Subplot. Wir sehen, dass es hier fast keinen Unterschied macht, wie lang die Drachen sind. Der Testscore ist immer gleich. Was einen Unterschied macht, sind die Berge.\n\nggplot(dragons_tbl, aes(x = body_length_cat, y = test_score, fill = mountain_range)) +\n  geom_boxplot(position = position_dodge(preserve = \"single\")) +\n  theme_bw() +\n  scale_fill_okabeito() +\n  labs(fill = \"Mountain\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ mountain_range) \n\n\n\nAbbildung 44.8— Boxplots der einzelnen Testscores aufgeteilt nach dem Berg der Befragung und der Körpergröße in getrennten Subplots.\n\n\n\n\nSchauen wir uns nun einmal ein lineares gemischtes Modell an. Wir nutzen daszu das R Paket lme4. Wir haben auch noch andere Pakete zur Aswahl, aber wir nutzen hier erstmal das gängiste Paket. Um ein lineares gemischtes Modell in R zu schätzen nutzen wir die Funktion lmer(). Die Funktion lmer() nimmt an, dass das Outcome test_score normalverteilt ist. Wir haben diese Annahme ja weiter oben in dem QQ-Plot überprüft.\nIn einem lineare gemischten Modell müssen wir die festen Effekte sowie die zufälligen Effekte definieren. Die festen Effekte werden ganz normal wie wir es gewohnt sind in das Modell eingegeben. Die zufälligen Effkete schreiben wir in eine Klammer in der Form (1|).\nWir schreiben (1|moutain_range) und definieren damit die Variable mountain_range als zufälligen Effekt im Modell. Wir schreiben 1| vor mountain_range, da wir für jeden Berg die gleiche Steigung von Körperlänge und Testscore annehmen. Wir können dann später noch das Model komplizierter aufbauen und jedem Berg eine eigene Steigung erlauben. Bauen wir uns jetzt erstmal ein lineares gemischtes Modell mit einem festen Effekt body_length_cat und einem zufälligen Effekt (1|mountain_range).\n\nlmer_1_fit <- lmer(test_score ~ body_length_cat + (1 | mountain_range), data = dragons_tbl)\nlmer_1_fit %>% model_parameters()\n\n# Fixed Effects\n\nParameter                  | Coefficient |   SE |         95% CI | t(473) |      p\n----------------------------------------------------------------------------------\n(Intercept)                |       46.85 | 7.43 | [32.25, 61.45] |   6.30 | < .001\nbody length cat [small]    |        1.68 | 3.89 | [-5.97,  9.33] |   0.43 | 0.666 \nbody length cat [medium]   |        4.08 | 3.71 | [-3.20, 11.37] |   1.10 | 0.271 \nbody length cat [large]    |        4.49 | 4.27 | [-3.90, 12.88] |   1.05 | 0.293 \nbody length cat [gigantic] |        1.03 | 4.81 | [-8.43, 10.49] |   0.21 | 0.831 \n\n# Random Effects\n\nParameter                      | Coefficient\n--------------------------------------------\nSD (Intercept: mountain_range) |       18.21\nSD (Residual)                  |       14.96\n\n\nUnser Model sieht etwas aufgeräumter aus. Als feste Effekte haben wir nur noch die Körperlänge body_length_cat und die dazugehörigen Koeffizienten des Modells. Unsere Variable mountain_range verschwindet dann in den zufälligen Effekten. Die Funktion summary liefert uns den gesamten Ausdruck, der etwas überwältigend ist. Vieles brauchen wir auch nicht davon.\n\nlmer_1_fit %>% summary()\n\n\n\n\n\nWas wir extrahieren wollen ist die Information von den zufälligen Effekten. Wir wollen wissen, wieviel Varianz durch die zufälligen Effekte erklärt wird. Wir nutzen dazu die Funktion VarCorr(), die uns erlaubt die Information zu en zufälligen Effekten zu extrahieren und auszugeben.\n\nprint(VarCorr(lmer_1_fit), comp = \"Variance\")\n\n Groups         Name        Variance\n mountain_range (Intercept) 331.42  \n Residual                   223.83  \n\n\nWieviel Varianz erklären nun die Berge? Wir können die erklärte Varianz der zufälligen Effekte einfach berechnen. Wir vergleichen die erklärte Varianz von mountain_range mit der gesamten Varianz. Die gesamte Varianz ist die Varianz aller zufälligen Effekte plus der residualen Vamrianz. Wir erhalten dann \\(R^2_{random} = 339.7/(339.7 + 223.8) \\approx 0.60\\). Wir sehen, dass ca. 60% der Varianz in unseren Daten von der Variable mountain_range verursacht wird.\nWir können die Funktion model_performance() nutzen um mehr über den Fit des Modells zu erfahren. Das R2 (cond.) ist faktisch das gleiche wie wir gerade oben berechnet haben. Wir benötigen also nicht immer den Ausdruck der zufälligen Effekte. Wir können auch die Informationen aus der Funktion model_performance() nehmen.\n\nlmer_1_fit %>% model_performance()\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2 (cond.) | R2 (marg.) |   ICC |   RMSE |  Sigma\n----------------------------------------------------------------------------------\n3983.403 | 3983.640 | 4012.620 |      0.598 |      0.004 | 0.597 | 14.774 | 14.961\n\n\nIn der Abbildung Abbildung 44.9 schauen wir uns nochmal an, ob wir das Modell auch gut gefittet haben. Der Residualplot sieht gut aus, wir erkennen kein Muster. Ebenso sieht der QQ-Plot gut aus, die Beobachtungen liegen alle auf der Geraden. Wir sind mit dem Modell soweit erstmal ganz zufrieden.\n\n\n\n\n\n(a) Residualplot\n\n\n\n\n\n\n(b) QQ-Plot\n\n\n\n\nAbbildung 44.9— Visuelle Überprüfung des Modells mit dem Residual und QQ-Plot.\n\n\nWir haben noch eine Variable in unseren Daten ignoriert. Wir haben uns bis jetzt nicht die Variabl site angeschaut. Auf jedem Berg haben wir die Drachen noch auf verschiedenen Flanken des Berges site befragt. Das heißt, wir haben die Variable site, die in der Variable mountain_site genestet ist. Wir schreiben daher ein neues Modell und nutzen die Schreibweise (1|mountain_range/site) um zu beschreiben, dass site immer zusamen in einem Berg vorkommt. Schaue dir dazu nochmal die Abbidlung ganz zu Beginn dieses Kapitels an um die Zusammenhänge nochmal visualisiert zu bekommen.\n\nlmer_2_fit <- lmer(test_score ~ body_length_cat + (1|mountain_range/site), data = dragons_tbl) \nlmer_2_fit %>% model_parameters()\n\n# Fixed Effects\n\nParameter                  | Coefficient |   SE |          95% CI | t(472) |      p\n-----------------------------------------------------------------------------------\n(Intercept)                |       46.89 | 7.80 | [ 31.56, 62.22] |   6.01 | < .001\nbody length cat [small]    |        1.32 | 3.99 | [ -6.51,  9.16] |   0.33 | 0.740 \nbody length cat [medium]   |        3.34 | 4.61 | [ -5.73, 12.41] |   0.72 | 0.470 \nbody length cat [large]    |        4.85 | 5.15 | [ -5.26, 14.97] |   0.94 | 0.346 \nbody length cat [gigantic] |        1.37 | 5.83 | [-10.08, 12.83] |   0.24 | 0.814 \n\n# Random Effects\n\nParameter                           | Coefficient\n-------------------------------------------------\nSD (Intercept: site:mountain_range) |        4.79\nSD (Intercept: mountain_range)      |       17.88\nSD (Residual)                       |       14.46\n\n\nDas Modell hat nun einen weiteren zufälligen Effekt. Es werden jetzt auch nochmal für jeden Berg die Flankeneffekte mit berücksichtigt. Hat das überhaupt einen Einfluss auf das Modell? Schauen wir uns einmal die Modellgüte mit der Funktion model_performance() an.\n\nlmer_2_fit %>% model_performance()\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2 (cond.) | R2 (marg.) |   ICC |   RMSE |  Sigma\n----------------------------------------------------------------------------------\n3970.693 | 3970.999 | 4004.084 |      0.623 |      0.004 | 0.621 | 14.120 | 14.460\n\n\nWir sehen, dass sich die erklärte varianz leicht erhöht hat. Die \\(R^2_{random}\\) liegt jetzt bei \\(0.623\\) also fast 62%. Etwas besser als vorher, aber auch nicht unbedingt sehr viel mehr.\nWie können wir nun unsere vier Modelle miteinander vergleichen? Wir haben ja folgende Modelle vorliegen:\n\nDas simple lineare Modell lm_simple_fit mit test_score ~ body_length_cat.\nDas multiple lineare Modell lm_mountain_fit mit test_score ~ body_length_cat + mountain_range.\nDas gemischte lineare Modell lmer_1_fit mit test_score ~ body_length_cat + (1|mountin_range).\nDas genestete gemischte lineare Modell lmer_2_fit mit test_score ~ body_length_cat + (1|mountain_range/site).\n\nUm die Modelle miteinander zu vergleichen können wir die Funktion compare_performance() nutzen. Wir erhalten mit der Option rank = TRUE auch eine Sortierung der Modelle wieder. Das beste Modell steht dann ganz oben.\n\ncompare_performance(lm_simple_fit, lm_mountain_fit, lmer_1_fit, lmer_2_fit, rank = TRUE)\n\n# Comparison of Model Performance Indices\n\nName            |   Model |   RMSE |  Sigma | AIC weights | BIC weights | Performance-Score\n-------------------------------------------------------------------------------------------\nlm_mountain_fit |      lm | 14.772 | 14.960 |       1.000 |       0.330 |            83.11%\nlmer_2_fit      | lmerMod | 14.120 | 14.460 |    5.84e-05 |       0.655 |            75.00%\nlmer_1_fit      | lmerMod | 14.774 | 14.961 |    1.72e-07 |       0.016 |            46.11%\nlm_simple_fit   |      lm | 20.661 | 20.770 |    1.24e-67 |    9.06e-62 |             0.00%\n\n\nIn diesem Beispiel wäre sogar eine multiple lineare Regression das beste Modell. Wir würden also auch mit zwei festen Effekten die Variabilität der Berge richtig mdellieren. Der Effekt der Flanken auf den Testscore scheint ziemlich klein zu sein, so dass wir auch auf die Variable site verzichten können.\nWas machen wir jetzt noch zum Schluß? Wir machen noch einen paarweisen Vergleich über alle Level der Vaeiable body_length_cat. Ich will hier nochmal zeigen, wie du einen multiplen Vergleich mit einem gemischten Modell in R rechnen kannst. Wir nutzen hier dann das R Paket emmeans um das compact letter display nutzen zu können.\nAls erstes nutzen wir die Funktion emmeans um die multiplen Vergleich über alle Level des Faktors body_length_cat zurechnen.\n\nres_lmer <- lmer_2_fit %>% \n  emmeans(~ body_length_cat) \n\nIm Weiteren nutzen wir jetzt das Objekt res_lmer um die Vergleiche zu rechnen und zu asjustieren. Wir nutzen die Bonferroni Methode für die Adjustierung der \\(p\\)-Werte.\n\nres_lmer %>% \n  contrast(method = \"pairwise\", adjust = \"bonferroni\") \n\n contrast          estimate   SE  df t.ratio p.value\n tiny - small       -1.3218 4.02 453  -0.329  1.0000\n tiny - medium      -3.3379 4.76 118  -0.701  1.0000\n tiny - large       -4.8531 5.31 148  -0.914  1.0000\n tiny - gigantic    -1.3744 6.02 152  -0.228  1.0000\n small - medium     -2.0161 3.83 134  -0.526  1.0000\n small - large      -3.5313 4.50 179  -0.784  1.0000\n small - gigantic   -0.0526 5.32 175  -0.010  1.0000\n medium - large     -1.5152 2.39 362  -0.634  1.0000\n medium - gigantic   1.9635 3.71 229   0.529  1.0000\n large - gigantic    3.4787 2.95 241   1.178  1.0000\n\nDegrees-of-freedom method: kenward-roger \nP value adjustment: bonferroni method for 10 tests \n\n\nWenn wir an dem compact letter display interessiert sind, dann müsen wir die Funktion cld() nutzen. Was wir brauchen, hängt dann immer davon ab, was wir zeigen wollen und was die Fragestellung ist.\n\nres_lmer_cld <- res_lmer %>% \n  cld(adjust = \"bonferroni\", Letters = letters) %>% \n  tidy() %>% \n  select(body_length_cat, estimate, conf.low, conf.high, .group) %>% \n  mutate(across(where(is.numeric), round, 2))\n\nres_lmer_cld \n\n# A tibble: 5 x 5\n  body_length_cat estimate conf.low conf.high .group\n  <chr>              <dbl>    <dbl>     <dbl> <chr> \n1 tiny                46.9     23.6      70.2 \" a\"  \n2 small               48.2     25.5      71.0 \" a\"  \n3 gigantic            48.3     25.8      70.7 \" a\"  \n4 medium              50.2     27.8      72.7 \" a\"  \n5 large               51.7     29.2      74.2 \" a\"  \n\n\nAn dem compact letter display sehen wir schon, dass es keinen Unterschied zwischen den Gruppen bzw. Leveln des Faktors body_length_cat gibt. Wir sehen bei allen Leveln ein a. Wir haben keine signifikante Unterschiede.\nIn Abbildung 44.10 siehst du nochmal die Daten zusammen mit dem compact letter display dargestellt.\n\nggplot() +\n  theme_bw() +\n  geom_point(data = dragons_tbl, aes(x = body_length_cat, y = test_score)) +\n  geom_text(data = res_lmer_cld, \n            aes(x = body_length_cat , y = estimate, label = .group),\n            position = position_nudge(x = 0.2), color = \"red\") +\n  geom_errorbar(data = res_lmer_cld,\n                aes(ymin = conf.low, ymax = conf.high, x = body_length_cat),\n                color = \"red\", width = 0.1,\n                position = position_nudge(x = 0.1)) +\n  geom_point(data = res_lmer_cld, \n             aes(x = body_length_cat , y = estimate),\n             position = position_nudge(x = 0.1), color = \"red\") +\n  scale_color_okabeito() +\n  labs(x = \"Körperlänge in Kategorien\"n\", = \"Testscore\"e\", \n       caption = \"Schwarze Punkte stellen Rohdaten dar.\n       Rote Punkte und Fehlerbalken stellen bereinigte Mittelwerte mit 95% Konfidenzgrenzen pro Behandlung dar.\n       Mittelwerte, mit einem gemeinsamen Buchstaben, sind nicht signifikant unterschiedlich.\")\n\n\n\nAbbildung 44.10— Scatterplot der Körperlängen zusammen mit den 95% Konfidenzintervall und dem compact letter display.\n\n\n\n\nManchmal wollen wir auch die 95% Konfidenzintervalle anzeigen, dann müssen wir wiederum die Funktion contrast() nutzen. Wir lassen uns auch hier die adjustoerten \\(p\\)-Werte wiedergeben. Wir nutzen dann das Objekt res_lmer_tbl um die 95% Konfidenzintervalle zu plotten.\n\nres_lmer_tbl <- res_lmer %>% \n  contrast(method = \"pairwise\") %>% \n  tidy(conf.int = TRUE) %>% \n  mutate(p.value = pvalue(adj.p.value),\n         across(where(is.numeric), round, 2)) %>% \n  select(contrast, estimate, p.value,\n         conf.low, conf.high) \n\nres_lmer_tbl\n\n# A tibble: 10 x 5\n   contrast          estimate p.value conf.low conf.high\n   <chr>                <dbl> <chr>      <dbl>     <dbl>\n 1 tiny - small         -1.32 0.997     -12.3       9.68\n 2 tiny - medium        -3.34 0.956     -16.5       9.85\n 3 tiny - large         -4.85 0.891     -19.5       9.81\n 4 tiny - gigantic      -1.37 >0.999    -18.0      15.2 \n 5 small - medium       -2.02 0.985     -12.6       8.58\n 6 small - large        -3.53 0.935     -15.9       8.87\n 7 small - gigantic     -0.05 >0.999    -14.7      14.6 \n 8 medium - large       -1.52 0.969      -8.06      5.03\n 9 medium - gigantic     1.96 0.984      -8.23     12.2 \n10 large - gigantic      3.48 0.764      -4.64     11.6 \n\n\nIn Abbildung 44.11 sehen wir die 95% Konfidenzintervalle für alle paarweisen Vergleiche der Körperlängen.\n\nggplot(res_lmer_tbl, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +\n  geom_hline(yintercept=0, linetype=\"11\", colour=\"grey60\") +\n  geom_errorbar(width=0.1) + \n  geom_point() +\n  coord_flip() +\n  theme_bw()  +\n  labs(x = \"Vergleich\", y = \"Mittelwertsunterschied des Gewichtes [kg/ha]\",\n       caption = \"Schwarze Punkte stellen die bereinigten Mittelwertsunterschiede mit 95% Konfidenzgrenzen dar.\n       Enthält ein 95% Konfidenzintervalle die 0 ist es nicht signifikant unterschiedlich.\"))\n\n\n\nAbbildung 44.11— Abbildung der 95% Konfidenzintervallefür alle paarweisen Vergleiche der Körperlängen."
  },
  {
    "objectID": "stat-modeling-mixed.html#nested",
    "href": "stat-modeling-mixed.html#nested",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.5 Nested",
    "text": "44.5 Nested\n\n\n\n\nhttps://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified\nhttps://www.statology.org/nested-anova-in-r/"
  },
  {
    "objectID": "experimental-design-samplesize.html",
    "href": "experimental-design-samplesize.html",
    "title": "\n48  Fallzahlplanung\n",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:50:10\nIn diesem Kapitel wollen wir uns mit der Fallzahlplanung beschäftigen. Eigentlich stimmt das Wort Planung überhaupt nicht. Wir machen hier eine Fallzahlabschätzung. Es geht hier darum, anhand von Werten aus der Literatur für dein eigenen Experiment die nötige Anzahl an Beobachtungen abzuschätzen. Nun ist es so, dass die Berechnung der benötigten Fallzahl in klinischen Studien oder aber Tierversuchsvorhaben vor dem Beginn des Versuchs durchgeführt werden muss. Es gibt in diesem Zusammenhang das Tierversuchsvorhaben im Falle von Tieren und den Ethikantrag im einer klinischen Studie. Beide Anträge werden faktisch bei einer Behörde gestellt und haben einen regulativen Charakter. Wir machen hier aber kein Jura. Deshalb hat dieses Kapitel auch keinen beratenden Charakter.\nWenn du an einer Institution arbeitest oder forscht, die einen Ethikantrag stellen oder einen Tierversuchsantrag einreichen will, wende dich an deine Vertrauensperson. Es muss jemanden bei dir geben, der für solche Anträge zuständig ist. Dieses Kapitel und ich sind es ausdrücklich nicht.\nEine weitere Besonderheit ist noch eine Studie, die Übrprüfen soll, ob der versuch übrhaupt machbar ist. Der versuch soll die Machbarkeit (eng. feasibility) testen. In diesem Fall brauchen wir keine Fallzahlberechnung. Wir testen ja eine sehr kleine Fallzahl, weil es uns um die technische Umsetzbarkeit des Versuches geht. Erst wenn wir wissen, dass wir den Versuch auch technisch durchführen können, machen wir dann eine statistsiche Fallzahlplanung."
  },
  {
    "objectID": "experimental-design-samplesize.html#theoretischer-hintergrund",
    "href": "experimental-design-samplesize.html#theoretischer-hintergrund",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.1 Theoretischer Hintergrund",
    "text": "48.1 Theoretischer Hintergrund\nManchmal hat man das Gefühl, dass Fallzahlplanung nur ein wildes Gerate ist. Das ist aus der Perspektive eines biologischen Fachlaien auch der Fall. Ich kenne mich sehr wenig in der vielen biologischen Feldern aus. Daher weiß ich wenig darüber was ein großer Effekt ist oder welchen Effekt du überhaupt in deinem Kartoffelexperiment erwarten kannst. Auch ist mir unklar was typische Mittelwertsunterschiede bei Wasserlinsen sind. Du musst sowas aber wissen, es ist ja schließlich dein Experiment. Wenn du also eine Fallzahlplanung durchführen willst, dann heißt es zuerst einmal Literatur wälzen oder mit den Fachkollegen sprechen.\nWir kennen ja schon die Formel für den t-Test. Der t-Test vergleicht die Mittelwerte von zwei normalverteilten Outcomes und gewichtet diesen Mittelwertsunterschied bei der Standardabweichung. Da wir in der Formel des t-Tests auch die Fallzahl inkludiert haben, können wir die Formel nach der Fallzahl umstellen.\n\\[\nT = \\cfrac{\\Delta}{s_p \\cdot \\sqrt{\\cfrac{2}{n_g}}}\n\\]\nDabei nutzen wir die Teststatistik etwas anders. Wir zerlegen die Teststatistik \\(T\\) für in den Wert für den \\(\\alpha\\)-Fehler und den \\(\\beta\\)-Fehler. Damit können wir auch die Power \\(1-\\beta\\) mit in unserer Formel berücksichtigen.\n\\[\nn_g = \\cfrac{2\\cdot(T_{\\alpha = 5\\%} + T_{\\beta = 20\\%})^2}{\\left(\\cfrac{\\Delta}{s_p}\\right)^2}\n\\]\nDabei nutzen wir für \\(T_{\\alpha = 5\\%} = 1.96\\) und \\(T_{\\beta = 20\\%} = 0.84\\) und vereinfachen damit die Formel ziemlich. Eigentlich nutzen wir diese Formel dann in der der Klausur oder aber um wirklich mal eben schnell zu schauen, was wir für eine Fallzahl erwarten.\nJetzt könntest du meinen, dass wir jetzt mit verschiedenen Powerleveln spielen könnten. Aber das ist leider nicht der Fall. Wir sind eigentlich zimelich auf 80% festgelegt. Da gibt es im Rahmen eines Antrags keinen Spielraum. Wir nehmen immer eine Power von 80% an.\n\n\n\n\n\n\nEinseitig oder zweiseitig im Spiegel der Regulierungsbehörden\n\n\n\nIn den allgemeinen Methoden des IQWiG, einer Regulierungsbehörde für klinische Studien, wird grundsätzlich das zweiseitige Testen empfohlen. Wenn einseitig getestet werden sollte, so soll das \\(\\alpha\\)-Niveau halbiert werden. Was wiederum das gleiche wäre wie zweiseitiges Testen - nur mit mehr Arbeit.\nZur besseren Vergleichbarkeit mit 2-seitigen statistischen Verfahren wird in einigen Guidelines für klinische Studien eine Halbierung des üblichen Signifikanzniveaus von 5 % auf 2,5 % gefordert. – Allgemeine Methoden Version 6.1 vom 24.01.2022, p. 180\nFazit des Dokumentes ist dann aber, dass wir immmer zu einem Signifikanzniveau \\(\\alpha\\) von 5% und einer Power von 80% testen."
  },
  {
    "objectID": "experimental-design-samplesize.html#tierversuchsantrag",
    "href": "experimental-design-samplesize.html#tierversuchsantrag",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.2 Tierversuchsantrag",
    "text": "48.2 Tierversuchsantrag\nWenn du einen Tierversuch durchführen willst, dann bist du natürlich hier falsch. Ich kann dir bei dem Ausfüllen von Dokumenten nicht helfen. Was ich aber kann, ist dir einen Überblick über die Inhalte zu geben, so dass du dann nochmal informiert an anderer Stelle Fragen stellen kanst. Schaue gerne einmal mein Video auf YouTube mit dem Kontext zum Tierversuchsvorhaben.\n\n\n\n\n\n\nEinführung in den Kontext zu Tierversuchsvorhaben per Video\n\n\n\nDu findest auf YouTube Kontext zu Tierversuchsvorhaben als Video Reihe. Es handelt sich hierbei um ein reines Lehrvideo mit keinem beratenden Anspruch.\n\n\nIn dem Video habe ich dann alles anhand des Tierversuchsvorhaben am LaGeSo in Berlin besprochen. Das hatte den Grund, dass ich zur Zeit des Videos an der Charité beschäftigt war. Da bei einem Tierversuchsantrag jeweils die Bundesländer zuständig sind, musst du bei deiner jeweiligen Ladesbehörde einmal schauen. In Niedersachsen musst du dir die Wenseite zu Tierversuche vom Laves anschauen. Hier findest du dann andere Dokumente und Ausfüllhilfen. Wenn man als Wissenschaftler viel wechselt, wird man leicht wirr. Jedesmal neue Dokumente ausfüllen."
  },
  {
    "objectID": "experimental-design-samplesize.html#ethikantrag",
    "href": "experimental-design-samplesize.html#ethikantrag",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.3 Ethikantrag",
    "text": "48.3 Ethikantrag\nEben hatten wir uns kurz den Antrag für ein Tierversuchsvorhaben angeschaut. Richtig kompliziert wird es, wenn wir nicht mit Tieren arebiten sondern Versuche am Menschen durchführen. Ein versuch am Menschen beinhaltet schon das Ausfüllen eines Fragebogens! Daher kanns du auch schnell in die Situtaton kommen, dass es eventuell eine ethische Komplikation gibt. Ich habe die Inhalte im Kontext einer klinischen Studie einmal in einem YouTube Video dargestellt und allgemein eingeordnet.\n\n\n\n\n\n\nEinführung in den Kontext zum Ethikantrag per Video\n\n\n\nDu findest auf YouTube Kontext zum Ethikantrag als Video Reihe. Es handelt sich hierbei um ein reines Lehrvideo mit keinem beratenden Anspruch.\n\n\nDa ich in meiner Lehre die klinischen Studie nur am Horizont sehe, gibt es hir auch keine weiteren Links zu dem Thema. In dem Video siehst du noch ein paar öffentliche Quellen. Da es sich aber bei einem Ethikantrag meist um einen internen Prozess einer Universitätsklinik handelt, sind die (aktuellen) Dokumente meist nicht öffentlich zugänglich. Im Zweifel bitte an die zuständigen Gremien an deiner Institution wenden."
  },
  {
    "objectID": "experimental-design-samplesize.html#genutzte-r-pakete-für-das-kapitel",
    "href": "experimental-design-samplesize.html#genutzte-r-pakete-für-das-kapitel",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.4 Genutzte R Pakete für das Kapitel",
    "text": "48.4 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, pwr, readxl, see,\n               effectsize, conflicted)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"extract\", \"magrittr\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "experimental-design-samplesize.html#mittelwertsvergleich-für-zwei-gruppen-in-r",
    "href": "experimental-design-samplesize.html#mittelwertsvergleich-für-zwei-gruppen-in-r",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.5 Mittelwertsvergleich für zwei Gruppen in R",
    "text": "48.5 Mittelwertsvergleich für zwei Gruppen in R\nDa wir ja nur die Formel des t-Tests für die Fallzahlberechnung haben, können wir auch immer nur die Fallzahl für den Vergleich zwischen zwei Gruppen rechnen. Das ist immer erstmal wieder ungewohnt. Aber wir machen das jetzt erstmal nur für zwei Gruppen. Später schauen wir uns an, ws passiert, wenn wir mehr Gruppen miteinander vergleichen wollen. Prinzipiell ist der Kern aber immer ein Zweigruppenvergleich, den wir dann etwas anders Aufbauen.\nWenn du für einen Wilcoxon-Test oder einen anderen nicht-parametrischen Test die Fallzahlplanung machen willst, rechne bitte einen t-Test und addiere \\(+15\\%\\) an Fallzahl drauf.\nFür die Berechnung der Fallzahl wollen wir das R paket pwr nutzen. Wir brauchen in diesem Kapitel nur drei Funktion aus dem Paket, aber es gibt auch weit aus mehr. Im Zweifel einfach einmal die Hilfeseite aufrufen und schauen was es dort noch so gibt.\nWir können mit der Funktion pwr.t.test() die Fallzahl für die Effektstärke nach Cohen’s \\(d\\) berechnen. Mehr über Cohen’s \\(d\\) kannst du im Kapitel 21 erfahren. Wir nutzen hier eine relativ harte Abschätzung. Aber hier wird sowieso alles abgeschätzt, da kommt es jetzt auf künstliche Genauigkeit nicht mehr an. Wir berechnen also Cohen’s \\(d\\) vereinfacht für die Fallzahlberechnung wie folgt.\n\\[\nd = \\cfrac{\\Delta}{s_{\\Delta}}\n\\]\nmit\n\n\n\\(\\Delta\\) als den zu erwartenden Mittelwertsunterschied zwischen den beiden Gruppen. Wir haben den Wert aus der Literatur entnommen.\n\n\\(s_{\\Delta}\\) als der Standardabweichung des Mittelwertsunterschieds. Wir können hier als Vereinfachung mit der Spannweite der Daten mit \\(\\frac{range}{4}\\) als Schätzer für die Standardabweichung rechnen. Ebenfalls haben wir die Werte aus einer Literaturquelle.\n\nEs gäbe auch die Möglichkeit über die Funktion cohen.ES() die Effekte für verschiedene statistische Tests sich wiedergeben zu lassen, wenn wir definieren, wie stark der Effekt zwischen den Gruppen sein soll. Es steht zur Auswahl small, medium und large. Wir erkennen, dass ist nicht gerade viel Abstufung.\n\ncohen.ES(test = \"t\", size=\"medium\") %>% \n  pluck(\"effect.size\")\n\n[1] 0.5\n\n\nDie Fallzahlberechnung geht recht einfach. Wir setzen die Option n = auf NULL, so dass uns die Funktion diese Option berechnet. Wir kriegen also die Fallzahl gegeben von dem Signifikanzniveau, der Power und der Effektstärke wieder. Dann geben wir noch an, dass wir zweiseitig testen. Also eigentlich alles fix, da können wir selber zwar was ändern, aber am Ende wird meist nur die Standardwerte von Dritten akzeptiert.\n\nres_ttest <- pwr.t.test(n = NULL,\n                        sig.level = 0.05, \n                        type = \"two.sample\", \n                        alternative = \"two.sided\", \n                        power = 0.80, \n                        d = 0.8)\nres_ttest\n\n\n     Two-sample t test power calculation \n\n              n = 25.52458\n              d = 0.8\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nBitte immer Aufrunden. Wir brauchen also \\(n_1 = n_2 = 26\\) Beobachtungen je Gruppe, so dass wir für \\(32\\) beobachtungen unseren Versuch planen können. In Abbildung 48.1 sehen die Power abhängig von der verwendeten Fallzahl. Wir sehen, dass wir mit mehr Fallzahl eine höhere Power erhalten würden, aber wir schon sehr nah an der Sättigung sind.\n\nplot(res_ttest) +\n  theme_minimal(base_size = 14) +\n  labs(title = 'Optimierte Fallzahl für den Zweistichproben t-Test.'))\n\n\n\nAbbildung 48.1— Optimierte Fallzahl für den Zweistichproben t-Test."
  },
  {
    "objectID": "experimental-design-samplesize.html#anteilsvergleich-für-zwei-gruppen-in-r",
    "href": "experimental-design-samplesize.html#anteilsvergleich-für-zwei-gruppen-in-r",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.6 Anteilsvergleich für zwei Gruppen in R",
    "text": "48.6 Anteilsvergleich für zwei Gruppen in R\nWann benötigen wir Anteile? Häufig nutzen wir Anteile, wenn wir zum Beispiel infizierte Ferkel untr zwei Behandlungen untersuchen wollen. Wie viel Prozent der Ferkel in der einen Gruppe werden infiziert sein und wieviel Ferkel in der anderen Gruppe. Daher haben wir ein Medikament und wollen schauen, ob sich die Anzahl an infizierten Ferkeln reduziert. Wir nehmen aber nicht die Anzahl als Wert sondern die relative Angabe. Im folgenden Beispiel haben wir \\(95\\%\\) infizierte Ferkel in der einen Gruppe und \\(80\\%\\) infizierte Ferkel in der anderen Gruppe. Wie viel Fallzahl brauchen wir nun, um diesen Untrschied nachzuweisen. Achtung, wir rechnen hier wirklich mit den relativen Zahlen und nicht mit der Differenz. Ist leider so.\nWir können die Funktion ES.h() benutzen um den Effekt zwischen zwei Wahrscheinlichkeiten zu berechnen. Wir geben einfach die beiden Wahrscheinlichkeiten für die zu erwartende Häufigkeit an infizierten Ferkeln ein. Dann berechnen wir den Effekt \\(h\\) und nutzen diesen Wert dann für die Fallzahlberechnung.\n\nES.h(p1 = 0.95, p2 = 0.80) %>% \n  round(2)\n\n[1] 0.48\n\n\nHier kommt es dann auch nicht wieder auf die letzte Prozentzahl an. Wir immer kann man hhier spielen. Aber du hast ja deine Zahlen aus der Literatur und passt diese Zahlen dann deinem Setting und anhand deinem biolologischen Wissen an. Es ist immer eine Gradwanderung, wie genau die Zahlen nun seien sollen. Insbesondere, wenn es dann doch nicht so viel Literatur gibt. Wir setzen die Option n = auf NULL, so dass uns die Funktion diese Option berechnet. Wir kriegen also die Fallzahl gegeben von dem Signifikanzniveau, der Power und der Effektstärke wieder. Dann geben wir noch an, dass wir zweiseitig testen.\n\nres_prop <- pwr.p.test(h = 0.48,\n                       n = NULL,\n                       sig.level = 0.05,\n                       power = 0.80,\n                       alternative = \"two.sided\")\nres_prop\n\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.48\n              n = 34.06623\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nAm Ende erhalten wir eine Fallzahl von \\(n_1 = n_2 = 35\\) Beobachtungen aus der Fallzahlberechnung. Wir wissen also, wie viele Ferkel wir untersuchen müssten um einen Unterschied von \\(95\\%\\) zu \\(80\\%\\) signifikant nachweisen zu können. In Abbildung 48.2 sehen wir nochml die Sättigungskurve für die Power für verschiedene Fallzahlen. Mit unserer berechneten Fallzahl von \\(n=35\\) pro Gruppe sind wir schon recht nah an der Sättigung der Funktion. Wir können damit die Fallzahl beibehalten und uns übrlegen, ob wir überhaupt das Geld und die Ressourcen haben um den Versuch mit dieser Anzahl an Ferkeln durchzuführen.\n\nplot(res_prop) +\n  theme_minimal(base_size = 14) +\n  labs(title = 'Optimierte Fallzahl für zwei Anteile.'))\n\n\n\nAbbildung 48.2— Optimierte Fallzahl für zwei Anteile."
  },
  {
    "objectID": "experimental-design-samplesize.html#mehr-als-zwei-gruppen",
    "href": "experimental-design-samplesize.html#mehr-als-zwei-gruppen",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.8 Mehr als zwei Gruppen",
    "text": "48.8 Mehr als zwei Gruppen\nWas passiert, wenn wir mehr als zwei Gruppen vorliegen haben? Was eigentlich immer der Fall ist. Also wir haben nicht nur zwei Düngestufen oder zwei Sorten Blumenkohl, die wir miteinander vergleichen wollen, sondern wir haben zehn oer mehr. Wir bauen jetzt nicht so ein großes Beispiel sondern nehmen einmal die Sprungweiten von den Hunde-, Katzen- und Fuchsflöhen.\n\nfleas_tbl <- read_excel(\"data/flea_dog_cat_fox.xlsx\") %>% \n  mutate(animal = as_factor(animal))\n\nIn Abbildung 48.3 sehen wir nochmal die Verteilung der Sprungweiten für die drei Tierarten als Boxplots dargestellt.\n\nggplot(fleas_tbl, aes(animal, jump_length, fill = animal)) + \n  theme_bw() +\n  geom_boxplot() +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito()\n\n\n\nAbbildung 48.3— Boxplot der Sprungweiten für die Hunde-, Katzen- und Fuchsflöhe.\n\n\n\n\nWenn wir jetzt für ein neues Experiment die Fallzahl planen wollen würden, dann brauchen wir die Mittelwerte und die Stanardabweichung der Sprungweiten. Wir haben ja hier unser Pilotexperiment vorliegen, also können wir auch hier die Mittelwerte und die Standardabweichung getrennt für die Tierarten berechnen.\n\nfleas_tbl %>% \n  group_by(animal) %>% \n  summarise(mean = mean(jump_length),\n            sd = sd(jump_length)) %>% \n  mutate(across(where(is.numeric), round, 2))\n\n# A tibble: 3 x 3\n  animal  mean    sd\n  <fct>  <dbl> <dbl>\n1 dog     8.13  2.14\n2 cat     4.74  1.9 \n3 fox     9.16  1.1 \n\n\nNatürlich sind wir nicht an den Mittelwerten sondern an den Unterschieden interessiert. Daher rechnen wir nochmal in Tabelle 48.1 alle Mittelwertsdifferenzen aus.\n\n\nTabelle 48.1— Mittelwertsdifferenzen für alle paarweisen Vergleiche.\n\n\n\ncat\nfox\n\n\ndog\n\\(8.13 - 4.74 = 3.39\\)\n\\(8.13 - 9.16 = -1.03\\)\n\n\ncat\n\n\\(4.74 - 9.16 = -4.42\\)\n\n\n\n\nWenn wir die kleinste Differenz in den Mittelwerten mit einer Power von 80% nachweisen können, dann können wir auch alle anderen größeren Mittelwertsdifferenzen mit einer Power größer als 80% nachweisen. Daher brauchen wir die Fallzahlplanung nur für den kleinsten Mittelwertsunterschied durchführen. Wir berechnen noch Cohen’s d mit \\(d = \\tfrac{1.03}{(2.14 + 1.1)/2} \\approx 0.16\\). Ganz schön kleiner Wert, wie uns die Funktion interpret_cohens_d() aus dem R Paket effectsize mitteilt.\n\ninterpret_cohens_d(0.15)\n\n[1] \"very small\"\n(Rules: cohen1988)\n\n\nWeil wir es können berechnen wir auch die Fallzahl und kriegen einen kleinen Schreck. Denn mit einem so kleinen Effekt brauchen wir wirklich viele Flöhe.\n\nres_flea <- pwr.t.test(n = NULL,\n                       sig.level = 0.05, \n                       type = \"two.sample\", \n                       alternative = \"two.sided\", \n                       power = 0.80, \n                       d = 0.16)\nres_flea\n\n\n     Two-sample t test power calculation \n\n              n = 614.1541\n              d = 0.16\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nMit am Ende über \\(2 \\cdot 615 = 1230\\) Flöhen für den Vergleich von Hunde- und Fuchsflöhen sind wir wirklich weit, weit oben was die Fallzahl angeht. Da hilft es dann auch nicht viel, dass wir mit zusätzlich \\(615\\) Katzenflöhen dann auch die anderen paaweisen Vergleichw als signifikant finden würden. Denn Cohen’s d für den Vergleich von den Hunde- und Katrzenflöhen wäre \\(d = \\tfrac{3.39}{(2.14 + 1.9)/2} \\approx 0.42\\). Damit würden wir dann eine Power von \\(0.99999997\\) erhalten. Wir können die Power berechnen indem wir das Feld Power mit NULL belegen und die Fallzahl von \\(n = 615\\) eintragen.\n\nres_flea <- pwr.t.test(n = 615,\n                       sig.level = 0.05, \n                       type = \"two.sample\", \n                       alternative = \"two.sided\", \n                       power = NULL, \n                       d = 0.42)\nres_flea\n\n\n     Two-sample t test power calculation \n\n              n = 615\n              d = 0.42\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number in *each* group"
  },
  {
    "objectID": "experimental-design-samplesize.html#gpower-als-alternative",
    "href": "experimental-design-samplesize.html#gpower-als-alternative",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.9 G*Power als Alternative",
    "text": "48.9 G*Power als Alternative\n\n\n\n\n\n\nEinführung in G*Power als Alternative per Video\n\n\n\nDu findest auf YouTube G*Power als Alternative als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.\n\n\nAls Alternative zu R wollen wir uns noch das Standalone Programmm G*Power | Statistical Power Analyses von der Heinrich-Heine-Universität Düsseldorf anschauen. Die Software ist nicht mehr die neuste, wird aber immer noch gewartet und an die aktuellen Versionen von Mac und Windows angepasst. Manchmal ist dann Point und Klick dann doch eine Alternative, wenn man sich ausprobieren will.\nIch werde also im Folgenden ein paar Screenshots zeigen, wie du mi G*Power dir auch die Fallzahl für Mittelwertsunterschiede und Anteilesunterschiede berechnen kannst. Allgemein ist es so das G*Power immer einseitig (eng. Tail(s) one) und zu einer Power von 95% testet. Daher müssen wir immr schauen, dass diese Werte stimmen. Insbeosndere, wenn du viel rumprobierst können auch die Werte mal wieder zurückspringen. Also bitte darauf achten.\nIn Abbildung 48.4 sehen wir die Berechnung der Fallzahl für den t-Test für einen Vergleich zweier Gruppen. Wir müssen darauf achten, dass wir die Testfamilie richtig wählen und dann den korrekten Test auswählen. Du siehst bei der eigenen Verwendung dann, dass es hier eine große Auswahl gibt. Wir nehmen aber den Standard von zwei unabhängigen Gruppen. Wir erhalten dann eine Fallzahl von \\(n = 54\\) für unseren Versuch. Das schöne an G*Power ist, dass du relativ einfach und schnell mit den Zahlen spielen kannst. Das Speichern ist schwerer, so dass ich immer einen Screenshot empfehle. Man vergisst schnell, was alles in en Feldern stand.\n\n\n\nAbbildung 48.4— Die Berechnung der Fallzahl für einen t-Test für zwei Gruppen mit einem Mittelwert +/- Standardabweichung von \\(14 \\pm 2\\) in der einen Gruppe und \\(16 \\pm 3\\) in der anderen Gruppe. Es ergibt sich ein Cohens’ d von \\(0.78\\). Wir müssen darauf achten zweiseitig und zu einer Power von 80% zu testen.\n\n\n\nIn Abbildung 48.5 sehen wir die Berechnung der Fallzahl für zwei Anteile. Wir haben zwei Gruppen vorliegen und in der ersten Gruppe haben wir 60% infizierte Ferkel, In der anderen Gruppe erwarten wir dann 90% infiztierte Ferkel. Um den Unterschied von 30% nachzuweisen, brauchen wir mindestens 180 Ferkel. Leider ist es so, dass wir den Test für Anteile unter dem Reiter Exact finden. Das muss man eben wisen. Achte wieder auf die Power und das zu zweiseitig testen willst.\n\n\n\nAbbildung 48.5— Die Berechung der Fallzahl für einen Anteil in zwei Gruppen von \\(0.6\\) in der einen Gruppe und \\(0.8\\) in der anderen Gruppe. Wir müssen darauf achten zweiseitig und zu eienr Power von 80% zu testen."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Skript Bio Data Science",
    "section": "",
    "text": "Auf den folgenden Seiten wirst du eine Menge über Statistik oder Data Science lernen. Du musst dafür nicht eine meiner Veranstaltungen besuchen. Gerne kannst du hier und dort einmal schauen, ob etwas für dich dabei ist. Das Skript wird fortlaufend von mir ergänzt. Neben dem Skript gibt es auch noch die erklärenden YouTube Videos. Ich freue mich, dass du Lust hast hier etwas zu lernen… oder aber du musst – da bald eine Klausur ansteht. Wie auch immer – schau dich einfach mal um. Im Anhang findest du auch einen kleinen Leitfaden für das Schreiben einer Abschlussarbeit. Vielleicht hilft dir die Anleitung ja beim Schreiben.\n\n\n\n\n\n\nGesammelte Klausurfragen in der Bio Data Science\n\n\n\n\n\nDu findest die gesammelten Klausurfragen auf GitHub oder auf ILIAS in dem entsprechenden Modul. Die Klausurfragen zu den einzelnen Vorlesungen in einem Modul werden in den entsprechenden Übungen des Moduls besprochen. Bitte komme in die Übungen.\nDu brauchst dir die Fragen nicht alle auszudrucken. Wir besprechen die Fragen teilweise in den Übungen.\nDie finale Version für die Klausur veröffentliche ich Ende November für das Wintersemester bzw. Ende Mai für das Sommersemester.\n\n\n\n\n\n\n\n\n\nInformationen zu einer Bachelorarbeit in der Bio Data Science\n\n\n\n\n\nWenn du dich fragst, wie die Rahmenbedingungen einer Bachelorarbeit bei mir sind findest du hier die Informationen zu einer Bachelorarbeit in der Bio Data Science. Oder du fragst mich einfach unverbindlich per Mail oder in einer meiner Vorlesungen. Wie es dir am besten passt.\n\n\n\n\n\nDu liest hier gerade das Skript für meine Vorlesungen an der Hochschule Osnabrück an der Fakultät Agrarwissenschaften und Landschaftsarchitektur (AuL). Wie immer Leben kannst du auf verschiedene Arten und Weisen den Stoff, den ich vermitteln will, lernen. Daher gibt es noch zwei andere Möglichkeiten. Zum einen Lernen auf YouTube, mit meinen Lernvideos oder du schaust dir das Material auf GitHub an. Auf GitHub habe ich auch Informationen, die du vielleicht brauchen kannst. Ebenso findest du im Kapitel 2 noch andere Literaturempfehlungen.\n\n\n\n\n\n\n\nWenn du möchtest kannst du auf YouTube unter https://www.youtube.com/c/JochenKruppa noch einige Lehrvideos als Ergänzung schauen. In den Videos wiederhole ich Inhalte und du kannst auf Pause drücken um nochmal Programmierschritte nachverfolgen zu können.\n\n\n\n\n\n\n\n\nAlle Materialien von mir findest du immer auf GitHub unter https://github.com/jkruppa/teaching. Selbst wenn du nicht mehr in einem meiner Kurse bist, kannst du so auf die Lehrinhalte immer nochmal zugreifen und die aktuellen Versionen haben. Auf GitHub liegt auch immer eine semesteraktuelle Version der gesammelten Klausurfragen für meine Module.\n\n\n\n\nWie erreichst du mich? Am einfachsten über die gute, alte E-Mail. Bitte bachte, dass gerade kurz vor den Prüfungen ich mehr E-Mails kriege. Leider kann es dann einen Tick dauern.\n\n\n\n\n\nEinfach an j.kruppa@hs-osnabrueck.de schreiben. Du findest hier auch eine kurze Formulierungshilfe. Einfach auf den Ausklapppfeil klicken.\nBitte gib immer in deiner E-Mail dein Modul - was du belegst - mit an. Pro Semester unterrichte ich immer drei sehr ähnlich klingende Module. Daher schau nochmal hier in der Liste, wenn du unsicher bist.\n\n\n\n\n\n\nE-Mailvorlage mit beispielhafter Anrede\n\n\n\n\n\nHallo Herr Kruppa,\n… ich belege gerade Ihr Modul Modulname und hätte eine Bitte/Frage/Anregung…\n… ich benötige Hilfe bei der Planung/Auswertung meiner Bachelorarbeit…\nMit freundlichen Grüßen\nM. Muster"
  },
  {
    "objectID": "experimental-design-samplesize.html#anteil-der-erklärten-varianz-in-r",
    "href": "experimental-design-samplesize.html#anteil-der-erklärten-varianz-in-r",
    "title": "\n48  Fallzahlplanung\n",
    "section": "\n48.7 Anteil der erklärten Varianz in R",
    "text": "48.7 Anteil der erklärten Varianz in R\nNun können wir die Fallzahlplanung auch für eine einfaktorielle ANOVA durchführen. Das ist unsere Basis. Wir würden dann überlegen, wie sich dann die Fallzahl mit weiteren Faktoren ändern würde. Auch hier ein Wort der Warnung. Es gibt häufig so starke Randbedingungen, wie Kosten oder Fläche, dass die Berechnung der Fallzahl absolet wird. Wenn du drei Blöcke hat, dann hast du drei Blöcke. nutze die Blöcke dann auch. Wenn du freeie Wahl hättest und viel, viel Geld, dan kann man sicherlich besser die Fallzahl abschätzen und nutzen. Fallzahlberechnung nur so zum Spaß hat dann ja auch wenig Sinn. Also hier nochmal unser Modell was wir uns mit einer einfaktoriellen ANOVA anschauen.\n\\[\ny \\sim f_1\n\\]\nWir immer brauchen wir auch einen Effekt. In dem Fall der ANOVA ist der Effekt Cohen’s \\(f\\). Wir berechnen Cohen’s \\(f\\) wie folgt aus dem \\(\\eta^2\\). Wir können an dieser Stelle schon die Werte für \\(\\eta^2\\) einsetzen und \\(f\\) berechnen.\n\\[\nf = \\sqrt{\\cfrac{\\eta^2}{1- \\eta^2}}\n\\]\nDu erinnerst dich aus der ANOVA, das \\(\\eta^2\\) beschreibt den Anteil an erklärter Varianz durch den Faktor in der ANOVA. Damit ist \\(\\eta^2\\) wie folgt definiert.\n\\[\n\\eta^2 = \\cfrac{SS_{treat}}{SS_{total}}\n\\]\nDas hilft uns nur so begrenzt weiter. Am besten überlegst du dir, wieviel Varianz wohl die Behandlung erklären kann. Damit hast du dann dein \\(\\eta^2\\). Wenn deine Behandlung vermutlich ca. 70% der Varianz in deinen Daten erklären und somit im Ourtcome erklären kann, dann setzt du \\(\\eta^2 = 0.7\\). Dann berechnest du dein \\(f = \\sqrt{\\tfrac{0.7}{0.3}} = 1.53\\) und hast damit einen sehr großen Effekt. Was dir auch die Funktion interpret_eta_squared() aus dem R Paket effectsize mitteilt.\n\ninterpret_eta_squared(1.53)\n\n[1] \"large\"\n(Rules: field2013)\n\n\nWir können dann Cohen’s \\(f\\) in die Funktion pwr.anova.test() stecken und die Fallzahl pro Gruppe ausrechnen. Wir haben jetzt mal einen Faktor mit drei Behandlunsgleveln angenommen, deshalb ist auch \\(k = 3\\) in der Funktion.\n\nres_anova <- pwr.anova.test(k = 3,\n                            f = 1.5,\n                            n = NULL,\n                            sig.level = 0.05,\n                            power = 0.80)\nres_anova\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 3\n              n = 2.713068\n              f = 1.5\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\nTja, mit so einem großen Effekt brauchen wir wirklich wenig Wiederholungen um mindestens einen Unterschied nachzuweisen. Stimmt, wir haben natürlich auch nur global über alle Gruppen geschaut. Ich finde die Fallzahlplanung für eine ANOVA relativ eingeschränkt, aber so ist das eben auch bei der Fallzahlplanung. Meistens ist das was möglich ist sehr eingeschränkt."
  },
  {
    "objectID": "stat-modeling-mixed.html#gee",
    "href": "stat-modeling-mixed.html#gee",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.6 GEE",
    "text": "44.6 GEE\n\n\n\n\nhttps://data.library.virginia.edu/getting-started-with-generalized-estimating-equations/\nhttps://rlbarter.github.io/Practical-Statistics/2017/05/10/generalized-estimating-equations-gee/"
  },
  {
    "objectID": "stat-modeling-mixed.html#annahmen-an-die-daten",
    "href": "stat-modeling-mixed.html#annahmen-an-die-daten",
    "title": "44  Lineare gemischte Modelle",
    "section": "\n44.1 Annahmen an die Daten",
    "text": "44.1 Annahmen an die Daten\nIm folgenden Kapitel zu den linearen gemischten Modellen gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDas Thema Modellvergleich und Variablenselektion ist im Falle des linearen gemischten Modells nochmal etwas spezieller. Wir gehen hier auch nochmal in einem Abschnitt drauf ein, wie wir das hier in dem Fall von linearen gemischten Modellen machen."
  },
  {
    "objectID": "stat-modeling-gee.html",
    "href": "stat-modeling-gee.html",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "",
    "text": "Version vom November 08, 2022 um 09:03:56\nVerallgemeinerte Schätzgleichungen (eng. Generalized Estimating Equations, abk. GEE) sind eine Methode zur Modellierung von Längsschnitt- oder Clusterdaten (eng. longitudinal bzw. clustered). Ich nutrze nur die Abkürzung GEE im weiteren Text, sonst wird mir das hier zu lang. Unter dem deutschen Begriff sind die GEE’s eigentlich nicht bekannt. Jedenfalls nicht bei Anwendern. Die GEE’s werden in der Regel bei nicht-normalen Daten wie binären oder Zähldaten verwendet. Damit siehst du auch schon, warum wir eigentlich nicht so oft GEE’s in der Anwendung finden. Wir haben in den Agrarwissenschaften meist ein normalverteiltes Outcome \\(y\\) und so nutzen wir dann häufig eben lineare gemischte Modelle. Damit ist das GEE auch eine Alternative für das lineare gemischte Modell. In beiden Modellklassen lassen sich normalverteilte, binäre und auch Zähldaten auswerten. Es ist eher eine Frage, was wir für eine Aussage über die Daten treffen wollen. Wollen wir eine beobachtungsbezogene Aussage (eng. subject-specific) treffen, dann nutzen wir lineare gemischte Modelle. Wollen wir eine populationsbezogene Aussage (eng. population average) treffen, dann nutzen wir das GEE."
  },
  {
    "objectID": "stat-modeling-gee.html#annahmen-an-die-daten",
    "href": "stat-modeling-gee.html#annahmen-an-die-daten",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.1 Annahmen an die Daten",
    "text": "45.1 Annahmen an die Daten\nIm folgenden Kapitel zu den Generalized Estimating Equations (GEE) gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nGrundsätzlich ist das Thema GEE eher ein stiefmütterliches statistisches Thema. Ich selber habe gar nicht so viel zu GEE’s gefunden, so dass wie immer gilt: Augen auf im statistischen Straßenverkehr! Besonders die Variablenselektion, die ja an die Modellklasse gebunden ist, mag nicht so funktionieren wie gewollt. Bitte bei GEE Fragestellungen keine automatisierte Selektion anwenden. Dann lieber über compare_models() aus dem R Paket parameters die Modellvergleiche direkt vergleichen."
  },
  {
    "objectID": "stat-modeling-gee.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-gee.html#genutzte-r-pakete-für-das-kapitel",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.2 Genutzte R Pakete für das Kapitel",
    "text": "45.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, geepack, gee,\n               geesmv, multcomp, emmeans, scales)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"extract\", \"magrittr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-gee.html#daten",
    "href": "stat-modeling-gee.html#daten",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.3 Daten",
    "text": "45.3 Daten\n\n\n\n\n\n\nDu musst deine Daten nach der ID sortieren\n\n\n\nGanz wichtig, sonst funktioniert das GEE nicht und du kriegst auch keine Warnmeldung! Du musst die Daten mit arrange für deine ID Spalte sortieren.\n\n\nIch habe hier ienmal zwei Datenbeispiel mitgebracht. Wir werden uns aber im folgenden Abschnitt dann nur die Schweine anschauen, das Kuhbeispiel können wir dann nochmal anderweitig nutzen oder aber du rechnest nochmal selber mit den Kühen. Wichtig hierbei ist, dass wir sicher sind, dass wir die Daten nach der ID Spalte der Tiere sortiert haben. Das heist, dass alle Tier ID’s Zeilen wirklich beieinander stehen. Das ist wichtig, sonst schafft GEE nur eine sehr seltsame Ausgaben zu produzieren. Leider ohne eine Warnung auszugeben. Deshalb nutzen wir die Funktion arrange() um nochmal nach der Spalte pig_id zu sortieren.\n\npig_gain_tbl <- read_excel(\"data/pig_feed_data.xlsx\") %>% \n  mutate(weight_gain = round(weight_gain, 2)) %>% \n  arrange(pig_id)\n\nIn Tabelle 45.1 sehen wir nochmal einen Auszug aus den Daten. Wir haben unsere wiederholte Messung time. Das heißt wir haben unsere Schweine wiederholt gemessen. Jedes Schwein für jede Behandlung fünfmal. Wir brauchen die pig_id um zu wissen, welche Werte der Geichtszunahme dann auch immer zu einem Ferkel gehören. Im Weiteren haben wir noch die Bucht, in der die Ferkel gehalten wurden, notiert. Die Information lassen wir aber hier erstmal im späteren Modell weg.\n\n\n\n\nTabelle 45.1— Auszug aus dem Daten zu den kranken Ferkeln. Jedes Ferkel wurde wiederholt gemessen.\n\ntime\npig_id\ncove\ntreatment\nweight_gain\n\n\n\n1\n1\n1\nfeed_10\n44.29\n\n\n2\n1\n1\nfeed_10\n59\n\n\n3\n1\n1\nfeed_10\n49.96\n\n\n4\n1\n1\nfeed_10\n66.17\n\n\n…\n…\n…\n…\n…\n\n\n2\n120\n10\nfeed_20\n56.17\n\n\n3\n120\n10\nfeed_20\n58.13\n\n\n4\n120\n10\nfeed_20\n68.48\n\n\n5\n120\n10\nfeed_20\n34.99\n\n\n\n\n\n\nDas zweite Datenbeispiel dient zur Veranschaulichung eines weiteres Messwiederholungsbeispiels. Wir haben drei Kühe wiederholt an drei Zeitpunkten gemessen. JEde Kuh hat immer nur die gleiche Behandlung erhalten. Das Outcome ist einmal die Anzahl an Zellen in der Milch pro ml und einmal der Fettgehalt in %. Die Daten sind in der Form relativ übersichtlich. Wir haben leider sehr wenige Messwiederholungen, so dass hier ein GEE oder aber auch ein lineares gemischtes Modell fraglich ist. Wir wollen eigentlich mindesnten fünf Level für den Clusterfaktor. Wir gehen wieder sicher, dass die Daten auch richtig nach ID sortiert sind.\n\nmilk_tbl <- read_csv2(\"data/milk_feeding.csv\") %>% \n  rename(cow_id = id_cow) %>% \n  arrange(cow_id)\n\nIn Tabelle 45.2 sehen wir nochmal den Ausschnitt aus den Milchdaten. Wir haben insgesamt auch nur vierzehn Kühe gemessen, was auch nicht so viele Tiere sind. Im Ferkelbeispiel hatten wir uns 120 Ferkel angeschaut. Deshal ist dieser Datensatz sehr klein für ein komplexes Modell wie GEE.\n\n\n\n\nTabelle 45.2— Auszug aus Daten zu Milchkühen. Jede Kuh wurde wiederholt gemessen.\n\ncow_id\ntrt\ntime_point\ncell_count\nfat_perc\n\n\n\n1\n1\n1\n1932\n0.69\n\n\n1\n1\n2\n6771\n0.94\n\n\n1\n1\n3\n2225\n0.01\n\n\n2\n0\n1\n2572\n0.15\n\n\n…\n…\n…\n…\n…\n\n\n13\n1\n3\n8445\n0.06\n\n\n14\n1\n1\n19707\n0.95\n\n\n14\n1\n2\n9428\n0.5\n\n\n14\n1\n3\n8184\n0.96\n\n\n\n\n\n\nGehen wir einmal auf den theoretischen Hintergrund zu GEE ein und schauen wir mal, wie wir da unser Datenbeispiel zu passt."
  },
  {
    "objectID": "stat-modeling-gee.html#theoretischer-hintergrund",
    "href": "stat-modeling-gee.html#theoretischer-hintergrund",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.4 Theoretischer Hintergrund",
    "text": "45.4 Theoretischer Hintergrund\nGanz wichtig, wir gehen jetzt nicht auf den mathematischen Hintergurnd ein. Das ist auch zu schräg. Das will heißen, dass der mathematische Hintergrund von GEE’s wirklich vieles übersteigt. Ich kann GEE’s anwenden, aber ich weis nicht, wie ein GEE mathematisch funktioniert. Das muss man ja auch nicht. Deshalb hier nur die Theorie, was ein GEE macht und in welchen Hintergründen wir das GEE anwenden. Zuerst schätzt das GEE die durchschnittlichen Auswirkungen auf die Population (eng. population average). Betrachten wir dabei die folgenden zwei Szenarien nach Allison (2009):\n\n\nSzenario 1: Du bist ein Arzt. Du möchtest wissen, um wie viel ein Cholesterinmedikament die Wahrscheinlichkeit eines Herzinfarkts bei deinem Patienten senkt.\n\nSzenario 2: Du bist ein staatlicher Gesundheitsbeamter. Du möchtest wissen, wie sich die Zahl der Menschen, die an einem Herzinfarkt sterben, verändern würde, wenn alle Menschen in der Risikogruppe das Cholesterinmedikament einnehmen würden.\n\nIm ersten Szenario wollen wir die subjektspezifischen (eng. subject-specific) Chancen wissen. Im zweiten Fall sind wir an der Vorhersage für die gesamte Bevölkerung interessiert. GEE kann uns Schätzungen für das zweite, aber nicht für das erste Szenario liefern. Dami sind wir schon recht weit. Wir wollen also nichts über die einzelnen Ferkel wissen, sondern nur über die Gesamtzahl an Ferklen mitteln. Das ist natürlich manachmal gewollt und manchmal eher nicht. In der Zucht kommt es drauf an, ob du individuelle Effekte haben möchtest, also für einen Eber oder eben die Leistung der gesamten Rasse bewerten willst. Je nachdem kannst du dan ein GEE einsetzen oder nicht. GEE’s sind somit für einfaches Clustering oder wiederholte Messungen gedacht. Komplexere Designs wie verschachtelte oder gekreuzte Gruppen, z. B. verschachtelte Messwiederholungen innerhalb eines Probanden oder einer Gruppe, können nicht ohne weiteres berücksichtigt werden. Hier nutzen wir dann wieder gemischte lineare Modelle.\nEin großer Vorteil der GEE ist, dass wir eine Korrelation zwischen den wiederholten Messungen, also Ferkeln, annehmen können. Das heist, wir können die Verwandtschaft oder den zeitlichen Zusammenhang zwischend den Messwiederholungen abbilden. Dafür brauchen wir dann natürlich auch Fallzahl, die schnell mal über die hundert Beobachtungen geht. Wir können dann zwischen folgenden Zusammenhängen der Korrelation entscheiden.\n\n\nindependence, daher sind die Beobachtungen im Zeitverlauf sind unabhängig.\n\nexchangeable, daher haben alle Beobachtungen im Zeitverlauf die gleiche Korrelation \\(\\rho_{const.}\\).\n\nar1, die Korrelation \\(\\rho\\) nimmt als Potenz der Anzahl \\(p\\) der Zeitpunkte, die zwischen zwei Beobachtungen liegen, ab. Daher rechnen wir mit \\(\\rho, \\rho^2, \\rho^3,..., \\rho^p\\) über die Zeitpunkte.\n\nunstructured, daher kann die Korrelation zwischen allen Zeitpunkten unterschiedlich sein.\n\nLeider gibt es keine automatische Auswahl. Wir müssen also überlegen, welche Korrelationmatrix am besten passen würde. Da unstructured sehr viel Fallzahl benötigt um valide zu sein, nehme ich meistens exchangeable, wenn ich ein GEE rechne. Eine unabhänige Korrealtion anzunehmen macht wenig Sinn, dann brauche ich auch kein GEE rechnen. Die Korrelation ist ja die Stärke von einem GEE.\nWir haben nun zwei R Pakete, die beide das gleiche tun, nämlich ein GEE rechnen. Wir haben die Wahl zwischen dem R Paket gee und der Funktion gee() sowie der Funktion geeglm() aus dem R Paket geepack. Ich neige zu dem letzteren Paket. Das R Paket geepack ist etwas neueren Ursprungs und funktioniert bisher recht reibungslos."
  },
  {
    "objectID": "stat-modeling-gee.html#post-hoc",
    "href": "stat-modeling-gee.html#post-hoc",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.5 Post hoc",
    "text": "45.5 Post hoc\nWie hier weiter"
  },
  {
    "objectID": "stat-modeling-gee.html#multipler-vergleich-mit-emmeans",
    "href": "stat-modeling-gee.html#multipler-vergleich-mit-emmeans",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.7 Multipler Vergleich mit emmeans\n",
    "text": "45.7 Multipler Vergleich mit emmeans\n\n\nres_gee <- geeglm_fit %>% \n  emmeans(~ treatment) \n\nres_gee_cld <- res_gee %>% \n  cld(adjust = \"bonferroni\", Letters = letters) %>% \n  tidy() %>% \n  select(treatment, estimate, conf.low, conf.high, .group) %>% \n  mutate(across(where(is.numeric), round, 2))\n\nres_gee_cld \n\n# A tibble: 3 x 5\n  treatment  estimate conf.low conf.high .group\n  <chr>         <dbl>    <dbl>     <dbl> <chr> \n1 feed_10        49.4     47.0      51.7 \" a \" \n2 feed_10+10     51.6     49.1      54.0 \" ab\" \n3 feed_20        53.3     51.0      55.6 \"  b\" \n\n\n\nres_gee_tbl <- res_gee %>% \n  contrast(method = \"pairwise\", adjust = \"bonferroni\") %>% \n  tidy(conf.int = TRUE) %>% \n  mutate(p.value = pvalue(adj.p.value),\n         across(where(is.numeric), round, 2)) %>% \n  select(contrast, estimate, p.value,\n         conf.low, conf.high) \n\nres_gee_tbl\n\n# A tibble: 3 x 5\n  contrast               estimate p.value conf.low conf.high\n  <chr>                     <dbl> <chr>      <dbl>     <dbl>\n1 feed_10 - (feed_10+10)    -2.19 0.355      -5.56      1.17\n2 feed_10 - feed_20         -3.93 0.012      -7.2      -0.66\n3 (feed_10+10) - feed_20    -1.73 0.636      -5.06      1.59"
  },
  {
    "objectID": "stat-modeling-gee.html#multipler-vergleich-mit-multcomp-und-geesmv",
    "href": "stat-modeling-gee.html#multipler-vergleich-mit-multcomp-und-geesmv",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.8 Multipler Vergleich mit multcomp und geesmv\n",
    "text": "45.8 Multipler Vergleich mit multcomp und geesmv\n\n\n\ngeesmv: Modified Variance Estimators for Generalized Estimating Equations\nDas R Paket geesmv bietet neun Implementierungen von Schätzern für die Varianz/Covarianzstruktur der Daten an. Jetzt stellt sich die Frage, welche Implementierung denn nun? Zum einen hat natürlich die geschätzte Varianz einen nicht zu unterschätzenden Effekt auf die Signifikanz der Koeffizienten des GEE Models. Zum anderen ist aber der multiple Vergleich nach dem Schätzen des Modells und dem getrennten Schätzen der Varianz sehr mühselig. Leider helfen uns auch unsere Standardpakete nicht so richtig weiter. Die Funktionalität ist nicht für geesmv implementiert. Was wiederum dafür spricht, dass der Bedarf von Anwendern sehr eingeschränkt zu seien scheint. Nun müssen wir folgende epischen Schritte durchführen um einen multiplen Vergleich rechnen zu können.\n\nWir fitten unser geeglm() Modell in der mean parametrization, dass heist wir entfernen den Intercept aus dem Modell und lassen unser Modell somit durch den Urspung laufen. Im Prinzip setzen wir den Intercept auf 0 und erhalten so die Mittelwerte jedes Levels des Faktors treatment.\nWir speichern die \\(\\beta\\)-Koeffizienten von dem treatment aus unserem GEE Modell in einem Objekt ab.\nWir rechnen mit der gleichen Angabe wie vorher das geeglm() Modell eine der neun Funktion. Ich habe hier zufällig die Funktion GEE.var.lz() gewählt. Wir speichern die Ausgabe der Varianz der Koeffizienten in einem Objekt.\nWir kombinieren die \\(\\beta\\)-Koeffizienten und die Varianz in einem Objekt mit der Funktion left_join().\nWir bauen uns unsere eigene Kontrastmatrix in der steht welches Level der Behandlung mit welchen anderen Level verglichen werden soll.\nWir übergeben alle Einzelteile an die Funktion glht() aus dem R Paket multcomp und rechnen unseren multiplen Vergleich.\n\nNa dann mal auf. Gehen wir die Schritte einmal nacheinander durch und schauen, was wir da so alles gemacht haben. Nochmal Achtung, hier musst du wirklich schauen, ob sich der Aufwand lohnt. Ich zeige es hier einmal, den in bestimmten Fällen kann sich eine andere Implementierung für die Schätzung der Varianz durchaus lohnen. Denn aus Erfahrung weiß ich, dass der Standardvarianzschätzer nicht immer der beste Schätzer sein muss (Kruppa und Hothorn 2021).\n\ngeeglm_fit <- geeglm(weight_gain ~ 0 + treatment + treatment * time,\n                     data = pig_gain_tbl, \n                     id = pig_id, \n                     family = gaussian,\n                     corstr = \"exchangeable\")\n\n\nbeta_tbl <- coef(geeglm_fit) %>% \n  enframe\n\n\ngee_lz_vcov <- GEE.var.lz(weight_gain ~ 0 + treatment + treatment * time,\n                          data = as.data.frame(pig_gain_tbl), \n                          id = \"pig_id\",\n                          family = gaussian,\n                          corstr = \"independence\") \n\n        treatmentfeed_10      treatmentfeed_10+10         treatmentfeed_20 \n               56.441300                58.014800                59.820125 \n                    time treatmentfeed_10+10:time    treatmentfeed_20:time \n               -2.358900                 0.207000                 0.182875 \n\nvbeta_tbl <- gee_lz_vcov$cov.beta %>% \n  enframe\n\n\ncoef_tbl <- left_join(beta_tbl, vbeta_tbl, by = \"name\") %>% \n  filter(str_detect(name, \"time\", negate = TRUE)) %>% \n  set_names(c(\"parameter\", \"beta\", \"vbeta\"))\n\n\ncontrMat_n <- setNames(rep(1, length(coef_tbl$parameter)),\n                       coef_tbl$parameter) %>% \n  contrMat(type = \"Tukey\")\n\ncontrMat_n \n\n\n     Multiple Comparisons of Means: Tukey Contrasts\n\n                                       treatmentfeed_10 treatmentfeed_10+10\ntreatmentfeed_10+10 - treatmentfeed_10               -1                   1\ntreatmentfeed_20 - treatmentfeed_10                  -1                   0\ntreatmentfeed_20 - treatmentfeed_10+10                0                  -1\n                                       treatmentfeed_20\ntreatmentfeed_10+10 - treatmentfeed_10                0\ntreatmentfeed_20 - treatmentfeed_10                   1\ntreatmentfeed_20 - treatmentfeed_10+10                1\n\n\n\nmult_gee <- glht(parm(coef = coef_tbl$beta, \n                      vcov = diag(coef_tbl$vbeta)), \n                 linfct = contrMat_n)\nmult_gee$df <- geeglm_fit$df.residual\n\n\nmult_gee %>% \n  tidy(conf.int = TRUE) %>% \n  select(contrast, estimate, conf.low, conf.high, adj.p.value)\n\n# A tibble: 3 x 5\n  contrast                               estimate conf.low conf.high adj.p.value\n  <chr>                                     <dbl>    <dbl>     <dbl>       <dbl>\n1 treatmentfeed_10+10 - treatmentfeed_10     1.57   -2.30       5.45       0.607\n2 treatmentfeed_20 - treatmentfeed_10        3.38   -0.511      7.27       0.103\n3 treatmentfeed_20 - treatmentfeed_10+10     1.81   -1.88       5.49       0.483"
  },
  {
    "objectID": "stat-modeling-gee.html#modellieren-mit-gee",
    "href": "stat-modeling-gee.html#modellieren-mit-gee",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.5 Modellieren mit gee()\n",
    "text": "45.5 Modellieren mit gee()\n\nLeider ist es so, dass wir kaum kontrollieren können, was alles aus den Funktionen in die R Console geschrieben wird. Die Funktionen sind schon recht alt und es gab mal einen Trend, dass eine Funktion immer schön was wiedergeben soll. Das ist natürlich immer etwas nervig, wenn man das nicht will. Wir erhalten also bei der Funktion gee() immer die Koeffizienten des Modells ausgegeben, ob wir es nun in einem Objekt speichern oder auch nicht. Ich finde sowas immer ziemlich nervig.\nAlso wir bauen wir uns unser gee Modell? Zuerst kommt wie immer die formula, da ändert sich nichts. Wir nehmen in unser Modell als Outcome die Gewichtszunahme und als Einflusvariablen dann die Behandlung sowie die Zeit und die Interaktion zwischen der Behandlung und der Zeit. Die Daten sind auch gleich. Erst mit der Option id = ändert sich was. Hier geben wir die Spalte ein, in der die ID’s der Ferkel bzw. der Beobachtungen stehen. Das war es auch schon für den CLustereffekt. Dann nach die Verteilungsfamilie, wir können hier auch für nicht normalverteilte Daten ein GEE schätzen. Zum Abschluss noch die Korrelationsstruktur definiert. Wir nehmen hier exchangeable, diese Korrelationsstruktur ist für den Anfang immer ganz gut und macht auch häufig Sinn.\n\ngee_fit <- gee(weight_gain ~ treatment + treatment * time,\n               data = pig_gain_tbl, \n               id = pig_id, \n               family = gaussian,\n               corstr = \"exchangeable\")\n\n             (Intercept)      treatmentfeed_10+10         treatmentfeed_20 \n               56.441300                 1.573500                 3.378825 \n                    time treatmentfeed_10+10:time    treatmentfeed_20:time \n               -2.358900                 0.207000                 0.182875 \n\n\nNachdem wir das Modell gefittet haben, können wir uns einmal die Korrelationsstruktur anschauen. Da ist die Funktion gee wirklich gut. Die Korrelationsstuktur können wir uns einfach so rausziehen.\n\npluck(gee_fit, \"working.correlation\") %>% \n  round(3)\n\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] 1.000 0.082 0.082 0.082 0.082\n[2,] 0.082 1.000 0.082 0.082 0.082\n[3,] 0.082 0.082 1.000 0.082 0.082\n[4,] 0.082 0.082 0.082 1.000 0.082\n[5,] 0.082 0.082 0.082 0.082 1.000\n\n\nWas sehen wir? Natürlich muss auf der Diagonalen eine 1 stehen, den untereinander sind die Variablen ja identisch und damit mit 1 korreliert. Auf der Nicht-Diagonalen finden wir dann die Korrelation untereinander. Da wir exchangeable für die Korrelationsstruktur gewählt haben, haben wir überall die gleiche Korrelation. Alle Ferkel sind untereinander über die Zeitpunkte gleich mit \\(\\rho = 0.82\\) korreliert.\nWir lassen uns jetzt noch die Modellparameter ausgeben und schauen uns einmal an, ob wir was signifikantes gefunden haben.\n\ngee_fit %>% model_parameters()\n\nParameter                     | Coefficient |   SE |         95% CI |     z |      p\n------------------------------------------------------------------------------------\n(Intercept)                   |       56.44 | 1.23 | [52.53, 60.35] | 28.27 | < .001\ntreatment [feed_10+10]        |        1.57 | 1.65 | [-3.96,  7.11] |  0.56 | 0.341 \ntreatment [feed_20]           |        3.38 | 1.66 | [-2.16,  8.91] |  1.20 | 0.041 \ntime                          |       -2.36 | 0.19 | [-3.49, -1.22] | -4.07 | < .001\ntreatment [feed_10+10] * time |        0.21 | 0.24 | [-1.40,  1.81] |  0.25 | 0.386 \ntreatment [feed_20] * time    |        0.18 | 0.25 | [-1.42,  1.79] |  0.22 | 0.456 \n\n\nWir sehen, dass es einen signifikanten Unterschied in der Zeit gibt, das war ja auch zu erwarten, denn mit der Zeit werden die Ferkel schwerer. Wir haben aber auch einen schwach signifikanten Effekt zwischen feed_10 und feed_20 mit einem \\(p\\)-Wert von \\(0.041\\). Hier machen wir kurz Stop, dann geht es aber in dem Abschnitt zu den Posthoc Tests mit dem Modell weiter. Wir wollen ja noch für alle Behanlungslevel einen paarweisen Vergleich rechnen."
  },
  {
    "objectID": "stat-modeling-gee.html#modellieren-mit-geeglm",
    "href": "stat-modeling-gee.html#modellieren-mit-geeglm",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "\n45.6 Modellieren mit geeglm()\n",
    "text": "45.6 Modellieren mit geeglm()\n\n\ngeeglm_fit <- geeglm(weight_gain ~ treatment + treatment * time,\n                     data = pig_gain_tbl, \n                     id = pig_id, \n                     family = gaussian,\n                     corstr = \"exchangeable\")\n\n\ngeeglm_fit %>% model_parameters()\n\nParameter                     | Coefficient |   SE |         95% CI | Chi2(1) |      p\n--------------------------------------------------------------------------------------\n(Intercept)                   |       56.44 | 1.23 | [54.04, 58.84] | 2120.76 | < .001\ntreatment [feed_10+10]        |        1.57 | 1.65 | [-1.66,  4.81] |    0.91 | 0.341 \ntreatment [feed_20]           |        3.38 | 1.66 | [ 0.13,  6.62] |    4.17 | 0.041 \ntime                          |       -2.36 | 0.19 | [-2.73, -1.99] |  153.65 | < .001\ntreatment [feed_10+10] * time |        0.21 | 0.24 | [-0.26,  0.67] |    0.75 | 0.386 \ntreatment [feed_20] * time    |        0.18 | 0.25 | [-0.30,  0.66] |    0.56 | 0.456"
  },
  {
    "objectID": "stat-modeling-logistic.html",
    "href": "stat-modeling-logistic.html",
    "title": "43  Logistische Regression",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:48:39"
  },
  {
    "objectID": "stat-modeling-logistic.html#annahmen-an-die-daten",
    "href": "stat-modeling-logistic.html#annahmen-an-die-daten",
    "title": "43  Logistische Regression",
    "section": "\n43.1 Annahmen an die Daten",
    "text": "43.1 Annahmen an die Daten\nUnser gemessenes Outcome \\(y\\) folgt einer Binomialverteilung. Damit finden wir im Outcome nur \\(0\\) oder \\(1\\) Werte.\nIm folgenden Kapitel zu der multiplen logistischen linearen Regression gehen wir davon aus, dass die Daten in der vorliegenden Form ideal sind. Das heißt wir haben weder fehlende Werte vorliegen, noch haben wir mögliche Ausreißer in den Daten. Auch wollen wir keine Variablen selektieren. Wir nehmen alles was wir haben mit ins Modell. Sollte eine oder mehre Bedingungen nicht zutreffen, dann schaue dir einfach die folgenden Kapitel an.\n\nWenn du fehlende Werte in deinen Daten vorliegen hast, dann schaue bitte nochmal in das Kapitel 38 zu Imputation von fehlenden Werten.\nWenn du denkst, dass du Ausreißer oder auffälige Werte in deinen Daten hast, dann schaue doch bitte nochmal in das Kapitel 36 zu Ausreißer in den Daten.\nWenn du denkst, dass du zu viele Variablen in deinem Modell hast, dann hilft dir das Kapitel 36 bei der Variablenselektion.\n\nDaher sieht unser Modell wie folgt aus. Wir haben ein \\(y\\) und \\(p\\)-mal \\(x\\). Wobei \\(p\\) für die Anzahl an Variablen auf der rechten Seite des Modells steht. Im Weiteren folgt unser \\(y\\) einer Binomailverteilung. Damit finden wir im Outcome nur \\(0\\) oder \\(1\\) Werte. Das ist hier sehr wichtig, denn wir wollen ja eine multiple logistische lineare Regression rechnen.\n\\[\ny \\sim x_1 + x_2 + ... + x_p\n\\]\nWir können in dem Modell auch Faktoren \\(f\\) haben, aber es geht hier nicht um einen Gruppenvergleich. Das ist ganz wichtig. Wenn du einen Gruppenvergleich rechnen willst, dann musst du in Kapitel 31 nochmal nachlesen."
  },
  {
    "objectID": "stat-modeling-logistic.html#genutzte-r-pakete-für-das-kapitel",
    "href": "stat-modeling-logistic.html#genutzte-r-pakete-für-das-kapitel",
    "title": "43  Logistische Regression",
    "section": "\n43.2 Genutzte R Pakete für das Kapitel",
    "text": "43.2 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               parameters, performance, gtsummary)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"extract\", \"magrittr\")\ncbbPalette <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "stat-modeling-logistic.html#daten",
    "href": "stat-modeling-logistic.html#daten",
    "title": "43  Logistische Regression",
    "section": "\n43.3 Daten",
    "text": "43.3 Daten\n\npig_tbl <- read_excel(\"data/infected_pigs.xlsx\") \n\n\n\n\n\nTabelle 43.1— Auszug aus dem Daten zu den kranken Ferkeln.\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nlocation\nactivity\ncrp\nfrailty\nbloodpressure\nweight\ncreatinin\ninfected\n\n\n\n61\nmale\nnortheast\n15.31\n22.38\nrobust\n49.88\n16.94\n3.07\n1\n\n\n53\nmale\nnorthwest\n13.01\n18.64\nrobust\n58.2\n17.95\n4.88\n0\n\n\n66\nfemale\nnortheast\n11.31\n18.76\nrobust\n56.8\n19.02\n3.98\n0\n\n\n59\nfemale\nnorth\n13.33\n19.37\nrobust\n56.47\n18.98\n5.18\n0\n\n\n63\nmale\nnorthwest\n14.71\n21.57\nrobust\n59.85\n16.57\n6.71\n1\n\n\n55\nmale\nnorthwest\n15.81\n21.45\nrobust\n58.1\n18.22\n5.43\n1\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n54\nfemale\nnorth\n11.82\n21.5\nrobust\n57.05\n17.95\n6.16\n1\n\n\n56\nmale\nwest\n13.91\n20.8\npre-frail\n50.84\n18.02\n6.52\n1\n\n\n57\nmale\nnorthwest\n12.49\n21.95\nrobust\n55.51\n17.73\n3.94\n1\n\n\n61\nmale\nnorthwest\n15.26\n23.1\nrobust\n58.5\n18.23\n2.73\n1\n\n\n59\nfemale\nnorth\n13.13\n20.23\npre-frail\n57.33\n17.21\n5.42\n1\n\n\n63\nfemale\nnorth\n10.01\n19.89\nrobust\n55.85\n17.76\n6.18\n1"
  },
  {
    "objectID": "stat-modeling-logistic.html#theoretischer-hintergrund",
    "href": "stat-modeling-logistic.html#theoretischer-hintergrund",
    "title": "43  Logistische Regression",
    "section": "\n43.4 Theoretischer Hintergrund",
    "text": "43.4 Theoretischer Hintergrund\nModellierung der Wahrscheinlichkeit für den Eintritt des Ereignisses\n\\[\nY \\rightarrow Pr(Y = 1)\n\\]\n\\(Pr(Y = 1)\\) liegt zwischen \\(0\\) un \\(1\\)\n\\(\\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}\\) oder auch Chance (eng. Odds) für das Eintreten von \\(Y=1\\) liegt zwischen \\(0\\) und \\(+\\infty\\)\n\\(\\log\\left(\\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}\\right)\\) liegt zwischen \\(-\\infty\\) und \\(+\\infty\\)\n\\(\\log\\left(\\cfrac{Pr(y = 1)}{1 - Pr(Y = 1)}\\right) = \\beta_0 + \\beta_1 x_1 + \\epsilon\\)\nWahrscheinlichkeit: Anteil an Allen Anteil Gewinner an allen Teilnehmern Anteil Personen mit Therapieerfolg an allen Studienteilnehmern\nChance = Odds: Verhältnis Verhältnis Gewinner zu Nichtgewinner Verhältnis Personen mit Therapieerfolg zu Personen ohne Therapieerfolg\n2 Kombinationen gewinnen - 3 Kombinationen verlieren Wahrscheinlichkeit zu gewinnen: \\(2 / 5 = 0.40\\) Chance zu gewinnen: \\(2:3 = 0.67\\) Deutlicherer Unterschied zwischen Chance und Wahrscheinlichkeit"
  },
  {
    "objectID": "stat-modeling-logistic.html#modellierung",
    "href": "stat-modeling-logistic.html#modellierung",
    "title": "43  Logistische Regression",
    "section": "\n43.5 Modellierung",
    "text": "43.5 Modellierung\n\nfit_1 <- glm(infected ~ age + sex + location + activity + crp + frailty + bloodpressure + weight + creatinin, \n             data = pig_tbl, family = binomial)\n\n\nmodel_parameters(fit_1, exponentiate = TRUE)\n\nParameter            | Odds Ratio |       SE |       95% CI |     z |      p\n----------------------------------------------------------------------------\n(Intercept)          |   1.31e-13 | 5.81e-13 | [0.00, 0.00] | -6.70 | < .001\nage                  |       1.03 |     0.03 | [0.98, 1.09] |  1.10 | 0.272 \nsex [male]           |       2.75 |     1.00 | [1.36, 5.69] |  2.77 | 0.006 \nlocation [northeast] |       0.56 |     0.20 | [0.28, 1.12] | -1.63 | 0.103 \nlocation [northwest] |       0.66 |     0.22 | [0.34, 1.25] | -1.28 | 0.202 \nlocation [west]      |       0.79 |     0.29 | [0.38, 1.62] | -0.64 | 0.520 \nactivity             |       0.90 |     0.09 | [0.75, 1.09] | -1.08 | 0.281 \ncrp                  |       2.97 |     0.35 | [2.38, 3.78] |  9.25 | < .001\nfrailty [pre-frail]  |       0.64 |     0.27 | [0.28, 1.44] | -1.06 | 0.288 \nfrailty [robust]     |       0.70 |     0.28 | [0.32, 1.51] | -0.89 | 0.376 \nbloodpressure        |       1.12 |     0.04 | [1.03, 1.21] |  2.77 | 0.006 \nweight               |       1.10 |     0.10 | [0.92, 1.30] |  1.05 | 0.293 \ncreatinin            |       1.03 |     0.09 | [0.86, 1.23] |  0.33 | 0.745 \n\n\n\nr2(fit_1)\n\n# R2 for Logistic Regression\n  Tjur's R2: 0.322\n\n\nTabelle 43.2\n\npig_tbl %>% tbl_summary(by = infected) %>% add_p() %>% as_flex_table()\n\n\n\n\n\n\nTabelle 43.2—  . \n\nCharacteristic\n0, N = 1551\n1, N = 2571\np-value2\n\n\n\nage\n60.0 (57.0, 63.0)\n60.0 (57.0, 63.0)\n0.5\n\n\nsex\n\n\n0.3\n\n\nfemale\n66 (43%)\n95 (37%)\n\n\n\nmale\n89 (57%)\n162 (63%)\n\n\n\nlocation\n\n\n0.6\n\n\nnorth\n40 (26%)\n81 (32%)\n\n\n\nnortheast\n33 (21%)\n51 (20%)\n\n\n\nnorthwest\n51 (33%)\n73 (28%)\n\n\n\nwest\n31 (20%)\n52 (20%)\n\n\n\nactivity\n13.35 (12.29, 14.34)\n13.24 (12.25, 14.53)\n0.7\n\n\ncrp\n19.12 (18.17, 19.92)\n20.66 (19.85, 21.46)\n<0.001\n\n\nfrailty\n\n\n0.7\n\n\nfrail\n20 (13%)\n33 (13%)\n\n\n\npre-frail\n54 (35%)\n79 (31%)\n\n\n\nrobust\n81 (52%)\n145 (56%)\n\n\n\nbloodpressure\n56.8 (53.9, 58.6)\n57.0 (54.9, 59.0)\n0.10\n\n\nweight\n18.36 (17.32, 19.34)\n18.33 (17.36, 19.44)\n0.9\n\n\ncreatinin\n4.82 (4.06, 5.88)\n4.97 (3.97, 5.87)\n0.8\n\n\n\n1Median (IQR); n (%)\n2Wilcoxon rank sum test; Pearson's Chi-squared test\n\n\n\n\n\n\nTabelle 43.3\n\nfit_1 %>% tbl_regression(exponentiate = TRUE) %>% as_flex_table()\n\n\n\n\n\n\nTabelle 43.3—  . \n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\nage\n1.03\n0.98, 1.09\n0.3\n\n\nsex\n\n\n\n\n\nfemale\n—\n—\n\n\n\nmale\n2.75\n1.36, 5.69\n0.006\n\n\nlocation\n\n\n\n\n\nnorth\n—\n—\n\n\n\nnortheast\n0.56\n0.28, 1.12\n0.10\n\n\nnorthwest\n0.66\n0.34, 1.25\n0.2\n\n\nwest\n0.79\n0.38, 1.62\n0.5\n\n\nactivity\n0.90\n0.75, 1.09\n0.3\n\n\ncrp\n2.97\n2.38, 3.78\n<0.001\n\n\nfrailty\n\n\n\n\n\nfrail\n—\n—\n\n\n\npre-frail\n0.64\n0.28, 1.44\n0.3\n\n\nrobust\n0.70\n0.32, 1.51\n0.4\n\n\nbloodpressure\n1.12\n1.03, 1.21\n0.006\n\n\nweight\n1.10\n0.92, 1.30\n0.3\n\n\ncreatinin\n1.03\n0.86, 1.23\n0.7\n\n\n1OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\nWir können uns einmal die Ergebnisse des Modellfits die logistischen Gerade für eine simple lineare Regression mit dem Modell \\(infected \\sim crp\\) anschauen. Wie immer können wir uns den Zusammenhang nur in einem simplen Modell anschauen. Im Fall einer multiplen linearen Regresion können wir nicht so viele Dimensionen in einer Grpahik darstellen. Wir fitten also das Modell fit_2 wie im folgenden dargestellt.\n\nfit_2 <- glm(infected ~ crp, data = pig_tbl, family = binomial)\n\nNun können wir uns mit der Funktion predict() die Wert auf der Geraden wiedergeben lassen. Wenn wir predict() nur so aufrufen, dann erhalten wir die Werte für \\(y\\) auf der transformierten \\(link\\)-Scale wieder. Das hilft uns aber nicht weiter, wir haben ja nur 0 und 1 Werte für \\(y\\) vorliegen.\n\npredict(fit_2, type = \"link\") %>% \n  extract(1:10) %>% \n  round(2)\n\n    1     2     3     4     5     6     7     8     9    10 \n 3.03 -0.73 -0.61  0.00  2.22  2.10 -0.39 -0.39  2.54  1.60 \n\n\nDa wir die Werte für die Wahrscheinlichkeit das ein Ferkel infiziert ist, also die Wahrscheinlichkeit \\(Pr(infected = 1)\\), müssen wir noch die Option type = reponse wählen. So erhalten wir die Wahrscheinlichkeiten wiedergegeben.\n\npredict(fit_2, type = \"response\") %>% \n  extract(1:10) %>% \n  round(2)\n\n   1    2    3    4    5    6    7    8    9   10 \n0.95 0.33 0.35 0.50 0.90 0.89 0.40 0.40 0.93 0.83 \n\n\nAbschließend können wir uns die Gerade auch in der Abbildung 43.1 visualisieren lassen. Auf der x-Achse sehen wir die crp-Werte und auf der y-Achse den Infektionsstatus. Auf der \\(reponse\\)-scale sehen wir eine S-Kurve. Auf der \\(link\\)-scale würden wir eine Gerade sehen.\n\nggplot(pig_tbl, aes(x = crp, y = infected)) +\n  theme_bw() +\n  geom_point() +\n  geom_line(aes(y = predict(fit_2, type = \"response\")), color = \"red\") \n\n\n\nAbbildung 43.1— Visualisierung der logistischen Gerade in einer simplen logistischen Regression mit der Variable crp."
  },
  {
    "objectID": "stat-modeling-gee.html#referenzen",
    "href": "stat-modeling-gee.html#referenzen",
    "title": "45  Generalized Estimating Equations (GEE)",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nAllison, Paul D. 2009. Fixed effects regression models. SAGE publications.\n\n\nKruppa, Jochen, und Ludwig Hothorn. 2021. „A comparison study on modeling of clustered and overdispersed count data for multiple comparisons“. Journal of Applied Statistics 48 (16): 3220–32."
  },
  {
    "objectID": "stat-modeling-mixed.html#referenzen",
    "href": "stat-modeling-mixed.html#referenzen",
    "title": "44  Lineare gemischte Modelle",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nAllison, Paul D. 2009. Fixed effects regression models. SAGE publications."
  },
  {
    "objectID": "experimental-design-preface.html",
    "href": "experimental-design-preface.html",
    "title": "Experimentelles Design",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:49:06\nWas ist ein experimentelles Design? Wir unterscheiden zuerst nach dem Organismus, den wir uns anschauen. Wenn wir über Tiere und Pflanzen sprechen, dann haben wir meist ein feststehendes experimentelles Design. Wir haben ein Feldexperiment vorliegen, dass natürlich mit Tieren auch in einem Stall stattfinden kann. Wenn wir uns Menschen betrachten, dann haben wir eine klinische Studie vorliegen. Wir werden uns in den folgenden Kapiteln erstmal nur mit dem experimentellen Design für Pflanzen und Tiere beschäftigen. Der große Unterschied its zum einen ethischer Natur und rein praktisch, dass sich Menschen frei bewegen können und Pflanzen sowie Tiere in einem Experiement nicht. Ja, es gibt natürlich noch weitreichende moralische und ethische Unterschiede. Deshalb jetzt erstmal das klassische Feldexperiement."
  },
  {
    "objectID": "experimental-design-preface.html#übersicht-der-experimentellen-designs",
    "href": "experimental-design-preface.html#übersicht-der-experimentellen-designs",
    "title": "Experimentelles Design",
    "section": "Übersicht der experimentellen Designs",
    "text": "Übersicht der experimentellen Designs\nWir schauen uns in den folgenden Kapiteln einmal eine Auswahl an experimentellen Designs an. Im Laufe derZeit werden sicherlich noch andere Designs ergänzt werden. Soweit erstmal diese Auswahl hier.\n\nDas Complete randomized design findest du in Kapitel 47.2. Das Complete randomized design ist der Klassiker unter den experimentellen Designs und wird häufig verwendet.\nDas Randomized vomplete block design findest du in Kapitel 47.3. Das Randomized vomplete block design ist entweder eine Erweiterung des Complete randomized design oder aber bringt noch eine neuen Faktor für die Wiederholung mit in das Experiment mit ein.\nDas Latin square design findest du in Kapitel 47.4. Das Latin square design liefert eine gleichmäßige Aufteilung der experimentellen Einheiten über ein Feld oder ein Stall.\nDas Alpha design findest du in Kapitel 47.5 und ist eine etwas komplexere Einteilung für die Randomisierung.\nDas Augmented design findest du in Kapitel 47.8. Das Augmented design wird seltener genutzt.\nDas Splot plot design findest du in Kapitel 47.7. Das Splot plot design gibt es in vielen Varianten. Wir schauen uns hier eine der häufigsten Varianten einmal an. Je nachdem wie man die Plots anordnet ergibt sich dann auch teilweise ein anderes Splot plot design.\n\nDormann (2013) und Hurlbert (1984)"
  },
  {
    "objectID": "experimental-design-preface.html#referenzen",
    "href": "experimental-design-preface.html#referenzen",
    "title": "Experimentelles Design",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\nDormann, Carsten F. 2013. Parametrische Statistik. Springer.\n\n\nHurlbert, Stuart H. 1984. „Pseudoreplication and the design of ecological field experiments“. Ecological monographs 54 (2): 187–211."
  },
  {
    "objectID": "experimental-design-basic.html",
    "href": "experimental-design-basic.html",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "",
    "text": "Version vom November 08, 2022 um 08:49:12\nIn diesem Kapitel wollen wir uns mit der Auswertung von verschiedenen experiemnetellen Designs beschäftigen. Wir schauen uns dafür jeweils eine mögliche Visualisierung an und bauen uns dann die Daten künstlich nach. Warum eigentlich künstliche Daten? Das heist wir erschaffen uns Daten wo wir genau wissen, wie der Mittelwert und die Standardabweichungen in den einzelnen Gruppen sind. Warum ist das hilfreich? Dadurch das wir wissen, dass der Mittelwertsunterschied zwischen Gruppe \\(A\\) und Gruppe \\(B\\) mit dem Effekt von \\(\\Delta_{A-B} = 5\\) erschaffen wurde, können wir dann auch die Ausgaben der Funktionen besser bewerten."
  },
  {
    "objectID": "experimental-design-basic.html#genutzte-r-pakete-für-das-kapitel",
    "href": "experimental-design-basic.html#genutzte-r-pakete-für-das-kapitel",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.1 Genutzte R Pakete für das Kapitel",
    "text": "47.1 Genutzte R Pakete für das Kapitel\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, conflicted, broom,\n               see, emmeans, multcomp, scales, performance,\n               effectsize, parameters)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"mutate\", \"dplyr\")\ncbbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nAm Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren."
  },
  {
    "objectID": "experimental-design-basic.html#sec-crd",
    "href": "experimental-design-basic.html#sec-crd",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.2 Complete randomized design (CRD)",
    "text": "47.2 Complete randomized design (CRD)\nDas komplette randomizierte Design (eng. complete randomized design) ist das simpleste Felddesign was wir anzubieten haben. Wir haben einen Stall oder ein Feld oder einen Tisch und unterteilen diesen Raum zufällig in Untereinheiten. Auf oder in jeder Untereinheit bringen wir dann eine Behandlung aus.\n\n\nAbbildung 47.1— Visualisierung des complete randomized design mit einer Behandlung und vier Behandlungsleveln.\n\n\nWir haben einen Tisch und stellen Töpfe mit Pflanzen auf den Tisch. Jeder Topf erhält zufällig eine Behandlung. Wir haben gleich viele Töpfe mit Pflanzen für jede Behandlung.\nWir haben einen Stall mit Buchten für Schweine. Jede Bucht erhält eine zufällige Behandlung. Wir haben gleich viele Buchten für jede Behandlung.\nWir haben ein Feld und erschaffen Parzellen auf dem Feld. Auf jeder Parzelle wird zufällig eine Variante ausgebracht. Wir haben geich viele Parzellen für jede Variante.\nSchauen wir uns das Complete randomized design einmal an einem konkreten Beispiel an. Wir nutzen dafür einen Faktor mit der Behandlung. Die Behandlung hat vier Level mit den einzelnen Leveln \\(A\\), \\(B\\), \\(C\\) und \\(D\\).\n\n47.2.1 Visualisierung\nIn Abbildung 47.2 sehen wir die Visualisierung unseres Versuches. Wir haben einen großen Raun in dem sich zufällig die Level der Behandlung drauf verteilen. Hierbei ist es wichtig zu verstehen, dass die Anordnung rein zufällig ist. Wir sehen, dass jedes Level der Behandlung mit \\(n = 5\\) auf das Feld aufgebracht wurde. Wir haben also ein balanciertes Design mit \\(N = 20\\) Beobachtungen. Wir könnten hier auch einen Tisch mit \\(n=20\\) Pflanzentöpfen vorliegen haben oder einen Stall mit \\(n = 20\\) Buchten.\n\n\nAbbildung 47.2— Visualisierung des complete randomized design mit einer Behandlung und vier Behandlungsleveln.\n\n\n\n47.2.2 Daten\nIm Folgenden bauen wir uns die Daten für das Complete randomized design. Dafür nuten wir die Funktion rnorm(). Die Funktion rnorm() erlaubt es aus einer Normalverteilung n Beobachtungen mit einem Mittelwert mean und einer Standardabweichung sd zu ziehen. Wir erschaffen uns so vier Behandlungsgruppen \\(A\\) bis \\(D\\) mit jeweils unterschiedlichen Mittelwerten von \\(\\bar{y}_A = 10\\), \\(\\bar{y}_B = 12\\), \\(\\bar{y}_C = 16\\) und \\(\\bar{y}_D = 20\\) sowie homogenen Varianzen mit \\(s_A = s_B = s_C = s_D = 2\\). Jede Behandlung hat \\(n = 5\\) Beobachtungen. Wir haben also ein balanziertes Design vorliegen.\n\nset.seed(20220916)\ncrd_tbl <- tibble(A = rnorm(n = 5, mean = 10, sd = 2),\n                  B = rnorm(n = 5, mean = 12, sd = 2),\n                  C = rnorm(n = 5, mean = 16, sd = 2),\n                  D = rnorm(n = 5, mean = 20, sd = 2)) %>% \n  gather(key = trt, value = rsp) %>% \n  mutate(trt = as_factor(trt))\n\nSchauen wir uns einmal die Daten an, die wir in R erhalten. Das Objekt crd_tbl ist ein tibble in Long-Format nach der Anwendung der Funktion gather(). Wir haben auch die Spalte trt für die Behanldung als Faktor umgewandelt.\n\ncrd_tbl\n\n# A tibble: 20 x 2\n   trt     rsp\n   <fct> <dbl>\n 1 A     12.3 \n 2 A     11.0 \n 3 A     13.4 \n 4 A     13.2 \n 5 A      4.27\n 6 B     12.2 \n 7 B     11.4 \n 8 B     15.4 \n 9 B      9.51\n10 B     11.9 \n11 C     13.1 \n12 C     15.4 \n13 C     16.3 \n14 C     19.0 \n15 C     19.4 \n16 D     20.9 \n17 D     17.8 \n18 D     20.6 \n19 D     24.6 \n20 D     17.5 \n\n\nWir haben also \\(N = 20\\) Beobachtungen vorliegen. Wir immer ist es schwer eine Datentabelle zu erfasen. Daher schauen wir uns die Daten einmal in Abbildung 47.3 als Boxplots an. Wir wolllen uns noch die Punkte zusätzlich anzeigen lassen. bei der geringen Anzahl an Beobachtungen wäre ein Dotplot oder ein Scatterplot auch eine Möglichkeit.\n\nggplot(crd_tbl, aes(trt, rsp, fill = trt)) +\n  theme_bw() +\n  geom_boxplot() +\n  geom_jitter(width = 0.2, shape = 4, size = 3) +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() \n\n\n\nAbbildung 47.3— Boxplots der Behandlungsgruppen zufällig aus einer Normalverteilung mit Varianzhomogenität generierten Daten.\n\n\n\n\nWir erinnern uns, dass die Daten alle varianzhomogen und normalverteilt sind. Wir haben die Daten so erschaffen. Dennoch wirken die Boxplots so, als würde teilweise eine schiefe Verteilung vorliegen. Bei so wenigen Beobachtungen ist es immer schwer, für oder gegen eine Verteilung zu argumentieren. Wir bleiben bei einer Normalverteilung, wenn wir glauben, dass das \\(y\\) approimativ normalverteilt ist. Wir schreiben dann, dass wir ein normalverteiltes \\(y\\) annehmen.\n\n47.2.3 Modellierung\nIm Folgenden wollen wir die Daten modellieren. Das heist wir wollen eine Linie durch eine multidimensionale Punktewolke zeichnen. Daher auch lineares Modell oder eben durch die Funktion lm() in R für linear model. Wir nutzen das Paket parameters und die Funktion model_parameters() um uns die Parameter des Modells auszugeben. Wir könnten auch die Funktion tidy() nutzen, aber wir erhalten durch die Funktion model_parameters() etwas mehr Informationen und bessere Spaltenüberschriften.\nWir bauen das Modell in folgender Form. Wir haben ein numerisches Outcome \\(y\\) sowie einen Faktor \\(f_1\\).\n\\[\ny \\sim f_1\n\\]\nNun können wir das abstrakte Modell in die Daten übersetzen und erhalten folgendes Modell.\n\\[\nrsp \\sim trt\n\\]\nDas heist, unsere numerische Variable rsp hängt ab von unserer faktoriellen Variable trt. Wir müssen immer wissen, wie die Spaltennamen in unserem Datensatz crd_tbl lauten sonst kann R die Spalten nicht finden.\n\nfit_crd <- lm(rsp ~ trt, crd_tbl)\n\nfit_crd %>%  model_parameters()\n\nParameter   | Coefficient |   SE |         95% CI | t(16) |      p\n------------------------------------------------------------------\n(Intercept) |       10.83 | 1.30 | [ 8.07, 13.59] |  8.33 | < .001\ntrt [B]     |        1.25 | 1.84 | [-2.65,  5.15] |  0.68 | 0.506 \ntrt [C]     |        5.80 | 1.84 | [ 1.90,  9.70] |  3.15 | 0.006 \ntrt [D]     |        9.47 | 1.84 | [ 5.57, 13.37] |  5.15 | < .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\nÜberlege mal, was die Spalte Coefficient aussagen möchte. Wir erhalten den (Intercept) mit \\(10.38\\) und damit den MIttelwert der Gruppe \\(A\\). In den folgenden Zeilen sind die Änderungen zu dem (Intercept) und damit zu der Gruppe \\(A\\) dargestellt. Da wir nur eine sehr kleine Anzhl an Beoabchtungen haben, haben wir hier auch Abweichungen zu den voreingestellten Mittelwerten und Standardabweichungen. Wir schauen uns ja auch nur eine Realisierung von möglichen Daten \\(D\\) an. Wir sehen, dass alle Koeffizienten signifikant und damit unterschiedlich von der Null sind. Der \\(p\\)-Wert ist kleiner als das Signiifkanzniveau von \\(\\alpha\\) gleich 5%.\nWir können jetzt nochmal überprüfen, ob die Residuen die Annahme der Varianzhomogenität erfüllen.\n\nfit_crd %>% check_homogeneity()\n\nOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.737).\n\n\nSowie ob die Residuen normalverteilt sind.\n\nfit_crd %>% check_normality()\n\nOK: residuals appear as normally distributed (p = 0.620).\n\n\nDa wir ja hiermit nur eine Zeile Text produziert haben und darübr hinaus wir gerne uns Dinge anschauen, können wir auch die Residuen einmal visualisieren. In Abbildung 47.4 sehen wir den QQ-Plot der Residuen sowie die Verteilung unserer Residuen in einem Desnityplot. Wir sehen, dass die Residuen einer Normalverteilung folgen.\n\ncheck_model(fit_crd, check = c(\"qq\", \"normality\"))\n\n\n\nAbbildung 47.4— QQ-Plot und Densityplot der Residuen aus dem lineare Modell.\n\n\n\n\nWunderbar. Wir können jetzt eine Varianzanalyse und dann eine Mittelwertsvergleich durchführen. Achtung, wir können uns hier auch etwas in die Ecke testen. Wenn wir nur lange genug neue Daten generieren, werden wir irgendwann auch einen Datensatz finden, der die Varianzhomogenität und die Normalverteilung ablehnt. Das liegt in der Theorie des statistischen Testens sowie der kleinen Fallzahl verborgen. Deshalb können wir im Zweifel gerne einmal deine Vortests in dem R Tutorium oder in einer statistischen Beratung diskutieren.\n\n47.2.4 Varianzanalyse und Mittelwertsvergleich\nDie einfaktorielle Varianzanalyse ist ziemlich einfach und ergibt sich fast von alleine. Wir nehmen das Objekt des Modells und pipen das Modell in die Funktion anova(). Wir lassen uns dann wieder die Modellparameter der ANOVA widergeben.\n\nres_anova <- fit_crd %>% \n  anova() \n\nres_anova %>% model_parameters()\n\nParameter | Sum_Squares | df | Mean_Square |     F |      p\n-----------------------------------------------------------\ntrt       |      283.24 |  3 |       94.41 | 11.16 | < .001\nResiduals |      135.35 | 16 |        8.46 |       |       \n\nAnova Table (Type 1 tests)\n\n\nWir sehen, dass der Faktor Behandlung signifkant ist, da der \\(p\\)-Wert kleiner ist als das Signifkanzniveau \\(\\alpha\\) gleich 5%. Wir können damit die Nullhypothese ablehnen, wir haben zumindestens einen paarweisen Gruppenunterschied in der Behandlung. Welchen wissen wir nicht, dafür machen wir dann die paarweisen Vergleiche. Eigentlich können wir uns in diesem simplen Fall die ANOVA schhenken und gleich den Mittelwertsvergleich rechnen. Aber das es Usus ist und auch in vielen Abschlussarbeiten verlangtt wird, machen wir hier es einfach mal gleich mit.\nJetzt brauchen wir nur noch die Effektstärke der ANOVA, also wieviel Varianz eigentlich der Faktor Behandlung erklärt. Dfür nutzen wir die Funktion eta_squared() aus dem Paket effectsize.\n\nres_anova %>% eta_squared(partial = FALSE)\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 |       95% CI\n-------------------------------\ntrt       | 0.68 | [0.38, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nMit einem \\(\\eta^2\\) von \\(0.86\\) wissen wir, dass 86% der Varianz von dem Faktor Behandlung erklärt wird. Das wundert uns nicht, denn wir haben ja nur den Faktor Behandlung in unseren Daten aus denen sich unser Outcome ergibt.\nNachdem wir kurz die ANOVA gerechnet haben, wollen wir noch den Mittelwertsvergleich rechnen. Wir nutzen dazu das Paket emmeans. Wir müssen der Funktion emmeans() ein Objekt aus einem Modell übergeben und der Funktion mitteilen, was der Faktor ist mit dem der Vergleich gerechnet werden soll. Wir haben hier den Faktor trt vorliegen und wollen einen parweisen Vergleich über alle Level des Faktors rechnen.\n\nres_crd <- fit_crd %>% \n  emmeans(~ trt) \n\nWir haben die Ausgabe der Funktion emmeans() in dem Objekt res_crd gespeichert und nutzen das Objekt zuerst um einmal die Ausgabe für das comapct letter display zu erhalten. Als Adjustierung des \\(\\alpha\\) Fehlers nutzen wir die Adjustierung nach Bonferroni. Es sind auch andere Adjustierungen möglich, aber aus Gründen der Einfachheit nehmen wir hier mal den Klassiker der Adjustierung. Je nach Fragestellung gibt es sicherlich auch eine bessere Alternative für Bonferroni.\n\nres_crd_cld <- res_crd %>% \n  cld(adjust = \"bonferroni\", Letters = letters) %>% \n  tidy() %>% \n  select(trt, estimate, conf.low, conf.high, .group) %>% \n  mutate(across(where(is.numeric), round, 2))\n\nNachdem wir noch ein wenig gerundet haben und die Spalten passend gewählt, erhalten wir dann folgende Ausgabe.\n\nres_crd_cld \n\n# A tibble: 4 x 5\n  trt   estimate conf.low conf.high .group\n  <chr>    <dbl>    <dbl>     <dbl> <chr> \n1 A         10.8     7.17      14.5 \" a  \"\n2 B         12.1     8.42      15.7 \" ab \"\n3 C         16.6    13.0       20.3 \"  bc\"\n4 D         20.3    16.6       24.0 \"   c\"\n\n\nWir nutzen die Ausgabe res_crd_cld direkt in der Abbildung 47.5 um uns das compact letter display zusammen mit den Daten und den entsprechenden 95% konfidenzintervallen anzeigen zu lassen. Der Code ist etwas länger, da wir hier verschiedene Schichten von einem geom übereinander legen müssen.\n\nggplot() +\n  theme_bw() +\n  geom_point(data = crd_tbl, aes(x = trt, y = rsp, fill = trt)) +\n  geom_text(data = res_crd_cld, \n            aes(x = trt , y = estimate, label = .group),\n            position = position_nudge(x = 0.2), color = \"red\") +\n  geom_errorbar(data = res_crd_cld,\n                aes(ymin = conf.low, ymax = conf.high, x = trt),\n                color = \"red\", width = 0.1,\n                position = position_nudge(x = 0.1)) +\n  geom_point(data = res_crd_cld, \n             aes(x = trt , y = estimate),\n             position = position_nudge(x = 0.1), color = \"red\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Behandlung\", y = \"Gewicht [kg/ha]\",\n       caption = \"Schwarze Punkte stellen die Rohdaten dar.\n       Rote Punkte und Fehlerbalken stellen bereinigte Mittelwerte mit 95% Konfidenzgrenzen pro Behandlung dar.\n       Mittelwerte, mit einem gemeinsamen Buchstaben, sind nicht signifikant unterschiedlich.\")\n\n\n\nAbbildung 47.5— Scatterplot der Behandlungsgruppen zusammen mit den 95% Konfidenzintervall und dem compact letter display.\n\n\n\n\nWi sehen an dem compact letter display, dass sich die Behandlung \\(A\\) von der Behandlung \\(B\\), \\(C\\) und \\(D\\) unterscheidet. Die Behandlung \\(B\\) und \\(C\\) sind gleich. Die Behandlung \\(C\\) unterschdeit sich von all den anderen Behandlungen. Wir erinnern uns, wenn die Buchstaben in dem compact letter display gleich sind, dann können wie die Nullhypothese für diese Vergleiche nicht ablehnen. Wir haben keinen signifikanten Unterschied vorliegen.\nNun ist es so, dass wir meistens noch die \\(p\\)-Werte für die paarweisen Vergleich sowie die 95% Konfidenzintervalle darstellen wollen. Wir nutzen dafür die Funktion contrast() aus dem Paket emmeans. Danach müssen wir noch Spalten auswählen und die \\(p\\)-Werte über die Funktion pvalue() aus dem Paket scales schöner formatieren. Wir erhalten dann das Objekt res_crd_tbl.\n\nres_crd_tbl <- res_crd %>% \n  contrast(method = \"pairwise\") %>% \n  tidy(conf.int = TRUE) %>% \n  mutate(p.value = pvalue(adj.p.value),\n         across(where(is.numeric), round, 2)) %>% \n  select(contrast, estimate, p.value,\n         conf.low, conf.high) \n\nIn dem Objekt res_crd_tbl finden wir dann die \\(p\\)-Werte für alle paarweisen Vergleiche sowie die 95% Konfidenzintevalle.\n\nres_crd_tbl\n\n# A tibble: 6 x 5\n  contrast estimate p.value conf.low conf.high\n  <chr>       <dbl> <chr>      <dbl>     <dbl>\n1 A - B       -1.25 0.903      -6.51      4.01\n2 A - C       -5.8  0.028     -11.1      -0.54\n3 A - D       -9.47 <0.001    -14.7      -4.21\n4 B - C       -4.55 0.103      -9.81      0.71\n5 B - D       -8.22 0.002     -13.5      -2.96\n6 C - D       -3.67 0.231      -8.93      1.59\n\n\nHier sehen wir dann die \\(p\\)-Werte für alle paarweisen Vergleiche und können dann die Entscheidung gegen die Nullhypothese für jeden der Kontraste einmal durchführen. Wir sehen, dass wir für alle Vergleiche die Nullhypothese ablehnen können, bis auf den Vergleich zwischen der Behandlung \\(B\\) und der Behandlung \\(C\\).\nIn der Abbildung 47.6 sehen wir die 95% Konfidenzintervalle für alle Vergleiche einmal dargestellt. Da wir es hier mit einem Mittelwertsvergleich zu tun haben, ist die Entscheidungsregel gegen die Nullhyppthese, dass wir ein signifikantes Konfidenzintervall vorliegen haben, wenn die Null nicht im Konfidenzintervall enthalten ist.\n\nggplot(res_crd_tbl, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +\n  geom_hline(yintercept=0, linetype=\"11\", colour=\"grey60\") +\n  geom_errorbar(width=0.1) + \n  geom_point() +\n  coord_flip() +\n  theme_bw()  +\n  labs(x = \"Vergleich\", y = \"Mittelwertsunterschied des Gewichtes [kg/ha]\",\n       caption = \"Schwarze Punkte stellen die bereinigten Mittelwertsunterschiede mit 95% Konfidenzgrenzen dar.\n       Enthält ein 95% Konfidenzintervalle die 0 ist es nicht signifikant unterschiedlich.\"))\n\n\n\nAbbildung 47.6— Abbildung der 95% Konfidenzintervallefür alle paarweisen Vergleiche der Behandlungsgruppen."
  },
  {
    "objectID": "experimental-design-basic.html#sec-rcbd",
    "href": "experimental-design-basic.html#sec-rcbd",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.3 Randomized complete block design (RCBD)",
    "text": "47.3 Randomized complete block design (RCBD)\nDas randomisierte, vollständige Blockdesign (eng. randomized complete block design) ist das Design, wenn es darum geht für verschiedene Räume die Varianz zu adjustieren bzw. zu modellieren. Was meinen wir mit Räumen? Wir meinen damit verschiedene Ställe, verschiedene Felder oder aber verschiedene Tische. Wir nennen diese zusätzlichen Beobachtungsräume auch Block.\n\n\n\n\n\n(a) Visualisierung des Randomized complete block design mit einer Behandlung und vier Behandlungsleveln. In jedem Block findet sich nur ein Behandlungslevel randomisiert wieder.\n\n\n\n\n\n\n(b) Visualisierung des Randomized complete block design mit einer Behandlung und vier Behandlungsleveln. In jedem Block finden wir mehrfach die Level der Behandlung. Im Prinzip ein Complete randomized design in mehreren Wiederholungen.\n\n\n\n\nAbbildung 47.7— Visualisierung der zwei Möglichkeiten ein Randomized complete block design zu konstruieren.\n\n\nWichtig ist zu unterschieden, wir pro Block nur einmal ein Level der Behandlung vorliegen haben. Dann hätten wir nämlich nur einen Topf mit Behandlung pro Block wie in Abbildung 47.7 (a) dargestellt. Damit haben wir den Block als Wiederholung. Oder wir haben ein Complete randomized design in Blöcken wiederholen vorliegen. Dann haben wir nämlich pro Block mehrere Wiederholungen der Behandlung wie in Abbildung 47.7 (b) veranschaulicht. Wir schauen uns erstmal den ersten Fall an. Das heist im Prinzip, dass unser Block die Wiederholung ist.\nHier ein paar Beispiele in Prosa, wie so ein Randomized complete block design konstruiert sein könnte.\nWir haben drei Tische und auf jeden der Tische steht zufällig vier ein Töpfe mit je einer Behandlung\nWir haben drei Ställe und in jedem Stall werden vier Buchten mit jeweils einer Behandlung genutzt.\nWir haben drei Felder mit jeweils vier Parzellen die zufällig mit jeweils einer der Behandlungen versehen werden.\nWir können natürlich auch auf den Tischen mehrere Wiederholungen einer Behandlung haben. Dann wird der Datensatz nur größer, aber die Auswertung unterschiedet sich nicht. Wir haben dann mehr Beobachtungen pro Block und Behandlung.\n\n47.3.1 Visualisierung\nIn der Abbildung 47.8 sehen wir eine Realisierung des Randomized complete block design. Wir haben insgesamt drei Blöcke vorliegen mit Block I, Block II und Block III. In jedem Block haben wir die Behandlungen \\(A\\), \\(B\\), \\(C\\) und \\(D\\) zufällig randomisiert. In jedem Block haben wir genau einmal ein Level der Behandlung vorliegen.\n\n\nAbbildung 47.8— Visualisierung des complete randomized design mit einer Behandlung und vier Behandlungsleveln.\n\n\n\n47.3.2 Daten\nIm Folgenden generieren wir uns die Daten für das Randomized complete block design. Wir wissen, dass in jedem Block die Behandlung genau einmal vorkommt. Um diese Datenstruktur mit zwei Faktoren nachzubauen, können wir die Funktion expand_grid() nutzen. Wir definieren zuerst, dass wir vier Behandlungslevel wollen und für jedes Behandlungslevel dann die drei Level des Blocks. Hier muss ich auch immer wieder rumspielen und probieren, bis ich die Daten dann zu dem Design passend habe. Wir erstellen uns so das Objekt factor_tbl.\n\nset.seed(20221001)\nfactor_tbl <- expand_grid(trt = 1:4, block = 1:3) %>% \n  mutate(trt = factor(trt, labels = c(\"A\", \"B\", \"C\", \"D\")),\n         block = factor(block, labels = as.roman(1:3))) \n\nfactor_tbl\n\n# A tibble: 12 x 2\n   trt   block\n   <fct> <fct>\n 1 A     I    \n 2 A     II   \n 3 A     III  \n 4 B     I    \n 5 B     II   \n 6 B     III  \n 7 C     I    \n 8 C     II   \n 9 C     III  \n10 D     I    \n11 D     II   \n12 D     III  \n\n\nWir sehen, dass jede Behandlung in allen drei Level des Blocks hat. Das entspricht unser Abbildung 47.8 und somit können wir uns darum kümmern, den Leveln der Behandlung und des Blocks einen Effekt zuzuweisen. Dafür brauchen wir die Modellmatrix, die beschreibt, wie sich für jede Beobachtung die Effekte zum Outcome rsp aufsummieren. Nicht jede Beobachtung ist in jedem Block in jeder Behandlung vertreten. Genau genommen hat jede Beobachtung nur eine einzige Behandlung/Block-Kombintation. Wir sehen diese Kombination dann in der Modellmatrix.\n\nmodel_mat <- factor_tbl %>% \n  model_matrix(~ trt + block) %>% \n  as.matrix()\n\nmodel_mat\n\n      (Intercept) trtB trtC trtD blockII blockIII\n [1,]           1    0    0    0       0        0\n [2,]           1    0    0    0       1        0\n [3,]           1    0    0    0       0        1\n [4,]           1    1    0    0       0        0\n [5,]           1    1    0    0       1        0\n [6,]           1    1    0    0       0        1\n [7,]           1    0    1    0       0        0\n [8,]           1    0    1    0       1        0\n [9,]           1    0    1    0       0        1\n[10,]           1    0    0    1       0        0\n[11,]           1    0    0    1       1        0\n[12,]           1    0    0    1       0        1\n\n\nWir sehen in der Modellmarix in jeder Zeile eine zukünftige Beobachtung. In den Spalten wird angegeben zu welchen Faktorleveln die Beobachtung gehört. Dabei bedeutet eine 1 ein Ja und eine 0 ein Nein. Die Beobachtung in der Zeile 5 wird zu Behandlungslevel \\(B\\) und Block \\(II\\) gehören.\nWir legen jetzt folgende Effekte für die einzelnen Behandlungslevel fest. Für den Intercept und damit auch für die Behandlung \\(A\\) auf \\(\\beta_{0} = \\beta_{A} = 20\\). Das Behandlunsglevel \\(B\\) wird auf \\(\\beta_{B} = 15\\), die Behandlung \\(C\\) auf \\(\\beta_{C} = 10\\) sowie die Behandlung \\(D\\) auf \\(\\beta_{D} = 5\\) gesetzt. Um die Sachlage zu vereinfachen setzen wir die Effekte der Blöcke auf \\(\\beta_{0} = \\beta_{I} = 0\\) sowie \\(\\beta_{II} = 0\\) und \\(\\beta_{III} = 0\\). Wir haben also faktisch keinen Effekt der Blöcke. Es ist egal welchen Tisch wir benutzen, die Effekte der Behandlung sind immer die Gleichen. Wenn wir die Daten so bauen würden, dann erhalten wir die Spalte rsp_eff in dem Datensatz rcbd_tbl. Wir haben keine Varianz. Deshalb müssen wir noch die Residuen mit \\(\\epsilon \\sim \\mathcal{N}(0, 2)\\) auf die Werte in der Spalte rsp_eff addieren. Wir erhalten die Spalte rsp für die Auswertung.\n\nrcbd_tbl <- factor_tbl %>% \n  mutate(rsp_eff = as.numeric(model_mat %*% c(20, 15, 10, 5, 0, 0)),\n         rsp = rsp_eff + rnorm(n(), 0, 2))\n\nrcbd_tbl\n\n# A tibble: 12 x 4\n   trt   block rsp_eff   rsp\n   <fct> <fct>   <dbl> <dbl>\n 1 A     I          20  19.8\n 2 A     II         20  17.6\n 3 A     III        20  18.2\n 4 B     I          35  34.4\n 5 B     II         35  33.9\n 6 B     III        35  32.3\n 7 C     I          30  28.4\n 8 C     II         30  29.5\n 9 C     III        30  29.5\n10 D     I          25  23.6\n11 D     II         25  24.9\n12 D     III        25  23.0\n\n\nIn Tabelle 47.1 sehen wir nochmal den Zusammenhang zwischen den generierten Daten und den entsprechenden berechneten Mittelwerten je Behandlungsgruppe. Wir berechnen den Mittelwert auf der Spalte rsp_eff. Wir sehen, dass wir die voreingestellten Mittelwerte in den Daten widerfinden.\n\n\n\n\nTabelle 47.1— Vergleich der Mittlwerte aus den Daten und den voreingestellten Effekten für die Generierung der Daten.\n\nFactor trt\nMean of level\nDifference to level A\nBeta\n\n\n\nA\n20\n0\n20\n\n\nB\n35\n15\n15\n\n\nC\n30\n10\n10\n\n\nD\n25\n5\n5\n\n\n\n\n\n\nAbschließend wollen wir uns die generierten Daten nochmal als einen Dotplot anschauen. Wir wollen dafür einen Dotplot nutzen, da wir mit drei Beobachtungen pro Level der Behandlung keinen sinnvollen Boxplot zeichnen können.\n\nggplot(rcbd_tbl, aes(trt, rsp, fill = block)) +\n  theme_bw() +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", \n               position = position_dodge(width = 0.4)) +\n  ylim(15, 40) +\n  scale_fill_okabeito() +\n  labs(fill = \"Block\", x = \"Behandlung\", y = \"Outcome\")\n\n\n\nAbbildung 47.9— Dotplot der Level der Behandlungen aufgeteilt für die Level des Blocks.\n\n\n\n\nWir können die Daten aus dem Datensatz rcbd_tbl jetzt für die Varianzanalyse und Mittelwertsvergleich nutzen.\n\n47.3.3 Modellierung\nIm Folgenden wollen wir die Daten modellieren. Das heist wir wollen eine Linie durch eine multidimensionale Punktewolke zeichnen. Daher auch lineares Modell oder eben durch die Funktion lm() in R für linear model. Wir nutzen das Paket parameters und die Funktion model_parameters() um uns die Parameter des Modells auszugeben. Wir könnten auch die Funktion tidy() nutzen, aber wir erhalten durch die Funktion model_parameters() etwas mehr Informationen und bessere Spaltenüberschriften.\nWir bauen das Modell in folgender Form. Wir haben ein numerisches Outcome \\(y\\) sowie einen Faktor \\(f_1\\) sowie einem Faktor für den Block \\(b_1\\).\n\\[\ny \\sim f_1 + b_1\n\\]\nNun können wir das abstrakte Modell in die Daten übersetzen und erhalten folgendes Modell.\n\\[\nrsp \\sim trt + block\n\\]\nDas heist, unsere numerische Variable rsp hängt ab von unserer faktoriellen Variable trt und der faktoriellen Blockvariable block. Wir müssen immer wissen, wie die Spaltennamen in unserem Datensatz crd_tbl lauten sonst kann R die Spalten nicht finden.\n\nfit_rcbd <- lm(rsp ~ trt + block, rcbd_tbl)\n\nfit_rcbd %>%  model_parameters()\n\nParameter   | Coefficient |   SE |         95% CI |  t(6) |      p\n------------------------------------------------------------------\n(Intercept) |       18.79 | 0.70 | [17.08, 20.51] | 26.75 | < .001\ntrt [B]     |       15.03 | 0.81 | [13.04, 17.01] | 18.53 | < .001\ntrt [C]     |       10.57 | 0.81 | [ 8.59, 12.56] | 13.03 | < .001\ntrt [D]     |        5.29 | 0.81 | [ 3.30,  7.27] |  6.52 | < .001\nblock [II]  |       -0.05 | 0.70 | [-1.77,  1.67] | -0.08 | 0.942 \nblock [III] |       -0.77 | 0.70 | [-2.49,  0.94] | -1.10 | 0.313 \n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\nWir sehen, dass wir die Koeffizienten, die wir vorher eingestellt haben, auch hier wiederfinden. Alle Steigungen der Behandlungslevel sind signifikant. Das hilft uns aber noch nicht so richtig weiter. Wir werden gleich das Modell in einer zweifaktoriellen ANOVA und einem Mittelwertsvergleich anschauen. Vorher wollen wir einmal statistisch Testen, ob die Varianzen homogens sind. Wir können die Varianzen aber nicht über das volle Modell testen, da wir nur eine Beobachtung per Behandlung/Block-Kombintation vorliegen haben.\n\nfit_rcbd %>% check_homogeneity()\n\nError in bartlett.test.default(x = mf[[1L]], g = mf[[2L]]) :  there must be at least 2 observations in each group\nDaher schauen wir uns nur die Varianzen für die Behandlung an und nehmen an, dass die Varanzen über die Blöcke homogen sind. Wir können nur einen Faktor testen und deshalb nehmen wir den für uns wichtigeren Faktor die Behandlung.\n\nlm(rsp ~ trt, rcbd_tbl) %>% check_homogeneity()\n\nOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.907).\n\n\nAbschließend schauen wir nochmal auf die Normalverteilung der Residuen.\n\nfit_rcbd %>% check_normality()\n\nOK: residuals appear as normally distributed (p = 0.391).\n\n\nIn der Abbildung 47.10 sehen wir den QQ-Plot und die Verteilung der Residuen im Densityplot. Auch die Visualisierung zeigt keine Aufälligkeiten. Wir sehen, dass die Residuen einer Normalverteilung folgen.\n\ncheck_model(fit_rcbd, check = c(\"qq\", \"normality\"))\n\n\n\nAbbildung 47.10— QQ-Plot und Densityplot der Residuen aus dem lineare Modell.\n\n\n\n\nWir können jetzt eine Varianzanalyse und dann eine Mittelwertsvergleich durchführen. Achtung, wir können uns hier auch etwas in die Ecke testen. Wenn wir nur lange genug neue Daten generieren, werden wir irgendwann auch einen Datensatz finden, der die Varianzhomogenität und die Normalverteilung ablehnt. Besonders in dem Fall, dass wir wenige Blöcke haben. Das liegt in der Theorie des statistischen Testens sowie der kleinen Fallzahl verborgen. Deshalb können wir im Zweifel gerne einmal deine Vortests in dem R Tutorium oder in einer statistischen Beratung diskutieren.\n\n47.3.4 Varianzanalyse und Mittelwertsvergleich\nAls erstes Rechnen wir eine zweifaktroielle ANOVA, da unser Modell zwei Faktoren hat. In R müssen wir dazu nur das Modell fit_rcbd in die Funktion anova() pipen. Wir erhalten dann die Ergebnisse aus der ANOVA mit der Funktion model_parameters() aus dem Paket parameters besser aufgearbeitet wieder. Die Mittelwertsunterschiede der Level der Behandlung haben wir bewusst sehr hoch angesetzt, so dass wir auf jeden Fall eine signifikante ANOVA erhalten sollen.\n\nres_anova <- fit_rcbd %>% \n  anova() \n\nres_anova %>% model_parameters()\n\nParameter | Sum_Squares | df | Mean_Square |      F |      p\n------------------------------------------------------------\ntrt       |      381.24 |  3 |      127.08 | 128.72 | < .001\nblock     |        1.50 |  2 |        0.75 |   0.76 | 0.509 \nResiduals |        5.92 |  6 |        0.99 |        |       \n\nAnova Table (Type 1 tests)\n\n\nAls Ergebnis haben wir einen signifikanten Faktor Behandlung trt sowie einen nicht signifikanten Faktor Block block. Wir können die Signifkanz an dem \\(p\\)-Wert bestimmen. Liegt der \\(p\\)-Wert unter dem Signifikanzniveau von \\(\\alpha\\) gleich 5% so können wir die Nullhypothese ablehnen. Wir haben dann mindestens einen signifikanten paarweisen Mittelwertsunterschied vorliegen.\nSchauen wir uns nun noch den Anteil der erklärten Varianz an. Wir nutzen dafür den Effektschätzer \\(\\eta^2\\).\n\nres_anova %>% eta_squared(partial = FALSE)\n\n# Effect Size for ANOVA (Type I)\n\nParameter |     Eta2 |       95% CI\n-----------------------------------\ntrt       |     0.98 | [0.93, 1.00]\nblock     | 3.85e-03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nWir sehen, dass durch den Faktor trt mit 92% der Varianz erklärt werden. Der Faktor Block erklärt nur ca. 2% der Varianz. Beides war so zu erwarten, denn wir haben ja auch den Datensatz in dieser Form gebaut. Die Behandlung hat einen starken Effekt und der Block hat gar keinen Effekt.\nSchauen wir nun auf den Mittelwertsvergleich. Wir nutzen dafür die Funktion emmeans() aus dem R Paket emmeans. Wichtig ist hier, dass wir uns jetzt die Vergleiche der Gruppen bzw. Level der Behandlung anschauen wollen.\n\nres_rcbd <- fit_rcbd %>% \n  emmeans(~ trt) \n\nAls erstes nutzen wir die Ausagbe der Funktion emmeans um uns das compact letter display wiedergeben zu lassen. Wir wollen wieder die Ausgaben runden und nutzen die Adjustierung der \\(p\\)-Werte für multiple Vergleiche nach Bonferroni. Nochmal als Erinnerung, das compact letter display gibt uns keine \\(p\\)-Werte wieder sondern wir Entscheiden anhand der vergebenen Buchstaben und deren Gleichheit über ein signifikantes Ergebnis oder ein nicht signifikantes Ergebnis.\n\nres_rcbd_cld <- res_rcbd %>% \n  cld(adjust = \"bonferroni\", Letters = letters) %>% \n  tidy() %>% \n  select(trt, estimate, conf.low, conf.high, .group) %>% \n  mutate(across(where(is.numeric), round, 2))\n\nres_rcbd_cld \n\n# A tibble: 4 x 5\n  trt   estimate conf.low conf.high .group \n  <chr>    <dbl>    <dbl>     <dbl> <chr>  \n1 A         18.5     16.5      20.5 \" a   \"\n2 D         23.8     21.8      25.8 \"  b  \"\n3 C         29.1     27.1      31.1 \"   c \"\n4 B         33.6     31.5      35.6 \"    d\"\n\n\nAn dem compact letter display sehen wir, dass sich alle Mittelwerte der Level der Behandlungen signifikant unterscheiden. In Abbildung 47.11 sehen wir die Daten zusammen mit dem compact letter display in einer Abbildung. Wir ändern hier das geom_point() zu geom_jitter() um ein Overplotting zu vermeiden. So können wir alle Beobachtungen als Punkte erkennen.\n\nggplot() +\n  theme_bw() +\n  geom_jitter(data = rcbd_tbl, aes(x = trt, y = rsp, fill = trt),\n              width = 0.05) +\n  geom_text(data = res_rcbd_cld, \n            aes(x = trt , y = estimate, label = .group),\n            position = position_nudge(x = 0.2), color = \"red\") +\n  geom_errorbar(data = res_rcbd_cld,\n                aes(ymin = conf.low, ymax = conf.high, x = trt),\n                color = \"red\", width = 0.1,\n                position = position_nudge(x = 0.1)) +\n  geom_point(data = res_rcbd_cld, \n             aes(x = trt , y = estimate),\n             position = position_nudge(x = 0.1), color = \"red\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Behandlung\", y = \"Gewicht [kg/ha]\",\n       caption = \"Schwarze Punkte stellen Rohdaten dar.\n       Rote Punkte und Fehlerbalken stellen bereinigte Mittelwerte mit 95% Konfidenzgrenzen pro Behandlung dar.\n       Mittelwerte, mit einem gemeinsamen Buchstaben, sind nicht signifikant unterschiedlich.\")\n\n\n\nAbbildung 47.11— Scatterplot der Behandlungsgruppen zusammen mit den 95% Konfidenzintervall und dem compact letter display.\n\n\n\n\nHäufig wollen wir nicht nur das compact letter display sehen sondern auch die dazugehörigen \\(p\\)-Werte und die entsprechenden 95% Konfidenzintervalle. Wir berechnen im Folgenden alle paarweisen Vergleiche bzw. Kontraste und lassen uns die adjustierten sowie formatierten \\(p\\)-Werte ausgeben. Wir runden wieder die Ausgabe.\n\nres_rcbd_tbl <- res_rcbd %>% \n  contrast(method = \"pairwise\") %>% \n  tidy(conf.int = TRUE) %>% \n  mutate(p.value = pvalue(adj.p.value),\n         across(where(is.numeric), round, 2)) %>% \n  select(contrast, estimate, p.value,\n         conf.low, conf.high) \n\nres_rcbd_tbl\n\n# A tibble: 6 x 5\n  contrast estimate p.value conf.low conf.high\n  <chr>       <dbl> <chr>      <dbl>     <dbl>\n1 A - B      -15.0  <0.001    -17.8     -12.2 \n2 A - C      -10.6  <0.001    -13.4      -7.76\n3 A - D       -5.29 0.003      -8.1      -2.48\n4 B - C        4.46 0.006       1.65      7.26\n5 B - D        9.74 <0.001      6.93     12.6 \n6 C - D        5.29 0.003       2.48      8.09\n\n\nAuch hier passen die \\(p\\)-Werte zu dem compact letter display. Alle Vergleiche sind signifikant. Das haben wir noch dem compact letter display auch so erwartet. Auch sehen wir das gleiche Ergebnis in Abbildung 47.12 für die 95% Konfidenzintervalle. Wir betrachten Mittelwertsunterschiede und kein Konfidenzintervall beinhaltet die Null somit sind alle Konfidenzintervalle signifikant.\n\nggplot(res_rcbd_tbl, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +\n  geom_hline(yintercept=0, linetype=\"11\", colour=\"grey60\") +\n  geom_errorbar(width=0.1) + \n  geom_point() +\n  coord_flip() +\n  theme_bw()  +\n  labs(x = \"Vergleich\", y = \"Mittelwertsunterschied des Gewichtes [kg/ha]\",\n       caption = \"Schwarze Punkte stellen die bereinigten Mittelwertsunterschiede mit 95% Konfidenzgrenzen dar.\n       Enthält ein 95% Konfidenzintervalle die 0 ist es nicht signifikant unterschiedlich.\"))\n\n\n\nAbbildung 47.12— Abbildung der 95% Konfidenzintervallefür alle paarweisen Vergleiche der Behandlungsgruppen."
  },
  {
    "objectID": "experimental-design-basic.html#sec-lsd",
    "href": "experimental-design-basic.html#sec-lsd",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.4 Latin square design (LSD)",
    "text": "47.4 Latin square design (LSD)\n\n47.4.1 Visualisierung\n\n\nAbbildung 47.13— Visualisierung des latin square design mit einer Behandlung und vier Behandlungsleveln.\n\n\n\n47.4.2 Daten\n\nexpand_grid(trt = 1:4, block = 1:4)\n\n# A tibble: 16 x 2\n     trt block\n   <int> <int>\n 1     1     1\n 2     1     2\n 3     1     3\n 4     1     4\n 5     2     1\n 6     2     2\n 7     2     3\n 8     2     4\n 9     3     1\n10     3     2\n11     3     3\n12     3     4\n13     4     1\n14     4     2\n15     4     3\n16     4     4\n\n\n\n47.4.3 Modellierung\n\n47.4.4 Varianzanalyse und Mittelwertsvergleich"
  },
  {
    "objectID": "experimental-design-basic.html#sec-alpha",
    "href": "experimental-design-basic.html#sec-alpha",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.5 Alpha design",
    "text": "47.5 Alpha design\n\n47.5.1 Visualisierung\n\n\n\nAbbildung 47.14— Visualisierung des alpha design mit einer Behandlung und vier Behandlungsleveln und zwölf unvollständigen Blöcken sowie vier Wiederholungen.\n\n\n\n\n47.5.2 Daten\n\n47.5.3 Modellierung\n\n47.5.4 Varianzanalyse und Mittelwertsvergleich"
  },
  {
    "objectID": "experimental-design-basic.html#sec-augment",
    "href": "experimental-design-basic.html#sec-augment",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.8 Augmented design",
    "text": "47.8 Augmented design"
  },
  {
    "objectID": "experimental-design-basic.html#sec-split",
    "href": "experimental-design-basic.html#sec-split",
    "title": "\n47  Grundlagen der Versuchsplanung\n",
    "section": "\n47.7 Split plot design",
    "text": "47.7 Split plot design\n\n47.7.1 Visualisierung\n\n\n\nAbbildung 47.15— Visualisierung des split plot design mit einer Behandlung und vier Behandlungsleveln sowie einer zweiten Behandlung mit fünf Behandlungsleveln. Die erste Behandlung ist über die drei Blöcke randomisiert.\n\n\n\n\n47.7.2 Daten\n\ndata_tbl <- expand_grid(trt = 1:4, block = 1:4, rep = 1:5) %>% \n    mutate(rsp = 20 + 2.5 * trt + 1.5 * block + rnorm(n(), 0, 1),\n           trt = factor(trt, labels = c(\"ctrl\", \"A\", \"B\", \"C\")),\n           block = factor(block, labels = as.roman(1:4)),\n           rep = as_factor(rep))\n\n\n47.7.3 Modellierung\n\n47.7.4 Varianzanalyse und Mittelwertsvergleich"
  }
]