```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Multiple Vergleiche oder Post-hoc Tests {#sec-posthoc}

In diesem Kapitel wollen wir uns mt den multipen Vergleichen beschäftigen. Das heißt, wir wollen statistisch Testen, ob sich die Level eines Faktors voneinander unterscheiden. Eventuell hast du schon eine einfaktorielle ANOVA gerechnet, wie in @sec-fac1 beschrieben. Oder aber du hast eine mehrfaktorielle ANOVA gerechnet wie in @sec-fac2 gezeigt. In beiden Fällen hast du jetzt einen signifikanten Faktor, der mehr als zwei Level hat. Du willst nun wissen, *welche* der Gruppenmittelwerte der Level sich signifikant unterscheiden. Hierfür können wir verschiedene Ansätze wählen.

1)  Wir haben eine einfaktorielle ANOVA gerechnet und nutzen nun paarweise Vergleiche um herauszufinden welche Gruppenmittelwerte sich unterscheiden (siehe @sec-posthoc-pairwise)
2)  Wir haben eine mehrfaktorielle ANOVA gerechnet und haben daher mehrere Faktoren. Wir nutzen nun entweder das R Paket `multcomp` (siehe @sec-posthoc-multcomp) oder das R Paket `emmeans` (siehe @sec-posthoc-emmeans) um herauszufinden welche Gruppenmittelwerte sich unterscheiden.

Wenn wir multiple Mittelwertsvergleiche rechnen, dann tritt das Problem des multipen Testens auf. Im @sec-statistisches-testen-alpha-adjust kannst du mehr über die Problematik erfahren und wie wir mit der $\alpha$ Inflation umgehen. Hier in diesem Kapitel gehe ich jetzt davon aus, dass dir die $\alpha$ Adjustierung ein Begriff ist.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, conflicted, broom,
               multcomp, emmeans, ggpubr)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Wir nutzen in diesem Kapitel den Datensatz aus dem Beispiel in @sec-example-3. Wir haben als Outcome die Sprunglänge in \[cm\] von Flöhen. Die Sprunglänge haben wir an Flöhen von Hunde, Katzen und Füchsen gemessen. Der Datensatz ist also recht übeerschaubar. Wir haben ein normalverteiltes $y$ mit `jump_length` sowie einen multinomialverteiltes $y$ mit `grade` und einen Faktor `animal` mit drei Leveln.

Du kannst dir komplexere Auswertungen im @sec-beispiel-auswertung anschauen. Dort sammelt sich mit der Zeit Auswertungen vom Fachbereich an. Daher finden sich dort auch Beispiele für multiple Vergleiche.

Im Folgenden laden wir den Datensatz `flea_dog_cat_fox.csv` und selektieren mit der Funktion `select()` die benötigten Spalten. Abschließend müssen wir die Spalte `animal`noch in einen Faktor umwandeln. Damit ist unsere Vorbereitung des Datensatzes abgeschlossen.

```{r}
#| message: false

fac1_tbl <- read_csv2("data/flea_dog_cat_fox.csv") %>%
  select(animal, jump_length, grade) %>% 
  mutate(animal = as_factor(animal))
```

In der @tbl-data-posthoc-1 ist der Datensatz `fac1_tbl` nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz mit einer normalverteilten Variable `jump_length` sowie der multinominalverteilten Variable `grade` und einem Faktor `animal` mit drei Leveln.
#| label: tbl-data-posthoc-1

fac1_tbl %>% kable(align = "c", "pipe")
```

Wir werden nun den Datensatz `fac1_tbl` in den folgenden Abschnitten immer wieder nutzen.

### Hypothesen für multiple Vergleiche

Als wir eine ANOVA gerechnet hatten, hatten wir nur eine Nullhypothese und eine Alternativehypothese. Wenn wir Nullhypothese abgelehnt hatten, wussten wir nur, dass sich mindestens ein paarweiser Vergleich unterschiedet. Multiple Vergleich lösen nun dieses Problem und führen ein Hypothesen*paar* für jeden paarweisen Vergleich ein. Zum einen rechnen wir damit $k$ Tests und haben damit auch $k$ Hypothesenpaare (siehe auch @sec-statistisches-testen-alpha-adjust zur Problematik des wiederholten Testens).

Wenn wir zum Beispiel alle Level des Faktors `animal` miteinander Vergleichen wollen, dann rechnen wir $k=3$ paarweise Vergleiche. Im Folgenden sind alle drei Hypothesenpaare dargestellt.

```{=tex}
\begin{align*}
H_{01}: &\; \bar{y}_{cat} = \bar{y}_{dog}\\
H_{A1}: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\end{align*}
```
```{=tex}
\begin{align*}
H_{02}: &\; \bar{y}_{cat} = \bar{y}_{fox}\\
H_{A2}: &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\end{align*}
```
```{=tex}
\begin{align*}
H_{03}: &\; \bar{y}_{dog} = \bar{y}_{fox}\\
H_{A3}: &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\end{align*}
```
Wenn wir drei Vergleiche rechnen, dann haben wir eine $\alpha$ Inflation vorliegen. Wir sagen, dass wir für das multiple Testen adjustieren müssen. In R gibt es eine Reihe von Adjustierungsverfahren. Wir nehmen meist Bonferroni oder das Verfahren, was in der jeweiligen Funktion als Standard (eng. *default*) gesetzt ist.

Wir adjustieren grundsätzlich die $p$-Werte und erhalten adjustierte $p$-Werte aus den jeweiligen Funktionen in R. Die adjustierten p-Werte können wir dann mit dem Signifikanzniveau von $\alpha$ gleich 5% vergleichen.

## Gruppenvergleiche mit `pairwise.*.test()` {#sec-posthoc-pairwise}

[Die Funktion `pairwise.*.test()` ist *veraltet*, wir nutzen das R Paket `emmeans`oder das R Paket `multcomp`.]{.aside}

Wenn wir nur einen Faktor mit mehr als zwei Leveln vorliegen haben, dann können wir die Funktion `pairwise.*.test()` nutzen. Der Stern `*` steht entweder als Platzhalter für `t` für den t-Test oder aber für `wilcox` für den Wilcoxon Test. Die Funktion ist relativ einfach zu nutzen und liefert auch sofort die entsprechenden p-Werte.

Die Funktion `pairwise.*.test()` ist in dem Sinne *veraltet*, da wir keine 95% Konfidenzintervalle generieren können. Da die Funktion aber immer mal wieder angefragt wird, ist die Funktion hier nochmal aufgeführt.

### Paarweiser t Test

Wir nutzen den paarweisen t-Test,

-   wenn wir ein normalverteiltes $y$ vorliegen haben, wie `jump_length`.
-   wenn wir *nur* einen Faktor mit mehr als zwei Leveln vorliegen haben, wie `animal`.

Die Funktion `pairwise.t.test` kann nicht mit Datensätzen arbeiten sondern nur mit Vektoren. Daher können wir der Funktion auch keine `formula` übergeben sondern müssen die Vektoren aus dem Datensatz mit `fac1_tbl$jump_length` für das Outcome und mit `fac1_tbl$animal` für die Gruppierende Variable benennen. Das ist umständlich und dhaer auch fehleranfällig.

::: column-margin
Mehr zu `mutate_if()` erfährst du auf der [Hilfeseite von mutate()](https://dplyr.tidyverse.org/reference/mutate_all.html)
:::

Als Adjustierungsmethode für den $\alpha$ Fehler wählen wir die Bonferroni-Methode mit `p.adjust.method = "bonferroni"` aus. Da wir eine etwas unübersichtliche Ausgabe in R erhalten nutzen wir die Funktion `tidy()`um die Ausgabe in ein saubers `tibble` zu verwandeln. Abschließend runden wir noch alle numerischen Spalten mit der Funktion `round` auf drei Stellen hinter dem Komma.

```{r}
pairwise.t.test(fac1_tbl$jump_length, fac1_tbl$animal,
                p.adjust.method = "bonferroni") %>% 
  tidy %>% 
  mutate_if(is.numeric, round, 3)
```

Wir erhalten in einem Tibble die adujstierten p-Werte nach Bonferroni. Wir können daher die adjustierten p-Werte ganz normal mit dem Signifikanzniveau $\alpha$ von 5% vergleichen. Wir sehen, dass der Gruppenvergleich `cat - dog` signifikant ist, der Gruppenvergleich `fox - dog` nicht signifkant ist und der Gruppenvergleich `fox - cat` wiederum signifkant ist.

Leider können wir uns keine Konfidenzintervalle wiedergeben lassen, so dass die Funktion nicht dem Stand der Wissenschaft und deren Ansprüchen genügt.

Im Folgenden wollen wir uns nochmal die Visualisierung mit dem R Paket `ggpubr` anschauen. Die [Hilfeseite des R Pakets `ggpubr`](https://rpkgs.datanovia.com/ggpubr/index.html) liefert noch eine Menge weitere Beispiele für den simplen Fall eines Modells $y ~ x$, also von einem $y$ und einem Faktor $x$.

Um die @fig-ggpubr-1 zu erstellen müssen wir als erstes die Funktion `compare_mean()` nutzen um mit der `formula` Syntax einen t-Test zu rechnen. wir adjustieren die p-Werte nach Bonferroni. Anschließend erstellen wir einen Boxplot mit der Funktion `ggboxplot()` und speichern die Ausgabe in dem Objekt `p`. Wie in `ggplot` üblich können wir jetzt auf das Layer `p` über das `+`-Zeichen noch weitere Layer ergänzen. Wir nutzen die Funktion `stat_pvalue_manual()` um die asjustierten p-Werte aus dem Objekt `stat_test_obj` zu ergänzen. Abschließend wollen wir noch den p-Wert einer einfaktoriellen ANOVA als globalen Test ergänzen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen ergänzt um den paarweisen Vergleich mit dem t-Test und den Bonferroni adjustierten p-Werten.
#| label: fig-ggpubr-1

stat_test_obj <- compare_means(
 jump_length ~ animal, data = fac1_tbl,
 method = "t.test",
 p.adjust.method = "bonferroni"
)

p <- ggboxplot(data = fac1_tbl, x = "animal", y = "jump_length",
               color = "animal", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
               add = "jitter", shape = "animal")

p + stat_pvalue_manual(stat_test_obj, label = "p.adj", y.position = c(13, 16, 19)) +
  stat_compare_means(label.y = 20, method = "anova")    

```

### Paarweiser Wilcoxon Test

Wir nutzen den paarweisen Wilxocon Test,

-   wenn wir ein *nicht*-normalverteiltes $y$ vorliegen haben, wie `grade`.
-   wenn wir *nur* einen Faktor mit mehr als zwei Leveln vorliegen haben, wie `animal`.

Die Funktion `pairwise.wilcox.test` kann nicht mit Datensätzen arbeiten sondern nur mit Vektoren. Daher können wir der Funktion auch keine `formula` übergeben sondern müssen die Vektoren aus dem Datensatz mit `fac1_tbl$jump_length` für das Outcome und mit `fac1_tbl$animal` für die Gruppierende Variable benennen. Das ist umständlich und dhaer auch fehleranfällig.

::: column-margin
Mehr zu `mutate_if()` erfährst du auf der [Hilfeseite von mutate()](https://dplyr.tidyverse.org/reference/mutate_all.html)
:::

Als Adjustierungsmethode für den $\alpha$ Fehler wählen wir die Bonferroni-Methode mit `p.adjust.method = "bonferroni"` aus. Da wir eine etwas unübersichtliche Ausgabe in R erhalten nutzen wir die Funktion `tidy()`um die Ausgabe in ein saubers `tibble` zu verwandeln. Abschließend runden wir noch alle numerischen Spalten mit der Funktion `round` auf drei Stellen hinter dem Komma.

```{r}
#| warning: false

pairwise.wilcox.test(fac1_tbl$grade, fac1_tbl$animal,
                     p.adjust.method = "bonferroni") %>% 
  tidy %>% 
  mutate_if(is.numeric, round, 3)
```

Wir erhalten in einem Tibble die adujstierten p-Werte nach Bonferroni. Wir können daher die adjustierten p-Werte ganz normal mit dem Signifikanzniveau $\alpha$ von 5% vergleichen. Wir sehen, dass der Gruppenvergleich `cat - dog` knapp signifikant ist, der Gruppenvergleich `fox - dog` ebenfalls signifkant ist und der Gruppenvergleich `fox - cat` auch signifkant ist.

Leider können wir uns keine Konfidenzintervalle wiedergeben lassen, so dass die Funktion nicht dem Stand der Wissenschaft und deren Ansprüchen genügt.

Im Folgenden wollen wir uns nochmal die Visualisierung mit dem R Paket `ggpubr` anschauen. Die [Hilfeseite des R Pakets `ggpubr`](https://rpkgs.datanovia.com/ggpubr/index.html) liefert noch eine Menge weitere Beispiele für den simplen Fall eines Modells $y ~ x$, also von einem $y$ und einem Faktor $x$.

Um die @fig-ggpubr-2 zu erstellen müssen wir als erstes die Funktion `compare_mean()` nutzen um mit der `formula` Syntax einen Wilcoxon Test zu rechnen. wir adjustieren die p-Werte nach Bonferroni. Anschließend erstellen wir einen Boxplot mit der Funktion `ggboxplot()` und speichern die Ausgabe in dem Objekt `p`. Wie in `ggplot` üblich können wir jetzt auf das Layer `p` über das `+`-Zeichen noch weitere Layer ergänzen. Wir nutzen die Funktion `stat_pvalue_manual()` um die asjustierten p-Werte aus dem Objekt `stat_test_obj` zu ergänzen. Abschließend wollen wir noch den p-Wert eines Kruskal Wallis als globalen Test ergänzen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen ergänzt um den paarweisen Vergleich mit dem Wilcoxon Test und den Bonferroni adjustierten p-Werten.
#| label: fig-ggpubr-2

stat_test_obj <- compare_means(
 grade ~ animal, data = fac1_tbl,
 method = "wilcox.test",
 p.adjust.method = "bonferroni"
)

p <- ggboxplot(data = fac1_tbl, x = "animal", y = "grade",
               color = "animal", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
               add = "jitter", shape = "animal")

p + stat_pvalue_manual(stat_test_obj, label = "p.adj", y.position = c(10, 13, 16)) +
  stat_compare_means(label.y = 20, method = "kruskal.test")    

```

## Gruppenvergleich mit dem `multcomp` Paket {#sec-posthoc-multcomp}

Wir drehen hier einmal die Erklärung um. Wir machen erst die Anwendung in R und sollte dich dann noch mehr über die statistischen Hintergründe der Funktionen interessieren, folgt ein Abschnitt noch zur Theorie. Du wirst die Funktionen aus `multcomp` vermutlich in deiner Abschlussarbeit brauchen. Häufig werden multiple Gruppenvergleiche in Abschlussarbeiten gerechnet.

### Gruppenvergleiche mit `multcomp` in R

::: column-margin
Die Ausgabe von `multcomp` können über die Funktion `tidy()` aufgeräumt werden. Mehr dazu unter der [Hilfeseite von `tidy`()](https://broom.tidymodels.org/reference/tidy.glht.html).
:::

Als erstes brauchen wir ein lineares Modell für die Verwendung von `multcomp`. Normalerweise verenden wir das gleiche Modell, was wir schon in der ANOVA verwendet haben. Wir nutzen hier ein simples lineares Modell mit nur einem Faktor. Im Prinzip kann das Modell auch größer sein. Du findest immer Beispiel im @sec-beispiel-auswertung, die dir eventuell dann nochmal zeigen, wie du deine Daten nutzen musst.

```{r}
fit_1 <- lm(jump_length ~ animal, data = fac1_tbl)
```

Wir haben das Objeckt `fit_1` mit der Funktion `lm()` erstellt. Im Modell sind jetzt alle Mittelwerte und die entsprechenden Varianzen geschätzt worden. Mit `summary(fit_1)` kannst du dir gerne das Modell auch nochmal anschauen.

::: column-margin
Wenn wir keinen *all-pair* Vergleich rechnen wollen, dann können wir auch einen *many-to-one* Vergleich mit dem `Dunnett` Kontrast rechnen.
:::

Im Anschluß nutzen wir die Funktion `glht()` um den multiplen vergleich zu rechnen. Als erstes musst du wissen, dass wenn wir *alle* Vergleiche rechnen wollen, wir einen *all-pair* Vergleich rechnen. In der Statistik heißt dieser Typ von Vergleich `Tukey`. Wir wollen jetzt als für den Faktor `animal` einen multiplen `Tukey`-Vergleich rechnen. Nichts anders sagt `mcp(animal = "Tukey")` aus, dabei steht `mcp` für *multiple comparison procedure*. Mit dem hinteren Teil der Funktion weiß jetzt die Funktion `glht()` was gerechnet werden soll. Wir müssen jetzt der Funktion nur noch mitgeben auf was der multiple vergleich gerehcnet werden soll, mit dem Objekt `fit_1`. Wir speichern die Ausgabe der Funktion in `comp_1_obj`.

```{r}
comp_1_obj <- glht(fit_1, linfct = mcp(animal = "Tukey")) 
```

Mit dem Objekt `comp_1_fit` können wir noch nicht soviel anfangen. Der Inhalt ist etwas durcheinander und wir wollen noch die Konfidenzintervalle haben. Daher pipen wir `comp_1_fit` erstmal in die Funktion `tidy()` und alssen mit der Option `conf.int = TRUE` die simultanen 95% Konfidenzintervalle berechnen. Dann nutzen wir die Funktion `select()` um die wichtigen Spalten zu selektieren. Abschließend mutieren wir noch alle numerischen Spalten in dem wir auf die dritte Kommastelle runden. Wir speichern alles in das Objekt `res_1_obj`.

```{r}
#| message: false
res_1_obj <- comp_1_obj %>% 
  tidy(conf.int = TRUE) %>% 
  select(contrast, estimate, adj.p.value, 
         conf.low, conf.high) %>% 
  mutate_if(is.numeric, round, 3)
```

Wir lassen uns dann den Inhalt von dem Objekt `res_1_obj` ausgeben.

```{r}
res_1_obj
```

Wir erhalten ein `tibble()` mit fünf Spalten. Zum einen den `contrast`, der den Vergleich widerspiegelt. Wir vergleichen im ersten Kontrast die Katzen- mit den Hundeflöhen, wobei wir `cat - dog` rechnen. Also wirklich der Mittelwert der Sprungweite der Katzenflöhe *minus* den Mittelwert der Sprungweite der Hundeflöhe rechnen. In der Spalte `estimate` sehen wir den Mittelwertsunterschied. Der Mittelwertsunterschied ist in der *Richtung* nicht ohne den Kontrast zu interpretieren. Danach erhalten wir die adjustierten $p$-Wert sowie die simultanen 95% Konfidenzintervalle.

Wir können die Nullhypothese ablehnen für den Vergleiche`cat - dog` mit einem p-Wert von $0.006$ sowie für den Vergleich $fox - cat$ mit einem p-Wert von $0.001$. Beide p-Werte liegen unter dem Signifikanzniveau von $\alpha$ gleich 5%.

In @fig-multcomp-1 sind die simultanen 95% Konfidenzintervalle nochmal in einem `ggplot` visualisiert. Die Kontraste und die Position hängen von dem Faktorlevel ab. Mit der Funktion `factor()` kannst du die Sortierung der Level einem Faktor ändern und somit auch Position auf den Achsen.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: Simultane 95% Konfidenzintervalle für den paarweisen Vergleich der Sprungweiten in [cm] der Hunde-, Katzen- und Fuchsflöhe.
#| label: fig-multcomp-1

  ggplot(res_1_obj, aes(contrast, y=estimate, 
                        ymin=conf.low, ymax=conf.high)) +
    geom_hline(yintercept=0, linetype="11", colour="grey60") +
    geom_errorbar(width=0.1) + 
    geom_point() +
    coord_flip() +
    theme_classic()
```

Die Entscheidung gegen die Nullhypothese anhand der simultanen 95% Konfidenzintervalle ist inhaltlich gleich, wie die Entscheidung anhand der p-Werte. Wir entscheiden gegen die Nullhypothese, wenn die 0 nicht mit im Konfindenzintervall enthalten ist. Wir wählen hier die 0 zur Entscheidung gegen die Nullhypothese, weil wir einen Mittelwertsvergleich rechnen.

Für den Vergleich `fox -dog` ist die 0 im 95% Konfidenzintervall, wir können daher die Nullhypothese nicht ablehnen. Das 95% Konfidenzintervall ist nicht signifikant. Bei dem Vergleich `fox - cat` sowie dem Vergleich `cat - dog` ist jeweils die 0 nicht im 95% Konfidenzintervall enthalten. Beide 95% Konfidenzintervalle sind signifikant, wir können die Nullhypothese ablehnen.

### Gruppenvergleiche mit `multcomp` in theoretisch

**work in progress**

Teststatistiken sind miteinander korreliert

Tukey Kontrast (all-pair)

```{r}
contrMat(n = c(7, 7, 7), type = "Tukey")
```

Dunnett Kontrast (many-to-one)

```{r}
contrMat(n = c(7, 7, 7), type = "Dunnett", base = 1)
```

## Gruppenvergleich mit der `emmeans` Paket {#sec-posthoc-emmeans}

::: column-margin
Wir können hier nicht alles erklären und im Detail durchgehen. Hier gibt es noch ein aufwendiges Tutorium zu `emmeans`: [Getting started with emmeans](https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/)
:::

### Gruppenvergleiche mit `emmeans` in R

https://stats.stackexchange.com/questions/404168/multcomp-vs-emmeans-for-multiple-comparisons#:\~:text=As%20I%20understand%20it%20(e.g.,values%20and%20short%20confidence%20intervals.

?emmeans::emm

::: column-margin
Die Ausgabe von `emmeans` können über die Funktion `tidy()` aufgeräumt werden. Mehr dazu unter der [Hilfeseite von `tidy`()](https://broom.tidymodels.org/reference/tidy.emmGrid.html).
:::

```{r}
fit_2 <- lm(jump_length ~ animal, data = fac1_tbl)

comp_2_obj <- fit_2 %>% 
  emmeans(~ animal) %>% 
  contrast(method = "pairwise") 
```

```{r}
res_2_obj <- comp_2_obj %>% 
  tidy(conf.int = TRUE) %>% 
  select(contrast, estimate, adj.p.value, conf.low, conf.high) %>% 
  mutate(across(where(is.numeric), round, 4))

res_2_obj
```

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| fig-cap: 95% Konfidenzintervalle.
#| label: fig-emmeans-1

  ggplot(res_2_obj, aes(contrast, y=estimate, ymin=conf.low, ymax=conf.high)) +
    geom_hline(yintercept=0, linetype="11", colour="grey60") +
    geom_errorbar(width=0.1) + 
    geom_point() +
    coord_flip() +
    theme_classic()
```
