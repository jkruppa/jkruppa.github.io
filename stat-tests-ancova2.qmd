```{r echo = FALSE}
#| message: false
#| echo: false
#| warning: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, plyr,
               patchwork, ggforce, see, sjPlot, tinytable, conflicted)
set.seed(202434)
conflicts_prefer(dplyr::summarise)
conflicts_prefer(dplyr::summarize)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(magrittr::set_names)
source("stat-tests-anova_plot/ancova_plots.R")
```

# Die ANCOVA {#sec-ancova}

*Letzte Änderung am `r format(fs::file_info("stat-tests-ancova2.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"It's better to solve the right problem approximately than to solve the wrong problem exactly." --- John Tukey*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Aktualisierung (seit 02.2025)

Dieses Kapitel wird in den nächsten Wochen aktualisiert. Ich plane zum Ende des SoSe 2025 eine neue Version des Kapitels erstellt zu haben. Deshalb kann hier das ein oder andere kurzfristig nicht mehr funktionieren.
:::

Eigentlich hat sich die Analysis of Covariance (ANCOVA) etwas überlebt. Wir können mit dem statistischen Modellieren *eigentlich* alles was die ANCOVA kann plus wir erhalten auch noch Effektschätzer für die Kovariaten und die Faktoren. Dennoch hat die ANCOVA ihren Platz in der Auswertung von Daten. Wenn du ein oder zwei Faktoren hast plus eine numerische Variable, wie das Startgewicht, für die du die Analyse adjustieren möchtest, dann ist die ANCOVA für dich gemacht. Es gibt auch noch andere Möglichkeiten, die Idee ist eben, dass du für jeden deiner Beobachtungen noch eine kontinuierliche Variable zusätzlich zu deinen Faktoren erhebst, die eben nicht dein Messwert ist. Im Bereich der Agrarwissenschaften ist die ANCOVA eher selten zu finden.

## Allgemeiner Hintergrund

Also kurz gesprochen adjustiert die Analysis of Covariance (ANCOVA) die Faktoren einer ANOVA um eine kontinuierliche Covariate. Eine Kovariate ist eine Variable, die mit berücksichtigt wird, um mögliche verzerrende Einflüsse auf die Analyseergebnisse (ungebräuchlich *Konfundierung*) abzuschätzen oder zu verringern. Adjustiert bedeutet in dem Fall, dass die Effekte des unterschiedlichen Startgewichts von Pflanzen durch das Einbringen der Kovariate mit in der statistischen Analyse berücksichtigt werden. Wir werden hier auch nur über die Nutzung in R sprechen und auf die theoretische Herleitung verzichten.

Wie immer gibt es auch passende Literatur um die ANCOVA herum. @karpen2017misuses beschreibt in [Misuses of Regression and ANCOVA in Educational Research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5701329/) nochmal Beispiele für die falsche oder widersprüchliche Nutzung der Regression und ANCOVA. Ich nutze die Quelle immer mal wieder in meinen vertiefenden Vorlesungen. Da wir hier ja nicht nur Agrawissenschaftler haben, hilft die Arbeit von @kim2018statistical mit [Statistical notes for clinical researchers: analysis of covariance (ANCOVA)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6237726/) auch nochmal weiter. Die Besonderheit bei der klinischen Forschung ist ja die "Beweglichkeit" der Beobachtungen. Menschen lassen sich eben nicht vollständig kontrollieren und daher ist die Thematik eine andere als bei Pflanzen und Tieren.

#### Das Modell {.unnumbered .unlisted}

Wenn wir neben einem bis mehreren Faktoren $f$ noch eine numerische Kovariate $c$ mit modellieren wollen, dann nutzen wir die ANCOVA (eng. *Analysis of Covariance*). Hier kommt dann immer als erstes die Frage, was heißt den Kovariate $c$? Hier kannst du dir eine numerische Variable vorstellen, die ebenfalls im Experiment gemessen wird. Es kann das Startgewicht oder aber die kummulierte Wassergabe sein. Wir haben eben hier keinen Faktor als Kategorie vorliegen, sondern eben etwas numerisch gemessen. Daher ist unsere Modellierung etwas anders.

$$
y \sim f_A + f_B + ... + f_P + f_A \times f_B + c_1 + ... + c_p
$$

mit

-   $y$ gleich dem Messwert oder Outcome
-   $f_A + f_B + ... + f_P$ gleich experimenteller Faktoren
-   $f_A \times f_B$ gleich einem beispielhaften Interaktionsterm erster Ordnung
-   $c_1 + ... + c_p$ gleich einer oder mehrer numerischer Kovariaten

Hier muss ich gleich die Einschränkung machen, dass wir *normalerweise* maximal ein zweifaktorielles Modell mit einem Faktor $A$ und einem Faktor $B$ sowie einer Kovariate $c$ betrachten. Sehr selten haben wir mehr Faktoren oder gar Kovariaten in dem Modell. Wenn das der Fall sein sollte, dann könnte eine andere Modellierung wie eine multiple Regression eine bessere Lösung sein.

#### Hypothesen {.unnumbered .unlisted}

Wenn wir von der ANCOVA sprechen, dann kommen wir natürlich nicht an den Hypothesen vorbei. Die ANCOVA ist ja auch ein klassischer statistischer Test. Hier müssen wir unterscheiden, ob wir eine Behandlung mit zwei Gruppen, also einem Faktor $A$ mit $2$ Leveln vorliegen haben. Oder aber eine Behandlung mit drei oder mehr Gruppen vorliegen haben, also einem Faktor $A$ mit $\geq 3$ Leveln in den Daten haben. Da wir schnell in einer ANOVA mehrere Faktoren haben, haben wir auch schnell viele Hypothesen zu beachten. Jeweils ein Hypothesenpaar pro Faktor muss dann betrachtet werden. Das ist immer ganz wichtig, die Hypothesenpaare sind unter den Faktoren mehr oder minder unabhängig. Bei der ANCOVA kommt dann noch die Kovariate mit hinzu, die wir dann ja auch noch testen müssen.

::: panel-tabset
## Faktor mit $2$ Leveln

Bei einem Faktor $A$ mit nur zwei Leveln $A.1$ und $A.2$ haben wir eine Nullhypothese, die du schon aus den Gruppenvergleichen wie dem t-Test kennst. Wir wollen zwei Mittelwerte vergleichen und in unserer Nullhypothese steht somit die Gleichheit. Da wir nur zwei Gruppen haben, sieht die Nullhypothese einfach aus.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2}
$$

In der Alternativehypothese haben wir dann den Unterschied zwischen den beiden Mittelwerten. Wenn wir die Nullhypothese ablehnen können, dann wissen wir auch welche Mittelwertsunterschied signifikant ist. Wir haben ja auch nur einen Unterschied getestet.

$$
H_A: \; \bar{y}_{A.1} \neq \bar{y}_{A.2}
$$ Das Ganze wird dann etwas komplexer im Bezug auf die Alternativehypothese wenn wir mehr als zwei Gruppen haben. Hier kommt dann natürlich auch die Stärke der ANOVA zu tragen. Eben mehr als zwei Mittelwerte vergleichen zu können.

## Faktor mit $\geq 3$ Leveln

Die klassische Nullhypothese der ANOVA hat natürlich mehr als zwei Level. Hier einmal beispielhaft die Nullhypothese für den Vergleich von drei Gruppen des Faktors $A$. Wir wollen als Nullhypothese testen, ob alle Mittelwerte der drei Gruppen gleich sind.

$$
H_0: \; \bar{y}_{A.1} = \bar{y}_{A.2} = \bar{y}_{A.3}
$$

Wenn wir die Nullhypothese betrachten dann sehen wir auch gleich das Problem der Alternativehypothese. Wir haben eine Menge an paarweisen Vergleichen. Wenn wir jetzt die Nullhypothese ablehnen, dann wissen wir nicht welcher der drei paarweisen Mittelwertsvergleiche denn nun unterschiedlich ist. Praktisch können es auch alle drei oder eben zwei Vergleiche sein.

$$
\begin{aligned}
H_A: &\; \bar{y}_{A.1} \ne \bar{y}_{A.2}\\
\phantom{H_A:} &\; \bar{y}_{A.1} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \bar{y}_{A.2} \ne \bar{y}_{A.3}\\
\phantom{H_A:} &\; \mbox{für mindestens einen Vergleich}
\end{aligned}
$$

Wenn wir die Nullhypothese abgelhent haben, dann müssen wir noch einen sogenannten Post-hoc Test anschließen um die paarweisen Unterschiede zu finden, die dann signifikant sind. Das ganze machen wir dann aber in einem eigenen Kapitel zum Post-hoc Test.

## Kovariate $c$

Bei der Kovariate testen wir, ob es eine Änderung über die Faktoren gibt. Hierbei ist natürlich keien Änderung ein paraleller Verlauf über die Faktorenlevel. Oder anders ausgedrückt, die Steigung $\beta_c$ von der Kovariate $c$ ist Null. Wir haben also als Nullhypothese keine Änderung in der Steigung. Damit haben wir auch eine Ähnlichkeit mit der Nullhypothese in der linearen Regression. Dort testen wir ja auch die Steigung.

$$
H_0: \beta_c = 0
$$

Die Alternativhypothese ist dann natürlich die Verneinung der Nullhypothese und damit eine Steigung oder Veränderung der Kovariate über die Faktoren. Wir können also eine Veränderung in den Mittelwerten der Faktoren beobachten, wenn sich die Kovariate ändert. Wir haben dann eben einen globalen Mittelwert mit einer Steigung in unserem Modell.

$$
H_A: \beta_c \neq 0
$$

Jetzt ist natürlich die Frage, wollen wir eine signifikante Kovariate oder nicht? Manchmal haben wir eine signifkante Kovariate im Modell und wollen unsere Faktoren für den Effekt der Kovariate adjustieren. Das machen wir dann indem wir die Kovariate mit ins Modell nehmen. In den Agrarwissenschaften ist es aber eher selten, dass wir eine signifikante Kovariate als erstrebenswert erachten.
:::

#### Welche Pakete gibt es eigentlich? {.unnumbered .unlisted}

Die Frage lässt sich relativ einfach beantworten. Es gibt neben der klassischen Implementierung in R mit der Funktion `aov()` nch die Möglichkeit die R Pakete `{car}` und die Funktion `Anova()` zu nutzen. Wenn es etwas komplexer sein soll und wir eventuell dann noch Messwiederholungen mit in den Daten haben, dann könnne wir auch das R Paket `{afex}` nutzen. Bei einer klassichen ANCOVA würde ich dann aber bei dem Standard in `{base}` oder `{car}` bleiben. Es gibt hier eigentlich keinen Grund noch komplexer zu werden.

## Theoretischer Hintergrund

Betrachten wir jetzt einmal den theoretischen Hintergrund der ANCOVA. Ich habe dazu im Folgenden einmal einen sehr theoretischen Datensatz zusammengebaut. Es geht hier auch eher darum das Prinzip zu verstehen als die Formeln der ANCOVA zu zerlegen. Wir haben in dem Datensatz einen Faktor A mit drei Leveln vorliegen sowie eine Kovariate $c$. Erhoben haben wir den Messwert $y$ in unserem Experiment. Dabei ist jetzt wichtig, dass die Kovariate $c$ in den Leveln des Faktors A aufsteigend sortiert ist. Darüber hinaus sind die Abstände zwischen den Messwerten immer gleich. Das habe ich sogebaut, dass wir damit keinen Restfehler mehr in den Daten vorliegen haben.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-ancova-theo
#| tbl-cap: "Datentabelle von einem Faktor A mit drei Gruppen $A.1$, $A.2$ und $A.3$ je drei Beobachtungen sowie einer numerischen Kovariate $c$. Die Kovariate $c$ ist aus didaktischen Gründen in den Leveln des Faktors A aufsteigend sortiert."

f1_ancova_theo_tbl |> 
  select(fa, cov, rsp) |> 
  set_names(c("Faktor A", "Kovariate $c$", "Messwert $y$")) |>  
  tt(width = 2/3, align = "c", theme = "striped")
```

Jetzt können wir einmal die Mittelwerte der Faktorlevel sowie den Mitelwert der Kovariate für jedes Faktorlevel berechnen. Damit haben wir dann folgende Tabelle vorliegen. Die Idee ist hier, dass wir neben dem Effekt des Faktors noch einen Effekt der Kovariate vorliegen haben. In unserem Fall steigt die Kovariate stetig mit dem Messwert an. Daher kann ein Teil der Variation in den Messwerten $y$ durch die Kovariate erklärt werden.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-1fac-ancova-theo-desc
#| tbl-cap: "Mittelwerte der drei Gruppen $A.1$, $A.2$ und $A.3$ des Faktors A und der numerischen Kovariate $c$ innerhalb der jeweiligen Level des Faktors A."

f1_ancova_theo_stat_tbl <- f1_ancova_theo_tbl |> 
  group_by(fa) |> 
  summarise(mean_rsp = mean(rsp),
            mean_cov = mean(cov)) 

f1_ancova_theo_stat_tbl  |> 
  set_names(c("Faktor A", "Mittelwert Messwert", "Mittelwert Kovariate")) |> 
  tt(width = 1, align = "c", theme = "striped")
```

Berechnen wir also einmal das Modell mit `lm()` und lassen uns die Koeffizienten wiedergeben. Dann können wir eventuell das Modell und die ANCOVA dann besser verstehen. Nochmal, wir haben keinen Restfehler in den Daten, deshals sind die Werte so schon glatt, wenn ich runde.

```{r}
lm(rsp ~ fa + cov, data = f1_ancova_theo_tbl) |> 
  coef() |> round(2)
```

Was haben wir nun als Koeffizienten aus dem Modell vorliegen? Der y-Achsenabschnitt liegt bei $6$ und fällt damit mit dem Mittelwert der ersten Levels $A.1$ unter der Berücksichtigung des Effekts der Kovariate $cov$ zusammen. Daher ist der Mittelwert des Levels $A.1$ gleich $6 + 1.6 \times 1.25$. Die $1.6$ ist der Mittelwert der Kovariate für das Level $A.1$ des Faktors. Faktisch kippst du den globalen Mittelwert $\beta_0$ der ANOVA um die Steigung oder den Effekt der Kovariate $c$. Du adjustierst also den globalen Mittelwert zu dem verglichen werden soll. In der folgenden @fig-ggplot-anova-msa-mse siehst du nochmal den Zusammenhang der Daten zu den Koeffizienten aus dem Modell dargestellt. Die Koeffizienten des Level $A.2$ und $A.3$ sind jetzt nicht mehr die Änderungen zu einem fixen Wert sondern zu dem Wert auf der Geraden, die durch die Steigung der Kovariate $c$ gegeben ist. Eigentlich eine ganz geschickte Idee.

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-msa-mse
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 7.5
#| fig-cap: "Visualisierung der ANCOVA mit einem Faktor A mit drei Leveln sowie einer Kovariate $c$, die innerhalb des Level des Faktors aufsteigend sortiert wurde. Es liegt keine unerklärte Streuung in den Daten vor. Die Steigung der Kovariaten leigt bei $\\beta_c = 1.25$. Die Mittelwertsdifferenzen der Faktorlevel werden zu Geraden der Kovariaten berechnet. Die Referenz ist der Mittelwert der Gruppe $A.1$ und die Gerade läuft daher durch den Mittelwert dieser Gruppe. *[Zum Vergrößern anklicken]*"

ancova_theo_p
```

::: callout-tip
## Weitere Tutorien für die ANCOVA

Wie immer gibt es auch für die Frage nach dem Tutorium für die ANCOVA verschiedene Quellen. Ich kann noch folgende Informationen und Hilfen empfehlen.

-   [How to perform ANCOVA in R](https://finnstats.com/2021/07/22/how-to-perform-ancova-in-r/) liefert nochmal mehr Code und weitere Ideen zu der Analyse in R.
-   [ANCOVA in R](https://www.datanovia.com/en/lessons/ancova-in-r/) beschreibt auch nochmal etwas anders die ANCOVA und deren Anwendung in R
-   [Kovarianzanalyse](https://wgruber.github.io/Modellbildung2/kovarianzanalyse.html) ist eine deutsche Quelle, die nochmal vertiefend auf die Kovarianzanalyse eingeht, was eigentlich dann auch nichts anderes ist als eine ANCOVA zu rechen.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, broom, quantreg, car, afex,
               see, performance, emmeans, multcomp, janitor,
               parameters, conflicted)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::filter)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Daten

Dann fangen wir wie immer mit den Daten als Beispiel an. Ich habe hier dann einmal einen Datensatz mit einem Faktor A und einer Kovariate c zusammengebaut. Der Faktor ist in diesem Fall die Flohart mit `animal` und die Kovariate `weight` mit dem jeweiligen Gewicht des entsprechenden Flohs.

```{r}
fac1_cov_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "covariate-fac1") |> 
  select(animal, weight, jump_length) |> 
  mutate(animal = as_factor(animal),
         weight = round(weight, 2),
         jump_length = round(jump_length, 2)) |> 
  rownames_to_column(".id")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac1cov-table
#| tbl-cap: "foo."

repeated_raw_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "covariate-fac1") |> 
  mutate_if(is.numeric, round, 2)

rbind(head(repeated_raw_tbl, n = 3),
      rep("...", times = ncol(repeated_raw_tbl)),
      tail(repeated_raw_tbl, n = 3)) |> 
  tt(width = 1, align = "c", theme = "striped")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-fac1cov
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "foo."

fac1_cov_tbl |> 
  ggplot(aes(x = weight, y = jump_length, color = animal,
             group = animal, shape = animal)) +
  theme_minimal() +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, linetype = 11) +
  labs(x = "Gewicht in [mg]", y = "Sprungweite in [cm]", fill = "Flohart") +
  scale_color_okabeito() +
  theme(legend.position = "top")
```

```{r}
fac2_cov_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "covariate-fac2") |> 
  select(animal, stage, weight, jump_length) |> 
  mutate(animal = as_factor(animal),
         stage = factor(stage, level = c("juvenile", "adult")),
         weight = round(weight, 2),
         jump_length = round(jump_length, 2)) |> 
  rownames_to_column(".id")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-fac2cov-table
#| tbl-cap: "foo."

fac2_cov_raw_tbl <- read_excel("data/fleas_complex_data.xlsx", sheet = "covariate-fac2") |> 
  mutate_if(is.numeric, round, 2)

rbind(head(fac2_cov_raw_tbl, n = 3),
      rep("...", times = ncol(fac2_cov_raw_tbl)),
      tail(fac2_cov_raw_tbl, n = 3)) |> 
  kable(align = "c", "pipe")
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| label: fig-ggplot-anova-boxplot-fac2cov
#| fig-align: center
#| fig-height: 4
#| fig-width: 5
#| fig-cap: "foo."

 ggplot(data = fac2_cov_tbl, 
        aes(x = weight, y = jump_length, shape = animal,
            color = animal, linetype = stage)) +
  theme_minimal() +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Gewicht in [mg]", y = "Sprungweite in [cm]", color = "Flohart",
       linetype = "Entwicklungsstadium", shape = "Flohart") +
  scale_color_okabeito() +
  theme(legend.position = "top")

```

## Einfaktoriell

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal*weight, data = fac1_cov_tbl) |> 
  tidy()
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*weight, data = fac1_cov_tbl) |> 
  Anova() |> 
  tidy()
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*weight, data = fac1_cov_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy()
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal*weight + Error(.id), data = fac1_cov_tbl,
        factorize = FALSE) 
```
:::

## Zweifaktoriell

::: panel-tabset
## `{base}`

```{r}
aov(jump_length ~ animal*stage*weight, data = fac2_cov_tbl) |> 
  tidy()
```

## `{car}`

#### Varianzhomogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*weight, data = fac2_cov_tbl) |> 
  Anova() |> 
  tidy()
```

#### Varianzheterogenität {.unnumbered .unlisted}

```{r}
lm(jump_length ~ animal*stage*weight, data = fac2_cov_tbl) |> 
  Anova(white.adjust = TRUE)  |> 
  tidy()
```

## `{afex}`

```{r}
aov_car(jump_length ~ animal*stage*weight + Error(.id), data = fac2_cov_tbl,
        factorize = FALSE) 
```
:::

## Referenzen {.unnumbered}
