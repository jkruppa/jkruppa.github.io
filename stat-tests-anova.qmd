```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc, plyr)
```

# Die ANOVA {#sec-anova}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

[Historisch betrachtet ist die ANOVA, *das* statistische Verfahren was gut per Hand ohne Computer berechnet werden kann. Daher war die ANOVA von den 20zigern bis in die frühen 90ziger des letzten Jahrhunderts *das* statistische Verfahren der Wahl.]{.aside}

::: callout-tip
## Einführung in die ANOVA per Video

Du findest auf YouTube [Grundlagen in R](https://www.youtube.com/playlist?list=PLe51bCp9JvEFUnFqaJG5aRmON9i1ZbOYC) als Video Reihe. Ich werde zwar alles nochmal hier als Text aufschreiben, aber manchmal ist das Sehen und Hören dann einfacher.
:::

Die ANOVA (eng. *analysis of variance*) ist wichtig. Was für ein schöner Satz um anzufangen. Wir brauchen die ANOVA aus mehreren Gründen. Die Hochzeiten der ANOVA sind eigentlich vorbei, wir haben in der Statistik für viele Fälle mittlerweile besser Werkzeuge, aber als Allrounder ist die ANOVA immer noch nutzbar.

::: column-margin
Die tolle Webseite [Data Science for Agriculture in R](https://schmidtpaul.github.io/DSFAIR/index.html) liefert eine Vielzahl von experimentellen Designs sowie deren Auswertung. Neben anderen komplexeren Designs, auch diese einfacheren Designs, die jeder kennen sollte.

-   [Completely randomized design](https://schmidtpaul.github.io/DSFAIR/CRD_Mead1993.html), ist das Standarddesign für ein Feldexperiment.

-   [Randomized complete block design (RCBD) with 1 factor](https://schmidtpaul.github.io/DSFAIR/RCBD_ClewerScarisbrick2001.html), beschreibt ein Experiment mit Blöcken und einem Behandlungsfaktor.

-   [Randomized complete block design (RCBD) with 2 factors](https://schmidtpaul.github.io/DSFAIR/RCBD_2f_rice.html), beschreibt ein Experiment mit Blöcken und einem Behandlungsfaktor sowie einem weiteren Faktor.

-   [Latin square design](https://schmidtpaul.github.io/DSFAIR/latsquare_Bridges1989.html), ist ein etwas spezielleres Design, wird aber auch viel genutzt.

Wir gehen in einem späteren Kapitel nochmal auf die experimentellen Designs ein.
:::

Wofür brauchen wir die ANOVA?

1)  Wir brauchen die ANOVA um mehr als zwei Gruppen *gleichzeitig* miteinander zu vergleichen. Das heißt wir haben einen Faktor mit mehr als zwei Levels und wollen wissen, ob sich *mindestens* zwei Level bzw. Gruppen im mittelwert unterscheiden.
2)  Wir brauchen die ANOVA und deren Varianzzerlegung in der Züchtung. Hier speilt die ANOVA eine gewichtige Rolle bei der Abschätzung des genetischen Effekts. Wir werden aktuell (Stand Ende 2022) hierauf noch nicht tiefer eingehen.
3)  Wir nutzen die ANOVA in vielen Anwendunsggebieten als eine Arte Vortest um zu schauen, ob sich ein Effekt in den Daten verbirgt. Eigentlich stammt dieses Ritual aus ANOVA als Vortest und dann ein Posthoc Test noch aus der Zeit, wo wir keine moderen Rechner zu Verfügung hatten. Damals machte diese Reihenfolge noch Sinn. Wir werdend arüber aber später nochmal lesen.
4)  Experimentelle Designs sind darauf ausgelegt mit der ANOVA ausgewertet zu werden. Insbesondere in den Agrawissenschaften hat die ANOVA daher eine historische Bedeutung. Insbesondere durch die enge Verzahnung vom Experiment auf dem Feld und der eigentlichen Auswertung mit der ANOVA.

Wir sehen also, dass die ANOVA zum einen alt ist, aber auch heute noch viel verwendet wird. Daher werden wir in diesem *langem* Kapitel uns einmal mit der ANOVA ausgiebig beschäftigen. Fangen wir also an, dieses großartige Schwerzeitaschenmesser der Statistik besser zu verstehen.

::: callout-note
## Was macht die ANOVA?

Die *einfaktorielle* ANOVA vergleicht die Parameter mehrerer Normalverteilungen miteinander. Oder etwas anders formuliert, vergleicht die ANOVA die Mittlelwerte von mehreren Gruppen bzw. Behandlungen miteinander.

Die *zweifaktorielle* ANOVA vergleicht die Parameter mehrerer Normalverteilungen miteinander von zwei Faktoren. Oder etwas anders formuliert, vergleicht die ANOVA die Mittlelwerte von mehreren Gruppen bzw. Behandlungen miteinander. Dabei kann die *zweifaktorielle* ANOVA auch die Interaktion zwischen zwei Variablen abbilden.
:::

::: {.callout-caution collapse="true"}
## Ein Wort zur Klausur

Wir rechnen keine ANOVA in der Klausur *per Hand* sondern interpretieren die Ausgabe der R Funktionen einer einfaktoriellen oder zweifaktoriellen ANOVA. Auch hier gilt, überprüfe was du in der Vorlesung gehört hast!

Bitte schau dir unbedingt die Aufgaben in den [gesammelten Klausurfragen auf GitHub](https://github.com/jkruppa/teaching/tree/main/Klausur) an um eine Idee zu haben, welche Fragen zu der ANOVA drankommen.

Wenn kein $F_{\alpha = 5\%}$ in der Klausur gegeben ist, setzen wir $F_{\alpha = 5\%} = 3.55$.
:::

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
pacman::p_load(tidyverse, magrittr, broom, 
               readxl, effectsize, ggpubr)
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Einfaktorielle ANOVA {#sec-fac1}

Die einfaktorielle ANOVA ist die simpelste Form der ANOVA. Wir nutzen einen Faktor mit mehr als zwei Leveln. Im Rahmen der einfaktoriellen ANOVA wollen wir usn auch die ANOVA theoretisch einmal anschauen. Danach wie die einfaktorielle ANOVA in R genutzt wird. Ebenso wie wir die einfaktorielle ANOVA visualsieren. Abschließend müssen wir uns noch überlegen, ob es einen Effektschätzer für die einfaktorielle ANOVA gibt.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Die einfaktorielle ANOVA verlangt ein normalverteiltes $y$ sowie Varianzhomogenität über den Behandlungsfaktor $x$. Daher alle Level von $x$ sollen die gleiche Varianz haben.

Unsere Annahme an die Daten $D$ ist, dass das dein $y$ normalverteilt ist und das die Level vom $x$ homogen in den Varianzen sind. Später mehr dazu, wenn wir beides nicht vorliegen haben...
:::

### Daten für die einfaktorielle ANOVA

Wir wollen uns nun erstmal den einfachsten Fall anschauen mit einem simplen Datensatz. Wir nehmen ein normalverteiltes $y$ aus den Datensatz `flea_dog_cat_fox.csv` und einen Faktor mit mehr als zwei Leveln. Hätten wir nur zwei Level, dann können wir auch einen t-Test rechnen können.

Im Folgenden selektieren mit der Funktion `select()` die beiden Spalten `jump_length` als $y$ und die Spalte `animal` als $x$. Danach müssen wir noch die Variable `animal` in einen Faktor mit der Funktion `as_factor()` umwandeln.

```{r}
#| message: false

fac1_tbl <- read_csv2("data/flea_dog_cat_fox.csv") %>%
  select(animal, jump_length) %>% 
  mutate(animal = as_factor(animal))
```

Wir erhalten das Objekt `fac1_tbl` mit dem Datensatz in @tbl-data-anova-1 nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz für die einfaktorielle ANOVA mit einer normalverteilten Variable `jump_length` und einem Faktor `animal` mit drei Leveln.
#| label: tbl-data-anova-1

fac1_tbl %>% kable(align = "c", "pipe")
```

Wir bauen daher mit den beiden Variablen mit dem Objekt `fac1_tbl` folgendes Modell für später:

$$
jump\_length \sim animal
$$

Bevor wir jetzt das Modell verwenden, müssen wir uns nochmal überlegen, welchen Schluß wir eigentlich über die Nullhypothese machen. Wir immer können wir nur die Nullhypothese ablehnen. Daher überlegen wir uns im Folgenden wie die Nullhypothese in der einfaktoriellen ANOVA aussieht. Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

### Hypothesen für die einfaktorielle ANOVA

Die ANOVA betrachtet die Mittelwerte und nutzt die Varianzen um einen Unterschied nachzuweisen. Daher haben wir in der Nullhypothese als Gleichheitshypothese. In unserem Beispiel lautet die Nullhypothese, dass die Mittelwerte jedes Levels des Faktors `animal` gleich sind.

$$
H_0: \; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}
$$

Die Alternative lautet, dass sich mindestens ein paarweiser Vergleich in den Mittelwerten unterschiedet. Hierbei ist das *mindestens ein Vergleich* wichtig. Es können sich alle Mittelwerte unterschieden oder eben nur ein Paar. Wenn eine ANOVA die $H_0$ ablehnt, also ein signifikantes Ergebnis liefert, dann wissen wir nicht, welche Mittelwerte sich unterscheiden.

$$
\begin{aligned}
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{aligned}
$$

Wir schauen uns jetzt einmal die ANOVA theoretisch an bevor wir uns mit der Anwendung der ANOVA in R beschäftigen.

### Einfaktoriellen ANOVA theoretisch

Kommen wir zurück zu den Daten in @tbl-data-anova-1. Wenn wir die ANOVA per Hand rechnen wollen, dann ist nicht das Long Format die beste Wahl sondern das Wide Format. Wir haben ein balanciertes Design vorliegen, dass heißt in jeder Level sind die gleiche Anzahl Beobachtungen. Wir schauen uns jeweils sieben Flöhe von jeder Tierart an. Für eine ANOVA ist aber ein balanciertes Design nicht notwendig, wir können auch mit ungleichen Gruppengrößen eine ANOVA rechnen.

[Statt einer einfaktoriellen ANOVA könnten wir auch gleich einen `pairwise.t.test()`rechnen. Historisch ebtrachtet ist die einfaktorielle ANOVA die Visualsierung des paarweisen t-Tests.]{.aside}

Eien einfaktorielle ANOVA macht eigentlich keinen großen Sinn, wenn wir anschließend sowieso paarweise Vergleich, wie in @sec-posthoc beschrieben, rechnen. Aus der Hisotrie stellte sich die Frage, ob es sich lohnt die ganze Arbeit für die paarweisen t-Tests per Hand zu rechnen. Daher wurde die ANOVA davorgeschaltet. War die ANOVA nicht signifikant, dann konnte man sich dann auch die Rechnerei für die paaweisen t-Tests sparen.

In @tbl-fac1-wide-01 sehen wir die Daten einmal als Wide Format dargestellt.

|  j  | dog  | cat | fox  |
|:---:|:----:|:---:|:----:|
|  1  | 5.7  | 3.2 | 7.7  |
|  2  | 8.9  | 2.2 | 8.1  |
|  3  | 11.8 | 5.4 | 9.1  |
|  4  | 8.2  | 4.1 | 9.7  |
|  5  | 5.6  | 4.3 | 10.6 |
|  6  | 9.1  | 7.9 | 8.6  |
|  7  | 7.6  | 6.1 | 10.3 |

: Wide Format der Beispieldaten `fac1_tbl` für die jeweils $j=7$ Beobachtungen für den Faktor `animal`. {#tbl-fac1-wide-01}

Wir können jetzt für jedes de Level den Mittelwert über all $j=7$ Beobachtungen berechnen.

$$
\begin{aligned}
\bar{y}_{dog} &= 8.13 \\
\bar{y}_{cat} &= 4.74 \\
\bar{y}_{fox} &= 9.16 \\
\end{aligned}
$$

Wir tuen jetzt für einen Moment so, als gebe es den Faktor `animal` nicht in den Daten und schauen uns die Verteilung der einzelnen Beobachtungen in @fig-anova-exp-1-1 einmal an. Wir sehen das sich die Beobachtungen von ca. 2.2cm bis 11 cm streuen. Woher kommt nun diese Streuung bzw. Varianz? Was ist die Quelle der Varianz? In @fig-anova-exp-1-2 haben wir die Punkte einmal nach dem Faktor `animal` eingefärbt. Wir sehen, dass die blauen Beobachtungen eher weitere Sprunglängen haben als die grünen Beobachtungen. Wir gruppieren die Beobachtungen in @fig-anova-exp-1-3 nach dem Faktor `animal` und sehen, dass ein Teil der Varianz der Daten von dem Faktor `animal` ausgelöst wird.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-1
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Die Spungweite in [cm] in Abhängigkeit von dem Faktor `animal` dargestellt."
#| fig-subcap: 
#|   - "Die Sprungweite in [cm] ohne den Faktor `animal` betrachtet."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` eingefärbt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` eingefärbt und gruppiert."
#| layout-nrow: 1
#| column: page

ggplot(fac1_tbl, aes(x = as.factor(1), y = jump_length)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("")

ggplot(fac1_tbl, aes(x = as.factor(1), y = jump_length, fill = animal)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("")

ggplot(fac1_tbl, aes(x = animal, y = jump_length, color = animal)) + 
  geom_point() +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        legend.position="none") +
  ylab("") + xlab("") 
```

Gehen wir einen Schritt weiter und zeichnen einmal das globale Mittel in die @fig-anova-exp-5-1 von $\bar{y}_{..} = 7.34$ und lassen die Beobachtungen gruppiert nach dem Faktor `animal`. Wir sehen, dass die Level des Faktors `animal` um das globale Mittel streuen. Was ja auch bei einem Mittelwert zu erwarten ist. Wir können jetzt in @fig-anova-exp-5-2 die lokalen Mittel für die einzelnen Level `dog`, `cat`und `fox` ergänzen. Und abschließend in @fig-anova-exp-5-3 die Abweichungen $\\beta_i$ zwischen dem globalen Mittel $\bar{y}_{..} = 7.34$ und den einzelnen lokalen Mittel berechnen. Die Summe der Abweichungen $\\beta_i$ ist $0.79 + (-2.6) + 1.81 \approx 0$. Das ist auch zu erwarten, den das globale Mittel muss ja per Definition als Mittelwert gleich großen Abstand "nach oben" wie "nach unten" haben.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-5
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Dotplot der Spungweite in [cm] in Abhängigkeit von dem Faktor `animal`."
#| fig-subcap: 
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und das globale Mittel $\\bar{y}_{..} = 7.34$ ergänzt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und die lokalen Mittel $\\bar{y}_{i.}$ für jedes Level ergänzt."
#|   - "Die Sprungweite in [cm] mit den Faktor `animal` gruppiert und die Abweichungen $\\beta_i$ ergänzt."
#| layout-nrow: 1
#| column: page

stat <- ddply(fac1_tbl, "animal", summarize,
              mean = mean(jump_length, na.rm = TRUE),
              sd = round(sd(jump_length, na.rm = TRUE), 2))
grand_mean <- mean(fac1_tbl$jump_length, na.rm = TRUE)

ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(round(grand_mean, 2))) +
  ylab("") + xlab("")


ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  stat_summary(fun = mean, aes(ymin=..y.., ymax=..y..), 
               geom='errorbar', width = 0.5, color = "black", size = 1.25) +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(4.75, round(grand_mean, 2), 8.13, 9.16)) +
  ylab("") + xlab("")


ggplot(fac1_tbl, aes(x = animal, y = jump_length, fill = animal)) + 
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  stat_summary(fun = mean, aes(ymin=..y.., ymax=..y..), 
               geom='errorbar', width = 0.5, color = "black", size = 1.25) +
  geom_hline(yintercept = mean(fac1_tbl$jump_length), size = 1.25, linetype = "dashed",
             alpha = 0.5) +
  annotate("text", x = 1:3, y = 6.7, size = 5,
           label = round(stat$mean - grand_mean, 2)) +
  theme(legend.position="none") +
  scale_y_continuous(breaks = c(4.75, round(grand_mean, 2), 8.13, 9.16)) +
  ylab("") + xlab("")

```

Wir tragen die Werte der lokalen Mittlwerte $\bar{y}_{i.}$ und deren Abweichungen $\beta_i$ vom globalen Mittelwert $\bar{y}_{..} = 7.34$ noch in die @tbl-fac1-wide-02 ein. Wir sehen in diesem Beispiel warum das Wide Format *besser* ist, wenn wir die lokalen Mittelwerte und die Abweichungen per Hand berechnen. Da wir in der Anwendung aber *nie* die ANOVA per Hand rechnen, liegen unsere Daten immer in R als Long Format vor.

|       j        |  dog   |  cat   |  fox   |
|:--------------:|:------:|:------:|:------:|
|       1        |  5.7   |  3.2   |  7.7   |
|       2        |  8.9   |  2.2   |  8.1   |
|       3        |  11.8  |  5.4   |  9.1   |
|       4        |  8.2   |  4.1   |  9.7   |
|       5        |  5.6   |  4.3   |  10.6  |
|       6        |  9.1   |  7.9   |  8.6   |
|       7        |  7.6   |  6.1   |  10.3  |
| $\bar{y}_{i.}$ | $8.13$ | $4.74$ | $9.16$ |
|   $\beta_i$    | $-2.6$ | $0.79$ | $1.81$ |

: Wide Format der Beispieldaten `fac1_tbl` für die jeweils $j=7$ Beobachtungen für den Faktor `animal`. Wir ergänzen die lokalen Mittlwerte $\bar{y}_{i.}$ und deren Abweichungen $\beta_i$ vom globalen Mittelwert $\bar{y}_{..} = 7.34$. {#tbl-fac1-wide-02}

Wie kriegen wir nun die ANOVA rechnerisch auf die Straße? Schauen wir uns dazu einmal die @fig-anova-exp-6 an. Auf der linken Seiten sehen wir vier Gruppen, die keinen Effekt haben. Die Gruppen liegen alle auf der gleichen Höhe. Es ist mit keinem Unterschied zwischen den Gruppen zu rechnen. Alle Gruppen*mittel* liegen auf dem globalen Mittel. Die Abweichungen der einzelnen Gruppen*mittel* zum globalen Mittel ist damit gleich null. Auf der rechten Seite sehen wir vier Gruppen mit einem Effekt. Die Gruppen unterscheiden sich in ihren Gruppen*mitteln*. Dadurch unterscheide sich aber auch die Gruppen*mittel* von dem globalen Mittel.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-exp-6
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: "Darstellung von keinem Effekt und leichtem bis mittleren Effekt in einer einfaktoriellen ANOVA mit einem Faktor mit vier Leveln A - D."
#| fig-subcap: 
#|   - "Kein Effekt"
#|   - "Leichter bis mittlerer Effekt"
#| layout-nrow: 1
#| column: page

no_effect_df <- setNames(stack(tibble(A = rnorm(20, 20, 1),
                                     B = rnorm(20, 20, 1),
                                     C = rnorm(20, 20, 1),
                                     D = rnorm(20, 20, 1))),
                        c("values", "trt"))

ggplot(no_effect_df, aes(x = trt, y = values, fill = trt)) + geom_boxplot() +
  theme_bw() +
  ##scale_fill_manual(values = par$cbbPalette) +
  theme(legend.position="none") +
  ylab("") + xlab("")

light_effect_df <- setNames(stack(tibble(A = rnorm(20, 20, 3),
                                         B = rnorm(20, 25, 4),
                                         C = rnorm(20, 15, 4),
                                         D = rnorm(20, 35, 3))),
                            c("values", "trt"))

ggplot(light_effect_df, aes(x = trt, y = values, fill = trt)) + geom_boxplot() +
  theme_bw() +
  ##scale_fill_manual(values = par$cbbPalette) +
  theme(legend.position="none") +
  ylab("") + xlab("")

```

Wir können daher wie in @tbl-sum-anova-eff geschrieben die Funktionsweise der ANOVA zusammenfassen.

|                            |     |                                                                   |
|:--------------------------:|:---:|:-----------------------------------------------------------------:|
| All level means are equal. |  =  | The differences between level means and the total mean are small. |

: Zusammenfassung der ANOVA Funktionsweise. {#tbl-sum-anova-eff}

Nun kommen wir zum eigentlichen Schwenk und warum eigentlich die ANOVA meist etwas verwirrt. Wir wollen eine Aussage über die Mittelwerte machen. Die Nullhypothese lautet, dass alle Mittelwerte gleich sind. Wie wir in @tbl-sum-anova-eff sagen, heißt alle Mittelwerte gleich auch, dass die Abweichungen von den Gruppenmitteln zum globalen Mittel klein ist.

Wie weit die Gruppenmittel von dem globalen Mittel weg sind, dazu nutzt die ANOVA die Varianz. Die ANOVA vergleicht somit

-   die Varianz der einzelnen Mittelwerte der (Gruppen)Level zum globalen Mittel (eng. *variability between levels*)
-   und die Varianz der Beobachtungen zu den einzelnen Mittelwerten der Level (eng. *variability within one level*)

[Die *sum of squares* sind nichts anderes als die Varianz. Wir nennen das hier nur einmal anders...]{.aside}

Wir berechnen also wie die Beobachtungen jeweils um das globale Mittel streuen ($SS_{total}$), die einzelnen Beobachtungen um die einzelnen Gruppenmittel $SS_{error}$ und die Streuung der Gruppenmittel um das globale Mittel ($SS_{animal}$). Wir nennen die Streuung Abstandquadrate (eng. *sum of squares*) und damit sind die *Sum of Square* $(SS)$ nichts anderes als die Varianz. Die @tbl-sumsquares zeigt die Berechnung des Anteils jeder einzlenen Beobachtung an den jeweiligen *Sum of Squares*.

::: column-page
| animal (x) | jump_length (y) | $\boldsymbol{\bar{y}_{i.}}$ | SS$_{\boldsymbol{animal}}$ | SS$_{\boldsymbol{error}}$ | SS$_{\boldsymbol{total}}$ |
|:----------:|:---------------:|:---------------------------:|:--------------------------:|:-------------------------:|:-------------------------:|
|    dog     |      $5.7$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(5.7 - 8.13)^2 = 5.90$  |  $(5.7 - 7.34)^2 = 2.69$  |
|    dog     |      $8.9$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(8.9 - 8.13)^2 = 0.59$  |  $(8.9 - 7.34)^2 = 2.43$  |
|    dog     |     $11.8$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  | $(11.8 - 8.13)^2 = 13.47$ | $(11.8 - 7.34)^2 = 19.89$ |
|    dog     |      $8.2$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(8.2 - 8.13)^2 = 0.00$  |  $(8.2 - 7.34)^2 = 0.74$  |
|    dog     |      $5.6$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(5.6 - 8.13)^2 = 6.40$  |  $(5.6 - 7.34)^2 = 3.03$  |
|    dog     |      $9.1$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(9.1 - 8.13)^2 = 0.94$  |  $(9.1 - 7.34)^2 = 3.10$  |
|    dog     |      $7.6$      |           $8.13$            |  $(8.13 - 7.34)^2 = 0.62$  |  $(7.6 - 8.13)^2 = 0.28$  |  $(7.6 - 7.34)^2 = 0.07$  |
|    cat     |      $3.2$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(3.2 - 4.74)^2 = 2.37$  | $(3.2 - 7.34)^2 = 17.14$  |
|    cat     |      $2.2$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(2.2 - 4.74)^2 = 6.45$  | $(2.2 - 7.34)^2 = 26.42$  |
|    cat     |      $5.4$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(5.4 - 4.74)^2 = 0.44$  |  $(5.4 - 7.34)^2 = 3.76$  |
|    cat     |      $4.1$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(4.1 - 4.74)^2 = 0.41$  | $(4.1 - 7.34)^2 = 10.50$  |
|    cat     |      $4.3$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(4.3 - 4.74)^2 = 0.19$  |  $(4.3 - 7.34)^2 = 9.24$  |
|    cat     |      $7.9$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(7.9 - 4.74)^2 = 9.99$  |  $(7.9 - 7.34)^2 = 0.31$  |
|    cat     |      $6.1$      |           $4.74$            |  $(4.74 - 7.34)^2 = 6.76$  |  $(6.1 - 4.74)^2 = 1.85$  |  $(6.1 - 7.34)^2 = 1.54$  |
|    fox     |      $7.7$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(7.7 - 9.16)^2 = 2.13$  |  $(7.7 - 7.34)^2 = 0.13$  |
|    fox     |      $8.1$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(8.1 - 9.16)^2 = 1.12$  |  $(8.1 - 7.34)^2 = 0.58$  |
|    fox     |      $9.1$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(9.1 - 9.16)^2 = 0.00$  |  $(9.1 - 7.34)^2 = 3.10$  |
|    fox     |      $9.7$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(9.7 - 9.16)^2 = 0.29$  |  $(9.7 - 7.34)^2 = 5.57$  |
|    fox     |     $10.6$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  | $(10.6 - 9.16)^2 = 2.07$  | $(10.6 - 7.34)^2 = 10.63$ |
|    fox     |      $8.6$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  |  $(8.6 - 9.16)^2 = 0.31$  |  $(8.6 - 7.34)^2 = 1.59$  |
|    fox     |     $10.3$      |           $9.16$            |  $(9.16 - 7.34)^2 = 3.31$  | $(10.3 - 9.16)^2 = 1.30$  | $(10.3 - 7.34)^2 = 8.76$  |
|            |                 |                             |          $74.68$           |          $56.53$          |         $131.21$          |

: Berechnung der $SS_{animal}$, $SS_{error}$ und $SS_{total}$ anhand der einzelnen gemessenen Werte $y$ für durch die jeweiligen Gruppenmittel $\bar{y}_{i.}$ und dem globalen Mittel $\bar{y}_{..}$ über alle Beobachtungen {#tbl-sumsquares}
:::

Die ANOVA wird deshalb auch Varianz*zerlegung* genannt, da die ANOVA versucht den Abstand der Beoabchtungen auf die Variablen im Modell zu zerlegen. Also wieviel der Streuung von den Beobachtungen kann von dem Faktor `animal` erklärt werden? Genau der Abstand von den Gruppenmitteln zu dem globalen Mittlelwert.

Du kannst dir das ungefähr als eine Reise von globalen Mittelwert zu der einzelnen Beobachtung vorstellen. Nehmen wir als Beispiel die kleinste Sprungweite eines Katzenflöhes von 2.2 cm und visualisieren wir uns die Reise wie in @fig-single-cat-anova zu sehen. Wie kommen wir jetzt *numerisch* vom globalen Mittel mit $7.34$ zu der Beobachtung? Wir können zum einen den direkten Abstand mit $2.2 - 7.34$ gleich $-5.14$ cm berechnen. Das wäre der *total* Abstand. Wie sieht es nun aus, wenn wir das Gruppenmittel mit beachten? In dem Fall gehen wir vom globalen Mittel zum Gruppenmittel `cat` mit $\bar{y}_{cat} - \bar{y}_{..} = 4.74 -7.34$ gleich $\beta_{cat} = -2.6$ cm. Jetzt sind wir aber noch nicht bei der Beobachtung. Wir haben noch einen Rest von $y_{cat,2} - \bar{y}_{cat} = 2.2 - 4.74$ gleich $\epsilon_{cat, 2} = -2.54$ cm, die wir noch zurücklegen müssen. Das heißt, wir können einen Teil der Strecke mit dem Gruppenmittelwert erklären. Oder anders herum, wir können die Strecke vom globalen Mittelwert zu der Beobachtung in einen Teil für das Gruppenmittel und einen unerklärten Rest zerlegen.

::: column-page
![Visualisierung der Varianzzerlegung des Weges vom globalen Mittel zu der einzelnen Beoabchtung. Um zu einer einzelnen Beobachtung zu kommen legen wir den Weg vom globalen Mittelwert über den Abstand vom globalen Mittel zum Gruppenmittel $\beta$ zurück. Dann fehlt noch der Rest oder Fehler oder Residuum $\epsilon$.](images/anova-pre-01.png){#fig-single-cat-anova fig-align="center" width="80%"}
:::

Wir rechnen also eine ganze Menge an Abständen und quadrieren dann diese Absatände zu den Sum of Squares. Oder eben der Varianz. Dann fragen wir uns, ob der Faktor in unserem Modell einen Teil der Abstände erklären kann. Wir bauen uns dafür eine ANOVA Tabelle. @tbl-anova-fac1-theo zeigt eine theoretische, einfaktorielle ANOVA Tabelle. Wir berechnen zuerst die Abstände als $SS$. Nun ist es aber so, dass wenn wir in einer Gruppe viele Level und/oder Beoabchtungen haben, wir auch größere Sum of Squares bekommen. Wir müssen also die Sum of Squares in mittlere Abweichungsqudrate (eng. *mean squares*) mitteln. Abschließend können wir die F Statistik berechnen, indem wir die $MS$ des Faktors durch die $MS$ des Fehlers teilen. Das Verhältnis von erklärter Varianz vom Faktor zu dem unerklärten Rest.

::: column-page
| Varianzquelle |  df   |                             Sum of squares                             |               Mean squares               |           F$_{\boldsymbol{calc}}$            |
|:-------------:|:-----:|:----------------------------------------------------------------------:|:----------------------------------------:|:--------------------------------------------:|
|    animal     | $k-1$ |    $SS_{animal} = \sum_{i=1}^{k}n_i(\bar{y}_{i.} - \bar{y}_{..})^2$    | $MS_{animal} = \cfrac{SS_{animal}}{k-1}$ | $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$ |
|     error     | $n-k$ | $SS_{error} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{i.})^2$ |  $MS_{error} = \cfrac{SS_{error}}{N-k}$  |                                              |
|     total     | $n-1$ | $SS_{total} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{..})^2$ |                                          |                                              |

: Einfaktorielle ANOVA in der theoretischen Darstellung. Die sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac1-theo}
:::

Wir füllen jetzt die @tbl-anova-fac1-example einmal mit den Werten aus. Nachdem wir das getan haben oder aber die Tabelle in R ausgegeben bekommen haben, können wir die Zahlen interpretieren.

::: column-page
| Varianzquelle |   df   |    Sum of squares     |                Mean squares                |         F$_{\boldsymbol{calc}}$          |
|:-------------:|:------:|:---------------------:|:------------------------------------------:|:----------------------------------------:|
|    animal     | $3-1$  | $SS_{animal} = 74.68$ | $MS_{animal} = \cfrac{74.68}{3-1} = 37.34$ | $F_{calc} = \cfrac{37.34}{3.14} = 11.89$ |
|     error     | $21-3$ | $SS_{error} = 56.53$  |  $MS_{error} = \cfrac{56.53}{18} = 3.14$   |                                          |
|     total     | $21-1$ | $SS_{total} = 131.21$ |                                            |                                          |

: Einfaktorielle ANOVA mit den ausgefüllten Werten. Die $SS_{total}$ sind die Summe der $SS_{animal}$ und $SS_{error}$. Die $MS$ berechnen sich dan direkt aus den $SS$ und den Freiheitsgraden ($df$). Abschließend ergibt sich dann die F Statistik. {#tbl-anova-fac1-example}
:::

Zu erst ist die berechnete F Statistik $F_{calc}$ von Interesse. Wir haben hier eine $F_{calc}$ von 11.89. Wir vergleichen wieder die berechnete F Statistik mit einem kritsichen Wert. Der kritische F Wert $F_{\alpha = 5\%}$ lautet für die einfaktorielle ANOVA in diesem konkreten Beispiel mit $F_{\alpha = 5\%} = `r round(qf(p=.05, df1=2, df2=18, lower.tail=FALSE), 2)`$. Die Enstscheidungsregel nach der F Testatitik lautet, die $H_0$ abzulehnen, wenn $F_{calc} > F_{\alpha = 5\%}$.

Wir können also die Nullhypothese $H_0$ in unserem Beispiel ablehnen. Es liegt ein signifikanter Unterschied zwischen den Tiergruppen vor. Mindestens ein Mittelwertsunterschied in den Sprungweiten liegt vor.

::: callout-important
## Entscheidung mit der berechneten Teststatistik $F_{\boldsymbol{calc}}$

Bei der Entscheidung mit der berechneten Teststatistik $F_{calc}$ gilt, wenn $F_{calc} \geq F_{\alpha = 5\%}$ wird die Nullhypothese (H$_0$) abgelehnt.

**Achtung --** Wir nutzen die Entscheidung mit der Teststatistik *nur und ausschließlich* in der Klausur. In der praktischen Anwendung hat die Betrachtung der berechneten Teststatistik *keine* Verwendung mehr.
:::

### Einfaktoriellen ANOVA in R

[Um eine ANOVA zu rechnen nutzen wir *zuerst* die Funktion `lm()`, warum das so ist kannst du im @sec-modeling-simple-stat nachlesen. Du brauchst das Wissen aber hier nicht unbedingt.]{.aside}

Wir rechnen keine ANOVA per Hand sondern nutzen R. Dazu müssen wir als erstes das Modell definieren. Das ist im Falle der infaktoriellen ANOVA relativ einfach. Wir haben unseren Datensatz `fac1_tbl` mit einer kontinuierlichen Variable `jump_lemgth` als $y$ vorliegen sowie einen Faktor `animal` mit mehr als zwei Leveln als $x$. Wir definieren das Modell in R in der Form `jump_length ~ animal`. Um das Modell zu rechnen nutzen wir die Funktion `lm()` - die Abkürzung für *linear model*. Danach pipen wir die Ausgabe vom `lm()` direkt in die Funktion `anova()`. Die Funktion `anova` berechnet uns dann die eigentliche einfaktorielle ANOVA. Wir speichern die Ausgabe der ANOVA in `fit_1`. Schauen wir uns die ANOVA Ausgabe einmal an.

```{r}
fit_1 <-  lm(jump_length ~ animal, data = fac1_tbl) %>% 
  anova

fit_1
```

Wir erhalten die Information was wir gerechnet haben, eine Varianzanalyse. Darunter steht, was das $y$ war nämlich die `jump_length`. Wir erhalten eine Zeile für den Faktor `animal` und damit die $SS_{animal}$ und eine Zeile für den Fehler und damit den $SS_{error}$. In R heißen die $SS_{error}$ dann `Residuals`. Die Zeile für die $SS_{total}$ fehlt.

Neben der berechneten F Statistik $F_{calc}$ von $11.89$ erhalten wir auch den p-Wert mit $0.005$. Wir ignorieren die F Statistik, da wir in der Anwendung nur den p-Wert berücksichtigen. Die Entscheidung gegen die Nulhypothese lautet, dass wenn der p-Wert kleiner ist als das Signifkanzniveau $\alpha$ von 5% wir die Nullhypothese ablehnen.

Wir haben hier ein signifikantes Ergebnis vorliegen. Mindestens ein Gruppenmittelerstunterschied ist signifikant. @fig-boxplot-anova-1 zeigt nochmal die Daten `fac1_tbl` als Boxplot. Wir überprüfen visuell, ob das Ergebnis der ANOVA stimmen kann. Ja, die Boxplots und das Ergebnis der ANOVA stimmen überein. Die Boxplots liegen nicht alle auf einer Ebene, so dass hier auch ein signifikanter Unterschied zu erwarten war.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden-, Katzen- und Fuchsflöhen.
#| label: fig-boxplot-anova-1

ggplot(fac1_tbl, aes(x = animal, y = jump_length, 
                     fill = animal)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() +
  theme(legend.position = "none") 

```

Abschließend können wir noch die Funktion `eta_squared()` aus dem R Paket `effectsize` nutzen um einen Effektschätzer für die einfaktorielle ANOVA zu berechnen. Wir können mit $\eta^2$ abschätzen, welchen Anteil der Faktor `animal` an der gesamten Varianz erklärt.

```{r}
fit_1 %>% eta_squared
```

Das $\eta^2$ können wir auch einfach händisch berechnen.

$$
\eta^2 = \cfrac{SS_{animal}}{SS_{total}} = \cfrac{74.68}{131.21} = 0.57 = 57\%
$$

Wir haben nun die Information, das 57% der Varianz der Beobachtungen durch den Faktor `animal` rklärt wird. Je nach Anwendungsgebiet kann die Relevanz sehr stark variieren. Im Bereich der Züchtung mögen erklärte Varianzen von unter 10% noch sehr relevant sein. Im Bereich des Feldexperiments erwarten wir schon höhere Werte für $\eta^2$. Immerhin sollte ja unsere Behandlung maßgeblich für die z.B. größeren oder kleineren Pflanzen gesorgt haben.

## Zweifaktorielle ANOVA {#sec-fac2}

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Die zweifaktorielle ANOVA verlangt ein normalverteiltes $y$ sowie Varianzhomogenität jeweils separat über beide Behandlungsfaktor $x_1$ und $x_2$. Daher alle Level von $x_1$ sollen die gleiche Varianz haben. Ebenso sollen alle Level von $x_2$ die gleiche Varianz haben.

Unsere Annahme an die Daten $D$ ist, dass das dein $y$ normalverteilt ist und das die Level vom $x_1$ und $x_2$ jewiels für sich homogen in den Varianzen sind. Später mehr dazu, wenn wir beides nicht vorliegen haben...
:::

Die zweifaktorielle ANOVA ist eine wunderbare Methode um herauszufinden, ob zwei Faktoren einen Einfluss auf ein normalverteiltes $y$ haben. Die Stärke der zweifaktoriellen ANOVA ist hierbei, dass die ANOVA *beide* Effekte der Faktoren auf das $y$ simultan modelliert. Darüber hinaus können wir auch noch einen Interaktionsterm mit in das Modell aufnehmen um zu schauen, ob die beiden Faktoren untereinander auch interagieren. Somit haben wir mit der zweifaktoriellen ANOVA die Auswertungsmehode für ein randomiziertes Blockdesign vorliegen.

### Daten für die zweifaktorielle ANOVA

Wir wollen uns nun einen etwas komplexes Modell anschauen mit einem etwas komplizierteren Datensatz `flea_dog_cat_fox_site.csv`. Wir brauchen hierfür ein normalverteiltes $y$ und sowie zwei Faktoren. Das macht auch soweit Sinn, denn wir wollen ja auch eine zweifaktorielle ANOVA rechnen.

Im Folgenden selektieren mit der Funktion `select()` die beiden Spalten `jump_length` als $y$ und die Spalte `animal` sowie die Spalte `site` als $x$. Danach müssen wir noch die Variable `animal` sowie die Variable `site` in einen Faktor mit der Funktion `as_factor()` umwandeln.

```{r}
#| message: false

fac2_tbl <- read_csv2("data/flea_dog_cat_fox_site.csv") %>% 
  select(animal, site, jump_length) %>% 
  mutate(animal = as_factor(animal),
         site = as_factor(site))
```

Wir erhalten das Objekt `fac2_tbl` mit dem Datensatz in @tbl-data-anova-2 nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| tbl-cap: Selektierter Datensatz für die zweifaktorielle ANOVA mit einer normalverteilten Variable `jump_length` und einem Faktor `animal` mit drei Leveln  sowie dem Faktor `site` mit vier Leveln.
#| label: tbl-data-anova-2

fac2_tbl %>% kable(align = "c", "pipe")
```

Die Beispieldaten sind in @fig-boxplot-anova-2 abgebildet. Wir sehen auf der x-Achse den Faktor `animal` mit den drei Leveln `dog`, `cat` und `fox`. Jeder dieser Faktorlevel hat nochmal einen Faktor in sich. Dieser Faktor lautet `site` und stellt dar, wo die Flöhe gesammelt wurden. Die vier Level des Faktors `site` sind `city`, `smalltown`, `village` und `field`.

```{r}
#| message: false
#| echo: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-boxplot-anova-2

ggplot(fac2_tbl, aes(x = animal, y = jump_length, 
                     fill = site)) +
  geom_boxplot() +
  labs(x = "Tierart", y = "Sprungweite [cm]") +
  theme_bw() 
```

Wir bauen dann mit den beiden Variablen bzw. Faktoren `animal` und `site` aus dem Objekt `fac2_tbl` folgendes Modell für die zweifaktorielle ANOVA:

$$
jump\_length \sim animal + site
$$

Bevor wir jetzt das Modell verwenden, müssen wir uns nochmal überlegen, welchen Schluß wir eigentlich über die Nullhypothese machen. Wir immer können wir nur die Nullhypothese ablehnen. Daher überlegen wir uns im Folgenden wie die Nullhypothese in der zweifaktoriellen ANOVA aussieht. Dann bilden wir anhand der Nullhypothese noch die Alternativehypothese.

### Hypothesen für die zweifaktorielle ANOVA

Wir haben für jeden Faktor der zweifaktoriellen ANOVA ein Hypothesenpaar. Im Folgenden sehen wir die jeweiligen Hypothesenpaare.

Einmal für `animal`, als Haupteffekt. Wir nennen einen Faktor den Hauptfaktor, weil wir an diesem Faktor am meisten interessiert sind. Wenn wir später einen Posthoc Test durchführen würden, dann würden wir diesen Faktor nehmen. Wir sind primär an dem Unterschied der Sprungweiten in \[cm\] in Gruppen Hund, Katze und Fuchs interessiert.

$$
\begin{aligned}
H_0: &\; \bar{y}_{cat} = \bar{y}_{dog} = \bar{y}_{fox}\\
H_A: &\; \bar{y}_{cat} \ne \bar{y}_{dog}\\
\phantom{H_A:} &\; \bar{y}_{cat} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \bar{y}_{dog} \ne \bar{y}_{fox}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{aligned}
$$

Einmal für `site`, als Nebeneffekt oder Blockeffekt oder Clustereffekt. Meist eine Variable, die wir auch erhoben haben und *vermutlich* auch einen Effekt auf das $y$ haben wird. Oder aber wir haben durch das exprimentelle Design noch eine Aufteilungsvariable wie Block vorliegen. In unserem Beispiel ist es `site` oder der Ort, wo wir die Hunde-, Katzen, und Fuchsflöhe gefunden haben.

$$
\begin{aligned}
H_0: &\; \bar{y}_{city} = \bar{y}_{smalltown} = \bar{y}_{village} = \bar{y}_{field}\\
H_A: &\; \bar{y}_{city} \ne \bar{y}_{smalltown}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{city} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{village}\\
\phantom{H_A:} &\; \bar{y}_{smalltown} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \bar{y}_{village} \ne \bar{y}_{field}\\
\phantom{H_A:} &\; \mbox{für mindestens ein Paar}
\end{aligned}
$$

Einmal für die Interaktion `animal:site` - die eigentliche Stärke der zweifaktoriellen ANOVA. Wir können uns anschauen, ob die beiden Faktoren miteinander interagieren. Das heißt, ob eine Interaktion zwischen dem Faktor `animal` und dem Faktor `site` vorliegt.

$$
\begin{aligned}
H_0: &\; \mbox{keine Interaktion}\\
H_A: &\; \mbox{eine Interaktion zwischen animal und site}
\end{aligned}
$$

Wir haben also jetzt die verschiedenen Hypothesenpaare definiert und schauen uns jetzt die ANOVA in R einmal in der Anwendung an.

### Zweifaktoriellen ANOVA in R

Bei der einfaktoriellen ANOVA haben wir die Berechnungen der Sum of squares nochmal nachvollzogen. Im Falle der zweifaktoriellen ANOVA verzichten wir darauf. Das Prinzip ist das gleiche. Wir haben nur mehr Mitelwerte und mehr Abweichungen von diesen Mittelwerten, da wir ja nicht nur einen Faktor `animal` vorliegen haben sondern auch noch den Faktor `site`. Da wir aber die ANOVA nur Anwenden und dazu R nutzen, müssen wir jetzt nicht per Hand die zweifaktorielle ANOVA rechnen. Du musst aber die R Ausgabe der ANOVA verstehen. Und diese Ausgabe schauen wir uns jetzt einmal ohne und dann mit Interaktionsterm an.

#### Ohne Interaktionsterm

Wir wollen nun einmal die zweifaktorielle ANOVA ohne Interaktionsterm rechnen die in @tbl-anova-fac2-ohne-inter dargestellt ist. Die $SS$ und $MS$ für die zweifaktorielle ANOVA berechnen wir nicht selber sondern nutzen die Funktion `anova()` in R.

::: column-page
| Varianzquelle |       df       | Sum of squares | Mean squares  |           F$_{\boldsymbol{calc}}$            |
|:-------------:|:--------------:|:--------------:|:-------------:|:--------------------------------------------:|
|    animal     |     $a-1$      | $SS_{animal}$  | $MS_{animal}$ | $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$ |
|     site      |     $b-1$      |  $SS_{site}$   |  $MS_{site}$  |  $F_{calc} = \cfrac{MS_{site}}{MS_{error}}$  |
|     error     | $n-(a-1)(b-1)$ |  $SS_{error}$  | $MS_{error}$  |                                              |
|     total     |     $n-1$      |  $SS_{total}$  |               |                                              |

: Zweifaktorielle ANOVA ohne Interaktionseffekt in der theoretischen Darstellung. Die Sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac2-ohne-inter}
:::

[Du kannst mehr über Geraden sowie lineare Modelle und deren Eigenschaften im @sec-modeling-simple-stat erfahren.]{.aside}

Im Folgenden sehen wir nochmal das Modell ohne Interaktionsterm. Wir nutzen die Schreibweise in R für eine Modellformel.

$$
jump\_length \sim animal + site
$$

Wir bauen nun mit der obigen Formel ein lineares Modell mit der Funktion `lm()` in R. Danach pipen wir das Modell in die Funktion `anova()` wie auch in der einfaktoriellen Variante der ANOVA. Die Funktion bleibt die Gleiche, was sich ändert ist das Modell in der Funktion `lm()`.

```{r}
fit_2 <-  lm(jump_length ~ animal + site, data = fac2_tbl) %>% 
  anova

fit_2
```

Wir erhalten wiederrum die ANOVA Ergebnistabelle. Ansatt nur die Zeile `animal` für den Effekt des Faktors `animal` sehen wir jetzt auch noch die Zeile `site` für den Effekt des Faktors `site`. Zuerst ist weiterhin der Faktor `animal` signifikant, da der $p$-Wert mit $0.000000039196$ kleiner ist als das Signifikanzniveau $\alpha$ von 5%. Wir können von mindestens einem Gurppenunterschied im Faktor `animal` ausgehen. Im Weiteren ist der Faktor `site` nicht signifikant. Es scheint keinen Untrschied zwischend den einzelnen Orten und der Sprunglänge von den Hunde-, Katzen- und Fuchsflöhen zu geben.

Neben der Standausgabe von R können wir auch die `tidy` Variante uns ausgeben lassen. In dem Fall sieht die Ausgabe etwas mehr aufgeräumt aus.

```{r}
fit_2 %>% tidy
```

Abschließend können wir uns übr $\eta^2$ auch die erklärten Anteile der Varainz wiedergeben lassen.

```{r}
fit_2 %>% eta_squared
```

Wir sehen, dass nur ein kleiner Teil der Varianz von dem Faktor `animal` erklärt wird, nämlich 26%. Für den Faktor `site` haben wir nur einen Anteil von 2% der erklärten Varianz. Somit hat die `site` weder einen signifikanten Einflluss auf die Sprungweite von Flöhen noch ist dieser Einfluss als relevant zu betrachten.

Abschließend können wir die Werte in der @tbl-anova-fac2-ohne-inter-example ergänzen. Die Frage ist inwieweit diese Tabelle in der Form von Interesse ist. Meist wird geschaut, ob die Faktoren signifikant sind oder nicht. Abschließend eventuell noch die $\eta^2$ Werte berichtet. Hier musst du schauen, was in deinem Kontext der Forschung oder Abschlussarbeit erwartet wird.

::: column-page
| Varianzquelle |        df        |     Sum of squares     |     Mean squares      |         F$_{\boldsymbol{calc}}$          |
|:-------------:|:----------------:|:----------------------:|:---------------------:|:----------------------------------------:|
|    animal     |      $3-1$       | $SS_{animal} = 180.03$ | $MS_{animal} = 90.02$ | $F_{calc} = \cfrac{90.02}{4.53} = 19.88$ |
|     site      |      $4-1$       |   $SS_{site} = 9.13$   |  $MS_{site} = 3.04$   |  $F_{calc} = \cfrac{3.04}{4.53} = 0.67$  |
|     error     | $120-(3-1)(4-1)$ | $SS_{error} = 516.17$  |  $MS_{error} = 4.53$  |                                          |
|     total     |     $120-1$      | $SS_{total} = 705.33$  |                       |                                          |

: Zweifaktorielle Anova ohne Interaktionseffekt mit den ausgefüllten Werten. Die $SS_{total}$ sind die Summe der $SS_{animal}$ und $SS_{error}$. Die $MS$ berechnen sich dan direkt aus den $SS$ und den Freiheitsgraden ($df$). Abschließend ergibt sich dann die F Statistik. {#tbl-anova-fac2-ohne-inter-example}
:::

#### Mit Interaktionssterm

Wir wollen nun noch einmal die zweifaktorielle ANOVA mit Interaktionsterm rechnen, die in @tbl-anova-fac3-inter dargestellt ist. Die $SS$ und $MS$ für die zweifaktorielle ANOVA berechnen wir nicht selber sondern nutzen wie immer die Funktion `anova()` in R.

::: column-page
|    Varianzquelle     |      df      |      Sum of squares       |       Mean squares        |                 F$_{\boldsymbol{calc}}$                  |
|:--------------------:|:------------:|:-------------------------:|:-------------------------:|:--------------------------------------------------------:|
|        animal        |    $a-1$     |       $SS_{animal}$       |       $MS_{animal}$       |       $F_{calc} = \cfrac{MS_{animal}}{MS_{error}}$       |
|         site         |    $b-1$     |        $SS_{site}$        |        $MS_{site}$        |        $F_{calc} = \cfrac{MS_{site}}{MS_{error}}$        |
| animal $\times$ site | $(a-1)(b-1)$ | $SS_{animal \times site}$ | $MS_{animal \times site}$ | $F_{calc} = \cfrac{MS_{animal \times site}}{MS_{error}}$ |
|        error         |    $n-ab$    |       $SS_{error}$        |       $MS_{error}$        |                                                          |
|        total         |    $n-1$     |       $SS_{total}$        |                           |                                                          |

: Zweifaktorielle ANOVA mit Interaktionseffekt in der theoretischen Darstellung. Die Sum of squares müssen noch zu den Mean squares gemittelt werden. Abschließend wird die F Statistik als Prüfgröße berechnet. {#tbl-anova-fac3-inter}
:::

Im Folgenden sehen wir nochmal das Modell mit Interaktionsterm. Wir nutzen die Schreibweise in R für eine Modellformel. Einen Interaktionsterm bilden wir durch das `:` in R ab. Wir können theoretisch auch noch weitere Interaktionsterme bilden, also auch `x:y:z`. Ich würde aber davon abraten, da diese Interaktionsterme schwer zu interpretieren sind.

$$
jump\_length \sim animal + site + animal:site
$$

Wir bauen nun mit der obigen Formel ein lineares Modell mit der Funktion `lm()` in R. Es wieder das gleich wie schon zuvor. Danach pipen wir das Modell in die Funktion `anova()` wie auch in der einfaktoriellen Variante der ANOVA. Die Funktion bleibt die Gleiche, was sich ändert ist das Modell in der Funktion `lm()`. Auch die Interaktion müssen wir nicht extra in der ANOVA Funktion angeben. Alles wird im Modell des `lm()` abgebildet.

Die visuelle Regel zur Überprüfung der Interaktion lautet nun wie folgt. @fig-anova-inter-example zeigt die entsprechende Vislualisierung. Wir haben keine Interaktion vorliegen, wenn die Geraden parallel zueinander laufen und die Abstände bei bei jedem Faktorlevel gleich sind. Wir schauen uns im Prinzip die erste Faktorstufe auf der x-Achse an. Wir sehen den Abstand von der roten zu blauen Linie sowie das die blaue Gerade über der roten Gerade liegt. Dieses Muster erwarten wir jetzt auch an dem Faktorlevel B und C. Eine leichte bis mittlere Interaktion liegt vor, wenn sich die Abstaände von dem zweiten Fakotr über die Faktorstufen des ersten Faktors ändern. Eine starke Interaktion liegt vor, wenn sich die Geraden schneiden.

```{r}
#| message: false
#| echo: false
#| label: fig-anova-inter-example
#| fig-align: center
#| fig-height: 5
#| fig-width: 5
#| fig-cap: "Darstellung von keiner Interaktion, leichter bis mittler Interaktion und starker Interaktion in einer zweifaktoriellen ANOVA mit einem Faktor mit drei Leveln A, B und C sowie einem Faktor mit zwei Leveln (rot und blau)."
#| fig-subcap: 
#|   - "Keine Interaktion"
#|   - "Leichte bis mittlere Intraktion"
#|   - "Starke Interaktion"
#| layout-nrow: 1
#| column: page

no_inter_tbl <- tibble(light = rep(c("low", "high"), each = 3),
                       water = rep(c("A", "B", "C"), each = 1, times = 2),
                       weight = c(1.2, 3.4, 2.6,
                                  0.5, 3.1, 2.1))

ggplot() +
  geom_point(data = no_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  geom_line(data = no_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position="none") +
  #scale_color_manual(values = par$cbbPalette[c(6, 7)]) +
  ylab("") + xlab("")




light_inter_tbl <- tibble(light = rep(c("low", "high"), each = 3),
                       water = rep(c("A", "B", "C"), each = 1, times = 2),
                       weight = c(3.1, 3.4, 2.6,
                                  0.5, 3.1, 2.1))
##
ggplot() +
  geom_point(data = light_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  geom_line(data = light_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position="none") +
  #scale_color_manual(values = par$cbbPalette[c(6, 7)]) +
  ylab("") + xlab("")


high_inter_tbl <- tibble(light = rep(c("low", "high"), each = 3),
                         water = rep(c("A", "B", "C"), each = 1, times = 2),
                         weight = c(1.2, 3.4, 2.6,
                                    2.9, 3.1, 2.1))
##
ggplot() +
  geom_point(data = high_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  geom_line(data = high_inter_tbl, aes(x = water, y = weight, color = light, group = light)) +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position="none") +
  #scale_color_manual(values = par$cbbPalette[c(6, 7)]) +
  ylab("") + xlab("")


```

In der @fig-interact-anova-1 sehen wir den Interaktionsplot für unser Beispiel. Auf der y-Achse ist die Sprunglänge abgebildet und auf der x-Achse der Faktor `animal`. Die einzelnen Farben stellen die Level des Faktor `site` dar.

```{r}
#| message: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 6
#| fig-cap: Boxplot der Sprungweiten [cm] von Hunden und Katzen.
#| label: fig-interact-anova-1

ggplot(fac2_tbl, aes(x = animal, y = jump_length,
                     color = site, group = site)) +
  stat_summary(fun = mean, geom = "point") +
  stat_summary(fun = mean, geom = "line") +
  theme_bw()

```

[Wenn sich die Geraden in einem Interaktionsplot schneiden, haben wir eine Interaktion zwischen den beiden Faktoren vorliegen]{.aside}

Wir schauen zur visuellen Überprüfung auf den Faktor `animal` und das erste level `cat`. Wir sehen die Ordnung des zweiten Faktors `site` mit `field`, `village`, `smalltown` und `city`. Diese Ordnung und die Abstände sind bei zweiten Faktorlevel `dog` schon nicht mehr gegeben. Die Geraden schneiden sich. Auch liegt bei dem Level `fox` eine andere ordnung vor. Daher sehen wir hier eine starke Interaktion zwischen den beiden Faktoren `animal` und `site`.

[Du kannst mehr über Geraden sowie lineare Modelle und deren Eigenschaften im @sec-modeling-simple-stat erfahren.]{.aside}

Wir nehmen jetzt auf jeden Fall den Interaktionsterm `animal:site` mit in unser Modell und schauen uns einmal das Ergebnis der ANOVA an. Das lineare Modell der ANOVA wird erneut über die Funktion `lm()` berechnet und anschließend in die Funktion `anova()` gepipt.

```{r}
fit_3 <-  lm(jump_length ~ animal + site + animal:site, data = fac2_tbl) %>% 
  anova

fit_3
```

[Wenn wir eine signifikante Interaktion vorliegen haben, dann müssen wir den Faktor A getrennt für jedes Levels des Faktors B auswerten.]{.aside}

Die Ergebnistabelle der ANOVA wiederholt sich. Wir sehen, dass der Faktor `animal` signifkant ist, da der p-Wert mit $0.000000000036$ kleiner ist als das Signifikanzniveau $\alpha$ von 5%. Wir können daher die Nullhypothese ablehnen. Mindestens ein Mittelwertsvergleich unterschiedet sich zwischen den Levels des Faktors `animal`. Im Weiteren sehen wir, dass der Faktor `site` nicht signifkant ist, da der p-Wert mit $0.39$ größer ist als das Signifikanzniveau $\alpha$ von 5%. Wir können daher die Nullhypothese nicht ablehnen. Abschließend finden wir die Interaktion zwischen dem Faktor `animal`und `site` las signifkant vor. Wenn wir eine signifikante Interaktion vorliegen haben, dann müssen wir den Faktor `animal` getrennt für jedes Levels des Faktors `site` auswerten. Wir können keine Aussage über die Sprungweite von Hunde-, Katzen- und Fuchsflöhen *unabhängig* von der Herkunft `site` der Flöhe machen.

[In Kapitel XX findest du ein Beispiel für eine signifikante Interaktion und die folgende Auswertung]{.aside}

Wir können wie immer die etwas aufgeräumte Variante der ANOVA Ausgabe mit der Funktion `tidy()` uns ausgeben lassen.

```{r}
fit_3 %>% tidy()
```

Im Folgenden können wir noch die $\eta^2$ für die ANOVA als Effektschätzer berechnen lassen.

```{r}
fit_3 %>% eta_squared
```

Wir sehen, dass nur ein kleiner Teil der Varianz von dem Faktor `animal` erklärt wird, nämlich 36%. Für den Faktor `site` haben wir nur einen Anteil von 3% der erklärten Varianz. Die Interaktion zwischen `animal` und `site` erklärt 38% der beobachteten Varianz udn ist somit auch vom Effekt her nicht zu ignorieren. Somit hat die `site` weder einen signifikanten Einflluss auf die Sprungweite von Flöhen noch ist dieser Einfluss als relevant zu betrachten.

Abschließend können wir die Werte in der @tbl-anova-fac3-inter-example ergänzen. Die Frage ist inwieweit diese Tabelle in der Form von Interesse ist. Meist wird geschaut, ob die Faktoren signifikant sind oder nicht. Abschließend eventuell noch die $\eta^2$ Werte berichtet. Hier musst du schauen, was in deinem Kontext der Forschung oder Abschlussarbeit erwartet wird.

::: column-page
|    Varianzquelle     |         df          |           Sum of squares           |           Mean squares            |         F$_{\boldsymbol{calc}}$          |
|:--------------------:|:-------------------:|:----------------------------------:|:---------------------------------:|:----------------------------------------:|
|        animal        |        $3-1$        |       $SS_{animal} = 180.03$       |       $MS_{animal} = 90.02$       | $F_{calc} = \cfrac{90.02}{2.97} = 30.28$ |
|         site         |        $4-1$        |         $SS_{site} = 9.13$         |        $MS_{site} = 3.04$         |  $F_{calc} = \cfrac{3.04}{2.97} = 1.02$  |
| animal $\times$ site |    $(3-1)(4-1)$     | $SS_{animal \times site} = 195.12$ | $MS_{animal \times site} = 32.52$ | $F_{calc} = \cfrac{32.52}{2.97} = 10.94$ |
|        error         | $120 - (3 \cdot 4)$ |       $SS_{error} = 321.06$        |        $MS_{error} = 2.97$        |                                          |
|        total         |       $120-1$       |       $SS_{total} = 705.34$        |                                   |                                          |

: Zweifaktorielle Anova mit Interaktionseffekt mit den ausgefüllten Werten. Die $SS_{total}$ sind die Summe der $SS_{animal}$ und $SS_{error}$. Die $MS$ berechnen sich dan direkt aus den $SS$ und den Freiheitsgraden ($df$). Abschließend ergibt sich dann die F Statistik. {#tbl-anova-fac3-inter-example}
:::

## Und weiter?

Nach einer berechnten ANOVA können wir zwei Fälle vorliegen haben.

[Wenn du in deinem Experiment keine *signifikanten* Ergebnisse findest, ist das nicht schlimm. Du kannst deine Daten immer noch mit der explorativen Datenanalyse auswerten wie in @sec-eda-ggplot beschrieben.]{.aside}

1)  Wir habe eine nicht signifkante ANOVA berechnet. Wir können die Nullhypothese $H_0$ nicht ablehnen und die Mittelwerte über den Faktor sind vermutlich alle gleich. Wir enden hier mit unserer statistischen Analyse.
2)  Wir haben eine signifikante ANOVA berechnet. Wir können die Nullhypothese $H_0$ ablehnen und mindestens ein Gruppenvergleich über mindestens einen Faktor ist vermutlich unterschiedlich. Wir können dann in @sec-posthoc eine Posthoc Analyse rechnen.
