# Frequentistische Hypothesentests {#sec-statistisches-testen}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, broom)
```

::: callout-tip
## Grundlagen der Wissenschaft und Falsifikationsprinzip

Du findest auf YouTube [Grundlagen der Wissenschaft und Falsifikationsprinzip](https://youtu.be/h45ftLNsspM) als Video.
:::

Das statistische Testen - eine Geschichte voller Missverständnisse. Wir wollen uns in den folgenden Kapiteln mit den Grundlagen des frequentistischen Hypothesentestens beschäftigen. Wenn ich hier einen Unterschied mache, dann muss es ja auch noch ein anderes Hypothesentesten geben. Ja, das nennt man dann bayesianische Statistik und kommt eventuell mal später. Wir konzentrieren uns aber zuerst auf frequentistische Hypothesentesten was seit gut hundert Jahren genutzt wird. Ich werde hier textlich nur einen kurzen Einstieg liefern. Vielleicht wird es in den folgenden Jahren länger aber aktuell (Ende 2022) bleiben wir hier bei einem kurzen Einstieg.

[Forschung basiert auf dem Falsifikationsprinzip. Wir können **nur ablehnen** und behalten das weniger schlechte Modell bei.]{.aside}

Beginnen wir mit der Logik der Forschung oder allgemeiner formuliert, als die Grundlage der Wissenschaft. Wir basieren all unsere Entscheidungen in der Wissenschaft auf dem Falsifikationsprinzip. Also bitte merken, wir können nur ablehnen (eng. *reject*).

::: callout-note
## Logik der Forschung

„Das ist die Logik der Forschung, die nie verifizieren, sondern immer nur jene Erklärungen beibehalten kann, die beim derzeitigen Erkenntnisstand am wenigsten falsifiziert sind." -- Wößmann, L.

Wir ersetzen schlechte Modelle (der Wirklichkeit) durch weniger schlechte Modelle (der Wirklichkeit).
:::

Wir wollen hier auf keinen Fall die Leistungen von Altvorderen schmälern. Dennoch hatten [Ronald Fischer (1890 - 1962)](https://en.wikipedia.org/wiki/Ronald_Fisher), als der Begründer der Statistik, andere Vorraussetzungen als wir heutzutage. Als wichtigster Unterschied sei natürlich das Gerät genannt, an dem du gerade diese Zeilen liest: dem Computer. Selbst die Erstellung einfachster Abbildungen war sehr, sehr zeitaufwendig. Die Berechnung von Zahlen lohnte sich mehr, als die Zahlen zu visualisieren. Insbesondere wenn wir die Explorative Datenanalyse nach [John Tukey (1915 - 2000)](https://en.wikipedia.org/wiki/John_Tukey) durchführen. Undenkbar zu den Zeiten von Ronald Fischer mehrere Abbildungen unterschiedlich nach Faktoren einzufärben und sich die Daten *anzugucken*.

[Über die Nullhypothese erfährst du mehr in dem folgenden @sec-hypothesen]{.aside}

Neben dieser Begrenzung von moderner Rechenkapazität um 1900 gab es noch eine andere ungünstige Entwicklung. Stark vereinfacht formuliert entwickelte Ronald Fischer statistische Werkzeuge um abzuschätzen wir wahrscheinlich die Nullhypothese unter dem Auftreten der beobachteten Daten ist. Nun ist es aber so, dass wir ja auch eine Entscheidung treffen wollen. Nach der Logik der Forschung wollen wir ja eine Hypothese falsifizieren, in unserem Fall die Nullhypothese. Die Entscheidungsregeln, also die statistische Testtheorie, kommen nun von [Jerzy Neyman (1894 - 1981)](https://en.wikipedia.org/wiki/Jerzy_Neyman) und [Egon Pearson (1895 - 1980)](https://en.wikipedia.org/wiki/Egon_Pearson), beide als die Begründer der frequentistischen Hypothesentests.

Schlussendlich gibt es noch eine andere Strömung in der Statistik, die auf den mathematischen Formeln von [Thomas Bayes (1701 - 1761)](https://en.wikipedia.org/wiki/Thomas_Bayes) basieren. In sich eine geschlossene Theorie, die auf der *inversen* Wahrscheinlichkeit basiert. Das klingt jetzt etwas schräg, aber eigentlich ist die bayesianische Statistik die Statistik, die die Fragen um die Alternativehypothese beantwortet. Der Grund warum die bayesianische Statistik nicht angewendet wurde, war der Bedarf an Rechenleistung. Die bayesiansiche Statistik lässt sich nicht händisch in endlicher Zeit lösen. Dieses *technische* Problem haben wir aber nicht mehr. Eigentlich könnten wir also die bayesiansiche Statistik verwenden. Wir wollen hier aber (noch) nicht auf die bayesianische Statistik eingehen, das werden wir später tun.

Wenn du allgemein Interesse hast an der Geschichte der Statistik dann sei auf @salsburg2001lady verwiesen. Ein sehr schönes Buch, was die *geschichtlichen* Zusammenhänge nochmal aufzeigt.

Kommen wir aber nun zu den wichtigeren Punkten. Die folgenden Kapitel ist sehr umfangreich und enthalten viele Informationen, die wir teilweise später nochmal brauchen. Darüber hinaus müssen wir noch das *Lernen und Verstehen* von der *Anwendung* unterscheiden. Wir teilen dabei die Test*entscheidung* und die Test*theorie* in zwei Kapitel auf.

Du erfährst im @sec-stat-entscheidung mehr zur Testentscheidung und welche Konzepte wir dort nutzen:

-   Wir verstehen die statistischen Testentscheidung nutzen wir das Konzept der Teststatistik $T$ (siehe @sec-teststatistik)
-   Wir können die statistischen Testentscheidung anwenden, da wir das Konzept des p-Wertes $Pr(T|H_0)$ (siehe @sec-pwert) und das Konzept der 95% Konfidenzintervalle verstanden haben (siehe @sec-ki)

Du erfährst im @sec-stat-theorie mehr zur Testtheorie und welche Konzepte wir dort nutzen:

-   Wir verstehen den Unterschied zwischen dem $\alpha$-Fehler und der $\beta$-Fehler (siehe @sec-alpha-beta)
-   Wir wissen um den Unterschied des einseitigen und zweiseitigen statistischen Testens (siehe @sec-einseitig-zweiseitig)
-   Wir verstehen die Adjustierung für multiple Vergleiche (siehe @sec-statistisches-testen-alpha-adjust)

::: callout-note
## Beispiel: Bin ich im Urlaub?

Hier nochmal zusammengefasst die Idee der frequentistischen Testtheorie anhand der Frage, ob du im Urlaub bist. 

- Bin ich im Urlaub?
- Wie wahrscheinlich bin ich im Urlaub? $Pr(U)$
- Wie wahrscheinlich bin ich nicht im Urlaub? $Pr(\bar{U})$
- Wie wahrscheinlich sind wir nicht im Urlaub? $Pr(\bar{U})$
- Wie wahrscheinlich ist es, die Daten $D_1$ zu beobachten, wenn wir nicht im Urlaub sind? $Pr(D_1|\bar{U})$

Wir würden meinen, dass wir die Frage "Bin ich im Urlaub?" beantworten können. Das stimmt aber nicht. Durch das Falsifikationsprinzip können wir nur eine Aussage über "nicht-im-Urlaub-sein" treffen. Darüber hinaus können wir keine Entscheidungen per se treffen sondern erhalten eine Wahrscheinlichkeitsuassage. Um die Sachlage noch komplizierter zu machen, treffen wir Aussagen über eine Population. Also sind *wir* im nicht im Urlaub. Abschließend treffen wir eine Aussage über die beobachteten Daten und können dann eine Wahrscheinlichkeit berechnen diese Datwen beobachtet zu haben, wenn wir nicht im Urlaub sind.

1) Wir machen Aussagen über Wahrscheinlichkeiten!
2) Wir machen Aussagen über Populationen?
3) Wir machen Aussagen über den Nicht-Zustand/Keinen Effekt

:::

## Referenzen {.unnumbered}
