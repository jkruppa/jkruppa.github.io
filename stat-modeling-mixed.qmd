```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, simstudy, writexl)
```

# Lineare gemischte Modelle {#sec-mixed}

*Letzte Änderung am `r format(fs::file_info("stat-modeling-mixed.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Wer die Arbeit kennt und sich nicht drückt, der ist verrückt." --- Tick, Trick und Track*

In diesem Kapitel vollen wir die Grundzüge der lineare gemischten Modell (eng. *linear mixed models*, abk. *lmm*) zu versuchen zu verstehen. Wir immer, es gibt dazu auch hervorragende Literatur wie das sehr ausführliche Buch von @zuur2009mixed. Fangen wir also einmal an zu verstehen, wie eigentlich ein Experiment aussehen muss, damit wir ein lineares gemischtes Modell rechnen wollen. Dabei ist der erste wichtige Punkt, das wir hier mit den gemischten Modellen hierarchische Daten abbilden. Es gibt also eine Hierarchie zwischen den Daten und damit auch eine Abhängigkeit innerhalb der Daten. Eine Abhängigkeit ist in der Statistik eine Korrelationsstruktur. Hier konzentrieren wir uns auf agrarwissenschaftliche Daten. Wir haben dabei in den Agarwissenschaften unser $x$ als Faktoren $f$ vorliegen. Für das $y$ können aber jeden Messwert als Outcome abbilden den wir wollen. Dafür gibt es dann zum Beispiel die Funktion `glmer()`, die das Äquivalent zu der Funktion `glm()` ist.

::: {layout="[15,85]" layout-valign="center"}
![](images/angel_01.png){fig-align="center" width="100%"}

> Dieses Kapitel ist mathematisch und statistisch teilweise inkorrekt. Insbesondere die Modelle unterschlagen Fehlerterme und andere Aspekte der Korrelationstruktur von hierarischen Daten. Aber wie immer... erst einfach verstehen, dann komplizierter nachlesen.
:::

Wir haben also folgendes, mehrfaktorielles Modell vorliegen. Diese Faktoren haben teilweise eine Hierarchie, die wir dann modellieren wollen.

$$
y \sim f_1 + f_2 + z_1 + z_2
$$

Und eigentlich haben wir ja gar nicht vier *gleichwertige* Faktoren vorliegen, sondern meistens unsere Behandlungsfaktor $f_1$ und $f_2$ an dem wir interessiert sind und dann noch bis zu zwei weitere Faktoren $z_1$ und $z_2$, die eine weitere Gruppierung repräsentieren. Wir können auch noch mehr Faktoren vorliegen haben, aber ich empfehle ein Design immer auf maximal vier Faktoren zu begrenzen. Unsere beiden Faktoren $z_1$ und $z_2$ beschreiben jetzt aber nicht noch mehr Behandlungen sondern stellen ein Feld, einen Block oder aber einen Stall dar. Wir haben es also mit Faktoren für eine "Position" zu tun. Die Position kann auch eine zeitliche Komponente sein. Deshalb schreiben wir etwas allgemeiner für die Faktoren $z_1$ und $z_2$ auch als "zufällige" Effekte. Wie schon erwähnt es handelt sich nicht ausschließlich um Blöcke, es können auch andere Positionen in Raum und Zeit sein. Es geht immer mehr und manchmal braucht man auch mehr Faktoren, aber in unserem Kontext hier würde ich anraten sich auf eher auf drei Faktoren zu begrenzen. Also entweder zwei Behandlungsfaktoren $f_1$ sowie $f_2$ und ein Positionsfaktor $z_1$ oder aber ein Behandlungsfaktor $f_1$ und zwei Positionsfaktoren $z_1$ sowie $z_2$.

Als wäre das nicht kompliziert genug, haben wir meistens auch noch verschachtelte (eng. *nested*) Daten vorliegen. Damit meine ich, dass wir den Faktor $z_1$ in jedem Level des Faktors $z_2$ vorliegen haben. Wir können eben verschiedene Standorte als Faktor $z_2$ betrachten und an jedem der Standorte haben wir Blöcke $z_1$ vorliegen. Mehr dazu findest du dann auch in dem Kapitel [Versuchsplanung in R](#sec-experimental-design-r) und gleich nochmal weiter unten im Text.

::: callout-important
## Welche R Implementierung verwenden?

In diesem Kapitel werden wir *nicht* die Implementierung von linearen gemischten Modellen in dem R Paket `{nlme}` verwenden. Das Paket `{nlme}` hat sinnvolle Funktionen und je nach Fragestellung haben diese auch eine Berechtigung. Es gibt aber neuere R Pakete wie `{lme4}` oder `{glmmTMB}`, die wir dann hier in dem Kapitel nutzen wollen wenn es um statistsiche Analyse mit linearen gemischten Modellen geht..
:::

Was ist nun das Besondere an einem linearen gemischten Modell? Wie der Name schon sagt, haben wir irgendwas gemischt. Glücklicherweise mischen wir nur zwei Dinge miteinander. Wir mischen hier feste Effekte (eng. *fixed effect*) und zufällige Effekte (eng. *random effect*) miteinander. Bis jetzt kennst du eigentlich nur feste Effekte. Immer wenn wir ein Modell gebaut haben, dann haben wir das Modell mit festen Effekten gebaut. Wir haben dabei Fakotoren als feste Effekte modelliert. Was ist also nun der Unterschied zwischen der Wahl einen Faktor als festen Effekt oder zufälligen Effekt anzusehen? Zuerst ist dies eine Modellierungsentscheidung. Wir müssen uns also zwischen Arten von Modellen unterscheiden. Daher können wir auch verschiedene Modelle mit unterschiedlichen Anzahlen an Faktoren bauen und dann diese Modelle vergleichen. Welcher Faktor jetzt als fester Effekt und welcher als zufälliger Effekt gilt, liegt dabei an uns.

Die Idee hinter dem Modell mit **festen Effekten** ist, dass die beobachteten Effektgrößen von Block zu Block variieren können, was aber nur auf den Varianz der Blöcke zurückzuführen ist. In Wirklichkeit sind die wahren Effektgrößen alle gleich: Sie sind fix. Alle Blöcke haben den gleichen Mittelwert und variieren nur in der Varianz. Wir sehen aber diesen wahren Mittelwert nicht, da sich alle Blöcke eben immer leicht unterscheiden. Mehr dazu auch in [The Fixed-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#fem))

Das Modell der **zufälligen Effekte** geht davon aus, dass es nicht nur eine wahre Effektgröße gibt, sondern eine Verteilung der wahren Effektgrößen. Jeder unserer Blöcke kann also einen anderen wahren Mittelwert haben. Das Ziel des Modells mit zufälligen Effekten ist es daher nicht, die eine wahre Effektgröße aller Blöcke zu schätzen, sondern den Mittelwert der Verteilung der wahren Effekte. Mehr dazu auch in [The Random-Effect Model](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pooling-es.html#rem))

Dabei verbinden die gemischten Modelle die Vorteile eines Modells mit festen Effekt sowie eines Modells mit zufälligen Effekten. Lineare gemischte Modelle schätzen nun die subjektspezifischen Auswirkungen (eng. *subject-specific*) auf die Varianz eines Versuches. Dabei kommt es häufig darauf an unter welchen Umständen eine Beobachtung gemessen wurde. Stehen die Pflanze zusammen auf einem Feld? Sind die Ferkel alle Nachkommen einer Sau? Daher erweitern wir unser lineare Modell um einen zufälligen Effekt $z$ und schreiben wie folgt.

$$
y \sim f_1 + 1|z_1
$$

Wir schreiben in R den Term für da zufällige Modell in der Form $z_0|z_1$. Meist setzen wir den Intercept $z_0$ für den zufälligen Effekt auf `1`. Wenn wir darstellen wollen, das ein zufälliger Faktor in einem anderen zufälligen Fakotr genestet ist, dann schreiben wir `1|z_1/z_2`.

$$
y \sim f_1 + 1|z_1/z_2
$$

Das heißt, dass der zufällige Blockfaktor $z_1$ in den zufälligen Blockfaktor $z_2$ genestet ist. Das klingt jetzt etwas schräg, also einmal ein Beispiel. Wir haben eine Schule, dann sind die Schulklassen dieser Schule in der Schule genestet. Es gibt diese spezifischen Klassen mit den Schülern schlichtweg nicht in anderen Schulen. Wir sagen genestet (eng. *nested*), wenn wir sagen wollen, dass ein Faktor in einen anderen Faktor verschränkt ist. Die Klassen einer Schule sind in der Schule genestet.

In der @fig-mermaid-r-mixed-01 siehst du einmal exemplarisch die Darstellung eines experimentellen Designs mit drei Faktoren. Die Behandlung ist dabei ein fester Effekt und die beiden Faktoren für die Tische und die Gewächshäuser sind zufällige Effekte. Damit wir in der Folge nicht immer so sehr durcheinander kommen, habe ich die festen Effekt als blau Kästen und die zufälligen Effekte als orange Kästen gesetzt.

```{mermaid}
%%| label: fig-mermaid-r-mixed-01
%%| fig-width: 6
%%| fig-cap: "Beispiel für drei Faktoren und deren Abhänigigkeitsstruktur untereinander. Die Behandlungen sind in den Tischen genested und die Tische in den Gewächshäusern. Die festen Effekte sind als blaue Kästen und die zufälligen als orange Kästen eingefärbt."
flowchart LR
    C(Behandlungen):::fixed --- D(((nested))) --> E(Tische):::random --- F(((nested))) --> G(Gewächshäuser):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

Okay, das ist jetzt bis hierher sehr abstrakt. Machen wir das mal konkret mit einem Beispiel mit drei Behandlungen gegen Blattläuse auf jeweils vier Tischen in drei Gewächshäusern. Pro Behandlung nehmen wir fünf Pflanzen. Damit ergibt sich folgendes Schema der Abhängigkeiten mit den jeweiligen Anzahlen.

$$
\overbrace{\mbox{Gewächshauser}}^{n_g = 3} \xrightarrow[alle]{beinhaltet} \underbrace{\mbox{Tische}}_{n_t = 4} \xrightarrow[alle]{beinhaltet} \overbrace{\mbox{Behandlungen}}^{n_b = 3} \xrightarrow[alle]{beinhaltet} \underbrace{\mbox{Beobachtungen}}_{n_w = 5}
$$

Wie du an dem obigen Beispiel sehen kannst, kommen wir bei linearen gemischten Modellen sehr schnell auf sehr große Fallzahlen. Wir haben im obigen, kleinen Beispiel alleine schon eine Fallzahl von $n_{gesamt} = 3 \times 4 \times 3 \times 5 = 180$ Pflanzen. Und damit ist eigentlich unser Beispiel sehr klein gewählt. Eigentlich brauchen wir für einen zufälligen Effekt als Daumenregel immer mehr als fünf Level für eine gute Modellschätzung.

Wie immer ist dieses Kapitel nur ein kleiner Teil von möglichen Orten um etwas über lineare gemischte Modelle zu lernen. In dem folgenden Kasten habe ich dir eine weitreichende Sammlung an Ideen und Tutorien zusammengesucht. Vielleicht findest du ja noch mehr Informationen dort. Für eine Analyse im Rahmen einer Abschlussarbeit sollte das Wissen hier aber reichen.

::: callout-tip
## Weitere Tutorien zu gemischten Modellen

Wie immer und natürlich im Besonderen bei linearen gemischten Modellen, gibt es eine Reihe von tollen Hilfen. Daher hier einmal eine lose Sammlung an Ideen und Tutorien, die mir geholfen haben dieses Kapitel hier zu schreiben. Fast jede Quelle hat dann nochmal Referezen zu weiteren Informationen und Hilfen.

-   [GLMM FAQ -- Ben Bolker and others](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random) ist meine Anlaufstelle, wenn ich mal was nachlesen muss. Eine sehr hilfreiche und umfangreiche Sammlung.
-   [Mixed Models with R -- Getting started with random effects](https://m-clark.github.io/mixed-models-with-R/) ist ein freies Buch, was ich auch immer mal wieder anschaue, wenn ich Fragen rund um das gemischte Modell habe. Dies ist hier nur ein Kapitel mit einer Zusammenfassung und eben kein ganzes Buch.
-   Teile dieses Kapitel basieren auf dem tollen [Tutorium von Gabriela K Hajduk](https://ourcodingclub.github.io/tutorials/mixed-models/). Die früheren Versionen mehr als die aktuelle Version, aber ich finde das Tutorium immer noch toll. Auch hier findest du sehr viel mehr Informationen und dann auch Links zu weiteren Quellen.
-   Ideen und weitere Erklärungen sind auch beim [Tutorium von Sara Stoudt](https://rlbarter.github.io/Practical-Statistics/2017/03/03/fixed-mixed-and-random-effects/) zu finden. Hier musst du dich aber mehr Einarbeiten, da der Artikel etwas mehr mathematisch aufgebaut ist.
-   Als weiteres Tutorium für die Auswertung von linearen gemischten Modellen und allgemein dem Modellieren von agarwissenschaftlichen Daten kann ich die Seite [Data Science for Agriculture in R](https://schmidtpaul.github.io/dsfair_quarto/) sehr empfehlen. Dort findest du dann auch die Abwendung der R Pakete aus diesem Kapitel. Und natürlich die verwandte Seite [Mixed Models for Agriculture in R](https://schmidtpaul.github.io/MMFAIR/) auf der gerade viele Beispiele gesammelt werden. Ein Großteil der Seite aber noch *under construction* (Stand Ende 2023) und teilweise zu detailliert für Abschlussarbeiten.
-   [Introduction to `{broom.mixed}`](https://cran.r-project.org/web/packages/broom.mixed/vignettes/broom_mixed_intro.html) hilft dabei die Ausgaben der verschiedenen R Pakte, die es zu gemischten Modellen gibt zu vereinheitlichen. Wir erhalten dann immer die gleiche `tidy()`-Ausgabe und nicht immer was anderes von den Funktionen wiedergegeben.
-   [Linear Models and Mixed Models with R](https://bodo-winter.net/tutorials.html) sind zwei PDF Dateien von @winter2013linear in denen er nochmal sehr schön erklärt wie lineare gemischte Modelle in R funktionieren.
:::

## Genutzte R Pakete

Normalerweise nutze ich *nur* R Pakete, die auch auf CRAN oder eben per `p_load()` zu installieren sind. In diesem Kapitel brauche ich aber noch ein extra Paket, da die Ausgaben von linearen gemischten Modellen sehr unordentlich sind. Das R Paket `{mixedup}` hilft mir hier. Deshalb installiere ich einmal wie folgt `{mixedup}`.

```{r}
#| eval: false
remotes::install_github('m-clark/mixedup')
```

Wir wollen folgende R Pakete ganz normal in diesem Kapitel nutzen. Es sind eine Menge geworden, aber das zeigt auch mal wieder, dass gemischte Modelle nicht unbedingt das einfachtse Modell sind.

```{r echo = TRUE}
#| message: false
#| warning: false
pacman::p_load(tidyverse, magrittr, broom, see, simstudy,
               multcomp, emmeans, lme4, broom.mixed, readxl,
               parameters, ggridges, scales, performance, 
               ggdist, gghalves, glmmTMB, lmerTest, mixedup,
               multilevelmod, agridat, desplot, modelsummary,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflicts_prefer(lme4::lmer)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_minimal(base_size = 12))
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

Als erstes Beispiel nehmen wir einen Datensatz zu den Testergebnissen von Schülern an amerikanischen Schulen. Jetzt ist das kein Beispiel, welches du vielleicht in einem biologischen oder agrarwissenschaftlichen Umfeld erwarten würdest. Ich mache das aber hier bewusst, da wir uns alle sehr gut die Abhängigkeiten von Schülerleistungen von der jeweiligen Klasse und dem Standort der Schule vorstellen können. Jedem wird klar sein, dass ein Testergebnis aus einer Klausur *nicht* unabhängig davon ist, auf welche Schule der Schüler geht oder in welcher Klasse er unterrichtet wird. Schüler in einer gemeinsamen Klasse oder Schule werden sich ähnlicher sein als Schüler in unterschiedlichen Klassen oder Schulen.

In der @fig-mermaid-r-mixed-school siehst du einmal das Abhängigkeitsverhältnis in unserem Schuldatenbeispiel. Wir wenden in den verschiedenen Klassen als Behandlung `trt` eines von drei Lehrmethoden *Frontal*, *Flipped Classroom* oder *HyperFlex* an. Dabei wird natürlich eine ganze Klasse nach der entsprechenden Lehrmethode unterrichtet. Pro Schule finden sich drei Klassen und eine Klasse ist dann in einer der neun Schulen genestet.

```{mermaid}
%%| label: fig-mermaid-r-mixed-school
%%| fig-width: 6
%%| fig-cap: "In unseren Schuldaten haben wir verschiedene Schulen `school` und Klassen `class` mit zwei innovativen Lehrmethoden unterrichtet. Eine Kontrollgruppe soll die Ergebnisse eines Leistungstests absichern. Daher sind die Lehrmethoden `trt` in dem Faktor `class` genestet. Der Faktor `class` ist dann wiederum in jedem Faktor `school` genestet."
flowchart LR
    C(trt):::fixed --- D(((nested))) --> E(class):::random --- F(((nested))) --> G(school):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

In dem folgenden Kasten werden einmal die Schuldaten simuliert. Daher können wir dann einmal nachvollziehen, welche Werte wir jeweils für die Effekte der Schule, der Klasse und der Lehrform gesetzt haben. Wir sehen dann auch mal, welche zufälligen Effekte wir eigentlich setzen müssen und wie wir dann die Modelle miteinander vergleichen. Du kannst den Kasten gerne überspringen und dann einfach mit der Visualisierung und Auswertung der Daten weitermachen.

::: {.callout-caution collapse="true"}
## Generierung von Schuldaten (3-faktoriell)

Warum sollte man Daten simulieren? Reichen da nicht echte Daten? Wir können an den simulierten Daten die Werte zurückverfolgen, wir wir bei der Erstellung voreingestellt haben. Damit können wir dann auch bewerten, wie gut die statistischen Methoden funktioniert haben. Wir machen es uns aber auch etwas einfacher und bauen uns kein kompliziertes Beispiel. Umfangreich ist es nur, da Daten für ein gemischtes Modell eben auch umfangreich *sind*.

Aus Gründen der Einfachheit haben wir immer ein balanciertes Design vorliegen. Wir haben also immer in allen Faktorkombinationen die gleiche Anzahl an Beobachtungen `n_reps` vorliegen. In der Anwendung mag es Unterschiede geben, so hat eine Sau sicherlich nicht immer exakt zwölf Ferkel, aber in unseren Beispielen macht es keinen Unterschied. Balanciert oder unbalanciert ist bei gemischten Modellen eher nachrangig wichtig. Das [R Paket `{simstudy}`](https://kgoldfeld.github.io/simstudy/articles/clustered.html) erlaubt die Simulation von komplexeren Gruppenstrukturen mit auch unbalancierten Daten. Am Ende wäre es dann mit `{simstudy}` vermutlich einfacher gewesen... hier können wir dann auch unterschiedlich Klassengrößen und Anzahlen simulieren.

Im Folgenden setze ich einmal Werte für die Schulanzahl, Klassenzahl pro Schule sowie die Anzahl an Behandlungen. Dann müssen wir noch definieren wie viele Schüler dann pro Klasse zu finden sind. Wenn wir das haben, dann können wir auch die Effekte der Klassen, Schulen und der Lehrformate festlegen. Dabei sind die Effekt der zufälligen Effekte der Klassen und Schule dann die zusätzliche Varianz abgebildet durch die Standardabweichungen.

```{r}
pacman::p_load(spatstat.random)
# set seed
set.seed(20231208)
# sample sizes
n_school <- 9
n_class_per_school <- 3
n_class <- n_school * n_class_per_school
n_trt <- 3
n_reps <- 20
# effects and standard deviation
sd_school <- 10
sd_class <- 5
sd_error <- 2
eff_trt <- c(frontal = 10,
             flipped = -10,
             hyflex = 30)
```

Dann können wir uns schon das Grid für die Daten erstellen. Dabei müssen wir dann mehrfach `expand_grid()` nutzen um erst die Schulen zu erschaffen, dann die Lehrformate den Schulen zuordnen und dann die Klassen pro Schule erschaffen. Ende müssen wir noch den Datensatz mit der Anzahl an Schülern pro Klasse erweitern. Dann beschreibt jede Zeile genau einen Schüler. Neben der Zuordnung jedes einzelnen Schülern zu einem Lehrformat, Klasse und Schule, müssen wir noch die Effekte $s_0$, $c_0$ und $t_{eff}$, die jeder Schüler durch eben jene Zuordnung erhält, ergänzen.

```{r}
school_grid_tbl <- tibble(s_id = 1:n_school,
                          s_0 = rnorm(n_school, 0, sd_school)) %>% 
  add_column(trt = rep(1:n_trt, n_trt),
             t_eff = rep(eff_trt, n_trt)) %>% 
  expand_grid(c_per_s = 1:n_class_per_school) %>%
  mutate(c_id = 1:n_class,
         c_0 = rnorm(n_class, 0, sd_class)) %>% 
  expand_grid(reps = 1:n_reps)
```

Jetzt können wir unseren Testscore berechnen, der sich aus den einzelnen Effekten der Schule $s_0$, der Klasse $c_0$ sowie dem Lehrformat $t_{eff}$ ergibt, berechnen. Am Ende addieren wir auf jeden Wert noch einen Fehler und runden die Werte des Tests auf zwei Stellen. Dann bauen wir uns noch die Faktorlevel für die Schulen, Klassen und dem Lehrformat.

```{r}
school_tbl <- school_grid_tbl %>% 
  arrange(trt) %>% 
  mutate(test = round(50 + s_0 + c_0 + t_eff + rnorm(n(), 0, sd_error), 2),
         s_id = factor(s_id, labels = c("Springfield School", "Jacksonville High", "Franklin Country", 
                                        "Clinton Christian", "Arlington Academy", "Georgetown High", 
                                        "Greenville School", "Bristol Country", "Dover Tech Center")),
         c_id = as_factor(c_id),
         c_per_s = factor(c_per_s, labels = c("1a", "1b", "1c")),
         trt = factor(trt, labels = c("Frontal", "Flipped classroom", "HyFlex"))) 
```

Dann schreiben wir die Daten noch in eine Exceldatei `school_testing.xlsx` und können diese dann im weiteren Verlauf der Analyse nutzen. Auch hier passen wir etwas die Namen der Spalten an, damit die Spalten etwas mehr Aussagekraft haben.

```{r}
school_tbl %>% 
  select(school_id = s_id, class_in_school_id = c_per_s, class_id = c_id, trt, test) %>% 
  write_xlsx("data/school_testing.xlsx")
```
:::

Die Schuldaten liegen dann in dem Datensatz `school_testing.xlsx` vor. Wir müssen hier dann nur noch die Faktoren bilden, damit wir dann auch die Visualisierungen sauber hinkriegen.

```{r}
school_tbl <- read_excel("data/school_testing.xlsx") %>% 
  mutate(school_id = as_factor(school_id),
         class_in_school_id = as_factor(class_in_school_id),
         class_id = as_factor(class_id),
         trt = as_factor(trt)) 
```

Es ergibt sich dann der Datensatz der Schuldaten wie in @tbl-school gekürzt gezeigt.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-school
#| tbl-cap: "Datensatz der Testscores für die Schüler an verschiedenen Schulen und Klassen. Die Schüler wurden in den Klassen jewiels mit einem von drei Lehrformaten unterrichtet. Die Klassen und Schulen sind die zufälligen Effekte. Das Lehrformat ist der feste Effekt."

school_raw_tbl <- read_excel("data/school_testing.xlsx") 

rbind(head(school_raw_tbl, n = 4),
      rep("...", times = ncol(school_raw_tbl)),
      tail(school_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

In der @tbl-mixed-simple-2fac im folgenden Kasten findest du den *einfachst möglichen* Datensatz für nur zwei Schülern pro Klasse sowie insgesamt nur zwei Klassen für zwei Schulen. Damit kannst du dir einmal denn Aufbau visualisieren und siehst auch einmal wie sich die Effekte der Klassen, Schule und Lehrformat für jeden der sechzehn Schüler zusammensetzt. Jede Zeile repräsentiert ja einen Schüler.

::: {.callout-note collapse="true"}
## Einfachst möglicher Schuldatensatz (3-faktoriell)

| school | $\boldsymbol{eff_{school}}$ | class | $\boldsymbol{eff_{class}}$ | trt | $\boldsymbol{eff_{trt}}$ | reps |
|:------:|:---------------------------:|:-----:|:--------------------------:|:---:|:------------------------:|:----:|
|   1    |           $0.23$            |   1   |          $-0.14$           |  1  |           $10$           |  1   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  1  |           $10$           |  2   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  2  |           $5$            |  1   |
|   1    |           $0.23$            |   1   |          $-0.14$           |  2  |           $5$            |  2   |
|   1    |           $0.23$            |   2   |           $0.21$           |  1  |           $10$           |  1   |
|   1    |           $0.23$            |   2   |           $0.21$           |  1  |           $10$           |  2   |
|   1    |           $0.23$            |   2   |           $0.21$           |  2  |           $5$            |  1   |
|   1    |           $0.23$            |   2   |           $0.21$           |  2  |           $5$            |  2   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  1  |           $10$           |  1   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  1  |           $10$           |  2   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  2  |           $5$            |  1   |
|   2    |           $0.71$            |   3   |          $-0.83$           |  2  |           $5$            |  2   |
|   2    |           $0.71$            |   4   |           $0.59$           |  1  |           $10$           |  1   |
|   2    |           $0.71$            |   4   |           $0.59$           |  1  |           $10$           |  2   |
|   2    |           $0.71$            |   4   |           $0.59$           |  2  |           $5$            |  1   |
|   2    |           $0.71$            |   4   |           $0.59$           |  2  |           $5$            |  2   |

: Kurzform eines dreifaktoriellen Datensatzes mit zwei zufälligen Effekten für `school` und `class` sowie einem Bahandlungsfaktor `trt`. Die zufälligen Effekte sind normalverteilt mit $\mathcal{N}(0, s^2)$. Pro Behandlung haben wir dann nur zwei Wiederholungen. Dennoch erreichen wir eine Fallzahl von sechzehn Beobachtungen daher Schülern. {#tbl-mixed-simple-2fac}
:::

Dann einmal den Datenklassiker `yates.oats` schlechthin als *das* [Split-plot experiment of oats](https://kwstat.github.io/agridat/reference/yates.oats.html) aus dem R Paket `{agridat}`. Warum ist es der Klassiker? Weil es im Prinzip das erste Split plot Experiment war. Deshalb ist es nicht schlechter als andere. Ich nutze es hier, weil es gut funktioniert und wir uns einmal eine Auswertung eines komplexeren Datensatzes mit einem linearen gemischten Modell anschauen können. Wir haben insgesamt die mittleren Ertragswerte von Hafer für 72 Parzellen vorliegen. Im weiteren haben wir zwei Behandlungsfaktoren mit der Stickstoffgabe `nitro` und der Sorte `gen`. Da wir ein Split plot Experiment vorliegen haben, brauchen wir natürlich die Reihen- und Spaltenpositionen sowie die Information über den Block. Alle drei Positionsfaktoren werden wir dann versuchen als zufällige Effekte in das gemischte Modell zu nehmen. In der @fig-mermaid-oats siehst du einmal das Abhängigkeitsverhältnis in den Daten.

```{mermaid}
%%| label: fig-mermaid-oats
%%| fig-width: 6
%%| fig-cap: "Abhängigkeitsstruktur des *split plot design*. Der Faktor `gen` ist in den Spalten `cols/rows` der Blöcke randomisiert und der zweite Faktor `nitro` innerhalb des anderen Faktors."
flowchart LR
    A(nitro):::fixed --- B(((nestet))) --> C(gen):::fixed --- D(((nestet))) --> E(cols/rows) --- F(block):::random
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

Ich erweitere noch den Datensatz um die einzelnen Pflanzenwerte indem ich für jeden `yield`-Wert als Mittelwert noch zwölf Pflanzen für die Parzelle simuliere. Damit baue ich die Daten sozusagen wieder zurück und komme auf meine individuellen Werte für jede der 72 Parzellen.

```{r}
data(yates.oats)
oats_tbl <- yates.oats %>% 
  as_tibble() %>% 
  mutate(nitro = as_factor(nitro),
         row = as_factor(row),
         col = as_factor(col)) %>% 
  expand_grid(plant_id = 1:12) %>% 
  mutate(plant_yield = round(rnorm(n(), yield, 2), 2)) %>% 
  select(row, col, block, nitro, gen, plant_id, plant_yield)
```

In der @tbl-yates siehst du nochmal einen Ausschnitt aus den Daten. Wir fokussieren uns hier auf das Outcome `yield` was wir als normalverteilt annehmen. Die anderen möglichen Outcomes ignorieren wir dann erstmal. Wir brauchen dann auch die Informationen für die Position auf dem Feld `row` und `col` um dann einen gute Abbildung des Designs über das R Paket `{desplot}` zu erstellen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-yates
#| tbl-cap: "Haferdatensatz im Split plot Design für zwei Behandlungsfaktoren `nitro` und `gen` sowie drei Positionsfaktoren `row`, `col` und `block`. Wir schauen uns hier nur das Outcome Haferertrag `yield` an."

yates_raw_tbl <- oats_tbl %>% 
  mutate(gen = as.character(gen),
         block = as.character(block),
         nitro = as.character(nitro),
         row = as.character(row),
         col = as.character(col)) %>% 
  as_tibble()

rbind(head(yates_raw_tbl, n = 4),
      rep("...", times = ncol(yates_raw_tbl)),
      tail(yates_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

Neben einem normalverteilten Outcome wollen wir uns danna auch noch eine andere häufige Art von einem Outcome anschauen. Wir betrachten nämlich noch Zähldaten oder Abundanz von Arten. Wir nutzen hier auch einen Datensatz aus dem R Paket `{agridat}` und zwar den Datensatz zu [Wireworms controlled by fumigants in a latin square](https://kwstat.github.io/agridat/reference/cochran.wireworms.html). Es geht hier also um die Verwendung von fünf Insektiziden in einem Feld mit $5 \times 5$ großen Parzellen. In jedem der Parzellen haben wir dann die Würmer an zehn Punkten gezählt. Die zehn Zählpunkte habe ich mir ausgedacht, aber dann aber wir später ein paar mehr Beobachtungen zum darstellen. Wie du siehst, haben wir hier ein *latin square design* vorliegen, welches ich dir nochmal in der @fig-mermaid-worms dargestellt habe.

```{mermaid}
%%| label: fig-mermaid-worms
%%| fig-width: 6
%%| fig-cap: "Schematische Darstellung der Abhängigkeitsstruktur im latin suare design für unsere Wurmdaten. Die Behandlungen werden in `rows` und `cols` genestet, die einem quadratischen Block mit den Längen der Anzahl der Level der Behandlungen entsprechen."
flowchart LR
    A(trt):::fixed --- B(((nested))) --> C(rows):::random
    B(((nested))) --> D(cols):::random
    C --- F(block)
    D --- F
    classDef fixed fill:#56B4E9,stroke:#333,stroke-width:0.75px
    classDef random fill:#E69F00,stroke:#333,stroke-width:0.75px
```

Im Folgenden habe ich einmal die Daten geladen und die Mittelwerte der Parzellen `worms` wieder auf die ursprünglichen, ausgedachten zehn Zählpunkte erweitert. Auch hier müssen wir dann unsere Daten wieder entsprechend mit Faktoren versehen, damit wir die Daten dann richtig im R Paket `{desplot}` abbilden können.

```{r}
data(cochran.wireworms)
wireworms_tbl <- cochran.wireworms %>% 
  as_tibble() %>% 
  mutate(trt = as_factor(trt),
         col = as_factor(col),
         row = as_factor(row)) %>% 
  expand_grid(site_id = 1:10) %>% 
  mutate(count_worms = rpois(n(), worms))
```

Du erhälst dann folgenden Auszug in der @tbl-worms von den Wurmdaten. Hier sind dann die Namen der Behandlungen etwas kurz, aber wir belassen es mal bei den Namen. Du kannst dir hier eben fünf Insektizide vorstellen, die wir dann miteinander vergleichen würden. Zu den Gruppenvergleichen findest du dann ganz am Ende des Kapitels nochmal einen eignene Abschnitt sowie dann auch zwei Anwendungsbeispiele.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-worms
#| tbl-cap: "Auszug aus den Wurmdaten in einem *latin square design* für fünf verschiedene Insektizide."

worm_raw_tbl <- wireworms_tbl %>% 
  mutate(trt = as.character(trt),
         col = as.character(col),
         row = as.character(row)) %>% 
  as_tibble()

rbind(head(worm_raw_tbl, n = 4),
      rep("...", times = ncol(worm_raw_tbl)),
      tail(worm_raw_tbl, n = 4)) %>% 
  kable(align = "c", "pipe")
```

In der folgenden Box findest du noch mehr Daten und experimentelle Designs aus dem [R Paket `{agridat}`](https://kwstat.github.io/agridat/reference/index.html). Dort findest du dann noch mehr Inspirationen wie Daten aussehen könnten, die mit einem linearen gemischten Modell ausgewertet werden. Nicht alle der dortigen Daten können nur mit einem gemischten Modell ausgewertet werden, es gibt auch eine Reihe an einfacheren Datensätzen. Ich habe hier jetzt zwei der über hundert Datensätze ausgewählt, die ich relativ repräsentativ finde.

::: callout-tip
## Weitere Daten zu gemischten Modellen

Alle Daten hier stammen aus dem [R Paket `{agridat}`](https://kwstat.github.io/agridat/reference/index.html) und lassen sich somit mit der Funktion `data()` laden. Die Daten liegen meistens nicht als `tibble()` vor, so dass manchmal noch etwas Datenaufbereitung notwendig ist.

-   [Mating crosses of chickens](https://kwstat.github.io/agridat/reference/becker.chicken.html)
-   [Latin square of four breeds of sheep with four diets](https://kwstat.github.io/agridat/reference/depalluel.sheep.html)
-   [Birth weight of lambs from different lines/sires](https://kwstat.github.io/agridat/reference/harville.lamb.html)
-   [Weight gain calves in a feedlot](https://kwstat.github.io/agridat/reference/urquhart.feedlot.html)
-   [Average daily gain of 65 steers for 3 lines, 9 sires.](https://kwstat.github.io/agridat/reference/harvey.lsmeans.html)
-   [Multi-environment trial of oats in United States, 5 locations, 7 years.](https://kwstat.github.io/agridat/reference/edwards.oats.html)
-   `glmer()` [Wireworms controlled by fumigants in a latin square](https://kwstat.github.io/agridat/reference/cochran.wireworms.html)

Es gibt natürlich noch mehr Datensätze, die du dann mit einem gemischten Modell auswerten kannst, aber das ist hier einmal eine Auswahl an möglichen Datensätzen zum üben.
:::

## Visualisierung

Der wichtigste Teil in einer Analyse ist die Visualisierung der Zusammenhänge. Das ist noch wahrer bei ser komplexen Modellen wie es die linearen gemischten Modelle sind. Wir müssen erstmal verstehen welche Gruppenstrukturen wir in den Daten haben und welchen Einfluss diese auf die jeweiligen Outcomes haben. Häufig müssen wir dazu dann aber mehrere Abbildungen erstellen, den bei so vielen Faktoren reichen dann einfache 2D Abbidlungen dann meistens nicht mehr aus. Ich versuche hier dann einmal zu zeigen, wie du das meiste aus `{ggplot}` rausholen kannst, um dir komplexe Daten zu visualisieren.

Wie bringen wir also möglichst viele informative Abbildungen sinnvoll zusammen? Wir nutzen dazu das [R Paket`{gghalves}`](https://erocoar.github.io/gghalves/). Wir können mit `{gghalves}` halbe Plots erstellen und diese dann miteinander kombinieren für ein Faktorlevel kombinieren. Dabei setzen wir dann in die Mitte Boxplots. Links von den Boxplots zeichnen wir die einzelnen Beobachtungen als Punkte mit `stat_dots()` und die Verteilung der einzelnen Beobachtungen zeichnen wir mit dem [R Paket `{ggdist}`](https://mjskay.github.io/ggdist/) auf die rechte Seite. Das Tutorium [Visualizing Distributions with Raincloud Plots](https://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/) liefert dann noch mehr Anleitungen für noch mehr Varianten. Wie du aber schon am R Code siehst, ist das eine etwas komplexere Abbildung geworden.

Damit wir den ganzen R Code nicht die ganze zeit kopieren müssen, habe ich im folgenden Chunk einmal ein `{ggplot}`-Template erstellt, welches ich dann immer wieder mit neuen Daten und einem `aes()`-Aufruf versehen werde. Das kürzt dann doch ziemlich den Code zusammen. Insbesondere da wir ja sehr viele Abbildungen für unsere drei Datensätz bauen müssen. Du kannst natürlich auch immer dreimal die einzelnen Abbildungen bauen oder aber mit `facet_wrap()` arbeiten um den dritten Faktor darzustellen.

```{r}
gg_half_template <- ggplot() +
  stat_halfeye(adjust = .5, width = .6, 
               .width = 0, justification = -.2, 
               point_colour = NA) + 
  geom_boxplot(width = 0.15, outlier.shape = NA) +
  stat_dots(side = "left", justification = 1.12, binwidth = .25) +
  coord_cartesian(xlim = c(1.2, 2.9), clip = "off") +
  scale_color_okabeito() +
  theme(legend.position = "top") 
```

### Schuldaten

Dann schauen wir uns einmal in den folgenden beiden Tabs die Schuldaten und damit die Effekte der Schulen und der jeweils drei Klassen auf die Testergebnisse der Schüler an. Es ist immer wichtig sich alle möglichen Kombinationen von Faktoren anzuschauen um dann auch eine Idee für das gemischte Modell im Anschluss zu finden. Sonst stochert man sehr im Nebel rum und mit den Abbildungen hat man dann einen Hinweis, wohin es gehen könnte.

::: panel-tabset
## Effekt der Schule

In der folgenden @fig-mixed-school-1 sehen wir einmal die Effekte der Schule aufgeteilt nach den Lehrformaten auf die Testergebnisse der jeweiligen Schüler. Es fällt sofort ein Effekt der Schulen auf die Testergebnisse auf. Zum Beispiel hat die *Greenville School* im Frontalunterricht sehr viel schlechte Testergebnisse als die beiden anderen Schulen mit Frontalunterricht. Ähnliches, aber im positiven Sinne, sehen wir bei der *Arlington Academy*, die gegen den Trend der beiden anderen Schulen, bessere Ergebnisse bei dem Lehrformat Flipped Classroom erreicht. Somit müssen wir in unserer Analyse die Schule mit berücksichtigen, es macht eben einen Unetrschied, auf welche Schule ein Schüler gegangen ist.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: "Dreifachplot der Testergebnisse der Schüler zusammen über alle drei Klassen in den jeweiligen neun Schulen aufgetrennt nach dem Lehrformat. Teilweise sind starke Effekte der Schulen auf die Testergebnisse der Schüler zu erkennen."
#| label: fig-mixed-school-1

gg_half_template %+%
  school_tbl + 
  aes(x = trt, y = test, color = school_id) +
  labs(x = "Lehrformat", y = "Testscore", color = "Schule") +
  guides(color = guide_legend(nrow = 3, byrow = FALSE))

```

## Effekt der Klassen

Jetzt schauen wir uns noch den Effekt der Klasse an und fragen uns in der @fig-mixed-school-3, ob wir auch einen starken Effekt der Klassen auf die Testergebnisse haben. Hier sehen wir zwar auch Unterschiede zwischen den Klassen, aber die Effekt sind in den Lehrformaten eher gleichmäßig vertreten. Die kleine Gruppe bei dem Lehrformat Frontal gehört zur einer Schule und nicht zu einer einzelnen Klasse. Damit könnten wir die Klasse eher ignorieren, wenn wir unser Modell bauen. Es macht nicht so einen großen Unterschied in welche Klasse ein Schüler gegangen ist.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: "Dreifachplot der Testergebnisse der Schüler zusammen über alle Schulen in den jeweiligen drei Klassen aufgetrennt nach dem Lehrformat. Die Effekte der einzelnen Klassen sind nicht so stark ausgeprägt. Der Effekt der Schulen scheint in diesem Fall stärker zu sein."
#| label: fig-mixed-school-3

gg_half_template %+%
  school_tbl + 
  aes(x = trt, y = test, color = class_in_school_id) +
  labs(x = "Lehrformat", y = "Testscore", color = "Klasse") +
  guides(color = guide_legend(nrow = 1, byrow = FALSE))

```
:::

Gerade haben wir gesehen, dass die Schulen mehr der Varianz in den Testergebnissen der Schüler erklären als die Klassen. Brauchen wir eigentlich nur die Schulen oder reichen auch die Informationen die in den einzelnen Klassen stecken? Wir haben ja unsere Daten so gebaut, dass wir immer nur drei Klassen pro Schule haben und jeweils eine der drei Klassen ein Lehrformat erhält. Damit könnte es sein, dass wir mit dem Faktor `class_id` auch die Varianz der Schulen `scholl_id` mit abbilden könnten. Das funktioniert hier aber nur, da die immer die gleiche Anzahl an Klassen mit der gleichen Anzahl an Lehrformaten in einer Schule verschachtelt ist. Schauen wir dazu einmal in die @fig-mixed-school-2. Wie wir sehen, scheinen die einzelnen Klassen die jeweiligen Schulen mit abzubilden. Die Klasse 19, 20 und 21 ist beim Forntalunterreicht schlechter. Dies wird die Schule *Greenville School* sein. Wir können also alleine durch die Information zu den einzlenen Klassen die Varianz der Schulen erklären! Mal schauen, was das dann später für unser lineares gemischtes Modell bedeutet.

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5
#| fig-width: 7
#| fig-cap: "Boxplot der Testergebnisse der drei Lehrformate aufgeteilt nach den individuellen Klassen. Da immer nur drei Klassen pro Schule erhoben wurden, bilden die individuellen Klassen auch den Effekt der Schulen mit ab."
#| label: fig-mixed-school-2

ggplot(school_tbl, aes(x = class_id, y = test, fill = trt)) +
  geom_boxplot(outlier.size = 0.5) +
  labs(x = "Individuelle Klassen ID", y = "Testscore", fill = "Lehrformat") +
  scale_fill_okabeito() +
  theme(legend.position = "top")
```

### Weizendaten

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-desplot-yates

desplot(oats_tbl, block ~ col*row, 
        num = nitro, col = gen,
        cex = 1, aspect = 5/3,
        main = "")
```

::: panel-tabset
## Effekt der Linie `gen`

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-yates-1-gen

gg_half_template %+%
  oats_tbl + 
  aes(x = gen, y = plant_yield, color = block) +
  labs(x = "Genetische Linie", y = "Ertrag", color = "Block") +
  guides(color = guide_legend(nrow = 1, byrow = FALSE))
```

## Effekt des Stickstoff `nitro`

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-yates-1-nitro

gg_half_template %+%
  oats_tbl + 
  aes(x = nitro, y = plant_yield, color = block) +
  labs(x = "Stickstoffkonzentration", y = "Ertrag", color = "Block") +
  guides(color = guide_legend(nrow = 1, byrow = FALSE))
```
:::

### Wurmdaten

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-desplot-wireworms
desplot(wireworms_tbl, trt ~ col * row,
        text = trt, cex = 1, show.key = FALSE,
        main = "")
```

```{r}
#| message: false
#| warning: false
#| echo: true
#| fig-align: center
#| fig-height: 5.5
#| fig-width: 7
#| fig-cap: Histogramm des Testscores über alle Datenpunkte zur Überprüfung der Annahme der Normalverteilung. Wir sehen eine approximative Normalverteilung des Testscores.
#| label: fig-mixed-wireworm-1
#| fig-subcap: 
#|   - "Spalte (`col`)"
#|   - "Reihe (`row`)"
#| layout-nrow: 1
#| column: page

gg_half_template %+%
  wireworms_tbl + 
  aes(x = trt, y = count_worms, color = col) +
  labs(x = "Insektizidbehandlung", y = "Anzahl Würmer", color = "Spalte (col)") +
  guides(color = guide_legend(nrow = 1, byrow = FALSE)) 

gg_half_template %+%
  wireworms_tbl + 
  aes(x = trt, y = count_worms, color = row) +
  labs(x = "Insektizidbehandlung", y = "Anzahl Würmer", color = "Reihe (row)") +
  guides(color = guide_legend(nrow = 1, byrow = FALSE)) 
```

## Modellierung

::: callout-important
## Mindestanzahl an Leveln für einen zufälligen Effekt

Wir brauchen mindestens 5 bis 6 Level für einen Faktor, den wir als zufälligen Effekt deklarieren. Das würde hier aber leider die Beispiele sehr komplex machen... deshalb hier mit weniger Leveln und dafür dann nicht so guten Ergebnissen.
:::

@bates2014fitting hat das [R Paket `{lme4}`](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) entwickelt, welches uns erlaubt lineare gemischte Modelle in R anzuwenden. Es gibt noch das ältere R Paket `{nlme}` was aber nicht mehr für lineare gemischte Modelle genutzt wird. Wir nutzen aber gerne die Funktion `gls()` aus dem R Paket `{nlme}`, wenn wir eine lineare Regression mit heterogenen Varianzen rechnen wollen.

[R Paket `{glmmTMB}`](https://glmmtmb.github.io/glmmTMB/index.html) und dann noch [Covariance structures with glmmTMB](https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html)

[R Paket `{mixedup}`](https://m-clark.github.io/mixedup/)

[R Paket `{multilevelmod}`](https://multilevelmod.tidymodels.org/articles/multilevelmod.html)

| Formula                         | Bedeutung                                                                                                                    |
|---------------------------------|------------------------------------------------------------------------------------------------------------------------------|
| $(1\; |\; g)$                   | Zufälliger $y$-Achsenabschnitt mit festen Mittelwert (eng. *Random intercept with fixed mean*)                               |
| $(1\; |\; g_1/g_2)$             | Der $y$-Achsenabschnitt variiert in $g_1$ und $g_2$ innerhalb von $g_1$ (eng. *Intercept varying among g1 and g2 within g1*) |
| $(1\; |\; g_1) + (1\; |\; g_2)$ | Der $y$-Achsenabschnitt variiert zwischen $g_1$ und $g_2$ (eng. *Intercept varying among g1 and g2*)                         |
| $x + (x\; |\; g)$               | Korrelierter zufälliger $y$-Achsenabschnitt und Steigung (eng. *Correlated random intercept and slope*)                      |
| $x + (x\; ||\; g)$              | Unkorrelierter zufälliger $y$-Achsenabschnitt und Steigung (eng. *Uncorrelated random intercept and slope*)                  |

: Bedeutung der Formelschreibweise der zufälligen Effekte in einem linearen gemischten Modell in `{lmer}`. Mehr zu der Bedeutung dann in der Veröffentlichung von @bates2014fitting.

### Mitteln über den zufälligen Effekt

Wir mitteln über einen zufälligen Effekt um die individuelle Varianz zu entfernen.

### ... mit dem R Paket `{lme4}`

@bates2014fitting hat das [R Paket `{lme4}`](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) entwickelt, welches uns erlaubt lineare gemischte Modelle in R anzuwenden. Es gibt noch das ältere R Paket `{nlme}` was aber nicht mehr für lineare gemischte Modelle genutzt wird. Wir nutzen aber gerne die Funktion `gls()` aus dem R Paket `{nlme}`, wenn wir eine lineare Regression mit heterogenen Varianzen rechnen wollen.

::: panel-tabset
## `lmer()` 2-faktoriell ungenested

```{r}
#| warning: false
#| message: false
lmer_2fac_fit <- lmer(test ~ trt +
                        (1 | school_id), 
                      data = school_tbl)
```

```{r}
#| warning: false
#| message: false
lmer_2fac_fit %>% icc()
```

```{r}
#| warning: false
#| message: false
lmer_2fac_fit %>% model_performance()
```

## `lmer()` 3-faktoriell ungenested

```{r}
#| warning: false
#| message: false
lmer_3fac_fit <- lmer(test ~ trt +
                        (1 | class_in_school_id) + 
                        (1 | school_id), 
                      data = school_tbl)
```

```{r}
#| warning: false
#| message: false
lmer_3fac_fit %>% icc()
```

```{r}
#| warning: false
#| message: false
lmer_3fac_fit %>% model_performance()
```

## `lmer()` 3-faktoriell genested

```{r}
#| warning: false
#| message: false
lmer_3fac_nested_fit <- lmer(test ~ trt +  
                               (1 | class_id/school_id), 
                             data = school_tbl)
```

```{r}
#| warning: false
#| message: false
lmer_3fac_nested_fit %>% icc()
```

```{r}
#| warning: false
#| message: false
lmer_3fac_nested_fit %>% model_performance()
```
:::

Mehr Informationen zu den Modellen gibt es mit folgenden Funktionen aus dem R Paket `{mixedup}`.

```{r}
#| warning: false
#| message: false
#| eval: false
extract_random_effects(lmer_2fac_fit)
extract_fixed_effects(lmer_2fac_fit)
summarize_model(lmer_2fac_fit)
extract_vc(lmer_2fac_fit)
```

Wir schauen uns dann einmal als Übersichtstabelle die drei Modelle an.

```{r}
#| warning: false
#| message: false
modelsummary(lst("lmer 2-fakoriell" = lmer_2fac_fit, 
                 "lmer 3-fakoriell genested" = lmer_3fac_nested_fit,
                 "lmer 3-fakoriell ungenested" = lmer_3fac_fit),
             statistic = c("conf.int",
                           "s.e. = {std.error}"))
```

Das R Paket `{lme4}` hat auch die Möglichkeit mit nicht normalverteilten Daten über die Funktion `glmer()` umzugehen. Da schauen wir aber gleich mal rein und zwar bei den Würmerdaten und stellen dabei auch das R Paket `{glmmTMB}` als Alternative vor.

### ... mit dem R Paket `{glmmTB}`

Hier schauen wir uns einmal den Datensatz zu den Würmern an.

[R Paket `{glmmTMB}`](https://glmmtmb.github.io/glmmTMB/index.html) und dann noch [Covariance structures with glmmTMB](https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html)

[glmmTMB: Generalized Linear Mixed Models using Template Model Builder](https://cran.r-project.org/web/packages/glmmTMB/)

::: panel-tabset
## `glmer()` mit `famliy = poisson`

```{r}
glmer_poisson_fit <- glmer(count_worms ~ trt + (1|row) + (1|col), 
                           data = wireworms_tbl, family = "poisson")
```

```{r}
glmer_poisson_fit  %>% check_overdispersion()
```

Wir haben sehr starke Overdispersion vorliegen und gehen daher rüber in den anderen Tab und rechnen eine Quasipoisson Regression. Nur wenn du keine Overdispersion vorliegen hast, dann kannst du eine eine Poisson Regression rechnen.

## `glmmTMB()` mit `famliy = nbinom1`

Da wir in `{lme4}` keine Quasipoissonverteilung auswählen können, nutzen wir das [R Paket `{glmmTMB}`](https://glmmtmb.github.io/glmmTMB/index.html) mit der Verteilungsfamilie `nbinom1`, was einer Parametrisierung einer Quasipoissonverteilung entspricht.

[Covariance structures with glmmTMB](https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html)

```{r}
glmmTMB_nbinom1_fit <- glmmTMB(count_worms ~ trt + (1|row) + (1|col), 
                               data = wireworms_tbl, family = nbinom1) 
```

Damit wir dann auch Overdispersion in einer Poissonregression berücksichtigen können nutzen wir den gleichen "Trick" wie in [Covariance structures for the error term with glmmTMB - a workaround](https://schmidtpaul.github.io/MMFAIR/glmmtmbdispformula0.html)
:::

```{r}
#| warning: false
#| message: false
modelsummary(lst("glmer poisson" = glmer_poisson_fit, 
                 "glmmTMB nbinom1" = glmmTMB_nbinom1_fit),
             statistic = c("conf.int",
                           "s.e. = {std.error}"))
```

### ... mit dem R Paket `{multilevelmod}`

[R Paket `{multilevelmod}`](https://multilevelmod.tidymodels.org/articles/multilevelmod.html)

[R Paket '{parsnip}' - Linear regression](https://parsnip.tidymodels.org/reference/linear_reg.html)

```{r}
oats_lmer_spec <- linear_reg() %>% 
  set_engine("lmer")
```

Wir brauchen die Funktion `extract_fit_engine()` damit wir dann die Funktionen aus den anderen Paketen korrekt anwenden können.

```{r}
oats_lmer_fit <- oats_lmer_spec %>% 
  fit(plant_yield ~ nitro + gen + nitro:gen + (1|block/gen), data = oats_tbl) %>% 
  extract_fit_engine()  
```

```{r}
#| warning: false
#| message: false
oats_lmer_fit %>% icc()
```

```{r}
#| warning: false
#| message: false
oats_lmer_fit %>% model_performance()
```

## Old (remove me)

Unser Model sieht etwas aufgeräumter aus. Als feste Effekte haben wir nur noch die Körperlänge `body_length_cat` und die dazugehörigen Koeffizienten des Modells. Unsere Variable `mountain` verschwindet dann in den zufälligen Effekten. Die Funktion `summary` liefert uns den gesamten Ausdruck, der etwas überwältigend ist. Vieles brauchen wir auch nicht davon.

![](images/lmer_summary.png){fig-align="center" width="90%"}

Was wir extrahieren wollen ist die Information von den zufälligen Effekten. Wir wollen wissen, wieviel Varianz durch die zufälligen Effekte erklärt wird. Wir nutzen dazu die Funktion `VarCorr()`, die uns erlaubt die Information zu en zufälligen Effekten zu extrahieren und auszugeben.

Wieviel Varianz erklären nun die Berge? Wir können die erklärte Varianz der zufälligen Effekte einfach berechnen. Wir vergleichen die erklärte Varianz von `mountain` mit der gesamten Varianz. Die gesamte Varianz ist die Varianz aller zufälligen Effekte plus der residualen Varianz. Wir erhalten dann $R^2_{random} = 339.7/(339.7 + 223.8) \approx 0.60$. Wir sehen, dass ca. 60% der Varianz in unseren Daten von der Variable `mountain` verursacht wird.

Wir können die Funktion `model_performance()` nutzen um mehr über den Fit des Modells zu erfahren. Das `R2 (cond.)` ist faktisch das gleiche wie wir gerade oben berechnet haben. Wir benötigen also nicht immer den Ausdruck der zufälligen Effekte. Wir können auch die Informationen aus der Funktion `model_performance()` nehmen.

## Gruppenvergleich {#sec-mult-comp-lmer-reg}

![](images/caution.png){fig-align="center" width="50%"}

text

::: panel-tabset
## `lmer`

```{r}
#| eval: false
lmer_fit <- lmer(test ~ trt + (1|id_school) + (1|id_class), data = dt_student) 

lmer_fit2 <- lmer(test ~ trt + (1|id_class/id_school), data = dt_student) 

compare_performance(lmer_fit, lmer_fit2, rank = TRUE)

plot(compare_performance(lmer_fit, lmer_fit2, rank = TRUE, verbose = FALSE))

lmer_fit %>% 
  model_performance()

lmer_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

lmer_fit %>% anova

```

## `lm`

```{r}
#| eval: false
lm_fit <- lm(test ~ trt + id_school + id_class, data = dt_student) 

lm_fit %>% 
  model_performance()

lm_fit %>% 
  emmeans(~ trt) %>% 
  pairs()

lm_fit %>% anova
```
:::

::: callout-tip
## Anwendungsbeispiel: Dreifaktorieller Gruppenvergleich für das Gewicht

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit Brokkoli an. Wir haben uns in diesem Experiment verschiedene Dosen `fert_amount` von einem Dünger aufgebracht sowie verschiedene Zeitpunkte der Düngung `fert_time` berücksichtigt. Auch hier haben wir einige Besonderheiten in den Daten, da nicht jede Faktorkombination vorliegt. Wir ignorieren aber diese Probleme und rechnen einfach stumpf unseren Gruppenvergleich.

```{r}
broc_tbl <- read_excel("data/broccoli_weight.xlsx") %>% 
  mutate(fert_time = factor(fert_time, levels = c("none", "early", "late")),
         fert_amount = as_factor(fert_amount),
         block = as_factor(block)) %>%
  select(-stem_hollowness) 
```

Wir nutze hier dann die Hilfe des R Pakets `{lmerTest}`

```{r}
#| warning: false
#| message: false
lmer_fit <- lmerTest::lmer(weight ~ fert_time + fert_amount + fert_time:fert_amount + (1 | block), 
                           data = broc_tbl) 
```

[R2 for Mixed Models -- Marginal vs. Conditional R2](https://easystats.github.io/performance/articles/r2.html#marginal-vs--conditional-r2)

```{r}
lmer_fit %>% r2()
```

[Intraclass Correlation Coefficient (ICC)](https://easystats.github.io/performance/reference/icc.html)

```{r}
lmer_fit %>% icc()
```

```{r}
lmer_fit %>% 
  model_performance()
```

Wir erhalten hier einen Fehler, aber wir haben ja auch nicht alle Faktorkombinationen in den Daten mit Werten vorliegen. Hier hätten wir etwas mehr sauber machen sollen.

Jetzt rechnen wir in den beiden folgenden Tabs einmal die ANOVA und dann auch den multiplen Gruppenvergleich mit `{emmeans}`. Da wir hier normalveteilte Daten haben, können wir dann einfach die Standardverfahren nehmen. Eventuell müssten wir bei dem Gruppenvergleich mit `emmeans()` nochmal für Varianzheterogenität adjustieren, aber da erfährst du dann mehr in dem Kapitel zu den [Multiple Vergleichen oder Post-hoc Tests](#sec-posthoc).

::: panel-tabset
## ANOVA mit `anova()`

Wir rechnen hier einmal die ANOVA und nutzen den $\mathcal{X}^2$-Test für die Ermittelung der p-Werte. Wir müssen hier einen Test auswählen, da per Standardeinstellung kein Test gerechnet wird. Wir machen dann die Ausgabe nochmal schöner und fertig sind wir.

Wir nutze hier dann die Hilfe des R Pakets `{lmerTest}`

```{r}
#| warning: false
#| message: false
lmer_fit %>% 
  anova() %>% 
  model_parameters()
```

Wir sehen, dass der Effekt der Düngerzeit und die Menge des Düngers signifikant ist, jedoch wir keinen signifikanten Einfluss durch die Interaktion haben. Wir haben aber also keine Interaktion vorliegen. Leider ist auch der Block signifikant, so dass wir eigentlich nicht über den Block mitteln sollten. Wir rechnen trotzdem die Analyse gemittelt über die Blöcke. Wenn du hier mehr erfahren möchtest, dann schaue dir das Beispiel hier nochmal im Kapitel zu dem [linearen gemischten Modellen](#sec-mixed) an.

## Gruppenvergleich mit `emmeans()`

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `fert_time` und `fert_amount` einen Gruppenvergleich. Dafür nutzen wir die Option `fert_time * fert_amount`. Wenn du die Analyse *getrennt* für die Menge und den Zeitpunkt durchführen willst, dann nutze die Option `fert_time | fert_amount`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- lmer_fit %>% 
  emmeans(~ fert_time * fert_amount) %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `emmean` stellt den mittleren Gewicht des Brokkoli je Faktorkombination dar gemittelt über alle Blöcke. Das Mitteln über die Blöcke ist eher fragwürdig, da wir ja einen Effekt der Blöcke in der ANOVA gefunden hatten. Hier schauen wir dann nochmal auf das Beispiel im Kapitel zu den [linearen gemischten Modellen](#sec-mixed). Dann können wir zum Abschluss auch das *compact letter display* anhand der Abbildung interpretieren.
:::

In der @fig-log-mod-gaussian-broc siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Wir sehen einen klaren Effekt der Düngezeitpunkte sowie der Düngermenge auf das Gewicht von Brokkoli. Wenn wir ein mittleres Gewicht von $500g$ für den Handel erreichen wollen, dann erhalten wir das Zielgewicht nur bei einer Düngemenge von $300mg/l$. Hier stellt sich dann die Frage, ob wir bei $225mg/l$ und einem frühen Zeitpunkt der Düngung nicht auch genug Brokkoli erhalten. Das Ziel ist es ja eigentlich in einen Zielbereich zu kommen. Die Köpfe sollen ja nicht zu schwer und auch nicht zu leicht sein. Aber diese Frage und andere Fragen der biologischen Anwendung lassen wir dann hier einmal offen, denn das Beispiel soll ja nur ein Beispiel sein.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-gaussian-broc
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mittleren Brokkoligewichte aus einer Gaussian Regression. Das `lm()`-Modell berechnet das mittler Gewicht des Brokkoli in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert. Wir nutzen hier den Standardfehler, da die Standardabweichung mit der großen Fallzahl rießig wäre. Wir haben noch ein Mindestgewicht von 500g ergänzt."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = fert_time, y = emmean, fill = fert_amount)) +
  theme_bw() + 
  labs(y = "Mittleres Gewicht [g] des Brokkoli", x = "Düngezeitpunkt",
       fill = "Düngemenge [mg/l]") +
  scale_y_continuous(breaks = seq(0, 500, by = 100)) +
  geom_hline(yintercept = 500, size = 0.75, linetype = 2) +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = .group, y = emmean + SE + 0.01),  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = emmean-SE, ymax = emmean+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

::: callout-tip
## Anwendungsbeispiel: Gruppenvergleich für Thripsenbefall (3-faktoriell)

Im folgenden Beispiel schauen wir uns nochmal ein praktische Auswertung von einem agrarwissenschaftlichen Beispiel mit jungen Apfelbäumen an. Wir haben uns in diesem Experiment verschiedene Dosen `trt` von einem Insektizid aufgebracht sowie verschiedene Startanzahlen von Raubmilben als biologische Alternative untersucht. Dann haben wir noch fünf Zeitpunkte bestimmt, an denen wir die Anzahl an Thripsen auf den Blättern gezählt haben. Wir haben nicht die Blätter per se gezählt sondern Fallen waagerecht aufgestellt. Dann haben wir geschaut, wie viele Thripsen wir über `above` und unter `below` von den Fallen gefunden haben. In unserem Fall beschränken wir uns auf die obere Anzahl an Thripsen und schauen uns auch nur die Behandlung mit dem Insektizid an.

```{r}
insects_tbl <- read_excel("data/insects_count.xlsx") %>% 
  mutate(timepoint = factor(timepoint, labels = c("1 Tag", "4 Tag", "7 Tag", "11 Tag", "14 Tag")),
         rep = as_factor(rep),
         trt = as_factor(trt)) %>%
  select(timepoint, trt, rep, thripse = thripse_above, mite = mite_above) %>% 
  filter(trt %in% c("10ml", "30ml", "60ml"))
```

Dann können wir auch schon die Poisson Regression mit `glm()` rechnen. Auch hier wieder darauf achten, dass wir dann als Option `family = poisson` oder `family = quasipoisson` wählen. Es hängt jetzt davon ab, ob du in deinen Daten Overdispersion vorliegen hast oder nicht. In den beiden folgenden Tabs, rechne ich dann mal beide Modelle.

::: panel-tabset
## `glmer()` mit `family = poisson`

Als Erstes rechnen wir eine normale Poisson Regression und schauen einmal, ob wir Overdispersion vorliegen haben. Wenn wir Overdispersion vorliegen haben, dann können wir keine Poisson Regression rechnen, sondern müssen auf eine Quasipoisson Regression ausweichen. Das ist aber sehr einfach, wie du im anderen Tab sehen wirst.

```{r}
insects_poisson_fit <- glmer(thripse ~ trt + timepoint + trt:timepoint + (1 | rep), 
                             data = insects_tbl, 
                             family = poisson) 
```

Bevor wir uns das Modell mit `summary()` überhaupt anschauen, wollen wir erstmal überprüfen, ob wir überhaupt Overdispersion vorliegen haben. Wenn ja, dann können wir uns die `summary()` hier gleich sparen. Also einmal geguckt, was die Overdispersion macht.

```{r}
insects_poisson_fit %>% check_overdispersion()
```

Wir haben sehr starke Overdispersion vorliegen und gehen daher rüber in den anderen Tab und rechnen eine Quasipoisson Regression. Nur wenn du keine Overdispersion vorliegen hast, dann kannst du eine eine Poisson Regression rechnen.

## `glmmTMB()` mit `family = nbinom1`

Da wir in `{lme4}` keine Quasipoissonverteilung auswählen können, nutzen wir das [R Paket `{glmmTMB}`](https://glmmtmb.github.io/glmmTMB/index.html) mit der Verteilungsfamilie `nbinom1`, was einer Parametrisierung einer Quasipoissonverteilung entspricht.

Entweder hast du in deinen Daten eine Overdispersion gefunden oder aber du meinst, es wäre besser gleich eine Quasipoisson zu rechnen. Beides ist vollkommen in Ordnung. Ich rechne meistens immer eine Quasipoisson und schaue dann nur, ob die Overdispersion sehr groß war. In den seltensten Fällen hast du eine Overdispersion vorliegen, die eher klein ist. Daher mache ich erst die Lösung und schaue, ob das Problem dann da war.

```{r}
insects_quasipoisson_fit <- glmmTMB(thripse ~ trt + timepoint + trt:timepoint + (1|rep), 
                                    data = insects_tbl,
                                    family = nbinom1) 
```

Du kannst in der `summary()` Ausgabe direkt sehen, ob du Overdispersion vorliegen hast. Du musst nur relativ weit unten schauen, was zu dem `Dispersion parameter` in den Klammern geschrieben ist. Wenn da eine Zahl größer als 1 drin steht, dann hast du Overdispersion.

```{r}
insects_quasipoisson_fit %>% 
  summary()
```

```{r}
insects_quasipoisson_fit %>% r2()
```

[Intraclass Correlation Coefficient (ICC)](https://easystats.github.io/performance/reference/icc.html)

```{r}
insects_quasipoisson_fit %>% icc()
```

```{r}
insects_quasipoisson_fit %>% 
  model_performance()
```

Wir haben hier auf jeden Fall Overdispersion vorliegen. Daher nutze ich dann auch das Modell hier mit der Annahme an eine Quasipoissonverteilung. Dann stimmt es auch mit unseren Varianzen und wir produzieren nicht zufällig zu viele signifikante Ergebnisse, die es dann gar nicht gibt.
:::

Ich habe mich gerade in den obigen Tabs für eine Quasipoisson Regression entschieden, da wir Overdispersion vorliegen haben. Damit mache ich dann mit dem `insects_quasipoisson_fit` Modell weiter. In den beiden folgenden Tabs findest du dann einmal das Ergebnis für die ANOVA und einmal für den Gruppenvergleich mit dem R Paket `{emmeans}`. Bitte beachte, dass die ANOVA für ein `glm()`-Objekt nicht ganz gleich wie für ein `lm()`-Objekt ist. Du kannst aber die ANOVA erstmal ganz normal interpretieren, nur haben wir hier nicht die Möglichkeit ein $\eta^2$ zu bestimmen. Dann nutzen wir `{emmeans}` für den Gruppenvergleich. Nochmal, weil wir Overdispersion festgestellt haben, nutzen wir das Objekt `insects_quasipoisson_fit` mit der Berücksichtigung der Overdispersion.

Im Folgenden rechnen wir einmal über alle Faktorkombinationen von `trt` und `timepoint` einen Gruppenvergleich. Dafür nutzen wir die Opition `trt * timepoint`. Wenn du die Analyse *getrennt* für die Zeitpunkte durchführen willst, dann nutze die Option `trt | timepoint`. Wir wollen die Wahrscheinlichkeiten für das Auftreten einer Beschädigung von wiedergegeben bekommen, deshalb die Option `regrid = "response`. Dann adjustieren wir noch nach Bonferroni und sind fertig.

```{r}
emm_obj <- insects_quasipoisson_fit %>% 
  emmeans(~ trt * timepoint, type = "response") %>%
  cld(Letters = letters, adjust = "bonferroni")
emm_obj
```

Das `emm_obj` Objekt werden wir dann gleich einmal in `{ggplot}` visualisieren. Die `rate` stellt die mittlere Anzahl an Thripsen je Faktorkombination dar. Dann können wir auch das *compact letter display* anhand der Abbildung interpretieren.

`str_trim()`

In der @fig-log-mod-pois-insect siehst du das Ergebnis der Auswertung in einem Säulendiagramm. Hier unbedingt `SE` als den Standardfehler für die Fehlerbalken nutzen, da wir sonst Fehlerbalken größer und kleiner als $0$ erhalten, wenn wir die Standardabweichung nutzen würden. Das ist in unserem Fall nicht so das Problem, aber wenn du eher kleine Anzahlen zählst, kann das schnell zu Werten kleiner Null führen. Wir sehen einen klaren Effekt der Behandlung `60ml`. Die Zeit hat keinen Effekt, was ja schon aus der ANOVA klar war, die Säulen sehen für jeden Zeitpunkt vollkommen gleich aus. Gut etwas Unterschied ist ja immer.

```{r}
#| echo: true
#| warning: false
#| message: false
#| label: fig-log-mod-pois-insect
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Säulendigramm der mitleren Zahl der Thripsen aus einer Poisson Regression. Das `glm()`-Modell berechnet die mittlere Anzahl in jeder Faktorkombination. Das *compact letter display* wird dann in `{emmeans}` generiert."

emm_obj %>% 
  as_tibble() %>% 
  ggplot(aes(x = timepoint, y = response, fill = trt)) +
  theme_bw() + 
  labs(y = "Mittlere Anzahl an Thripsen", x = "Messzeitpunkte der Zählungen",
       fill = "Dosis") +
  geom_bar(stat = "identity", width = 0.8, 
           position = position_dodge(width = 0.9, preserve = "single")) +
  geom_text(aes(label = str_trim(.group), y = response + SE + 1), size = 3,  
            position = position_dodge(width = 0.9), vjust = -0.25) +
  geom_errorbar(aes(ymin = response-SE, ymax = response+SE),
                width = 0.2,  
                position = position_dodge(width = 0.9, preserve = "single")) +
  scale_fill_okabeito()
```
:::

## Referenzen {.unnumbered}
