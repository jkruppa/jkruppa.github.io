```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Sensitivitätsanalyse {#sec-sensitivity}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

![](images/caution.png){fig-align="center" width="50%"}

## Theoretischer Hintergrund

Wir brauchen die Sensitivitätsanalyse wenn wir Beobachtungen aus unseren Daten entfernt oder aber hinzugefügt haben. Das heißt du hast entweder eine Variablenselektion wie im @sec-variable-selection beschrieben durchgeführt. Oder aber du hast fehlende Werte wie in @sec-missing beschrieben imputiert. Es kann auch sein, dass du Ausreißer aus den Daten entfernt oder aber imputiert hast, wie es in @sec-outlier beschrieben ist. Im Prinzip kannst du auch alles drei gemacht haben, aber meistens beschränkt sich die *Veränderung* der Daten nur auf eins der drei Möglichkeiten.

::: column-margin
![](images/angel_01.png){fig-align="center" width="50%"}

Das ist hier natürlich eine Sensitivitätsanalyse für Arme. Wie man es richtig umfangreich macht, findest du in einem sehr gutem und umfangreichen Tutorial zu [What Makes a Sensitivity Analysis?](https://lesslikely.com/statistics/sensitivity/)
:::

Dieses Kapitel ist relativ übersichtlich. Wir werden die Modelle nach der jeweiligen algorithmischen Veränderung uns nochmal anschauen und dann *deskriptive* entscheiden, ob wir eine große Veränderung in den Daten sehen. Es gibt zwar auch die Möglichkeit die Modelle untereinander zu vergleichen, aber ist hier die Aussagekraft nicht so stark. Die Idee hinter dem Modellvergleich ist eher die *Anzahl an Spalten* zu verändern und nicht die Werte in der Datenmatrix. Deshalb machen wir es zwar, genießen die Sache aber mit Vorsicht.

## Genutzte R Pakete für das Kapitel

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, dlookr, broom, modelsummary,
               see, performance, ggpubr, factoextra, FactoMineR,
               conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("extract", "magrittr")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Daten

In diesem Beispiel betrachten wir wieder die Gummibärchendaten. Auch hier haben wir echte Daten vorliegen, so dass wir Ausreißer entdecken könnten. Da wir hier auch fehlende Werte in den Daten haben, können wir diese fehlenden Werte auch einfach imputieren und uns dann die Effekte anschauen. Das heißt wir haben also einen idealen Datensatz für unsere Sensitivitätsanalysen.

```{r}
#| message: false

gummi_tbl <- read_excel("data/gummibears.xlsx")  %>%
  select(gender, age, height, semester) %>% 
  mutate(gender = as_factor(gender)) 
```

In der @tbl-gummi-1 ist der Datensatz `gummi_tbl` nochmal für die ersten sieben Zeilen dargestellt. Wir werden später sehen, wie sich die Fallzahl von $n = `r nrow(gummi_tbl)`$ immer wieder ändert, je nachdem wie wir mit den fehlenden Daten und den Variablen umgehen.

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Auszug aus dem Datensatz `gummi_tbl`. Wir betrachten die ersten sieben Zeilen des Datensatzes."
#| label: tbl-gummi-sens-1

gummi_tbl %>% head(7) %>% kable(align = "c", "pipe")
```

## Das Modell

$$
height \sim gender + age + semester 
$$

Wir wollen jetzt als erstes das volle Modell schätzen

```{r}
#| message: false
#| warning: false
fit_full <- lm(height ~ gender + age + semester, data = gummi_tbl)

```

## Nach der Detektion von Ausreißer

Teilweise können wir eine Überprüfung auf Ausreißer nur auf einen Datensatz *ohne* fehlende Werte durchführen. Hier beißt sich dann die Katze in den Schwanz.

```{r}
#| message: false
#| warning: false
diagnose_outlier(gummi_tbl) 
```

```{r}
#| message: false
#| warning: false
gummi_out_imp_tbl <- gummi_tbl %>% 
  mutate(age = imputate_outlier(., age, method = "capping"),
         semester = imputate_outlier(., semester, method = "capping"))
```

```{r}
#| message: false
#| warning: false
fit_outlier <- lm(height ~ gender + age + semester, data = gummi_out_imp_tbl)
```

## Nach der Imputation von fehlenden Werten

```{r}
#| message: false
#| warning: false
gummi_imp_tbl <- gummi_tbl %>% 
  mutate(age = imputate_na(., age, method = "mean"),
         gender = imputate_na(., gender, method = "rpart"),
         height = imputate_na(., height, method = "median"),
         semester = imputate_na(., semester, method = "mode"))

```

```{r}
#| message: false
#| warning: false
fit_imp <- lm(height ~ gender + age + semester, data = gummi_imp_tbl)

```

## Nach der Variablen Selektion

Nehmen wir an, wir hätten eine Variablenselektion durchgeführt und die Variable `semester` aus dem Modell entfernt.

```{r}
#| message: false
#| warning: false
fit_var_select <- lm(height ~ gender + age, data = gummi_tbl)
```

## Modellvergleich

```{r}
#| message: false
#| echo: false
#| tbl-cap: "Auszug aus dem Datensatz `gummi_tbl`. Wir betrachten die ersten sieben Zeilen des Datensatzes."
#| label: tbl-gummi-model-sens

modelsummary(lst("Null Modell" = lm(height ~ 1, data = gummi_tbl),
                 "Volles Modell" = fit_full,
                 "Outlier" = fit_outlier,
                 "Imputation" = fit_imp,
                 "Variablen Selektion" = fit_var_select),
             estimate  = "{estimate}",
             statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}"))
```

```{r}
#| message: false
#| echo: false

compare_performance(fit_full, fit_outlier, fit_imp, fit_var_select,
                    rank = TRUE)
```
