<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Skript Bio Data Science - 54&nbsp; Decision trees</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./classification-svm.html" rel="next">
<link href="./classification-knn.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Decision trees</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Skript Bio Data Science</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Willkommen</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./organisation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Organisation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./literature.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literatur</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Einführung</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./example-preface.html" class="sidebar-item-text sidebar-link">Datenbeispiele</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-fleas-dogs-cats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Von Flöhen auf Hunden und Katzen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-fleas-dogs-cats-foxes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Von Flöhen auf Tieren</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-fleas-dogs-cats-foxes-site.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Von Flöhen auf Tieren in Habitaten</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-fleas-dogs-cats-length-weight.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Von vielen Flöhen auf Hunden und Katzen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-gummi-bears.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Von Gummibärchen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example-complex.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Von komplexeren Daten</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./programing-preface.html" class="sidebar-item-text sidebar-link">Programmieren in R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-letters-numbers.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Buchstaben und Zahlen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-basics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Operatoren, Funktionen und Pakete</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-import.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Daten einlesen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-dplyr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Daten bearbeiten</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./programing-purrr-furrr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mit <code>purrr</code> und <code>furrr</code></span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./eda-preface.html" class="sidebar-item-text sidebar-link">Explorative Datenanalyse</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-descriptive.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Deskriptive Statistik</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-ggplot.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Visualisierung von Daten</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-transform.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transformieren von Daten</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda-distribution.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Verteilung von Daten</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./stat-tests-preface.html" class="sidebar-item-text sidebar-link">Frequentistische Hypothesentests</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-basic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Die Testentscheidung</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-theorie.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Die Testtheorie</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-effect.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Der Effektschätzer</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Der t-Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Die ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-ancova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Die ANCOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-utest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Der Wilcoxon-Mann-Whitney-Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-kruskal.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Der Kruskal-Wallis-Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-friedman.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Friedman Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-chi-test.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Der <span class="math inline">\(\mathcal{X}^2\)</span>-Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-diagnostic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Der diagnostische Test</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-pretest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Pre-Tests oder Vortest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-tests-posthoc.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Multiple Vergleiche oder Post-hoc Tests</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./stat-linear-reg-preface.html" class="sidebar-item-text sidebar-link">Grundlagen der linearen Regression</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-basic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Simple lineare Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-quality.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Maßzahlen der Modelgüte</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-linear-reg-corr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Korrelation</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./stat-modeling-preface.html" class="sidebar-item-text sidebar-link">Statistisches Modellieren</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-basic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Multiple lineare Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-variable-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Variablenselektion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-outlier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Ausreißer</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-missing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Imputation fehlender Werte</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-sensitivity.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Sensitivitätsanalyse</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-gaussian.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Gaussian Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-poisson.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Poisson Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-multinom.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Multinomiale / Ordinale logistische Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-logistic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Logistische Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-mixed.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Lineare gemischte Modelle</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-gee.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Generalized Estimating Equations (GEE)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stat-modeling-non-linear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Nicht lineare Regression</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./experimental-design-preface.html" class="sidebar-item-text sidebar-link">Experimentelles Design</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-basic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Grundlagen der Versuchsplanung</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimental-design-samplesize.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Fallzahlplanung</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./classification-preface.html" class="sidebar-item-text sidebar-link">Klassifikation oder maschinelles Lernen</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-basic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Grundlagen der Klassifikation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Data splitting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-pre-processing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Data preprocessing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-model-compare.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Vergleich von Algorithmen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-knn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title"><span class="math inline">\(k\)</span> nearest neighbor</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-randomforest.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Decision trees</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-svm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Support vector machines</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classification-neural-networks.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Neural networks</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">Anhang</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-example-analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Beispielhafte Auswertungen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-r-tutorial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Tutorium in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-how-to-write.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Writing principles</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-bewertungsbogen.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Bewertungsbogen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./module.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Modulbeschreibung</span></a>
  </div>
</li>
    </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
<li><a href="#genutzte-r-pakete" id="toc-genutzte-r-pakete" class="nav-link active" data-scroll-target="#genutzte-r-pakete"> <span class="header-section-number">54.1</span> Genutzte R Pakete</a></li>
  <li><a href="#daten" id="toc-daten" class="nav-link" data-scroll-target="#daten"> <span class="header-section-number">54.2</span> Daten</a></li>
  <li><a href="#sec-rpart" id="toc-sec-rpart" class="nav-link" data-scroll-target="#sec-rpart"> <span class="header-section-number">54.3</span> Entscheidungsbaum mit Rpart</a></li>
  <li><a href="#sec-rf" id="toc-sec-rf" class="nav-link" data-scroll-target="#sec-rf"> <span class="header-section-number">54.4</span> Random Forest mit ranger</a></li>
  <li><a href="#sec-xgboost" id="toc-sec-xgboost" class="nav-link" data-scroll-target="#sec-xgboost"> <span class="header-section-number">54.5</span> Gradient boosting mit xgboost</a></li>
  <li><a href="#tuning" id="toc-tuning" class="nav-link" data-scroll-target="#tuning"> <span class="header-section-number">54.6</span> Tuning</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-class-tree" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Decision trees</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><div class="cell">

</div>
<p><em>Version vom December 08, 2022 um 17:55:34</em></p>
<p>In diesem Kapitel wollen wir uns mit Entscheidungsbäumen (eng. <em>decision trees</em>) beschäftigen. Wie oft gibt es auch bei der Anwendung von Entscheidungsbäumen eine Menge Varianten. Wir wollen uns in diesem Kapitel eine erste Übersicht geben und du kannst dann ja schauen, welche Varianten es noch von den Entscheidungsbäumen gibt. Wichtig ist zu wissen, unsere Bäume spalten sich immer nur in zwei Äste auf.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/angel_01.png" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>Wir werden uns hier mit der Anwendung beschäftigen. Wie immer lassen wir daher <em>tiefere</em> mathematische Überlegungen weg.</p>
</div></div><ul>
<li>In <a href="#sec-rpart"><span>Kapitel&nbsp;54.3</span></a> schauen wir uns <em>einen</em> Entscheidungsbaum an. Wir teilen nacheinander unsere Beobachtungen immer weiter anhand unser Prädiktoren in zwei Gruppen auf, bis wir nur noch Gruppen haben, die fast nur noch aus einer Klasse des Labels bestehen.</li>
<li>In <a href="#sec-rf"><span>Kapitel&nbsp;54.4</span></a> schauen wir uns ein Ensemble von Entscheidungsbäumen an. Wir lassen daher nicht einen sondern hunderte von Entscheidungsbäumen wachsen. Damit wir nicht immer den gleichen Baum auf den gleichen Daten wachsen lassen, wählen zufällig Beobachtungen und Variablen aus, die wir zum Erstellen der Bäume nutzen. Wir lassen einen Random Forest wachsen.</li>
<li>In <a href="#sec-xgboost"><span>Kapitel&nbsp;54.5</span></a> betrachten wir eine komplexere Implementierung der Random Forest. Wir nutzen hier Gradient Boosting um die Bäume noch besser anhand unseres Trainingsdatensatzes wachsen zu lassen.</li>
</ul>
<p>Alle drei Algorithmen gehen wir jetzt einmal durch. Dabei können wir bei einem Entscheidunsgbaum noch recht gut nachvollziehen, was dort eigentlich passiert. Bei mehreren Bäumen zusammen, können wir nur noch schematisch nachvollziehen was die einzelnen Schritte in der Modellbildung sind.</p>
<section id="genutzte-r-pakete" class="level2" data-number="54.1"><h2 data-number="54.1" class="anchored" data-anchor-id="genutzte-r-pakete">
<span class="header-section-number">54.1</span> Genutzte R Pakete</h2>
<p>Wir wollen folgende R Pakete in diesem Kapitel nutzen.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">tidymodels</span>, <span class="va">magrittr</span>, </span>
<span>               <span class="va">janitor</span>, <span class="va">vip</span>, <span class="va">rpart.plot</span>, <span class="va">see</span>,</span>
<span>               <span class="va">xgboost</span>, <span class="va">conflicted</span><span class="op">)</span></span>
<span><span class="fu">conflict_prefer</span><span class="op">(</span><span class="st">"select"</span>, <span class="st">"dplyr"</span><span class="op">)</span></span>
<span><span class="fu">conflict_prefer</span><span class="op">(</span><span class="st">"filter"</span>, <span class="st">"dplyr"</span><span class="op">)</span></span>
<span><span class="fu">conflict_prefer</span><span class="op">(</span><span class="st">"mutate"</span>, <span class="st">"dplyr"</span><span class="op">)</span></span>
<span><span class="fu">conflict_prefer</span><span class="op">(</span><span class="st">"extract"</span>, <span class="st">"magrittr"</span><span class="op">)</span></span>
<span><span class="co">##</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2025429</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.</p>
</section><section id="daten" class="level2 page-columns page-full" data-number="54.2"><h2 data-number="54.2" class="anchored" data-anchor-id="daten">
<span class="header-section-number">54.2</span> Daten</h2>
<p>Bei dem vorherigen Beispielen haben wir immer unseren Datensatz zu den infizierten Ferkeln genutzt. In diesem Kapitel wolle wir uns aber mal auf einen echten Datensatz anschauen. Wir nutzen daher einmal den Gummibärchendatensatz. Als unser Label und daher als unser Outcome nehmen wir das Geschlecht <code>gender</code>. Dabei wollen wir dann die weiblichen Studierenden vorhersagen. Im Weiteren nehmen wir nur die Spalte Geschlecht sowie als Prädiktoren die Spalten <code>most_liked</code>, <code>age</code>, <code>semester</code>, und <code>height</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tbl</span> <span class="op">&lt;-</span> <span class="fu">read_excel</span><span class="op">(</span><span class="st">"data/gummibears.xlsx"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>gender <span class="op">=</span> <span class="fu">as_factor</span><span class="op">(</span><span class="va">gender</span><span class="op">)</span>,</span>
<span>         most_liked <span class="op">=</span> <span class="fu">as_factor</span><span class="op">(</span><span class="va">most_liked</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">gender</span>, <span class="va">most_liked</span>, <span class="va">age</span>, <span class="va">semester</span>, <span class="va">height</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">drop_na</span><span class="op">(</span><span class="va">gender</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wir dürfen keine fehlenden Werte in den Daten haben. Wir können für die Prädiktoren später die fehlenden Werte imputieren. Aber wir können keine Labels imputieren. Daher entfernen wir alle Beobachtungen, die ein <code>NA</code> in der Variable <code>gender</code> haben. Wir haben dann insgesamt <span class="math inline">\(n = 473\)</span> Beobachtungen vorliegen. In <a href="#tbl-gummi-model-rf">Tabelle&nbsp;<span>54.1</span></a> sehen wir nochmal die Auswahl des Datensatzes in gekürzter Form.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-gummi-model-rf" class="anchored">
<table class="table table-sm table-striped">
<caption>Tabelle 54.1— Auszug aus dem Daten zu den Gummibärchendaten.</caption>
<thead><tr class="header">
<th style="text-align: center;">gender</th>
<th style="text-align: center;">most_liked</th>
<th style="text-align: center;">age</th>
<th style="text-align: center;">semester</th>
<th style="text-align: center;">height</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">lightred</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">193</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">yellow</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">159</td>
</tr>
<tr class="odd">
<td style="text-align: center;">w</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">159</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">180</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">180</td>
</tr>
<tr class="even">
<td style="text-align: center;">m</td>
<td style="text-align: center;">white</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">darkred</td>
<td style="text-align: center;">26</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">170</td>
</tr>
<tr class="odd">
<td style="text-align: center;">w</td>
<td style="text-align: center;">yellow</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">164</td>
</tr>
<tr class="even">
<td style="text-align: center;">w</td>
<td style="text-align: center;">darkred</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">165</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">orange</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">186</td>
</tr>
<tr class="even">
<td style="text-align: center;">m</td>
<td style="text-align: center;">green</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">193</td>
</tr>
<tr class="odd">
<td style="text-align: center;">m</td>
<td style="text-align: center;">lightred</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">194</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Unsere Fragestellung ist damit, können wir anhand unserer Prädiktoren männliche von weiblichen Studierenden unterscheiden und damit auch klassifizieren? Um die Klassifikation mit Entscheidungsbäumen rechnen zu können brauchen wir wie bei allen anderen Algorithmen auch einen Trainings- und Testdatensatz. Wir splitten dafür unsere Daten in einer 3 zu 4 Verhältnis in einen Traingsdatensatz sowie einen Testdatensatz auf. Der Traingsdatensatz ist dabei immer der größere Datensatz. Da wir aktuell nicht so viele Beobachtungen in dem Gummibärchendatensatz haben, möchte ich mindestens 100 Beobachtungen in den Testdaten. Deshalb kommt mir der 3:4 Split sehr entgegen.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="aside">Im maschinellen Lernen sind alle Datensätze, die weniger als tausend Beobachtungen vorliegen haben, klein.</span></div></div>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_data_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">gummi_tbl</span>, prop <span class="op">=</span> <span class="fl">3</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wir speichern uns jetzt den Trainings- und Testdatensatz jeweils separat ab. Die weiteren Modellschritte laufen alle auf dem Traingsdatensatz, wie nutzen dann erst ganz zum Schluss einmal den Testdatensatz um zu schauen, wie gut unsere trainiertes Modell auf den neuen Testdaten funktioniert.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_train_data</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">gummi_data_split</span><span class="op">)</span></span>
<span><span class="va">gummi_test_data</span>  <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">gummi_data_split</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nachdem wir die Daten vorbereitet haben, müssen wir noch das Rezept mit den Vorverabreitungsschritten definieren. Wir schreiben, dass wir das Geschlecht <code>gender</code> als unser Label haben wollen. Daneben nehmen wir alle anderen Spalten als Prädiktoren mit in unser Modell, das machen wir dann mit dem <code>.</code> Symbol. Da wir noch fehlende Werte in unseren Prädiktoren haben, imputieren wir noch die numerischen Variablen mit der Mittelwertsimputation und die nominalen fehlenden Werte mit Entscheidungsbäumen. Es gibt wie immer noch andere Imputationsmöglichkeiten, ich habe mich jetzt aus praktischen Gründen für dies beiden Verfahren entschieden. Ich überspringe hier auch die Diagnose der Imputation, also ob das jetzt eine gute und sinnvolle Imputation der fehlenden Werte war oder nicht. Die Diagnoseschritte müsstest du im Anwendungsfall nochmal im <a href="stat-modeling-missing.html">Kapitel zur Imputation</a> nachlesen und anwenden. Dann müssen wir noch alle numerischen Variablen normalisieren und alle nominalen Variablen dummykodieren. Am Ende werde ich nochmal alle Variablen entfernen, sollte die Varianz in einer Variable nahe der Null sein.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_rec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">gender</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">gummi_train_data</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">step_impute_mean</span><span class="op">(</span><span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">step_impute_bag</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">step_range</span><span class="op">(</span><span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">step_nzv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">gummi_rec</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor          4

Operations:

Mean imputation for all_numeric_predictors()
Bagged tree imputation for all_nominal_predictors()
Range scaling to [0,1] for all_numeric_predictors()
Dummy variables from all_nominal_predictors()
Sparse, unbalanced variable filter on all_predictors()</code></pre>
</div>
</div>
<p>Alles in allem haben wir ein sehr kleines Modell. Wir haben ja nur ein Outcome und vier Prädiktoren. Trotzdem sollte dieser Datensatz reichen um zu erklären wie Entscheidungsbäume funktionieren.</p>
</section><section id="sec-rpart" class="level2" data-number="54.3"><h2 data-number="54.3" class="anchored" data-anchor-id="sec-rpart">
<span class="header-section-number">54.3</span> Entscheidungsbaum mit Rpart</h2>
<p>Wie funktioniert nun ein Entscheidungsbaum? Ein Entscheidungsbaum besteht aus Knoten (eng. <em>nodes</em>) und Ästen (eng. <em>edge</em>). Dabei hat immer ein Knoten zwei Äste. Die Beobachtungen in einem Knoten fallen nach einer Entscheidungsregel anhand eines Prädiktors in entlang zweier Äste in zwei separate Knoten. So können wir unsere <span class="math inline">\(n = 473\)</span> zum Beispiel anhand des Alters in zwei Gruppen aufteilen. Wir legen willkürlich die Altersgrenze bei 22 fest.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tbl</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>grp <span class="op">=</span> <span class="fu">if_else</span><span class="op">(</span><span class="va">age</span> <span class="op">&gt;=</span> <span class="fl">22</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">grp</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">tabyl</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  .   n     percent valid_percent
  0 207 0.437632135    0.44420601
  1 259 0.547568710    0.55579399
 NA   7 0.014799154            NA</code></pre>
</div>
</div>
<p>Wir erhalten mit diesem Split zwei Gruppen mit je <span class="math inline">\(n_0 = 207\)</span> und <span class="math inline">\(n_1 = 259\)</span> Beobachtungen. Wir haben jetzt diesen Split willkürlich gewählt. In dem Algorithmus für die Entscheidungsbäume wird dieser Schritt intern optimiert, so dass wir den besten Wert für den Alterssplit finden, der uns möglichst reine Knoten im Bezug auf das Label liefert. Wir wollen ja am Ende einen Algorithmus trainieren, der uns die Geschlechter bestmöglich auftrennt, so dass wir eine neue Beobachtung bestmöglich vorhersagen können. Wenn keine Aufteilungen in einem Knoten mehr möglich sind, dann nennen wir diesen Knoten einen Terminalknoten.</p>
<p>In <a href="#fig-class-rf-01">Abbildung&nbsp;<span>54.5</span></a> sehen wir ein Beispiel für zwei numerische Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. Auf der linken Seite ist das Koordinatensystem mit dreizehn Beobachtungen dargestellt. Von den dreizehn Beobachtungen sind zehn Fälle (eng. <em>cases</em>) und drei Kontrollen (eng. <em>control</em>). Wir wollen uns jetzt an dem Koordinatensystem die Idee der Splits für ein Baumwachstum veranschaulichen. Auf der rechten Seite sehen wir nämlich den ersten Knoten des Entscheidungsbaums (eng. <em>root node</em>) in dem sich alle Beobachtungen befinden. Wir wollen jetzt die Beobachtungen anhand der Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> so aufspalten, dass für möglichst reine Knoten erhalten. Wir stoppen auch im Splitting wenn wir weniger oder gleich vier Beobachtungen nach einem Split in einem Knoten erhalten.</p>
<div id="fig-class-rf-01" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-rf-01.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.1— Darstellung des Anwachsen des Entscheidungsbaumes. Links sind die beiden Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> als Koordinatensysten dargestellt. Die Punkte stllen die Beobachtungen mit den jeweiligen Label weiß und schwarz dar. Rechts ist der Knoten <span class="math inline">\(t_1\)</span> dargestellt, der alle Beobachtungen beinhaltet..</figcaption><p></p>
</figure>
</div>
<p>In <a href="#fig-class-rf-02">Abbildung&nbsp;<span>54.6</span></a> sehen wir den ersten Split des Prädiktors <span class="math inline">\(X_1\)</span> anhand des Wertes <span class="math inline">\(c_1\)</span>. Wir erhalten nach dem Split die zwei neuen Knoten <span class="math inline">\(t_2\)</span> und <span class="math inline">\(t_3\)</span>. Wir haben den Split so gewählt, dass wir einen reinen Knoten <span class="math inline">\(t_3\)</span> erhalten. Da der Knoten <span class="math inline">\(t_3\)</span> jetzt nur noch Fälle enthaält, wird dieser Knoten zu einem Terminalknoten und es finden keine weiteren Aufspaltungen mehr statt. Wir machen jetzt also mit dem Knoten <span class="math inline">\(t_2\)</span> weiter.</p>
<div id="fig-class-rf-02" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-rf-02.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.2— Darstellung des ersten Splits anhand des Prädiktors <span class="math inline">\(X_1\)</span>. Wir wählen den Wert <span class="math inline">\(c_1\)</span> für den Split so, dass wir möglichst reine Knoten produzieren. Wir erhalten zwei neue Knoten <span class="math inline">\(t_2\)</span> und <span class="math inline">\(t_3\)</span>. Der Knoten <span class="math inline">\(t_3\)</span> ist maximal rein und wird daher zu einem Terminalknoten.</figcaption><p></p>
</figure>
</div>
<p>In <a href="#fig-class-rf-03">Abbildung&nbsp;<span>54.8</span></a> sehen wir den Split durch den Prädiktor <span class="math inline">\(X_2\)</span> nach dem Wert <span class="math inline">\(c_2\)</span>. Wir erhalten wieder zwei neue Knotenn <span class="math inline">\(t_4\)</span> und <span class="math inline">\(t_5\)</span>. Der Knoten <span class="math inline">\(t_4\)</span> wird nach unseren Regeln wieder zu einem Terminalknoten. Wir haben nur Fälle in dem Knoten <span class="math inline">\(t_4\)</span> vorliegen. Wir stoppen auch bei dem Knoten <span class="math inline">\(t_5\)</span> unsere weitere Aufteilung, da wir hier vier oder weniger Beobachtungen vorliegen haben. Damit sind wir mit dem Split zu einem Ende gekommen.</p>
<div id="fig-class-rf-03" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-rf-03.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.3— Darstellung des zweiten Splits anhand des Prädiktors <span class="math inline">\(X_2\)</span>. Wir wählen wiederum den Wert <span class="math inline">\(c_2\)</span> für den Split so, dass wir möglichst reine Knoten erhalten. So erhalten wir zwei neue Knoten <span class="math inline">\(t_4\)</span> und <span class="math inline">\(t_5\)</span>. Da nun <span class="math inline">\(t_4\)</span> ebenfalls ein reiner Knoten ist, wird der Knoten <span class="math inline">\(t_4\)</span> ebenfalls zu einem Terminalknoten. Wir stoppen hier das Wachstum, da mir eine mindest Anzahl von vier Beobachtungen in den Knoten erreicht haben.</figcaption><p></p>
</figure>
</div>
<p>In <a href="#fig-class-rf-04">Abbildung&nbsp;<span>54.12</span></a> sehen wir jetzt eine neue Beobachtung <code>?</code> die mit gegebenen Werten für <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span> in den terminalen Knoten <span class="math inline">\(t_5\)</span> fällt. Wir zählen dort die Fälle und erhalten eine Klassenzugehörigkeitswahrscheinlichkeit von 25%. Daher würden wir sagen, dass die neue Beobchtung eine Kontrolle ist. Es handelt sich damit um eine weiße Beoabchtung.</p>
<div id="fig-class-rf-04" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-rf-04.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.4— Darstellung der Vorhersage einer neuen Beobachtung mit Werten für die Prädiktoren <span class="math inline">\(X_1\)</span> und <span class="math inline">\(X_2\)</span>. Unsere neue Beobachtung <code>?</code> fällt in den Terminalknoten <span class="math inline">\(t_5\)</span>. Dort zählen wir die schwarzen Kreise. Wir stellen fest, dass die neue Beobachtung mit 25% Wahrscheinlichkeit ein Fall und damit schwarz ist. Daher ist die neue Beobachtung weiß.</figcaption><p></p>
</figure>
</div>
<p>Damit haben wir einmal den simplen Fall mit zwei numerischen Prädiktoren durchgespielt. Auch haben wir wenige Beobachtungen und sind schnell zu reinen Knoten gekommen. Wenn wir jetzt natürlich sehr viel mehr Beobachtungen haben oder sehr viele Prädiktoren dann wird die Sache sehr schnell sehr rechenintensiv. Dafür haben wir dann eben R.</p>
<p>Wenn wir in R einen Entscheidungsbaum rechnen wollen, dann nutzen wir die Funktion <code>decision_tree()</code> wir wollen nur eine maximale Tiefe von 5 Knoten haben und/oder mindestens 10 Beobachtungen in einem Knoten. Je nachdem welche Bedingung wir eher erreichen. Ebenfalls können wir das Wachstum mit dem Parameter <code>cost_complexity</code> kontrollieren. Sollte sich das Modell nicht um mindestens 0.001 verbessern, dann werden wir den nächsten Knoten nicht anlegen. Wir wählen als Engine den Algorithmus <code>rpart</code>, da wir uns diese Art von Algorithmus gut mit dem R Paket <code>rpart.plot</code> visualisieren können.</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_mod</span> <span class="op">&lt;-</span> <span class="fu">decision_tree</span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fl">5</span>, min_n <span class="op">=</span> <span class="fl">10</span>, cost_complexity <span class="op">=</span> <span class="fl">0.001</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"rpart"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Jetzt kommt wieder das Modell zusammen mit dem Rezept. Wir speichern wieder beides in einen Workflow.</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_wflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">rpart_mod</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">gummi_rec</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Den Workflow können wir dann mit dem Traingsdatensatz einmal durchlaufen lassen und uns das gefittete Modell wiedergeben lassen.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_fit</span> <span class="op">&lt;-</span> <span class="va">rpart_wflow</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">gummi_train_data</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nachdem wir das trainierte Modell vorliegen haben, nutzen wir die Funktion <code>augment()</code> um das Modell auf die Testdaten anzuwenden.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_aug</span> <span class="op">&lt;-</span> <span class="fu">augment</span><span class="op">(</span><span class="va">rpart_fit</span>, <span class="va">gummi_test_data</span> <span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Jetzt geht es los und wir schauen uns einmal an, wie gut die Klassifizierung mit dem Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_cm</span> <span class="op">&lt;-</span> <span class="va">rpart_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">conf_mat</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_class</span><span class="op">)</span></span>
<span></span>
<span><span class="va">rpart_cm</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 44 12
         w  8 55</code></pre>
</div>
</div>
<p>Das freut einen doch. Das sieht ziemlich gut aus. Wir haben auf der Diagonalen fast alle Beoabchtungen und nur sehr wenige falsche Vorhersagen auf der Nichtdiagonalen. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_cm</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.832
 2 kap                  binary         0.661
 3 sens                 binary         0.846
 4 spec                 binary         0.821
 5 ppv                  binary         0.786
 6 npv                  binary         0.873
 7 mcc                  binary         0.663
 8 j_index              binary         0.667
 9 bal_accuracy         binary         0.834
10 detection_prevalence binary         0.471
11 precision            binary         0.786
12 recall               binary         0.846
13 f_meas               binary         0.815</code></pre>
</div>
</div>
<p>Wir besprechen hier nicht alle, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 83% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">roc_curve</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_w</span>, event_level <span class="op">=</span> <span class="st">"second"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">autoplot</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-01" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-01-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.5— ROC Kurve für den Entscheidungsbaum mit dem <code>rpart</code> Algorithmus.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Es gibt viele Möglichkeiten sich einen Entscheidungsbaum anzuschauen. Wir nutzen hier das R Paket <code>rpart.plot</code> und die gleichnamige Funktion <code>rpart.plot()</code>. Die vielen Möglichkeiten der Darstellung und der Optionen findest in der Vignette <a href="http://127.0.0.1:52037/help/library/rpart.plot/doc/prp.pdf">Plotting rpart trees with the rpart.plot package.</a>. Wir gehen hier einmal auf die Variante <code>extra = 101</code> ein. Es gibt insgesamt elf verschiedene Arten plus eben noch die Möglichkeit 100 zu einer der elf genannten Varianten hinzufügen, um auch den Prozentsatz der Beobachtungen im Knoten anzuzeigen. Zum Beispiel zeigt <code>extra = 101</code> die Anzahl und den Prozentsatz der Beobachtungen in dem Knoten an.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rpart_fit</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">extract_fit_engine</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">rpart.plot</span><span class="op">(</span>roundint <span class="op">=</span> <span class="cn">FALSE</span>, extra <span class="op">=</span> <span class="fl">101</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-02" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-02-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.6— Visualisierung des finalen <code>rpart</code> Entscheidungsbaums.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-class-rf-02">Abbildung&nbsp;<span>54.6</span></a> sehen wir den finalen Entscheidungsbaum. Wir sehen, dass wir nicht weiter als fünf Splits nach unten gewandert sind. Das hatten wir ja auch mit dem Parameter <code>tree_depth</code> so eingestellt. Jetzt sehen wir aber auch, dass wir mit dem Preprocessing auch eine Grube graben können. Wir haben in unserem ersten Knoten 189 Männer und 165 Frauen. Daher hat der Knoten nach Mehrheitsentscheidung den Status <code>m</code>. Jetzt spalten wir den Knoten nach der Körpergröße von <span class="math inline">\(0.48\)</span> in zwei Gruppen. Was soll jetzt <span class="math inline">\(0.48\)</span> heißen? Keine Ahnung. Wir haben die Daten normalisiert. Wenn du hier die Werte für die Splits <em>interpretieren</em> willst, dann musst du auf den Orginaldaten rechnen. Nach dem Split sehen wir zwei Knoten, in denen zum einen die Männer domiern und zum anderen die Frauen. Wir splitten wieder nach der Körpergröße und erhalten immer reinere Knoten in den fast nur noch Männer oder Frauen sind.</p>
<p>Schaue dir auch die anderen Arten der Visualisierung in <code>rpart.plot</code> an und entscheide, ob dir die anderen Varianten bessere Informationen liefern, die zu deiner wissenschaftlichen Fragestellung passen.</p>
<p>An der Stelle trifft dann immer die Klassifikation auf die Interpretation. Du kannst nicht das Modell im Nachgang wieder entnormalisieren. Das geht nicht. Wenn du auf den Orginaldaten rechnest, dann wirst du ein anderes Modell erhalten. Das Modell mag besser oder schlechter sein, auf jeden Fall anders. Wie so oft hängt es von der wissenschaftlichen Fragestellung ab.</p>
</section><section id="sec-rf" class="level2" data-number="54.4"><h2 data-number="54.4" class="anchored" data-anchor-id="sec-rf">
<span class="header-section-number">54.4</span> Random Forest mit ranger</h2>
<p>Bis jetzt haben wir <em>einen</em> Entscheidungsbaum wachsen lassen. Was wäre, wenn wir statt einen Baum mehrere Bäume wachsen lassen. Wir lassen einen ganzen Wald (eng. <em>forest</em>) entstehen. Nun macht es wenig Sinn, immer den gleichen Baum auf immer den selben Daten wachsen zu lassen. Daher wählen wir zufällig eine Anzahl an Zeilen und Spalten aus bevor wir einen Baum in unserem Wald wachsen lassen. Dabei bringen wir zwei den Zufall in die Generierung eines Baums mit ein.</p>
<ol type="1">
<li>Durch die zufällige Auswahl der Beobachtungen mit Zurücklegen. Wir haben also einzelne Zeilen und damit Beobachtungen mehrfach in den Daten.</li>
<li>Durch die zufällige Auswahl eines Sets an Variablen. Wir nutzen nicht immer alle Variablen in unserem Modell sondern nur ein Set an Spalten.</li>
</ol>
<p>Im maschinellen Lernen nennen wir diese Methode <em>Bagging</em>. Das Wort <em>Bagging</em> steht für <em>bootstrap aggregating</em> und ist eine Methode, um Vorhersagen aus verschiedenen Modellen zu kombinieren. In unserem Fall sind es die verschiedenen Entscheidungsböume. Dabei müssen alle Modelle mit dem gleichen Algorithmus laufen, können aber auf verschiedenen Datensätzen oder aber Variablensätzen zugreifen. Häufig haben die Modelle eine hohe Varianz in der Vorhersage und wir nutzen dann Bagging um die Modelle miteinander zu kombinieren und dadurch die Varianz zu verringern. Die Ergebnisse der Modelle werden dann im einfachsten Fall gemittelt. Das Ergebnis jeder Modellvorhersage geht mit gleichem Gewicht in die Vorhersage ein. Wir haben auch noch andere Möglichkeiten, aber du kannst dir Vorstellen wir rechnen verschiedene Modelle <span class="math inline">\(j\)</span>-mal und bilden dann ein finales Modell in dem wir alle <span class="math inline">\(j\)</span>-Modelle zusammenfassen. Wie wir die Zusammenfassung rechnen, ist dann immer wieder von Fall zu Fall unterschiedlich. Wir erhalten am Ende einen <em>Ensemble</em> Klassifizierer, da ja ein Ensemble von Modellen zusammengefasst wird. In dem Fall von den Entscheidungsbäumen ist das Ensemble ein Wald an Bäumen.</p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Parallele CPU Nutzung
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Wenn wir wirklich viele Bäume wachsen lassen wollen, dann bietet sich die parallele Berechnung an. Das können wir über das R Paket <code>parallel</code> realisieren. Wir detektieren erstmal wie viele Kerne wir auf dem Rechner zu Verfügung haben.</p>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cores</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">cores</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8</code></pre>
</div>
</div>
<p>Wenn wir das gemacht haben, dann können wir in <code>set_engine("ranger", num.threads = cores)</code> auswählen, dass die Berechnung parallel verlaufen soll. Besonders auf Großrechnern macht die parallele Berechnung am meisten Sinn.</p>
</div>
</div>
</div>
<p>Auch hier ist es so, dass es verschiedene Algorithmen für den Random Forest gibt. Wir nehmen hier dann den <code>ranger</code> Algorithmus. Du kannst wie immer schauen, welche Algorithmen es noch gibt und auch wiederum verschiedene Algorithmen ausprobieren. In jedem Baum sollen drei Prädiktoren (<code>mtry = 3</code>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<code>min_n = 10</code>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<code>trees = 1000</code>). Darüber hinaus wollen wir uns auch die <em>Variable Importance</em> wiedergeben lassen. Die Variable Importance beschreibt, wie gut ein Prädiktor über alle Bäume des Waldes, in der Lage war Splits in möglichst reine Knoten durchzuführen. Ein Prädiktor mit einer hohen Variable Importance, ist also besonders geeignet für gute Splits mit hoher Reinheit.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_mod</span> <span class="op">&lt;-</span> <span class="fu">rand_forest</span><span class="op">(</span>mtry <span class="op">=</span> <span class="fl">3</span>, min_n <span class="op">=</span> <span class="fl">10</span>, trees <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"ranger"</span>, importance <span class="op">=</span> <span class="st">"impurity"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_wflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">ranger_mod</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">gummi_rec</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <code>fit()</code> unser Modell anpassen.</p>
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_fit</span> <span class="op">&lt;-</span> <span class="va">ranger_wflow</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">gummi_train_data</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In der <a href="#fig-class-rf-07">Abbildung&nbsp;<span>54.7</span></a> sehen wir dann die Variable Importance sortiert für alle Prädiktoren. Ganz wichtig, die Variable Importance ist nicht numerisch zu interpretieren und auch nicht über verschiedene Datensäze hinweg. Wir können nur die Variable Importance von einem Datensatz anschauen und dort sehen welche Variablen den meisten Einfluss haben. Wir sehen also, dass die Körpergröße eine sehr große Wichtigkeit hat um die Männer von den Frauen in den Gummibärchendaten zu trennen. Das macht auch Sinn. Frauen und Männer sind nun mal unterschiedlich groß. Nicht mehr so wichtig ist das Alter und das Semester. Beide Prädiktoren haben einen ehr geringeren Einfluss auf die Aufteilung der beiden Geschlechter. Der Lieblingsgeschmack tut bei der Einteilung in Männer und Frauen nichts zur Sache.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_fit</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">vip</span><span class="op">(</span>num_features <span class="op">=</span> <span class="fl">20</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-07" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-07-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.7— Visualisierung der <em>Variable Importance</em> aus unseren <code>ranger</code> Algorithmus.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser Modell auf den Testdatensatz anwenden und schauen, wie gut der Random Forest unsere Geschlechter vorhersagen kann.</p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_aug</span> <span class="op">&lt;-</span> <span class="fu">augment</span><span class="op">(</span><span class="va">ranger_fit</span>, <span class="va">gummi_test_data</span> <span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nun schauen wir uns an wie gut die Klassifizierung mit dem <code>ranger</code> Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_cm</span> <span class="op">&lt;-</span> <span class="va">ranger_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">conf_mat</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_class</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ranger_cm</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 45 12
         w  7 55</code></pre>
</div>
</div>
<p>Ja, das sieht ähnlich gut aus wie der <code>rpart</code> Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_cm</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.840
 2 kap                  binary         0.679
 3 sens                 binary         0.865
 4 spec                 binary         0.821
 5 ppv                  binary         0.789
 6 npv                  binary         0.887
 7 mcc                  binary         0.681
 8 j_index              binary         0.686
 9 bal_accuracy         binary         0.843
10 detection_prevalence binary         0.479
11 precision            binary         0.789
12 recall               binary         0.865
13 f_meas               binary         0.826</code></pre>
</div>
</div>
<p>Wir besprechen wie beim <code>rpart</code> Algorithmus nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 84% richtig klassifizierter Geschlechter. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt guter Wert.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. Damit sind wir mit dem Random Forest Algorithmus soweit durch und wir schauen uns jetzt einen etwas komplexeren xgboost Algorithmus an.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">roc_curve</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_w</span>, event_level <span class="op">=</span> <span class="st">"second"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">autoplot</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-03" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-03-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.8— ROC Kurve für den Random Forest mit dem <code>ranger</code> Algorithmus.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Kann ich auch eine Kreuzvalidierung und Tuning für Random Forest durchführen?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ja, kannst du. Wenn du <em>nur</em> eine Kreuzvalidierung durchführen willst, findest du alles im <a href="classification-knn.html"><span>Kapitel&nbsp;53</span></a> für den <span class="math inline">\(k\)</span>-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den Random Forest Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</p>
<p>Wenn du also den Random Forest Algorithmus auch tunen willst, dann schaue einfach weiter unten nochmal bei dem Tuning des xgboost Algorithmus rein. Es ändert sich kaum was für die Auwahl der <a href="https://parsnip.tidymodels.org/reference/details_rand_forest_ranger.html">Tuning Parameter vom Random Forest Algorithmus</a>.</p>
</div>
</div>
</section><section id="sec-xgboost" class="level2" data-number="54.5"><h2 data-number="54.5" class="anchored" data-anchor-id="sec-xgboost">
<span class="header-section-number">54.5</span> Gradient boosting mit xgboost</h2>
<p>Als letztes Beispiel für Entscheidungsbäume schauen wir uns das Boosting an. Auch hier haben wir es wieder mit einem Wald an Entscheidungsbäumen zu tun, die wir auch wieder zusammenfassen wollen. Wir verlassen uns also nicht auf die Klassifikation von einem Baum, sondern nehmen die Informationen von vielen Bäumen zusammen. Was ist jetzt der Unterschied zu einem Random Forest? Bei einem Random Forest bauen wir uns im Prinzip hunderte einzelne Bäume und trainieren darauf den Algorithmus. Am Ende fassen wir dann alle Bäume für die Vorhersage zusammen. Beim Boosting nutzen wir die Information des ersten Baumes für das Wachstum des zweiten Baumes und so weiter. Das Boosting verkettet also die Informationen der einzelnen Bäume zu einem kontinuierlichen Lernen. Daher sind Bossting Algorithmen meist sehr gute Klassifizierer.</p>
<p>Wir unterscheiden beim Boosting grob in zwei Kategorien. Zum einen gibt es das adaptive Boosting und das gradient Boosting. Beim adaptiven Boosting erhalten die Beobachtungen über die verschiedenen Klassifizierungsschritte unterschiedliche Gewichte für ihre Bedeutung. In <a href="#fig-class-adaboost">Abbildung&nbsp;<span>54.9</span></a> sehen wir ein Beispiel für den <code>adaboost</code> Algorithmus. Wir haben einen ursprünglichen Datensatz mit blauen und roten Beobachtungen. Wir wollen nun diese Beobachtungen voneinander trennen und damit einen Klassifizierer bauen. Wir fangen mit einem simplen Entscheidungsbaum an, der nur einen Split durchführt. Jetzt haben wir zwei falsch klassifizierte blaue Beobachtungen und eine falsche rote Beobachtung. Nun erhöhen wir das Gewicht dieser drei Beobachtungen. Der nächste Klassifizierer soll nun insbesondere auf diese drei Beobachtungen achten. Wir erhalten daher einen anderen Split und damit zwei blaue Beobachtungen die nicht richtig klassifiziert wurden. Wir erhöhen wieder das Gewicht der beiden falsch klassifizierten blauen Beobachtungen. Der dritte Klassifizierer schafft es jetzt die beiden blauen Beobachtungen gut von den roten Beobachtungen zu trennen. Wir stoppen jetzt hier und bringen alle Klassifiziererregeln, also wo der Split liegen soll, in einen Klassifizierer zusammen.</p>
<div id="fig-class-adaboost" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-xgboost.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.9— Darstellung von adaptive Boosting an drei Klassifizieren, die nacheinander auf die neu gewichteten Daten angewendet werden. Am Ende werden alle drei Klassifizierer dann in einen Klassifizierer kombiniert.</figcaption><p></p>
</figure>
</div>
<p>In der <a href="#fig-class-gradientboost">Abbildung&nbsp;<span>54.10</span></a> sehen wir die Idee des gradient Boosting einmal dargestellt. Die Idee ist recht simple. Wir wollen wieder nacheinander einen Klassifizierer auf schon klassifizierte Daten anwenden. Wir wollen also das unser zweiter Klassifizierer von dem ersten Klassifizier lernt. Wie machen wir das? Indem wir im ersten Schritt unsere Daten klassifizieren. Wir machen das mit einem Entscheidungsbaum, der mehrere Splits durchführt, die wir dann zu einer eckigen Graden zusammenfassen. Dann haben wir aber einen Fehler als Abstand zu den Splits oder eben zu der Graden. Diese Abstände übertragen wir dann in einen neuen Datensatz auf dem wir dann den nächsten Entscheidungsbaum wachsen lassen. Wir reduzieren also den Fehler des ersten Klassifizierers durch den zweiten Klassifizierer. Dann übertragen wir den Fehler des zweiten Klassifizierers in einen neuen Datensatz und lassen den dritten Klassifizierer den Fehler weiter reduzieren. Am Ende kombinieren wir alle drei Klassifizierer in ein Modell. Durch das gradient Boosting erhalten wir ziemlich gute Entscheidungsbäume, die in der Lage sind sehr schnell und effizient eine Vorhersage zu treffen.</p>
<div id="fig-class-gradientboost" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/class-xgboost-2.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.10— Darstellung von gradient Boosting an drei Klassifizieren, die nacheinander auf die <em>Fehler</em> des vorherigen Klassifizierers angewendet werden. Beachte die Nulllinie bei dem Klassifizierer zwei und drei.</figcaption><p></p>
</figure>
</div>
<p>Nach dieser theoretischen Einführung wollen wir uns einmal mit der Implementierung beschäftigen. Wir nutzen hier einmal die bekannten Parameter aus dem Random Forest Algorithmus um unseren <code>xgboost</code> Algorithmus zu trainieren. Wie wir gleich noch im Tuning sehen werden, hatr der <code>xgboost</code> Algorithmus noch mehr Parameter an denen du schrauben kannst. In jedem Baum sollen drei Prädiktoren (<code>mtry = 3</code>) und einer Anzahl von mindestens zehn Beobachtungen je Knoten (<code>min_n = 10</code>) und wir wollen insgesamt eintausend Bäume wachsen lassen (<code>trees = 1000</code>).</p>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_mod</span> <span class="op">&lt;-</span> <span class="fu">boost_tree</span><span class="op">(</span>mtry <span class="op">=</span> <span class="fl">3</span>, min_n <span class="op">=</span> <span class="fl">10</span>, trees <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"xgboost"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nun bauen wir uns wieder unseren Workflow indem wir das Modell mit dem Rezept für die Gummidatensatz verbinden. Das tolle ist jetzt, dass wir hier wieder des Rezept vom Anfang verwenden können. Wir müssen also nicht das Rezept neu definieren. Wir bauen uns also einfach nur einen neuen Workflow.</p>
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_wflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">xgboost_mod</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">gummi_rec</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wenn wir den Workflow haben, dann können wir wieder mit der Funktion <code>fit()</code> unser Modell anpassen. Es ist eine wahre Freude. Ich mache das ja jetzt auch schon hier eine Weile im Skript und es ist echt super, wie gut das funktioniert.</p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_fit</span> <span class="op">&lt;-</span> <span class="va">xgboost_wflow</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">gummi_train_data</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wie auch beim Random Forest Algorithmus können wir uns beim xgboost Algorithmus die Variable Importance wiedergeben lassen. Die Wichtigkeit der Variablen wird in xgboost anhand von drei verschiedenen <em>Wichtigkeiten</em> für eine Variable berechnet. Hier unterscheidet sich dann der Algorithmus xgboost von dem Random Forest Algorithmen. Achtung, wir können nicht einfach die Variable Importance von einem Random Forest Algorithmus mit der eines xgboost Algorithmus vergleichen. Wir kriegen hier andere Werte zurück, die wir dann auch anders interpretieren können.</p>
<ul>
<li>
<strong>Gain</strong> ist der relative Beitrag der entsprechenden Variable zum entgültigen Modell. Wir addieren dafür den Beitrag der Variable für die Splits für jeden Baum auf. Eine höhere Punktzahl deutet darauf hin, dass die Variable für die Vorhersage des Baums wichtiger ist. Die Variable war in der Lage die Klassen gut voneinander zu trennen.</li>
<li>
<strong>Cover</strong> ist die relative Beobachtung, die mit einem Prädiktor verbunden ist. Also der Anteil der Beobachtungen, die mit dieser Variable zusammenhängen. Nehmen wir an Merkmal <span class="math inline">\(X_1\)</span> wird dazu verwendet, um einen Terminalknoten für 10 Beobachtungen in einem Baum zu erschaffen. Im in einem weiteren Baum ist es ein Terminalkonten mit 20 Beobachtungen. Damit haben wir 30 absolute Beobachtungen, die mit Merkmal <span class="math inline">\(X_1\)</span> verbunden sind. Die relative Beobachtung ist dann 30 geteilt durch die Summe aller absoluten Beobachtungen für alle Merkmale.</li>
<li>
<strong>Häufigkeit</strong> bezieht sich auf die relative Häufigkeit, mit der eine Variable in den zusammengestellten Bäumen vorkommt. Nehmen wir an Merkmal <span class="math inline">\(X_1\)</span> kommt in Baum A in einem Split und in Baum B in zwei Splits vor. Die absolute Häufigkeit von Merkmal <span class="math inline">\(X_1\)</span> ist 3 und die relative Häufigkeit ist dann 3 durch die Summe aller absoluten Vorkommen für alle Merkmale.</li>
</ul>
<p>Schauen wir uns also einmal die Kriterien der Variable Importance für unsere Gummibärchendaten einmal an. Gehen wir mal die Parameter <code>gain</code>, <code>cover</code> und <code>frequency</code> einmal für unsere Körpergröße durch. Zuerst hat die Körpergröße den höchsten Wert in <code>gain</code> mit <span class="math inline">\(0.84\)</span>. Da wir das Gain auf 1 skaliert haben, macht die Körpergröße 84% des gesamten Gain in dem Modell aus. Daher wissen wir, dass die Körpergröße einen überaus bedeutenden Anteil an der Vorhersage des Geschlechts hat. Im Weiteren sehen wir an dem Parameter <code>cover</code>, dass in 34% der Beobachtungen ein Split mit der Körpergröße <em>vorausgeht</em>. Das heißt, 34% der Beobachtungen wurden anhand der Körpergröße aufgeteilt. Da wir nicht wissen wie viele Splits es ingesamt gab, muss man dieses Wert immer etwas vorsichtig bewerten. Die <code>frequency</code> teilt uns mit, dass in 33% der der Splits auch die Körpergröße vor kam. Wir sehen, die Körpergröße ist wichtig für die Vorhersage des Geschlechts. Wenn Variablen fehlen, dann haben diese keinen Einfluss auf die Klassifikation gehabt.</p>
<div class="cell">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xg_imp</span> <span class="op">&lt;-</span> <span class="va">xgboost_fit</span> <span class="op">%&gt;%</span> </span>
<span><span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span> <span class="op">%$%</span> </span>
<span>  <span class="fu">xgboost</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.importance.html">xgb.importance</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">fit</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span><span class="fu">across</span><span class="op">(</span><span class="fu">where</span><span class="op">(</span><span class="va">is.numeric</span><span class="op">)</span>, <span class="va">round</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">xg_imp</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              Feature Gain Cover Frequency
1:             height 0.84  0.34      0.33
2:                age 0.07  0.19      0.19
3:           semester 0.06  0.29      0.31
4: most_liked_darkred 0.02  0.12      0.13
5:   most_liked_green 0.01  0.05      0.05
6:   most_liked_white 0.00  0.00      0.00</code></pre>
</div>
</div>
<p>In der <a href="#fig-class-rf-08">Abbildung&nbsp;<span>54.11</span></a> sehen wir dann die Variable Importance sortiert für alle Prädiktoren und eingeteilt in Cluster. Die Funktion <code>xgb.ggplot.importance()</code> versucht ähnlich bedeutende Prädiktoren in gleiche Cluster zuzuordnen.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xg_imp</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">xgb.ggplot.importance</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_fill_okabeito</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-08" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-08-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.11— Visualisierung der <em>Variable Importance</em> aus unseren <code>xgboost</code> Algorithmus. Wir sehen, dass sich grob drei Gruppen für Bedeutung der Variablen für die Klassifikation gebildet haben.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Nach unserem kleinen Ausflug zu der Variable Importance können wir jetzt wieder unser xgboost Modell auf den Testdatensatz anwenden und schauen, wie gut das gradient Boosting unsere Geschlechter vorhersagen kann.</p>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_aug</span> <span class="op">&lt;-</span> <span class="fu">augment</span><span class="op">(</span><span class="va">xgboost_fit</span>, <span class="va">gummi_test_data</span> <span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nun schauen wir uns an wie gut die Klassifizierung mit dem xgboost Modell funktioniert hat. Als erstes bauen wir uns einmal die <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Konfusionsmatrix</a> um zu sehen wie gut die beiden Geschlechter in dem Testdatensatz vorhergesagt wurden.</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_cm</span> <span class="op">&lt;-</span> <span class="va">xgboost_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">conf_mat</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_class</span><span class="op">)</span></span>
<span></span>
<span><span class="va">xgboost_cm</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Truth
Prediction  m  w
         m 48 13
         w  4 54</code></pre>
</div>
</div>
<p>Ja, das sieht ähnlich gut aus wie der Random Forest Algorithmus. Wir haben eine gute Aufspaltung nach dem Geschlechtern. Viele der Beobachtungen liegen auf der Diagonalen und nur wenige Beobachtungen wurden falsch klassifiziert. Jetzt können wir uns noch eine ganze Reihe an anderen Gütekriterien für den <a href="classification-model-compare.html">Vergleich von Modellen</a> ausgeben lassen.</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_cm</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   .metric              .estimator .estimate
   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
 1 accuracy             binary         0.857
 2 kap                  binary         0.715
 3 sens                 binary         0.923
 4 spec                 binary         0.806
 5 ppv                  binary         0.787
 6 npv                  binary         0.931
 7 mcc                  binary         0.723
 8 j_index              binary         0.729
 9 bal_accuracy         binary         0.865
10 detection_prevalence binary         0.513
11 precision            binary         0.787
12 recall               binary         0.923
13 f_meas               binary         0.850</code></pre>
</div>
</div>
<p>Wier vorher schon besprechen wir nicht alle Kriterien, du kannst dann gerne nochmal in dem Kapitel über die Modellvergleiche nachlesen, was die ganze Gütekriterien alles bedeuten. Wenn wir uns auf die Accuarcy konzentrieren, erhalten wir einen guten Wert von 86% richtig klassifizierter Geschlechter. Besonders die Sensitivität ist mit 92% sehr gut. Die Sensitivität gibt ja an, wie zuverlässig unser xgboost Algorithmus erkennt, ob man eine Frau ist. Die Spezifität ist etwas niedriger, also die Fähigkeit die Männer auch als Männer zu erkennen. Das ist für echte Daten ohne Tuning und Kreuzvaldierung schon ein echt sehr guter Wert. Da sind wir noch besser als beim Random Forest.</p>
<p>Nun schauen wir uns noch schnell die ROC Kurve an und sehen, dass die Kurve schon weit von der Diagonalen entfernt ist. Wir sehen eine gute ROC Kurve. Die AUC sollte auch recht groß sein. In den folgenden Schritten wollen wir einmal den xgboost Algorithmus tunen und schauen, ob wir noch bessere Ergebnisse für die Klassifikation mit anderen Parametern für den Algorithmus hin bekommen.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">xgboost_aug</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">roc_curve</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_w</span>, event_level <span class="op">=</span> <span class="st">"second"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">autoplot</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-04" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-04-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.12— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Kann ich auch eine Kreuzvalidierung für xgboost durchführen?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ja, kannst du. Wenn du <em>nur</em> eine Kreuzvalidierung durchführen willst, findest du alles im <a href="classification-knn.html"><span>Kapitel&nbsp;53</span></a> für den <span class="math inline">\(k\)</span>-NN Algorithmus. Du musst dort nur den Workflow ändern und schon kannst du alles auch auf den xgboost Algorithmus anwenden. Wir nutzen gleich die Kreuzvalidierung in Kombination mit dem Tuning vom xgboost Algorithmus.</p>
</div>
</div>
</section><section id="tuning" class="level2" data-number="54.6"><h2 data-number="54.6" class="anchored" data-anchor-id="tuning">
<span class="header-section-number">54.6</span> Tuning</h2>
<p>Was heißt Tuning? Wie bei einem Auto können wir an verschiedenen Stellschrauben bei einem mathematischen Algorithmus schrauben. Welche Schrauben und Teile das sind, hängt dann wieder vom Algorithmus ab. Im Falle des xgboost Algorithmus können wir an folgenden Parametern drehen und jeweils schauen, was dann mit unserer Vorhersage passiert. Insgesamt hat der <a href="https://parsnip.tidymodels.org/reference/details_boost_tree_xgboost.html">xgboost Algorithmus acht Tuningparameter</a>, wir wählen jetzt für uns hier drei aus. Ich nehme hier auch nur drei Parameter, da sich dann drei Parameter noch sehr gut visuell darstellen lassen. In der Anwendung wäre dann natürlich besser alle Parameter zu tunen, aber das dauert dann auch lange.</p>
<ul>
<li>
<code>mtry</code>, zufällig ausgewählte Anzahl an Variablen für jeden Baum. Das heißt, für jeden Baum werden von unseren Variablen die Anzahl <code>mtry</code> zufällig ausgewählt und auf diesem kleineren Datensatz der Baum erstellt.</li>
<li>
<code>min_n</code>, kleinste Knotengröße, die noch akzeptiert wird. Wenn ein Knoten unter <code>min_n</code> fällt, dann endet hier das Wachstum des Baumes.</li>
<li>
<code>trees</code>, Anzahl der Bäume die in einem xgboost Algorithmus erstellt werden.</li>
</ul>
<p>Nun ist es so, dass wir natürlich nicht händisch alle möglichen Kombinationen von der Anzahl der ausgewählten Variablen pro Baum, der kleinsten Knotengröße und der Anzahl der Bäume berechnen wollen. Das sind ziemlich viele Kombinationen und wir kommen dann vermutlich schnell durcheinander. Deshalb gibt es die Funktion <code>tune()</code> aus dem R Paket <code>tune</code>, die uns einen Prozess anbietet, das Tuning automatisiert durchzuführen.</p>
<p>Als erstes müssen wir uns ein Objekt bauen, das aussieht wie ein ganz normales Modell in der Klassifikation. Aber wir ergänzen jetzt noch hinter jeder zu tunenden Option noch die Funktion <code>tune()</code>. Das sind die Parameter des Algorithmus, die wir später tunen wollen.</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tune_spec</span> <span class="op">&lt;-</span>  <span class="fu">boost_tree</span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, </span>
<span>                         min_n <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, </span>
<span>                         trees <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"xgboost"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tune_spec</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = tune()
  min_n = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<p>Jetzt bauen wir uns den Workflow indem wir statt unserem Modell, die Tuninganweisung in den Workflow reinnehmen. Echt simpel und straightforward. Das Rezept bleibt ja das Gleiche.</p>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tune_wflow</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">tune_spec</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">gummi_rec</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Jetzt müssen wir noch alle Kombinationen aus den drei Parametern <code>mtry</code>, <code>min_n</code> und <code>trees</code> ermitteln. Das macht die Funktion <code>grid_regular()</code>. Es gibt da noch andere Funktionen in dem R Paket <code>tune</code>, aber ich konzentriere mich hier auf die einfachste. Jetzt müssen wir noch die Anzahl an Kombinationen festlegen. Ich möchte für jeden Parameter fünf Werte tunen. Daher nutze ich hier die Option <code>levels = 5</code> auch damit hier die Ausführung nicht so lange läuft. Fange am besten mit <code>levels = 5</code> an und schaue, wie lange das zusammen mit der Kreuzvalidierung dann dauert. Dann kannst du die Levels noch hochschrauben. Beachte aber, dass mehr Level nur mehr <em>Zwischenschritte</em> bedeutet. Jede Option hat eine Spannweite <code>range</code>, die du dann anpassen musst, wenn du <em>höhere</em> Werte haben willst. Mehr Level würden nur mehr Zwischenschritte bedeuten. In unserem Fall weiß zum Beispiel die Funktion <code>mtry()</code> nicht, wie viele Variablen in dem Datensatz sind. Wir müssen also die <code>range</code> für die Anzahl an ausgewählten Variablen selber setzen. Ich wähle daher eine Variable bis vier Variablen.</p>
<div class="cell">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_grid</span> <span class="op">&lt;-</span> <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">mtry</span><span class="op">(</span>range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                           <span class="fu">trees</span><span class="op">(</span><span class="op">)</span>,</span>
<span>                           <span class="fu">min_n</span><span class="op">(</span><span class="op">)</span>,</span>
<span>                           levels <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Das Tuning nur auf dem Trainingsdatensatz durchzuführen ist nicht so eine gute Idee. Deshalb nutzen wir hier auch die Kreuzvalidierung. Eigentlich ist eine 10-fache Kreuzvalidierung mit <span class="math inline">\(v=10\)</span> besser. Das dauert mir dann aber hier im Skript viel zu lange. Deshalb habe ich hier nur <span class="math inline">\(v=5\)</span> gewählt. Wenn du das Tuning rechnest, nimmst du natürlich eine 10-fach Kreuzvalidierung.</p>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">gummi_train_data</span>, v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nun bringen wir den Workflow zusammen mit dem Tuninggrid und unseren Sets der Kreuzvaidierung. Daher pipen wir den Workflow in die Funktion <code>tune_grid()</code>. Als Optionen brauchen wir die Kreuzvaldierungsdatensätze und das Tuninggrid. Wenn du <code>control_grid(verbose = TRUE)</code> wählst, dann erhälst du eine Ausgabe wie weit das Tuning gerade ist. <strong>Achtung!</strong>, das Tuning dauert seine Zeit. Im Falle des xgboost Algorithmus dauert das Tuning zwar nicht so lange, aber immer noch ein paar Minuten. Wenn du dann alle acht Parameter des xgboost Algorithmustunen wollen würdest, dann würde die Berechnung sehr viel länger dauern. Du kannst das Ergebnis des simpleren Tunings auch in der Datei <code>gummi_xgboost_tune_res.rds</code> finden.</p>
<div class="cell">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tune_res</span> <span class="op">&lt;-</span> <span class="va">gummi_tune_wflow</span> <span class="op">%&gt;%</span> </span>
<span>   <span class="fu">tune_grid</span><span class="op">(</span>resamples <span class="op">=</span> <span class="va">gummi_folds</span>,</span>
<span>             grid <span class="op">=</span> <span class="va">gummi_grid</span>,</span>
<span>             control <span class="op">=</span> <span class="fu">control_grid</span><span class="op">(</span>verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>Damit du nicht das Tuning durchlaufen lassen musst, habe ich das Tuning in die Datei <code>gummi_xgboost_tune_res.rds</code> abgespeichert und du kannst dann über die Funktion <code>read_rds()</code> wieder einlesen. Dann kannst du den R Code hier wieder weiter ausführen.</p>
<div class="cell">

</div>
<p>Nachdem das Tuning durchgelaufen ist, können wir uns über die Funktion <code>collect_metrics()</code>, die Ergebnisse des Tunings für jede Kombination der drei Parameter <code>mtry</code>, <code>min_n</code> und <code>trees</code> wiedergeben lassen. Diese Ausgabe ist super unübersichtlich. Ich habe mich ja am Anfange des Abschnitts auch für drei Tuningparameter entschieden, da sich dann diese drei Parameter noch gut visualisieren lassen. Deshalb einmal die Abbildung der mittleren Accuarcy und der mittleren AUC-Werte über alle Kreuzvalidierungen.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tune_res</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">as_factor</span><span class="op">(</span><span class="va">trees</span><span class="op">)</span>,</span>
<span>         min_n <span class="op">=</span> <span class="fu">as_factor</span><span class="op">(</span><span class="va">min_n</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">mtry</span>, <span class="va">mean</span>, color <span class="op">=</span> <span class="va">min_n</span>, linetype <span class="op">=</span> <span class="va">trees</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">.metric</span>, scales <span class="op">=</span> <span class="st">"free"</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_log10</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_number.html">label_number</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_okabeito</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-05" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-05-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.13— Tuning Kurven für den <code>xgboost</code> Algorithmus.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Damit wir nicht händisch uns die beste Kombination raussuchen müssen, können wir die Funktion <code>show_best()</code> nutzen. Wir wählen hier die beste Accuarcy und erhalten dann die sortierten Ergebnisse nach der Accuarcy des Tunings.</p>
<div class="cell">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gummi_tune_res</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">show_best</span><span class="op">(</span><span class="st">"accuracy"</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 9
   mtry trees min_n .metric  .estimator  mean     n std_err .config             
  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1     2  1000    11 accuracy binary     0.839     5  0.0105 Preprocessor1_Model…
2     2  1500    11 accuracy binary     0.839     5  0.0105 Preprocessor1_Model…
3     2  2000    11 accuracy binary     0.839     5  0.0105 Preprocessor1_Model…
4     4   500    11 accuracy binary     0.839     5  0.0138 Preprocessor1_Model…
5     4  1000    11 accuracy binary     0.839     5  0.0138 Preprocessor1_Model…</code></pre>
</div>
</div>
<p>Das war die Funktion <code>show_best()</code> aber wir können uns auch die gleich die besten Parameter nach der Accuracy raus ziehen. Das Rausziehen der besten Parameter macht für uns die Funktion <code>select_best()</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">best_xgboost</span> <span class="op">&lt;-</span> <span class="va">gummi_tune_res</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select_best</span><span class="op">(</span><span class="st">"accuracy"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">best_xgboost</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
   mtry trees min_n .config               
  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 
1     2  1000    11 Preprocessor1_Model033</code></pre>
</div>
</div>
<p>Wir sehen, dass wir <code>mtry = 3</code> wählen sollten. Dann müssen wir als Anzahl der Bäume <code>trees = 1000</code> nutzen. Die minimale Anzahl an Beobachtungen pro Knoten ist dann <code>11</code>. Müssen wir jetzt die Zahlen wieder in ein Modell eingeben? Nein, müssen wir nicht. Mit der Funktion <code>finalize_workflow()</code> können wir dann die besten Parameter aus unserem Tuning gleich mit dem Workflow kombinieren. Dann haben wir unseren finalen, getunten Workflow. Du siehst dann auch in der Ausgabe, dass die neuen Parameter in dem xgboost Algorithmus übernommen wurden.</p>
<div class="cell">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">final_gummi_wf</span> <span class="op">&lt;-</span> <span class="va">gummi_tune_wflow</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">best_xgboost</span><span class="op">)</span></span>
<span></span>
<span><span class="va">final_gummi_wf</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow ════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: boost_tree()

── Preprocessor ────────────────────────────────────────────────────────────────
5 Recipe Steps

• step_impute_mean()
• step_impute_bag()
• step_range()
• step_dummy()
• step_nzv()

── Model ───────────────────────────────────────────────────────────────────────
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 2
  trees = 1000
  min_n = 11

Computational engine: xgboost </code></pre>
</div>
</div>
<p>Jetzt bleibt uns nur noch der letzte Fit übrig. Wir wollen unseren finalen, getunten Workflow auf die Testdaten anwenden. Dafür gibt es dann auch die passende Funktion. Das macht für uns die Funktion <code>last_fit()</code>, die sich dann die Informationen für die Trainings- und Testdaten aus unserem Datensplit von ganz am Anfang extrahiert.</p>
<div class="cell">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">final_fit</span> <span class="op">&lt;-</span> <span class="va">final_gummi_wf</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">last_fit</span><span class="op">(</span><span class="va">gummi_data_split</span><span class="op">)</span> </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Da wir immer noch eine Kreuzvaldierung rechnen, müssen wir dann natürlich wieder alle Informationen über alle Kreuzvaldierungsdatensätze einsammeln. Dann erhalten wir unsere beiden Gütekriterien für die Klassifikation des Geschlechts unser Studierenden nach dem xgboost Algorithmus. Die Zahlen sind schon gut für echte Daten. Eine Accuracy von 84% bedeutet das wir über acht von zehn Studierenden richtig klassifizieren. Die AUC ist auch schon fast hervorragend, wir bringen kaum Label durcheinander.</p>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">final_fit</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.840 Preprocessor1_Model1
2 roc_auc  binary         0.902 Preprocessor1_Model1</code></pre>
</div>
</div>
<p>Dann bleibt uns nur noch die ROC Kurve zu visualisieren. Da wir wieder etwas faul sind, nutzen wir die Funktion <code>autoplot()</code>. Als Alternative geht natürlich auch das <a href="https://web.expasy.org/pROC/screenshots.html">R Paket <code>pROC</code></a>, was eine Menge mehr Funktionen und Möglichkeiten bietet.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">final_fit</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">collect_predictions</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">roc_curve</span><span class="op">(</span><span class="va">gender</span>, <span class="va">.pred_w</span>, event_level <span class="op">=</span> <span class="st">"second"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">autoplot</span><span class="op">(</span><span class="op">)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-class-rf-06" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="classification-randomforest_files/figure-html/fig-class-rf-06-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Abbildung 54.14— ROC Kurve für den Entscheidungsbaum mit dem <code>xgboost</code> Algorithmus nach der Kreuvalidierung und dem Tuning.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Eine gute ROC Kurve würde senkrecht nach oben gehen und dann waagrecht nach rechts. Dann hätten wir eine AUC von 1 und eine perfekte Separation der beiden Label durch unseren Algorithmus. Unser Algorithmus würde jedem weiblichen Studierenden in dem Testdatensatz korrekt dem Geschlecht <code>w</code> zuweisen. Da wir eine ROC Kurve hier vorliegen haben, die sehr weit weg von der Diagonalen ist, haben wir sehr viele richtig vorhergesagte Studierende in unseren Testdaten. Unser Modell funktioniert um das Geschlecht von Studierenden anhand unserer Gummibärchendaten vorherzusagen.</p>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./classification-knn.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title"><span class="math inline">\(k\)</span> nearest neighbor</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./classification-svm.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Support vector machines</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>