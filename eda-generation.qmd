```{r echo = FALSE}
#| warning: false
#| message: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, see, modelr, ggforce,
               latex2exp, patchwork, parsnip, ggdag, ggimage, ggpmisc,
               conflicted)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
conflicts_prefer(dplyr::filter)
conflicts_prefer(ggplot2::annotate)
set.seed(20250701)
theme_modeling <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(size = 12, face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

```{r}
#| eval: true
#| echo: false
#| cache: true
#| message: false
#| warning: false
#| label: sim-mean-samplesize
source("simulation/sim-gen-data-mean.R")
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-modeling-R.R")
source("images/R/eda-generation.R")
```

# Generierung von Daten {#sec-eda-gen-data}

*Letzte Änderung am `r format(fs::file_info("eda-generation.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Je größer die Insel des Wissens, desto größer der Strand der Verzweiflung." --- unbekannt*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion

Dieses Kapitel wird in den nächsten Monaten geschrieben und ist damit eine zukünftige Großbaustelle. Ich plane zum Beginn des SoSe 2026 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

In diesem Kapitel geht es um die Erstellung von zufälligen Daten. Oder anderherum, wir wollen uns künstliche Daten (eng. *artificial data* oder eng. *synthetic data*) generieren. Warum machen wir das? Eine Frage, die sich vermutlich kein Statistiker oder Date Scientist stellen würde, ist es doch Teil der wissenschaftlichen Arbeit simulierte Daten zu erstellen. Auf diesen simulierten Daten werden dann die neuen entwickelten Algorithmen getestet. Für Menschen außerhalb der Data Science mag es seltsam erscheinen, dass wir uns einfach Daten erschaffen können. Diese synthetischen Daten kommen dann aber den biologischen Daten manchmal recht Nahe. Daher kannst auch du dir deine Daten theoretisch einfach selber bauen, nachdem du dieses Kapitel gelesen hast.

::: callout-warning
## Achtung, bitte beachten!

> *"With great power comes great responsibility." --- Uncle Ben to Peter Parker in Spiderman*

Keine Daten für die Abschlussarbeit erschaffen. Auch wenn die Daten mal nicht so passen, wie du dir das aus einem Experiment erhofft hast, ist es nicht erlaubt sich einfach die Daten selber zu simulieren. Simulierte Daten haben keinen wissenschaftlichen Wert abseits der Validierung von neuen Algorithmen.

Was du aber machen *kannst*, ist deine experimentellen Daten schon mal im Design vorbauen um deine Analyse in R vorzurechnen. Wenn du dann aus deinem Experiment die echten Daten vorliegen hast, kannst du dann schneller die Analysen rechnen. Du hast dann ja schon alles einmal geübt und vorgearbeitet.
:::

Daher nutzen wir diesen Kapitel auch anders. Wir erschaffen uns ja Daten um Algorithmen zu verstehen. Wenn wir wissen wie die Daten aufgebaut sind, dann können wir auch besser verstehen was uns ein Modell oder ein statistischer Test wiedergibt. Dafür brauchen wir dann die synthetischen Daten. Eine andere Möglichkeit ist, dass du einmal ausprobieren möchtest, wie eine potenzielle Analyse ablaufen würde. Dann macht es auch Sinn einmal über künstliche Daten nachzudenken. Ich komme dann immer mal wieder auf dieses Kapitel zurück, wenn ich in anderen Kapiteln mal künstliche Daten brauche. Wir schauen uns verschiedene Wege künstliche Daten zu erschaffen einmal an und es geht auch in Excel relativ einfach.

## Allgemeiner Hintergrund

> *"We test our framework both on synthetic data, as the only source of ground truth on which we can objectively assess the performance of our algorithms, as well as on real data to demonstrate its real-world practicability." --- @jackson2009intelligent*

Wenn wir Daten generieren wollen, dann müssen wir auch wissen, was wir genieren wollen. Dafür müssen wir dann verstehen, wovon wir sprechen. Da wir es bei der Datengenerierung auch immer mit statistischen Modellen zu tun haben, müssen wir auch die Fachsprache der statistischen Modellierung nutzen. Dann wollen wir verstehen, was wir eigentlich simulieren. Klar, wir simulieren Daten, aber was brauchen wir dafür an statistischen Maßzahlen? Ich betrachte dann nochmal die Einschränkungen dieses Kapitels, denn wir können natürlich hier nicht alles simulieren, was möglich ist. Faktisch konzentrieren wir uns hier auf häufige Datenstrukturen in den Agrawissenschaften. Dann zeige stelle ich dir nochmal kurz die zwei R Pakete vor, die wir dann hier nutzen können.

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use independent variable because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Jeder nennt in der Statistik sein Y und X wie er möchte. Da ich hier nicht nur von Y und X schreiben will, führe ich eben die Worte ein, die ich nutzen will. Damit sind die Worte dann auch richtig, da der Kontext definiert ist. Andere mögen es dann anders machen. Ich mache es eben dann so. Danke." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Modellieren als Grundlage für die Generierung von Daten. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren. Du kannst dann immer zu dem Kasten zurückgehen, wenn wir mal ein Wort nicht mehr ganz klar ist. Die fetten Begriffe sind die üblichen in den folgenden Kapiteln. Die anderen Worte werden immer mal wieder in der Literatur genutzt.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

#### Effekt, Streuung und Fallzahl {.unnumbered .unlisted}

Was brauchen wir um Daten zu generieren? Wir brauchen einen Effekt, eine Streuung der generierten Date um den Mittelwert sowie die Fallzahl als Anzahl an Beobachtungen. Dann müssen wir noch entscheiden aus welcher Verteilung unsere Daten kommen sollen. In dem folgenden Venndiagramm habe ich dir nochmal den Dreiklang der drei statistischen Eigeschaften für die Generierung von Daten zusammengefasst. Wir müssen uns also klar werden, welchen Effekt wir simulieren wollen, welche Streuung in den Daten vorliegen soll und natürlich wie viele Beobachtungen wir in den generierten Daten vorfinden wollen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 6
#| fig-width: 7
#| fig-cap: "Was wird benötigt um Daten zu generieren? Der Effekt beschreibt den Unterschied zwischen Gruppen oder spezieller den Mittelwert in einer Normalverteilung. Die Streuung beschreibt die Unsicherheit in den Daten oder eben die Standardabweichung. Über die Fallzahl wird definiert wie viele Beobachtungen erstellt werden sollen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-venn

p_venn_gen
```

Wir machen wir das jetzt praktisch in R. Dazu haben wir verschiedene Möglichkeiten, wir beginnen hier einmal mit der simplesten Form. Mit der Funktion `rnorm()` können wir uns zufällige Daten aus einer theoretischen Normalverteilung ziehen. Es gibt natürlich noch viel mehr `r*`-Funktionen für die Generierung von Daten. Die Seite [Probability Distributions in R](https://www.stat.umn.edu/geyer/old/5101/rlook.html) zeigt nochmal einen großen Überblick. Im [Kapitel zu den Verteilungen](#sec-distribution) findest du dann auch nochmal mehr Informationen zu den einzelnen Funktionen.

Fangen wir aber einmal mit der einfachen Funktion für die Normalverteilung an. Hier genieren wir uns also einmal fünf Beobachtungen aus einer Normalverteilung. Wir brauchen dafür die Fallzahl (`n`), die wir generieren wollen. Dann den Mittelwert der theoretischen Verteilung (`mean`) sowie die Streuung (`sd`). Dann erhalten wir fünf Zahlen, die in der Gesamtheit den vorgestellten Zahlen entsprechen.

```{r}
rnorm(n = 5, mean = 0, sd = 1) |> round(2)
```

Wenn wir jetzt den Mittelwert der fünf Zahlen berechnen, dann erhalten wir aber gar nicht einen Mittelwert von $0$ und auch nicht eine Standardabweichung von $1$ wieder. Wie kann das sein? Häufig stolperst du hier ein wenig. Wieso Daten generieren, wenn die Daten dann nicht die Eigenschaften haben, die wir wollen? Hier kommt die Grundgesamtheit und die Stichprobe ins Spiel. In der Grundgesamtheit hast du einen Mittelwert von $2$ und eine Standardabweichung von $1$ vorliegen. Du ziehst aber nur eine kleine Stichprobe wie ich dir einmal in der folgenden Abbildung zeige. Zwar liegt der theoretische Mittelwert auf der Null, aber die Mittelwerte der einzelnen Simulationen können stark variieren.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Visualisierung der Abweichung des beobachteten Mittelwerts von dem theoretischen Mittelwert der Normalverteilung. Fünf Simulationen mit je fünf Beobachtungen wurden durchgeführt und jeweils der Mittelwert berechnet. Die Beobachtungen wurde aus einer Standardnormalverteilung mit $\\mathcal{N}(0, 1)$ gezogen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-normal

p_theo_observed
```

Der Zusammenhang wird dir vielleicht dann nochmal in der folgenden Abbildung klarer. Ich habe hier einmal eine kleine Simulation laufen lassen. Dabei habe ich immer Daten aus einer Standardnormalverteilung mit einem Mittelwert von $0$ und einer Standardabweichung von $1$ generiert. Was ich dabei geändert habe ist die Fallzahl. Wenn ich nur zwei Beobachtungen generiere, dann finde ich eine große Breite an beobachteten Mittlwerten. Wenn ich die Fallzahl erhöhe, dann komme ich immer näher an den erwarteten Mittelwert in meinen beobachteten Daten heran. Bei eintausend Beobachtungen habe ich faktisch kaum noch eine Abweichung vorliegen. Hier siehst du eben, es kommt auch stark auf die Fallzahl an. Wenn du dir zu wenig Beobachtungen anschaust, dann wirst du nicht immer den theoretischen Mittelwert oder Effekt in den generierten Daten wiederfinden.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7.5
#| fig-cap: "Zusammenhang zwischen der simulierten Anzahl an Beobachtungen und dem beobachteten Mittelwert zu dem theoretischen Mittelwert der Verteilung aus der die Beobachtungen generiert wurden. Die Beobachtungen wurde aus einer Standardnormalverteilung mit $\\mathcal{N}(0, 1)$ gezogen. Es wurden 1000 Simulationen durchgeführt. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-mean-sim

p1_mean + p2_mean +
  plot_layout(ncol = 2, widths = c(7, 1)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Welche Möglichkeiten gibt es eigentlich? {.unnumbered .unlisted}

Wenn wir Daten generieren wollen, dann haben wir im Prinzip zwei Möglichkeiten. Wir bauen uns die Daten selber per Hand in Excel oder aber nutzen die entsprechenden R Pakete. Ich stelle hier die zwei größeren R Pakete vor sowie die Lösungen per Hand in Excel. Wir haben natürlich auch die Möglichkeit die Daten in R ohne Pakete zu erstellen. Das macht in einem einfacheren Setting auch mehr Sinn.

-   Das [R Paket `{simstudy}`](https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html) liefert eigentlich alles was wir brauchen, wenn die Daten komplizierter werden. Insbesondere wenn wir keinen normlaverteilten Messwert vorliegen haben oder aber abhängige Einflussvariablen. Wenn ich größere Datensätze generiere, dann nutze ich gerne dieses Paket. Hier gibt es aber die Einschränkung, dass sich faktorielle Experimente nicht gut darstellen lassen. In diesem Fall ist die händsiche Erstellung manchmal einfacher.
-   Das [R Paket `{simdata}`](https://cran.r-project.org/web/packages/simdata/vignettes/Demo.html) hat den Vorteil große, komplexe Koreelationsstrukturen abzubilden. Wir können hier Netzwerkeffekte gut darstellen und dann auch in einen Datensatz übersetzen. Auch Transformationen von Daten lassen sich hier gut integrieren. Hier liegt aber nicht der Fokus auf einem faktoriellen Design mit Gruppeneffekten.
-   Wir schauen uns natürlich auch Excel an. Hier haben wir natürlich gleich die Möglichkeit uns die Daten dort zu bauen, wo wir die erhobenen Messwerte dann später nach dem durchgführten Experiment auch abspeichern. Deshalb zeige ich auch hier einmal wie wir dann die Daten händisch aufbauen.

Abschließend muss ich noch erwähnen, dass faktorielle Designs, die wir dann häufig in den Agrarwissenschaften finden, wir am besten dann händisch in R zusammenbauen. Wir nutzen dann die Funktionen, die es schon in R gibt und erstellen uns dann selber den Datensatz. Das ist im Prinzip so ähnlich wie in Excel nur das wir etwas besser nachvollziehbare Wege haben.

## Theoretischer Hintergrund

Neben dem allgmeinen Hintergrund können wir natürlich auch etwas tiefer in die Materie einsteigen. Zum einen müssten wir überlegen, welche Effekte es eigentlich gibt. Wir wollen ja Daten generieren, die nicht gleich sind. Daher wollen wir etwas bauen, wo wir auch einen Effekt sehen. Zwar ist es auch interessant sich Daten zu generieren wo die Nullhypothese wahr ist und nichts passiert, aber das ist eher nicht der Fokus der praktischen Arbeit. Wenn wir ein Experiment machen, dann wollen wir eigentlich auch einen Effekt oder Unterschied in den Gruppen oder allgemeiner den Daten sehen.

#### Welche Effekte gibt es? {.unnumbered .unlisted}

Wenn wir also Wissen, dass wir einen Effekt $\Delta$, eine Streuung $s$ und Fallzahl $n$ definieren müssen um uns zufällige Daten zu generieren, was sind denn dann die Effekte? Die Streuung und die Fallzahl sind ja realtiv einfach zu verstehen. Die Fallzahl legen wir fest und es ist eben die Anzahl an Beobachtungen, die wir generieren wollen. Im Prinzip also die Anzahl an Zeilen in unserem Datensatz. Die Streuung ist schon etwas schwerer zu fassen, ist aber am Ende nichts anderes als die Varianz in den Daten. Also zum Beispiel bei einer Normalverteilung, wie stark streuen meine Beobachtungen um den Mittelwert. Die Effekt sind schon etwas schwerer zu greifen, da wir hier erstmal definieren müssen, welche Effekte es gibt. Grob gesprochen gibt es im Rahmen der Genierung von Daten zwei Effekte von Bedeutung. Entweder sind wir an einer Mittelwertsdifferenz interessiert oder aber an einem Anteil.

::: panel-tabset
## Mittelwertsdifferenz

Die Mittelwertsdifferenz wird sehr häufig als Effektschätzer genutzt, wenn wir Daten erstellen wollen. Du kennst die Mittelwertsdifferenz schon aus der Darstellung der Mittelwerte von Gruppen anhand des Barplots. Hier können wir als Effekt entweder auf den absoluten Mittelwertsunterschied hinaus wollen oder aber die relative Veränderung angeben. Im Rahmen der Simulation nutzen wir die absolute Differenz sehr viel häufiger. In der folgenden Abbildung habe ich dir einmal für zwei Gruppen in einem Faktor einen Barplot sowie die Mittelwertsdifferenz mit Dotplots dargestellt.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7.5
#| fig-cap: "Darstellung eines einfaktoriellen Datensatzes  mit zwei Gruppen und unterschiedlichen Mittelwerten bei gleicher Varianz für einen normalverteilten Messwert. Der Effekt ist hier die Mittelwertsdifferenz. **(A)** Säulendiagramm (eng. *barplot*) **(B)** Dotplot mit absoluter und relativer Differenz zwischen den beiden Gruppen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-03

p_barplot_intro + p_effect_intro + 
  plot_layout(ncol = 2, widths = c(1, 2)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## Anteilsverhältnis

Eine andere Möglichkeit sind die Anteile. Hier fragen wir, wie häufig triit ein Ereignis in der Population auf? Daher ist die Pflanze krank? Oder aber, liegen wir im Zielbereich? Wir sind hier an einem Anteilsverhältnis interessiert. Anteile werden in unserem Kontext eigentlich immer mit ja (1) oder nein (0) kodiert. Wenn wir also zwei Gruppen haben, die gesunden und die kranken Pflanzen, dann können wir die Anteile an gesunden und kranken Pflanzen auf zwei Arten berechnen. Entweder sind wir an dem Anteil von den kranken Pflanzen an allen Pflanzen interessiert, dann rechnen wir ein Verhältnis. Wenn wir aber den Anteil von kranken Pflanzen an gesunden Pflanzen wollen, dann berechnen wir die Chance. In der folgenden Abbildung habe ich dir den Zusammenhang nochmal dargestellt.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10.5
#| fig-cap: "Visualisierung zweier Effektschätzer für Anteile an einem gestapelten Säulendiagramm (eng. *stacked barplot*) für einen Faktor mit einer Gruppe $A.1$. **(A)** Das Verhältnis (eng. *ratio*) beschreibt den Anteil der blauen Beobachtungen an allen Beobachtungen. Daher ein Art mittleres Verhältnis. **(B)** Die Chance (eng. *odd*) beschreibt den Anteil von blauen zu orangen Beobachtungen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-rr-or-intro

p_rr_intro + p_or_intro +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

Etwas wilder wird es jetzt, wenn wir die Effekte zwischen zwei Gruppen mit Anteilen berechnen wollen. Hier nutzen wir dann nicht die Differenz sondern ebenfalls den Anteil. Daher haben wir es hier mit einem Anteil von einem Anteil zu tun. Daher berechnen wir hier dann das Risikoverhältnis (eng. *risk ratio*) oder aber das Chancenverhältnis (eng. *odds ratio*). Als reine Formel ist es dann meistens verwirrender, deshlab hier einmal als Abbildung visualisert. In dem [Kapitel zu den Effektschätzern](#sec-effect) kannst du noch mehr lesen und dein Wissen vertiefen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10.5
#| fig-cap: "Visualisierung zweier Effektschätzer für Anteilsverhältnisse an zwei gestapelten Säulendiagramm (eng. *stacked barplot*) für einem Faktor mit zwei Gruppen $A.1$ und $A.2$. **(A)** Das Risikoverhältnis (eng. *risk ratio*) beschreibt den Anteil der blauen Beobachtungen an allen Beobachtungen im Verhältnis der beiden Gruppen. **(B)** Das Chancenverhältnis (eng. *odds ratio*) beschreibt den Anteil von blauen zu orangen Beobachtungen im Verhältnis der beiden Gruppen. Der Doppelbruch kann dann entsprechend umgeformt werden. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-rr-or

p_rr + p_or +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

Was nehmen wir hier mit?

-   Die Mittelwertsdifferenz ist zu gebrauchen, wenn wir von einem normalverteilten Messwert ausgehen. Oder aber, wenn wir mit den mittleren Effekt leben können. Wir wollen also die mittlere Anzahl an Blattläusen anstatt die Anzahl vergleichen. Oder aber die mittlere Infektionsrate anstatt den Anteil der kranken Pflanzen.
-   Anteilsverhätnisse nutzen wir, wenn wir einen Messwert vorliegen haben, der nicht normalverteilt ist und wir über die Anteile von Gruppen in unserem Messwert sprechen wollen. Daher wir wollen über den Anteil in den Boniutnotenstufen reden oder aber den Anteil an kranken Pflanzen modellieren.

Häufig reicht erstmal eine Genierung mit dem Mittelwert und der Mittelwertsdifferenz. Wir können uns vielen Fragsetllen erstmal mit einem Mittel annäheren und dann später nochmal diffferenzierter Auswerten. Beachte immer, das es hier ja um die Erstellung von künstlichen Daten geht, die selten die Komplexizität echter Daten abbilden können. Daher habe ich hier auch den Fokus auf der Normalverteilung und der Genierung von mitteleren Differenzen.

#### Effekt und Streuung {.unnumbered .unlisted}

Jetzt müssen wir noch den Zusammenhang zwischen Effekt und Streuung verstehen. Je höher deine Fallzahl ist, desto eher wirst du in den genierten Daten deine voreingestellten Effekte wiederfinden. Es gibt aber noch die Variable der Streuung. Wenn du eine Streuung mit ins Spiel bringst, dann werden natürlcih auch deine Effekte wiederum verzerrt. Bei einer Streuung erhälst du nicht deine voreingestellten Werte genau so wieder. Das ist manchmal etwas verwirrend, aber auch häufig der Grund warum wir nicht nur einen Datensatz simulieren sondern viele, die wir dann eben mitteln. Das hat aber keine Relevanz, wenn du deine Daten generierst um deine Analysepipeline zu testen. Wir schauen uns jetzt einmal den Fall eines faktoriellen und eines kovariaten Designs an.

::: panel-tabset
## Faktorielles Design

In dem folgenden Beispiel habe ich ein einfaktorielles Design mit nur zwei Leveln gewählt. Wir sehen recht gut, das wir bei keinem Effekt keinen Mittelwertsunterschied vorliegen haben. Ich habe hier eine Mittelwertsdifferenz von $+3$ voreingestellt. Wenn wir dann auch keine Streuung vorliegen haben, dann liegen alle Beobachtungen auf dem Mittelwert als ein Punkt. Wenn wir dann Streuung vorliegen haben, dann spreizen die Punkte auf dem Faktorlevel. Durch die Streuung können wir dann auch nicht mehr exakt die voreingestellten Effekte wiederfinden. Je kleiner die Fallzahl, desto größer ist dann die Abweichung von den voreingestellten Effekten.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 7
#| fig-width: 9
#| fig-cap: "Darstellung eines absoluten und relativen Effekt in einem einfaktoriellen Design mit zwei Leveln $A.1$ und $A.2$ als Gruppen. Der Effekt ist die absolute oder relative Mittelwertsdifferenz. Pro Gruppe wurden sechs Beobachtungen erhoben. Ohne Streuung geht die Grade direkt durch die Mittelwerte der Gruppen. **(A)** Kein Effekt und keine Streuung. Die absolute Mittelwertsdifferenz ist 0 und die relative Mittelwertsdifferenz ist x1 als Faktor. **(B)** Effekt und keine Streuung. Die absolute Mittelwertsdifferenz ist +3 und die relative Mittelwertsdifferenz ist x1.5 als Faktor.  **(C)** Kein Effekt und Streuung. Die absolute Mittelwertsdifferenz ist -0.5 und die relative Mittelwertsdifferenz ist x0.93 als Faktor.**(D)** Effekt und Streuung. Die absolute Mittelwertsdifferenz ist +2.7 und die relative Mittelwertsdifferenz ist x1.4 als Faktor. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-square-fac

p1_square_fac + p2_square_fac + p3_square_fac + p4_square_fac +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

## Kovariates Design

Haben wir ein kovariates Design vorliegen, dann wollen wir ja die Steigung in der Graden als Effekt einstellen. Ich habe hier eine Steigung von $+1.5$ und einen Intercept von $3$ voreingestellt. Wir brauchen immer etwas Streuung, sonst kann der Algorithmus keine Grade berechnen. Daher hier auch bei keiner Streuung ein winziger Wert, den wir dann eben auch in der Steigung wiederfinden. Ohne Streuung erhalten wir auch die voreingestellten Werte für die Steigung wieder. Haben wir keinen Effekt der Kovariaten auf den Messwert, dann haben wir auch keine Steigung. Sobald wir Streuung ins Spiel bringen, haben wir auch eine mehr oder minder starke Abweichung in den Daten. Insbesondere bei keinem Effekt und dann noch Streuung kann man schnell denken, dass wir doch was in den Daten hätten.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 7
#| fig-width: 9
#| fig-cap: "Darstellung eines Effekts als Steigung in einem kovariaten Design. Der Effekt der Steigung ist mit $\\beta_1$ gleich +1.5 und der Intercept ist mit $\\beta_0$ gleich 3 voreingestellt. Durch die Streuung mit der geringen Fallzahl von sechs Beobachtungen kann Steigung nicht immer erreicht werden. **(A)** Kein Effekt und keine Streuung. Die Steigung ist faktisch 0 und der Intercept 3. **(B)** Effekt und keine Streuung. Dei Steigung ist 1.5 und der Intercept ist 3. **(C)** Kein Effekt und moderate Streuung. Durch die Streuung entsteht eine leichte negative Steigung und eine Abweichung vom Intercept. **(D)** Effekt und moderate Streuung. Die Steigung und der Intercept werden durch die Streuung verzerrt. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-square-cov

p1_square_cov + p2_square_cov + p3_square_cov + p4_square_cov +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```
:::

#### Einschränkungen bei der Generierung {.unnumbered .unlisted}

Wenn wir über die Simulation von Daten sprechen, dann kommen wir nicht darum herum einmal über die schrecklich nette Familie der Verteilungen zu sprechen. Wir haben ja nicht nur auf der rechten Seite der Tilde unsere Einflussvariablen, die entweder Faktoren oder Kovariaten sind, sondern auch die Messwerte, die wir simulieren wollen. Diese Messwerte gehören aber einer Verteilungsfamilie an. Zwar ist die Normalverteilung (eng. *gaussian*) sehr häufig aber können wir mit der Normalverteilung nicht alle Messwerte abbilden. Daher brauchen wir auch die anderen Verteilungen. Daher hier einmal die Übersicht für dich. Das R Paket `{simstudy}` hat eine [Vielzahl an Verteilungen implementiert](https://kgoldfeld.github.io/simstudy/articles/simstudy.html#distributions) auf die wir hier nicht tiefer eingehen werden.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.7
#| fig-width: 7
#| fig-cap: "Erweiterte Darstellung der statistischen Modellierung. Die Messwerte $Y$ folgen einer Verteilung. Die Einflussvariablen liegen kontinuierlich als Kovariaten oder aber kategorial als Faktoren vor. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-02

p_lhs_rhs_detail
```

Wir konzentrieren uns hier nur auf einen kleinen Teil der möglichen Simulationen und Datengenerierungen. Das hat neben der vielen möglichen Verteilungen auch den Grund, dass wir usn hier ja nicht mit der algorithmischen Modellentwicklung in der Statistik beschäftigen wollen. Wir wollen ja nicht neue Algorithmen bauen und diese dann auf Daten evaluieren. Daher konzentrieren wir uns hier auf wenige Verteilungen, die dann aber das abbilden, was wir häufig brauchen. Wenn du mehr über Verteilungen wissen willst, dann ist die Shiny App [The distribution zoo](https://ben18785.shinyapps.io/distribution-zoo/) einen Besuch wert. Als Litertaur kann ich dir nur @dormann2013parametrische empfehlen, der sehr detailiert für Einsteiger auf Verteilungen eingeht.

-   Die **Normalverteilung** erlaubt uns das Frischegewicht, Trockengewicht oder aber Chlorophyllgehalt zu simulieren. Also im Prinzip die Messwerte, die wir hauptsächlich in einem agrawissenschaftlichen Umfeld erheben.
-   Die **Possionverteilung** erlaubt uns alles was wir Zählen zu simulieren. Also im Prinzip alle Anzahlen von Schädlingen oder aber Blütenstände sowie Blättern. Wir zählen hier eben etwas.
-   Die **Ordinalverteilung** ist dafür gut, wenn wir Noten simulieren wollen. Daher brauchen wir die Ordinalverteilung um unsere Boniturnoten zu generieren. Prinzipiell aber auch die Antwortverteilungen in einem Fragebogen.
-   Die **Binomialverteilung** ist die Verteilung, die wir nutzen, wenn wir nur zwei mögliche Messwerte haben. Also im prinzip gesunde Beobachtung oder kranke Beobachtung. Wir haben nur zwei Ausprägungen in dem Messwert vorliegen.

Neben den vorgestellten Verteilungen schauen wir uns dann noch die Simulation von **pseudo Zeitreihen** an. Wir haben hier dann verschiedene Messwerte über einen zeitlichen Verlauf vorliegen. Teilweise dann in einer etwas wirren Form, da wir eventuell keinen linearen Zusammenhang mehr vorliegen haben. Daher müssen wir dann hier etwas mehr schauen, dass wir die Daten gut simuliert kriegen.

Dann mache ich hier noch die Einschränkung, dass ich prinzipiell alles unter der Annahme der Varianzhomogenität generiere. Daher addiere ich über alle Faktorkombinationen oder Gruppen immer den gleichen Fehler auf. Im Prinzip kannst du natürlich auch für einzelne Faktorkombinationen dann einen anderen Fehler addieren und dir dafür einen Vektor mit unterschiedlichen Fehlertermen bauen, aber darauf gehe ich nur einmal kurz bei dem einfakoriellen Design ein. Und dann noch die Ergänzung, dass wir uns immer nur balancierte Designs erstellen. Das heißt wir haben keine fehlenden Werte in unseren Daten und die Gruppen in unseren Faktoren haben auch immer die gleiche Fallzahl.

#### Selbst gebaute Verteilungen {.unnumbered .unlisted}

Am Ende möchte ich noch auf eine andere Art der Simulation von Daten eingehen. Wir können uns auch eine wilde Verteilung selber bauen und dann aus deiser wilden verteilung dann unsere Beboachtungen ziehen. In dem Tutorium [Wilcoxon is (almost) a one-sample t-test on signed ranks](https://lindeloev.github.io/tests-as-linear/simulations/simulate_wilcoxon.html) wird einmal gezeigt wie wir das machen könnten. Wir bauen usn dazu erstmal eine Verteilung, die aus drei Verteilungen besteht. Wir haben hier aber ein paar Einschränkungen. Zum einen ist unsere Verteilung um die Null angeordnet. Das macht es einfacher verschiedene Verteilungen miteinander zu verbinden.

```{r}
null_dist_tbl <- tibble(y = c(rnorm(10000), 
                              exp(rnorm(10000)), 
                              runif(10000, min=-3, max=-2)),
                        type = "null")
```

Dann siehst du hier einnmal die Verteilung dargestellt. Wenn wir nur aus dieser Verteilung Beobachtungen ziehen, dann haben wir natürlich einen Effekt zwischen potenziellen Gruppen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "Selbstgebaute Verteilung mit einem Plateu und einem steilen Peak. Die Messwerte sind auch negative, da alle ursprünglichen drei Verteilungen um die Null zentriert sind. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-own-dist

null_dist_tbl |> 
  ggplot(aes(y)) +
  theme_modeling() +
  geom_histogram(bins = 200, fill = "#56B4E9", color = "black") +
  scale_x_continuous(limits = c(-4, 10)) +
  labs(x = "Messwert (y)", y = "Anzahl")
```

Wenn wir jetzt noch einen Effekt haben wollen, dann können wir natürlich die beiden Gruppen nicht aus der gleichen Verteilung ziehen. Daher können wir uns auch noch eine Alternative Verteilung bauen indem wir einfach die Messwerte um einen fixen Effekt erhöhen. Hier wähle einen Effekt von $+2$. Du kannst natürlich auch die Nullverteilung erstmal aus dem negativen herausschieben und dann nochmal einen Effekt addieren.

```{r}
eff_dist_tbl <- tibble(y = c(rnorm(10000), 
                             exp(rnorm(10000)), 
                             runif(10000, min=-3, max=-2)),
                       type = "alt") |> 
  mutate(y = y + 2) |> 
  bind_rows(null_dist_tbl)
```

In der folgenden Abbildung siehst du dann einmal wie sich die beiden Verteilungen mit den unterschiedlichen Effekten ergeben. Bitte beachte, dass die Alterntaive erstmal neu generiert wurde und nicht die verschobene Nullhypothese ist. Daher hat die Alternative natürlich auch eine andere Verteilung als die Nullhypothese.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Selbstgebaute Verteilung mit einem Plateu und einem steilen Peak für die Nullhypothese und die Alternativehypothese verschoben um den Effekt von $+2$. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-own-dist-eff

eff_dist_tbl |> 
  ggplot(aes(y, fill = type)) +
  theme_modeling() +
  geom_histogram(bins = 200, color = "black") +
  scale_x_continuous(limits = c(-4, 10)) +
  labs(x = "Messwert (y)", y = "Anzahl") +
  scale_fill_okabeito(name = "", labels = c("Effekt", "Null")) +
  theme(legend.position = "top")
```

Für die Genierierung deiner Daten würdest du dann mit `slice_sample()` dir dann die gewünschten Anzahlen aus den beiden Verteilungen rausziehen. Hier hilft die tolle Funktion `group_by()`, die dir dann alles in einem Abwasch macht. Ich will hier pro Gruppe dann nur drei zufällig ausgewählte Beobachtungen haben.

```{r}
eff_dist_tbl |> 
  group_by(type) |> 
  slice_sample(n = 3)
```

Bei den selbstgebauten Verteilungen ist die Effektzuweisung aber überhaupt nicht einfach und ab zwei Gruppen wird es wirklich nicht mehr schön. Daher zeige ich dir hier nur die Idee, in der Anwendung zeige ich dir etwas robustere Varianten, die einfacher zu bedienen sind. Wenn es aber wirklich mal was wirres sein soll, dann ist diese Art der Verteilungserstellung wirklich eine Möglichkeit um auf künstliche Daten zu kommen.

::: callout-tip
## Weitere Tutorien für die Genierung von Daten

Wir immer geht natürlich mehr als ich hier Vorstellen kann. Du findest im Folgenden Tutorien, die mich hier in dem Kapitel inspiriert haben. Ich habe mich ja in diesem Kapitel auf die Durchführbarkeit in R und die allgemeine Verständlichkeit konzentriert.

-   Einen guten Überblick liefert Brad Duthie in seinem Tutorium [Creating simulated data sets in R](https://stirlingcodingclub.github.io/simulating_data/index.html). Hier kannst du dich dann nochmal in die Grundlagen einlesen.
-   Auch Excel kann künstliche Daten generieren. Dafür schaue ich dann immer in die [statistischen Funktionen (Referenz)](https://support.microsoft.com/de-de/office/statistische-funktionen-referenz-624dac86-a375-4435-bc25-76d659719ffd) Seite nach. Die Seite ist leider etwas schwer zu lesen.
-   [Getting started simulating data in R: some helpful functions and how to use them](https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/) gibt nochmal einen guten Überblick über die Standardfunktionen in R um sich schnell Daten zu generieren.
-   [The distribution zoo](https://ben18785.shinyapps.io/distribution-zoo/) sowie [Probability Distributions in R](https://www.stat.umn.edu/geyer/old/5101/rlook.html) oder aber auch [Plotting Continuous Probability Distributions In R With ggplot2](https://dk81.github.io/dkmathstats_site/rvisual-cont-prob-dists.html) gben nochmal einen Einblick in die Verteilungen. Dabei würde ich den Distribution Zoo als Shiny App erstmal vorziehen. Die anderen beiden Quelle liefern nochmal mehr mathematischen Hintergrund.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, simstudy, simdata, modelr, 
               ggpmisc, janitor, conflicted)
set.seed(20250820)
conflicts_prefer(ggplot2::annotate)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Normalverteilt

Beginnen wir mit der wichtigsten Art der Simulation von Messwerten. Wir fangen mit der Normalverteilung an. Das heißt, dass unser Messwert $y$ normalverteilt ist und wir unsere Messwerte aus mehreren Normalverteilungen zusammenbauen. Jede der Faktoren oder Kovariaten ist normalverteilt und hat damit immer einen Mittelwert und eine Varianz als Streuung. Das macht es dann auch für usn einfacher einmal die Grundlagen zu verstehen. Am Ende kannst du dir auch mittlere Noten oder eine mittlere Anzahl generieren und dann eben etwas stärker Runden. Dazu mehr dann in den folgenden Verteilungen.

### Faktorielles Design

Ein faktorielles Design heißt nichts anderes als das du einen Faktor mit Leveln vorliegen hast. Häufig ist dieser Faktor dann deine Behandlung und deine Level sind dann die Strufen der Behandlung. Wenn du nur zwei Behandlungen vorliegen hast, dann rechnest du dann später einen Zweigruppenvergleich wie eben den t-Test. Wenn du mehr als zwei Gruppen vorliegen hast, wirst du dann eine einfaktorielle ANOVA nutzen und den entsprechenden Post-hoc Test. Weil zwei Gruppen eben so schön einfach sind, fangen wir hier damit einmal an. An den zwei Gruppen kannst du dann immer schön die Grundlagen nachvollziehen.

#### Einfaktoriell $f_A$ mit 2 Leveln {.unnumbered .unlisted}

Beginnen wir also einmal mit dem einfaktoriellen Design mit nur zwei Gruppen. In der folgenden schematischen Darstellung ist einmal das Modell dargestellt. Wir haben einen Messwert und einen Faktor, der aus zwei Gruppen besteht. Das Modell ist sehr simple und soll uns nur helfen einmal die Simulation von Daten in R zu verstehen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f1lvl2-theo

p_1fac_2lvl_model
```

Wir haben jetzt unzählige Möglichkeiten die Daten zu generieren. Ich zeige hier einmal die zwei einfacheren Methoden. Einmal können wir die Daten getrennt in einem `tibble()` erstellen. Hierbei ist es wichtig, dass wir ein balanciertes Design vorliegen haben. Dann bauen wir uns das Long-Format über `gather()`. Wir schauen uns immer Gruppen mit gleicher Fallzahl an. Dann können wir auch die Spalten getrennt zusammenbauen und am Ende alles einmal aufaddieren. Wir haben hier einen Effekt von einer Mittelwertsdifferenz von $+3$ vorliegen bei keiner Streuung.

:::: panel-tabset
## Getrennt

Wenn wir wenig Gruppen haben, dann ist die getrennte Erstellung in einem `tibble()` sehr übersichtlich. Wir stellen ja den Effekt jeweils in den einzelnen Gruppen separat ein.

```{r}
fac1_tbl <- tibble("1" = rnorm(n = 5, mean = 3, sd = 0.001),
                   "2" = rnorm(n = 5, mean = 6, sd = 0.001)) |> 
  gather(key = "f_a", value = "y")
```

## Additiv

Im additiven Zusammenbauen nutzen wir viele Funktionen um uns die Spalten mit den Faktoren, Effekten und Fehler aufzubauen. Am Ende addieren wir die Spalten zum Messwert auf.

```{r}
fac1_tbl <- tibble(f_a = gl(2, 5, labels = c("1", "2")),
                   eff_a = rep(c(3, 6), each = 5),
                   error = rnorm(length(f_a), 0, 0.001),
                   y = eff_a + error)
```

::: {layout="[15,85]" layout-valign="top"}
![](images/angel_01_small.png){fig-align="center" width="100%"}

> *Das additive Zusammenbauen funktioniert hier nur in dieser Form so gut, da wir einen normalverteilten Messwert haben. In anderen Verteilungen können wir nicht einfach den Fehler addieren. Das hängt hier mit der Symmetrie der Normalverteilung um den Mittelwert zusammen.*
:::
::::

Dann rechnen wir einfach einmal einen schnellen t-Test und schauen, ob wir die Differenz wiedererhalten. Wir sehen, dass wir die gleichen Mittelwerte wiedergeben bekommen und natürlich auch einen signifkanten Unterschied. Die Streuung ist ja super klein.

```{r}
t.test(y ~ f_a, data = fac1_tbl)
```

Wir können uns den Zusammenhang auch als eine simple lineare Regression darstellen lassen. Da ich die Streuung sehr gering eingestellt habe, können wir auch die Koeffizienten exakt so wiedererhalten. In der folgenden linearen Regression siehst du einmal wie die Mittelwertsdifferenz wieder der eingestellten Differenz entspricht.

```{r}
lm(y ~ f_a, fac1_tbl) |> coef() |> round(2)
```

In der folgenden Abbildung ist der Zusammenhang nochmal graphisch dargestellt. Wir haben den Mittelwert der ersten Gruppe als Intercept im Modell und die Steigung der Graden als Mittelwertsdifferenz. Wir sehen hier also nochmal den Zusammenhang zwischen der Datengenerierung und der linearen Regression.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "Darstellung der einfaktoriellen Simulation mit zwei Gruppen. Der Intercept stellt den Mittelwert der ersten Gruppe dar. Die Mittelwertsdifferenz ist die Steigung der Graden. *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-1

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 3, linewidth = 0.5, color = "#CC79A7") +
  geom_abline(intercept = 0, slope = 3, color = "#E69F00") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Einfaktorielle Simulation mit 2 Leveln",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)")
```

Manchmal wollen wir uns auch Daten erstellen, die nicht die gleiche Varianz in allen Gruppen haben. In diesem Fall hilft am meisten die getrennte Erstellung. Wir nehmen dann einfah in jeder Gruppe eine andere Varianz und lassen dann die Daten erstellen. In dem folgenden Kasten siehst du nochmal ein Beispiel für die Generierung von Daten mit Varianzheterogenität. Ob wir das brauchen hängt dann davon ab, was du mit den simulierten Daten ausprobieren möchtest.

::: callout-note
## Varianzheterogeniät zwischen den Gruppen

In der getrennten Erstellung von Daten können wir dann für jede Gruppe eine eigene Varianz festlegen. Hier habe ich in der einen Gruppe eine Standardabweichung von $5$ und in der anderen Gruppe eine Standardabweichung von $1$ angenommen.

```{r}
#| eval: false
fac1_tbl <- tibble("1" = rnorm(n = 5, mean = 3, sd = 5),
                   "2" = rnorm(n = 5, mean = 6, sd = 1)) |> 
  gather(key = "f_a", value = "y")
```
:::

#### Einfaktoriell $f_A$ mit \>2 Leveln {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f1lvl3-theo

p_1fac_3lvl_model
```

:::: panel-tabset
## `tibble()`

#### Getrennt {.unnumbered .unlisted}

```{r}
fac1_tbl <- tibble("1" = rnorm(5, 2, 0.001),
                   "2" = rnorm(5, 6, 0.001),
                   "3" = rnorm(5, 4, 0.001)) |> 
  gather(key = "f_a", value = "y")
```

#### Additiv {.unnumbered .unlisted}

```{r}
fac1_tbl <- tibble(f_a = gl(3, 5, labels = c("1", "2", "3")),
                   eff_a = rep(c(2, 6, 4), each = 5),
                   error = rnorm(length(f_a), 0, 0.001),
                   y = eff_a + error)
```

## Excel

::: callout-warning
## Achtung, bitte beachten!

Die Erstellung von Daten in Excel ist nicht für die *wissenschaftliche* Bewertung von Algorithmen sinnvoll und angebracht. Wir nutzen hier Excel um recht einfach uns zufällig Daten zu erstellen. Wir nutzen dann die künstlichen Exceldaten um unsere Analyse für unsere echten experimentelle Daten zu üben. Auch ist die vereinfachte Erstellung von künstlichen Daten in Excel hilfreich um die zugrundeliegende Konzepte nochmal zu verstehen.
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-fac1-excel

p_fac1_excel
```

```{r}
excel_fac1_tbl <- read_excel("data/data_generation_excel.xlsx",
                             sheet = "einfaktoriell") |> 
  clean_names() |> 
  mutate(faktor_a = as_factor(faktor_a))
```

```{r}
lm(messwert ~ faktor_a, data = excel_fac1_tbl) |> 
  coef() |> round()
```
::::

[R Library Contrast Coding Systems for categorical variables](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

::: panel-tabset
## Treatment coding (default)

*Treatment coding* mit `contr.treatment` (default)

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.treatment")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-21

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 2, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Treatment coding",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)")
```

## Effect coding

*Effect coding* mit `contr.sum`

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.sum")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-22

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 4, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Effect coding",
       subtitle = "Intercept ist der globale Mittelwert",
       x = "Faktor A", y = "Messwert (Y)")
```
:::

#### Zweifaktoriell ohne Interaktion $f_A + f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2nointer-theo

p_2fac_nointer_model +
  labs(title = "") 
```

```{r}
fac2_nointer_tbl <- tibble(f_a = rep(gl(3, 5), 2),
                           f_b = gl(2, 15),
                           y = 2 + 
                             2 * as.numeric(f_a) + 
                             3 * as.numeric(f_b) + 
                             rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + f_b, fac2_nointer_tbl) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2nointer

ggplot(fac2_nointer_tbl, aes(f_a, y, color = f_b)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 7, linewidth = 0.5, color = "#CC79A7") +
  geom_abline(intercept = 8, slope = 2, color = "#56B4E9") +
  geom_abline(intercept = 5, slope = 2, color = "#E69F00") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Zweifaktorielle Simulation",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)", color = "Faktor B") +
  scale_color_okabeito(label = c("B.1", "B.2")) +
  theme(legend.position = "top")
```

#### Zweifaktoriell mit Interaktion $f_A + f_B + f_A \times f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln und deren Interaktion $f_A \\times f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2inter-theo

p_2fac_model +
  labs(title = "") 
```

:::: panel-tabset
## `tibble()`

```{r}
fac2_tbl <- expand_grid(f_a = 1:3, f_b = 1:2, rep = 1:5) |> 
  mutate(f_a = as_factor(f_a),
         f_b = as_factor(f_b))
```

```{r}
fac2_mat <- fac2_tbl |> 
  model_matrix(~ f_a * f_b) |> 
  as.matrix()
```

```{r}
eff_vec <- c(intercept = 7, 
             f_a2 = 2, f_a3 = 4, f_b2 = 3, 
             f_a2xf_b2 = 0, f_a3xf_b2 = -6)
```

```{r}
eff <- fac2_mat %*% eff_vec
```

```{r}
fac2_inter_tbl <- fac2_tbl |> 
  mutate(y = eff + rnorm(length(eff), 0, 0.001))
```

Wenn du jetzt noch Varianzheterogenität haben möchtest, dann müsstest du dir einen Vektor mit den verschiedenen Aufrufen der Funktion `rnorm()` für die jeweiligen Faktorkombinationen bauen. Hier wären es dann bei sechs Faktorkombinationen eben sechsmal `rnorm()` mit jeweils fünf Beobachtungen als Anzahl der Wiederholungen.

## Excel

::: callout-warning
## Achtung, bitte beachten!

Die Erstellung von Daten in Excel ist nicht für die *wissenschaftliche* Bewertung von Algorithmen sinnvoll und angebracht. Wir nutzen hier Excel um recht einfach uns zufällig Daten zu erstellen. Wir nutzen dann die künstlichen Exceldaten um unsere Analyse für unsere echten experimentelle Daten zu üben. Auch ist die vereinfachte Erstellung von künstlichen Daten in Excel hilfreich um die zugrundeliegende Konzepte nochmal zu verstehen.
:::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-fac2-excel

p_fac2_excel
```

```{r}
excel_fac2_tbl <- read_excel("data/data_generation_excel.xlsx",
                             sheet = "zweifaktoriell") |> 
  clean_names() |> 
  mutate(faktor_a = as_factor(faktor_a),
         faktor_b = as_factor(faktor_b))
```

Die Zahlen kommen jetzt nicht perfekt hin, da ich hier mit einer Standardabweichung von 2 eine recht hohe Streuung gewählt habe. Darüber hinaus habe ich dann auch sehr wenige Beobachtungen gebaut. Deshalb passt der Intercept nicht ganz, den der Intercept müsste eigentlich 10 sein und nicht 9. Daher stimmen dann auch die anderen Effekt nicht perfekt.

```{r}
lm(messwert ~ faktor_a * faktor_b, data = excel_fac2_tbl) |> 
  coef() |> round()
```
::::

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2inter

ggplot(fac2_inter_tbl, aes(f_a, y, color = f_b, group = f_b)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 7, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "line", show.legend = FALSE) +
  stat_summary(fun = "mean", geom = "label", show.legend = FALSE, 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Zweifaktorielle Simulation",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)", color = "Faktor B") +
  scale_color_okabeito(label = c("B.1", "B.2")) +
  theme(legend.position = "top")
```

### Kovariates Design

#### Einkovariat $c_1$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c1-theo

p_1cov_model 
```

```{r}
cov1_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   y = 2 + 
                       2 * c_1 + 
                           rnorm(10, 0, 0.001))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c1

ggplot(cov1_tbl, aes(c_1, y)) +
  theme_modeling() +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_point() +
  stat_poly_line(color = "#E69F00", linewidth = 0.5) +
  stat_poly_eq(use_label("eq"), size = 8) +
  scale_x_continuous(breaks = -3:2) +
  scale_y_continuous(breaks = c(-4, -2, 0, 2, 4, 6)) +  
  labs(title = "Einkovariate Simulation",
       subtitle = "Intercept ist der y-Achsenabschnitt",
       x = "Covariate 1", y = "Messwert (Y)")
```

#### Zweikovariat unabhängig $c_1 + c_2$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c2-theo

p_2cov_model
```

```{r}
cov2_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   c_2 = rnorm(10, 0, 1),
                   y = 2 + 
                       1 * c_1 + 
                       2 * c_2 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2, cov2_tbl) |> 
  coef() |> round(2)
```

#### Zweikovariat abhängig $c_1 + c_2$ {.unnumbered .unlisted}

#### Komplexere Modelle {.unnumbered .unlisted}

::: panel-tabset
## `tibble()`

## `{simstudy}`

## Excel

`NORM.INV(ZUFALLSZAHL(); 0; 5)`
:::

## Possionverteilt

::: callout-note
## Normalverteilung und Runden

Du kannst auch eine Normalverteilung nehmen und dann einfach runden.

```{r}
rnorm(n = 5, mean = 10, sd = 1) |> round()
```

Die Abweichungen sind tolerable wie @kruppa2016simulation gezeigt hat.
:::

Im Folgenden müssen wir die Fallzahl erhöhen, da die Poissonverteilung keine eigenen Parameter für die Varianz hat. Die Streuung ist nämlich eien Funktion des Mittelwerts. Je größer der Mittelwert, desto größer die Varianz.

### Faktorielles Design

::: panel-tabset
## Getrennt

Wenn wir wenig Gruppen haben, dann ist die getrennte Erstellung in einem `tibble()` sehr übersichtlich. Wir stellen ja den Effekt jeweils in den einzelnen Gruppen separat ein.

```{r}
fac1_tbl <- tibble("1" = rpois(n = 1000, lambda = 3),
                   "2" = rpois(n = 1000, lambda = 6)) |> 
  gather(key = "f_a", value = "y")
```

## Additiv

Im additiven Zusammenbauen nutzen wir viele Funktionen um uns die Spalten mit den Faktoren, Effekten und Fehler aufzubauen. Am Ende addieren wir die Spalten zum Messwert auf.

```{r}
fac1_tbl <- tibble(f_a = gl(2, 1000, labels = c("1", "2")),
                   eff_a = rep(c(3, 6), each = 1000),
                   y = rpois(n = length(eff_a), lambda = eff_a))
```
:::

```{r}
fac1_tbl |> 
  group_by(f_a) |> 
  summarise(mean(y), median(y))
```

```{r}
rnbinom(10, mu = 4, size = 2)
```

### Kovariates Design

## Ordinalverteilt

[Ordinal Categorical Data](https://kgoldfeld.github.io/simstudy/articles/ordinal.html)

### Faktorielles Design

### Kovariates Design

## Binomialverteilt

### Faktorielles Design

### Kovariates Design

## Zeitreihen

[Spline Data](https://kgoldfeld.github.io/simstudy/articles/spline.html)

### Faktorielles Design

### Kovariates Design

## Referenzen {.unnumbered}
