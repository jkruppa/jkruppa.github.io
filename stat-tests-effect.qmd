```{r echo = FALSE}
pacman::p_load(tidyverse, readxl, knitr, kableExtra, Hmisc)
```

# Der Effektschätzer {#sec-effect}

*Version vom `r format(Sys.time(), '%B %d, %Y um %H:%M:%S')`*

> *"Alles, was wir hören, ist eine Meinung, keine Tatsache. Alles, was wir sehen, ist eine Perspektive, nicht die Wahrheit." --- Marcus Aurelius, Meditationen*

::: column-margin
Eine wunderbare Übersicht über den Begriff *Effektschätzer* liefert das englische Buch [Doing Meta-Analysis with R: A Hands-On Guide](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html).
:::

Der Effektschätzer. Ein seltsames Kapitel, denn ich tue mich sehr schwer, dieses Kapitel irgendwo in die Linearität dieses Buches hier einzuordnen. Deshalb ist dieses Kapitel eigentlich immer an der falschen Stelle. Entweder hast du schon die statistischen Tests gelesen und du wüsstest gerne was die Effektschätzer sind *oder* du suchst hier nochmal die Beschreibung der Effektschätzer zum Beispiel aus der multiple Regression heraus. Also steht jetzt dieses Kapitel hier im Raum und du musst schauen, was du wirklich brauchst. Oder ob du dieses Kapitel erst überspringst und dann später nochmal hier liest.

[Der Effektschätzer wird auch gerne Theta $\boldsymbol{\theta}$ genannt. Da wir dann aber später noch mit anderen Konzepten in die Quere kommen, nutze ich das etwas intuitivere Delta $\boldsymbol{\Delta}$.]{.aside}

Wenn wir einen der vielen Effektschätzer berechnen wollen, dann nutzen wir dafür die Effektschätzer aus dem [R Paket effectsize](https://easystats.github.io/effectsize/index.html). Das R Paket `effectsize` liefert Effektschätzer für fast alle statistischen Gelegenheiten. Wir werden hier wie immer nur den groben Überblick abdecken. Vermutlich wird das Kapitel dann noch Anwachsen. Streng genommen gehört das @sec-test-diag zu den diagnostischen Tests auf einer 2x2 Kreuztabelle auch irgendwie zu Effektschätzern. Wenn du Spezifität und Sensitivität suchst bist du in dem Kapitel zu diagnostischen Tests richtig.

Wir unterscheiden hier erstmal grob in zwei Arten von Effektschätzern:

1)  Effektschätzer, die einen **Mittelwertsunterschied** beschreiben.
2)  Effektschätzer, die einen **Anteilsunterschied** beschreiben.

Daneben gibt es wie noch die Korrelation wie in @sec-lin-reg-corr beschrieben. Die Korrelation wollen wir aber in diesem Kapitel nicht vorgreifen bzw. wiederholen.

Am Ende muss du immer den Effekt im Kontext der Fragestellung bzw. des Outcomes $y$ bewerten. Der numerische Unterschied von $0.1$ cm kann in einem Kontext viel sein. Das Wachstum von Bakterienkolonien kann ein Unterschied von $0.1$ cm viel sein. Oder aber sehr wenig, wenn wir uns das Wachstum von Bambus pro Tag anschauen. Hier bist du gefragt, den Effekt in den Kontext richtig einzuordnen. Ebenso stellt sich die Frage, ob ein Unterschied von 6% viel oder wenig ist.

::: callout-tip
## Effektschätzer

Wenn wir uns einen Unterschied eines **Mittelwerts** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn der Mittlwertsunterschied $\Delta$ zwischen der Gruppe $A$ und der Gruppe $B$ gleich 0 ist. Die Nullhypothese gilt. Beide Gruppen $A$ und $B$ haben den gleichen Mittelwert.

$$
\Delta_{A-B} = A - B = 0
$$

Wenn wir uns einen Unterschied eines **Anteils** anschauen, dann haben wir *keinen* Effekt vorliegen, wenn der Anteilsunterschied $\Delta$ zwischen der Gruppe $A$ und der Gruppe $B$ gleich 1 ist. Die Nullhypothese gilt. Beide Gruppen $A$ und $B$ haben den gleichen Anteil.

$$
\Delta_{A/B} = \cfrac{A}{B} = 1
$$

Dieses Wissen brauchen wir um die Signifikanzschwelle bei einem 95% Konfidenzintervall richtig zu setzen und interpretieren zu können. Siehe dazu auch nochmal das @sec-ki.
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, magrittr, see, scales,
               effectsize, parameters, broom,
               emmeans, conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("mutate", "dplyr")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Am Ende des Kapitels findest du nochmal den gesamten R Code in einem Rutsch zum selber durchführen oder aber kopieren.

## Unterschied zweier Mittelwerte

Wir berechnen zwei Mittelwerte $\bar{y}_1$ und $\bar{y}_2$. Wenn wir wissen wollen wie groß der Effekt zwischen den beiden Mittelwerten ist, dann bilden wir die Differenz. Wir berechnen das $\Delta_{y_1-y_2}$ für $y_1$ und $y_2$ indem wir die beiden Mittelwerte voneinander abziehen.

$$
\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2
$$

[Warum schreiben wir hier vermutlich? Ein statistischer Test ist eine Funktion von $\Delta$, $s$ und $n$. Wir können auch mit kleinem $\Delta$ die Nullhypothese ablehnen, wenn $s$ und $n$ eine passende Teststatistik generieren. Siehe dazu auch das @sec-delta-n-s.]{.aside}

Wenn es keinen Unterschied zwischen den beiden Mittelwerten $\bar{y}_1$ und $\bar{y}_2$ gibt, dann ist die Differenz $\Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2$ gleich 0. Wir sagen, die Nullhypothese *vermutlich* gilt, wenn die Differenz klein ist. Was wir besser annehmen können ist, dass die Relevanz klein ist. Effekt mit einem geringen Mittelwertsunterschied sind meistens nicht relevant. Aber diese Einschätzung hängt stark von der Fragestellung ab.

$$
H_0: \Delta_{y_1-y_2} = \bar{y}_1 - \bar{y}_2 = 0
$$

In @tbl-dog-cat-small-delta ist nochmal ein sehr simples Datenbeispiel gegeben an dem wir den Zusammenhang nochmal nachvollziehen wollen.

```{r}
#| echo: false
#| label: tbl-dog-cat-small-delta
#| tbl-cap: Beispiel für die Berechnung von einem Mittelwertseffekt an der Sprunglänge [cm] von Hunde und Katzenflöhen.
data_tbl <- tibble(animal = gl(2, 4, labels = c("cat", "dog")),
                   jump_length = c(8.0, 7.9, 8.3, 9.1, 8.0, 7.8, 9.2, 7.7)) 

data_tbl %>% 
  kable(align = "c", "pipe")

mean_tbl <- data_tbl %>% 
  group_by(animal) %>% 
  summarise(mean_animal = round(mean(jump_length), 1),
            var_animal = round(var(jump_length), 1))

mean_cat <- mean_tbl$mean_animal[1]
mean_dog <- mean_tbl$mean_animal[2]

```

Nehmen wir an, wir berechnen für die Sprungweite \[cm\] der Hundeflöhe einen Mittelwert von $\bar{y}_{dog} = `r mean_dog`$ und für die Sprungweite \[cm\] der Katzenflöhe einen Mittelwert von $\bar{y}_{cat} =`r mean_cat`$. Wie große ist nun der Effekt? Oder anders gesprochen, welchen Unterschied in der Sprungweite macht es aus ein Hund oder eine Katze zu sein? Was ist also der Effekt von `animal`? Wir rechnen $\bar{y}_{dog} - \bar{y}_{cat} = 8.2 - 8.3 = -0.1$. Zum einen wissen wir jetzt "die Richtung". Da wir ein Minus vor dem Mittelwertsunterschied haben, müssen die Katzenflöhe weiter springen als die Hundeflöhe, nämlich 0.1 cm. Dennoch ist der Effekt sehr klein.

### Cohen's d

Da der Mittlwertsunterschied *alleine* nnur eine eingeschränkte Aussage über den Effekt erlaubt, gibt es noch Effektschätzer, die den Mittelwertsunterschied $\Delta_{y_1-y_2}$ mit der Streuung $s^2$ sowie der Fallzahl zusammenbringt. Der bekannteste Effektschätzer für einen Mittelwertsunterschied bei großer Fallzahl mit mehr als 20 Beobachtungen ist Cohen's d. Wir können Cohen's d wie folgt berechnen.

$$
|d| = \cfrac{\bar{y}_1-\bar{y}_2}{\sqrt{\cfrac{s_1^2+s_2^2}{2}}}
$$

Wenn wir die berechneten Mittelwerte und die Varianz der beiden Gruppen in die Formel einsetzten ergibt sich ein absolutes Cohen's d von 0.24 für den Gruppenvergleich.

$$
|d| = \cfrac{8.2 - 8.3}{\sqrt{(0.5^2+0.3^2) /2}} = \cfrac{-0.1}{0.41} = \lvert-0.24\rvert
$$

::: column-margin
Mehr Informationen zu Cohen's d gibt es auf der Hilfeseite von `effectsize`: [Interpret standardized differences](https://easystats.github.io/effectsize/reference/interpret_cohens_d.html)
:::

Was denn nun Cohen's d *exakt* aussagt, kann niemand sagen. Aber wir haben einen Wust an möglichen Grenzen. Hier soll die Grenzen von Cohen (1988) einmal angegeben werden. Cohen (1988) hat in seiner Arbeit folgende Grenzen in @tbl-cohen-d für die Interpretation von $d$ vorgeschlagen.

|     Cohen's d      | Interpretation des Effekts |
|:------------------:|:--------------------------:|
|     $d < 0.2$      |         Sehr klein         |
| $0.2 \leq d < 0.5$ |           Klein            |
| $0.5 \leq d < 0.8$ |           Mittel           |
|    $d \geq 0.8$    |           Stark            |

: Interpretation der Effektstärke nach Cohen (1988). {#tbl-cohen-d}

Wir können auch über die Funktion `cohens_d()` Cohen's d einfach in R berechnen. Die Funktion `cohens_d()` akzeptiert die Formelschreibweise. Die 95% Konfidenzintervalle sind mit Vorsicht zu interpretieren. Denn die Nullhypothese ist hier nicht so klar formuliert. Wir lassen also die 95% Konfidenzintervalle erstmal hier so stehen.

```{r}
cohens_d(jump_length ~ animal, data = data_tbl, pooled_sd = TRUE)
```

Dankenswerterweise gibt es noch die Funktion `interpret_cohens_d`, die es uns erlaubt auszusuchen nach welche Literturquelle wir den Wert von Cohen's d interpretieren wollen. Ob dieser Effekt relevant zur Fragestellung ist musst du selber entscheiden.

```{r}
interpret_cohens_d(0.24, rules = "cohen1988")
```

### Hedges' g

Soweit haben wir uns mit sehr großen Fallzahlen beschäftigt. Cohen's d ist dafür auch sehr gut geeigent und wenn wir mehr als 20 Beobachtungen haben, können wir Cohen's d auch gut anwenden. Wenn wir weniger Fallzahl vorliegen haben, dann können wir Hedges' g nutzen. Hedges' g bietet eine Verzerrungskorrektur für kleine Stichprobengrößen ($N < 20$) sowie die Möglichkeit auch für *unbalanzierte* Gruppengrößen einen Effektschätzeer zu berechnen. Die Formel sieht mit dem Korrekturterm recht mächtig aus.

$$
g = \cfrac{\bar{y}_1 - \bar{y}_2}{s^*} \cdot \left(\cfrac{N-3}{N-2.25}\right) \cdot \sqrt{\cfrac{N-2}{N}}
$$

mit

$$
s^* = \sqrt{\cfrac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}
$$

Wir können aber einfach die Mittelwerte und die Varianzen aus unserem beispiel einsetzen. Da unsere beiden Gruppen gleich groß sind $n_1 = n_2$ und damit ein balanziertes Design vorliegt, sind Cohen's d und Hedges' g numerisch gleich. Wir können dann noch für die geringe Fallzahl korrigieren und erhalten ein händisches $g = 0.18$.

$$
g = \cfrac{8.2 - 8.3}{0.41} \cdot \left(\cfrac{8-3}{8-2.25}\right) \cdot \sqrt{\cfrac{8-2}{8}} = \lvert-0.24\rvert \cdot 0.87 \cdot 0.87 \approx 0.18
$$

mit

$$
s^* = \sqrt{\cfrac{(4-1)\cdot0.5^2 + (4-1)\cdot0.3^2}{4+4-2}} = \sqrt{\cfrac{0.75 + 0.27}{6}} = 0.41
$$

In R gibt es die Funktion `hedges_g()` die uns erlaubt in der Formelschreibweise direkt Hedges' g zu berechnen. Wir sehen hier eine Abweichung von unserer händischen Rechnung. Das ist aber in soweit nicht ungewöhnlich, da es noch eine Menge Varianten der Anpassung für die geringe Fallzahl gibt. In der Anwendung nutzen wir die Funktion aus dem Paket `effectsize` wie hier durchgeführt.

Wir ignorieren wie auch bei Cohen's d das 95% Konfidenzintervall, da die Interpretation ohne die Nullhypothese nicht möglich ist. Die Nullhypothese ist in diesem Fall komplexer. Wir lassen daher das 95% Konfidenzintervall erstmal einfach hier so stehen.

```{r}
hedges_g(jump_length ~ animal, data = data_tbl, pooled_sd = TRUE)
```

Auch für Hedges' g gibt es die Möglichkeit sich über die Funktion `interpret_hedges_g()` den Wert von $g=0.21$ interpretieren zu lassen. Nach Sawilowsky (2009) haben wir hier einen kleinen Effekt vorliegen. Ob dieser Effekt relevant zur Fragestellung ist musst du selber entscheiden.

```{r}
interpret_hedges_g(0.21, rules = "sawilowsky2009")
```

[Die Hilfeseite zu dem Paket `effectsize`](https://easystats.github.io/effectsize/reference/interpret_cohens_d.html) bietet eine Liste an möglichen Referenzen für die Wahl der Interpretation der Effektstärke. Du musst dann im Zweifel schauen, welche der Quellen und damit Grenzen du nutzen willst.

## Unterschied zweier Anteile

[Eine Wahrscheinlichkeit und eine Chance sind nicht das Gleiche. Mehr in diesem Abschnitt.]{.aside}

Neben den Unterschied zweier Mittelwerte ist auch häufig das Interesse an dem Unterschied zwischen zwei Anteilen. Nun unterscheiden wir zwischen Wahrscheinlichkeiten und Chancen. Beide Maßzahlen, die Wahrscheinlichkeit wie auch die Chance, beschreiben einen Anteil. Hier tritt häufig Verwirrung auf, daher hier zuerst ein Beispiel.

Wir behandelt $n = 65$ Hunde mit dem Antiflohmittel *FleaEx*. Um die Wirkung von *FleaEx* auch bestimmen zu können haben wir uns zwei Gruppen von Hunden ausgesucht. Wir haben Hunde, die mit Flöhe infiziert sind und Hunde, die nicht mit Flöhen infiziert sind. Wir schauen nun in wie weit *FleaEx* gegen Flöhe hilft im Vergleich zu einer Kontrolle.

|              |           |                   |                   |
|:------------:|:---------:|:-----------------:|:-----------------:|
|              |           |     **Group**     |                   |
|              |           |     *FleaEx*      |     *Control*     |
| **Infected** | *Yes (1)* | $18_{\;\Large a}$ | $23_{\;\Large b}$ |
|              | *No (0)*  | $14_{\;\Large c}$ | $10_{\;\Large d}$ |

: Eine 2x2 Tabelle als Beispiel für unterschiedliche Flohinfektionen bei nach einer Behandlung mit *FleaEx* für die Berechnung von Effektschätzern eines Anteils. {#tbl-2x2-ratio-delta}

Aus der @tbl-2x2-ratio-delta können wir entnehmen, dass 18 behandelte Hunde mit Flöhen infiziert sind und 14 Hunde keine Infektion aufweisen. Bei den Hunden aus der Kontrolle haben wir 23 infizierte und 10 gesunde Tiere beobachtet.

[Es gibt verschiedene Typen von klinischen Studien, also Untersuchungen an Menschen. Einige Studien liefern nur $OR$ wieder andere Studientypen liefern $RR$.]{.aside}

Wir können nun zwei Arten von Anteilen berechnen um zu beschreiben, wie sich der Anteil an infizierten Hunden verhält. Das bekanntere ist die Frequenz oder Wahrscheinlichkeit oder Risk Ratio ($RR$). Das andere ist das Chancenverhältnis oder Odds Ratio ($OR$). Beide kommen in der Statistik vor und sind unterschiedlich zu interpretieren.

Um die die Odds Ratio und die Risk Ratios auch in R berechnen zu können müssen wir einmal die 2x2 Kreuzabelle in R nachbauen. Wir nutzen dafür die Funktion `matrix()` und müssen schauen, dass die Zahlen in der 2x2 Kreuztabelle in R dann auch so sind, wie in der Datentabelle. Das ist jetzt ein schöner Codeblock, ist aber dafür da um sicherzustellen, dass wir die Zahlen richtig eintragen.

```{r}
cross_mat <- matrix(c(18, 23, 14, 10),
  nrow = 2, byrow = TRUE,
  dimnames = list(
    Infected = c("Yes", "No"),
    Group = c("FleaEx", "Control")
  )
)

cross_mat
```

::: column-margin
@george2020s liefert eine gute Übersicht über *What's the risk: differentiating risk ratios, odds ratios, and hazard ratios?*
:::

Später werden wir das $OR$ und $RR$ wieder treffen. Das $OR$ kommt in der logistsichen Regression als Effektschätzer vor. Wir nutzen das $RR$ als Effektschätzer in der Poissonregression.

### Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)

Wir berechnen wir nun das Wahrscheinlichkeitsverhältnis oder Risk Ratio (RR)? Das Risk Ratio ist das Verhältnis von den infizierten Hunden in der Behandlung ($a$) zu allen infizierten Hunden ($a+c$) zu dem Verhältnis der gesunden Hunde in der Behandlung ($b$) zu allen gesunden Hunden ($b+d$). Das klingt jetzt etwas wirr, deshlab helfen manchaml wirklich Formeln, den Zusammenhang besser zu verstehen.

[$Pr(\mbox{FleaEx}|\mbox{infected})$ ist die Wahrscheinlichkeit infiziert zu sein, wenn der Hund mit *FleaEx* behandelt wurde.]{.aside}

$$
Pr(\mbox{FleaEx}|\mbox{infected}) = \cfrac{a}{a+c} = \cfrac{18}{18+14} \approx 0.56
$$

[$Pr(\mbox{Control}|\mbox{infected})$ ist die Wahrscheinlichkeit infiziert zu sein, wenn der Hund mit in der Kontrolle war.]{.aside}

$$
Pr(\mbox{Control}|\mbox{infected}) = \cfrac{b}{b+d} = \cfrac{23}{23 + 10} \approx 0.70
$$

Das Risk Ratio ist mehr oder minder das Verhältnis von der beiden Spalten der @tbl-2x2-ratio-delta für die Behandlung. Wir erhalten also ein $RR$ von $0.76$. Damit mindert die Gabe von *FleaEx* die Wahrscheinlichkeit sich mit Flöhen zu infizieren.

$$
\Delta_{y_1/y_2} = RR = \cfrac{Pr(\mbox{FleaEx}|\mbox{infected})}{Pr(\mbox{Control}|\mbox{infected})} =  \cfrac{0.56}{0.70} \approx 0.80 
$$

Wir überprüfen kurz mit der Funktion `riskratio()` ob wir richtig gerechnet haben. Das 95% Konfidenzintervall können wir interpretieren, dafür brauchen wir aber noch einmal eine Idee was "kein Effekt" bei einem Risk Ratio heist.

```{r}
riskratio(cross_mat)
```

Wann liegt nun kein Effekt bei einem Anteil wie dem RR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe.

$$
H_0: RR = \cfrac{Pr(\mbox{dog}|\mbox{infected})}{Pr(\mbox{cat}|\mbox{infected})} = 1
$$

Wir interpretieren das $RR$ nun wie folgt. Unter der Annahme, dass ein kausaler Effekt zwischen der Behandlung und dem Outcome besteht, können die Werte des relativen Risikos auf folgende Art und Weise interpretiert werden:

-   $RR = 1$ bedeutet, dass die Behandlung keinen Einfluss auf das Outcome hat
-   $RR < 1$ bedeutet, dass das Risiko für das Outcome durch die Behandlung verringert wird, was ein "Schutzfaktor" ist
-   $RR > 1$ bedeutet, dass das Risiko für das Outcome durch die Behandlung erhöht wird, was ein "Risikofaktor" ist.

Das heist in unserem Fall, dass wir mit einem RR von $0.80$ eine protektive Behandlung vorliegen haben. Die Gabe von *FleaEx* reduziert das Risiko mit Flöhen infiziert zu werden. Durch das 95% Konfidenzintervall wissen wir auch, dass das $RR$ nicht signifikant ist, da die 1 im 95% Konfidenzintervall enthalten ist.

### Chancenverhältnis oder Odds Ratio (OR)

Neben dem Risk Ratio gibt es noch das Odds Ratio. Das Odds Ratio ist ein Chancenverhältnis. Wenn der Mensch an sich schon Probleme hat für sich Wahrscheinlichkeiten richtig einzuordnen, scheitert man allgemein an der Chance vollkommen. Dennoch ist das Odds Ratio eine gute Maßzahl um abzuschätzen wie die Chancen stehen, einen infizierten Hund vorzufinden, wenn der Hund behandelt wurde.

Scaheun wir uns einmal die Formeln an. Im Gegensatz zum Risk Ratio, welches die Spalten miteinander vergleicht, vergleicht das Odds Ratio die Zeilen. Als erstes berechnen wir die Chance unter der Gabe von *FleaEx* infiziert zu sein wie folgt.

$$
Odds(\mbox{FleaEx}|\mbox{infected}) = a:b = 18:23 = \cfrac{18}{23} = 0.78
$$ Dann berechnen wir die Chance in der Kontrollgruppe infiziert zu sein wie folgt.

$$
Odds(\mbox{Control}|\mbox{infected}) = c:d = 14:10 = \cfrac{14}{10} \approx 1.40 
$$ Abschließend bilden wir das Chancenverhältnis der Chance unter der Gabe von *FleaEx* infiziert zu sein zu der Chance in der Kontrollgruppe infiziert zu sein. Es ergbit sich das Odds Ratio wie folgt.

$$
\Delta_{y_1/y_2} = OR =  \cfrac{Odds(\mbox{Flea}|\mbox{infected})}{Odds(\mbox{Control}|\mbox{infected})} = \cfrac{a \cdot d}{b \cdot c} = \cfrac{0.78}{1.40} \approx 0.56
$$

Wir überprüfen kurz mit der Funktion `oddsratio()` ob wir richtig gerechnet haben. Das 95% Konfidenzintervall können wir interpretieren, dafür brauchen wir aber noch einmal eine Idee was "kein Effekt" bei einem Odds Ratio heist.

```{r}
oddsratio(cross_mat)
```

Wann liegt nun kein Effekt bei einem Anteil wie dem OR vor? Wenn der Anteil in der einen Gruppe genauso groß ist wie der Anteil der anderen Gruppe.

$$
H_0: OR =  \cfrac{Odds(\mbox{dog}|\mbox{infected})}{Odds(\mbox{cat}|\mbox{infected})} = 1
$$

Wir interpretieren das $OR$ nun wie folgt. Unter der Annahme, dass ein kausaler Effekt zwischen der Behandlung und dem Outcome besteht, können die Werte des Odds Ratio auf folgende Art und Weise interpretiert werden:

-   $OR = 1$ bedeutet, dass die Behandlung keinen Einfluss auf das Outcome hat
-   $OR < 1$ bedeutet, dass sich die Chance das Outcome zu bekommen durch die Behandlung verringert wird, was ein "Schutzfaktor" ist
-   $OR > 1$ bedeutet, dass sich die Chance das Outcome zu bekommen durch die Behandlung erhöht wird, was ein "Risikofaktor" ist.

Das heist in unserem Fall, dass wir mit einem OR von $0.56$ eine protektive Behandlung vorliegen haben. Die Gabe von *FleaEx* reduziert die Chance mit Flöhen infiziert zu werden. Durch das 95% Konfidenzintervall wissen wir auch, dass das $OR$ nicht signifikant ist, da die 1 im 95% Konfidenzintervall enthalten ist.

### Odds Ratio (OR) zu Risk Ratio (RR)

::: column-margin
@grant2014converting gibt nochmal eine wissenschaftliche Diskussion des Themas zur Konvertierung von OR zu RR.
:::

Wenn wir das OR berechnet haben, wollen wir eventuell das $OR$ in dem Sinne eines Riskoverhältnisses berichten. Leider ist es nun so, dass wir das nicht einfach mit einem $OR$ machen können. Ein $OR$ von 3.5 ist ein großes Chancenverhältnis. Aber ist es auch 3.5-mal so wahrscheinlich? Nein so einfach können wir das OR nicht interpretieren. Wir können aber das $OR$ in das $RR$ umrechnen. Dafür brauchen wir aber das $p_0$. Dabei ist das $p_0$ das Basisrisiko also die Wahrscheinlichkeit des Ereignisses ohne die Intervention. Wenn wir nichts tun würden, wie wahrscheinlich wäre dann das Auftreten des Ereignisses? Es ergibt sich dann die folgende Formel für die Umrechnung des $OR$ in das $RR$.

$$
RR = \cfrac{OR}{(1 - p_0 + (p_0 \cdot OR))}
$$

Schauen wir uns das einmal in einem Beispiel an. Wir nutzen für die Umrechnung die Funktion `oddsratio_to_riskratio()` aus dem R Paket `effectsize`. Wenn wir ein $OR$ von 3.5 haben, so hängt das $RR$ von dem Basisriskio ab. Wenn das Basisirisko für die Erkrankung ohne die Behandlung sehr hoch ist mit $p_0 = 0.85$, dann ist das $RR$ sehr klein.

```{r}
OR <- 3.5
baserate <- 0.85

oddsratio_to_riskratio(OR, baserate) %>% round(2)
```

Auf der anderen Seite nähert sich das $OR$ dem $RR$ an, wenn das Basisriskio für die Erkrankung mit $p_0 = 0.04$ sehr klein ist.

```{r}
OR <- 3.5
baserate <- 0.04

oddsratio_to_riskratio(OR, baserate) %>% round(2)
```

Weil wir natürlich das Basisrisiko nur abschätzen können, verbleibt hier eine gewisse Unsicherheit, wie das $RR$ zu einem gegebenen $OR$ aussieht.

## Wirkungsgrad von Pflanzenschutzmitteln

Neben den klassischen Effektmaßzahlen, die sich aus einem Mittelwert oder einem Anteil direkt berechnen, gibt es noch andere Effektmaße. Einer dieser Effektmaße ist der Wirkungsgrad für zum Beispiel ein Pflanzenschutzmittel. Wir können hier aber auch weiter denken und uns überlegen in wie weit wir eine Population von Schaderregern durch eine Behandlung reduzieren können. Unabdingbar ist in diesem Fall eine positive Kontrolle in der nichts gemacht wird sondern nur der normale Befall gemessen wird. Wir berechnen hier den Wirkungsgrad nach @abbott1925method mit der Anpassung von @finner1989berechnung. Der Wirkungsgrad $WG$ eines Schutzmittels im Vergleich zur Kontrolle berechnet sich wie folgt.

$$
WG = \left(\cfrac{X_n - Y_n}{X_n}\right)
$$

mit

-   $Y_n$ Anzahl lebend in der Behandlung
-   $X_n$ Anzahl lebend in der Kontrolle

Natürlich ist die Formel wieder sehr abstrakt, deshalb haben wir zwei Beispieldaten. Zuerst schauen wir uns einen Datensatz zu dem Befall mit Trespe an. Wir haben also Parzellen in denen sich die Trespe ausbreitet und haben verschiedene Behandlungen durchgeführt. Wichtig hierbei, wir haben auch Parzellen wo wir nichts gemacht haben, das ist dann unsere positive Kontrolle (*ctrl*). Da unsere Daten nicht im Long-Format vorliegen müssen wir die Daten erst noch anpassen und dann die Spalte `block` in einen Faktor umwandeln.

```{r}
trespe_tbl <- read_excel("data/raubmilben_data.xlsx", sheet = "trespe") %>% 
  pivot_longer(block_1:block_4,
               names_to = "block",
               values_to = "count") %>% 
  mutate(block = factor(block, labels = 1:4),
         variante = as_factor(variante))
```

In der @fig-effect-1 sehen wir nochmal die orginalen, untransformierten Daten sowie die log-transformierten Daten.

```{r}
#| echo: true
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| label: fig-effect-1
#| fig-cap: "Dotplot der Anzahl an Trespen je Sorte und Block."
#| fig-subcap: 
#|   - "Verteilung der Werte auf der originalen Skala."
#|   - "Verteilung der Werte auf der logarithmischen Skala. Beobachtungen mit einer 0 Zählung wurden auf 1 gesetzt."
#| layout-nrow: 1
#| column: page

ggplot(trespe_tbl, aes(variante, count, fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  labs(x = "Behandlungsvariante", y = "Anzahl", fill = "Block") +
  scale_fill_okabeito()
  
ggplot(trespe_tbl, aes(variante, log1p(count), fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  labs(x = "Behandlungsvariante", y = "log(Anzahl)", fill = "Block") +
  scale_fill_okabeito()
  
```

```{r}
#| message: false
#| warning: false

fit <- glm(count ~ variante + block, data = trespe_tbl, family = poisson)
```

```{r}
#| message: false
#| warning: false
fit %>% 
  emmeans(~variante, type = "response") %>% 
  tidy() %>% 
  mutate(WG_abbott = percent((rate[1] - rate)/rate[1])) %>% 
  select(variante, rate, WG_abbott)
```

Im zweiten Beispiel wollen wir uns mit dem geometrischen Mittel $WG_{geometric}$ als Schätzer für den Wirkungsgrad beschäftigen. Hier kochen wir dann einmal die Veröffentlichung von @finner1989berechnung nach. Dafür brauchen wir einmal die Daten zu den Raubmilben, die ich schon als Exceldatei aufbereitet habe. Wie immer sind die Rohdaten im Wide-Format, wir müssen aber im Long-Format rechnen. Da bauen wir uns also einmal schnell die Daten um. Dann wollen wir noch die Anzahlen der Raubmilben logarithmieren, so dass wir jede Anzahl um 1 erhöhen um logarithmierte Nullen zu vermeiden. Das ganze machen wir dann in einem Rutsch mit der Funktion `log1p()`.

```{r}
mite_tbl <- read_excel("data/raubmilben_data.xlsx", sheet = "mite") %>% 
  pivot_longer(block_1:block_5,
               names_to = "block",
               values_to = "count") %>% 
  mutate(block = factor(block, labels = 1:5),
         sorte = as_factor(sorte),
         log_count = log1p(count))
```

Schauen wir uns einmal die Daten in der @fig-effect-2 an.

```{r}
#| echo: true
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 3
#| fig-width: 5
#| label: fig-effect-2
#| fig-cap: "Dotplot der Anzahl an Raubmilden je Sorte und Block."
#| fig-subcap: 
#|   - "Verteilung der Werte auf der originalen Skala."
#|   - "Verteilung der Werte auf der logarithmischen Skala. Beobachtungen mit einer 0 Zählung wurden auf 1 gesetzt."
#| layout-nrow: 1
#| column: page

ggplot(mite_tbl, aes(sorte, count, fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  labs(x = "Sorten", y = "Anzahl", fill = "Block") +
  scale_fill_okabeito()
  
ggplot(mite_tbl, aes(sorte, log1p(count), fill = block)) +
  theme_bw() +
  geom_dotplot(binaxis = "y", stackdir = "center") +
  labs(x = "Sorten", y = "log(Anzahl)", fill = "Block") +
  scale_fill_okabeito()
  
```

Wir brauchen jetzt eine Helferfunktion, die uns aus $Pr$ die Gegenwahrscheinlichkeit $1 - Pr$ berechnet. Auch wollen wir dann die Prozentangabe der Gegenwahrscheinlichkeit, also die Gegenwahrscheinlichkeit $1 - Pr$ multipliziert mit Einhundert. Dann brauchen wir als Variable noch die Gruppengröße $n_g$, die bei uns ja bei 5 liegt. Wir haben pro Sorte fünf Beobachtungen je Block.

```{r}
get_q <- function(x){100 * (1 - x)}
n_group <- 5
```

$$
\Delta_{geometric} = \left(\cfrac{\prod_{i=1}^n y_j}{\prod_{i=1}^n y_{ctrl}}\right)^{1/n_g} \mbox{ mit Sorte } j 
$$

```{r}
residual_tbl <- lm(log_count ~ sorte + block, data = mite_tbl) %>% 
  glance() %>% 
  select(df.residual, sigma)
residual_tbl
```

```{r}
t_quantile <- qt(p = 0.05, df = residual_tbl$df.residual, lower.tail = FALSE)
t_quantile
```

```{r}
mite_tbl %>% 
  mutate(count = count + 1) %>% 
  group_by(sorte) %>% 
  summarise(prod = prod(count)) %>% 
  mutate(tau = (prod/prod[9])^(1/n_group),
         WG_geometric = get_q(tau),
         a = sqrt(2/n_group) * residual_tbl$sigma * t_quantile + log(tau),
         KI = get_q(exp(a)))
```

$$
[-\infty; a] 
$$

$$
a = \sqrt{2/n} \cdot s \cdot t_{(t-1)(n-1),\,\alpha} + \ln(1 - GM)
$$

```{r}
#| message: false
#| warning: false

fit <- glm(count ~ sorte + block, data = mite_tbl, family = poisson)
```

```{r}
#| message: false
#| warning: false
fit %>% 
  emmeans(~sorte, type = "response") %>% 
  tidy() %>% 
  mutate(WG_abbott = percent((rate[9] - rate)/rate[9])) 

fit %>% 
  emmeans(~sorte, type = "link") 

```

## Referenzen {.unnumbered}
