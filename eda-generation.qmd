```{r echo = FALSE}
#| warning: false
#| message: false
pacman::p_load(tidyverse, readxl, knitr, kableExtra, see, modelr, ggforce,
               latex2exp, patchwork, parsnip, ggdag, ggimage, conflicted)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
conflicts_prefer(dplyr::filter)
set.seed(20250701)
theme_modeling <- function() {
  theme_minimal() +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(size = 16, face = "bold"),
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.caption = element_text(face = "italic"),
          axis.title = element_text(size = 12, face = "bold"),
          axis.text = element_text(size = 12),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

```{r}
#| eval: true
#| echo: false
#| cache: true
#| message: false
#| warning: false
#| label: sim-mean-samplesize
source("simulation/sim-gen-data-mean.R")
```

```{r}
#| echo: false
#| message: false
#| warning: false
source("images/R/stat-modeling-R.R")
source("images/R/eda-generation.R")
```

# Generierung von Daten {#sec-eda-gen-data}

*Letzte Änderung am `r format(fs::file_info("eda-generation.qmd")$modification_time, '%d. %B %Y um %H:%M:%S')`*

> *"Je größer die Insel des Wissens, desto größer der Strand der Verzweiflung." --- unbekannt*

![](images/caution.png){fig-align="center" width="100%"}

::: {.callout-caution appearance="simple"}
## Stand des Kapitels: Konstruktion

Dieses Kapitel wird in den nächsten Monaten geschrieben und ist damit eine zukünftige Großbaustelle. Ich plane zum Beginn des SoSe 2026 eine fertige Version des Kapitels erstellt zu haben. Während das Kapitel entsteht, funktioniert so manches dann nicht so wie es soll. Bitte daher hier dann abwarten.
:::

In diesem Kapitel geht es um die Erstellung von zufälligen Daten. Oder anderherum, wir wollen uns künstliche Daten (eng. *artificial data* oder eng. *synthetic data*) generieren. Warum machen wir das? Eine Frage, die sich vermutlich kein Statistiker oder Date Scientist stellen würde, ist es doch Teil der wissenschaftlichen Arbeit simulierte Daten zu erstellen. Auf diesen simulierten Daten werden dann die neuen entwickelten Algorithmen getestet. Für Menschen außerhalb der Data Science mag es seltsam erscheinen, dass wir uns einfach Daten erschaffen können. Diese synthetischen Daten kommen dann aber den biologischen Daten manchmal recht Nahe. Daher kannst auch du dir deine Daten theoretisch einfach selber bauen, nachdem du dieses Kapitel gelesen hast.

::: callout-warning
## Achtung, bitte beachten!

> *"With great power comes great responsibility." --- Uncle Ben to Peter Parker in Spiderman*

Keine Daten für die Abschlussarbeit erschaffen. Auch wenn die Daten mal nicht so passen, wie du dir das aus einem Experiment erhofft hast, ist es nicht erlaubt sich einfach die Daten selber zu simulieren. Simulierte Daten haben keinen wissenschaftlichen Wert abseits der Validierung von neuen Algorithmen.

Was du aber machen *kannst*, ist deine experimentellen Daten schon mal im Design vorbauen um deine Analyse in R vorzurechnen. Wenn du dann aus deinem Experiment die echten Daten vorliegen hast, kannst du dann schneller die Analysen rechnen. Du hast dann ja schon alles einmal geübt und vorgearbeitet.
:::

Daher nutzen wir diesen Kapitel auch anders. Wir erschaffen uns ja Daten um Algorithmen zu verstehen. Wenn wir wissen wie die Daten aufgebaut sind, dann können wir auch besser verstehen was uns ein Modell oder ein statistischer Test wiedergibt. Dafür brauchen wir dann die synthetischen Daten. Eine andere Möglichkeit ist, dass du einmal ausprobieren möchtest, wie eine potenzielle Analyse ablaufen würde. Dann macht es auch Sinn einmal über künstliche Daten nachzudenken. Ich komme dann immer mal wieder auf dieses Kapitel zurück, wenn ich in anderen Kapiteln mal künstliche Daten brauche. Wir schauen uns verschiedene Wege künstliche Daten zu erschaffen einmal an und es geht auch in Excel relativ einfach.

## Allgemeiner Hintergrund

> *"We test our framework both on synthetic data, as the only source of ground truth on which we can objectively assess the performance of our algorithms, as well as on real data to demonstrate its real-world practicability." --- @jackson2009intelligent*

Wenn wir Daten generieren wollen, dann müssen wir auch wissen, was wir genieren wollen. Dafür müssen wir dann verstehen, wovon wir sprechen. Da wir es bei der Datengenerierung auch immer mit statistischen Modellen zu tun haben, müssen wir auch die Fachsprache der statistischen Modellierung nutzen. Dann wollen wir verstehen, was wir eigentlich simulieren. Klar, wir simulieren Daten, aber was brauchen wir dafür an statistischen Maßzahlen? Ich betrachte dann nochmal die Einschränkungen dieses Kapitels, denn wir können natürlich hier nicht alles simulieren, was möglich ist. Faktisch konzentrieren wir uns hier auf häufige Datenstrukturen in den Agrawissenschaften. Dann zeige stelle ich dir nochmal kurz die zwei R Pakete vor, die wir dann hier nutzen können.

#### Sprachlicher Hintergrund {.unnumbered .unlisted}

> *"In statistics courses taught by statisticians we don't use independent variable because we use independent on to mean stochastic independence. Instead we say predictor or covariate (either). And, similarly, we don't say "dependent variable" either. We say response." --- [User berf auf r/AskStatistics](https://www.reddit.com/r/AskStatistics/comments/qt1hvu/comment/hkigiks/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)*

Wenn wir uns mit dem statistischen Modellieren beschäftigen wollen, dann brauchen wir auch Worte um über das Thema reden zu können. Statistik wird in vielen Bereichen der Wissenschaft verwendet und in jedem Bereich nennen wir dann auch Dinge anders, die eigentlich gleich sind. Daher werde ich mir es hier herausnehmen und auch die Dinge so benennen, wie ich sie für didaktisch sinnvoll finde. Wir wollen hier was verstehen und lernen, somit brauchen wir auch eine klare Sprache.

::: {layout="[15,85]" layout-valign="top"}
![](images/personal_opinion.png){fig-align="center" width="100%"}

> *"Jeder nennt in der Statistik sein Y und X wie er möchte. Da ich hier nicht nur von Y und X schreiben will, führe ich eben die Worte ein, die ich nutzen will. Damit sind die Worte dann auch richtig, da der Kontext definiert ist. Andere mögen es dann anders machen. Ich mache es eben dann so. Danke." --- Jochen Kruppa-Scheetz, meiner bescheidener Meinung nach.*
:::

In dem folgenden Kasten erkläre ich nochmal den Gebrauch meiner Begriffe im statistischen Modellieren als Grundlage für die Generierung von Daten. Es ist wichtig, dass wir hier uns klar verstehen. Zum einen ist es angenehmer auch mal ein Wort für ein Symbol zu schreiben. Auf der anderen Seite möchte ich aber auch, dass du dann das Wort richtig einem Konzept im statistischen Modellieren zuordnen kannst. Deshalb einmal hier meine persönliche und didaktische Zusammenstellung meiner Wort im statistischen Modellieren. Du kannst dann immer zu dem Kasten zurückgehen, wenn wir mal ein Wort nicht mehr ganz klar ist. Die fetten Begriffe sind die üblichen in den folgenden Kapiteln. Die anderen Worte werden immer mal wieder in der Literatur genutzt.

{{< include stat-modeling/stat-modeling-callout-words.qmd >}}

#### Effekt, Streuung und Fallzahl {.unnumbered .unlisted}

Was brauchen wir um Daten zu generieren? Wir brauchen einen Effekt, eine Streuung der generierten Date um den Mittelwert sowie die Fallzahl als Anzahl an Beobachtungen. Dann müssen wir noch entscheiden aus welcher Verteilung unsere Daten kommen sollen. In dem folgenden Venndiagramm habe ich dir nochmal den Dreiklang der drei statistischen Eigeschaften für die Generierung von Daten zusammengefasst. Wir müssen uns also klar werden, welchen Effekt wir simulieren wollen, welche Streuung in den Daten vorliegen soll und natürlich wie viele Beobachtungen wir in den generierten Daten vorfinden wollen.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 6
#| fig-width: 7
#| fig-cap: "Was wird benötigt um Daten zu generieren? Der Effekt beschreibt den Unterschied zwischen Gruppen oder spezieller den Mittelwert in einer Normalverteilung. Die Streuung beschreibt die Unsicherheit in den Daten oder eben die Standardabweichung. Über die Fallzahl wird definiert wie viele Beobachtungen erstellt werden sollen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-venn

p_venn_gen
```

Wir machen wir das jetzt praktisch in R. Dazu haben wir verschiedene Möglichkeiten, wir beginnen hier einmal mit der simplesten Form. Mit der Funktion `rnorm()` können wir uns zufällige Daten aus einer theoretischen Normalverteilung ziehen. Es gibt natürlich noch viel mehr `r*`-Funktionen für die Generierung von Daten. Die Seite [Probability Distributions in R](https://www.stat.umn.edu/geyer/old/5101/rlook.html) zeigt nochmal einen großen Überblick. Im [Kapitel zu den Verteilungen](#sec-distribution) findest du dann auch nochmal mehr Informationen zu den einzelnen Funktionen.

Fangen wir aber einmal mit der einfachen Funktion für die Normalverteilung an. Hier genieren wir uns also einmal fünf Beobachtungen aus einer Normalverteilung. Wir brauchen dafür die Fallzahl (`n`), die wir generieren wollen. Dann den Mittelwert der theoretischen Verteilung (`mean`) sowie die Streuung (`sd`). Dann erhalten wir fünf Zahlen, die in der Gesamtheit den vorgestellten Zahlen entsprechen.

```{r}
rnorm(n = 5, mean = 0, sd = 1) |> round(2)
```

Wenn wir jetzt den Mittelwert der fünf Zahlen berechnen, dann erhalten wir aber gar nicht einen Mittelwert von $0$ und auch nicht eine Standardabweichung von $1$ wieder. Wie kann das sein? Häufig stolperst du hier ein wenig. Wieso Daten generieren, wenn die Daten dann nicht die Eigenschaften haben, die wir wollen? Hier kommt die Grundgesamtheit und die Stichprobe ins Spiel. In der Grundgesamtheit hast du einen Mittelwert von $2$ und eine Standardabweichung von $1$ vorliegen. Du ziehst aber nur eine kleine Stichprobe wie ich dir einmal in der folgenden Abbildung zeige. Zwar liegt der theoretische Mittelwert auf der Null, aber die Mittelwerte der einzelnen Simulationen können stark variieren.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7
#| fig-cap: "Visualisierung der Abweichung des beobachteten Mittelwerts von dem theoretischen Mittelwert der Verteilung. Fünf Simulationen mit je fünf Beobachtungen wurden durchgeführt und jeweils der Mittelwert berechnet. Die Beobachtungen wurde aus einer Standardnormalverteilung mit $\\mathcal{N}(0, 1)$ gezogen. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-normal

p_theo_observed
```

Der Zusammenhang wird dir vielleicht dann nochmal in der folgenden Abbildung klarer. Ich habe hier einmal eine kleine Simulation laufen lassen. Dabei habe ich immer Daten aus einer Standardnormalverteilung mit einem Mittelwert von $0$ und einer Standardabweichung von $1$ generiert. Was ich dabei geändert habe ist die Fallzahl. Wenn ich nur zwei Beobachtungen generiere, dann finde ich eine große Breite an beobachteten Mittlwerten. Wenn ich die Fallzahl erhöhe, dann komme ich immer näher an den erwarteten Mittelwert in meinen beobachteten Daten heran. Bei eintausend Beobachtungen habe ich faktisch kaum noch eine Abweichung vorliegen. Hier siehst du eben, es kommt auch stark auf die Fallzahl an. Wenn du dir zu wenig Beobachtungen anschaust, dann wirst du nicht immer den theoretischen Mittelwert oder Effekt in den generierten Daten wiederfinden.

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7.5
#| fig-cap: "Zusammenhang zwischen der simulierten Anzahl an Beobachtungen und dem beobachteten Mittelwert zu dem theoretischen Mittelwert der Verteilung aus der die Beobachtungen generiert wurden. Die Beobachtungen wurde aus einer Standardnormalverteilung mit $\\mathcal{N}(0, 1)$ gezogen. Es wurden 1000 Simulationen durchgeführt. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-mean-sim

p1_mean + p2_mean +
  plot_layout(ncol = 2, widths = c(7, 1)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Einschränkungen bei der Generierung {.unnumbered .unlisted}

Wir konzentrieren uns hier nur auf einen kleinen Teil der möglichen Simulationen und Datengenerierungen. Das hat neben der vielen möglichen Verteilungen auch den Grund, dass wir usn hier ja nicht mit der algorithmischen Modellentwicklung in der Statistik beschäftigen wollen. Wir wollen ja nicht neue Algorithmen bauen und diese dann auf Daten evaluieren. Daher konzentrieren wir uns hier auf wenige Verteilungen, die dann aber das abbilden, was wir häufig brauchen.

-   Die **Normalverteilung** erlaubt uns das Frischegewicht, Trockengewicht oder aber Chlorophyllgehalt zu simulieren. Also im Prinzip die Messwerte, die wir hauptsächlich in einem agrawissenschaftlichen Umfeld erheben.
-   Die **Possionverteilung** erlaubt uns alles was wir Zählen zu simulieren. Also im Prinzip alle Anzahlen von Schädlingen oder aber Blütenstände sowie Blättern. Wir zählen hier eben etwas.
-   Die **Ordinalverteilung** ist dafür gut, wenn wir Noten simulieren wollen. Daher brauchen wir die Ordinalverteilung um unsere Boniturnoten zu generieren. Prinzipiell aber auch die Antwortverteilungen in einem Fragebogen.
-   Die **Binomialverteilung** ist die Verteilung, die wir nutzen, wenn wir nur zwei mögliche Messwerte haben. Also im prinzip gesunde Beobachtung oder kranke Beobachtung. Wir haben nur zwei Ausprägungen in dem Messwert vorliegen.

Neben den vorgestellten Verteilungen schauen wir uns dann noch die Simulation von **pseudo Zeitreihen** an. Wir haben hier dann verschiedene Messwerte über einen zeitlichen Verlauf vorliegen. Teilweise dann in einer etwas wirren Form, da wir eventuell keinen linearen Zusammenhang mehr vorliegen haben. Daher müssen wir dann hier etwas mehr schauen, dass wir die Daten gut simuliert kriegen.

#### Welche Möglichkeiten gibt es eigentlich? {.unnumbered .unlisted}

Wenn wir Daten generieren wollen, dann haben wir im Prinzip zwei Möglichkeiten. Wir bauen uns die Daten selber per Hand in Excel oder aber nutzen die entsprechenden R Pakete. Ich stelle hier die zwei größeren R Pakete vor sowie die Lösungen per Hand in Excel. Wir haben natürlich auch die Möglichkeit die Daten in R ohne Pakete zu erstellen. Das macht in einem einfacheren Setting auch mehr Sinn.

-   Das [R Paket `{simstudy}`](https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html) liefert eigentlich alles was wir brauchen, wenn die Daten komplizierter werden. Insbesondere wenn wir keinen normlaverteilten Messwert vorliegen haben oder aber abhängige Einflussvariablen. Wenn ich größere Datensätze generiere, dann nutze ich gerne dieses Paket.
-   Das [R Paket `{simdata}`](https://cran.r-project.org/web/packages/simdata/vignettes/Demo.html) hat den Vorteil große, komplexe Koreelationsstrukturen abzubilden. Wir können hier Netzwerkeffekte gut darstellen und dann auch in einen Datensatz übersetzen. Auch Transformationen von Daten lassen sich hier gut integrieren. Hier liegt aber nicht der Fokus auf einem faktoriellen Design mit Gruppeneffekten.
-   Wir schauen uns natürlich auch Excel an. Hier haben wir natürlich gleich die Möglichkeit uns die Daten dort zu bauen, wo wir die erhobenen Messwerte dann später nach dem durchgführten Experiment auch abspeichern. Deshalb zeige ich auch hier einmal wie wir dann die Daten händisch aufbauen.

Abschließend muss ich noch erwähnen, dass faktorielle Designs, die wir dann häufig in den Agrarwissenschaften finden, wir am besten dann händsich in R zusammenbauen. Wir nutzen dann die Funktionen, die es schon in R gibt und erstellen uns dann selber den Datensatz. Das ist im Prinzip so ähnlich wie in Excel nur das wir etwas besser nachvollziehbare Wege haben.

## Theoretischer Hintergrund

#### Effekt und Streuung {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 7
#| fig-width: 9
#| fig-cap: "foo. **(A)** foo. **(B)** foo. **(C)** foo. **(D)** foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-square-cov

p1_square_cov + p2_square_cov + p3_square_cov + p4_square_cov +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 7
#| fig-width: 9
#| fig-cap: "foo. **(A)** foo. **(B)** foo. **(C)** foo. **(D)** foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-square-fac

p1_square_fac + p2_square_fac + p3_square_fac + p4_square_fac +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.7
#| fig-width: 7
#| fig-cap: "Erweiterte Darstellung der statistischen Modellierung. Die Messwerte $Y$ folgen einer Verteilung. Die Einflussvariablen liegen kontinuierlich als Kovariaten oder aber kategorial als Faktoren vor. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-02

p_lhs_rhs_detail
```

#### Welche Effekte gibt es? {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 7.5
#| fig-cap: "Darstellung eines einfaktoriellen Datensatzes als Säulendiagramm (eng. *barplot*) mit zwei Gruppen und unterschiedlichen Mittelwerten bei gleicher Varianz für einen normalverteilten Messwert. Der Effekt ist hier die Mittelwertsdifferenz. **(A)** foo. **(B)** foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-03

p_barplot_intro + p_effect_intro + 
  plot_layout(ncol = 2, widths = c(1, 2)) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 4.5
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-05

p_rr_or
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 5
#| fig-width: 10.5
#| fig-cap: "foo. **(A)** foo. **(B)** foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-07-foo

p_rr + p_or +
  plot_layout(ncol = 2) +
  plot_annotation(tag_levels = 'A', tag_prefix = '(', tag_suffix = ')') &
  theme(plot.tag = element_text(size = 16, face = "bold"))
```

#### Theoretische Verteilung vs. selbst gebaute Verteilung {.unnumbered .unlisted}

[Wilcoxon is (almost) a one-sample t-test on signed ranks](https://lindeloev.github.io/tests-as-linear/simulations/simulate_wilcoxon.html)

```{r}
own_dist_tbl <- tibble(y = c(rnorm(10000), 
                             exp(rnorm(10000)), 
                             runif(10000, min=-3, max=-2)))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 3.5
#| fig-width: 7
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-own-dist

own_dist_tbl |> 
  ggplot(aes(y)) +
  theme_modeling() +
  geom_histogram(bins = 200, fill = "#56B4E9", color = "black") +
  scale_x_continuous(limits = c(-4, 10)) +
  labs(x = "Messwert (y)", y = "Anzahl")
```

::: callout-tip
## Weitere Tutorien für die Genierung von Daten

Wir immer geht natürlich mehr als ich hier Vorstellen kann. Du findest im Folgenden Tutorien, die mich hier in dem Kapitel inspiriert haben. Ich habe mich ja in diesem Kapitel auf die Durchführbarkeit in R und die allgemeine Verständlichkeit konzentriert.

-   Einen guten Überblick liefert Brad Duthie in seinem Tutorium [Creating simulated data sets in R](https://stirlingcodingclub.github.io/simulating_data/index.html). Hier kannst du dich dann nochmal in die Grundlagen einlesen.
-   Auch Excel kann künstliche Daten generieren. Dafür schaue ich dann immer in die [statistischen Funktionen (Referenz)](https://support.microsoft.com/de-de/office/statistische-funktionen-referenz-624dac86-a375-4435-bc25-76d659719ffd) Seite nach. Die Seite ist leider etwas schwer zu lesen.
-   [Getting started simulating data in R: some helpful functions and how to use them](https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/)
-   [The distribution zoo](https://ben18785.shinyapps.io/distribution-zoo/) und [Probability Distributions in R](https://www.stat.umn.edu/geyer/old/5101/rlook.html) oder [Plotting Continuous Probability Distributions In R With ggplot2](https://dk81.github.io/dkmathstats_site/rvisual-cont-prob-dists.html)
:::

## Genutzte R Pakete

Wir wollen folgende R Pakete in diesem Kapitel nutzen.

```{r echo = TRUE}
#| message: false
pacman::p_load(tidyverse, simstudy, simdata, modelr, 
               ggpmisc, conflicted)
set.seed(20250820)
conflicts_prefer(ggplot2::annotate)
```

An der Seite des Kapitels findest du den Link *Quellcode anzeigen*, über den du Zugang zum gesamten R-Code dieses Kapitels erhältst.

## Simulationen

[The distribution zoo](https://ben18785.shinyapps.io/distribution-zoo/)

::: callout-warning
## Achtung, bitte beachten!

Die Erstellung von Daten in Excel ist nicht für die *wissenschaftliche* Bewertung von Algorithmen sinnvoll und angebracht. Wir nutzen hier Excel um recht einfach uns zufällig Daten zu erstellen. Wir nutzen dann die künstlichen Exceldaten um unsere Analyse für unsere echten experimentelle Daten zu üben. Auch ist die vereinfachte Erstellung von künstlichen Daten in Excel hilfreich um die zugrundeliegende Konzepte nochmal zu verstehen.
:::

@dormann2013parametrische

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-fac1-excel

tibble(x = 0:10, y = 0:10) |> 
  ggplot(aes(x, y)) +
  xlim(c(0, 10)) + ylim(c(0, 10)) +
  theme_void() +
  geom_image(data = tibble(x = 5, y = 4.6),
             aes(image = "images/gen-data-fac1-excel.png"), size = 0.8) 

```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 8
#| fig-cap: "foo. *[Zum Vergrößern anklicken]*"
#| label: fig-gen-data-fac2-excel

tibble(x = 0:10, y = 0:10) |> 
  ggplot(aes(x, y)) +
  xlim(c(0, 10)) + ylim(c(0, 10)) +
  theme_void() +
  geom_image(data = tibble(x = 5, y = 4),
             aes(image = "images/gen-data-fac2-excel.png"), size = 1.1) 

```

### Normalverteilter Messwert

#### Einfaktoriell $f_A$ mit 2 Leveln {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f1lvl2-theo

p_1fac_2lvl_model
```

```{r}
fac1_tbl <- tibble("1" = rnorm(5, 3, 0.001),
                   "2" = rnorm(5, 6, 0.001)) |> 
  gather(key = "f_a", value = "y")
```

```{r}
lm(y ~ f_a, fac1_tbl) |> coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-1

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 3, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Einfaktorielle Simulation mit 2 Leveln",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)")
```

#### Einfaktoriell $f_A$ mit \>2 Leveln {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f1lvl3-theo

p_1fac_3lvl_model
```

```{r}
fac1_tbl <- tibble("1" = rnorm(5, 2, 0.001),
                   "2" = rnorm(5, 6, 0.001),
                   "3" = rnorm(5, 4, 0.001)) |> 
  gather(key = "f_a", value = "y")
```

[R Library Contrast Coding Systems for categorical variables](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

::: panel-tabset
## Treatment coding (default) {.unnumbered .unlisted}

*Treatment coding* mit `contr.treatment` (default)

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.treatment")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-21

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 2, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Treatment coding",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)")
```

## Effect coding

*Effect coding* mit `contr.sum`

```{r}
lm(y ~ f_a, fac1_tbl, contrasts = list(f_a = "contr.sum")) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-model-in-R-fa-22

ggplot(fac1_tbl, aes(f_a, y)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 4, linewidth = 0.5, color = "#CC79A7") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Effect coding",
       subtitle = "Intercept ist der globale Mittelwert",
       x = "Faktor A", y = "Messwert (Y)")
```
:::

#### Zweifaktoriell ohne Interaktion $f_A + f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2nointer-theo

p_2fac_nointer_model +
  labs(title = "") 
```

```{r}
fac2_nointer_tbl <- tibble(f_a = rep(gl(3, 5), 2),
                           f_b = gl(2, 15),
                           y = 2 + 
                             2 * as.numeric(f_a) + 
                             3 * as.numeric(f_b) + 
                             rnorm(15, 0, 0.001))
```

```{r}
lm(y ~ f_a + f_b, fac2_nointer_tbl) |> 
  coef() |> round(2)
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2nointer

ggplot(fac2_nointer_tbl, aes(f_a, y, color = f_b)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 7, linewidth = 0.5, color = "#CC79A7") +
  geom_abline(intercept = 8, slope = 2, color = "#56B4E9") +
  geom_abline(intercept = 5, slope = 2, color = "#E69F00") +
  geom_point() +
  stat_summary(fun = "mean", geom = "label", 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Zweifaktorielle Simulation",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)", color = "Faktor B") +
  scale_color_okabeito(label = c("B.1", "B.2")) +
  theme(legend.position = "top")
```

#### Zweifaktoriell mit Interaktion $f_A + f_B + f_A \times f_B$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kategorialen Einflussvariablen als Faktor $f_A$ mit drei Leveln sowie einer kategorialen Einflussvariablen als Faktor $f_B$ mit zwei Leveln und deren Interaktion $f_A \\times f_B$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2inter-theo

p_2fac_model +
  labs(title = "") 
```

```{r}
fac2_tbl <- expand_grid(f_a = 1:3, f_b = 1:2, rep = 1:1000) |> 
  mutate(f_a = as_factor(f_a),
         f_b = as_factor(f_b))

fac2_mat <- fac2_tbl |> 
  model_matrix(~ f_a * f_b) |> 
  as.matrix()

eff_vec <- c(7, 2, 4, 3, 0, -6)

eff <- fac2_mat %*% eff_vec 

fac2_inter_tbl <- fac2_tbl |> 
  mutate(y = eff + rnorm(length(eff), 0, 0.001))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4.5
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-f2inter

ggplot(fac2_inter_tbl, aes(f_a, y, color = f_b, group = f_b)) +
  theme_modeling() +
  geom_vline(xintercept = 1, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 7, linewidth = 0.5, color = "#CC79A7") +
#  geom_abline(intercept = 8, slope = 2, color = "#56B4E9") +
 # geom_abline(intercept = 5, slope = 2, color = "#E69F00") +
  geom_point() +
  stat_summary(fun = "mean", geom = "line", show.legend = FALSE) +
  stat_summary(fun = "mean", geom = "label", show.legend = FALSE, 
               aes(label = round(..y..)), position = position_nudge(0.1)) +
  scale_x_discrete(labels = c("A.1", "A.2", "A.3")) +
  labs(title = "Zweifaktorielle Simulation",
       subtitle = "Intercept ist der Mittelwert von Gruppe A.1",
       x = "Faktor A", y = "Messwert (Y)", color = "Faktor B") +
  scale_color_okabeito(label = c("B.1", "B.2")) +
  theme(legend.position = "top")
```

#### Einkovariat $c_1$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches simples Modell mit einem Messwert $Y$ und einer kontinuierlichen Einflussvariable als Kovariate $c_1$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c1-theo

p_1cov_model 
```

```{r}
cov1_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   y = 2 + 
                       2 * c_1 + 
                           rnorm(10, 0, 0.001))
```

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 6
#| fig-cap: "foo *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c1

ggplot(cov1_tbl, aes(c_1, y)) +
  theme_modeling() +
  geom_vline(xintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_hline(yintercept = 0, linewidth = 0.5, color = "grey50") +
  geom_point() +
  stat_poly_line(color = "#E69F00", linewidth = 0.5) +
  stat_poly_eq(use_label("eq"), size = 8) +
  scale_x_continuous(breaks = -3:2) +
  scale_y_continuous(breaks = c(-4, -2, 0, 2, 4, 6)) +  
  labs(title = "Einkovariate Simulation",
       subtitle = "Intercept ist der y-Achsenabschnitt",
       x = "Covariate 1", y = "Messwert (Y)")
```

#### Zweikovariat unabhängig $c_1 + c_2$ {.unnumbered .unlisted}

```{r}
#| message: false
#| echo: false
#| warning: false
#| fig-align: center
#| fig-height: 2
#| fig-width: 7
#| fig-cap: "Schemantisches multiples Modell mit einem Messwert $Y$ und zwei kontinuierlichen Einflussvariablen als Kovariate $c_1$ und Kovariate $c_2$ dargestellt. *[Zum Vergrößern anklicken]*"
#| label: fig-eda-gen-c2-theo

p_2cov_model
```

```{r}
cov2_tbl <- tibble(c_1 = rnorm(10, 0, 1),
                   c_2 = rnorm(10, 0, 1),
                   y = 2 + 
                       1 * c_1 + 
                       2 * c_2 + 
                           rnorm(10, 0, 0.001))
```

```{r}
lm(y ~ c_1 + c_2, cov2_tbl) |> 
  coef() |> round(2)
```

#### Zweikovariat abhängig $c_1 + c_2$ {.unnumbered .unlisted}

#### Komplexere Modelle {.unnumbered .unlisted}

::: panel-tabset
## `tibble()`

## `{simstudy}`

## Excel

`NORM.INV(ZUFALLSZAHL(); 0; 5)`
:::

### Possionverteilter Messwert

### Ordinalverteilter Messwert

[Ordinal Categorical Data](https://kgoldfeld.github.io/simstudy/articles/ordinal.html)

### Binomialverteilter Messwert

### Zeitreihen

[Spline Data](https://kgoldfeld.github.io/simstudy/articles/spline.html)

## Referenzen {.unnumbered}
